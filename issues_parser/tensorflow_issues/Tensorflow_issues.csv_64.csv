Issue Number,Issue Title,Issue Body
9634,cuda_configure.bzl makes bad symlink for: cuda/include/cudnn.h --> cuda/include/include/cudnn.h,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS release 6.7 (Final) x86_64
- **TensorFlow installed from (source or binary)**:  source
- **TensorFlow version (use command below)**: master: git version 550df413158b32645ca5df4dcaabc67f1a48964d (checked out May 3rd 2017)
- **Bazel version (if compiling from source)**: bazel-0.4.5
- **CUDA/cuDNN version**: 7.5/5.1.3
- **GPU model and memory**: Quadro K600 1GB DDR3
- **Exact command to reproduce**:

```
setenv CC '/mnt/nfs/home/momeara/opt/bin/gcc'
setenv CXX '/mnt/nfs/home/momeara/opt/bin/g++'
setenv EXTRA_BAZEL_ARGS '--verbose_failures --jobs=1'
setenv CPLUS_INCLUDE_PATH '/mnt/nfs/home/momeara/opt/include'
setenv C_INCLUDE_PATH '/mnt/nfs/home/momeara/opt/include'
setenv LIBRARY_PATH '/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64'
setenv LD_LIBRARY_PATH /mnt/nfs/work/momeara/sea/DeepSEA/cuda/lib64:/usr/local/cuda-7.5/lib64:/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64:/usr/local/cuda-7.5/extras/CUPTI/lib64:$LD_LIBR\
ARY_PATH
setenv PATH /usr/local/cuda-7.5/bin:/mnt/nfs/work/momeara/sea/DeepSEA/tensorflow/bazel-0.4.5/output:$PATH

./configure
Please specify the location of python. [Default is /mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin/python]:
Found possible Python library paths:
  /mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/lib/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/lib/python2.7/site-packages]

Using python library path: /mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/lib/python2.7/site-packages
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n] n
jemalloc disabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y
XLA JIT support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N] y
VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N] n
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N] n
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify which gcc should be used by nvcc as the host compiler. [Default is /mnt/nfs/home/momeara/opt/bin/gcc]:
Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5.1.3
Please specify the location where cuDNN 5.1.3 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /mnt/nfs/work/momeara/sea/DeepSEA/cuda
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 5.2
WARNING: Output base '/mnt/nfs/home/momeara/.cache/bazel/_bazel_momeara/ef8339021629a8146b3e301bb7dc3099' is on NFS. This may lead to surprising failures and undetermined behavior.
................................................................................
____Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
Configuration finished

bazel --output_user_root=/scratch/momeara/.cache/baze build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --jobs=1
```

### Describe the problem
During configure, it tries to make a symlink

    ln -s /mnt/nfs/work/momeara/sea/DeepSEA/cuda/include/cudnn.h /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow/bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include/cudnn.h

but this fails because the directory `/scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow/bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include` does not exist

notice that it has `include/include` at the end.

If I change this line: https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/cuda_configure.bzl#L877

    genrules.append(_symlink_genrule_for_dir(repository_ctx, None, """",
            ""cudnn-include"", [cudnn_header_dir + ""/cudnn.h""], [""include/cudnn.h""]))

to 

    genrules.append(_symlink_genrule_for_dir(repository_ctx, None, """",
            ""cudnn-include"", [cudnn_header_dir + ""/cudnn.h""], [""cudnn.h""]))

the build proceeds without error


### Source code / logs

____[107 / 393] Writing script external/local_config_cuda/cuda/cuda-include.genrule_script.sh [for host]
ERROR: /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/external/local_config_cuda/cuda/BUILD:1309:1: Executing genrule @local_config_cuda//cuda:cudnn-include failed: bash failed: error exec\
uting command
  (cd /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/mnt/nfs/work/momeara/sea/DeepSEA/cuda/lib64:/usr/local/cuda-7.5/lib64:/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64:/usr/local/cuda-7.5/extras/CUPTI/lib64:/mnt/nfs/ho\
me/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64 \
    PATH=/usr/local/cuda-7.5/bin:/mnt/nfs/work/momeara/sea/DeepSEA/tensorflow/tensorflow/bazel-0.4.5/output:/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin:/mnt/nfs/work/momeara/tools/anaconda2/bin:\
/mnt/nfs/home/momeara/.local/bin:/mnt/nfs/home/momeara/opt/node-v4.5.0-linux-x64/bin:/mnt/nfs/home/momeara/opt/bin:/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin:/mnt/nfs/work/momeara/tools/anacond\
a2/bin:/mnt/nfs/home/momeara/.local/bin:/mnt/nfs/home/momeara/opt/node-v4.5.0-linux-x64/bin:/mnt/nfs/home/momeara/opt/bin:/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin:/mnt/nfs/work/momeara/tools/\
anaconda2/bin:/mnt/nfs/home/momeara/.local/bin:/mnt/nfs/home/momeara/opt/node-v4.5.0-linux-x64/bin:/mnt/nfs/home/momeara/opt/bin:/usr/lib64/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/bin:\
/bin:/usr/bin \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh;
ln -s /mnt/nfs/work/momeara/sea/DeepSEA/cuda/include/cudnn.h bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include/cudnn.h    '): com.google.devtools.build.lib.shell.BadExitStatusExcept\
ion: Process exited with status 1.
ln: creating symbolic link `bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include/cudnn.h': No such file or directory
blaze: Leaving directory `/scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow/'
____Building complete.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
____Elapsed time: 75.364s, Critical Path: 3.99s

"
9633,SIGSEGV with sparse_add and broadcasting,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes, enclosed below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary via pip
- **TensorFlow version (use command below)**:
('v1.0.0-65-g4763edf-dirty', '1.0.1')
- **Bazel version (if compiling from source)**:
N/A, using pip installation
- **CUDA/cuDNN version**:
N/A, CPU-only
- **GPU model and memory**:
none
- **Exact command to reproduce**:
```
from __future__ import print_function
import numpy as np
import tensorflow as tf

dense_sz = [1, 1000, 1000]
dense = tf.constant(1.0, shape=dense_sz, dtype=tf.float32)

sparse_sz = [10, 1000, 1000]
nnz = 100
nz_ind = np.random.choice(np.prod(sparse_sz), size=nnz, replace=False)
nz_ind = np.unravel_index(nz_ind, dims=sparse_sz)
nz_ind = np.array(nz_ind).T
assert np.all(nz_ind < np.array(sparse_sz)[None, :])
# Ensure canonical ordering.
ind = np.lexsort([nz_ind[:, i].flatten() for i in reversed(range(nz_ind.shape[1]))])
nz_ind = nz_ind[ind, :]
print('nz_ind\n', nz_ind)

sparse_plc = tf.sparse_placeholder(tf.float32)
sparse_sum = tf.sparse_add(dense, sparse_plc)
init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    print('after init')
    res = sess.run(sparse_sum, feed_dict={sparse_plc: tf.SparseTensorValue(nz_ind, np.ones((nnz,)), sparse_sz)})
    print('sum\n', res)
```

### Describe the problem
Running the code above results in
```
[...]
after init

Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)
```
For lower values of nnz, (nnz = 1) it finishes fine quite often.
```
[...]
after init
sum
 [[[ 1.  1.  1. ...,  1.  1.  1.]
  [ 1.  1.  1. ...,  1.  1.  1.]
  [ 1.  1.  1. ...,  1.  1.  1.]
  ..., 
  [ 1.  1.  1. ...,  1.  1.  1.]
  [ 1.  1.  1. ...,  1.  1.  1.]
  [ 1.  1.  1. ...,  1.  1.  1.]]]

Process finished with exit code 0
```

### Source code / logs
See above."
9632,"building error, tensorflow r1.0, with bazel 0.4.5, Ubuntu 16.04.1 LTS    armv7 board","I try to use TensorFlow r1.0 on an Odroid-XU3 board (armv7).
The distribution is an Ubuntu 16.04.1 LTS (Xenial Xerus)

Bazel is succesfully installed from bazel-0.4.5-dist.zip

During the configuration, I get multiple errors:

````
odroid@odroid:~/local_DT_project/tensorflow_git$ python --version
Python 2.7.12

odroid@odroid:~/local_DT_project/tensorflow_git$ git status
On branch r1.0
Your branch is up-to-date with 'origin/r1.0'.
nothing to commit, working directory clean

odroid@odroid:~/local_DT_project/tensorflow_git$ ./configure
Please specify the location of python. [Default is /usr/bin/python]:
Please specify optimization flags to use during compilation [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n]
jemalloc enabled on Linux
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow 
Do you wish to build TensorFlow with CUDA support? [y/N]
No CUDA support will be enabled for TensorFlow   
Configuration finished
.........................................................................................................
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
....................................................................................................
ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/workspace.bzl:403:3: no such package '@junit_jar//jar': Error downloading [https://gith
ub.com/junit-team/junit4/releases/download/r4.12/junit-4.12.jar] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/
junit_jar/junit-4.12.jar: java.lang.IllegalStateException and referenced by '//external:junit'.
ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/contrib/nccl/BUILD:23:1: no such package '@nccl_archive//': Error downloading [https://
github.com/nvidia/nccl/archive/024d1e267845f2ed06f3e2e42476d50f04a00ee6.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d
2dddc/external/nccl_archive/024d1e267845f2ed06f3e2e42476d50f04a00ee6.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/contrib/n
ccl:python/ops/_nccl_ops.so'.
ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/contrib/nccl/BUILD:23:1: no such package '@nccl_archive//': Error downloading [https://
github.com/nvidia/nccl/archive/024d1e267845f2ed06f3e2e42476d50f04a00ee6.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d
2dddc/external/nccl_archive/024d1e267845f2ed06f3e2e42476d50f04a00ee6.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/contrib/n
ccl:python/ops/_nccl_ops.so_check_deps'.
ERROR: Evaluation of query ""deps((//tensorflow/... - //tensorflow/examples/android/...))"" failed: errors were encountered while computing transitive c
losure.
````

Any suggestion to finish the installation?

Cheers,
Willy"
9630,separable_conv2d() got an unexpected keyword argument 'rate',"When running : 
```
model = Xception(include_top=True, weights='imagenet')
```
I'm getting this error : 

```
Traceback (most recent call last):
  File ""/home/username/PycharmProjects/segmentation/data/xception.py"", line 273, in <module>
    model = Xception(include_top=True, weights='imagenet')
  File ""/home/username/PycharmProjects/segmentation/data/xception.py"", line 155, in Xception
    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)
  File ""/home/username/.virtualenvs/cv/lib/python3.5/site-packages/keras/engine/topology.py"", line 578, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/username/.virtualenvs/cv/lib/python3.5/site-packages/keras/layers/convolutional.py"", line 986, in call
    padding=self.padding)
  File ""/home/username/.virtualenvs/cv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 2967, in separable_conv2d
    rate=dilation_rate)
TypeError: separable_conv2d() got an unexpected keyword argument 'rate'
```"
9628, tf.cond doesn't work as expected,"### System information
- **Windows 10**:
- **TensorFlow installed from pip install**:
- **TensorFlow version 1.0**:

### Describe the problem
When I use tf.cond, both f1 and f2 are executed.

### Source code / logs

    sess = tf.Session()
    x = tf.constant(7)
    y = tf.constant(5)
    lst = []
    def f1():
        global lst
        lst.append(x)
        return x
    def f2(): 
        global lst
        lst.append(y)
        return y
    r = tf.cond(tf.less(x, y), f1, f2)
    print(sess.run(lst))  #return [7,5], which means lst.append(x) and lst.append(y) are both executed
"
9627,Out of memory when running small network with mnist?,"I work in Ubuntu14.04 with 1080Ti(12GB memory).
When I run a small network using mnist data set, at the beginning, everything is OK. But after nearly 3000
 iterations with batchsize 128, tensorflow returns out of memory error. It looks something is accumulated into memory, but I don't know what it is. Here is the error log:
```
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 802816 totalling 1.86GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2492 Chunks of size 3211264 totalling 7.45GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3212544 totalling 3.06MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 2 Chunks of size 3686400 totalling 7.03MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3937280 totalling 3.75MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6422528 totalling 6.12MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 12845056 totalling 12.25MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 21105152 totalling 20.13MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 9.86GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                 10584624333
InUse:                 10582817024
MaxInUse:              10582817280
NumAllocs:                 1438980
MaxAllocSize:            115605504

W tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************
W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 3.06MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:993] Resource exhausted: OOM when allocating tensor with shape[128,32,14,14]
```
And here is part of my code:
```
def iterate_minibatches(inputs, batchsize, shuffle=False):
    if shuffle:
        indices = np.arange(len(inputs))
        np.random.shuffle(indices)
    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):
        if shuffle:
            excerpt = indices[start_idx:start_idx + batchsize]
        else:
            excerpt = slice(start_idx, start_idx + batchsize)
        yield inputs[excerpt]

X = np.load('mnist.npz')['x_train']
X = np.reshape(X,(-1,28,28,1))
epoch = 200
num = 0 
for i in range(epoch):
    for batch in iterate_minibatches(X, batchsize, shuffle=True):
        Rng = np.random.rand(batchsize,100).astype('float32')
        if  num%6!=0:
            _, p_d, err_d = sess.run([train_d,p_real,d_loss/batchsize],{real:batch,rng:Rng})
        else:
            _, p_g, err_g = sess.run([train_g,p_fake,g_loss/batchsize],{rng:Rng})
            del _
        if (num+1)%200==0:
            _img = sess.run([fake],{rng:Rng})[0]
            img = np.reshape(_img,(-1,28,28))
            img = np.array(255*img,dtype='uint8')
            save_images(img,str(num+1)+'.png')
```
What is the problem? ( No other programs occupy GPU memory）


"
9625,embedding failed on gpu,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_word2vec_basic.py
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04.5
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0/5
- **GPU model and memory**: titan x (pascal) * 4
- **Exact command to reproduce**: python tutorial_word2vec_basic.py

### Describe the problem
embedding failed on gpu
1. The code works well on CPU. 
2. The code works well with GPU disabled: 
sess = tf.InteractiveSession(config=tf.ConfigProto(device_count={'GPU':0}))
3. The code failed with GPU:
sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))

### Source code / logs
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:02:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x3a47a50
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties:
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:03:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x3a4b3d0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties:
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:82:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x3a4ed50
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties:
name: TITAN X (Pascal)
major: 6 minor: 1 memoryClockRate (GHz) 1.531
pciBusID 0000:83:00.0
Total memory: 11.90GiB
Free memory: 11.76GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 2
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 2 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 3 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0: Y Y N N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1: Y Y N N
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2: N N Y Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3: N N Y Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: TITAN X (Pascal), pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: TITAN X (Pascal), pci bus id: 0000:82:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: TITAN X (Pascal), pci bus id: 0000:83:00.0)
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0
/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: TITAN X (Pascal), pci bus id: 0000:03:00.0
/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: TITAN X (Pascal), pci bus id: 0000:82:00.0
/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: TITAN X (Pascal), pci bus id: 0000:83:00.0
I tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0
/job:localhost/replica:0/task:0/gpu:1 -> device: 1, name: TITAN X (Pascal), pci bus id: 0000:03:00.0
/job:localhost/replica:0/task:0/gpu:2 -> device: 2, name: TITAN X (Pascal), pci bus id: 0000:82:00.0
/job:localhost/replica:0/task:0/gpu:3 -> device: 3, name: TITAN X (Pascal), pci bus id: 0000:83:00.0

Load or Download matt_mahoney_text8 Dataset> data/mm_test8/
('Data size', 17005207)
132853 Steps a Epoch, total Epochs 20
learning_rate: 1.000000
batch_size: 128
()
Real vocabulary size 253854
Limited vocabulary size 50000
('Most 5 common words (+UNK)', [['_UNK', 418391], ('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764)])
('Sample data', [5239, 3084, 12, 6, 195, 2, 3137, 46, 59, 156], ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against'])
()
(12, 'as', '->', 195, 'term')
(12, 'as', '->', 5239, 'anarchism')
(12, 'as', '->', 6, 'a')
(12, 'as', '->', 3084, 'originated')
(6, 'a', '->', 2, 'of')
(6, 'a', '->', 3084, 'originated')
(6, 'a', '->', 195, 'term')
(6, 'a', '->', 12, 'as')
(195, 'term', '->', 12, 'as')
(195, 'term', '->', 2, 'of')
(195, 'term', '->', 6, 'a')
(195, 'term', '->', 3137, 'abuse')
(2, 'of', '->', 3137, 'abuse')
(2, 'of', '->', 195, 'term')
(2, 'of', '->', 46, 'first')
(2, 'of', '->', 6, 'a')
(3137, 'abuse', '->', 195, 'term')
(3137, 'abuse', '->', 2, 'of')
(3137, 'abuse', '->', 59, 'used')
(3137, 'abuse', '->', 46, 'first')
()
[TL] Word2vecEmbeddingInputlayer word2vec_layer: (50000, 128)
()
word2vec_layer/nce_biases/Adagrad: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases/Adagrad: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_biases/Adagrad/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases/Adagrad/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Adagrad: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Adagrad: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Adagrad/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Adagrad/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Adagrad: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Adagrad: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Adagrad/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Adagrad/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_biases: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_biases/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Initializer/truncated_normal/TruncatedNormal: (TruncatedNormal)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Initializer/truncated_normal/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Initializer/truncated_normal/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Initializer/truncated_normal: (Add): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Initializer/truncated_normal: (Add)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform/RandomUniform: (RandomUniform)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform: (Add): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform: (Add)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Assign: (Assign)/job:localhost/replica:0/task:0/gpu:0
init: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] init: (NoOp)/job:localhost/replica:0/task:0/gpu:0
Const_4: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Const_4: (Const)/job:localhost/replica:0/task:0/gpu:0
Const_3: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Const_3: (Const)/job:localhost/replica:0/task:0/gpu:0
Const_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Const_2: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_biases/Initializer/Const: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases/Initializer/Const: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Initializer/truncated_normal/stddev: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Initializer/truncated_normal/stddev: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Initializer/truncated_normal/mean: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Initializer/truncated_normal/mean: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Initializer/truncated_normal/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Initializer/truncated_normal/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform/max: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform/max: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform/min: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform/min: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Initializer/random_uniform/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Initializer/random_uniform/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
_send_word2vec_layer/embeddings_0: (_Send): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] _send_word2vec_layer/embeddings_0: (_Send)/job:localhost/replica:0/task:0/cpu:0
param 0: (50000, 128) (mean: -0.000195725995582, median: -0.000534415245056, std: 0.577156186104 ) word2vec_layer/embeddings:0
word2vec_layer/nce_weights: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
_send_word2vec_layer/nce_weights_0: (_Send): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] _send_word2vec_layer/nce_weights_0: (_Send)/job:localhost/replica:0/task:0/cpu:0
param 1: (50000, 128) (mean: -9.69215670921e-06, median: 2.75921775028e-05 , std: 0.0777502208948 ) word2vec_layer/nce_weights:0
word2vec_layer/nce_biases: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
_send_word2vec_layer/nce_biases_0: (_Send): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] _send_word2vec_layer/nce_biases_0: (_Send)/job:localhost/replica:0/task:0/cpu:0
param 2: (50000,) (mean: 0.0 , median: 0.0 , std: 0.0 ) word2vec_layer/nce_biases:0
num of params: 12850000
layer 0: Tensor(""word2vec_layer/embedding_lookup:0"", shape=(128, 128), dtype=float32)
50000 vocab saved to vocab_text8.txt in /home/omnisky/app/sourceCode/tensorlayer/example
word2vec_layer/nce_biases/Adagrad: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases/Adagrad: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/Adagrad: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/Adagrad: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/Adagrad: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/Adagrad: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/ExpandDims: (ExpandDims)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/stack: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/stack: (Pack)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/ExpandDims: (ExpandDims)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/ExpandDims: (ExpandDims)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/stack: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/stack: (Pack)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/stack: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/stack: (Pack)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/stack: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/stack: (Pack)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Prod_1: (Prod): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Prod_1: (Prod)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Maximum: (Maximum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Maximum: (Maximum)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Prod: (Prod): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Prod: (Prod)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/floordiv: (FloorDiv): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/floordiv: (FloorDiv)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Cast: (Cast): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Cast: (Cast)/job:localhost/replica:0/task:0/gpu:0
gradients/Fill: (Fill): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Fill: (Fill)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Tile: (Tile): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Tile: (Tile)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/truediv: (RealDiv): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/truediv: (RealDiv)/job:localhost/replica:0/task:0/gpu:0
gradients/Reshape_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Reshape_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
stack: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] stack: (Pack)/job:localhost/replica:0/task:0/gpu:0
ones: (Fill): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] ones: (Fill)/job:localhost/replica:0/task:0/gpu:0
gradients/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ones_like: (Fill): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ones_like: (Fill)/job:localhost/replica:0/task:0/gpu:0
nce_loss/truediv: (RealDiv): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/truediv: (RealDiv)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/mod: (FloorMod): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/mod: (FloorMod)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/ConcatOffset: (ConcatOffset): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/ConcatOffset: (ConcatOffset)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/sub_1: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/sub_1: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_3: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_3: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
nce_loss/stack_2: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/stack_2: (Pack)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/sub_1: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/sub_1: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
nce_loss/stack: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/stack: (Pack)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_biases: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_biases/read: (Identity): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_biases/read: (Identity)/job:localhost/replica:0/task:0/cpu:0
word2vec_layer/nce_weights: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/nce_weights/read: (Identity): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/nce_weights/read: (Identity)/job:localhost/replica:0/task:0/cpu:0
word2vec_layer/embeddings: (VariableV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings: (VariableV2)/job:localhost/replica:0/task:0/gpu:0
word2vec_layer/embeddings/read: (Identity): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embeddings/read: (Identity)/job:localhost/replica:0/task:0/cpu:0
nce_loss/Cast: (Cast): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Cast: (Cast)/job:localhost/replica:0/task:0/gpu:0
nce_loss/LogUniformCandidateSampler: (LogUniformCandidateSampler): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/LogUniformCandidateSampler: (LogUniformCandidateSampler)/job:localhost/replica:0/task:0/cpu:0
nce_loss/Log_1: (Log): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Log_1: (Log)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Log: (Log): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Log: (Log)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat: (ConcatV2): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat: (ConcatV2)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/embedding_lookup_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Adagrad/update_word2vec_layer/nce_weights/Unique: (Unique): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/Unique: (Unique)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_weights/Shape: (Shape): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/Shape: (Shape)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_weights/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/embedding_lookup_1_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Adagrad/update_word2vec_layer/nce_biases/Unique: (Unique): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/Unique: (Unique)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_biases/Shape: (Shape): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/Shape: (Shape)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_biases/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/cpu:0
nce_loss/embedding_lookup_1: (Gather): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/embedding_lookup_1: (Gather)/job:localhost/replica:0/task:0/cpu:0
nce_loss/Slice_3: (Slice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice_3: (Slice)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Slice_1: (Slice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice_1: (Slice)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_5: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_5: (Reshape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/embedding_lookup: (Gather): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/embedding_lookup: (Gather)/job:localhost/replica:0/task:0/cpu:0
nce_loss/Slice_2: (Slice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice_2: (Slice)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/sub_1: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/sub_1: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Slice: (Slice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice: (Slice)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/sub_1: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/sub_1: (Sub)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/concat: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/concat: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_1_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Shape_2: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Shape_2: (Shape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_1: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_1: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_2: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_2: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_1: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_1: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/Shape_1: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/Shape_1: (Shape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Adagrad/update_word2vec_layer/embeddings/Unique: (Unique): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/Unique: (Unique)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/embeddings/Shape: (Shape): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/Shape: (Shape)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/embeddings/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/strided_slice: (StridedSlice)/job:localhost/replica:0/task:0/cpu:0
word2vec_layer/embedding_lookup: (Gather): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] word2vec_layer/embedding_lookup: (Gather)/job:localhost/replica:0/task:0/cpu:0
nce_loss/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
nce_loss/add_1: (Add): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/add_1: (Add)/job:localhost/replica:0/task:0/gpu:0
nce_loss/sub_1: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/sub_1: (Sub)/job:localhost/replica:0/task:0/gpu:0
nce_loss/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/zeros_like: (ZerosLike)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_4: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_4: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ExpandDims: (ExpandDims)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_2: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_2: (Reshape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Shape_3: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Shape_3: (Shape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_2: (StridedSlice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_2: (StridedSlice)/job:localhost/replica:0/task:0/gpu:0
nce_loss/stack_1: (Pack): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/stack_1: (Pack)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ones: (Fill): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ones: (Fill)/job:localhost/replica:0/task:0/gpu:0
nce_loss/MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_3_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_3_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_3: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_3: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_4_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_4_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_4: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_4: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/Shape: (Shape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/Shape: (Shape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/BroadcastGradientArgs: (BroadcastGradientArgs)/job:localhost/replica:0/task:0/gpu:0
nce_loss/add: (Add): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/add: (Add)/job:localhost/replica:0/task:0/gpu:0
nce_loss/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_3: (ConcatV2): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_3: (ConcatV2)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_grad/zeros_like: (ZerosLike)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/Neg: (Neg): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/Neg: (Neg)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_1_grad/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_1_grad/zeros_like: (ZerosLike)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/zeros_like: (ZerosLike): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/zeros_like: (ZerosLike)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/GreaterEqual: (GreaterEqual): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/GreaterEqual: (GreaterEqual)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/Select_1: (Select): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/Select_1: (Select)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/Exp: (Exp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/Exp: (Exp)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/Log1p: (Log1p): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/Log1p: (Log1p)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/Select: (Select): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/Select: (Select)/job:localhost/replica:0/task:0/gpu:0
sampled_losses/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses/sub: (Sub)/job:localhost/replica:0/task:0/gpu:0
sampled_losses: (Add): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] sampled_losses: (Add)/job:localhost/replica:0/task:0/gpu:0
gradients/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Log1p_grad/add: (Add): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Log1p_grad/add: (Add)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Log1p_grad/Reciprocal: (Reciprocal): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Log1p_grad/Reciprocal: (Reciprocal)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Log1p_grad/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Log1p_grad/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Exp_grad/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Exp_grad/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_1_grad/Select_1: (Select): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_1_grad/Select_1: (Select)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_1_grad/Select: (Select): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_1_grad/Select: (Select)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_1_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_1_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_1_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_1_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_1_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_1_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Neg_grad/Neg: (Neg): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Neg_grad/Neg: (Neg)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Neg: (Neg): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Neg: (Neg)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/mul_1: (Mul)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_grad/Select_1: (Select): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_grad/Select_1: (Select)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_grad/Select: (Select): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_grad/Select: (Select)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Select_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Select_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/AddN: (AddN): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/AddN: (AddN)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/Slice_1: (Slice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/Slice_1: (Slice)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/Slice: (Slice): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/Slice: (Slice)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Neg: (Neg): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Neg: (Neg)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/Pad: (Pad): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/Pad: (Pad)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_1_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_1_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_1_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_1_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_1_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_1_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_1_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_1_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/Pad: (Pad): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/Pad: (Pad)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_1_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_1_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Neg: (Neg): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Neg: (Neg)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_5_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_5_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/Pad: (Pad): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/Pad: (Pad)/job:localhost/replica:0/task:0/gpu:0
gradients/AddN_1: (AddN): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/AddN_1: (AddN)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Adagrad/update_word2vec_layer/nce_biases/UnsortedSegmentSum: (UnsortedSegmentSum): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/UnsortedSegmentSum: (UnsortedSegmentSum)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_biases/SparseApplyAdagrad: (SparseApplyAdagrad): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/SparseApplyAdagrad: (SparseApplyAdagrad)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/add_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_4_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_4_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_3_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_3_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_grad/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_grad/MatMul_1: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_grad/MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_grad/MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/MatMul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/MatMul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_2_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_2_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/mul_1: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/mul_1: (Mul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/Sum_1: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/Sum_1: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/Reshape_1: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/Reshape_1: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/mul: (Mul)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/Sum: (Sum): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/Sum: (Sum)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/tuple/group_deps: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/tuple/group_deps: (NoOp)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/tuple/control_dependency_1: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/tuple/control_dependency_1: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_1_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_1_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/Pad: (Pad): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/Pad: (Pad)/job:localhost/replica:0/task:0/gpu:0
gradients/AddN_3: (AddN): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/AddN_3: (AddN)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Adagrad/update_word2vec_layer/nce_weights/UnsortedSegmentSum: (UnsortedSegmentSum): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/UnsortedSegmentSum: (UnsortedSegmentSum)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_weights/SparseApplyAdagrad: (SparseApplyAdagrad): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/SparseApplyAdagrad: (SparseApplyAdagrad)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/Mul_grad/tuple/control_dependency: (Identity): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/tuple/control_dependency: (Identity)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/ExpandDims_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/ExpandDims_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
gradients/AddN_2: (AddN): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/AddN_2: (AddN)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum: (UnsortedSegmentSum): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum: (UnsortedSegmentSum)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/embeddings/SparseApplyAdagrad: (SparseApplyAdagrad): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/SparseApplyAdagrad: (SparseApplyAdagrad)/job:localhost/replica:0/task:0/cpu:0
Adagrad: (NoOp): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad: (NoOp)/job:localhost/replica:0/task:0/gpu:0
MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
Reshape: (Reshape): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Reshape: (Reshape)/job:localhost/replica:0/task:0/gpu:0
Mean: (Mean): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Mean: (Mean)/job:localhost/replica:0/task:0/gpu:0
_recv_Placeholder_0: (_Recv): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] _recv_Placeholder_0: (_Recv)/job:localhost/replica:0/task:0/cpu:0
_recv_Placeholder_1_0: (_Recv): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] _recv_Placeholder_1_0: (_Recv)/job:localhost/replica:0/task:0/cpu:0
_send_Mean_0: (_Send): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] _send_Mean_0: (_Send)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_biases/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_biases/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_biases/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_biases/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_weights/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_weights/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/nce_weights/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/nce_weights/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/embeddings/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/embeddings/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/update_word2vec_layer/embeddings/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/update_word2vec_layer/embeddings/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/cpu:0
Adagrad/learning_rate: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Adagrad/learning_rate: (Const)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/embedding_lookup_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/ExpandDims/dim: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/Size: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/Size: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_grad/Shape: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_grad/Shape: (Const)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/Slice_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/stack/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/stack/1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_grad/Rank: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_grad/Rank: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/ExpandDims/dim: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/Size: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/Size: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/word2vec_layer/embedding_lookup_grad/Shape: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/word2vec_layer/embedding_lookup_grad/Shape: (Const)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/ExpandDims_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/ExpandDims_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Mul_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Mul_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_2_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_2_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/ExpandDims/dim: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/Size: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/Size: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/embedding_lookup_1_grad/Shape: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/embedding_lookup_1_grad/Shape: (Const)/job:localhost/replica:0/task:0/cpu:0
gradients/nce_loss/Slice_2_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/stack/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/stack/1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_2_grad/Rank: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_2_grad/Rank: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/stack/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/stack/1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_1_grad/Rank: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_1_grad/Rank: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/concat/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/concat/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/stack/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/stack/1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Slice_3_grad/Rank: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Slice_3_grad/Rank: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/Reshape_5_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/Reshape_5_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_1_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/add_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/add_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_1_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_1_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/sub_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/sub_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/nce_loss/concat_3_grad/Rank: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/nce_loss/concat_3_grad/Rank: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/mul_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/mul_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/sub_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/sub_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Reshape_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Reshape_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Maximum/y: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Maximum/y: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Const_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Const_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Const: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Const: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Tile/multiples: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Tile/multiples: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Mean_grad/Reshape/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Mean_grad/Reshape/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Const: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Const: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
Const_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Const_1: (Const)/job:localhost/replica:0/task:0/gpu:0
Reshape/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Reshape/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
ones/Const: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] ones/Const: (Const)/job:localhost/replica:0/task:0/gpu:0
stack/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] stack/1: (Const)/job:localhost/replica:0/task:0/gpu:0
strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
strided_slice/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] strided_slice/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_4/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_4/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/truediv/y: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/truediv/y: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ones_like/Const: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ones_like/Const: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ones_like/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ones_like/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_3/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_3/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Slice_3/size: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice_3/size: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Shape_5: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Shape_5: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Slice_2/size: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice_2/size: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/stack_2/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/stack_2/1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_3/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_3/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_3/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_3/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_3/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_3/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Shape_4: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Shape_4: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_5/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_5/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_4/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_4/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Reshape_3/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape_3/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ones/Const: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ones/Const: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/stack_1/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/stack_1/1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_2/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_2/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_2/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_2/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_2/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_2/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_2/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_2/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_2/values_0: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_2/values_0: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/ExpandDims/dim: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/ExpandDims/dim: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_1/axis: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_1/axis: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat_1/values_0: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat_1/values_0: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_1/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_1/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_1/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_1/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice_1/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice_1/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Slice_1/begin: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice_1/begin: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Shape_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Shape_1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Slice/begin: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Slice/begin: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/stack/1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/stack/1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice/stack_2: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice/stack_2: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice/stack_1: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice/stack_1: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/strided_slice/stack: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/strided_slice/stack: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/Shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Shape: (Const)/job:localhost/replica:0/task:0/gpu:0
nce_loss/concat/axis: (Const): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/concat/axis: (Const)/job:localhost/replica:0/task:0/cpu:0
nce_loss/Reshape/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] nce_loss/Reshape/shape: (Const)/job:localhost/replica:0/task:0/gpu:0
gradients/sampled_losses/Log1p_grad/add/x: (Const): /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] gradients/sampled_losses/Log1p_grad/add/x: (Const)/job:localhost/replica:0/task:0/gpu:0
E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Invalid argument: AttrValue must not have reference type value of float_ref
for attr 'tensor_type'
; NodeDef: word2vec_layer/embeddings/Adagrad/_71 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_100_word2vec_layer/embeddings/Adagrad"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^Adagrad/learning_rate, ^Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum, ^Adagrad/update_word2vec_layer/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: AttrValue must not have reference type value of float_ref
for attr 'tensor_type'
; NodeDef: word2vec_layer/embeddings/Adagrad/_71 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_100_word2vec_layer/embeddings/Adagrad"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^Adagrad/learning_rate, ^Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum, ^Adagrad/update_word2vec_layer/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
[[Node: word2vec_layer/embeddings/Adagrad/_71 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_100_word2vec_layer/embeddings/Adagrad"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^Adagrad/learning_rate, ^Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum, ^Adagrad/update_word2vec_layer/embeddings/Unique)]]
Traceback (most recent call last):
File ""tutorial_word2vec_basic.py"", line 369, in 
main_word2vec_basic()
File ""tutorial_word2vec_basic.py"", line 246, in main_word2vec_basic
_, loss_val = sess.run([train_op, cost], feed_dict=feed_dict)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 767, in run
run_metadata_ptr)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _run
feed_dict_string, options, run_metadata)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
target_list, options, run_metadata)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: AttrValue must not have reference type value of float_ref
for attr 'tensor_type'
; NodeDef: word2vec_layer/embeddings/Adagrad/_71 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_100_word2vec_layer/embeddings/Adagrad"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^Adagrad/learning_rate, ^Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum, ^Adagrad/update_word2vec_layer/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
[[Node: word2vec_layer/embeddings/Adagrad/_71 = _Recv[_start_time=0, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_100_word2vec_layer/embeddings/Adagrad"", tensor_type=DT_FLOAT_REF, _device=""/job:localhost/replica:0/task:0/cpu:0""](^Adagrad/learning_rate, ^Adagrad/update_word2vec_layer/embeddings/UnsortedSegmentSum, ^Adagrad/update_word2vec_layer/embeddings/Unique)]]
"
9624,Is batch_norm_param argument missing in the depthwise convolution 2d layer implementation?,"This is with reference to: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L1850

The line says ""if `batch_norm_params` is None"" but there is no batch_norm_params argument included in the function, and it doesn't seem that batch_norm is implemented within the function as an option. Is the batch_norm function included in the regularizer function or has it not been implemented by default within the function?

Thanks for your help."
9623,What is the best way to test speed of TF,I am trying to test the speed of TF but seems TF is using python and it is gonna be quite slow. What is the rrecommended way to test the speed of a model in TF?
9621,How can I load data from a data file just like http://projector.tensorflow.org/ does when using Tensorboard embedding projector,"At http://projector.tensorflow.org/  we can choose a data file from our own computer by the `Load data` button(see the red rectangle below) and visualize the high-dimensional data
![image](https://cloud.githubusercontent.com/assets/7208819/25652477/fbc9675e-301a-11e7-931f-c7bb22fbdea2.png)
![image](https://cloud.githubusercontent.com/assets/7208819/25652234/ce6c2158-3019-11e7-9c10-47fe2a1e2224.png)

But when I tried to using Tensorboard embedding on my own computer (follow the instruction at https://www.tensorflow.org/get_started/embedding_viz and start a server on localhost:6006 by command `tensorboard --logdir=LOG_DIR` )
I just find the `Load data` button doesn't exist (see below)

![image](https://cloud.githubusercontent.com/assets/7208819/25652904/0f4ff566-301d-11e7-9a1e-4d097d108349.png)

So I want to ask when I run Tensorboard on localhost, how can I enable the load data button like http://projector.tensorflow.org/ does, thus I can visualize the high-dimensional data by uploading my file rather than writing code ?

thanks a lot :)

"
9620,inception/imagenet_distributed_train running is faild,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Not - Use last TF master and last Models
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:   Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: from source ( dramatically less compilation number of files, less in 100 files.)
- **TensorFlow version (use command below)**: 'v1.1.0-rc2-607-g550df41', '1.1.0-rc2' 

- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: 8.0, 6
- **GPU model and memory**: Nvidia P100 PCI - 16 GB
- **Exact command to reproduce**:
On ps - bazel-bin/inception/imagenet_distributed_train --job_name='ps' --task_id=0 --ps_hosts='11.11.11.31:2222' --worker_hosts='11.11.11.41:2222,11.11.11.41:2223'

All good 

INFO:tensorflow:PS hosts are: ['11.11.11.31:2222']
INFO:tensorflow:Worker hosts are: ['11.11.11.41:2222', '11.11.11.41:2223']
2017-05-03 11:12:54.447399: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2017-05-03 11:12:54.447459: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 11.11.11.41:2222, 1 -> 11.11.11.41:2223}
2017-05-03 11:12:54.456646: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:296] Started server with target: grpc://localhost:2222

### Describe the problem

On Worker 

CUDA_VISIBLE_DEVICES='1' bazel-bin/inception/imagenet_distributed_train --batch_size=128 --job_name='worker' --ps_hosts='11.11.11.31:2222' --worker_hosts='11.11.11.41:2222,11.11.11.41:2223' --data_dir=/data/imagenet_data/ --train_dir=/data/imagenet_train/ --task_id=1

It's failed with
 INFO:tensorflow:PS hosts are: ['11.11.11.31:2222']                                                                
INFO:tensorflow:Worker hosts are: ['11.11.11.41:2222', '11.11.11.41:2223']                                        
2017-05-03 11:24:17.640127: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> 11.11.11.31:2222}                                                                        
2017-05-03 11:24:17.640169: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 11.11.11.41:2222, 1 -> localhost:2223}                                               
2017-05-03 11:24:17.648767: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:296] Started server with target: grpc://localhost:2223                                                                                     
Traceback (most recent call last):                                                                                
  File ""/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 66, in <module>                                                                     
    tf.app.run()                                                                                                  
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run                
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))                                                            
  File ""/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py"", line 62, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File ""/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_distributed_train.py"", line 157, in train
    inception.loss(logits, labels)
  File ""/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_model.py"", line 128, in loss
    weight=1.0)
  File ""/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/slim/losses.py"", line 166, in cross_entropy_loss
    cross_entropy = tf.contrib.nn.deprecated_flipped_softmax_cross_entropy_with_logits(
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/lazy_loader.py"", line 53, in __getattr__
    module = self._load()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/lazy_loader.py"", line 42, in _load
    module = importlib.import_module(self.__name__)
  File ""/usr/lib/python2.7/importlib/__init__.py"", line 37, in import_module
    __import__(name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py"", line 34, in <module>
    from tensorflow.contrib import image
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/__init__.py"", line 39, in <module>
    from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereograms
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py"", line 26, in <module>
    ""_single_image_random_dot_stereograms.so""))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/python/ops/_single_image_random_dot_stereograms.so: undefined symbol: _ZN6google8protobuf8internal10LogMessageC1ENS0_8LogLevelEPKci

Thanks,

Boris





"
9619,feed input node (which is a sentence) using Tensor Flow Inference Interface,"hi all,

unfortunately there is little stuff when we are going to link the tensorflow model to android
this is the thing I am doing
I freezed and optimized tensorflow model
It is a RNN lstm model , getting a sentence then saying if that positive or negative
I successfully added all the things in android studio
Now I have a editbox to enter my sentence , then touch Run button, then this run button should fill the label if this sentence was positive or negative,

but dont know how to feed input node when that is sentence, 
even didnt find any document to do so,

hope someone kindly help me

I did  something like this but is incorrect
`protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    inferenceInterface = new TensorFlowInferenceInterface();
    inferenceInterface.initializeTensorFlow(getAssets(), MODEL_FILE);


    final Button button = (Button) findViewById(R.id.button);

    button.setOnClickListener(new View.OnClickListener() {
        public void onClick(View v) {

            final EditText editNum1 = (EditText) findViewById(R.id.editNum1);

            inferenceInterface.fillNodeInt(INPUT_NODE, INPUT_SIZE, editNum1);

            inferenceInterface.runInference(new String[] {OUTPUT_NODE});

            int[] resu = {0, 0};
            inferenceInterface.readNodeInt(OUTPUT_NODE, resu);

            final TextView textViewR = (TextView) findViewById(R.id.txtViewResult);
            textViewR.setText(Float.toString(resu[0]) + "", "" + Float.toString(resu[1]));
        }
    });

}`
the problem is I couldnt find any method in TensorFlowInferenceInterface that gives the string as input they were int or float or byte

appreciate you help
"
9618,Can't load the model file from model_dir in CNN text classifier,"Dear all,
I am working on NLP using tensor flow, i am using thhe text classifier using cnn from the tensor flow git hub example, where i stored my trained model by passing ""model_dir"" argument successfully , but when i try to reload the model it says an error
Error occurring part of my code is, 

""
classifier = learn.Estimator(model_fn=cnn_model,model_dir = ""/home/local/models/"")
#classifier.fit(x_train, y_train, steps=1000)
y_predicted = [p['class'] for p in classifier.predict(x_test, as_iterable=True)]
print(y_predicted)
""
this is a code when i try to reload the model file files from the ""model_dir"" which is already stored in it when train.

The error is ,

""
Traceback (most recent call last):
  File ""CNN_Text.py"", line 114, in <module>
    y_predicted = [p['class'] for p in classifier.predict(x_test, as_iterable=True)]
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 281, in new_func
    return func(*args, **kwargs)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 565, in predict
    as_iterable=as_iterable)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 857, in _infer_model
    infer_ops = self._get_predict_ops(features)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1188, in _get_predict_ops
    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.INFER)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1103, in _call_model_fn
    model_fn_results = self._model_fn(features, labels, **kwargs)
  File ""CNN_Text.py"", line 31, in cnn_model
    target = tf.one_hot(target, 2, 1, 0)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 2156, in one_hot
    name)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1848, in _one_hot
    axis=axis, name=name)
  File ""/home/local/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 509, in apply_op
    (input_name, err))
ValueError: Tried to convert 'indices' to a tensor and failed. Error: None values not supported.
""

Please help me to solve this problem.
Thank you in advance."
9616,NameError: name' core' is not defined !,"When I try to : import tensorflow as tf
this error appears:

NameError: name' core' is not defined !

What should I do?"
9614,Tensorboard not fully functional behind nginx proxy,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes. The ngnix configuration to proxy tensorboard from port 6006 to port 80. Details below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
('v1.0.1-2-g250e72c-dirty', '1.0.1')
- **Bazel version (if compiling from source)**:
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778
- **CUDA/cuDNN version**:
8.0.61/cudnn-8.0-linux-x64-v5.1
- **GPU model and memory**:
""TITAN X (Pascal) and 12187 MBytes
- **Exact command to reproduce**:
tensorboard  --logdir /tmp/retrain_logs/

### Describe the problem
I follow the image retraining tutorial  [https://www.tensorflow.org/tutorials/image_retraining]. As we have different applications providing a webinterface and a firewall that blocks all ports except 22(ssh) and 80(http)/443(https) we want to put all of them behind a nginx proxy. 
With the config below the tensorboard shows up, however no data is displayed.
When disabling all other applications / services that run on port 80 and forcing tensorboard to deliver on port 80 with `sudo tensorboard --port 80 --logdir /tmp/retrain_logs` the data graphs (ie. accuracy_1, cross_entropy_1, etc.) are displayed. 

### Source code / logs
`server {
        listen 80 default_server;
        listen [::]:80 default_server;

        root /var/www/html;

        # Add index.php to the list if you are using PHP
        index index.html index.htm index.nginx-debian.html;

        server_name _;

        location / {
                # First attempt to serve request as file, then
                # as directory, then fall back to displaying a 404.
                try_files $uri $uri/ =404;
        }
        location /tensorflow {
                rewrite ^/tensorflow(.*) /$1 break;
                proxy_pass http://127.0.0.1:6006/;
        }
}
`


"
9613,ValueError:tensorflow,"when I'm trying to run the tensorflow odel with my data generating an error as:

Traceback (most recent call last):
  File ""/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/__main__/textsum/seq2seq_attention.py"", line 214, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/ubuntu/tensorflow/models/summarization/bazel-bin/textsum/seq2seq_attention.runfiles/__main__/textsum/seq2seq_attention.py"", line 209, in main
    decoder = seq2seq_attention_decode.BSDecoder(model, batcher, hps, vocab)
  File ""/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_decode.py"", line 95, in __init__
    self._model.build_graph()
  File ""/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py"", line 296, in build_graph
    self._add_seq2seq()
  File ""/home/ubuntu/tensorflow/models/summarization/textsum/seq2seq_attention_model.py"", line 224, in _add_seq2seq
    tf.log(tf.nn.softmax(model_outputs[-1])), hps.batch_size*2)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1970, in top_k
    return gen_nn_ops._top_kv2(input, k=k, sorted=sorted, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 2462, in _top_kv2
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2397, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1757, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1707, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: input must have last dimension >= k = 128 but is 102 for 'seq2seq/decode_output/TopKV2' (op: 'TopKV2') with input shapes: [64,102], [].
"
9612,Problems on the doc of install cudnn on Ubuntu and OS X,"The [docs on install CUDA on Ubuntu as well as OS X](https://www.tensorflow.org/install/install_linux) says that we need to set CUDA_HOME as described in the NVIDIA documentation as following, however, I cannot find any NVIDIA official documentation on how to set CUDA_HOME, could anyone provide this doc so that we can make the doc better?

>  Ensure that you create the CUDA_HOME environment variable as described in the NVIDIA documentation.


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9610,Broken link Mac/GPU/py3 whl file,"On page: 
[https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package](https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package)

This link is broken:
[https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl](https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl)"
9603,Try launch tensorflow and get error,"i have install tensorflow on windows 10 and when i put a demo he gives me this error plz help me tanks

![capturar](https://cloud.githubusercontent.com/assets/17919329/25643061/65e33d62-2f95-11e7-9d78-18ad59ec8526.JPG)
"
9600,Why the basic function of different rnn cells are different?,"I'd like to tackle two issues. The first one is about the initializer. I can define initializer in `LSTMCell ` but not in `GRU` cell. The second one is `layer_normalization`. There is `LayerNormBasicLSTMCell` available for using layer normalization on LSTM cell. But there is not other kinds of cell used in that way. I wonder why not make this general functions available for all kinds of cells?
"
9599,couldn't find libtensorflow_demo.so,"java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader
I tried to integrate the tensorflow android sample to my existing project but the TensorFlowClassifier cannot execute since libtensorflow_demo.so is not loaded. What should I do?"
9597,Invalid link in https://www.tensorflow.org/deploy/distributed,"Seems that the [CIFAR-10 multi-GPU trainer](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/image/cifar10/cifar10_multi_gpu_train.py) link in https://www.tensorflow.org/deploy/distributed is broken. Actually this code only exists <= r0.12. There is three ways to fix it:
  1. Use an old version such as  [CIFAR-10 multi-GPU trainer](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow_models/tutorials/image/cifar10/cifar10_multi_gpu_train.py)
  2. Remove this link in the doc page
  3. Create a new cifar10_multi_gpu_train.py file for r1.1

I can work on this issue, is there any suggestions on which way to go?

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9596,Synchronous distributed tensorflow training doesn't synchronize among workers,"### System Information:
- **Debian 4.5.5**
- **TF installed from binary (pip3 install tensorflow-gpu==1.0.1 --user)**
- **TF version: v1.0.0-65-g4763edf-dirty 1.0.1**
- **Bazel version: N.A.**
- **CUDA 8.0 cuDNN v5.1**

### Steps to reproduce
1. Make a directory and download the following files into it:
[training.py](https://gist.github.com/GD06/b88d4b20a4587add984323525bbf4be2) [run.sh](https://gist.github.com/GD06/0bdb36ba6b76070b7cd7fadfd30fce6b)
2. Run the command ./run.sh to simply reproduce this issue.

### Detailed descriptions for the bug

Recently, I tried to deploy the synchronous distributed tensorflow training on the cluster. I followed the tutorial and the inception example to write my own program. The [training.py](https://gist.github.com/GD06/b88d4b20a4587add984323525bbf4be2) is from other user's [implementation](http://ischlag.github.io/2016/06/12/async-distributed-tensorflow/), which follows the same API usage as the official example. I modified it to enable it running on a single machine with multiple GPUs by making them communicate through localhost and mapping each worker to see only one GPU.

The [run.sh](https://gist.github.com/GD06/0bdb36ba6b76070b7cd7fadfd30fce6b) launched three processes. One of them is the parameter server and the others are two workers implemented by between-graph replication. I created the training supervisor by tf.train.Supervisor() to manage multiple sessions in the distributed training for the initialization and synchronization. 

I expect these two workers would synchronize each batch and work in the same epoch. However, the worker 0, which is launched prior to the worker 1, completed the whole training set without waiting for the worker 1. After that, the process of the worker 0 finished training process and exited normally while worker 1 behaved like falling into the deadlock and keep near 0% utilization of CPU and GPU for several hours.

Based on my observation, I suspect these two workers didn't communicate and synchronize at all for the data they passed. I report this problem as a bug because I create the optimizer tf.train.SyncReplicasOptimizer as suggested by the official website and the inception example. However, it seems that the synchronization behaviors, if any, are very strange and the program can not exit normally.

### Source code / logs
Two files:
[training.py](https://gist.github.com/GD06/b88d4b20a4587add984323525bbf4be2): This file contains the source code for the parameter server and workers created to use synchronous distributed optimizers (tf.train.SyncReplicasOptimizer). 
[run.sh](https://gist.github.com/GD06/0bdb36ba6b76070b7cd7fadfd30fce6b): This file launched the parameter server and the workers.
Log:
Please produce according to the steps and look at worker_0_log and worker_1_log

### Update
To ensure that two workers don't synchronize with each other, I write another [training.py](https://gist.github.com/GD06/b56d62b718bbd0b033703320e4b214dc) by making the worker 1 exist after the first time output information. Then the worker 0 continue to execute without waiting for the worker 1 and obtain the final trained model. This kind of behavior surely disobeys the definition of the synchronous distributed training."
9594,How can I check the test coverage?,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12
- **TensorFlow installed from (source or binary)**: (binary) pip install tensorflow
- **TensorFlow version (use command below)**: 
tensorflow (1.1.0)
tensorflow-gpu (1.0.1)
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: AMD Radeon R9 M370X 2048 MB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm planning to develop some test codes for contribution.
Therefore, I need to find some untested codes using code coverage tools.

I have tried to find the way to check test coverage in this project.
But I couldn't figure that out.

Is there anyone tell me how to check it out?

I'm now running tests like this.
```
./configure
bazel test //tensorflow/tensorboard/backend:application_test
```

Sincerely
"
9593,libtensorflow.so: undefined reference to `__cpu_model',"When linking with the tensorflow C++ library, the following error occurs: libtensorflow.so: undefined reference to `__cpu_model'

Seems to be related to issue #7223

I manage to work around this error with: ( as done by https://github.com/tensorflow/tensorflow/pull/7241/commits/d7955a66088567ade60213448bbab861de9055cd)
`#ifndef USE_SSE_CRC32C`
in the file tensorflow/core/lib/hash/crc32c_accelerate.cc

Doing this removed the error.

System information:
Ubuntu 16.04 64 bit
Intel i5 CPU
NVIDIA GTX 980 GPU
Built using CMake with BUILD_SHARED_LIB enabled which creates the libtensorflow.so file
"
9591,Several links error in README.md.,"### System information
- **OS: Windows 10 Enterprise x64**:
- **Browser: Chrome 58 x64**:
- **Location: China**:

### Issue
The [Installing TensorFlow](https://www.tensorflow.org/install/) link from [README.md](https://github.com/tensorflow/tensorflow) fails with error:
```
Error: Not Found

The requested URL /versions/r0.12/install/index.html was not found on this server.
```

The [Community](https://www.tensorflow.org/community/) link fails with error:
```
Error: Not Found

The requested URL /versions/r0.12/community/index.html was not found on this server.
```

"
9590,Memory Leak from Deep Learning Training Step? (Finalized Graph),"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, although my code is somewhat based on the MNIST deep learning tutorial.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04 VERSION=""14.04.5 LTS, Trusty Tahr""
- **TensorFlow installed from (source or binary)**:
binary (I think, not 100% sure since it's been a few months since install. How can I check?)
- **TensorFlow version (use command below)**:
('v0.11.0-2614-g14aeb08-dirty', '0.12.0-rc0')
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA Version 8.0.44
- **GPU model and memory**:
GeForce GTX 780M 4GB
- **Exact command to reproduce**:
`self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})`

### Describe the problem

I apologize if this is not an actual bug; I am relatively new to TensorFlow. I have posted on StackOverflow [here](http://stackoverflow.com/questions/43695085/tensorflow-deep-learning-memory-leak) and the only response I have gotten suggests filing a bug report here.

If I comment the sess.run line above, _and only that line_, out (but still do all my pre-processing and validation/testing and such for a few thousand training batches), the memory leak does not happen.

The leak is on the order of a few GB per hour (I am running Ubuntu, and have 16GB RAM + 16GB swap; the system becomes very laggy and unresponsive after 1-3 hours of running, when about 1/3-1/2 the RAM is used, which is a bit weird to me since I still have lots of RAM and the CPU is mostly free when this happens...)

Here is some of the initializer code (only run once, at the beginning) if it is relevant:
```

    with tf.name_scope('after_final_layer') as scope:
        self.layer1 = weights[""wc1""]
        self.y_conv = network(self.x, weights, biases, self.keepratio)['out']
        variable_summaries(self.y_conv)
        # Note: Don't add a softmax reducer in the network if you are going to use this
        # cross-entropy function
        self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.y_conv, self.y_true, name = ""softmax/cross_ent""), name = ""reduce_mean"")
        self.train_step = tf.train.AdamOptimizer(learning_rate, name = ""Adam_Optimizer"").minimize(self.cross_entropy)

        self.prediction = tf.argmax(self.y_conv, 1)
        self.correct_prediction = tf.equal(self.prediction, tf.argmax(self.y_true, 1))

        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))

        if tensorboard:
            # Merge all the summaries and write them out to the directory below
            self.merged = tf.summary.merge_all()
            self.my_writer = tf.summary.FileWriter('/home/james/PycharmProjects/AI_Final/my_tensorboard', graph=self.sess.graph)

        # self.sess.run(tf.initialize_all_variables()) #old outdated way to do below
        tf.global_variables_initializer().run(session=self.sess)
        self.sess.graph.finalize() #make sure nothing new is added to graph

```
Notice that I have finalized the graph, so nothing new should be added to it.

Am I doing something wrong/is this expected behavior, or is this a real bug?

I have attached the source code as well (two .py files in directory).  **Note: I am happy put in the work to reduce the source to a minimal recreation of the bug, but first I'd like verification that 1) this would be helpful (i.e. that the above info is not enough) and that 2) this is probably a bug, and not just an obvious beginner mistake on my part.**

Thank you in advance.

[source.zip](https://github.com/tensorflow/tensorflow/files/969906/source.zip)"
9589,sparse_reshape could not generate correct SparseTensor shape before eval,"**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X EL Capitan & CentOS7.3.1611
TensorFlow installed from (source or binary): N/A (compiling from HEAD)
TensorFlow version (use command below): 1.1.0
CUDA/cuDNN version: none (AMD GPU)
Exact command to reproduce:

````
# python 2.7.12, tensorflow 1.1.0
import tensorflow as tf
from tensorflow.python.ops import gen_sparse_ops
from tensorflow.python.framework import sparse_tensor
from tensorflow.python.ops import array_ops

ori = tf.SparseTensor([[1,2],[3,4],[5,5]], [1,2,5], [10,10])
a = tf.sparse_reshape(ori, [100,1])
print(a.get_shape())  # will get TensorShape([Dimension(None), Dimension(None)]) instead of (TensorShape([Dimension(100), Dimension(1)]))
````

**Describe the problem**
sparse_reshape could not generate correct SparseTensor shape before eval. (but it is correct with tf.Session().run(a))
This will cause some problems for further matrix operation if we want to eval later.
The issue came from sparse_ops.py, line 428:
```SparseTensor( reshaped_ind, array_ops.identity(sp_input.values), reshaped_shape)``` 
SparseTensor could not convert ```dense_shape=reshaped_shape``` correctly before eval()
"
9588,Feature Request: SparseTensor operation,"Hi, 
I am recently using SparseTensor. However, I found that there are a lot of math operations not supported for SparseTensor. For example, mod , floor, and argmin, etc. Do you have plans for extending the math operations of SparseTensor. 

Thanks,
Anthony"
9587,tf_env_collect.sh script is not working well in Mac OS,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12
- **TensorFlow installed from (source or binary)**: (binary) pip install tensorflow
- **TensorFlow version (use command below)**: 
tensorflow (1.1.0)
tensorflow-gpu (1.0.1)
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: AMD Radeon R9 M370X 2048 MB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

This script to extract the environment is not working well in my Mac. ( MacOS 10.12 )
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

I think we should replace &>> into >> in the script.
There are 4 *&>>* in this script.
```
c++ --version &>> $OUTPUT_FILE
```

```
c++ --version >> $OUTPUT_FILE
```





### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Let me show my results.
```
./tf_env_collect.sh 
Collecting system information...
cat: /proc/1/cgroup: No such file or directory
./tf_env_collect.sh: line 31: syntax error near unexpected token `>'
./tf_env_collect.sh: line 31: `c++ --version &>> $OUTPUT_FILE'

$ cat tf_env.txt 

== cat /etc/issue ===============================================
Darwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4

== are we in docker =============================================
No

== compiler =====================================================
```

after replacing &>> into >>, the script works well in my computer.

```
$ ./tf_env_collect.sh 
Collecting system information...
cat: /proc/1/cgroup: No such file or directory
2017-05-02 14:34:10.933872: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 14:34:10.933897: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 14:34:10.933903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 14:34:10.933908: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 14:34:10.933912: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
./tf_env.sh: line 77: nvidia-smi: command not found
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt


$ cat tf_env.txt 

== cat /etc/issue ===============================================
Darwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4

== are we in docker =============================================
No

== compiler =====================================================

== cat /etc/issue ===============================================
Darwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4

== are we in docker =============================================
No

== compiler =====================================================

== uname -a =====================================================
Darwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64

== check pips ===================================================

== check for virtualenv =========================================
False

== tensorflow import ============================================

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================

== cat /etc/issue ===============================================
Darwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64
Mac OS X 10.12.4

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.1.0 (clang-802.0.38)
Target: x86_64-apple-darwin16.5.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== uname -a =====================================================
Darwin Chrisui-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.2.0)
tensorflow (1.1.0)
tensorflow-gpu (1.0.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================

== cuda libs  ===================================================
```"
9586,Support custom loss function for DNNRegressor,"DNNRegressor is commonly used, and it does not support customize the loss function, which limits itself.

I wanna know if there are any schedule to support the customize loss function for DNNRegressor or is there any difficulties for supporting that?"
9585,Links in RNN Tutorial are broken,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.12
- **TensorFlow installed from (source or binary)**: (binary) pip install tensorflow
- **TensorFlow version (use command below)**: 
tensorflow (1.1.0)
tensorflow-gpu (1.0.1)
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: AMD Radeon R9 M370X 2048 MB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I found two broken links from the RNN Tutorial.

https://www.tensorflow.org/versions/r0.12/tutorials/recurrent/

1. [Penn Tree Bank] link is broken 
<img width=""903"" alt=""rnn_tutorial1"" src=""https://cloud.githubusercontent.com/assets/3013964/25601837/ea13bdc6-2f29-11e7-8bd5-c70975f3e77b.png"">
Current link url is 
http://www.cis.upenn.edu/~treebank/

2. [building from source] link is broken
<img width=""1414"" alt=""rnn_tutorial2"" src=""https://cloud.githubusercontent.com/assets/3013964/25601838/ebfa28f0-2f29-11e7-9346-7c78c7ab9534.png"">
Current link url is 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup#installing-from-sources
"
9583,TensorArray: Tried to write to index 18 but array is not resizeable and size is: 18,"### Problem
I wrote an application using TensorArray. It prints out error about allocate memory.
For each sample. It must create a lot of TensorArray to store temporary data.
With few number of samples (around 20), it passed smoothly 100 epochs.
When I trained with the whole dataset (10.000 samples), it have never passed epoch 6. The stopped epochs are varied.

### Logs
2017-05-02 10:29:25,886 CFG INFO [Epoch 0] Shuffling data...                                                                                                                                     
(0.058350346982479095, 0.76190478)                                                                                                                                                               
2017-05-02 10:29:31.197277: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: Tried to read from index 23 but array size is: 23                                                   
2017-05-02 10:29:31.197277: W tensorflow/core/framework/op_kernel.cc:1152] Invalid argument: TensorArray bu/dec_c_ta_4628: Tried to write to index 23 but array is not resizeable and size is: 23
Traceback (most recent call last):                                                                                                                                                               
  File ""/work/vietld/py27/lib/python2.7/runpy.py"", line 174, in _run_module_as_main                                                                                                              
  File ""/work/vietld/py27/lib/python2.7/runpy.py"", line 72, in _run_code                                                                                                                         
    exec code in run_globals                                                                                                                                                                     
  File ""/home/s1610204/tree-lstm/py/run.py"", line 45, in <module>                                                                                                                                
    train(args)                                                                                                                                                                                  
  File ""/home/s1610204/tree-lstm/py/run.py"", line 29, in train                                                                                                                                   
    loss, acc = treelstm.train(session, train_data)                                                                                                                                              
  File ""py/lstmtree.py"", line 175, in train                                                                                                                                                      
    loss, acc, _ = session.run([self.full_loss, self.acc, self.train_op], feed_dict)                                                                                                             
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 778, in run                                                                                     
    run_metadata_ptr)                                                                                                                                                                            
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 982, in _run                                                                                    
    feed_dict_string, options, run_metadata)                                                                                                                                                     
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1032, in _do_run                                                                                
    target_list, options, run_metadata)                                                                                                                                                          
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1052, in _do_call                                                                               
    raise type(e)(node_def, op, message)                                                                                                                                                         
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray bu/dec_c_ta_4628: Tried to write to index 23 but array is not resizeable and size is: 23                               
         [[Node: bu/while_decode/dec/write_dec_c_ta/write_dec_c_ta = TensorArrayWriteV3[T=DT_FLOAT, _class=[""loc:@bu/dec_c_ta""], _device=""/job:localhost/replica:0/task:0/cpu:0""](bu/while_decode
/dec/cond_1/gather_dec_c_ta/Enter, bu/while_decode/Identity_3, bu/while_decode/dec/LSTM/add_6, bu/while_decode/Identity_1)]]                                                                     
                                                                                                                                                                                                 
Caused by op u'bu/while_decode/dec/write_dec_c_ta/write_dec_c_ta', defined at:                                                                                                                   
  File ""/work/vietld/py27/lib/python2.7/runpy.py"", line 174, in _run_module_as_mai ""__main__"", fname, loader, pkg_name)                                                                                                              
                                                                                                                                                         
  File ""/work/vietld/py27/lib/python2.7/runpy.py"", line 72, in _run_code exec code in run_globals                                                                                                                                                                                                                                                                                     
  File ""/home/s1610204/tree-lstm/py/run.py"", line 45, in <module>                                                                                                                                
    train(args)                                                                                                                                                                                  
  File ""/home/s1610204/tree-lstm/py/run.py"", line 20, in train                                                                                                                                   
    treelstm = RecursiveLSTM(config)                                                                                                                                                             
  File ""py/lstmtree.py"", line 137, in __init__                                                                                                                                                   
    name='while_decode')                                                                                                                                                                         
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2623, in while_loop                                                                       
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)                                                                                                                          
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2456, in BuildLoop                                                                        
    pred, body, original_loop_vars, loop_vars, shape_invariants)                                                                                                                                 
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2406, in _BuildLoop                                                                       
    body_result = body(*packed_vars_for_body)                                                                                                                                                    
  File ""py/lstmtree.py"", line 115, in decode_body                                                                                                                                                
    r_dec_c_ta = dec_c_ta.write(i, c, name='write_dec_c_ta')                                                                                                                                     
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 279, in write                                                                             
    name=name)                                                                                                                                                                                   
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_data_flow_ops.py"", line 2823, in _tensor_array_write_v3                                                          
    name=name)                                                                                                                                                                                   
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op                                                                      
    op_def=op_def)                                                                                                                                                                               
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op                                                                               
    original_op=self._default_original_op, op_def=op_def)                                                                                                                                        
  File ""/work/vietld/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__                                                                                
    self._traceback = _extract_stack()                                                                                                                                                           
                                                                                                                                                                                                 
InvalidArgumentError (see above for traceback): TensorArray bu/dec_c_ta_4628: Tried to write to index 23 but array is not resizeable and size is: 23                                             
         [[Node: bu/while_decode/dec/write_dec_c_ta/write_dec_c_ta = TensorArrayWriteV3[T=DT_FLOAT, _class=[""loc:@bu/dec_c_ta""], _device=""/job:localhost/replica:0/task:0/cpu:0""](bu/while_decode
/dec/cond_1/gather_dec_c_ta/Enter, bu/while_decode/Identity_3, bu/while_decode/dec/LSTM/add_6, bu/while_decode/Identity_1)]]      

------------------------
### System information
- **Operating system**: Altix-UV 3000, SUSE Enterprise Server 12 SP2
- **TensorFlow installed from**: binary
- **TensorFlow version**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: No GPU, 256GB RAM
- **Exact command to reproduce**:

SYSTEM ENVIRONMENT: == cat /etc/issue ===============================================
Linux altix-uv 3.12.62-60.64.8-default #1 SMP Tue Oct 18 12:21:38 UTC 2016 (42e0a66) x86_64 x86_64 x86_64 GNU/Linux
VERSION = 12
VERSION=""12-SP1""
VERSION_ID=""12.1""

== are we in docker =============================================
No

== compiler =====================================================
c++ (SUSE Linux) 4.8.5
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux altix-uv 3.12.62-60.64.8-default #1 SMP Tue Oct 18 12:21:38 UTC 2016 (42e0a66) x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.1)
protobuf (3.2.0)
tensorflow (1.1.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
2017-05-02 10:42:09.139127: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 10:42:09.139314: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 10:42:09.139322: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 10:42:09.139328: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-02 10:42:09.139334: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
sched_getaffinity: Invalid argument
can't determine number of CPU cores: assuming 4
sched_getaffinity: Invalid argument
can't determine number of CPU cores: assuming 4
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /opt/cuda/8.0/lib64:/opt/cuda/8.0/lib:/work/vietld/cuda/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 77: nvidia-smi: command not found

== cuda libs  ===================================================

### Source code / logs
I dont know why github cant attach this .zip file
Please download it from https://drive.google.com/open?id=0BxQsywFyW2C7UUVSeHBHZ25mWXM
"
9581,Enhancement: Better Model Saving & Loading,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.something
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Feature Request; not bug

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Much of it is documented here in depth; especially the pain part: http://stackoverflow.com/questions/43708616/tensorflow-inference 

I would really really appreciate a way to save JUST the model and load JUST the model as a graph.  I might even be able to help in coding this feature.

You can do it however you want; but the easiest might be to use a scoping prefix such as 'model/stuff'  I would very much like to do this:

def inference(X):
   create a model
   return prediction_op

do your training however; with TFRecords; with feed dicts; with your custom queue runners etc...There are a million options...

tf.train.ModelSaver(SCOPE_PARENT, PATH)

where SCOPE_PARENT is the top level scope to save; so if I structure my scoping as such:

'inputs/inputstuffs'
'model/layer1' , 'model/layer2' etc etc 
'adams etc'

it would save just 'model/layer1' (but not any of the gradient stuff...)

then at inference time I can do...

model = tf.train.ModelLoader(PATH)
that model takes the initial input of the first layer of that graph; whatever that is.  Most commonly for inference I see feed_dict.

so I can set up whatever kind of processing I want; either in memory based with feed_dicts or perhaps batch processing via queue runners; but the point is that the input is seperate from the model.

As it stands right now; I'm looking at TensorFlow for our use case as a non starter if the training input system is really this tightly bound to the inference system.  This type of thing really needs to be built...

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9579,MNIST Tutorial Appears to Not Toggle XLA Compilation,"I have been using the JIT compilation/XLA tutorial (https://www.tensorflow.org/performance/xla/jit#step_3_run_with_xla), and it seems that whether or not XLA compilation happens doesn't depend on the statement on line 63 in mnist_softmax_xla.py. The comment above it says that line will turn on XLA JIT compilation. When I run with the two options explained on the page (--xla='' for compiling without XLA, and TF_XLA_FLAGS=--xla_generate_hlo_graph=.* for compiling with XLA), the second executes line 63 and the first does not. But, both seem to compute in exactly the same way, going through compiler/xla/service. The output for both runs is:
```
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
2017-05-01 12:50:25.203870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-01 12:50:25.203904: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-01 12:50:25.232661: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-05-01 12:50:25.232702: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices
2017-05-01 12:50:25.233155: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
2017-05-01 12:50:25.233165: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
2017-05-01 12:50:25.233894: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-05-01 12:50:25.233903: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices
2017-05-01 12:50:25.234360: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Xpu. Devices:
2017-05-01 12:50:25.234369: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
2017-05-01 12:50:25.234372: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (1): <undefined>, <undefined>
2017-05-01 12:50:25.234376: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (2): <undefined>, <undefined>
2017-05-01 12:50:25.234379: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (3): <undefined>, <undefined>
2017-05-01 12:50:25.234382: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (4): <undefined>, <undefined>
2017-05-01 12:50:25.234385: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (5): <undefined>, <undefined>
2017-05-01 12:50:25.234389: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (6): <undefined>, <undefined>
2017-05-01 12:50:25.234392: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (7): <undefined>, <undefined>
0.9206
```"
9578,Building TensorFlow with CPU SIMD OPTIONS enabled on Windows 10 FAILED,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: master
- **Bazel version (if compiling from source)**: No
- **CUDA/cuDNN version**: No
- **GPU model and memory**: No
- **Exact command to reproduce**:MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I was following the instructions to build tensorflow on Windows 
https://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmake
The error came when I tried to build the PIP package. I have VS2015.
The error is related to zlib at  
CMake Error at C:/Projects/tensorflow/tensorflow/contrib/cmake/build/zlib/tmp/zlib-gitclone.cmake:84 (message):
    Failed to init submodules in:
    'C:/Projects/tensorflow/tensorflow/contrib/cmake/build/zlib/src/zlib'
There are more errors with the same issue (git failed to init submodules) for: highwayhash, and jasoncpp.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35\libs\python35.lib  -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Projects/tensorflow/tensorflow/contrib/cmake/build

MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj
....
""C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj"" (default target) (11) ->
(CustomBuild target) ->
  C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: ""cmd.exe"" exited with code 1 [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj]
...
msbuild.log
Creating directories for 'zlib'
  Performing download step (git clone) for 'zlib'
  Cloning into 'zlib'...
  Note: checking out '50893291621658f355bc5b4d450a8d06a563053d'.
  
  You are in 'detached HEAD' state. You can look around, make experimental
  changes and commit them, and you can discard any commits you make in this
  state without impacting any branches by performing another checkout.
  
  If you want to create a new branch to retain commits you create, you may
  
[msbuild.txt](https://github.com/tensorflow/tensorflow/files/968656/msbuild.txt)

do so (now or later) by using -b with the checkout command again. Example:
  
    git checkout -b <new-branch-name>
  
  HEAD is now at 5089329... zlib 1.2.8
  fatal: 'submodule' appears to be a git command, but we were not
  able to execute it. Maybe git-submodule is broken?
  CMake Error at zlib-gitclone.cmake:84 (message):
    Failed to init submodules in:
    'C:/Projects/tensorflow/tensorflow/contrib/cmake/build/zlib/src/zlib'
  
C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: ""cmd.exe"" exited with code 1. [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj]
Done executing task ""CustomBuild"" -- FAILED.
Done building target ""CustomBuild"" in project ""zlib.vcxproj"" -- FAILED.
Done Building Project ""C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj"" (default targets) -- FAILED.



"
9576,"dilated convolution in 3D, error:  No algorithm without scratch worked","I'm using tf.nn.convolution to implement the dilated convolution in 3D. I got ""No algorithm without scratch worked"" error during training. Here is the related code

To define the model,
```
def inference(self, images, is_training, keep_prob):
        """""" Forward inference
        Return:

        """"""
        c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))
        score = self._conv(c1, scope = 'score', filters = 2,  filter_size = (1,1,1) )

        pred = tf.nn.softmax(score)

        # pdb.set_trace()
        return score, pred

    def _conv(self, in_tensor, filters, scope, filter_size = None):
        """""" """"""

        if self._wd is None:
            myreg = None
        else:
            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))

        if filter_size is None:
            filter_size = self._filter_size

        with tf.variable_scope(scope):
            return tf.layers.conv3d(
                in_tensor, filters = filters,
                kernel_size = filter_size, padding = 'valid',
                activation = None,
                kernel_initializer  = tf.truncated_normal_initializer(stddev = self._stddev),
                kernel_regularizer =myreg,
                name = 'conv')        

    def _dilation_conv(self, in_tensor, n_filters, scope, dilation_rate, filter_size = None):
        """""" dilated convolution filter with batch norm. """"""
        
        if self._wd is None:
            myreg = None
        else:
            myreg = tf.contrib.layers.l2_regularizer(float(self._wd))

        if filter_size is None:
            filter_size = self._filter_size

        batch_size, H, W, D, in_channel = in_tensor.get_shape().as_list()            

        with tf.variable_scope(scope):
            kernel = tf.get_variable('weights', shape = self._filter_size + (in_channel, n_filters),
                                     dtype = tf.float32,
                                     initializer = tf.truncated_normal_initializer(stddev=self._stddev))
            output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')

            # Somehow set training = True even for testing phase works
            # better.
            if self._bn:
                output = tf.layers.batch_normalization(
                    output, training = True, name = 'bn')

            return tf.nn.relu(output, 'relu')
            
    def get_loss(self, labels, scores, beta = 0.9999):
        """"""
        return total loss of the model, including data loss and
        regularization loss.
    
        It looks that softmax_cross_entropy_with_logits does not need the
        input logits 2 dimension. As long as the last dimension is for
        classes, it should work. So, we do not need reshape the input tensor. 

        TF has a weighted_cross_entropy_with_logits, but this function is
        for multi-class problem, i.e. a picture may have both a dog and a
        truck.
        """"""

        class_weight = tf.constant([beta, 1.0 - beta])
        # TF suppot numpy's broadcasting. score array has dim BXY2,
        # weights array has dim (2), which is broadcast to BXY2.
        weighted_logits = tf.multiply(scores, class_weight)

        # both logits and labels are BXY2 dimension. 
        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = weighted_logits, labels = labels)
        # fromm dim BXY to dim 0 (scalar)
        cross_entropy_mean = tf.reduce_mean(cross_entropy, name = 'cross_entropy')

        reg_loss_list = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
        if reg_loss_list:
            return cross_entropy_mean + tf.add_n(reg_loss_list)
        else:
            return cross_entropy_mean
```
And to train the model, I used tf.train.AdamOptimizer. I didn't paste the training related code, since I don't think they are relevant, but I can add them later if that helps. 

Here is the error logs I saw: 
``` 
In [40]: train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')
2017-05-01 15:08:10.813716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:85:00.0)
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1038     try:
-> 1039       return fn(*args)
   1040     except errors.OpError as e:

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1020                                  feed_dict, fetch_list, target_list,
-> 1021                                  status, run_metadata)
   1022 

/usr/lib/python3.4/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:

NotFoundError: No algorithm without scratch worked!
	 [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]
	 [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_89_Adam/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
<ipython-input-40-c48a6e49a4b4> in <module>()
----> 1 train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')

/home/weiliu/projects/seismic/code/weiliu/train.py in train(train_dataset, test_dataset, model, init_lr, summary_dir, in_ckpt, out_ckpt)
    141                          keep_prob_pl: 0.5}
    142 
--> 143             _, loss_value = sess.run([optimizer, loss], feed_dict = feed_dict)
    144 
    145             global_step_val = tf.train.global_step(sess, global_step)

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    776     try:
    777       result = self._run(None, fetches, feed_dict, options_ptr,
--> 778                          run_metadata_ptr)
    779       if run_metadata:
    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    980     if final_fetches or final_targets:
    981       results = self._do_run(handle, final_targets, final_fetches,
--> 982                              feed_dict_string, options, run_metadata)
    983     else:
    984       results = []

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1030     if handle is None:
   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1032                            target_list, options, run_metadata)
   1033     else:
   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1050         except KeyError:
   1051           pass
-> 1052       raise type(e)(node_def, op, message)
   1053 
   1054   def _extend_graph(self):

NotFoundError: No algorithm without scratch worked!
	 [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]
	 [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_89_Adam/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2', defined at:
  File ""/usr/local/bin/ipython"", line 11, in <module>
    sys.exit(start_ipython())
  File ""/usr/local/lib/python3.4/dist-packages/IPython/__init__.py"", line 119, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/usr/local/lib/python3.4/dist-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/usr/local/lib/python3.4/dist-packages/IPython/terminal/ipapp.py"", line 348, in start
    self.shell.mainloop()
  File ""/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py"", line 440, in mainloop
    self.interact()
  File ""/usr/local/lib/python3.4/dist-packages/IPython/terminal/interactiveshell.py"", line 431, in interact
    self.run_cell(code, store_history=True)
  File ""/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python3.4/dist-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-40-c48a6e49a4b4>"", line 1, in <module>
    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')
  File ""/home/weiliu/projects/seismic/code/weiliu/train.py"", line 116, in train
    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step = global_step)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py"", line 315, in minimize
    grad_loss=grad_loss)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py"", line 386, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py"", line 368, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gradients_impl.py"", line 560, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_grad.py"", line 77, in _Conv3DGrad
    padding=op.get_attr(""padding"")),
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 663, in conv3d_backprop_input_v2
    padding=padding, name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

...which was originally created as op 'c1/dilation_conv', defined at:
  File ""/usr/local/bin/ipython"", line 11, in <module>
    sys.exit(start_ipython())
[elided 8 identical lines from previous traceback]
  File ""<ipython-input-40-c48a6e49a4b4>"", line 1, in <module>
    train.train(train_dataset, test_dataset, model = model, out_ckpt='./ckpt_3d/dilation', summary_dir='./summary_3d/dilation')
  File ""/home/weiliu/projects/seismic/code/weiliu/train.py"", line 67, in train
    images_placeholder, is_training = istraining_pl, keep_prob = keep_prob_pl )
  File ""/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py"", line 71, in inference
    c1 = self._dilation_conv(images, self._n_filters, scope = 'c1', dilation_rate = (1,1,1))
  File ""/home/weiliu/projects/seismic/code/weiliu/dilation_net_3d.py"", line 116, in _dilation_conv
    output = tf.nn.convolution(in_tensor, kernel, padding = 'SAME', strides = (1,1,1), dilation_rate = dilation_rate, name = 'dilation_conv')
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 661, in convolution
    op=op)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 331, in with_space_to_batch
    return op(input, num_spatial_dims, padding)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 653, in op
    name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 140, in _non_atrous_convolution
    name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 529, in conv3d
    strides=strides, padding=padding, name=name)
  File ""/home/weiliu/.local/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 768, in apply_op
    op_def=op_def)

NotFoundError (see above for traceback): No algorithm without scratch worked!
	 [[Node: gradients/c1/dilation_conv_grad/Conv3DBackpropInputV2 = Conv3DBackpropInputV2[T=DT_FLOAT, padding=""SAME"", strides=[1, 1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients/c1/dilation_conv_grad/Shape, c1/weights/read, gradients/AddN_3)]]
	 [[Node: Adam/update/_26 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_89_Adam/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

```
I also check the `atrous_convolution_test.py` and it seems I used it right. 

I'm on Ubuntu 14.04 64 bit, tensorflow version 1.1.0-rc2. 

If anyone can point me direction how to debug, that would be great. "
9572,cuda_error_out_of_memory when trying to run tensorflow/tensorflow/examples/tutorials/layers/cnn_mnist.py,"When I run tensorflow/tensorflow/examples/tutorials/layers/cnn_mnist.py on GPU I get the cuda_error_out_of_memory. 

I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_driver.cc:1002] failed to allocate 3.00G (3221225472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_driver.cc:1002] failed to allocate 2.70G (2899102720 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:404] error retrieving driver version: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/version
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\kernels\conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)

To circumvent it, I thought of using `config.gpu_options.per_process_gpu_memory_fraction` or `config.gpu_options.allow_growth`, but I don't know where to set the session configuration as I don't see any sessions in the code. Also, is there any way I can set session configuration globally for one file?"
9571,model_dir deletion while running python script,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10
- **TensorFlow installed from (source or binary)**:  binary, installed via pip
- **TensorFlow version (use command below)**: 1.1.0
- **Bazel version (if compiling from source)**:na
- **CUDA/cuDNN version**: na
- **GPU model and memory**: na
- **Exact command to reproduce**:?

### Describe the problem
Feature request: As part of an hyperparameter optimization routine, I use tensorflow's high level api tf.contrib.learn.DNNRegressor() (should apply to the others as well). The problem is that it creates for each instance an own new model_dir, which I can't delete during running the python script (even after the model instance is overwritten and no longer in RAM). It is a problem because it consumes rather fast large amounts of disk storage. As far as I can see there is no way to delete the temp dir while running the program, only once it terminates the dir is released and removable. 

### Source code / logs
here is a pseudo code example:
https://stackoverflow.com/questions/43639516/model-dir-deletion-in-tensorflow"
9570,Tensorflow inconsistence results every run,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9569,I updated tensorflow gpu version and jupyter notebook and I can not import tensorflow after updates. here is the error I got: ,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9567,Bazel error: building tensorflow 1.1 from source (CPU only),"### Problem description

The Docker build script below fails to build TensorFlow 1.1 from source with the following error messages:

```
ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: no such attribute 'urls' in 'http_archive' rule.
ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package.
```

Complete build log:

```
$ docker start tensorflow-builder
$ docker attach tensorflow-builder
root@8eef137e3404:/tensorflow# git fetch -fapv
From https://github.com/tensorflow/tensorflow
 = [up to date]      0.6.0      -> origin/0.6.0
 = [up to date]      docs-republishing -> origin/docs-republishing
 = [up to date]      estimator_windows -> origin/estimator_windows
 = [up to date]      fix-makefile-build -> origin/fix-makefile-build
 = [up to date]      master     -> origin/master
 = [up to date]      r0.10      -> origin/r0.10
 = [up to date]      r0.11      -> origin/r0.11
 = [up to date]      r0.12      -> origin/r0.12
 = [up to date]      r0.7       -> origin/r0.7
 = [up to date]      r0.8       -> origin/r0.8
 = [up to date]      r0.9       -> origin/r0.9
 = [up to date]      r1.0       -> origin/r1.0
 = [up to date]      r1.1       -> origin/r1.1
 = [up to date]      rn_delete  -> origin/rn_delete
root@8eef137e3404:/tensorflow# git checkout -b r1.1 origin/r1.1
Switched to a new branch 'r1.1'
root@8eef137e3404:/tensorflow# git pull
Already up-to-date.
root@8eef137e3404:/tensorflow# ./configure
Please specify the location of python. [Default is /usr/local/bin/python]: 
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] 
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] 
No XLA support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]

Using python library path: /usr/lib/python3/dist-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] 
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] 
No CUDA support will be enabled for TensorFlow
Configuration finished
.
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
..........
ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: no such attribute 'urls' in 'http_archive' rule.
ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package.
```

### Dockerfile

```
FROM ubuntu:16.04

# https://github.com/kubernetes/test-infra/blob/master/images/pull-kubernetes-bazel/Dockerfile

RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    openjdk-8-jdk \
    pkg-config \
    zip \
    unzip \
    zlib1g-dev \
    bash-completion \
    git \
    wget \
    python && \
    apt-get clean

ENV BAZEL_VERSION 0.3.2
RUN wget ""https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel_${BAZEL_VERSION}-linux-x86_64.deb"" && \
    dpkg -i ""bazel_${BAZEL_VERSION}-linux-x86_64.deb"" && \
    rm ""bazel_${BAZEL_VERSION}-linux-x86_64.deb""

# Fetch TensorFlow source code and build dependencies

RUN apt-get install -y --no-install-recommends git python3-numpy swig python3-dev python3-wheel && \
    apt-get install -y --no-install-recommends python3-setuptools rsync && \
    apt-get clean && \
    ln -s /usr/bin/python3 /usr/local/bin/python && \
    git clone --quiet --recurse-submodules https://github.com/tensorflow/tensorflow.git /tensorflow
WORKDIR /tensorflow

# Steps to build:
#
# host$ docker build -t bazel .
# host$ docker run -it --name bazel-builder bazel
#
# bazel-builder$ ./configure (press enter repeatedly)
# bazel-builder$ bazel build -c opt --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package
# bazel-builder$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
# bazel-builder$ exit
#
# host$ docker cp bazel-build:/tmp/tensorflow_pkg/tensorflow-0.11.0-py3-none-any.whl /tmp
```"
9566,Documentation pages are unnecessarily large,"```
curl https://www.tensorflow.org/api_docs/python/tf/abs | wc -c  # 1841844 (1.8MB)
```
Each page in the documentation now contains a HUGE left navbar contributing over 99% of the size.

1. This would waste a lot of network traffic on loading identical navbar over and over again.
2. It creates a big trouble when I tried to build an offline version of the doc. The whole html documents used to be <100MB, now they are 2.5GB."
9564,No module named tensorflow (problem with python 2),"Hi,
 I'm trying to install tensorflow on this machine:

Ubuntu 16.04
cuda 8.0
cudnn 5.1
python 2.7 (no Anaconda)

I installed tensorflow on both python 3 and python 2. It works with python 3 but with python 2 always gives the import error: **No module named tensorflow**. 
What can I do to solve this?

Thanks"
9560,"tf.pow(x, y) will freeze for negative integer y","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10, and macOS 10.12.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.1.0 on both operation systems
- **Bazel version (if compiling from source)**: not compiled from source
- **CUDA/cuDNN version**: CPU only on Windows, while CUDA 8.0 on macOS
- **GPU model and memory**: Nvidia Titan X, 12GB
- **Exact command to reproduce**: a short piece of Python code
- **Python version**: 3.5.2 (Anaconda) on Windows, 3.6.0 (Anaconda) on macOS

### Describe the problem

tf.pow(x, y) will freeze for negative integer y (and of course, integer x).  It will not freeze for negative floating number y.

### Source code / logs

```python
import tensorflow as tf

with tf.Graph().as_default(), tf.Session().as_default():
    print(tf.pow(5, -2).eval())  # this will not stop
```
"
9559,no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.,"### Describe the problem
I use ubuntu, and install anaconda3 and tensorflow followed the instruction. After it, I am trying to learn how to retrain a model that follows the inception tutorial. It seems that I got the following errors

ERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.

Is there a way to solve this issue?

### Source code / logs

parallels@ubuntu:~/anaconda3/lib/python3.6/site-packages$ bazel build tensorflow/examples/image_retraining:retrain
ERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.
INFO: Elapsed time: 0.073s

"
9558,https://github.com/tensorflow/tensorflow/issues/9553,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9557,Wrong path for absolute variable scopes,"Using absolute paths for scopes is useful when structuring large models.

We can enter a name scope from its absolute path by appending a slash:

```python
with tf.name_scope('foo'):
  with tf.name_scope('bar/') as scope:
    print(tf.constant(0).name)  # bar/Const:0
    print(bar)  # bar
```

However, this does not work with variable scopes:

```python
with tf.variable_scope('foo'):
  with tf.variable_scope('bar/') as bar:
    print(tf.constant(0).name)  # bar/Const:0
    print(bar.name)  # foo/bar/ (Expected: bar)
```

The last line should print `bar` instead of `foo/bar/`."
9554,TFRecord Writer Bug Saving Float List,"OS: Linux Ubuntu 14.04
TF: Version 1.1 (CPU) python 2.7

When saving a list of floats to TFRecords format with 
`tf.train.Feature(float_list=tf.train.FloatList(value=value) 
`
,where value it list of floats converted from a numpy array using tolist(), I get the following error:

TypeError: [0.0, 41.95294952392578, 1.4004319906234741, 46.5711784362793, 33.32099914550781, 1.545793056488037, has type list, but expected one of: int, long, float

which surprises me because it is explicitly a list of floats. 

```
def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))


def _float32_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=value))

def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))
 

    with tf.Session() as sess:
        # initialize variables
        sess.run(init_op)
        # Input threading
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)

        print('Writing', filename)
        recordWriter = tf.python_io.TFRecordWriter(filename)

        try:
            while not coord.should_stop():

                img, latent = sess.run([img_op, latent_op])

                example = tf.train.Example(features=tf.train.Features(feature={
                    'image/width': _int64_feature(image_dims[0]),
                    'image/height': _int64_feature(image_dims[1]),
                    'image/channels': _int64_feature(image_dims[2]),
                    'image/encoded': _bytes_feature(img[0]),
                    'latent/size': _int64_feature(latent_dim),
                    'latent/data': _float32_feature(latent.tolist())}))
                recordWriter.write(example.SerializeToString())

        except tf.errors.OutOfRangeError:
            print('Done training -- epoch limit reached')

        finally:
            # When done, ask the threads to stop.
            coord.request_stop()

        recordWriter.close()
        coord.join(threads)
        sess.close()
```"
9553,configure does not work on macOS if sed is GNU sed,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.4
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: Current head: 3ce228e

### Describe the problem
If sed is GNU sed on macOS, configure fails with `sed: can't read : No such file or directory`.
"
9552,Adding a property `trainable` to `tf.Variable`,"Feature request: wouldn't be handy to have a property `trainable` in the class `tf.Variable`?

P.S. sorry in advance for the question but... am I supposed/entitled to sketch an implementation in my TF fork and then issue a pull request?"
9550,ctc_greedy_decoder inconsistent with ctc_beam_search_decoder,"The following extract from the the `ctc_beam_search_decoder` documentation seems to be misleading:
""The `ctc_greedy_decoder` is a special case of the `ctc_beam_search_decoder` with `top_paths=1` and `beam_width=1` (but that decoder is faster for this special case).""

Instead, the following results can be observed: 

| Decoding ""AA<ctc_blank>AA"" using | `merge_repeated=True` | `merge_repeated=False` |
| --- | --- | --- |
| `tf.nn.ctc_beam_search_decoder(top_paths=1, beam_width=1)` | ""A""   | ""AA"" |
| `tf.nn.ctc_greedy_decoder()` | ""AA"" | ""AAAA"" |

To reproduce:

```python
import numpy as np
import tensorflow as tf
from unittest import TestCase


class CtcDecodersTest(TestCase):
    def test(self):
        def decode_greedily(beam_search: bool, merge_repeated: bool):
            aa_ctc_blank_aa_logits = tf.constant(np.array([[[1.0, 0.0]], [[1.0, 0.0]], [[0.0, 1.0]],
                                                    [[1.0, 0.0]], [[1.0, 0.0]]], dtype=np.float32))
            sequence_length = tf.constant(np.array([5], dtype=np.int32))

            (decoded_list,), log_probabilities = \
                tf.nn.ctc_beam_search_decoder(inputs=aa_ctc_blank_aa_logits,
                                              sequence_length=sequence_length,
                                              merge_repeated=merge_repeated,
                                              beam_width=1) \
                    if beam_search else \
                    tf.nn.ctc_greedy_decoder(inputs=aa_ctc_blank_aa_logits,
                                             sequence_length=sequence_length,
                                             merge_repeated=merge_repeated)

            return list(tf.Session().run(tf.sparse_tensor_to_dense(decoded_list)[0]))

        self.assertEqual([0], decode_greedily(beam_search=True, merge_repeated=True))
        self.assertEqual([0, 0], decode_greedily(beam_search=True, merge_repeated=False))
        self.assertEqual([0, 0], decode_greedily(beam_search=False, merge_repeated=True))
        self.assertEqual([0, 0, 0, 0], decode_greedily(beam_search=False, merge_repeated=False))
```

This is confusing and probably not intended.

How to solve this:

- Adapt the documentation or
- Adapt the `ctc_beam_search_decoder` implementation to that of `ctc_greedy_decoder` or vice versa. Both directions would cover my use case (""AA""), this decision would depend on which of the other behaviors (""A"" or ""AAAA"") is needed and which of them could be dropped.

### System information
OSX 12.4, TensorFlow 1.1.0 CPU from binary"
9549,Tensorflow Failed to create Session,"Hi

I tried basic program in python shell. It fails to create session. Please assist.

Thanks 

```
Python 2.7.6 (default, Oct 26 2016, 20:30:19)
[GCC 4.8.4] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.7.5 locally
>>> hello = tf.constant('hi,tensorflow')
>>> sess = tf.Session()
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node                                                                                                              read from SysFS had negative value (-1), but there must be at least one NUMA no                                                                                                             de, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with prop                                                                                                             erties:
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:02:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one                                                                                                              is currently active; existing: 0x2e0fe90
E tensorflow/core/common_runtime/direct_session.cc:137] Internal: failed initial                                                                                                             izing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevic                                                                                                             ePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.                                                                                                             py"", line 1187, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.                                                                                                             py"", line 552, in __init__
    self._session = tf_session.TF_NewDeprecatedSession(opts, status)
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/error                                                                                                             s_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InternalError: Failed to create session.
```"
9548,distributed alexnet error : alexnet_v2/pool1/MaxPool : tensor_in must be 4-dimensional,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: linux Centos 7.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tensorflow (0.11.0)


### Describe the problem
When I try to run distributed alexnet training in TensorFlow, the alexnet model definition is referred to [here](https://github.com/tensorflow/models/blob/master/slim/nets/alexnet.py). The Error occurred at 'alexnet_v2/pool1/MaxPool' as follows
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: tensor_in must be 4-dimensional
         [[Node: alexnet_v2/pool1/MaxPool = MaxPool[T=DT_FLOAT, data_format=""NHWC"", ksize=[1, 3, 3, 1], padding=""VALID"", strides=[1, 2, 2, 1], _device=""/job:worker/replica:0/task:0/cpu:0""](alexnet_v2/conv1/Relu)]]
```

### Source code / logs
```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
from datetime import datetime
import math
import sys
import time

from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf

tf.app.flags.DEFINE_string(""ps_hosts"", """", ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """", ""Comma-separated list of hostname:port pairs"")

tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")
tf.app.flags.DEFINE_integer(""batch_size"", 100, ""Training batch size"")
tf.app.flags.DEFINE_integer('num_batches', 100, ""Number of batches to run."")

FLAGS = tf.app.flags.FLAGS

slim = tf.contrib.slim
trunc_normal = lambda stddev: tf.truncated_normal_initializer(0, 0, stddev)

def alexnet_v2_arg_scope(weight_decay=0.0005):
  with slim.arg_scope([slim.conv2d, slim.fully_connected],
                      activation_fn=tf.nn.relu,
                      biases_initializer=tf.constant_initializer(0.1),
                      weights_regularizer=slim.l2_regularizer(weight_decay)):
    with slim.arg_scope([slim.conv2d], padding='SAME'):
      with slim.arg_scope([slim.max_pool2d], padding='VALID') as arg_sc:
        return arg_sc


def alexnet_v2(inputs,
               num_classes=1000,
               is_training=True,
               dropout_keep_prob=0.5,
               spatial_squeeze=True,
               scope='alexnet_v2'):
  with tf.variable_scope(scope, 'alexnet_v2', [inputs]) as sc:
    end_points_collection = sc.name + '_end_points'
    # Collect outputs for conv2d, fully_connected and max_pool2d.
    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],
                        outputs_collections=[end_points_collection]):
      net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID',
                        scope='conv1')
      net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')
      net = slim.conv2d(net, 192, [5, 5], scope='conv2')
      net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')
      net = slim.conv2d(net, 384, [3, 3], scope='conv3')
      net = slim.conv2d(net, 384, [3, 3], scope='conv4')
      net = slim.conv2d(net, 256, [3, 3], scope='conv5')
      net = slim.max_pool2d(net, [3, 3], 2, scope='pool5')

      # Use conv2d instead of fully_connected layers.
      with slim.arg_scope([slim.conv2d],
                          weights_initializer=trunc_normal(0.005),
                          biases_initializer=tf.constant_initializer(0.1)):
        net = slim.conv2d(net, 4096, [5, 5], padding='VALID',
                          scope='fc6')
        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,
                           scope='dropout6')
        net = slim.conv2d(net, 4096, [1, 1], scope='fc7')
        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,
                           scope='dropout7')
        net = slim.conv2d(net, num_classes, [1, 1],
                          activation_fn=None,
                          normalizer_fn=None,
                          biases_initializer=tf.zeros_initializer,
                          scope='fc8')

      # Convert end_points_collection into a end_point dict.
      end_points = slim.utils.convert_collection_to_dict(end_points_collection)
      if spatial_squeeze:
        net = tf.squeeze(net, [1, 2], name='fc8/squeezed')
        end_points[sc.name + '/fc8'] = net
      return net, end_points

def main(_):

  #Construct the cluster and start the server
  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")

  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)  


  if FLAGS.job_name == ""ps"":
    server.join()

  elif FLAGS.job_name == ""worker"":
    with tf.device(tf.train.replica_device_setter(worker_device=""/job:worker/task:%d"" % FLAGS.task_index, cluster=cluster)):

      image_size = 224
      images = tf.Variable(tf.random_normal([FLAGS.batch_size, image_size, image_size, 3], dtype=tf.float32, stddev=1e-1))
      
      with slim.arg_scope(alexnet_v2_arg_scope()):
        logits, end_points = alexnet_v2(images, is_training = False)    
      saver = tf.train.Saver()
      summary_op = tf.merge_all_summaries()
      #summary_op = tf.summary.merge_all()
      init_op = tf.global_variables_initializer()

    # Create a Supervisor that will checkpoint the model and computes summaries。
    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0), logdir=""./alexnet_train_logs"", init_op=init_op, summary_op=summary_op, saver=saver, save_model_secs=600)

    # Get a TensorFlow session managed by the supervisor.
    with sv.managed_session(server.target) as sess:
      num_steps_burn_in = 10
      total_duration = 0.0
      total_duration_squared = 0.0
      for i in xrange(FLAGS.num_batches + num_steps_burn_in):
        start_time = time.time()
        _ = sess.run(logits)
        duration = time.time() - start_time
        if i >= num_steps_burn_in:
          if not i % 10:
            print ('%s: step %d, duration = %.3f' % (datetime.now(), i - num_steps_burn_in, duration))
        total_duration += duration
        total_duration_squared += duration * duration
      mn = total_duration / FLAGS.num_batches
      vr = total_duration_squared / FLAGS.num_batches - mn * mn
      sd = math.sqrt(vr)
      print ('%s: across %d steps, %.3f +/- %.3f sec / batch' % (datetime.now(), FLAGS.num_batches, mn, sd))
         
    # Stop TensorFlow Session
    sv.stop()

if __name__ == ""__main__"":
  tf.app.run()
```

"
9545,Duplicate variable shown in Tensorboard expected?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS Sierra 12.12.4
- **TensorFlow installed from (source or binary)**:
pip
- **TensorFlow version (use command below)**:
1.1.0 (CPU)
### Describe the problem
I am trying to implement E2C (available from https://arxiv.org/pdf/1506.07365.pdf). Basically it is a neural network that is used for learning a transition model using neural networks. In the training set I have data of the form (X_t, X_t+1) where both X_t and X_t+1 needs to be transformed by an encoding network (e.g. a variational autoencoder). I use the following snippet for creating the encoding network (adapted from https://github.com/ericjang/e2c):

```python
    def encode(self, x, share=None):
        fc = tf.contrib.layers.fully_connected
        with tf.variable_scope('Encoder', reuse=share):
            l1 = fc(x, 400, weights_initializer=tf.orthogonal_initializer(),
                    activation_fn=tf.nn.relu)
            l2 = fc(l1, 100, weights_initializer=tf.orthogonal_initializer(),
                    activation_fn=tf.nn.relu)
            return l2

    def decode(self, z, share=None):
        fc = tf.contrib.layers.fully_connected
        with tf.variable_scope(""Decoder"", reuse=share):
            l1 = fc(z, 100, weights_initializer=tf.orthogonal_initializer(1.1),
                    activation_fn=tf.nn.relu)
            l2 = fc(l1, 400, weights_initializer=tf.orthogonal_initializer(1.1),
                    activation_fn=tf.nn.relu)

            return fc(l2, self.x_dim,
                      weights_initializer=tf.orthogonal_initializer(1.1),
                      activation_fn=tf.nn.sigmoid)
```
Then I would use something like

```python
h_enc_t = encoder(X_t)
h_enc_t_next = encoder(X_{t+1}, share=True)
```
to create the encoded output for the model.

The problem is that when visualizing this on Tensorboard, while it is sharing the variables by setting `share=True` for the variable scope, on the graph visulisation you will have `Encoder` and `Encoder_1` instead of just a `Decoder` scope. Of course they took different input since we need to transform X_t and X_t+1, but shouldn't the network be wrapped in the same scope since underneath we are reusing the same weights? I wonder if it is a feature to have `Encoder_1` and `Encoder` separately or it is a limitation of the variable scoping. The problem is illustrated in the screenshot below, you will see duplicates for 'Encoder' 'SampleQPhi"" etc:

![graph-run](https://cloud.githubusercontent.com/assets/6040760/25559064/98fecc5a-2d2b-11e7-8669-00b1227abf17.png)

However, I would expect something like this (as appeared in the paper) to be a more reasonable visualization (h_enc) with input x_t and x_t+1 are the same network:

<img width=""546"" alt=""screenshot 2017-04-30 15 51 01"" src=""https://cloud.githubusercontent.com/assets/6040760/25565322/fc04ab8a-2dbc-11e7-9876-5e823a3bf47b.png"">


Many thanks in advance!"
9542,PreventGradient Signature Changed in TF 1.1.0 Breaking Forward Compatibility when Loading / Running Graph,"Loading and then attempting to run a graph that was saved by TF 1.1.0 on TF 1.0.1 leads to:
```
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef mentions attr 'message' not in Op<name=PreventGradient; signat
ure=input:T -> output:T; attr=T:type>; NodeDef: gradients/sparse_softmax_cross_entropy_loss/xentropy/xentropy_grad/PreventGradient =
 PreventGradient[T=DT_FLOAT, message=""Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_l
ogits due to the fused implementation\'s interaction with tf.gradients()""](sparse_softmax_cross_entropy_loss/xentropy/xentropy:1)
```
It seems as if the the NodeDef proto has changed in a manner that breaks older versions. The new field, `message` seems like it should be optional.

System info:
```
== cat /etc/issue ===============================================
Linux 6da178ae8f14 3.13.0-57-generic #95-Ubuntu SMP Fri Jun 19 09:28:15 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.2 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux 6da178ae8f14 3.13.0-57-generic #95-Ubuntu SMP Fri Jun 19 09:28:15 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.12.0)
protobuf (3.2.0)
tensorflow (1.0.1)

== check for virtualenv =========================================
False

== tensorflow import ============================================
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are a
vailable on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are
 available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are
 available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are av
ailable on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are a
vailable on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are av
ailable on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there
must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus
id: 0000:00:1e.0)
tf.VERSION = 1.0.1
tf.GIT_VERSION = v1.0.0-65-g4763edf-dirty
tf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirty
Sanity check: array([1], dtype=int32)
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sat Apr 29 12:36:12 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.57                 Driver Version: 367.57                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 0000:00:1E.0     Off |                    0 |
| N/A   53C    P0    57W / 149W |      0MiB / 11439MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
```"
9539,load a checkpoint and use it to create a new graph,"**system information:**
I am using the latest Tensorflow code on Ubuntu 16.04

**problem:**
because the tensorflow SSD can't directly output the final bounding box that i want, so i want to use the orginal checkpoint to create my graph. But i failed, i really wish someone could help me!!! Thanks!!

**error:**
i get the error:
```
Traceback (most recent call last):
  File ""haha.py"", line 43, in <module>
    select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)
  File ""/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py"", line 120, in ssd_bboxes_select
    select_threshold, img_shape, num_classes, decode)
  File ""/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py"", line 70, in ssd_bboxes_select_layer
    localizations_layer = ssd_bboxes_decode(localizations_layer, anchors_layer)
  File ""/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py"", line 35, in ssd_bboxes_decode
    (-1, l_shape[-2], l_shape[-1]))
  File ""/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py"", line 224, in reshape
    return _wrapit(a, 'reshape', newshape, order=order)
  File ""/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py"", line 48, in _wrapit
    result = getattr(asarray(obj), method)(*args, **kwds)
ValueError: total size of new array must be unchanged
```

**Source code**
```
import os
import math
import random

import numpy as np
import tensorflow as tf

slim = tf.contrib.slim
import matplotlib.image as mpimg

import sys
sys.path.append('../')

from nets import ssd_vgg_300, ssd_common, np_methods
from preprocessing import ssd_vgg_preprocessing

gpu_options = tf.GPUOptions(allow_growth=True)
config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)

with tf.Graph().as_default() as g:
    with g.name_scope('haha'):
		net_shape = (300, 300)
		data_format = 'NHWC'
		select_threshold=0.5
		nms_threshold=.45
		# Create graph
		image_input=tf.placeholder(tf.float32,shape=[None,None,3],name='input')

		height = image_input.shape[0]
		width = image_input.shape[1]

		image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(
			image_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)
		image_4d = tf.expand_dims(image_pre, 0)
		# Define the SSD model.
		reuse = True if 'ssd_net' in locals() else None
		ssd_net = ssd_vgg_300.SSDNet()
		with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):
			predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)
		ssd_anchors = ssd_net.anchors(net_shape)
		rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(
			predictions, localisations, ssd_anchors,
			select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)
			    
		rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)
		rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)
		rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)
			    # Resize bboxes to original image shape. Note: useless for Resize.WARP!
		rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)

		temp=tf.stack([height,width,height,width])
		rbboxes=rbboxes*temp
		facePredictions=rbboxes
		saver = tf.train.Saver()

image_test=np.ones((500,500,3))

with tf.Session(config=config) as sess:
	sess.run(tf.global_variables_initializer())
	saver.restore(sess, ""/home/wahaha/documents/haha/SSD-Tensorflow-master/log/model.ckpt-50000"")
	predictions_val=facePredictions.eval(feed_dict={image_input:image_test})
	output_graph_def = tf.graph_until.convert_variables_to_constants(sess, g.as_graph_def, output_node_names=['haha'])

	with tf.gfile.FastGFile(hahaFace.pb, mode = 'wb') as f:
		f.write(output_graph_def.SerializeToString())
```"
9536,[bug] Distributed FIFOQueue dequeue duplicate data,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 14.04 
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.0.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0 5.1
- **GPU model and memory**:
Pascal TitanX 
- **Exact command to reproduce**:
https://gist.github.com/lispc/27c9f4fe935abade5de90c18276e1742

### Describe the problem
In distributed tensorflow, if I do multiple dequeue from a remote FIFOQueue, duplicate results will be popped. For example, 1 2 3 4 5 were pushed into the FIFOQueue, then the popped results may be 1 1 2 3 4 4 5. Is it a bug? Or designed feature?
The code is posted above. Logs is also in that gist.
"
9532,event_accumulator is missing in v1.1,"### System information
* TensorFlow version: v1.1

### Describe the problem
Before v1.1, there is a class called EventAccumulater in `python/summary/event_accumulator.py` which is used to export the data from tensorboard. However, in v1.1 this file is missing and the `README.md` is still the old version, saying ""If you wish to load TensorFlow events, you should use an EventAccumulator (to load from a single events file) or an EventMultiplexer (to load from multiple events files)"".
Is there any alternative API to load the data from tensorboard record files?
"
9530,PyCharm won't correctly import tensorflow,"I get the following error when I try to run a python program:

`ImportError: libcudnn.so.5: cannot open shared object file: No such file or directory`

I understand this is a simple error most people would encounter when they start tensorflow. I did checked the solutions on Stackoverflow and I managed to run the same program in Terminal. What I did is I made an virtualenv and I activated it and when I try using python3 to run the program it successfully proceeds without any error. However the error always appear when I run the program in PyCharm even with python interpreter set to the location of virtualenv I created. Can someone tell me why as I had no idea why it works in terminal but not with PyCharm.
"
9528,TensorFlow processes and core engine documentations ,"Hi all,

I am interesting to understand more details about TF core engine. My focus interest on how a process create and launch when session is being created. Also, how the threads work and how python api translate these threads to C++ TF engine. Is there any documentation about that ? 

Sincerely
"
9527,tf.while_loop much slower than static graph?,"I'm running on TF 1.1, and I've used `tf.while_loop` + `TensorArray` to implement dynamic unrolling of a type of recurrence that I previously unrolled statically through python code. The difference in speed is very dramatic, with forward inference being about 200x slower when dynamically unrolled, and backprop about 2x slower. Is this expected? Are there any tricks for optimization that I'm missing? This is on CPU. Performance gap on GPU is even larger."
9526,[Tutorial Update] Logging and Monitoring Basics,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

TensorFlow 1.1
n/a as purely documentation related

### Describe the problem

The currently published tutorial for [Logging and Monitoring](https://www.tensorflow.org/get_started/monitors) is based on functionality that has been identified as _deprecated_ (see i.p. the discussion in #7669 .)

I truly appreciate all the hard work 💯  put into moving the functionality of TF itself forward.

It would be most appreciated, if this tutorial could be updated to reflect suggested best practices when using `sessionRunHook` et al. to ease adoptabilty of TF.


### Source code / logs

n/a
"
9525,Statically-linked libraries in TF binary can cause symbol collisions,"TensorFlow currently statically links all dependencies. This sometimes causes hard-to-diagnose crashes (e.g. segfaults) when another version of a dependency is loaded into the process. This can even happen within TensorFlow if separate TensorFlow .so's are loaded into the same Python process.

Possible solutions would be to reduce the visibility of these symbols, dynamically link common libraries, or run TF in a separate process.

Known problematic libraries:
* protobuf (#8403, #8394)
* OpenCL, OpenCV (#7378)

Other related issues:
* #7480"
9522,Changing optimizer during the training gives weird results.,"I am trying to change the var_list provided to the minimize() function after some iterations. I am trying to implement a two step finetuning, where for first ""n"" iterations, I am training the last layer of the network and after that finetuning the whole network. So for first ""n"" iterations i am providing variables of last layer in var_list and after ""n"" iterations i am providing all variables in the network. 
It seems like whole network is being reinitialised when I change the optimizer after ""n"" iterations. "
9521,Documentation for tf.nn.ctc_* `label` argument is unclear,"The documentation for the connectionist temporal classifiers is unclear for `label` argument.  Here is what exists currently:

```
labels: An int32 SparseTensor. labels.indices[i, :] == [b, t] means labels.values[i] stores the id for (batch b, time t). labels.values[i] must take on values in [0, num_labels). See core/ops/ctc_ops.cc for more details.
```

The only way I was able to figure it out is from Jerod's comment on this SO:

http://stackoverflow.com/questions/42488070/how-to-design-the-label-for-tensorflows-ctc-loss-layer"
9519,Runs regex filter doesn't work in tensorboard v1.1,"### System information
- Custom code, worked fine on 1.0
- OS: Linux Ubuntu 16.04
- installed binary via pip3
- TensorFlow version v1.1.0-rc0-61-g1ec6ed5, 1.1.0
- CUDA v8.0, cuDNN v5.1
- GTX 1070, 8GB RAM
- To reproduce: run tensorboard, try to filter runs in web interface, nothing happens

### Problem description
Running tensorboard with v1.1 gives me the following warnings in the console (repeated four times) once the web interface is opened:

`WARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404`

At first I ignored it, but it turns out that when examining the runs in the web interface, the regex filter for the runs doesn't work at all. This exact command in the exact same folder with the exact same logs worked without issue with v1.0.
"
9518,GPU version of self_adjoint_eig,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux RBSylaptop 4.9.0-1-amd64 #1 SMP Debian 4.9.6-3 (2017-01-28) x86_64 GNU/Linux

- **TensorFlow installed from (source or binary)**:
$ pip3 install tensorflow-gpu
- **TensorFlow version (use command below)**:
tf.VERSION = 1.1.0
tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5
tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5
- **GPU model and memory**:
Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.645
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.31GiB

### Describe the problem
It looks like there is no eigen vector kernel that would run on GPU. Even the CPU version seems to be serial as it uses only one core for a single matrix.

### Source code / logs
This code just create a random 10*10 matrix and try to compute its eigen values and vectors on the GPU.

    mat = np.random.random((10, 10))
    sess = tf.Session()
    with tf.device('/gpu:0'):
        eigen = tf.self_adjoint_eig(mat)
    sess.run(eigen)

Which fails with the error:

    InvalidArgumentError (see above for traceback): Cannot assign a device to node 'SelfAdjointEigV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_DOUBLE, compute_v=true, _device=""/device:GPU:0""](SelfAdjointEigV2/input)]]


And for a large enough matrix, it can be seen that the CPU kernel only uses one core."
9517,Placing Variables on the cpu using `tf.contrib.layers` functions,"Dear tensorflow team,

After constructing my model using the functionality provided by `tf.contrib.layers` I now want to extend my model over several GPUs. I learned that it might be beneficary to place Variables on the CPU when doing that, to reduce data transfer overhead. After not seeing an easy way to do this I found a workaround I described on [stackoverflow](http://stackoverflow.com/questions/43678599/device-placement-of-kernels-and-biases-when-using-tf-contrib-layers/43685023#43685023). My solution is to generate Variable-nodes in the graph where the Variable-getter of the `fully_connected` layer for example would expect the variables to be.

As this is not a very nice solution, I messed with the `fully_connected` layer and the `_build_variable_getter` function to basically allow me to specify, where I want to place the variabels. Thus after 

- adding the kwarg `variable_device` to `tf.contrib.layer.fully_connected`
- adding the kwarg `variable_device` to `tf.contrib.layer._build_variable_getter`
- adding the kwarg `device` to `tf.contrib.layer._model_variable_getter`
- and passing this as kwarg to `model_variable` defined in `tensorflow.contrib.framework.python.ops.variables`

I get the desired functionality when using the `fully_connected` layer.
Below you find the modified version of `layers.py` 

In my eyes this would be a very useful feature for all layers that contain trainable variables, which is why I would like to make a request for this feature.
If you think the supplied modification is good enough, I can also try to make a pull request, after updating the other layers.

Best, Johannes

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: As described above, I did
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: ('v1.0.0-65-g4763edf-dirty', '1.0.1')
- **CUDA/cuDNN version**: 8, 5.1
- **GPU model and memory**: Titan X Pascal, 12GB

### Source code / logs
See 
- [stackoverflow](http://stackoverflow.com/questions/43678599/device-placement-of-kernels-and-biases-when-using-tf-contrib-layers/43685023#43685023)
- [modified layers.py](https://drive.google.com/file/d/0BxImZIuERGB2MHBMRDZkejM4LVU/view?usp=sharing)"
9516,Tensor flow cannot be imported properly in windows,"I have installed CPU version of Tensor flow in my laptop using the command line using pip install.

OS: Windows 8.1 64 bit Python 3.5.1

But, when I tried importing it in the python 3.5.1 it throws the following error message.

> import _pywrap_tensorflow ImportError: No module named '_pywrap_tensorflow' Error importing tensorflow. Unless you are using bazel, you should not try to import tensorflow from its source directory; please exit the tensorflow source tree, and relaunch your python interpreter from there.

 I have tried getting answers in Stackoverflow, but no hope. I have even tried changing the directories but nothing works.
I am new to python. Please help me to solve this issue !!"
9515,How do you generate tensorflow docs so you can confirm documentation fixes you make?,"Example: Suppose I see a formatting error in a Tensorflow function's arguments on the web. I then make a change in the ""Args: ..."" section of the function's python comments.
How can I generate these html docs after making this fix?"
9513,4D and higher dimensional convolutional layers,Are there any plans to implement 4D or higher convolutional layers?
9512,Tensorboard cannot load more than two event file in logdir,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, Custom network structure and data pre-processing for my own task and dataset, modified based on current single GPU CIFAR-10 tutorial (which use the monitored session).

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro 1703

- **TensorFlow installed from (source or binary)**:
Binary, install locally by using `pip install .\xxx.whl` in my miniconda environment, for the environment, `pip freeze` give the following information
```
appdirs==1.4.3
bleach==1.5.0
cycler==0.10.0
html5lib==0.9999999
Markdown==2.2.0
matplotlib==2.0.0
numpy==1.12.1
olefile==0.44
packaging==16.8
Pillow==4.1.0
protobuf==3.2.0
pyparsing==2.2.0
python-dateutil==2.6.0
pytz==2017.2
six==1.10.0
tensorflow-gpu==1.1.0rc2
Werkzeug==0.12.1
```

- **TensorFlow version (use command below)**:
Nightly build [#149](http://ci.tensorflow.org/view/Nightly/job/nightly-win/149/) (GPU Version), 1.1.0-rc2

- **CUDA/cuDNN version**:
CUDA 8.0, cuDNN 5.1

- **GPU model and memory**:
Quadro M1200, 4GB, WDDM mode

### Describe the problem
When restart the training (due to some hyper parameter adjustment) the third time, Tensorboard cannot load the new event file. It can only load the first two event file and after that scalar will stop refreshing.

Powershell console gave the following output:
```
[tensor] PS D:\Workspace\ConsorFlow> tensorboard.exe --logdir '../input_data/lpr_train_exp_01'
WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.
Starting TensorBoard b'52' at http://DESKTOP-P7T44AT:6006
(Press CTRL+C to quit)
WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.
ERROR:tensorflow:Unable to get size of D:\Workspace\input_data\lpr_train_exp_01\events.out.tfevents.1493274079.DESKTOP-P7T44AT: D:\Workspace\input_data\lpr_train_exp_01\events.out.tfevents.1493274079.DESKTOP-P7T44AT
WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.
WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.
WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.
WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.
WARNING:tensorflow:Detected out of order event.step likely caused by a TensorFlow restart. Purging expired events from Tensorboard display between the previous step: -1 (timestamp: -1) and current step: 17454 (timestamp: 1493310366.6493406). Removing 174 scalars, 76 histograms, 76 compressed histograms, 451 images, and 0 audio.
```
The 'current step' 17454 in the output is the first step in my second restart.

Information about event files:
1st:   events.out.tfevents.1493274079
2nd:  events.out.tfevents.1493310339
3rd:   events.out.tfevents.1493352650

About this problem in Ubuntu:
I just switch to windows several days ago, such problem did not exist in Ubuntu (at least 14.04). I was using the exact same script, but with tensorflow version 1.01 (GPU, not nightly version), install following the offical instruction. 

Under windows, it was because of #7500, which leave me no choice but to install a nightly build. "
9511,Cannot import tensorflow in IPython3 (while in normal python3 IDLE works fine) after pip installation,"I have installed tensorflow-gpu via `pip` installation and I am experiencing this issue. I cannot import it in `IPython3` but it works fine with the regular `python3`.

```bash
petrux@orion:~$ ipython -c ""import tensorflow; print(tensorflow.__version__)""
1.1.0
petrux@orion:~$ python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
petrux@orion:~$ python3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
v1.1.0-rc0-61-g1ec6ed5 1.1.0
petrux@orion:~$ ipython -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
petrux@orion:~$ ipython3 -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-1-5730349aae22> in <module>()
----> 1 import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)

/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py in <module>()
     52 
     53 # Protocol buffers
---> 54 from tensorflow.core.framework.graph_pb2 import *
     55 from tensorflow.core.framework.node_def_pb2 import *
     56 from tensorflow.core.framework.summary_pb2 import *

/usr/local/lib/python3.5/dist-packages/tensorflow/core/framework/graph_pb2.py in <module>()
      4 import sys
      5 _b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))
----> 6 from google.protobuf import descriptor as _descriptor
      7 from google.protobuf import message as _message
      8 from google.protobuf import reflection as _reflection

ImportError: No module named 'google.protobuf'; 'google' is not a package
```

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: `pip`
- **TensorFlow version (use command below)**: `('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')`"
9509,Tensorflow with XLA hangs with both GPU and CPU at ~0% usage when training.,"I am using the newest tensorflow which I built from source as of yesterday in an attempt to fix this issue.  Originally I had a source build of tensorflow 1.1.0.  I am running Ubuntu 16.04 with CUDA 8 and CUDNN 5.  My GPU is a GTX 1080.

The problem I am having is when I try to train my character based translator model using the XLA compiler.  The code makes it all the way through the initialize variables, etc up to the first run command which contains my train step and then just freezes.  Both my GPU and CPU are idle.  I attached gdb to my process and it seems to be stuck waiting for some sort of notification.  My model builds and runs fine if I am running it without training in predict mode but still with XLA.  It also runs fine if I train it without XLA.  Just the combo of XLA and training is the issue.

I attached to this my code plus some sample training data.  This problem should be reproducible by running the train.py.

[CharacterTranslator.zip](https://github.com/tensorflow/tensorflow/files/963946/CharacterTranslator.zip)"
9508,Problem running Tensorflow graph using C++ API,"I have retrained Inception-v3 model using (Tensorflow) Python API, and saved a standalone Graph in .pb form. I have also used a dropout layer before the final layer. I can successfully run inference on the graph in python. The code to generate predictions in python is as follows:
`softmax_tensor = sess.graph.get_tensor_by_name('final_layer/final_result/Softmax:0')
predictions = sess.run(softmax_tensor, { 'DecodeJpeg/contents:0': image_data, 'final_layer/dropout/Placeholder:0': 1.})`
The C++ counterpart of the python code is as follows:
` string input_layer = ""Mul"";
  string output_layer = ""final_layer/dropout/Placeholder:0"";
  Status run_status = session->Run({{input_layer, resized_tensor}},
                                   {output_layer}, {}, &outputs);`

The C++ code ends up with the following error message:
`Running model failed: Invalid argument: You must feed a value for placeholder tensor 'final_layer/dropout/Placeholder'`

What should I change in the above C++ code to remove this error?"
9507,AttributeError: 'Tensor' object has no attribute '_displayhook',"I'm running TensorFlow on Zeppelin with Python 3.5.2, the TensorFlow version is 1.0.1.

It shows up AttributeError: 'Tensor' object has no attribute '_displayhook' error when I was running a Gaussian Distribution.

import tensorflow as tf
import matplotlib.pyplot as plt

n_values = 32
x = tf.linspace(-3.0, 3.0, n_values)

sigma = 1.0
mean = 0.0

a = tf.exp(tf.negative(tf.pow(x - mean, 2.0) / (2.0 * tf.pow(sigma, 2.0)))) 
b = (sigma * tf.sqrt(2.0 * 3.1415))

z = a / b"
9506,No supported kernel for GPU devices is available for assigning a variable of int32 type,"**tensorflow version**  v1.1.0-rc0-61-g1ec6ed5
**code to reproduce**
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import tensorflow as tf
print(tf.GIT_VERSION, tf.VERSION)

for device in ['cpu', 'gpu']:
    print(device)
    with tf.device('/{}:0'.format(device)):
        var = tf.get_variable('var{}'.format(device), shape=[1], dtype='int32')
        vari = tf.assign(var, [23])

    sess = tf.Session()
    sess.run(vari)
```
**error**
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'vargpu': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
```

This should be caused by [TF_CALL_GPU_NUMBER_TYPES](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/register_types.h#L171) only iterating over float types, and it is used to [generate the assign kernels](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/dense_update_ops.cc#L174). However [TF_CALL_NUMBER_TYPES](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/register_types.h#L154) iterates over all types including integers. Is this asymmetry a deliberate design choice?"
9505,Check failed: NDIMS == dims() (2 vs. 1) when I build a svm model,"when I build a svm model with tf.learn, it get error like this: 
`F tensorflow/core/framework/tensor_shape.cc:36] Check failed: NDIMS == dims() (2 vs. 1)Asking for tensor of 2 dimensions from a tensor of 1 dimensions
`
I have ask a question in stackoverflow, It could be a issue according the reply:
http://stackoverflow.com/questions/43638488/check-failed-ndims-dims-2-vs-1-when-i-build-a-svm-model

all the reproduce code here:
```
import tensorflow as tf
import pandas as pd
from tensorflow.contrib.learn.python.learn.estimators import svm


detailed_occupation_recode = tf.contrib.layers.sparse_column_with_hash_bucket(
    column_name='detailed_occupation_recode', 
    hash_bucket_size = 1000
)
education = tf.contrib.layers.sparse_column_with_hash_bucket(
    column_name='education',
    hash_bucket_size=1000
)
# Continuous base columns
age = tf.contrib.layers.real_valued_column('age')
wage_per_hour = tf.contrib.layers.real_valued_column('wage_per_hour')



columns = ['age', 'detailed_occupation_recode', 'education', 'wage_per_hour','label']
FEATURE_COLUMNS = [
    # age, age_buckets, class_of_worker, detailed_industry_recode,
    age, detailed_occupation_recode, education, wage_per_hour

]


LABEL_COLUMN = 'label'

CONTINUOUS_COLUMNS = ['age', 'wage_per_hour']

CATEGORICAL_COLUMNS = ['detailed_occupation_recode','education']


df_train = pd.DataFrame([[12,'12','7th and 8th grade',40,'- 50000'],
                [40,'45','7th and 8th grade',40, '50000+'],
                [50,'50','10th grade',40,'50000+'],
                [60,'30','7th and 8th grade',40,'- 50000']],
                columns=['age', 'detailed_occupation_recode', 'education', 'wage_per_hour', 'label'])


df_test = pd.DataFrame([[12,'12','7th and 8th grade',40,'- 50000'],
                [40,'45','7th and 8th grade',40, '50000+'],
                [50,'50','10th grade',40,'50000+'],
                [60,'30','7th and 8th grade',40,'- 50000']],
                columns=['age', 'detailed_occupation_recode', 'education', 'wage_per_hour', 'label'])
df_train[LABEL_COLUMN] = (df_train[LABEL_COLUMN].apply(lambda x: '+' in x)).astype(int)
df_test[LABEL_COLUMN] = (df_test[LABEL_COLUMN].apply(lambda x: '+' in x)).astype(int)
dtypess = df_train.dtypes


def input_fn(df):
    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}
    categorical_cols = {k: tf.SparseTensor(
        indices=[[i, 0] for i in range(df[k].size)],
        values=df[k].values,
        dense_shape=[df[k].size, 1]) for k in CATEGORICAL_COLUMNS}    
    feature_cols = dict(continuous_cols.items() + categorical_cols.items())
    feature_cols['example_id'] = tf.constant([str(i+1) for i in range(df['age'].size)])
    label = tf.constant(df[LABEL_COLUMN].values)
    return feature_cols, label

def train_input_fn():
    return input_fn(df_train)

def eval_input_fn():
    return input_fn(df_test)

model_dir = '../svm_model_dir'

model = svm.SVM(example_id_column='example_id', feature_columns=FEATURE_COLUMNS, model_dir=model_dir)
model.fit(input_fn=train_input_fn, steps=10)
results = model.evaluate(input_fn=eval_input_fn, steps=1)
for key in sorted(results):
    print(""%s: %s"" % (key, results[key]))
```
and the all error output text:

```
WARNING:tensorflow:The default value of combiner will change from ""sum"" to 

""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:tf.variable_op_scope(values, name, default_name) is deprecated, use tf.variable_scope(name, default_name, values)
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you
 resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you
 resize your input, as this behavior may change.
WARNING:tensorflow:From /Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:882: hinge_loss (from t
ensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.hinge_loss instead.
WARNING:tensorflow:From /Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (f
rom tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-dupl
icate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
WARNING:tensorflow:From /Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:882: hinge_loss (from t
ensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.
Instructions for updating:
Use tf.losses.hinge_loss instead.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machi
ne and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machi
ne and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine
and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine
 and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine
and could speed up CPU computations.
F tensorflow/core/framework/tensor_shape.cc:36] Check failed: NDIMS == dims() (2 vs. 1)Asking for tensor of 2 dimensions from a tensor of 1 dimensions
[1]    66225 abort      python simple-tf-svm.py
```"
9503,Ops for Reading from Cloud Spanner,"Is there any plan to make F1 public (be it a service in Google Cloud or just open source) and make it possible to store TensorFlow tensors in F1? I ask because as far as I can tell (might be wrong), there isn't a ""native"" database for TensorFlow (meaning a C++ reader with direct connection to the DB), and F1 supports Protobuf columns which would seem like a natural fit for Tensorflow data.

From [here](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41344.pdf)
> The F1 data model is very similar to the Spanner data
> model. In fact, Spanner’s original data model was more like
> Bigtable, but Spanner later adopted F1’s data model. At
> the logical level, F1 has a relational schema similar to that
> of a traditional RDBMS, with some extensions including
> explicit table hierarchy and columns with Protocol Buffer
> data types.
"
9502,"Internally inconsistent results on GPU, not on CPU","### System Information
```
Ubuntu 16.04 LTS
CUDA 8.0
cuDNN v5.1
NVIDIA Tesla K80 (11439MiB)
tensorflow 1.0.1 (bug also present in 1.1.0) [pip]
keras 2.0.3 [python setup.py install]
```

### Problem
I can define a convnet that returns reasonable results with CPU, but returns a mixture of expected and nonsense results with GPU. The problem with the GPU processing is made clear by passing a set of ""all ones"" images to the net; the output should be identical for all 16 images, yet the outputs for the last one or two images differ drastically from the rest.

I see this problem when using the GPU, but not with CPU.  No exceptions are raised, and there are no warnings beyond the usual `TensorFlow library wasn't compiled to use ___ instructions, but these are available on your machine and could speed up CPU computations.`.

I see this problem using `tensorflow` as my `keras` backend, but not when using `theano` as my backend.  That statement is true whether I set `image_data_format` to `channels_last` or `channels_first`, for either backend.

I've found three changes to the model architecture defined below that make the problem go away: (1) change the number of filters, as described in more detail below, (2) remove the `UpSampling2D` layer, or (3) remove the  `AveragePooling2D` layer.  Given (3), this issue may be related to https://github.com/tensorflow/tensorflow/issues/8566 .

### Code
Consider the following convnet.

```
import tensorflow as tf
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2D
from keras.models import Model
import numpy as np

def my_model(filters=65):
    np.random.seed(0)
    inputs = Input((None, None, 3))
    conv1 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(inputs)
    conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)
    conv2 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(conv1)
    conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv2)
    conv3 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv2)
    conv3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv3)
    conv4 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv3)
    conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv4)
    conv5 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv4)
    conv5_up = UpSampling2D(size=(8, 8))(conv5)
    conv5_up = AveragePooling2D(pool_size=(8, 8), strides=(1,1), padding='same')(conv5_up)
    return Model(inputs=inputs, outputs=conv5_up)
```

We can test the self-consistency of this net by feeding it 16 ""all ones"" images.  The output features should be identical for each input image, since the input images are simply all ones.

```
def test(filters=65, device='gpu'):
    # Make a batch of 16 ""images"", ALL ONES.
    img = np.ones((16, 512, 512, 3), dtype='float32')
    with tf.device('/%s:0'%device):
        model = my_model(filters)
        features = model.predict(img)
    # Compare features of 1st and 16th image.
    # Since the input was all ones, they should agree.
    inconsistent = np.any(features[0] != features[15])
    if inconsistent:
        print ""Inconsistent!""
```

The model architecture is parameterized by a single parameter, `filters`, the number of filters in each layer.  Interestingly, I see that the model inconsistency cares about powers of 2 in `filters`:

• consistency for `filters=1 through 64`,
• inconsistency for `filters=65 through 127`,
• consistency for `filters=128`, 
• inconsistency for `filters=129 through 150`.

The smallest model that shows the problem is at `filters=65`.  Below I show a single feature output for the 1st and 16th input images.  They should agree, but they don't.

Features for 1st image (which is identical for images 1-15):
![features_1st_image](https://cloud.githubusercontent.com/assets/4852957/25504294/33eb3ad6-2b52-11e7-9b1d-636bd576ed23.png)

Features for 16th image:
![features_16th_image](https://cloud.githubusercontent.com/assets/4852957/25504297/3969ab6e-2b52-11e7-87e7-67bed7a8c7b3.png)

As can be seen, the feature map for the 16th image differs dramatically from images 1-15, even though the inputs are identical (all ones).

If I repeat this test with a `filters=129` instead of `filters=65`, the bug appears earlier in the batch; the features for images 1-14 are identical, while the features for images 15 and 16 differ from the rest, and from each other.


"
9501,Securing Tensorflow models on Android,"### Describe the problem
I am using android to deploy my Tensorflow model. I am obfuscating names already but that wont stop people stealing and just plugging and playing graph file in their apps. Feature request for accepting encrypted graph files to prevent our graph files from leaking or any pointers on how to implement it.
"
9500,Tensorflow Video Decoding on a Separate Thread in a Distributed System ,"Having a distributed system, I need to enqueue frames on a CPU device, while processing the frames, that is, training the network, has to be on a GPU device. Could this be performed in parallel?

Currently, tensorflow enables Audio coding through FFMPEG(contrib), are there any features for video encoding and decoding which is multi-threaded? "
9499,No name 'debug' in module 'tensorflow',"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Pro
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu --upgrade
- **TensorFlow version (use command below)**: 1.0.1
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Cuda:8, CuDnn:5.1
- **GPU model and memory**: Pascal TitanX (x2)
- **Exact command to reproduce**: 
from tensorflow.python import debug as tf_debug

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Won't import.  This is the exact import from the docs; I have done nothing fancy; just normal install of everything.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

you can replicate this really easy.

python -c ""from tensorflow.python import debug as tf_debug;"""
9498,tf.metrics.accuracy maintains a running accuracy?,"I use the `tf.metrics.accuracy`, however it is a bit **counter-intuitive** in that it maintains a **running** accuracy (the [doc](https://www.tensorflow.org/api_docs/python/tf/metrics/accuracy) agrees with this).  The following simple script illustrates the situation

```python
import os
# supress tensorflow logging other than errors
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
import tensorflow as tf


print(tf.__version__)
# 1.1.0

x = tf.placeholder(tf.int32, [5])
y = tf.placeholder(tf.int32, [5])
acc, acc_op = tf.metrics.accuracy(labels=x, predictions=y)

sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())
sess.run(tf.local_variables_initializer())

v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],
                                       y: [1, 0, 0, 0, 1]})
print(v)
# [0.0, 0.8]

v = sess.run(acc)
print(v)
# 0.8

v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],
                                       y: [0, 1, 1, 1, 1]})
print(v)
# [0.8, 0.4]

v = sess.run(acc)
print(v)
# 0.4
```

My concerns are
1. the use of accuracy is bit **surprising**, are we supposed to manually construct the normal accuracy?
2. IMHO, it is better to 
    1. implement the normal accuracy behavior or
    2. provide a clean way to **reset** the local variables created by `tf.metrics.accuracy`, i.e., the `count` and `total`."
9496,"icc Compilation Errors in tf1.0: usage of ""typename"" on TTypes","- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.0
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: not configured
- **GPU model and memory**: not configured
- **Exact command to reproduce**: `CC=icc bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`

When compiling tensorflow using icc (version 17.0.3 20170404) using the command above, errors appear concerning the usage of `typename` associated with `TTypes`. For instance: 

> tensorflow/core/kernels/depthtospace_op.cc(88): error: type name is not allowed
      typename TTypes<T, 4>::ConstTensor Tinput = input.tensor<T, 4>();

A more constrained example, however, makes the problem more apparent. Command:
`CC=icc bazel build -c opt //tensorflow/core/kernels:resize_nearest_neighbor_op`
Output (partial):
> tensorflow/core/kernels/resize_nearest_neighbor_op.cc(57): error: type name is not allowed
      typename TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();

I can change line resize_nearest_neighbor_op.cc(57) to:
`TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();`
and repeat the command to get Output (partial):
> tensorflow/core/kernels/resize_nearest_neighbor_op.cc(57): error: use the ""typename"" keyword to treat nontype ""tensorflow::TTypes<T, NDIMS, IndexType>::ConstTensor [with T=T, NDIMS=4, IndexType=Eigen::DenseIndex={std::ptrdiff_t={long}}]"" as a type in a dependent context
      TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();

I do not know if Intel Compiler compatibility is an intended feature of tensorflow, but I hoped this issue would still be of interest to the developers.
Thank you!"
9495,Inconsistent results when tf.sqrt() is applied to tensor versus element-wise ,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: fedora 24
- **TensorFlow installed from (source or binary)**: pip
- **Exact command to reproduce**:
```
import tensorflow as tf

import numpy as np

start = 0 
linear_indices = (tf.range(start, 496) + 1) * 8 + 1 
index = 495 - start  

rind  = tf.sqrt(tf.cast(linear_indices, tf.float32)) - 63  
rind1 = tf.gather(rind, index)

linear_index = tf.gather(linear_indices, index)
rind2 = tf.sqrt(tf.cast(linear_index, tf.float32)) - 63  

session = tf.Session()
print(session.run(rind1))
print(session.run(rind2))
```
Output:
```
In [5]: %run calculation_test.py
3.8147e-06
0.0
```
### Describe the problem
The order of operations gives different behavior in tf.gather. `rind1` and `rind2` tensors should have the same value (0).

cc @altosaar"
9494,graph_transforms tool obfuscate_names won't work,"### System information

- **OS Platform and Distribution : Ubuntu 16.04**
**GIT_VERSION: v1.1.0-rc0-61-g1ec6ed5**
**Tensorflow Version: 1.1.0**

```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=MYMODEL.pb \
--out_graph=MYMODEL_OPT.pb \
--inputs='input_feed:0,Squeeze_1:0,lstm/state_feed:0' \
--outputs='lstm/initial_state:0,softmax:0,lstm/state:0' \
--transforms='
  obfuscate_names'
```





Bug: Model as follows (Inception V3) -> (LSTM)
I used the graph_transform tool to obfuscate names using the obfuscate_names command for android deployment. model seems to work fine on android but when I try to obfuscate names problems start to surface.


logs
```
Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Node 'rY' expects to be colocated with unknown node 'logits/biases'
                                                                                 at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392)
                                                                                 at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)
                                                                                 at com.example.thisismohit.local.MainActivity.onCreate(MainActivity.java:158) 
                                                                                 at android.app.Activity.performCreate(Activity.java:6283) 
                                                                                 at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119) 
                                                                                 at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2646) 
                                                                                 at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2758) 
                                                                                 at android.app.ActivityThread.access$900(ActivityThread.java:177) 
                                                                                 at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1448) 
                                                                                 at android.os.Handler.dispatchMessage(Handler.java:102) 
                                                                                 at android.os.Looper.loop(Looper.java:145) 
                                                                                 at android.app.ActivityThread.main(ActivityThread.java:5942) 
                                                                                 at java.lang.reflect.Method.invoke(Native Method) 
                                                                                 at java.lang.reflect.Method.invoke(Method.java:372) 
                                                                                 at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1400) 
                                                                                 at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1195) 

```"
9489,failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
```
Linux 4.4.0-75-generic #96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
```
- **TensorFlow version (use command below)**:
```
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
v1.0.0-65-g4763edf-dirty 1.0.1
```
- **CUDA/cuDNN version**:  8.0

- **GPU model and memory**:
```
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2785
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 145.50MiB
```

### Describe the problem
If I change the order of device usage, it would report error 

### Source code / logs
- If I use GPU first then CPU, it would be fine
```
with tf.device('/gpu:0'):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
    c = tf.matmul(a, b)
with tf.device('/cpu:0'):
    e = tf.constant([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], shape=[2, 9],dtype=tf.float32, name='e')
    f = tf.matmul(c,e)
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
print(sess.run(f))
```
- But if I use CPU first then GPU, it return error
```
with tf.device('/cpu:0'):
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
    c = tf.matmul(a, b)
with tf.device('/gpu:0'):
    e = tf.constant([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], shape=[2, 9],dtype=tf.float32, name='e')
    f = tf.matmul(c,e)
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
print(sess.run(f))
```
- the error dump below
```
    print(sess.run(f))
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(2, 2), b.shape=(2, 9), m=2, n=9, k=2
         [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](MatMul/_1, e)]]

Caused by op 'MatMul_1', defined at:
  File ""m1_n0teb00k/tensorflow_palyground.py"", line 13, in <module>
    f = tf.matmul(c,e)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 1765, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1454, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(2, 2), b.shape=(2, 9), m=2, n=9, k=2
         [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](MatMul/_1, e)]]
```"
9488,return type of `tf.reduce_any`,"I find that if the input tensor has type `bool`, the output of `tf.reduce_any` has type 'uint8'. My question is, why not `bool`? In the [document](https://www.tensorflow.org/api_docs/python/tf/reduce_any), it says it is equivalent to `np.any`, but the latter return `bool`.

Same applied to  `tf.reduce_all`."
9487,"terminate called after throwing an instance of 'std::bad_alloc', not out of memory","Hi, I'm using Keras with tensorflow back-end to train a LSTM network, I was doing a grid search over the learning_rate and dropout factor with the fixed batch size of 64, It ran perfectly but in the middle of it was interrupted by signal 6: SIGABRT with the following error: 

    terminate called after throwing an instance of 'std::bad_alloc'  what():  std::bad_alloc

It should not be a memory allocation problem because it was running earlier for batch size of 64 which is not too much in my case

you can find my system information(tf_env.txt) from the following link:  
https://www.dropbox.com/s/wcv8y88fh659zck/tf_env.txt?dl=0




"
9486,maybe a big bug of save/restore on python3,"tensorflow version:
v1.1.0-rc0-61-g1ec6ed5 1.1.0

python version:
3.6.1

No GPU.

I use 
`saver.save(sess, './model/')`
and
`saver.restore(sess, './model/')`
but 
`saver.restore` doesn't work.The predict result changes at every time.And at Python2.7 the predict result stay the same.
At first,I think it was the problem of windows.http://stackoverflow.com/questions/43630048/tensorflow-save-restore-a-model-in-windows"
9485,BernoulliWithSigmoidProbs is obsolete,"I think `tf.contrib.distributions.BernoulliWithSigmoidProbs` can be removed, because `Bernoulli` itself has a `logits` parameter that does the exact same thing, afaik. If you agree, I can make a pull-request if necessary."
9484,"ImportError (in import tensorflw-gpu as tf) : Tensorflow windows10, CUDA8.0/cuDNN5.1 and python 3.5.2","Hi, i am facing an issue if importError on a setup !
1. Windows10, Microsoft visual studio (2017)
2. CUDA 8.0/cuDNN5.1
3. Python 3.5.2
4. PATH for CUDA, cuDNN5.1 Libraries/bin/include set properly !!
5. Setup is created with Docker & tensorflow-gpu environment

While i am trying to verify my installation with ""import tensorflow-gpu as tf"", encountering with  ImportError: python library specific errors. pl do suggest some remedies !!

Here is complete log of error:  
$ python
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow-gpu as tf
  File ""<stdin>"", line 1
    import tensorflow-gpu as tf
                     ^
SyntaxError: invalid syntax
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9481,Error on Windows when installed in a virtualenv that has a non-ASCII character in the path,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: binary from PyPI
- **TensorFlow version (use command below)**: 1.1.0
- **Exact command to reproduce**:

      from tensorflow.contrib.rnn.python.ops.gru_ops import *

### Describe the problem
I encountered this when importing keras but it's reproducible with the command above. My virtualenv is in a folder that has an accented character in its name (see the log below). If I install TensorFlow globally, it works.

### Source code / logs
```
D:\Marci\Programozás\algorimp\test>venv\scripts\python -c ""from tensorflow.contrib.rnn.python.ops.gru_ops import *""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\__init__.py"", line 26, in <module>
    from tensorflow.contrib import crf
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\crf\__init__.py"", line 32, in <module>
    from tensorflow.contrib.crf.python.ops.crf import _lengths_to_masks
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\crf\python\ops\crf.py"", line 44, in <module>
    from tensorflow.contrib.rnn.python.ops import core_rnn_cell
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\rnn\__init__.py"", line 80, in <module>
    from tensorflow.contrib.rnn.python.ops.gru_ops import *
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\rnn\python\ops\gru_ops.py"", line 32, in <module>
    resource_loader.get_path_to_datafile(""_gru_ops.so""))
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\util\loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\python\framework\load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\rnn\python\ops\_gru_ops.dll not found
```
"
9480,Tensorboard 0.0.0.0:6006 cannot work On Win7 but localhost:6006 works,"I use tensorboard on Win7.
Everyting works fine and the cmd shows ""Starting TensorBoard b'47' at http://0.0.0.0:6006
""
But when I  input ""http://0.0.0.0:6006"" into chrome, nothing happens.
I google for it but find limited answer.
Then I input ""http://localhost:6006"" into chrome, the page comes out.
"
9479,No audio for detected object on retrained model,"By following [retraining tutorial](https://www.tensorflow.org/tutorials/image_retraining) and @petewarden's instructions from https://github.com/tensorflow/tensorflow/issues/2883, I am able to run the retrained model without errors. It detects any object from the model I created, but does not pronounce from speaker. It was working for demo model.
"
9476,iOS: No OpKernel was registered to support Op 'Less' with these attrs.  ,"hi , all! I have tried to load the model inside iOS that I generated from python.
and right now, I have the following problem:
```
Error adding graph to session:
No OpKernel was registered to support Op 'Less' with these attrs.  
Registered devices: [CPU],     Registered kernels: device='CPU';
 T in [DT_FLOAT]  [[Node: rnn/while/Less = Less[T=DT_INT32](rnn/while/Merge, rnn/while/Less/Enter)]]
```

Here is the python script generating the model:
```
def add_dynamic_rnn_layer(inputs, out_size, batch_size, Xt_size, time_step, num_layer=1, keep_prob=0.5):
    # Reshaping to (batch_size, time_step, Xt_size)
    inputs = tf.reshape(inputs, [-1, time_step, Xt_size])
    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(out_size, state_is_tuple=True,forget_bias=1.0),
                                                input_keep_prob=keep_prob)
                             for _ in range(num_layer)])
    cell =  tf.contrib.rnn.DropoutWrapper(cell,  input_keep_prob=keep_prob)
    sequence_length = np.zeros([batch_size], dtype=int)
    sequence_length += time_step
    init_state = cell.zero_state(batch_size, tf.float32)
    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=init_state, dtype=tf.float32, time_major=False,sequence_length=sequence_length)
    return tf.transpose(rnn_outputs, [1, 0, 2])[-1]


with tf.Session() as sess:
  # ...... other model code....
   add_dynamic_rnn_layer()
   output_graph_def = convert_variables_to_constants(sess, sess.graph_def,
                                                          output_node_names=['predictions', 'prediction_labels'])
   with tf.gfile.FastGFile('inference'+str(time.time())+'.pb', mode='wb') as f:
            f.write(output_graph_def.SerializeToString())
```
Here is the objective-C++ code loading the model and creating the session:
```
{
    NSString *path = [[NSBundle mainBundle] pathForResource:pbname ofType:@""pb""];
    if (!path) return false;
    auto status = ReadBinaryProto(tensorflow::Env::Default(), path.fileSystemRepresentation, &graph);
    if (!status.ok()) {
        NSLog(@""Error reading graph: %s"", status.error_message().c_str());
        return NO;
    }
    
    // This prints out the names of the nodes in the graph.
    auto nodeCount = graph.node_size();
    NSLog(@""Node count: %d"", nodeCount);
    for (auto i = 0; i < nodeCount; ++i) {
        auto node = graph.node(i);
        NSLog(@""Node %d: %s '%s'"", i, node.op().c_str(), node.name().c_str());
    }
    
    tensorflow::SessionOptions options;
    auto status = tensorflow::NewSession(options, &session);
    if (!status.ok()) {
        NSLog(@""Error creating session: %s"", status.error_message().c_str());
        return NO;
    }
    
    status = session->Create(graph);
    if (!status.ok()) {
        NSLog(@""Error adding graph to session: %s"", status.error_message().c_str());
    }  
}
```
the environment as follows:
 - python 3.5 / xcode 8.3.2
 - the iOS based on mac os x 10.12  / the tensorflow version: r1.1
 - the model generated based on Ubuntu / tensorflow is r1.1 gpu version

I have done things as follow:
- build_all_ios.sh    
  - success,don't have any warning and error.
- set the xcode build settings 
  - header search path
  ```
  /Users/jw/Desktop/tensorflow  non-recursive
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/downloads non-recursive
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src non-recursive
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/downloads/eigen non-recursive
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/proto non-recursive
  ```
  -  other linker flags:        
  ```
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf.a
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf-lite.a
  /Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a
  -force_load
  ```
 - check the tf_op_files.txt
   - have the line ` tensorflow/core/kernels/cwise_op_less.cc`
 - using the tensorflow version v1.0 
   - have the same error

I would be gratefull if anyone has an idea on why iOS seems to not be able to find the less Op ?
Or the solution to the question : No OpKernel was registered to support Op 'Less' with these attrs.  
"
9475,AttributeError: module 'tensorflow.contrib.cudnn_rnn' has no attribute 'CudnnLSTM',"I am experiencing this when I call tf.contrib.cudnn_rnn.CudnnLSTM:
`AttributeError: module 'tensorflow.contrib.cudnn_rnn' has no attribute 'CudnnLSTM'`

This happens with 1.1.0-rc2, 1.0.1 and probably 1.0.0. Previously, I was using version 0.12.head, and everything is fine. I suspect this is because the model was not exposed in [tensorflow/contrib/cudnn_rnn/\_\_init__.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/__init__.py) in an earlier version.

Even though this is fixed in this [commit]( https://github.com/tensorflow/tensorflow/commit/986d337e7da04de627218c12e20be1e3abbf6097), it's somehow not included in 1.1.0-rc2. In 1.1.0-rc2, when I look at the \_\_init__.py, it's still like this:

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops import CudnnGRU
from tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops import CudnnLSTM
from tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops import CudnnRNNRelu
from tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops import CudnnRNNTanh
from tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops import RNNParamsSaveable

from tensorflow.python.util.all_util import remove_undocumented
remove_undocumented(__name__)
```

Please fix this in the official release of 1.1 version.

For the reference, my 1.1.0-rc2 is installed from this:
https://pypi.python.org/packages/fd/1a/b6e78223c8e05a8bdee8f9bb20d4926f81db50e583632a1cde6e5b5ec2f0/tensorflow-1.1.0-cp35-cp35m-manylinux1_x86_64.whl#md5=fc5ed08795ef5afa60b48ae916def79c"
9474,Tensorboard text summary ops not on r1.1,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.12.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: `v1.1.0-rc0-61-g1ec6ed5 1.1.0`
- **Bazel version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: `tmp = tf.summary.text('Hello')`

### Describe the problem
Tensorboard in r1.1 has a text summary tab and it is mentioned in RELEASE.md but it looks like the command to add a text summary is not available. It's on the [master](https://github.com/tensorflow/tensorflow/blob/6a1825e2369d2537e15dc585705c53c4b763f3f6/tensorflow/python/summary/summary.py#L65) branch but not on [r1.1](https://github.com/tensorflow/tensorflow/blob/1ec6ed51182adf8f1b03a3188c16cd8a45ca6c85/tensorflow/python/summary/summary.py#L44-L65)

### Source code / logs
n/a
"
9473,ModuleNotFoundError: No module named 'tensorflow',"### Problem

I have problem running tensorflow, I am quite new in using tensorflow and Python, hence pardon me if this is stupid question to ask. The problem is when I tried running tensorflow in windows command prompt, it worked just fine but then it give me ModuleNotFoundError when I tried running it through .py file. Is there something wrong? Please help me, thank you
------------------------

### System information
- Tensorflow version 1.1 (installed using instruction given in [Here](https://www.tensorflow.org/install/install_windows) in conda environment named tensorflow-gpu
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pre-built binary
- **CUDA/cuDNN version**: 8.0/5.1


### Source code / logs
```

(tensorflow-gpu) C:\Users\USER\Anaconda3\envs>python
Python 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
2017-04-27 12:01:30.461948: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
2017-04-27 12:01:30.462096: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
2017-04-27 12:01:30.462199: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
2017-04-27 12:01:30.462298: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-04-27 12:01:30.462375: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-04-27 12:01:30.462448: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-04-27 12:01:31.657721: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:887] Found device 0 with properties:
name: GeForce GT 740M
major: 3 minor: 5 memoryClockRate (GHz) 1.0325
pciBusID 0000:07:00.0
Total memory: 2.00GiB
Free memory: 1.67GiB
2017-04-27 12:01:31.657920: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:908] DMA: 0
2017-04-27 12:01:31.659743: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:918] 0:   Y
2017-04-27 12:01:31.660988: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:07:00.0)
>>> print(sess.run(hello))
b'Hello, TensorFlow!'
>>> ^Z


(tensorflow-gpu) C:\Users\USER\Anaconda3\envs>hello_tf.py
Traceback (most recent call last):
  File ""C:\Users\USER\Anaconda3\envs\hello_tf.py"", line 1, in <module>
    import tensorflow as tf
ModuleNotFoundError: No module named 'tensorflow'
```

Here is my hello_tf.py:
```
import tensorflow as tf


hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
print(sess.run(hello))
```
"
9472,a,"Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9471,Time cost for each training step increases with the training procedure,"When I try to run a SRGAN network by 32 images with 96 * 96 size, each training step the time cost increases. At the beginning, each step cost 35 seconds, but when 160 steps later, the time cost increases to more than 200 seconds. By checking the time log, I can see it do increase with the training step. If I save the model and restart training process, the time cost reduces to about 35 seconds and start increasing again."
9470,Cmake build error on windows 10 (fatal error C1001),"

### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Windows 10
- **TensorFlow installed from**:source
- **TensorFlow version**:master
- **Bazel version**:NA
- **CUDA/cuDNN version**:8.0/5.1
- **GPU model and memory**:GTX 1080
- **Exact command to reproduce**:MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj


### Describe the problem
I was following cmake build instruction
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake
to build python package with GPU support using visual studio 2015 Update 3. It took a few hours until I hit fatal error C1001.

### logs
```
c:\work\libraries_local\tensorflow\tensorflow\core\kernels\reduction_ops_gpu.cu.cc(64): fatal error C1001: An internal error has occurred in the compiler. [C:\work\libraries_local\tensorflow\tensorflow\contrib\cmake\build\tf_core_gpu_kernels.vcxproj]
  
  (compiler file 'f:\dd\vctools\compiler\utc\src\p2\main.c', line 255)
  
   To work around this problem, try simplifying or changing the program near the locations listed above.
```"
9469,ImportError: No module named '_pywrap_tensorflow_internal',"Hi all,

Using windows 7 and have made tensorflow work in the cpu version. But keep getting this error in the gpu version. 

Installed it using pip install tensorflow-gpu. Have cuda 8.0 and cudnn 5.1. Have the dll file and cudnn files copied over. GPU model is K610M.

Thanks in advance for the assistance.

Capture of the screen:
(C:\Users\KiraYamato\Anaconda3) C:\Users\KiraYamato>activate tensorflow-gpu

(tensorflow-gpu) C:\Users\KiraYamato>python
Python 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v
.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__
.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 914, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified procedure could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__
.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__
.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 914, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified procedure could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tens
orflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib\__init__
.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_probl
ems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>> "
9467,Link Error for the deprecated/__init__.py,"It seems that the link ""look '[here](https://www.tensorflow.org/code/tensorflow/contrib/deprecated/__init__.py)'"" can not point to the right page in the [doc of histogram_summary](https://www.tensorflow.org/api_docs/python/tf/contrib/deprecated/histogram_summary), should we just change it to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/deprecated/__init__.py?

Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9466,Improved documentation for TensorArray,"The current documentation for `TensorArray` could use an expanded introduction explaining its utility and main motivation, examples of actual usage, and further explanation of some of its methods. The docs [here](https://www.tensorflow.org/api_docs/python/tf/TensorArray) do not have a single usage example. The overall description of the section is just:

""This class is meant to be used with dynamic iteration primitives such as `while_loop` and `map_fn`. It supports gradient back-propagation via special ""flow"" control flow dependencies.""

How is meant to be used with dynamic iteration primitives? What does that entail and why do we need a special construct for dynamic iteration? And what is ""flow""? It's very cryptic as it stands. Furthermore, some methods are very poorly described, like `close`. It's unclear if it needs to be invoked at the end, or what? [Comments on stack overflow](http://stackoverflow.com/questions/41113004/what-is-the-effect-of-calling-tensorarray-close) only add to the confusion. With the increasing importance of dynamic graphs, a basic construct like `TensorArray` should really be well documented, like `Variable`.
"
9465,Misleading error message when running restore op with path to an .index file,"Using V2 checkpoint files, calling `saver.restore()` with path to the `.index` returns the following error: 

    Error loading checkpoint from /home/peci1/tradr-git/tradr-ws/src/tradr-simulation/safe_exploration/scripts/ddpg/models/my-model.index: Not found: Tensor name ""ActorFullyConnected1/b"" not found in checkpoint files /home/peci1/tradr-git/tradr-ws/src/tradr-simulation/safe_exploration/scripts/ddpg/models/my-model.index

I think it'd be nicer to get an error saying ""File ... is not a checkpoint. Please, remove the .index extension"". This is roughly what you get if you pass any other file."
9463,Drupal8 chatbot integrate with TensorFlow,"Looking for developer who able to integrate tensorflow for answer to users in messenger if it was not recognized by prepared static answers. 
https://www.drupal.org/project/chatbot/releases/8.x-1.x-dev
High rate of operating for this job. "
9462,numpy prod overflow during creating tensor,"I am trying to allocate super large tensor using tensorflow, but failed.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/tensor_util.py#L417
Above code uses numpy.prod to calculate shape size, and for numpy everything is typed, say if the shape is [500000000, 5], then numpy.prod returns -1794967296, it's very easy to reproduce it.
So how about use int64 instead? int64 should be large enough for any tensor.
Changing shape_size = np.prod(shape) to shape_size = np.prod(shape, dtype=np.int64) should fix it. Also about 100 lines of code using np.prod, could we change them all to int64?"
9460,a dead link to the TensorBoard: Graph Visualization tutorial in the TensorBoard page,"Hi all,

there is a dead link to the TensorBoard: Graph Visualization tutorial from the TensorBoard Graphs page
[
<img width=""668"" alt=""screen shot 2017-04-26 at 16 17 40"" src=""https://cloud.githubusercontent.com/assets/1344378/25439486/d78f29e2-2a9c-11e7-87e1-f73e0dbf848c.png"">
](url)
now:

https://www.tensorflow.org/versions/master/how_tos/graph_viz/

should be:

https://www.tensorflow.org/get_started/graph_viz

OS - MacOS,
TensorFlow from pip or conda
Version: v1.0.0-rc2-15-g47bba63-dirty 1.0.0

Best,
Paddy"
9458,How np.array([]) works in numpy,"my sample code :

```
a = 2.0
b = 3.0
x = np.array([a, b])
print x
```

Output : ` [ 2.  3.]`

I just wanted to know , how this array is created here.  Basically how np.array works ?  Which constructor/function is invoking to generate this array ?

I tried putting prints in `/numpy/numpy/lib/user_array.py` but that didn't help. "
9456,TFClassify taking too long to disply result,"I am using tensorflow in android. I installed the apk for TFClassify available. I ran the application and it is running swiftly with inference time of not more than 400ms. However when I replaced the available trained model with my model, it is taking around 2000ms for computational before displaying the result. Why is there such a difference and how can I optimize my retrained_graph.pb? I have converted the retrained model to optimized & quantized graph.
"
9455,Batch + dynamic_pad + squeeze + one_hot + dynamic_rnn throws shape error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.1 LTS (Xenial Xerus)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.1.0-rc2-259-g34c738c
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Python version**: 3.5.2
- **Exact command to reproduce**: `python ./bug.py`

### Describe the problem

A certain combination of ops causes `tf.nn.dynamic_rnn` to throw a `ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.` during compilation of the graph. I will attach the script to reproduce the issue and the required tfrecords file.

The problem seems to be a combination of batching with `dynamic_pad` enabled, and `squeeze` + `one_hot`. I use `squeeze` + `one_hot` because `SequenceExample` gives me a `[examples x time_steps x 1]` tensor, and `one_hot` adds another dimension, so I first need to get rid of the last dimension to get a `[examples x time_steps x 3]` one-hot encoded tensor.

A few observations:

- When excluding `availability_one_hot` from the `lstm_inputs` concat, the script runs ok.
- When commenting out the `dynamic_rnn` op and evaluating `print(sess.run(tf.shape(lstm_inputs)))` instead, the output is `[2 8 4]`, which is the correct shape (1 normal feature + 3 from the one-hot encoding = 4 features)`.
- I tried to recreate the batch with a `tf.constant()` literal, but using that the graph worked fine, so the batching with dynamic padding is needed to reproduce the issue. 

### Source code / logs

Script + data file: [bug.zip](https://github.com/tensorflow/tensorflow/files/957645/bug.zip)

Output:
```
Traceback (most recent call last):
  File ""/home/ede/repos/xxx/xxx/misc/tftest/bug.py"", line 38, in <module>
    inputs=lstm_inputs
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py"", line 582, in dynamic_rnn
    dtype=dtype)
  File ""/home/ede/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py"", line 652, in _dynamic_rnn_loop
    ""Input size (depth of inputs) must be accessible via shape inference,""
ValueError: Input size (depth of inputs) must be accessible via shape inference, but saw value None.
```"
9454,python tensorflow ImportError,"The following is my code:

#matplotlib inline
import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from sklearn.metrics import confusion_matrix

tf.__version__
from tensorflow.examples.tutorials.mnist import input_data
data = input_data.read_data_sets(""data/MNIST/"", one_hot=True)

print(""Size of:"")
print(""- Training-set:\t\t{}"".format(len(data.train.labels)))
print(""- Test-set:\t\t{}"".format(len(data.test.labels)))
print(""- Validation-set:\t\t"".format(len(data.validation.labels)))

data.test.labels[0:5, :]
data.test.cls = np.array([label.argmax() for label in data.test.labels])
data.test.cls[0:5]

--------------------------------------------------------------------------------

The error in above code is:

Traceback (most recent call last):
  File ""C:/Users/KumarRaja/Desktop/skywalker.py"", line 5, in <module>
    from sklearn.metrics import confusion_matrix
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\__init__.py"", line 57, in <module>
    from .base import clone
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\base.py"", line 10, in <module>
    from scipy import sparse
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse\__init__.py"", line 221, in <module>
    from .csr import *
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse\csr.py"", line 15, in <module>
    from ._sparsetools import csr_tocsc, csr_tobsr, csr_count_blocks, \
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse\_sparsetools.py"", line 7, in <module>
    __bootstrap__()
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse\_sparsetools.py"", line 6, in __bootstrap__
    imp.load_dynamic(__name__,__file__)
  File ""C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

---------------------------------------------------------------------------------------------------------------
I hv installed the missing dll files in their respective location but the code isn't working after that also.Please help me with the above problem.

"
9453, Tensorflow in Raspberry Pi -- Create kernel failed: Not found: No registered '_Arg' OpKernel,"### System information
-I have followed steps to install Tensorflow on Raspberry Pi 3 from the page 
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile

After installation I tried to run the example from this page 
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examples


### Describe the problem
While executing the command label_image, I got a number of errors which I am unable to find anywhere on stack overflow or google. The error that I get I have pasted below.

### Source code / logs
pi@raspberrypi:~/tensorflow $ tensorflow/contrib/pi_examples/label_image/gen/bin/label_image 

2017-04-26 02:42:45.526198: I tensorflow/contrib/pi_examples/label_image/label_image.cc:145] Loaded JPEG: 512x600x3
2017-04-26 02:42:46.861870: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

2017-04-26 02:42:46.862015: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

	 [[Node: _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
2017-04-26 02:42:46.872857: E tensorflow/contrib/pi_examples/label_image/label_image.cc:376] Running model failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

	 [[Node: _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]"
9450,Compute gradient inside tf.while_loop using TensorArray,"I was trying to call opt.compute_gradients() inside the while_loop, but it failed with the error message:
```
AttributeError: 'WhileContext' object has no attribute 'pred'
```
I found a similiar problem in [stackoverflow](http://stackoverflow.com/questions/42313788/how-to-do-opt-compute-gradients-multiple-times-in-single-sess-run)

test code:
```python
batch_size = 2
inputs = tf.ones((batch_size, 10))
labels = tf.zeros((batch_size, 1))
outputs = tf.layers.dense(inputs, units=1)
loss = outputs - labels
loss_ta = tf.TensorArray(dtype=tf.float32, size=batch_size)
loss_ta = loss_ta.unstack(loss)

opt = tf.train.AdamOptimizer(0.1)
init_grad = []
vars_list = tf.trainable_variables()
for var in vars_list:
    init_grad.append(tf.zeros_like(var))

i = tf.constant(0, dtype=tf.int32)
def condition(i, *args):
    return tf.less(i, batch_size)
def loop_fn(i, gradients, all_loss):
    loss_ = all_loss.read(i)
    grads = opt.compute_gradients(loss_, vars_list)
    for idx, (grad, var) in enumerate(grads):
        gradients[idx] += grad
    return i + 1, gradients, all_loss
_, final_grad, _ = tf.while_loop(condition, loop_fn, [i, init_grad, loss_ta])

train_op = opt.apply_gradients(zip(final_grad, vars_list))
```
Seems like the problem is in the TensorArray, if I do not read loss from the TensorArray, it will be fine. Besides, I am using version1.0.1 on CPU"
9449,iOS Example error: Create kernel failed,"I'm trying to run the iOS example 'simple' provided. Script build_all_ios.sh runs fine, I'M able to deploy the application, but when I click on the 'Run Model' button, I get the following error: 
```
2017-04-26 00:16:30.272956: I /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:149] Session created.
2017-04-26 00:16:30.273190: I /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:152] Graph created.
2017-04-26 00:16:30.508996: I /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:157] Creating session.
2017-04-26 00:16:30.772992: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

2017-04-26 00:16:30.773030: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

	 [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
2017-04-26 00:16:30.773723: E /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:221] Running model failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

	 [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```
The error happens both on the simulator and on the device (iPhone 7). 

Please let me know if you need any additional information about this issue from my side.
Thanks and regards,
Roberto Falk"
9447,Unable to install v0.11 - missing distribution,"### System information
- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Not installed
- **TensorFlow version (use command below)**: 0.11
- **CUDA/cuDNN version**: 5.0
- **GPU model and memory**: Titan X 12 GB
- **Exact command to reproduce**:
root@system76-server:/# export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp35-cp35m-linux_x86_64.whl
root@system76-server:/# sudo -H pip3 install --upgrade TF_BINARY_URL


### Describe the problem
The distribution for v0.11 is missing. I am building from binary. Here is the error message:
""Collecting TF_BINARY_URL
  Could not find a version that satisfies the requirement TF_BINARY_URL (from versions: )
No matching distribution found for TF_BINARY_URL""

There is some URGENCY here. At our startup, we have just started a pilot with our very first client. Due to privacy concerns, the app is being shipped to client on a desktop, which is being set up right now. Our current stable app version uses TF 0.11 and we dont wish to move to 1.0 unless absolutely unavoidable. 

Would really appreciate it if you would help asap!

PS: This might help just me, but given this is a distribution issue, others may also benefit from this. Either ways, many apologies if this is the wrong request for GitHub!  "
9446,dynamic_rnn: session.run with train_step behaves differently than train_step run alone,"### System information
- 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
- via pip
- 1.0.0-65-g4763edf-dirty 1.0.1
- cuda-8.0 + cudnn-5.1.10
- GeForce GTX 760 + 1996MiB

### Describe the problem

Consider the following pieces of code:

#### Variant 1
    loop:
        feed_dict = {c_state: current_state.c, h_state: current_state.h, ...}
        loss_sum, current_state, _ = sess.run([reduce_sum(loss), final_state, train_step], feed_dict=feed_dict)

#### Variant 2
    loop:
        feed_dict = {...}
        loss_sum, current_state = sess.run([reduce_sum(loss), final_state], feed_dict=feed_dict)
        train_step.run(feed_dict)

#### Variant 3
    loop:
        feed_dict = {...}
        loss_sum, current_state = sess.run([reduce_sum(loss), final_state], feed_dict=feed_dict)
        sess.run([train_step], feed_dict=feed_dict)


**Variant 1** breaks after a couple of iterations (15 in my case) by raising a ""ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[200,10,25600]"" exception whereas **Variant 2** and **Variant 3** do not.

train_step is a minimize operation (optimizer doesn't matter) on a dynamic_rnn with a given initial_state and a single layer of LSTM cells.


I cannot imagine the reason why **Variant 1** needs more and more memory whereas the other both don't. Seems like something's wrong here.

SO question: http://stackoverflow.com/questions/43620353/resourceexhaustederror-when-using-session-run-instead-of-train-step-run-in-a-loo"
9445,Issue with running Tensorflow with OpenCL - Ubuntu 14.04.3 (Trusty) - AMD R5 Radeon M335 GPU,"Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):14.04.3-->Trusty

TensorFlow installed from (source or binary):Source

TensorFlow version (use command below):1.0 (Steps-> Downloaded tensorflow from https://github.com/benoitsteiner/tensorflow-opencl, ./configure - to configure project)

Bazel version (if compiling from source):0.4.5

CUDA/cuDNN version:NA

OPENCL Version:
Number of platforms:	1
Platform Profile:	FULL_PROFILE
Platform Version:	OpenCL 2.0 AMD-APP (1800.11)
Platform Name:	AMD Accelerated Parallel Processing
Platform Vendor:	Advanced Micro Devices, Inc.
Platform Extensions:	cl_khr_icd cl_amd_event_callback cl_amd_offline_devices

GPU model and memory:
Platform Name:	AMD Accelerated Parallel Processing
Number of devices:	2
Device Type:	CL_DEVICE_TYPE_GPU
Board name:	AMD Radeon (TM) R5 M335
Memory:	4096M

Exact command to reproduce:
run the python script -- ipython keras_code.py

** G++/GCC version**:
g++-4.9 (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4

I have compiled CPP programs, they work fine.

ComputeCPP: 0.1.4
-- ** Python**: I am using Anaconda distribution Python for 2.7.2. (Anaconda - 2.4.3)

Describe the problem

I have compile tensorflow, and deployed the same -> No issues here. when I try to run the code I run into the following error:

2017-04-23 14:01:15.180795: W ./tensorflow/core/common_runtime/sycl/sycl_util.h:44] No OpenCL GPU found that is supported by ComputeCpp, trying OpenCL CPU
2017-04-23 14:01:15.180843: F ./tensorflow/core/common_runtime/sycl/sycl_util.h:53] No OpenCL GPU nor CPU found that is supported by ComputeCpp
Aborted (core dumped)

I have attached the code file. Please note this is a simplified version of the file. The logic is:

Read data from files,
Pass it through a NN
I am using Keras as the Functional programming API on top of Tensorflow.

More details: Output of Computecpp_info:
********************************************************************************

ComputeCpp Info (CE 0.1.4)

********************************************************************************

Toolchain information:

GLIBCXX: 20150426
This version of libstdc++ is supported.

********************************************************************************


Device Info:

Discovered 2 devices matching:
  platform    : <any>
  device type : <any>

--------------------------------------------------------------------------------
Device 0:

  Device is supported                     : UNTESTED - Device not tested on this OS
  CL_DEVICE_NAME                          : Hainan
  CL_DEVICE_VENDOR                        : Advanced Micro Devices, Inc.
  CL_DRIVER_VERSION                       : 1800.11 (VM)
  CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_GPU 
--------------------------------------------------------------------------------
Device 1:

  Device is supported                     : UNTESTED - Device running untested driver
  CL_DEVICE_NAME                          : Intel(R) Core(TM) i7-6500U CPU @ 2.50GHz
  CL_DEVICE_VENDOR                        : GenuineIntel
  CL_DRIVER_VERSION                       : 1800.11 (sse2,avx)
  CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_CPU 

If you encounter problems when using any of these OpenCL devices, please consult
this website for known issues:
https://computecpp.codeplay.com/releases/v0.1.4/platform-support-notes

********************************************************************************
Please let me know if there are any fixes or if I can do something to get round this issue.
Thanks and regards
Sayantan
[tensorflow-code-throwing-error.txt](https://github.com/tensorflow/tensorflow/files/956152/tensorflow-code-throwing-error.txt)

"
9443,"Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()","iPhone6 und tensorflow/tensorflow/contrib/ios_examples/simple/
I have this Error! Hife!


<pre>
2017-04-25 18:19:07.181759: I /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:149] Session created.
2017-04-25 18:19:07.181966: I /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:152] Graph created.
2017-04-25 18:19:07.642122: I /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:157] Creating session.
2017-04-25 18:19:08.422609: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

2017-04-25 18:19:08.422813: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

	 [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
2017-04-25 18:19:08.425927: E /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:221] Running model failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
	.  Registered:  <no registered kernels>

	 [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
2017-04-25 18:19:08.426901: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BatchToSpace"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""crops""')
2017-04-25 18:19:08.426969: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BatchToSpace"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""crops""')
2017-04-25 18:19:08.427017: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SpaceToBatch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.427041: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SpaceToBatch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.427073: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Requantize"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QINT32 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.427122: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RequantizationRange"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.427146: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedReshape"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.427166: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedReshape"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.427186: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedMaxPool"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.427206: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedAvgPool"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.427371: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedMul"" device_type: ""CPU"" constraint { name: ""T1"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""T2"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""Toutput"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.427407: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedMatMul"" device_type: ""CPU"" constraint { name: ""T1"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""T2"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""Toutput"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.427452: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedInstanceNorm"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.427646: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedBiasAdd"" device_type: ""CPU"" constraint { name: ""T1"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""T2"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.427697: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedBiasAdd"" device_type: ""CPU"" constraint { name: ""T1"" allowed_values { list { type: DT_QINT8 } } } constraint { name: ""T2"" allowed_values { list { type: DT_QINT8 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.427737: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedRelu6"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QINT32 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.427760: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedRelu6"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.428026: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedRelu"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QINT32 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.428054: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedRelu"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.428077: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizeV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.428098: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizeV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT8 } } }')
2017-04-25 18:19:08.428270: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizeV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT16 } } }')
2017-04-25 18:19:08.428319: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizeV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT16 } } }')
2017-04-25 18:19:08.428341: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizeV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.428366: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizeDownAndShrinkRange"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QINT32 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.428461: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AddN"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.428482: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AddN"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.428502: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ArgMin"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dimension""')
2017-04-25 18:19:08.428543: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ArgMin"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""dimension""')
2017-04-25 18:19:08.428564: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ArgMax"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dimension""')
2017-04-25 18:19:08.428653: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ArgMax"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""dimension""')
2017-04-25 18:19:08.428676: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AvgPoolGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""orig_input_shape""')
2017-04-25 18:19:08.428695: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AvgPool"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.428732: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AvgPool"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } }')
2017-04-25 18:19:08.428755: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BatchNormWithGlobalNormalizationGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.428892: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BroadcastGradientArgs"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""s0"" host_memory_arg: ""s1"" host_memory_arg: ""r0"" host_memory_arg: ""r1""')
2017-04-25 18:19:08.429034: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BroadcastGradientArgs"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""s0"" host_memory_arg: ""s1"" host_memory_arg: ""r0"" host_memory_arg: ""r1""')
2017-04-25 18:19:08.429056: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_HostCast"" device_type: ""GPU"" host_memory_arg: ""x"" host_memory_arg: ""y""')
2017-04-25 18:19:08.429090: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_HostCast"" device_type: ""CPU""')
2017-04-25 18:19:08.429238: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatOffset"" device_type: ""GPU"" host_memory_arg: ""concat_dim"" host_memory_arg: ""shape"" host_memory_arg: ""offset""')
2017-04-25 18:19:08.429406: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatOffset"" device_type: ""CPU""')
2017-04-25 18:19:08.429433: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429456: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429564: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429815: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT8 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429871: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT16 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT16 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429920: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.429997: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ConcatV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.430316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Placeholder"" device_type: ""GPU""')
2017-04-25 18:19:08.430334: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PlaceholderV2"" device_type: ""CPU""')
2017-04-25 18:19:08.430365: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Placeholder"" device_type: ""CPU""')
2017-04-25 18:19:08.430412: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OnesLike"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.430511: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OnesLike"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.430535: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ZerosLike"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.430554: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ZerosLike"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.430595: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Fill"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dims""')
2017-04-25 18:19:08.430616: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Fill"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""dims""')
2017-04-25 18:19:08.430636: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Fill"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""dims""')
2017-04-25 18:19:08.430714: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Const"" device_type: ""CPU""')
2017-04-25 18:19:08.430737: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BatchNormWithGlobalNormalization"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.430753: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Abort"" device_type: ""CPU""')
2017-04-25 18:19:08.430769: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ControlTrigger"" device_type: ""CPU""')
2017-04-25 18:19:08.430784: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LoopCond"" device_type: ""CPU""')
2017-04-25 18:19:08.430821: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefNextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.430940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefNextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } }')
2017-04-25 18:19:08.430963: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefNextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431032: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefNextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431109: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefNextIteration"" device_type: ""CPU""')
2017-04-25 18:19:08.431125: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NextIteration"" device_type: ""CPU""')
2017-04-25 18:19:08.431145: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefExit"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431254: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefExit"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431387: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefEnter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.431408: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefEnter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } }')
2017-04-25 18:19:08.431428: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefEnter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431572: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefEnter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431596: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Enter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.431616: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Enter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } }')
2017-04-25 18:19:08.431635: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Enter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431705: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Enter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431957: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Enter"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_RESOURCE } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.431988: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefMerge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432009: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefMerge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432030: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefMerge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""inputs"" host_memory_arg: ""output"" host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432252: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefMerge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""inputs"" host_memory_arg: ""output"" host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432286: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefMerge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_RESOURCE } } } host_memory_arg: ""inputs"" host_memory_arg: ""output"" host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432304: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ControlTrigger"" device_type: ""GPU""')
2017-04-25 18:19:08.432322: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Merge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432342: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Merge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432558: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Merge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""inputs"" host_memory_arg: ""output"" host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432584: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Merge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""inputs"" host_memory_arg: ""output"" host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432607: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Merge"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_RESOURCE } } } host_memory_arg: ""inputs"" host_memory_arg: ""output"" host_memory_arg: ""value_index""')
2017-04-25 18:19:08.432624: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefMerge"" device_type: ""CPU""')
2017-04-25 18:19:08.432883: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Merge"" device_type: ""CPU""')
2017-04-25 18:19:08.432955: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSelect"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""index""')
2017-04-25 18:19:08.433006: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSelect"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""index""')
2017-04-25 18:19:08.433030: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSwitch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""pred""')
2017-04-25 18:19:08.433053: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSwitch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""pred"" host_memory_arg: ""output_false"" host_memory_arg: ""output_true""')
2017-04-25 18:19:08.433164: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSwitch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""data"" host_memory_arg: ""pred"" host_memory_arg: ""output_false"" host_memory_arg: ""output_true""')
2017-04-25 18:19:08.433683: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSwitch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""pred"" host_memory_arg: ""output_false"" host_memory_arg: ""output_true""')
2017-04-25 18:19:08.433715: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Switch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""pred""')
2017-04-25 18:19:08.433829: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Switch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""pred"" host_memory_arg: ""output_false"" host_memory_arg: ""output_true""')
2017-04-25 18:19:08.434041: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Switch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""data"" host_memory_arg: ""pred"" host_memory_arg: ""output_false"" host_memory_arg: ""output_true""')
2017-04-25 18:19:08.434068: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Switch"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""pred"" host_memory_arg: ""output_false"" host_memory_arg: ""output_true""')
2017-04-25 18:19:08.434091: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSwitch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""pred""')
2017-04-25 18:19:08.434111: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefSwitch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""pred""')
2017-04-25 18:19:08.434243: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Switch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""pred""')
2017-04-25 18:19:08.434264: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Switch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""pred""')
2017-04-25 18:19:08.434285: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2DBackpropInput"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } label: ""eigen_tensor""')
2017-04-25 18:19:08.434305: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2DBackpropInput"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } label: ""custom""')
2017-04-25 18:19:08.434443: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2DBackpropInput"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.434466: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2DBackpropFilter"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } label: ""eigen_tensor""')
2017-04-25 18:19:08.434487: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedConcat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.434526: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedConcat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.434567: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2DBackpropFilter"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } label: ""custom""')
2017-04-25 18:19:08.434641: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2DBackpropFilter"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.434662: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FusedPadConv2D"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.434682: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FusedResizeAndPadConv2D"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.434703: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CropAndResizeGradImage"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""image_size""')
2017-04-25 18:19:08.434757: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PlaceholderV2"" device_type: ""GPU""')
2017-04-25 18:19:08.434835: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CropAndResizeGradBoxes"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.434856: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CropAndResizeGradBoxes"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.434876: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CropAndResize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""crop_size""')
2017-04-25 18:19:08.434896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CropAndResize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""crop_size""')
2017-04-25 18:19:08.434942: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CTCGreedyDecoder"" device_type: ""CPU""')
2017-04-25 18:19:08.435029: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BiasAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.435049: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BiasAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435068: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Add"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435087: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RealDiv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435158: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Div"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435178: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Div"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }')
2017-04-25 18:19:08.435247: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApproximateEqual"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435268: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApproximateEqual"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } }')
2017-04-25 18:19:08.435287: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Equal"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435306: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Greater"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435341: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GreaterEqual"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435490: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""IsFinite"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435511: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Less"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435643: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SpaceToBatchND"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tblock_shape"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""block_shape"" host_memory_arg: ""paddings""')
2017-04-25 18:19:08.435674: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SpaceToBatchND"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tblock_shape"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""block_shape"" host_memory_arg: ""paddings""')
2017-04-25 18:19:08.435743: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Log"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435784: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LogicalNot"" device_type: ""CPU""')
2017-04-25 18:19:08.435917: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Minimum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Mul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.435958: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Mul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.436025: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReciprocalGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436045: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""InvGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436083: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RsqrtGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436104: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BroadcastArgs"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""s0"" host_memory_arg: ""s1"" host_memory_arg: ""r0""')
2017-04-25 18:19:08.436124: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Rsqrt"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436273: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Select"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.436327: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Select"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436346: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436365: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SigmoidGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436418: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sigmoid"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436482: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sqrt"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436540: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SquaredDifference"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""x"" host_memory_arg: ""y"" host_memory_arg: ""z""')
2017-04-25 18:19:08.436564: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SquaredDifference"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436582: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436601: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.436663: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TanhGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436684: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AssignSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.436702: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AssignSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436836: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AssignAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.436859: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""AssignAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.436879: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SpaceToDepth"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.437030: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SpaceToDepth"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.437089: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DepthToSpace"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.437110: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DepthToSpace"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.437128: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Reciprocal"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.437147: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DynamicPartition"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.437211: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DynamicPartition"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.437232: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DynamicStitch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""indices""')
2017-04-25 18:19:08.437252: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DynamicStitch"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""indices""')
2017-04-25 18:19:08.437271: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQuantWithMinMaxVarsPerChannelGradient"" device_type: ""CPU""')
2017-04-25 18:19:08.437289: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQuantWithMinMaxVarsPerChannel"" device_type: ""CPU""')
2017-04-25 18:19:08.437305: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQuantWithMinMaxVarsGradient"" device_type: ""CPU""')
2017-04-25 18:19:08.437432: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQuantWithMinMaxVars"" device_type: ""CPU""')
2017-04-25 18:19:08.437452: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQuantWithMinMaxArgsGradient"" device_type: ""CPU""')
2017-04-25 18:19:08.437471: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FusedBatchNormGrad"" device_type: ""CPU""')
2017-04-25 18:19:08.437488: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FusedBatchNorm"" device_type: ""CPU""')
2017-04-25 18:19:08.437509: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Gather"" device_type: ""CPU"" constraint { name: ""Tparams"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.437550: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Gather"" device_type: ""CPU"" constraint { name: ""Tparams"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.437687: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Gather"" device_type: ""CPU"" constraint { name: ""Tparams"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.437809: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Gather"" device_type: ""CPU"" constraint { name: ""Tparams"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.437834: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DepthwiseConv2dNative"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.437854: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StopGradient"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438011: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StopGradient"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.438050: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Dequantize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.438072: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Dequantize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT8 } } }')
2017-04-25 18:19:08.438091: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Dequantize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT16 } } }')
2017-04-25 18:19:08.438109: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Dequantize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT16 } } }')
2017-04-25 18:19:08.438176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Dequantize"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.438198: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PreventGradient"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438217: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PreventGradient"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.438237: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Identity"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438256: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Identity"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.438379: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefIdentity"" device_type: ""CPU""')
2017-04-25 18:19:08.438397: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PreventGradient"" device_type: ""CPU""')
2017-04-25 18:19:08.438413: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StopGradient"" device_type: ""CPU""')
2017-04-25 18:19:08.438428: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Identity"" device_type: ""CPU""')
2017-04-25 18:19:08.438465: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""InTopK"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.438483: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""InTopK"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.438502: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ParallelConcat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.438573: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ParallelConcat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438595: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_ParallelConcatStart"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.438614: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_ParallelConcatStart"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438633: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefIdentity"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438683: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefIdentity"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.438841: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ParseSingleSequenceExample"" device_type: ""CPU""')
2017-04-25 18:19:08.438870: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_ParallelConcatUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.438946: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_ParallelConcatUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.438964: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Print"" device_type: ""CPU""')
2017-04-25 18:19:08.439073: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Assert"" device_type: ""CPU""')
2017-04-25 18:19:08.439105: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LRN"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.439127: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MatMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } label: ""eigen""')
2017-04-25 18:19:08.439310: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MatMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } label: ""eigen""')
2017-04-25 18:19:08.439333: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Assign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.439386: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Assign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.439416: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MatMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.439434: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MatMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.439506: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MaxPoolGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.439527: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MaxPoolGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.439622: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MaxPool"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.439661: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MaxPool"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.439690: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MirrorPad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.439883: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MirrorPad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.439906: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NonMaxSuppression"" device_type: ""CPU""')
2017-04-25 18:19:08.440020: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OneHot"" device_type: ""CPU"" constraint { name: ""TI"" allowed_values { list { type: DT_UINT8 } } } constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""depth""')
2017-04-25 18:19:08.440046: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OneHot"" device_type: ""CPU"" constraint { name: ""TI"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""depth""')
2017-04-25 18:19:08.440219: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OneHot"" device_type: ""CPU"" constraint { name: ""TI"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""depth""')
2017-04-25 18:19:08.440246: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OneHot"" device_type: ""CPU"" constraint { name: ""TI"" allowed_values { list { type: DT_UINT8 } } } constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""depth""')
2017-04-25 18:19:08.440287: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OneHot"" device_type: ""CPU"" constraint { name: ""TI"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""depth""')
2017-04-25 18:19:08.440312: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""OneHot"" device_type: ""CPU"" constraint { name: ""TI"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""depth""')
2017-04-25 18:19:08.440423: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Pack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.440443: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Pack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.440490: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Pack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } }')
2017-04-25 18:19:08.440516: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Pad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.440536: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Pad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.440611: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyMomentum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""accum""')
2017-04-25 18:19:08.440629: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PaddingFIFOQueue"" device_type: ""CPU""')
2017-04-25 18:19:08.440645: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQueue"" device_type: ""CPU""')
2017-04-25 18:19:08.440660: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Cast"" device_type: ""CPU""')
2017-04-25 18:19:08.440676: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueClose"" device_type: ""CPU""')
2017-04-25 18:19:08.440708: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PaddingFIFOQueueV2"" device_type: ""CPU""')
2017-04-25 18:19:08.440861: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueDequeueUpToV2"" device_type: ""CPU""')
2017-04-25 18:19:08.440898: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueDequeueUpTo"" device_type: ""CPU""')
2017-04-25 18:19:08.440921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayWriteV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.440941: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayWriteV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.440958: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueDequeueV2"" device_type: ""CPU""')
2017-04-25 18:19:08.440974: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueEnqueueManyV2"" device_type: ""CPU""')
2017-04-25 18:19:08.440989: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueEnqueueMany"" device_type: ""CPU""')
2017-04-25 18:19:08.441050: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueEnqueueV2"" device_type: ""CPU""')
2017-04-25 18:19:08.441075: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Softsign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441128: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Softsign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.441152: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyFtrl"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyFtrl"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.441248: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPush"" device_type: ""CPU""')
2017-04-25 18:19:08.441265: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueEnqueue"" device_type: ""CPU""')
2017-04-25 18:19:08.441285: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Any"" device_type: ""CPU"" constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""reduction_indices""')
2017-04-25 18:19:08.441425: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Max"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441451: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Max"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441621: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BatchToSpaceND"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tblock_shape"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tcrops"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""block_shape"" host_memory_arg: ""crops""')
2017-04-25 18:19:08.441651: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BatchToSpaceND"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tblock_shape"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tcrops"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""block_shape"" host_memory_arg: ""crops""')
2017-04-25 18:19:08.441675: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Mean"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441820: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Mean"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441847: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TopKV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.441867: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TopKV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.441887: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Min"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442038: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Min"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442185: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Prod"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442209: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Prod"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442226: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefExit"" device_type: ""CPU""')
2017-04-25 18:19:08.442246: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442384: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Sum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442414: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442439: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.442463: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442627: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.442671: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442697: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.442718: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""EluGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.442784: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Relu6Grad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442868: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Relu6Grad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.442891: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Relu6"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.442928: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Relu6"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.442950: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReluGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.443026: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReluGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.443044: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ImmutableConst"" device_type: ""CPU""')
2017-04-25 18:19:08.443063: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Relu"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.443082: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Relu"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.443220: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""FakeQuantWithMinMaxArgs"" device_type: ""CPU""')
2017-04-25 18:19:08.443244: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Reshape"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tshape"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.443407: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Reshape"" device_type: ""CPU"" constraint { name: ""Tshape"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.443445: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySizeV2"" device_type: ""CPU""')
2017-04-25 18:19:08.443462: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayCloseV3"" device_type: ""CPU""')
2017-04-25 18:19:08.443478: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueCloseV2"" device_type: ""CPU""')
2017-04-25 18:19:08.443497: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeBilinearGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.443518: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeNearestNeighborGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""size""')
2017-04-25 18:19:08.443584: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeNearestNeighborGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""size""')
2017-04-25 18:19:08.443606: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeNearestNeighbor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""size""')
2017-04-25 18:19:08.443626: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeNearestNeighbor"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""size""')
2017-04-25 18:19:08.443643: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RestoreSlice"" device_type: ""CPU""')
2017-04-25 18:19:08.443904: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.443960: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.443980: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.443999: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.444017: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT16 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.444179: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT16 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.444209: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.444230: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Concat"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""concat_dim""')
2017-04-25 18:19:08.444255: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""InvertPermutation"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""x"" host_memory_arg: ""y""')
2017-04-25 18:19:08.444278: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Reverse"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dims""')
2017-04-25 18:19:08.444480: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Reverse"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""dims""')
2017-04-25 18:19:08.444526: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReverseSequence"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tlen"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.444581: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReverseSequence"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tlen"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.444604: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReverseSequence"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tlen"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.444692: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReverseSequence"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tlen"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.444711: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SaveSlices"" device_type: ""CPU""')
2017-04-25 18:19:08.444726: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Save"" device_type: ""CPU""')
2017-04-25 18:19:08.444742: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayClose"" device_type: ""CPU""')
2017-04-25 18:19:08.444825: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MergeV2Checkpoints"" device_type: ""CPU""')
2017-04-25 18:19:08.444842: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RestoreV2"" device_type: ""CPU""')
2017-04-25 18:19:08.444904: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SaveV2"" device_type: ""CPU""')
2017-04-25 18:19:08.444921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ParseExample"" device_type: ""CPU""')
2017-04-25 18:19:08.444986: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.445011: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.445035: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.445244: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""shape""')
2017-04-25 18:19:08.445271: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.445294: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.445316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.445471: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.445529: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyMomentum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.445554: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyMomentum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.445704: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.445730: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.445752: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.445775: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.445943: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterDiv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.445968: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterDiv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.445990: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterDiv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.446029: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterDiv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.446317: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Size"" device_type: ""CPU"" constraint { name: ""out_type"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""output""')
2017-04-25 18:19:08.446342: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Size"" device_type: ""CPU"" constraint { name: ""out_type"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""output""')
2017-04-25 18:19:08.446363: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.446400: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.446534: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.446557: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.446647: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.446689: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.446774: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.446904: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdAdd"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.446926: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_Recv"" device_type: ""CPU""')
2017-04-25 18:19:08.446944: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_HostSend"" device_type: ""GPU"" host_memory_arg: ""tensor""')
2017-04-25 18:19:08.446964: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyAdadelta"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.447107: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.447136: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.447154: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_Send"" device_type: ""GPU""')
2017-04-25 18:19:08.447285: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LinSpace"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""start"" host_memory_arg: ""stop"" host_memory_arg: ""num"" host_memory_arg: ""output""')
2017-04-25 18:19:08.447357: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.447429: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_HostRecv"" device_type: ""GPU"" host_memory_arg: ""tensor""')
2017-04-25 18:19:08.447454: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LinSpace"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""start"" host_memory_arg: ""stop"" host_memory_arg: ""num"" host_memory_arg: ""output""')
2017-04-25 18:19:08.447479: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Range"" device_type: ""CPU"" constraint { name: ""Tidx"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""start"" host_memory_arg: ""limit"" host_memory_arg: ""delta"" host_memory_arg: ""output""')
2017-04-25 18:19:08.447722: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Range"" device_type: ""CPU"" constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""start"" host_memory_arg: ""limit"" host_memory_arg: ""delta"" host_memory_arg: ""output""')
2017-04-25 18:19:08.447744: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_HostRecv"" device_type: ""CPU""')
2017-04-25 18:19:08.447761: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DeleteSessionTensor"" device_type: ""CPU""')
2017-04-25 18:19:08.447781: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionTensor"" device_type: ""GPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.447801: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionTensor"" device_type: ""GPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.447984: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionTensor"" device_type: ""GPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448005: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionTensor"" device_type: ""CPU""')
2017-04-25 18:19:08.448024: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandleV2"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448063: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandleV2"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448086: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandleV2"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448162: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandle"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448184: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandle"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448204: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandle"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.448287: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_Recv"" device_type: ""GPU""')
2017-04-25 18:19:08.448331: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandleV2"" device_type: ""CPU""')
2017-04-25 18:19:08.448352: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.448536: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.448562: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.448583: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterMul"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.448746: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Rank"" device_type: ""CPU"" host_memory_arg: ""output""')
2017-04-25 18:19:08.448769: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ShapeN"" device_type: ""CPU"" constraint { name: ""out_type"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""output""')
2017-04-25 18:19:08.448789: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ShapeN"" device_type: ""CPU"" constraint { name: ""out_type"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""output""')
2017-04-25 18:19:08.448806: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""VariableV2"" device_type: ""CPU""')
2017-04-25 18:19:08.448855: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Shape"" device_type: ""CPU"" constraint { name: ""out_type"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""output""')
2017-04-25 18:19:08.448879: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Shape"" device_type: ""CPU"" constraint { name: ""out_type"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""output""')
2017-04-25 18:19:08.448982: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LogSoftmax"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449110: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Softmax"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449132: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CheckNumerics"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449151: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SoftplusGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.449170: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SoftplusGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449348: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Slice"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""begin"" host_memory_arg: ""size""')
2017-04-25 18:19:08.449390: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Slice"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""begin"" host_memory_arg: ""size""')
2017-04-25 18:19:08.449435: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Slice"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""begin"" host_memory_arg: ""size""')
2017-04-25 18:19:08.449456: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SoftsignGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.449475: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SoftsignGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449545: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedConv2D"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""Tfilter"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.449591: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseMatMul"" device_type: ""CPU"" constraint { name: ""Ta"" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: ""Tb"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.449613: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseMatMul"" device_type: ""CPU"" constraint { name: ""Ta"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tb"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.449867: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseMatMul"" device_type: ""CPU"" constraint { name: ""Ta"" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: ""Tb"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449894: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseMatMul"" device_type: ""CPU"" constraint { name: ""Ta"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tb"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449916: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayReadV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.449940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayReadV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.449957: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueDequeueMany"" device_type: ""CPU""')
2017-04-25 18:19:08.450118: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.450145: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.450167: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.450190: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.450369: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.450395: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.450449: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.450473: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseToDense"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.450578: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackClose"" device_type: ""GPU"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.450602: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPop"" device_type: ""GPU"" constraint { name: ""elem_type"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.450647: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPop"" device_type: ""GPU"" constraint { name: ""elem_type"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""handle"" host_memory_arg: ""elem""')
2017-04-25 18:19:08.450671: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPop"" device_type: ""GPU"" constraint { name: ""elem_type"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""handle"" host_memory_arg: ""elem""')
2017-04-25 18:19:08.450760: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Stack"" device_type: ""GPU"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.450778: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ShardedFilespec"" device_type: ""CPU""')
2017-04-25 18:19:08.450794: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Stack"" device_type: ""CPU""')
2017-04-25 18:19:08.450813: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Exit"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.450862: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Exit"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } }')
2017-04-25 18:19:08.450895: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Exit"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.450916: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Exit"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.450978: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPop"" device_type: ""CPU""')
2017-04-25 18:19:08.451002: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSliceGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""shape"" host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.451070: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSliceGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""shape"" host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.451101: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSliceGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""shape"" host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.451181: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayCloseV3"" device_type: ""GPU"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.451357: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayCloseV2"" device_type: ""GPU"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.451381: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Square"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.451398: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayClose"" device_type: ""GPU"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.451431: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayCloseV2"" device_type: ""CPU""')

2017-04-25 18:19:08.452321: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NoOp"" device_type: ""GPU""')
2017-04-25 18:19:08.452347: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySizeV2"" device_type: ""GPU"" host_memory_arg: ""handle"" host_memory_arg: ""size""')
2017-04-25 18:19:08.452406: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySizeV3"" device_type: ""CPU""')
2017-04-25 18:19:08.452446: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySplitV3"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.452489: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySplitV3"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.452511: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSliceAssign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.452774: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSliceAssign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.452800: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSliceAssign"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.452907: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StringJoin"" device_type: ""CPU""')
2017-04-25 18:19:08.452928: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGradV2"" device_type: ""GPU"" host_memory_arg: ""handle"" host_memory_arg: ""grad_handle""')
2017-04-25 18:19:08.452944: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueDequeue"" device_type: ""CPU""')
2017-04-25 18:19:08.453024: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""PlaceholderWithDefault"" device_type: ""CPU""')
2017-04-25 18:19:08.453041: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGrad"" device_type: ""CPU""')
2017-04-25 18:19:08.453056: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NoOp"" device_type: ""CPU""')
2017-04-25 18:19:08.453072: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""CTCBeamSearchDecoder"" device_type: ""CPU""')
2017-04-25 18:19:08.453109: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySplitV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.453132: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySplitV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.453169: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BiasAddGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.453236: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BiasAddGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.453259: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySplit"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.453364: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySplit"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.453411: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Neg"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.453431: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.453552: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } }')
2017-04-25 18:19:08.453628: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.453649: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""NextIteration"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_STRING } } } host_memory_arg: ""data"" host_memory_arg: ""output""')
2017-04-25 18:19:08.453690: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.453798: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.453822: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.453943: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterNdSub"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.453968: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayScatterV3"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.454149: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayScatterV3"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.454176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayUnpack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.454195: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayUnpack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.454246: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454279: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454347: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454370: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454391: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454460: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454567: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcat"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454590: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcat"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454611: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcat"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454651: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcat"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454745: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcat"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454768: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcat"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.454788: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.454808: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.454941: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.454963: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } }')
2017-04-25 18:19:08.454982: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.455020: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.455037: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Restore"" device_type: ""CPU""')
2017-04-25 18:19:08.455061: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455132: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.455156: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455180: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.455322: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayScatterV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455345: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayScatterV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.455370: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455394: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.455419: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455584: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.455609: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Unpack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455629: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Unpack"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.455726: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var""')
2017-04-25 18:19:08.455794: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } host_memory_arg: ""var""')
2017-04-25 18:19:08.455815: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.455861: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.455894: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.455914: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } }')
2017-04-25 18:19:08.455979: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.456000: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGatherV2"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.456017: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArray"" device_type: ""CPU""')
2017-04-25 18:19:08.456115: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReverseV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.456157: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ReverseV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tidx"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""axis""')
2017-04-25 18:19:08.456293: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""IsVariableInitialized"" device_type: ""CPU""')
2017-04-25 18:19:08.456316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayPack"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.456405: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayPack"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.456426: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayPack"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.456445: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayPack"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } }')
2017-04-25 18:19:08.456524: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayPack"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.456544: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayPack"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.456565: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Elu"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.456627: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayWriteV3"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.456664: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayWriteV3"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.456725: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_Send"" device_type: ""CPU""')
2017-04-25 18:19:08.456742: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""RefEnter"" device_type: ""CPU""')
2017-04-25 18:19:08.456761: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayWrite"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.456901: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayWrite"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.456921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGradV3"" device_type: ""GPU"" host_memory_arg: ""handle"" host_memory_arg: ""grad_handle""')
2017-04-25 18:19:08.456940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyAdam"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.457066: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGrad"" device_type: ""GPU"" host_memory_arg: ""handle"" host_memory_arg: ""grad_handle""')
2017-04-25 18:19:08.457089: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Softplus"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.457108: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Softplus"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.457125: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGradV3"" device_type: ""CPU""')
2017-04-25 18:19:08.457140: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGradV2"" device_type: ""CPU""')
2017-04-25 18:19:08.457186: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayV3"" device_type: ""CPU""')
2017-04-25 18:19:08.457283: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayV2"" device_type: ""CPU""')
2017-04-25 18:19:08.457302: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TileGrad"" device_type: ""CPU"" host_memory_arg: ""multiples""')
2017-04-25 18:19:08.457322: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGather"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.457341: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGather"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.457378: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGather"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } }')
2017-04-25 18:19:08.457401: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGather"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } }')
2017-04-25 18:19:08.457480: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGather"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.457501: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayGather"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } }')
2017-04-25 18:19:08.457594: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LogicalAnd"" device_type: ""CPU""')
2017-04-25 18:19:08.457640: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Exp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.457659: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySizeV3"" device_type: ""GPU"" host_memory_arg: ""handle"" host_memory_arg: ""size""')
2017-04-25 18:19:08.457804: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Tile"" device_type: ""CPU"" constraint { name: ""Tmultiples"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""multiples""')
2017-04-25 18:19:08.457828: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TopK"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.457848: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TopK"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.457871: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.457896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.458022: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.458047: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.458071: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.458095: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.458247: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Pow"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.458274: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""mg"" host_memory_arg: ""ms"" host_memory_arg: ""mom""')
2017-04-25 18:19:08.458296: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayReadV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.458316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayReadV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.458439: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""ms"" host_memory_arg: ""mom""')
2017-04-25 18:19:08.458478: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""LoopCond"" device_type: ""GPU"" host_memory_arg: ""input"" host_memory_arg: ""output""')
2017-04-25 18:19:08.458495: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Variable"" device_type: ""CPU""')
2017-04-25 18:19:08.458516: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""accum""')
2017-04-25 18:19:08.458538: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } host_memory_arg: ""var"" host_memory_arg: ""accum""')
2017-04-25 18:19:08.458747: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SplitV"" device_type: ""CPU"" constraint { name: ""Tlen"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""size_splits"" host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.458872: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SplitV"" device_type: ""CPU"" constraint { name: ""Tlen"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""size_splits"" host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.459022: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SplitV"" device_type: ""CPU"" constraint { name: ""Tlen"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""size_splits"" host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.459209: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SplitV"" device_type: ""CPU"" constraint { name: ""Tlen"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""size_splits"" host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.459237: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SplitV"" device_type: ""CPU"" constraint { name: ""Tlen"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""size_splits"" host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.459361: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SplitV"" device_type: ""CPU"" constraint { name: ""Tlen"" allowed_values { list { type: DT_INT64 } } } constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""size_splits"" host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.459512: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyAdam"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""m"" host_memory_arg: ""v""')
2017-04-25 18:19:08.459645: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueSize"" device_type: ""CPU""')
2017-04-25 18:19:08.459665: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BiasAddV1"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.459684: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BiasAddV1"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.459723: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.459842: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.459867: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.459946: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.460054: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.460306: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.460357: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackClose"" device_type: ""CPU""')
2017-04-25 18:19:08.460379: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Maximum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.460439: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdadelta"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.460704: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdadelta"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.460732: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyMomentum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.460755: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyMomentum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.460828: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.461054: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.461081: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.461103: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ScatterUpdate"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.461126: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdadelta"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.461255: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyAdadelta"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.461278: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPush"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""handle""')
2017-04-25 18:19:08.461299: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPush"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""handle"" host_memory_arg: ""elem"" host_memory_arg: ""output""')
2017-04-25 18:19:08.461320: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StackPush"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_BOOL } } } host_memory_arg: ""handle"" host_memory_arg: ""elem"" host_memory_arg: ""output""')
2017-04-25 18:19:08.461451: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyMomentum"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.461475: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyFtrl"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.461499: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyFtrl"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.461610: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyFtrl"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""accum"" host_memory_arg: ""linear""')
2017-04-25 18:19:08.461679: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.461699: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyFtrl"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.461762: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""var"" host_memory_arg: ""gradient_accumulator"" host_memory_arg: ""gradient_squared_accumulator""')
2017-04-25 18:19:08.461793: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""var"" host_memory_arg: ""gradient_accumulator"" host_memory_arg: ""gradient_squared_accumulator""')
2017-04-25 18:19:08.461868: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""var"" host_memory_arg: ""gradient_accumulator"" host_memory_arg: ""gradient_squared_accumulator""')
2017-04-25 18:19:08.461896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } } host_memory_arg: ""var"" host_memory_arg: ""gradient_accumulator"" host_memory_arg: ""gradient_squared_accumulator""')
2017-04-25 18:19:08.462044: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySize"" device_type: ""CPU""')
2017-04-25 18:19:08.462124: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MaxPoolGradGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.462146: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MaxPoolGradGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.462211: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.462236: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.462395: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.462423: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.462447: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""gradient_accumulator"" host_memory_arg: ""gradient_squared_accumulator""')
2017-04-25 18:19:08.462607: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } host_memory_arg: ""var"" host_memory_arg: ""gradient_accumulator"" host_memory_arg: ""gradient_squared_accumulator""')
2017-04-25 18:19:08.462708: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Tanh"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.462744: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Inv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.462761: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Squeeze"" device_type: ""CPU""')
2017-04-25 18:19:08.462779: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.462924: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyAdagradDA"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } }')
2017-04-25 18:19:08.462947: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayRead"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.462967: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayRead"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.462984: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Enter"" device_type: ""CPU""')
2017-04-25 18:19:08.463003: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""accum""')
2017-04-25 18:19:08.463047: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.463166: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.463193: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.463264: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.463373: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""InvertPermutation"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.463398: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.463423: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.463518: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.463616: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SparseApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.463639: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.463677: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyProximalGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } }')
2017-04-25 18:19:08.463716: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Exit"" device_type: ""CPU""')
2017-04-25 18:19:08.463798: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueDequeueManyV2"" device_type: ""CPU""')
2017-04-25 18:19:08.463819: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayScatter"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.463839: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayScatter"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.463879: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MirrorPadGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.463921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""MirrorPadGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tpaddings"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""paddings""')
2017-04-25 18:19:08.464117: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyAdadelta"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var"" host_memory_arg: ""accum"" host_memory_arg: ""accum_update""')
2017-04-25 18:19:08.464154: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""GetSessionHandle"" device_type: ""CPU""')
2017-04-25 18:19:08.464174: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.464195: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.464343: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.464367: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.464388: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.464408: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArrayConcatV3"" device_type: ""CPU"" constraint { name: ""dtype"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""lengths"" host_memory_arg: ""handle""')
2017-04-25 18:19:08.464548: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.464567: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QueueSizeV2"" device_type: ""CPU""')
2017-04-25 18:19:08.464604: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceApplyGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""var""')
2017-04-25 18:19:08.464626: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SqrtGrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.464642: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""_HostSend"" device_type: ""CPU""')
2017-04-25 18:19:08.464661: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Conv2D"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.464735: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeBilinear"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""size""')
2017-04-25 18:19:08.464756: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResizeBilinear"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""size""')
2017-04-25 18:19:08.464774: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TemporaryVariable"" device_type: ""CPU""')
2017-04-25 18:19:08.464792: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ExpandDims"" device_type: ""CPU"" constraint { name: ""Tdim"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""dim""')
2017-04-25 18:19:08.464844: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DestroyTemporaryVariable"" device_type: ""CPU""')
2017-04-25 18:19:08.464865: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TruncateDiv"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_UINT8 } } }')
2017-04-25 18:19:08.464954: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.464976: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyProximalAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } }')
2017-04-25 18:19:08.464992: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ShardedFilename"" device_type: ""CPU""')
2017-04-25 18:19:08.465013: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""BroadcastArgs"" device_type: ""GPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""s0"" host_memory_arg: ""s1"" host_memory_arg: ""r0""')
2017-04-25 18:19:08.465053: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Split"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.465155: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Split"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.465176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Split"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: ""split_dim""')
2017-04-25 18:19:08.465193: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Where"" device_type: ""CPU""')
2017-04-25 18:19:08.465299: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""SoftmaxCrossEntropyWithLogits"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.465323: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSlice"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.465475: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSlice"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.465501: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""StridedSlice"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: ""begin"" host_memory_arg: ""end"" host_memory_arg: ""strides""')
2017-04-25 18:19:08.465527: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Transpose"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } constraint { name: ""Tperm"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""perm""')
2017-04-25 18:19:08.465550: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Transpose"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tperm"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""perm""')
2017-04-25 18:19:08.465676: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""Transpose"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: ""Tperm"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""perm""')
2017-04-25 18:19:08.465702: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.465726: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyAdagrad"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.465868: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.465895: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_HALF } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.465919: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.465973: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.466096: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT32 } } }')
2017-04-25 18:19:08.466123: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ResourceSparseApplyCenteredRMSProp"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_DOUBLE } } } constraint { name: ""Tindices"" allowed_values { list { type: DT_INT64 } } }')
2017-04-25 18:19:08.466248: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""ApplyGradientDescent"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_FLOAT } } }')
2017-04-25 18:19:08.466276: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""QuantizedBatchNormWithGlobalNormalization"" device_type: ""CPU"" constraint { name: ""Tinput"" allowed_values { list { type: DT_QUINT8 } } } constraint { name: ""out_type"" allowed_values { list { type: DT_QINT32 } } }')
2017-04-25 18:19:08.466431: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""TensorArraySize"" device_type: ""GPU"" host_memory_arg: ""handle"" host_memory_arg: ""size""')
2017-04-25 18:19:08.466453: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: ""DeleteSessionTensor"" device_type: ""GPU"" host_memory_arg: ""handle""')
</pre>"
9442,No 1-dimensional max pool?,"It seems that there is no 1-dimensional max pool.  

I'm using one for my own projects.  Should I submit a pull request?"
9441,Non deterministic behaviour of tf.train.batch in case the number of threads is higher than 1.,"This is related to the StackOverflow question: http://stackoverflow.com/questions/43612366/tf-train-batch-output-is-not-deterministic/43613376#43613376

The thread owner creates a batch with the following code:
```
BatchedInputs = tf.train.batch(
  Inputs,
  batch_size=64,
  num_threads=8,
  capacity=500 + 3 * 64)
``` 

And he noticed that created batches are not in every run the same. They are quite similar, but sometimes the inputs are mixed or some are missing.
According to the answer on StackOverflow reducing the number of pre-fetch threads to 1 is solving this issue.

Since this could be an issue for test-set evaluation (where everyone would expect the exact same outcome for every run), I wonder if this is the intended behaviour?
It should at least be added to the documentation for `tf.train.batch` that the generated batches can be non-deterministic.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Binary (pip3)
- **TensorFlow version (use command below)**:
1.1.0
- **Bazel version (if compiling from source)**:
non
- **CUDA/cuDNN version**:
CUDA 8.0, cuDNN 5.1
- **GPU model and memory**:
GTX680
- **Exact command to reproduce**:
See above.

### Describe the problem
see above

### Source code / logs
-"
9440,Loading sklearn model in Java. Model created with DNNClassifier in python,"The goal is to open in Java a model created/trained in phyton with tensorflow.contrib.learn.learn.DNNClassifier.

At the moment the main issue is to know the correct name of the ""Operation"" to give in java on the session runner method.

I have this test code in python :

`from __future__ import division, print_function, absolute_import
import tensorflow as tf
import pandas as pd
import tensorflow.contrib.learn as learn
import numpy as np
from sklearn import metrics
from sklearn.cross_validation import train_test_split
from tensorflow.contrib import layers
from tensorflow.contrib.learn.python.learn.utils import input_fn_utils
from tensorflow.python.ops import array_ops
from tensorflow.python.framework import dtypes
from tensorflow.python.util.compat import as_text

print(tf.VERSION)

df = pd.read_csv('../NNNormalizeData-out.csv')

inputs = []
target = []

y=0;    
for x in df.columns:
    if y != 35 :
        #print(""added %d"" %y)
        inputs.append(x)
    else :
        target.append(x)
    y+=1

total_inputs,total_output = df.as_matrix(inputs).astype(np.float32),df.as_matrix([target]).astype(np.int32)

train_inputs, test_inputs, train_output, test_output = train_test_split(total_inputs, total_output, test_size=0.2, random_state=42)

# Define inputs format
feature_columns = [tf.contrib.layers.real_valued_column("""",dimension=train_inputs.shape[1],dtype=tf.float32)]
#target_column = [tf.contrib.layers.real_valued_column(""output"", dimension=train_output.shape[1])]

classifier = learn.DNNClassifier(hidden_units=[10, 20, 5], n_classes=5
                                 ,feature_columns=feature_columns)

classifier.fit(train_inputs, train_output, steps=100)

# Save Model into saved_model.pbtxt file (possible to Load in Java)
tfrecord_serving_input_fn = tf.contrib.learn.build_parsing_serving_input_fn(layers.create_feature_spec_for_parsing(feature_columns))  
classifier.export_savedmodel(export_dir_base=""test"", serving_input_fn = tfrecord_serving_input_fn,as_text=True)


# Measure accuracy
pred = list(classifier.predict(test_inputs, as_iterable=True))
score = metrics.accuracy_score(test_output, pred)
print(""Final score: {}"".format(score))

# test individual samples 
sample_1 = np.array( [[0.37671986791414125,0.28395908337619136,-0.0966095873607713,-1.0,0.06891621389763203,-0.09716678086712205,0.726029084013637,4.984689881073479E-4,-0.30296253267499107,-0.16192917054985334,0.04820256230479658,0.4951319883569152,0.5269983894210499,-0.2560313828048315,-0.3710980821053321,-0.4845867212612598,-0.8647234314469595,-0.6491591208322198,-1.0,-0.5004549422844073,-0.9880910165770813,0.5540293108747256,0.5625990251930839,0.7420121698556554,0.5445551415657979,0.4644276850235627,0.7316976292340245,0.636690006814346,0.16486621649984112,-0.0466018967678159,0.5261100063227044,0.6256168612312738,-0.544295484930702,0.379125782517193,0.6959368575211544]], dtype=float)
sample_2 = np.array( [[1.0,0.7982741870963959,1.0,-0.46270838239235024,0.040320274521029376,0.443451913224413,-1.0,1.0,1.0,-1.0,0.36689718911339564,-0.13577379160035796,-0.5162916256414466,-0.03373651520104648,1.0,1.0,1.0,1.0,0.786999801054777,-0.43856035121103853,-0.8199093927945158,1.0,-1.0,-1.0,-0.1134921695894473,-1.0,0.6420892436196663,0.7871737734493178,1.0,0.6501788845358409,1.0,1.0,1.0,-0.17586627413625022,0.8817194210401085]], dtype=float)

pred = list(classifier.predict(sample_2, as_iterable=True))
print(""Prediction for sample_1 is:{} "".format(pred))

pred = list(classifier.predict_proba(sample_2, as_iterable=True))
print(""Prediction for sample_2 is:{} "".format(pred))`
____________________________________________________________________________________________________________
A model_saved.pbtxt file is created.

I try to load this model in Java with the following code :

` public class HelloTF {
    public static void main(String[] args) throws Exception {
        SavedModelBundle bundle=SavedModelBundle.load(""/java/workspace/APIJavaSampleCode/tfModels/dnn/ModelSave"",""serve"");
        Session s = bundle.session();

        double[] inputDouble = {1.0,0.7982741870963959,1.0,-0.46270838239235024,0.040320274521029376,0.443451913224413,-1.0,1.0,1.0,-1.0,0.36689718911339564,-0.13577379160035796,-0.5162916256414466,-0.03373651520104648,1.0,1.0,1.0,1.0,0.786999801054777,-0.43856035121103853,-0.8199093927945158,1.0,-1.0,-1.0,-0.1134921695894473,-1.0,0.6420892436196663,0.7871737734493178,1.0,0.6501788845358409,1.0,1.0,1.0,-0.17586627413625022,0.8817194210401085};
        float [] inputfloat=new float[inputDouble.length];
        for(int i=0;i<inputfloat.length;i++)
        {
            inputfloat[i]=(float)inputDouble[i];
        }
        Tensor inputTensor = Tensor.create(new long[] {35}, FloatBuffer.wrap(inputfloat) );

        Tensor result = s.runner()
                .feed(""input_example_tensor"", inputTensor)
                .fetch(""dnn/multi_class_head/predictions/probabilities"")
                .run().get(0);


         float[] m = new float[5];
         float[] vector = result.copyTo(m);
         float maxVal = 0;
         int inc = 0;
         int predict = -1;
         for(float val : vector) 
         {
             System.out.println(val+""  "");
             if(val > maxVal) {
                 predict = inc;
                 maxVal = val;
             }
             inc++;
         }
         System.out.println(predict);



    }`


I get the error on the .run().get(0); line :

`Exception in thread ""main"" org.tensorflow.TensorFlowException: Output 0 of type float does not match declared output type string for node _recv_input_example_tensor_0 = _Recv[_output_shapes=[[-1]], client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=3663984897684684554, tensor_name=""input_example_tensor:0"", tensor_type=DT_STRING, _device=""/job:localhost/replica:0/task:0/cpu:0""]()
    at org.tensorflow.Session.run(Native Method)
    at org.tensorflow.Session.access$100(Session.java:48)
    at org.tensorflow.Session$Runner.runHelper(Session.java:285)
    at org.tensorflow.Session$Runner.run(Session.java:235)
    at tensorflow.HelloTF.main(HelloTF.java:35)`

It seams like the ""runner"" is expecting strings instead of floats array ... (?)

I suspect the ""operation"" names (that were extracted looking into the saved_model.pbtxt)are not correct in the lines :

`  .feed(""input_example_tensor"", inputTensor)
                .fetch(""dnn/multi_class_head/predictions/probabilities"")`

Some help would be appreciated since it is really important to execute in ""real-time"" the models in Java. 

 "
9439,small error in DynamicAttentionWrapper,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Not relevant

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Not relevant

- **TensorFlow installed from (source or binary)**:

Not relevant

- **TensorFlow version (use command below)**:

1.1

- **Bazel version (if compiling from source)**:

Not relevant

- **CUDA/cuDNN version**:

Not relevant

- **GPU model and memory**:

Not relevant

- **Exact command to reproduce**:

Not relevant

### Describe the problem

line 465 in tensorflow/tensorflow/contrib/seq2seq/python/ops/dynamic_attention_wrapper.py says 

'''
if not callable(cell_input_fn):. 
'''
I think it should say 

'''
if not callable(probability_fn):
'''

### Source code / logs

None"
9437,Docs generation is broken in Python 3.5,"### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from**: Source
- **TensorFlow version**: b6bafadd51a471daa7157f515598e08e8f9f1611
- **Bazel version**: 0.4.5
- **Exact command to reproduce**: `bazel run -- //tensorflow/tools/docs:generate --src_dir=tensorflow/docs_src --output_dir=/tmp/tf_docs`

### Describe the problem
Problem 1: Since python 3.5, `namedtuple` objects have no `__dict__` property. See [here](http://stackoverflow.com/questions/34166469/did-something-about-namedtuple-change-in-3-5-1) and [here](http://bugs.python.org/issue24931) for more details. This problem is easily fixed by changing all instances of `h3.format(**info.__dict__)` to `h3.format(**info._asdict())` in [`pretty_docs.py`](https://github.com/tensorflow/tensorflow/blob/b6bafadd51a471daa7157f515598e08e8f9f1611/tensorflow/tools/docs/pretty_docs.py).

Problem 2: The codegen library used by the docs generator is 5 years old and doesn't work with python 3.5 (the problem I'm getting is identical to https://github.com/berkerpeksag/astor/issues/48 and https://github.com/alecthomas/importmagic/issues/25).

### Source code / logs
Initial stack trace:
```
Traceback (most recent call last):
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/generate.py"", line 49, in <module>
    sys.exit(doc_generator.build(flags))
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/generate_lib.py"", line 473, in build
    write_docs(output_dir, parser_config, yaml_toc=self.yaml_toc)
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/generate_lib.py"", line 127, in write_docs
    f.write(pretty_docs.build_md_page(page_info))
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/pretty_docs.py"", line 39, in build_md_page
    return _build_class_page(page_info)
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/pretty_docs.py"", line 126, in _build_class_page
    parts.append(h3.format(**method_info.__dict__))
AttributeError: '_MethodInfo' object has no attribute '__dict__'
ERROR: Non-zero return code '1' from command: Process exited with status 1.
```

Stack trace after fixing dictionary problem:
```
Traceback (most recent call last):
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/generate.py"", line 49, in <module>
    sys.exit(doc_generator.build(flags))
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/generate_lib.py"", line 473, in build
    write_docs(output_dir, parser_config, yaml_toc=self.yaml_toc)
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/generate_lib.py"", line 119, in write_docs
    page_info = parser.docs_for_object(full_name, py_object, parser_config)
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/parser.py"", line 1201, in docs_for_object
    page_info.set_signature(py_object, parser_config.reverse_index)
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/parser.py"", line 797, in set_signature
    self._signature = _generate_signature(function, reverse_index)
  File ""/home/amcrae/.cache/bazel/_bazel_amcrae/c5da01ed82406ffc0f71b490859f88cc/execroot/tf_docs/bazel-out/local-py3-opt/bin/tensorflow/tools/docs/generate.runfiles/org_tensorflow/tensorflow/tools/docs/parser.py"", line 638, in _generate_signature
    default_text = codegen.to_source(ast_default)
  File ""/home/amcrae/workspace/tf_docs/venv/lib/python3.5/site-packages/codegen.py"", line 68, in to_source
    generator.visit(node)
  File ""/usr/lib/python3.5/ast.py"", line 245, in visit
    return visitor(node)
  File ""/home/amcrae/workspace/tf_docs/venv/lib/python3.5/site-packages/codegen.py"", line 386, in visit_Call
    if node.starargs is not None:
AttributeError: 'Call' object has no attribute 'starargs'
ERROR: Non-zero return code '1' from command: Process exited with status 1.
```

UPDATE: Command for fixing dictionary issue is 
```
sed -i -e 's/__dict__/_asdict()/' tensorflow/tools/docs/pretty_docs.py
```"
9436,Python Configuration Error: 'PYTHON_BIN_PATH' environment variable is not set,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X Sierra
- **TensorFlow installed from (source or binary)**: N/A (compiling from HEAD)
- **TensorFlow version (use command below)**: N/A (see above)
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**: none (AMD GPU)
- **GPU model and memory**: Radeon Pro 460
- **Exact command to reproduce**:

`sudo bazel build --config opt --copt=-msse4.1 --copt=-msse4.1 --copt=-mavx --copt=-mavx2 --copt=-mfma //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem

Trying to build tensorflow from source (version installed via pip does not use some optimised CPU instructions), get the following error:


```bash
 ~/workspace/tensorflow   master  sudo bazel build --config opt --copt=-msse4.1 --copt=-msse4.1 --copt=-mavx --copt=-mavx2 --copt=-mfma //tensorflow/tools/pip_package:build_pip_package
WARNING: Config values are not defined in any .rc file: opt
ERROR: /Users/kachkach/workspace/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Traceback (most recent call last):
	File ""/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl"", line 180
		_create_python_repository(repository_ctx)
	File ""/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl"", line 157, in _create_python_repository
		_get_env_var(repository_ctx, _PYTHON_BIN_PATH)
	File ""/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl"", line 48, in _get_env_var
		_python_configure_fail(""'%s' environment variable is no...)
	File ""/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl"", line 36, in _python_configure_fail
		fail(""
%sPython Configuration Error:%...))

Python Configuration Error: 'PYTHON_BIN_PATH' environment variable is not set
 and referenced by '//third_party/py/numpy:headers'.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.
```
Note that I used `which python3` to find where my Python binary is located, and exported that as PYTHON_BIN_PATH, but it does not seem to help."
9435,Tensorflow Error - no such package '@local_config_cuda//cuda',"So I'm trying to run the image retraining official tensorflow tutorial from this link: https://www.tensorflow.org/tutorials/image_retraining 

I need to get it working for my dissertation with my own images in less than a month so it's extremely urgent.
Once I get to the line ""bazel build tensorflow/examples/image_retraining:retrain""
I get this output:
""ERROR: error loading package 'tensorflow/examples/image_retraining': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': error loading package 'external': The repository named 'local_config_cuda' could not be resolved.""

This thread seems to be the same issue, but no solutions offered: https://github.com/tensorflow/tensorflow/issues/5805

This thread has more activity but it's talking about '@local_config_cuda//crosstool' rather than '@local_config_cuda/cuda/' so may not be helpful for me: https://github.com/tensorflow/tensorflow/issues/4105

I'm using Linux Mint.
Here is my tf_env.txt file for details about my system: [tf_env.txt](https://github.com/tensorflow/tensorflow/files/954822/tf_env.txt)
Let me know if there's any other details I should add which could be useful.

I used this page for installation: https://www.tensorflow.org/install/install_linux
So CUDA® Toolkit 8.0.
cuDNN v5.1
virtualenv install of Tensorflow

Trying to run python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
says ""Failed to load the native TensorFlow runtime.""
but I can get other simple Tensorflow stuff to work so not sure why that is.


"
9434,Using replace to evaluate multiple gradients during training in Keras,"I am a researcher in optimization and I am interested in testing algorithms for training DNNs using keras, and am now using tensorflow backend.

In practice, I would like to do something a bit different from the other optimizers, I would like to compute the gradient at a slightly different value of the tensor of parameters than the current one, and the update I will make to the parameters will depend on both the current gradient and this other gradient.  

In practice this has proven more difficult than anticipated.
See https://github.com/fchollet/keras/issues/6175
it was suggested I come to here for further suggestions.

My code is a standard keras python code, the body does

model = Sequential()
model.add(Dense(512, input_shape=(784,)))
...
model.compile(loss='categorical_crossentropy',
              optimizer = myopt,
              metrics=['accuracy'])
history = model.fit(X_train, Y_train,
                    batch_size=batch_size, nb_epoch=nb_epoch, 
                    verbose=1, validation_data=(X_test, Y_test))


In the get_updates call function of my custom optimizer, it begins as usual

    def get_updates(self, params, constraints, loss):
        grads = self.get_gradients(loss, params)

Now, I want to now get the gradients at a different value of grads. First I tried just defining another tensor of the same structure but different values and take the get_gradients, but of course the loss is a graph depending on params already. Then I tried changing params itself (then copying the old values of the tensor to another one, to replace params after the evaluation) but apparently as the forward pass was not made this was ineffective. As per the advice in the above github conversation in keras, I tried,

        tempparams = [a+1. for a in params]
        replace = {p:npm for p, npm in zip(params, tempparams)}
        gradsn = [tf.contrib.graph_editor.graph_replace(g.op, replace) for g in grads]


but this is still not OK, as I get the error

TypeError: Expected a type in (<class 'tensorflow.python.framework.ops.Operation'>), got: <class 'tensorflow.python.ops.variables.Variable'


Thank you



"
9433,scan in theano and tensorflow,"There is a function written with theano:

```
`import numpy as np
import theano as theano
import theano.tensor as T

def forward_prop_step(x_t, s_t1_prev, s_t2_prev):
            # This is how we calculated the hidden state in a simple RNN. No longer!
            # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))

            # Word embedding layer
            x_e = E[:,x_t]

            # GRU Layer 1
            z_t1 = T.nnet.hard_sigmoid(U[0].dot(x_e) + W[0].dot(s_t1_prev) + b[0])
            r_t1 = T.nnet.hard_sigmoid(U[1].dot(x_e) + W[1].dot(s_t1_prev) + b[1])
            c_t1 = T.tanh(U[2].dot(x_e) + W[2].dot(s_t1_prev * r_t1) + b[2])
            s_t1 = (T.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev

            # GRU Layer 2
            z_t2 = T.nnet.hard_sigmoid(U[3].dot(s_t1) + W[3].dot(s_t2_prev) + b[3])
            r_t2 = T.nnet.hard_sigmoid(U[4].dot(s_t1) + W[4].dot(s_t2_prev) + b[4])
            c_t2 = T.tanh(U[5].dot(s_t1) + W[5].dot(s_t2_prev * r_t2) + b[5])
            s_t2 = (T.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev

            # Final output calculation
            # Theano's softmax returns a matrix with one row, we only need the row
            o_t = T.nnet.softmax(V.dot(s_t2) + c)[0]

return [o_t, s_t1, s_t2]`
```

I have tried to rewrite it with tensorflow:

```
`import numpy as np, tensorflow as tf, operator

def forward_prop_step(x_t, s_t1_prev, s_t2_prev):
                        # This is how we calculated the hidden state in a simple RNN. No longer!
                        # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))

                        # Word embedding layer
                        x_e = E[:,x_t]

                        # GRU Layer 1
                        z_t1 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[0], x_e)) + tf.reduce_sum(tf.multiply(W[0], s_t1_prev)) + b[0])
                        r_t1 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[1], x_e)) + tf.reduce_sum(tf.multiply(W[1], s_t1_prev)) + b[1])
                        c_t1 = tf.nn.tanh(tf.reduce_sum(tf.multiply(U[2], x_e)) + tf.reduce_sum(tf.multiply(W[2], (s_t1_prev * r_t1))) + b[2])
                        s_t1 = (tf.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev

                        # GRU Layer 2
                        z_t2 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[3], s_t1)) + tf.reduce_sum(tf.multiply(W[3], s_t2_prev)) + b[3])
                        r_t2 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[4], s_t1)) + tf.reduce_sum(tf.multiply(W[4], s_t2_prev)) + b[4])
                        c_t2 = tf.nn.tanh(tf.reduce_sum(tf.multiply(U[5], s_t1)) + tf.reduce_sum(tf.multiply(W[5], (s_t2_prev * r_t2))) + b[5])
                        s_t2 = (tf.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev

                        # Final output calculation
                        # Tensorflow's softmax returns a matrix with one row, we only need the row
                        o_t = tf.nn.softmax(tf.reduce_sum(tf.multiply(V, s_t2)) + c)[0]

                        return [o_t, s_t1, s_t2]`
```

In theano, scan function is called to perform ""forward_prep_step"" function in a loop:

```
`[o, s, s2], updates = theano.scan(
            forward_prop_step,
            sequences=x,
            truncate_gradient=self.bptt_truncate,
            outputs_info=[None, 
                          dict(initial=T.zeros(self.hidden_dim)),
dict(initial=T.zeros(self.hidden_dim))])`
```

There is a scan function in tensorflow as well, but they don't get the same parameters. How could be the transformation of scan function above, into tensorflow scan function? "
9431,"Hi,",
9430,"(v1.1.0, CPU)SSE,SSE2,etc warning messages on Windows 10","These are awkward messages since TensofFlow doesn't support windows build officially.

![image](https://cloud.githubusercontent.com/assets/4515120/25375011/5e524a40-29da-11e7-96f9-b9f4f17ae3ee.png)
"
9428,libhexagon_controller.so build failed [missing files: GRAPHINIT := /prj/dsp/qdsp6/arch/cnn/setup/inceptionv3_uint8in.c],"OS: Ubuntu 16.04 64bits
Android Version: 7.1 (Nougat)
NDK Version: android-ndk-r12b
HEXAGON SDK: 3.1
nnlib source: https://source.codeaurora.org/quic/hexagon_nn/nnlib

I have been following the steps provided at below link, for using tensorflow on hexagon. 
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hvx

Environment and copying files properly as mentioned in the link is taken care of.
Having said that, I am facing 2 issues with the build,

(1-  skel.so) while building skel.so for hexagon , error reported **missing file**

GRAPHINIT := /prj/dsp/qdsp6/arch/cnn/setup/inceptionv3_uint8in.c in nnlib/Makefile


(2 - stub+controller.so) while building libhexagon_controller.so, there is this error reported:

    ------------------------------------------
     --- V = android_Debug_aarch64
     --- GLUE_DIR = glue
     --- HEXAGON_SDK_ROOT = /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1
     ------------------------------------------

 making /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1/test/common/test_util
 making /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1/tools/qaic
 making /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1/libs/common/atomic
 making /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1/libs/common/rpcmem
 making .
 android_Debug_aarch64/hexagon_controller.o: In function                                         `hexagon_controller_InitInputNodeDataToInceptionDummyData':
 /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1/examples/common/generated_hexagon_controller/src_impl/  hexagon_controller.c:74: undefined reference to `inception_dummy_int_data_224x224'
 /home/zaheer.s/Qualcomm/Hexagon_SDK/3.1/examples/common/generated_hexagon_controller/src_impl/  hexagon_controller.c:74: undefined reference to `inception_dummy_int_data_224x224'
 collect2: error: ld returned 1 exit status
 make[1]: *** [android_Debug_aarch64/libhexagon_controller.so] Error 1
 ERROR making .

I am not sure if any work around is provided to fix the missing files causing build error. please suggest a fix.

PS:- I am able to run sample examples provided with ${QUALCOMM_SDK} /examples/common/gemm.
"
9427,Resource Exhausted and Initialization Errors on gpu,"Hello,
I have been facing a resource exhausted error on my gpu for a couple of days and can't seem to figure out how to fix it.
So, i have been training custom made conv net on a kaggle dataset for facial recognition with the 53% accuracy..it currently has four convolutional + maxpooling layers followed by 2 fully connected layers
My convolutional layers currently have a stride of (2,2) but since that results in loss of information i wanted to reduce the strides to (1,1). This is a snippet of the various error i'm facing 

Training on the data
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1021     try:
-> 1022       return fn(*args)
   1023     except errors.OpError as e:

/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1003                                  feed_dict, fetch_list, target_list,
-> 1004                                  status, run_metadata)
   1005 

/home/carnd/anaconda3/envs/dl/lib/python3.5/contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()
    468           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 469           pywrap_tensorflow.TF_GetCode(status))
    470   finally:

InternalError: Dst tensor is not initialized.
	 [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2304,1152] values: [0 0 0]...>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

During handling of the above exception, another exception occurred:

InternalError                             Traceback (most recent call last)
<ipython-input-37-ab81f6da0f51> in <module>()
      2 print(""Training on the data"")
      3 with tf.Session() as sess:
----> 4     sess.run(tf.global_variables_initializer())
      5 
      6     for epoch in range(epochs):

/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    765     try:
    766       result = self._run(None, fetches, feed_dict, options_ptr,
--> 767                          run_metadata_ptr)
    768       if run_metadata:
    769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
    963     if final_fetches or final_targets:
    964       results = self._do_run(handle, final_targets, final_fetches,
--> 965                              feed_dict_string, options, run_metadata)
    966     else:
    967       results = []

/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1013     if handle is None:
   1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1015                            target_list, options, run_metadata)
   1016     else:
   1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1033         except KeyError:
   1034           pass
-> 1035       raise type(e)(node_def, op, message)
   1036 
   1037   def _extend_graph(self):

InternalError: Dst tensor is not initialized.
	 [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2304,1152] values: [0 0 0]...>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

Caused by op 'zeros_28', defined at:
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py"", line 184, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2821, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-34-12683d1a5f6b>"", line 47, in <module>
    optimizer = tf.train.AdamOptimizer().minimize(cost)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 298, in minimize
    name=name)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 412, in apply_gradients
    self._create_slots(var_list)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/adam.py"", line 119, in _create_slots
    self._zeros_slot(v, ""m"", self._name)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 656, in _zeros_slot
    named_slots[var] = slot_creator.create_zeros_slot(var, op_name)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py"", line 121, in create_zeros_slot
    val = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1370, in zeros
    output = constant(zero, shape=shape, dtype=dtype, name=name)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 169, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Dst tensor is not initialized.
	 [[Node: zeros_28 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [2304,1152] values: [0 0 0]...>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

### The error faced in the previous training run of the network was a resource exhausted error which i have commented on in another issue
https://github.com/tensorflow/tensorflow/issues/9400#issuecomment-296718808

I am using  a g2.2x large ec2 instance on aws amazon with a 32gb storage volume

Here is a link to the original unbroken code 
https://github.com/vijpandaturtle/facial-expressions
And here is the dataset of 48x48 pixel images(around 35000 images)
https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge
Thanks"
9424,[minor bug] tf1.0+ compatibility script doesn't handle old batch_matmul arguments,"tf 1.0 merges `batch_matmul` into `matmul`, but the compatibility script forgot to rename the arguments for `batch_matmul`

what is needed is: 
`adj_x` --> `transpose_a`
`adj_y` --> `transpose_b`

I would be happy to write a quick PR.

References:

https://www.tensorflow.org/versions/r0.12/api_docs/python/

https://www.tensorflow.org/api_docs/python/tf/matmul"
9423,Feature Request : Gradients for tf.contrib.image.rotate(),"I wish to propagate gradients through image rotation. This is currently not supported:

```
import tensorflow as tf
import numpy as np

images = tf.zeros(shape=[5, 10, 10, 1])
angles = 2 * np.pi * np.random.random(5) - np.pi
out = tf.contrib.image.rotate(images, angles)
out_sum = tf.reduce_sum(out)
images_grad = tf.gradients(out_sum, [images])

print images_grad
```

gives

```[None]```"
9422,Enable use of cuDNN RNNs with optimizers other than GradientDescentOptimizer,"Currently cuDNN-based RNNs in TF are limited to GradientDescentOptimizer ([#6620](https://github.com/tensorflow/tensorflow/issues/6620)). This is a serious limitation given the widespread use of other optimizers. The claim that this cannot be supported in TF because cuDNN RNN don't have known shapes at static time seems overly pessimistic. Just like RNNParamsSaver provides a mechanism to convert between canonical shaped variables and the parameter buffer, a simple wrapper can be provided that does this automatically for cuDNN RNNs, so that the size of the parameter buffer is statically calculated and then used to define the variable, especially since the shape of the parameter buffer is just a 1D vector anyway."
9421,import tensorflow in python script using php,"I try to execute a python script using php , the python script requires importing tensorflow , when i run the php script this error occur : 

Training....string(1374) ""Traceback (most recent call last): File ""/opt/lampp/htdocs/gp/test.py"", line 1, in import tensorflow File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in from tensorflow.python import * File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 72, in raise ImportError(msg) ImportError: Traceback (most recent call last): File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 61, in from tensorflow.python import pywrap_tensorflow File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in _pywrap_tensorflow = swig_import_helper() File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description) ImportError: /opt/lampp/lib/libstdc++.so.6: version `GLIBCXX_3.4.19' not found (required by /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so) Failed to load the native TensorFlow runtime. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error for some common reasons and solutions. Include the entire stack trace above this error message when asking for help. """
9420,[Java] Distributed mode support,"### Describe the problem

Is there any plan to add distributed mode to the Java API? I checked the code and it seems to be doable (unless I missed something) so I was wondering if anyone is already working on it? I went through the issue tracker and PRs but couldn't find anything related."
9419,1080P image by SRGAN automatically killed,"When I use a small image for SRGAN training, it runs well, but when I use a 1080P image for generation, the process killed without any related log. The batch is 8 so I don't think it will run out all my GPU memory, also there's no fully connection layer in my SRGAN

gpu device: GTX 1060 6G
tf version: 1.0.0
python version: 2.7

if my code is required, pleasure to provide it"
9417,Faild to build a pip package for TensorFlow with GPU,"TF master - 24/2/2017

When I build a pip package for TensorFlow with GPU support by invoke the following command:
$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package


I see following error;

ERROR: /root/tensorflow/tensorflow/contrib/verbs/BUILD:61:1: C++ compilation of rule '//tensorflow/contrib/verbs:grpc_verbs_service' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 151 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.                                                   
In file included from ./tensorflow/contrib/verbs/grpc_verbs_service.h:25:0,                                       
                 from tensorflow/contrib/verbs/grpc_verbs_service.cc:22:                                          
./tensorflow/core/distributed_runtime/rpc/grpc_call.h:74:28: error: 'core' has not been declared                  
 class UntypedCall : public core::RefCounted {                                                                    
                            ^                                                                                     
./tensorflow/core/distributed_runtime/rpc/grpc_call.h:74:34: error: expected '{' before 'RefCounted'              
 class UntypedCall : public core::RefCounted {                                                                    
                                  ^                                                                               
./tensorflow/core/distributed_runtime/rpc/grpc_call.h:75:2: error: expected primary-expression before 'public'    
  public:                                                                                                         
  ^                                                                                                               
./tensorflow/core/distributed_runtime/rpc/grpc_call.h:75:2: error: expected '}' before 'public'"
9416,Android Demo: Rotation on some devices broken.,"### System information
- **Android**:
- **TensorFlow installed from source**:
- **TensorFlow version 1.0.0**:
N/A

### Describe the problem
The Android Demo code seems to be a bit buggy on our Pixel C. I wanted to confirm that this isn't an issue with the TF code but it's a strange one.

The Rotation in the demo apps on our Pixel C didn't seem to work correctly. It would give the value of 3 when it should have read 90. This meant that the input was basically on it's side. I found that for it to work that this line needed to be set to 0.

```sensorOrientation = rotation + screenOrientation;``` needed to be
```sensorOrientation = 0;```
However, when used in landscape mode this didn't crop around the centre of the preview image but instead it created a square from the left edge.

```
|------------------| ---------|                         
|                  |          |
|       CROP       |          |
|     SQUARE       |          |
|__________________|__________|
```
When set to 0.
The solution seemed to be to set the Orientation to 360.  

```
|-----|------------------|----|                         
|     |                  |    |
|     |        CROP      |    |
|     |      SQUARE      |    |
|_____|__________________|____|
```
When set to 360.

At the time (a couple of weeks ago) I recalled that it forced some code to run that would centre it as required for some other operations however going through the code to find it I can't. I think it was related to this but it doesn't make sense as to why 360 solved the issue.
```
private void configureTransform(final int viewWidth, final int viewHeight) {
    final Activity activity = getActivity();
    if (null == textureView || null == previewSize || null == activity) {
      return;
    }
    final int rotation = activity.getWindowManager().getDefaultDisplay().getRotation();
    final Matrix matrix = new Matrix();
    final RectF viewRect = new RectF(0, 0, viewWidth, viewHeight);
    final RectF bufferRect = new RectF(0, 0, previewSize.getHeight(), previewSize.getWidth());
    final float centerX = viewRect.centerX();
    final float centerY = viewRect.centerY();
    if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {
      bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY());
      matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL);
      final float scale =
          Math.max(
              (float) viewHeight / previewSize.getHeight(),
              (float) viewWidth / previewSize.getWidth());
      matrix.postScale(scale, scale, centerX, centerY);
      matrix.postRotate(90 * (rotation - 2), centerX, centerY);
    } else if (Surface.ROTATION_180 == rotation) {
      matrix.postRotate(180, centerX, centerY);
    }
    textureView.setTransform(matrix);
  }
```

So I guess the question is that is this happening due to some strange hardware bug with the Pixel C or some coding error. I'm leaning towards the former as this is too bizarre to be caused by code but thought i'd open the discussion out as others trying to run the app in landscape may face similar issues."
9415,"XLA ""resnet 50"" style example crash during graph building","Note: The test code below was cobbled together from various un-credited sources.

The example crashes, during the building of the reduce_mean.   It fails with quite a large stack, maybe some sort of stack overflow?  Without the last two 'block's (marked with #*****) the compilation succeeds.

Perhaps it is as simple as it failing on my laptop (OS/X, 16GB RAM).


```
import tensorflow as tf
import numpy as np

def _get_variable(name, shape, initializer, dtype=tf.float32):

  return tf.get_variable(name,
                         shape=shape,
                         initializer=initializer,
                         dtype=dtype)
def inference(x):

  with tf.variable_scope('scale1', use_resource=True):
    x = conv(x, 7, 2, 64)
    x = tf.nn.relu(x)

  with tf.variable_scope('max_pool', use_resource=True):
    x = max_pool(x, ksize=3, stride=2)

  with tf.variable_scope('scale2-1', use_resource=True):
    x = block(x, 1, 64, 256)

  with tf.variable_scope('scale2-2', use_resource=True):
    x = block(x, 1, 64, 256)

  with tf.variable_scope('scale2-3', use_resource=True):
    x = block(x, 1, 64, 256)



  with tf.variable_scope('scale3-1', use_resource=True):
    x = block(x, 2, 128, 512)

  with tf.variable_scope('scale3-2', use_resource=True):
    x = block(x, 1, 128, 512)

  with tf.variable_scope('scale3-3', use_resource=True):
    x = block(x, 1, 128, 512)

  with tf.variable_scope('scale3-4', use_resource=True):
    x = block(x, 1, 128, 512)



  with tf.variable_scope('scale4-1', use_resource=True):
    x = block(x, 2, 256, 1024)

  with tf.variable_scope('scale4-2', use_resource=True):
    x = block(x, 1, 256, 1024)

  with tf.variable_scope('scale4-3', use_resource=True):
    x = block(x, 1, 256, 1024)

  with tf.variable_scope('scale4-4', use_resource=True):
    x = block(x, 1, 256, 1024)

  with tf.variable_scope('scale4-5', use_resource=True):
    x = block(x, 1, 256, 1024)

  with tf.variable_scope('scale4-6', use_resource=True):
    x = block(x, 1, 256, 1024)



  with tf.variable_scope('scale5-1', use_resource=True):
    x = block(x, 2, 512, 2048)

  with tf.variable_scope('scale5-2', use_resource=True):  #*****
    x = block(x, 1, 512, 2048)

  with tf.variable_scope('scale5-3', use_resource=True): #*****
    x = block(x, 1, 512, 2048)

  x = tf.reduce_mean(x, reduction_indices=[1, 2])

  with tf.variable_scope('fc', use_resource=True):
    x = fc(x, 1000)

  return x


def block(x, first_stride, internal_filters, final_filters):
  shape_in = x.get_shape()

  shortcut = x

  with tf.variable_scope('a', use_resource=True):
    x = conv(x, 1, first_stride, internal_filters)
    x = tf.nn.relu(x)

  with tf.variable_scope('b', use_resource=True):
    x = conv(x, 3, 1, internal_filters)
    x = tf.nn.relu(x)

  with tf.variable_scope('c', use_resource=True):
    x = conv(x, 1, 1, final_filters)

  with tf.variable_scope('shortcut', use_resource=True):
    pad = int(x.get_shape()[-1] - shape_in[-1])
    kernel = np.reshape(np.concatenate((np.identity(shape_in[-1], dtype=np.float32),
                                        np.zeros([pad, shape_in[-1]]))),
                        [1, 1, shape_in[-1], final_filters])

    shortcut = tf.nn.conv2d(shortcut,
                            kernel,
                            [1,first_stride,first_stride,1],
                            padding='SAME')

  return tf.nn.relu(x + shortcut)


def fc(x, num_units_out):
  num_units_in = x.get_shape()[1]
  weights_initializer = tf.truncated_normal_initializer(stddev=0.01)

  weights = _get_variable('weights', shape=[num_units_in, num_units_out],
                          initializer=weights_initializer)
  biases = _get_variable('biases', shape=[num_units_out],
                         initializer=tf.constant_initializer(0.0))

  x = tf.nn.xw_plus_b(x, weights, biases)

  return x

def conv(x, ksize, stride, filters_out):

  filters_in = x.get_shape()[-1]
  shape = [ksize, ksize, filters_in, filters_out]
  initializer = tf.truncated_normal_initializer(stddev=0.1)

  weights = _get_variable('weights', shape=shape, initializer=initializer)
  return tf.nn.conv2d(x,
                      weights,
                      [1, stride, stride, 1],
                      padding='SAME')


def max_pool(x, ksize=3, stride=2):
  return tf.nn.max_pool(x,
                        ksize=[1, ksize, ksize, 1],
                        strides=[1, stride, stride, 1],
                        padding='SAME')


#
# Main code
#

with tf.device(""/job:localhost/replica:0/task:0/device:XLA_CPU:0""):
  # Inputs
  x = tf.placeholder(tf.float32, shape=[2, 224, 224, 4])

  # Inference
  logits = inference(x)

sess = tf.InteractiveSession()

sess.run(tf.global_variables_initializer())

training_data = np.zeros([2, 224, 224, 4]);

sess.run(logits, feed_dict={x: training_data})

sess.close()

```"
9414,CNN pip installed error E tensorflow/stream_executor/cuda/cuda_dnn.cc:352],"MacOS pip installed tensorflow 
Only cnn triggered this error 
```
2017-04-24 04:14:57.699073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-04-24 04:14:57.699094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-04-24 04:14:57.701039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 650M, pci bus id: 0000:01:00.0)
2017-04-24 04:15:04.233947: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Loaded runtime CuDNN library: 5005 (compatibility version 5000) but source was compiled with 5105 (compatibility version 5100).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
2017-04-24 04:15:04.234420: F tensorflow/core/kernels/conv_ops.cc:659] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 
Abort trap: 6
```
```
Name: tensorflow-gpu
Version: 1.1.0
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /Users/andrey/tf/lib/python3.6/site-packages
Requires: wheel, protobuf, six, numpy, werkzeug
```
CUDA Driver Version: 8.0.81
GPU Driver Version: 10.16.34 355.10.05.35f05

```
Device 0: ""GeForce GT 650M""
  CUDA Driver Version / Runtime Version          8.0 / 8.0
  CUDA Capability Major/Minor version number:    3.0
  Total amount of global memory:                 1024 MBytes (1073414144 bytes)
  ( 2) Multiprocessors, (192) CUDA Cores/MP:     384 CUDA Cores
  GPU Max Clock rate:                            900 MHz (0.90 GHz)
  Memory Clock rate:                             2508 Mhz
  Memory Bus Width:                              128-bit
  L2 Cache Size:                                 262144 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0
  Compute Mode:
     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 8.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GT 650M
```
"
9413,Android ops - not supporting NCHW data format,"Hi,

I'm using my custom tensorflow v1.0.1 model freezed and exported to Android arm-ABI-v7a (I compiled tensorflow 1.0.1 with selective registration for the models ops).

As a training time optimization we tried to convert the data format to NCHW format (as written in the tensorflow performance tutorial).

But now, when I run inference on Android, I get the following error in the logcat:

 E/native: tensorflow_inference_jni.cc:233 Error during inference: Invalid argument: CPU BiasOp only supports NHWC. [[Node: conv_layer_1/BiasAdd = BiasAdd[T=DT_FLOAT, data_format=""NCHW"", _device=""/job:localhost/replica:0/task:0/cpu:0""](conv_layer_1/conv_l11, bc11_init)]]


Are you going to add NCHW support for android CPU ops in the future versions?

Thanks,
Eran


### System information
- **Have I written custom code: Yes - custom model*:
- **OS Linux Ubuntu 16.04:
- **TensorFlow installed from source:
- **TensorFlow version 1.0.1:
- **Bazel version 0.4.5*:
- **CUDA/cuDNN version 5.1.10:
- **GPU model and memory GTX 1080 TI:

"
9412,Android Demo DetectorActivity landscape orientation problem,"I'm trying to change the orientation to landscape:

`private static final Size DESIRED_PREVIEW_SIZE = new Size(1280, 720);`
`private static final boolean USE_YOLO = true`

```
        <activity android:name=""org.tensorflow.demo.DetectorActivity""
                  android:screenOrientation=""landscape""
                  android:label=""@string/activity_name_detection"">
            <intent-filter>
                <action android:name=""android.intent.action.MAIN"" />
                <category android:name=""android.intent.category.LAUNCHER"" />
            </intent-filter>
        </activity>
```

But it draws detected rects wrongly.
How to fix it?

"
9411,Cifar10 Tutorial Link to Example Code 404's,"Following any of the links to the code for the CIFAR10 tutorial 404's.

Example link: https://www.tensorflow.org/versions/master/tutorials/deep_cnn#code_organization

Any from above."
9410,Error Building from Source with CUDA 7.5 in docker.,"Please go to Stack Overflow for help and support.
http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues.
We want to focus on work that benefits the whole community, e.g., fixing
bugs and adding features. Support only helps individuals. GitHub also notifies
thousands of people when issues are filed. We want them to see you communicating
an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I cloned r1.1 branch, and tried either leave repo as-is or modify `WORKSPACE.bzl` . Both comes out same error. 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:r1.1
- **Bazel version (if compiling from source)**:0.4.5, compiled from sorce 
- **CUDA/cuDNN version**:CUDA 7.5.17 & cuDNNv5 (using nvidia/cuda:7.5-cudnn5-devel-ubuntu14.04
- **GPU model and memory**:GPU is onls
 
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```

### Describe the problem
Error when running `tensorflow/tools/ci_build/builds/configured GPU  bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package
` .The error message is:

> ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/nccl_archive/BUILD:33:1: error while parsing .d file: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local_linux-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/all_reduce.cu.pic.d (No such file or directory). nvcc fatal : Unsupported gpu architecture 'compute_60'
Note that I compile it in docker and have no Nvidia Pascal GPU, after looing for help on [StackOverflow](http://stackoverflow.com/questions/43525148/error-building-tensorflow-docker-image-with-cuda-7-5), I think there would be some unsupported configs. So I tried to alternate nccl package url in ./tensorflow/workspace.bzl. But still the issue occurs. I think it might be a bug that tensorflow installer not support CUDA 7.5 well, or should I add any options for nvcc when building with  bazel.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached. Try to provide a reproducible test case that is the minimum
necessary to generate the problem.


"
9407,Usage of float64 with version >0.11,"### System information
- Tensorflow is used as a backend for Keras library with setup ""floatx"":""float64"", i.e. this is default float type
- OS X El Capitan operational system
- TensorFlow was installed via pip
- Tensorflow version 0.12.1
 
My custom loss function includes exponent and it gets overflowed very easily, that is why I have to use float64. But after updating TensorFlow from 0.11 to 0.12 (I needed tensorboard) I started to get error while creating the model, when convolutional layer is added.

Traceback of the error when I am adding a Conv layer to my model:
```
miniconda/lib/python2.7/site-packages/keras/models.pyc in add(self, layer)
    330                  output_shapes=[self.outputs[0]._keras_shape])
    331         else:
--> 332             output_tensor = layer(self.outputs[0])
    333             if isinstance(output_tensor, list):
    334                 raise TypeError('All layers in a Sequential model '

miniconda/lib/python2.7/site-packages/keras/engine/topology.pyc in __call__(self, x, mask)
    570         if inbound_layers:
    571             # This will call layer.build() if necessary.
--> 572             self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
    573             # Outputs were already computed when calling self.add_inbound_node.
    574             outputs = self.inbound_nodes[-1].output_tensors

miniconda/lib/python2.7/site-packages/keras/engine/topology.pyc in add_inbound_node(self, inbound_layers, node_indices, tensor_indices)
    633         # creating the node automatically updates self.inbound_nodes
    634         # as well as outbound_nodes on inbound layers.
--> 635         Node.create_node(self, inbound_layers, node_indices, tensor_indices)
    636 
    637     def get_output_shape_for(self, input_shape):

miniconda/lib/python2.7/site-packages/keras/engine/topology.pyc in create_node(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)
    164 
    165         if len(input_tensors) == 1:
--> 166             output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
    167             output_masks = to_list(outbound_layer.compute_mask(input_tensors[0], input_masks[0]))
    168             # TODO: try to auto-infer shape

miniconda/lib/python2.7/site-packages/keras/layers/convolutional.pyc in call(self, x, mask)
    161         output = K.conv2d(x, self.W, strides=self.subsample,
    162                           border_mode=self.border_mode,
--> 163                           dim_ordering='tf')
    164         output = K.squeeze(output, 2)  # remove the dummy dimension
    165         if self.bias:

miniconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc in conv2d(x, kernel, strides, border_mode, dim_ordering, image_shape, filter_shape, filter_dilation)
   2689     if filter_dilation == (1, 1):
   2690         strides = (1,) + strides + (1,)
-> 2691         x = tf.nn.conv2d(x, kernel, strides, padding=padding)
   2692     else:
   2693         assert filter_dilation[0] == filter_dilation[1]

miniconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.pyc in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, name)
    394                                 strides=strides, padding=padding,
    395                                 use_cudnn_on_gpu=use_cudnn_on_gpu,
--> 396                                 data_format=data_format, name=name)
    397   return result
    398 

miniconda/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
    519                   ""%s type %s of argument '%s'."" %
    520                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,
--> 521                    inferred_from[input_arg.type_attr]))
    522 
    523           types = [values.dtype]

TypeError: Input 'filter' of 'Conv2D' Op has type float64 that does not match type float32 of argument 'input'.
```
As I understood, float64 is simply not supported as it is considered to be not needed to have that much of precision, but I need this format because of the numbers that are calculated.
Is there any solution to this problem?
"
9406,gather_nd gradient / scatter_nd is broken,"Test code:
```
import tensorflow as tf
session = tf.InteractiveSession()

n_base_time = 5
n_in = 7
n_beam = 3
n_batch = 1
base = tf.ones((n_base_time, n_batch, n_in))  # (base_time,batch,n_in)
idxs_exp = tf.constant(0, shape=(n_beam, n_batch, 2), name=""idxs_exp"")  # (beam,batch,2), where the 2 stands for (base_time,batch)
# Thus K == 2. gather_nd out will be idxs_exp.shape[:2] + params.shape[2:] = (beam,batch,n_in).
gathered = tf.gather_nd(base, idxs_exp)  # (beam,batch,n_in)
gathered_shape, _ = session.run([tf.shape(gathered), gathered])
assert list(gathered_shape) == [n_beam, n_batch, n_in]

base_grad = tf.gradients(gathered, base)
assert base_grad is not None
session.run(base_grad)
```

The first `session.run` as well as the assert-check for the `gathered_shape` works fine but then the second `session.run` for the gradient breaks with the exception:
```
InvalidArgumentError (see above for traceback): Must have updates.shape = indices.shape[:IXDIM] + params_shape[IXDIM:], got updates.shape [3,1,7], indices.shape [3,1,2], params_shape [5,1,7]
         [[Node: gradients/GatherNd_grad/ScatterNd = ScatterNd[T=DT_FLOAT, Tindices=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](idxs_exp, gradients/Fill/_39, gradients/GatherNd_grad/Shape)]]
```
This exception message is also confusing because what it complains about what is not the case seems to be actually the case.
"
9405,"testAvgPoolSamePadding fails on ppc64le. Attempting to root cause, have some info need some help","Please go to Stack Overflow for help and support.
http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues.
We want to focus on work that benefits the whole community, e.g., fixing
bugs and adding features. Support only helps individuals. GitHub also notifies
thousands of people when issues are filed. We want them to see you communicating
an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
  No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
  Ubuntu 16.04 ppc64le
- **TensorFlow installed from (source or binary)**:
  From source
- **TensorFlow version (use command below)**:
  'v1.0.1-0-ge895d5c-dirty'
- **Bazel version (if compiling from source)**:
  Build label: 0.4.4-2017-04-13 (@80a07b5)
- **CUDA/cuDNN version**:
  No GPU
- **GPU model and memory**:
  No GPU
- **Exact command to reproduce**:
  bazel test //tensorflow/compiler/tests:pooling_ops_test_cpu
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```

### Describe the problem
pooling_ops_test_cpu **fails on ppc64le**, the test failing is **testAvgPoolSamePadding**

I am making an attempt to root cause the issue, need some help with understanding the code flow (i am new to tensorflow code but interested/would-like-to debug & help :smile: )

First i tried to understand the input parameters being passed to the avg_pool function (this is after understanding what avg_pool does)

The input tensor for this test case is 
[[[1 2 3],[4 5 6],[7 8 9],[10 11 12],[13 14 15],[16 17 18]]]   (4-d tensor)

The test expects avg_pool o/p as [  7. ,   8. ,   9. ,  11.5,  12.5,  13.5] but gets [  7. ,   8. ,   9. ,  11.5,   9. ,  13.5] (4th entry is different)

Then i tried to trace the code to see why the entry differs (only for ppc64le, x86 the test passes)

Test case calls avg_pool in python/ops/nn_ops.py, which ultimately drops into core/kernels/avgpooling_op.cc. The AvgPoolingOp class ""compute"" func calls SpatialAvgPool which i tried to find/grep, could find it in core/kernels/eigen_pooling.h. 

This is where i am getting lost. I am suspecting an int overflow or sign type issue and my goal is to pinpoint the exact location where this could be happening, however seeing the code in avgpooling_op.cc (or eigen_pooling.h) i cant seem to find any good places where i can debug further
Any help or pointers where i can go from here (or if i am following the right trail) would help

Thanks!
Vaibhav


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached. Try to provide a reproducible test case that is the minimum
necessary to generate the problem.

Failure assertion snippet

exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
F.
======================================================================
FAIL: testAvgPoolSamePadding (__main__.PoolingTest)
----------------------------------------------------------------------
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/tests/pooling_ops_test_cpu.runfiles/org_tensorflow/tensorflow/compiler/tests/pooling_ops_test.py"", line 288, in testAvgPoolSamePadding
    expected=expected_output)
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/tests/pooling_ops_test_cpu.runfiles/org_tensorflow/tensorflow/compiler/tests/pooling_ops_test.py"", line 125, in _VerifyValues
    data_format, expected)
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/tests/pooling_ops_test_cpu.runfiles/org_tensorflow/tensorflow/compiler/tests/pooling_ops_test.py"", line 108, in _VerifyOneTest
    self.assertAllClose(expected, actual.flatten(), rtol=1e-5, atol=1e-6)
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/compiler/tests/pooling_ops_test_cpu.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 485, in assertAllClose
    np.testing.assert_allclose(a, b, rtol=rtol, atol=atol)
  File ""/usr/lib64/python2.7/site-packages/numpy/testing/utils.py"", line 1411, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/lib64/python2.7/site-packages/numpy/testing/utils.py"", line 796, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=1e-05, atol=1e-06

(mismatch 16.6666666667%)
 x: array([  7. ,   8. ,   9. ,  11.5,  12.5,  13.5])
 y: array([  7. ,   8. ,   9. ,  11.5,   9. ,  13.5], dtype=float32)

----------------------------------------------------------------------
Ran 2 tests in 0.514s
"
9402,tensorflow home page equation bug for section MNIST For ML Beginners,"for section 2 of Get Started, https://www.tensorflow.org/get_started/mnist/beginners, there is a statement error.

- **for screenshot 1, the equation is : wx + b**

![图片注释](http://odqb0lggi.bkt.clouddn.com/5480622df9f06c8e773366f4/5b83df08-28be-11e7-9a94-0242ac140004)Please go to Stack Overflow for help and support.
http://stackoverflow.com/questions/tagged/tensorflow

- **for screenshot 2, the equation is : xw + b**

![图片注释](http://odqb0lggi.bkt.clouddn.com/5480622df9f06c8e773366f4/838d76da-28be-11e7-9a94-0242ac140004)



"
9401,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use,"OS: Ubuntu 14.04
TF installed from source.
TF version: 1.1.0-rc

I want to reuse a RNNCell in two different variable scopes, which could simply  be like this:

```
import tensorflow as tf
from tensorflow.contrib import rnn

x = tf.placeholder(tf.int32, [128, 20])
embedding = tf.get_variable('embedding', [10000, 100])
cells = []
for _ in range(10):
    cell = rnn.BasicLSTMCell(100, state_is_tuple=True)
    cells.append(cell)
cell = rnn.MultiRNNCell(cells)
zero_state = cell.zero_state(128, tf.float32)

inputs = tf.nn.embedding_lookup(embedding, x)
with tf.variable_scope('rnn1'):
    _, state = tf.nn.dynamic_rnn(cell, inputs=inputs, initial_state=zero_state)
with tf.variable_scope('rnn2'):
    _, state = tf.nn.dynamic_rnn(cell, inputs=inputs, initial_state=zero_state)
```

But I got following error:

```
Traceback (most recent call last):
  File ""test.py"", line 18, in <module>
    _, state = tf.nn.dynamic_rnn(cell, inputs=inputs, initial_state=zero_state)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 582, in dynamic_rnn
    dtype=dtype)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 745, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2623, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2456, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2406, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 730, in _time_step
    (output, new_state) = call_cell()
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 716, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 968, in __call__
    cur_inp, new_state = cell(cur_inp, cur_state)
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 242, in __call__
    with _checked_scope(self, scope or ""basic_lstm_cell"", reuse=self._reuse):
  File ""/usr/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/home/swp/test/local/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 84, in _checked_scope
    type(cell).__name__))
ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fb1c0aa1e90> with a different variable scope than its first use.  First use of cell was with scope 'rnn1/rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn2/rnn/multi_rnn_cell/cell_0/basic_lstm_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)

```
I googled this issue and found that https://github.com/tensorflow/tensorflow/issues/8191 is similar but not identical. That issue was caused by new arg ""reuse"" of LSTMCell.
Strangely, when I use TF with version 1.0.1 builf from binary. the same code doesn't have this ValueError.

So, my questions is how to reuse a RNNCell within different variable scopes correctly in version 1.1.0-rc.
Thanks!"
9400,Tensorflow is still taking up all GPU memory despite allocation of memory,"**System Information:**
- OS Platform: Linux Ubuntu 16.04
- TensorFlow installed from binary
- TensorFlow version: 1.0.1
- CUDA version: 8.0
- cuDNN version: 5.1

output for print(tf.GIT_VERSION, tf.VERSION):
('v1.0.0-65-g4763edf-dirty', '1.0.1')

**Problem:**
I have three codes running GPU-enabled TensorFlow. Currently, when the GPU is allocated for two of the processes, the GPU does get allocated. However, no matter how much GPU I allocate to the last process, it takes up all the GPU, disallowing other two processes to run simultaneously. 

**First process (the one with problem)**
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1060
major: 6 minor: 1 memoryClockRate (GHz) 1.6705
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.68GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0)

**Second process:**
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1060
major: 6 minor: 1 memoryClockRate (GHz) 1.6705
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 237.00MiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 1.19G (1273049856 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 1.07G (1145744896 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 983.40M (1031170560 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 885.06M (928053504 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 796.55M (835248128 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 716.90M (751723264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 645.21M (676550912 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 580.69M (608896000 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 522.62M (548006400 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 470.36M (493205760 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 423.32M (443885312 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 380.99M (399496960 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 342.89M (359547392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 308.60M (323592704 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 277.74M (291233536 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 249.97M (262110208 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 224.97M (235899392 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
WARNING:apscheduler.scheduler:Execution of job ""session (trigger: interval[0:00:01], next run at: 2017-04-24 11:24:48.702309)"" skipped: maximum number of running instances reached (1)
E tensorflow/stream_executor/cuda/cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
E tensorflow/stream_executor/cuda/cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
F tensorflow/core/kernels/conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 

**The code I am using to allocate GPU for the first process:**
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))

I have also looked up stackoverflow but it does not seem to have the same problems raised.
Some pages I referred to:
http://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory 
https://www.tensorflow.org/tutorials/using_gpu 
https://github.com/tensorflow/tensorflow/issues/398 "
9399,Distributed Tensorflow model is no faster than standalone,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I have taken the [Resnet code](https://github.com/tensorflow/models/tree/master/resnet) from the Tensorflow model zoo and distributed it as according to https://www.tensorflow.org/deploy/distributed
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04.1 LTS
- **TensorFlow installed from (source or binary)**:
Official Tensorflow-GPU docker image
- **TensorFlow version (use command below)**:
('v1.0.0-2378-g2259213', '1.1.0-rc0')
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
Version 8
- **GPU model and memory**:
Tested on multiple setups within a cluster
4 machines with 2x Nvidia TitanX 12GB
1 machine with 2x GeForce GTX 1080 8GB
- **Exact command to reproduce**:
The commands differ slightly between machines depending on cluster configuration, but for 1 PS and 2 workers it looks like this:

`CUDA_VISIBLE_DEVICES="""" python resnet_main.py --dataset=""cifar10"" --train_data_path=""/notebooks/cifar_data/data_batch*"" --train_dir=""/notebooks/tmp/resnet_model/train"" --log_root=""/notebooks/tmp/resnet_model"" --job_name=""ps"" --task_index=0 --eval_data_path=""/notebooks/cifar_data/test_batch.bin"" --eval_dir=""/notebooks/tmp/resnet_model/test""`

`CUDA_VISIBLE_DEVICES=0 python resnet_main.py --dataset=""cifar10"" --train_data_path=""/notebooks/cifar_data/data_batch*"" --train_dir=""/notebooks/tmp/resnet_model/train"" --log_root=""/notebooks/tmp/resnet_model"" --job_name=""worker"" --task_index=0 --eval_data_path=""/notebooks/cifar_data/test_batch.bin"" --eval_dir=""/notebooks/tmp/resnet_model/test""`

`CUDA_VISIBLE_DEVICES=0 python resnet_main.py --dataset=""cifar10"" --train_data_path=""/notebooks/cifar_data/data_batch*"" --train_dir=""/notebooks/tmp/resnet_model/train"" --log_root=""/notebooks/tmp/resnet_model"" --job_name=""worker"" --task_index=1 --eval_data_path=""/notebooks/cifar_data/test_batch.bin"" --eval_dir=""/notebooks/tmp/resnet_model/test""`


### Describe the problem
When running the Resnet model on CIFAR10 from the tf zoo in a distributed environment (asynchronous, between-graph replication), there is no performance gain. 

Running Resnet 110 on a single (non-distributed) machine, single GPU resulted in approximately 3 iterations per second. This is considered the baseline for any tests on the following configurations - all of which resulted in approximately the same number of iterations per second irrespective of configuration.
_Note: in all cases, each worker has their own dedicated GPU_
1. 1 PS, 2 workers on one machine
2. 1 PS with dedicated GPU & 1 worker on one machine, 1 worker on another machine
3. 1 PS & 2 workers on one machine, 2 workers on another machine
4. 1 PS & 2 workers on one machine, 3 more machines with 2 workers each
5. 4 machines with 2 workers each, two of these with 1 PS each
6. 4 machines, each with 1 PS & 2 workers

When starting up the workers, each would begin training as soon as it's ready, printing information to the terminal during/after each iteration. The difference is speed is visually noticeable - when there is only 1 worker running, it's as fast as I would expect. As more workers spin up, all of the existing workers slow down. In this way, I can see (with 8 terminals on my screen) the entire cluster slowing as more workers begin.

I monitored system stats during training to rule things out as the bottleneck and found the following for each machine:
- CPU usage: CPU usage is not at 100% for any machine
- GPU usage: GPU usage repeatedly flickers between 0% and ~80% - once per iteration
- Network usage: Network bandwidth in/out for any given machine is never more than ~80% of its capacity. the network speed is limited to 1Gbps, and it doesn't reach this cap. We raised the limit to 2Gbps and saw no increased usage or performance.
- HDD usage: Batches are loaded from disk multi-threaded. I printed to the screen during file-access and it's practically instantaneous.

For the input pipeline, I have also tried switching between `tf.RandomShuffleQueue` and `tf.train.shuffle_batch` and playing with the number of threads/min after deque etc for each of these batching methods to no avail.

### Source code / logs
Source code files attached below - `cifar_input.py` has small modifications from the original input pipeline. The original cifar input code is the file `cifar_input_orig.py`

[resnet_distrib.zip](https://github.com/tensorflow/tensorflow/files/950254/resnet_distrib.zip)



**Thank you in advance for any light you may be able to shed on this!**
"
9398,Tf.gradients returning all zeroes when called on result of a tf.gradient call,"I have the following code snippet:

interpolates = alpha*real_data + ((1-alpha)*fake_data)
disc_interpolates = Discriminator(interpolates)
gradients = tf.gradients(disc_interpolates, [interpolates])[0]
second_grad = tf.gradients(gradients[0], [interpolates])[0]

Where Discriminator corresponds to a neural network. The first call to tf.gradients is working correctly and I get back non-zero slope values in the gradients variable. However whenever I try to find the second derivative by applying tf.gradients to the gradients variable, my result is always a vector of zeroes. 

Is this expected behavior or should I be able to find the second derivatives of my neural net? "
9397,hi  tensorflow,"Please go to Stack Overflow for help and support.
http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues.
We want to focus on work that benefits the whole community, e.g., fixing
bugs and adding features. Support only helps individuals. GitHub also notifies
thousands of people when issues are filed. We want them to see you communicating
an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```

### Describe the problem

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached. Try to provide a reproducible test case that is the minimum
necessary to generate the problem.
"
9394,Max_pool with dynamic ksize,"I have the following code for a convolutional layer. This layer is part a larger computational graph.

```
# Define the shape of the filter
filter_shape = [1,
                config.char_filter_size,
                config.dim_char,
                config.dim_char]

# Define the convolutional layer weights and biases
W_conv = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1),
                     name=""W_conv"")
b_conv = tf.Variable(tf.constant(0.1, shape=[config.dim_char]),
                     name=""b_conv"")
# Do 2d convolution
conv = tf.nn.conv2d(char_embeddings,
                    W_conv,
                    strides=[1, 1, 1, 1],
                    padding=""VALID"",
                    name=""conv"")
# Apply nonlinearity
# h_conv has the same shape as conv
h_conv = tf.nn.relu(tf.nn.bias_add(conv, b_conv),
                    name=""conv_relu"")
# Maxpooling h_conv over dim 2 (char dim)

# ERROR HERE
conv_pooled = tf.nn.max_pool(h_conv,
                             ksize=[1, 1, tf.shape(h_conv)[-2], 1],
                             strides=[1, 1, 1, 1],
                             padding='VALID',
                             name=""conv_max_pool"")
```

When trying to run, I get the error:

> TypeError: Expected int for argument 'ksize' not tf.Tensor shape=() dtype=int32.

is tf.nn.max_pool unable to handle dynamic ksize?"
9392,Build of tensor flow r1.1 w/ Google Cloud option enabled fails: incompatible C++ header and code,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:   OS X 10.10.3 (14D2134)
- **TensorFlow installed from (source or binary)**:  github clone / source (r1.1)
- **TensorFlow version (use command below)**: r1.1
- **Bazel version (if compiling from source)**: 0.4.5-homebrew
- **CUDA/cuDNN version**:  N/A (not built with CUDA)
- **GPU model and memory**: N/A (not built with CUDA)
- **Exact command to reproduce**:  
1. configure build for CPU and with google cloud enabled,  
2. bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
Build of tensor flow for CPU / google cloud enabled fails for r1.1 (and also master),

1. configure build for CPU and with google cloud enabled,  
2. bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Source code / logs
ERROR: /Users/jshore/src/tensorflow/tensorflow/core/platform/cloud/BUILD:115:1: C++ compilation of rule '//tensorflow/core/platform/cloud:retrying_utils' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 93 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/core/platform/cloud/retrying_utils.cc:97:9: error: return type 'const tensorflow::Status' must match previous return type 'tensorflow::Status' when lambda expression has unspecified explicit return type
        return status;
"
9391,"Is it possible to remove the ""third_party directory""?! [An attempt to package for Ubuntu]","Hi guys,

We have successfully used C/C++ API as shared library in our applications, but there are some issues [like this one](https://github.com/cjweeks/tensorflow-cmake/issues/13) which my colleages ran into.
Simultaneously, I was working to distribute the whole work as a debian package for Ubuntu 16.04, and I found that it is very annoying that you have used many external dependencies under the ""third_party"" directory. I'm trying to remove these dependencies one by one, which is a little bit troublesome but I think is possible. I am packaging anything else needed on my way.

The question is, do you have any advise on this? What should have been taken care of? And why in first place you put these in your repo instead of leading the users to install specific versions on their system as build dependency? I think that having external header files under the directory after build does not make sense at all! Please lighten me up.

Thanks for your great work, Google and The Community!
"
9387,Wrong implementation of ResNet in tensorflow/tensorflow/contrib/slim/python/slim/nets/ ?,"I'm a researcher working on models related to ResNet_v1. As I was trying to use the code in this reporsitory: tensorflow/tensorflow/contrib/slim/python/slim/nets/
I realized that the ResNet_v1 model is different from Kaiming He's implementation. Specifically, in Kaiming's implementation, he applied stride 2 at the START of each block and the stride is applied to the 1*1 conv layer. For example, in Kaiming's original caffe prototxt (https://github.com/KaimingHe/deep-residual-networks/blob/master/prototxt/ResNet-101-deploy.prototxt), this is the first layer of 'conv3' (named in his ResNet paper) or block 2 (named by your implementation):

```
layer {
	bottom: ""res2c""
	top: ""res3a_branch1""
	name: ""res3a_branch1""
	type: ""Convolution""
	convolution_param {
		num_output: 512
		kernel_size: 1
		pad: 0
		stride: 2
		bias_term: false
	}
}
```

This layer is a 1*1 conv layer that mimics the 'skip-connection' because of dimension mismatch at the bottleneck between blocks. And so does 'res3a_branch2a', which is the start of the first residual module in 'conv3'.

Instead, in the tensorflow implementation, the stride 2 is applied to the END of each block(see function **resnet_v1_block()** in resnet_v1.py) and the stride is applied to the 3*3 conv layer of the last Residual module in each block(see function **bottleneck()** in resnet_v1.py). 

It's obvious that these two are different. Can anybody explain if it is wrong or implemented as such for some reasons?"
9383,Issue with latest Cuda Install for Windows,Took a little digging but the new DLL from Nvidia is called cudnn64_6.dll; the latest build of TensorFlow requires that to be cudnn64_5.dll. Crashes importing TensorFlow until this is renamed.
9382,"Tensorboard not (correctly) displaying histograms; unreliably displaying graphs (V1.1rc2,win7,chrome57)","When I went from tensorflow V1.0 to V1.1rc2, histograms stopped working correctly: the data isn't drawn unless that trace is highlighted via mouseover, and even then it's not using the right plot boundaries:
![image](https://cloud.githubusercontent.com/assets/8495647/25305145/f3be2926-2743-11e7-8ed1-589d4b17452e.png)
is an example (cursor is not displayed but is at the dot in top left of graph; otherwise graph is blank) generated from this code:
```
import tensorflow as tf
import numpy as np

xx = tf.Variable(tf.random_normal([4,4], dtype=np.float32),dtype=tf.float32)
yy = tf.Variable(np.eye(4, dtype=np.float32), dtype=tf.float32)
zz = tf.matmul(xx, yy)
save_location = 'g:\\tmp\\lstm3\\dbg\\dbg'
tf.summary.histogram('tensorboard_no_like', zz)
merged = tf.summary.merge_all()
sess = tf.InteractiveSession()
train_writer = tf.summary.FileWriter(save_location, sess.graph)
sess.run(tf.global_variables_initializer())
sess.run(tf.local_variables_initializer())
qwert = zz.eval()
m = sess.run(merged)
train_writer.add_summary(m)

```
I haven't tried this toy repro with v1.0, but other models that I've done in 1.0 and 1.1rc2 exhibit the same behavior. The distributions look fine, and scalars also display fine.

Another problem that's new to me between 1.0 and 1.1rc2 is that graphs sometimes display fine, sometimes are blank until I reload browser page a few times. (Apologies if this should have been a separate issue; wanted to keep spam volume down). I don't have a strong idea of what triggers this, but the frequency is pretty high, roughly half the time.

the console running tensorboard emits the following warning periodically, the timing of which I haven't correlated with either problem mentioned above:

> WARNING:tensorflow:path ../external\data/plugin/text/runs not found, sending 404

### System Information
- using custom code, copied above
- Windows 7 64 bit, fully patched
- tensorflow 1.1rc2 downloaded from https://pypi.python.org/packages/0d/cb/25f2cdd8905070373945c1f57edbe9d5f51a4482aa7097e5613cbdc4a41f/tensorflow_gpu-1.1.0rc2-cp35-cp35m-win_amd64.whl#md5=80ccd71614b438ffe8af3cd0dd572d3b and installed via pip
- CUDA 8.0 CUDNN 5.1
- GTX 1080 ti, 11gb ram
- generate histogram's data (eg, with code above), start tensorboard, (fail to) view histogram; view graph, experience intermittent success
"
9381,Mac Gpu Link not working?,"Hello,

I was trying to install Tensorflow for Mac GPU Python 3 one from github and I found that it is a broken URL Giving me an HTTP 404 Error.

The URL is - `https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-mac-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-mac/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-1.1.0rc2-py3-none-any.whl`

Please Fix the Url.


Best,
Daksh"
9379,[C++] xthread:  0xC0000005: Access violation reading location 0xFFFFFFFFFFFFFFFF,"I want to read frozen graph from file.
So I have class A:

```
class A
{
     std::shared_ptr<B> b_ptr;
public:
     A()
     {
         b_ptr.reset(new B());
     }
};
```

class B:

```//include tensorflow
using namespace tensorflow;
class B
{
     SessionOptions _sessionOptions;
     std::unique_ptr<Session> _session;
     GraphDef _graph;
     std::shared_ptr<std::thread> _thread;
public:
     B()
     {
         graph::SetDefaultDevice(""/cpu:0"", &_graph);
         ConfigProto& config = _sessionOptions.config;
	 config.set_intra_op_parallelism_threads(1);
	 _session.reset(NewSession(_sessionOptions));
         ReadBinaryProto(Env::Default(), ""path/to/graph"", &_graph);
	 _session->Create(_graph);
         _thread.reset(new std::thread(&B::Task, this));
     }
     void Task();
}
```

And I have the problem mentioned above when I read frozen graph with ReadBinaryProto  ~~I create session~~. If I comment a line _thread.reset(new std::thread(&B::Task, this)), this code will return successfully. If I comment all the code refered with tensorflow it will return successfully too."
9378,gcc failed: error executing command,"`$ bazel build tensorflow/tools/graph_transforms:transform_graph:`

```
ERROR: /home/osboxes/tensorflow/tensorflow/core/kernels/BUILD:2083:1: C++ compilation of rule '//tensorflow/core/kernels:svd_op' failed: gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 115 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-6/README.Bugs> for instructions.
Slow read: a 607144-byte read from /home/osboxes/.cache/bazel/_bazel_osboxes/a2c72928f8ca1d272e54d2254eb1b173/execroot/tensorflow/bazel-out/local-py3-opt/bin/tensorflow/core/kernels/_objs/strided_slice_op/tensorflow/core/kernels/strided_slice_op.o took 96724ms.
Target //tensorflow/tools/graph_transforms:transform_graph failed to build
Use --verbose_failures to see the command lines of failed build steps.

```

[gccFailed.txt](https://github.com/tensorflow/tensorflow/files/948805/gccFailed.txt)

Ubuntu 17.04"
9377,grpc error in distributed tensorlfow ,"pciBusID 0000:04:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0)
**# E0422 12:13:21.315971987   26528 tcp_server_posix.c:148]     check for SO_REUSEPORT: {""created"":""@1492834401.315943300"",""description"":""OS Error"",""errno"":92,""file"":""external/grpc/src/core/lib/iomgr/socket_utils_common_posix.c"",""file_line"":181,""os_error"":""Protocol not available"",""syscall"":""setsockopt(SO_REUSEPORT)""}**
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:200] Initialize GrpcChannelCache for job ps -> {0 -> localhost:8865}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:200] Initialize GrpcChannelCache for job worker -> {0 -> localhost:8866}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:221] Started server with target: grpc://localhost:8865

I try distributed tensorflow and start only one server and one worker, the model does not converge as the local version."
9375,"Bug in the situation of multiple ps servers, NotFoundError","I have 2 ps servers and 3 worker servers (Ubuntu14.04, Python 3.5.3 and Tensorflow 1.0.1 with virtualenv). I am trying the demo based on https://www.tensorflow.org/deploy/distributed.

I got NotFoundError errors when I use 2 ps servers. (It can run well when I use 1 ps server. And It can run well with 2 ps server, when I use ""save_checkpoint_secs=None"" in MonitoredTrainingSession().)

-----------------------------------------------------------------------------------------
THE CODE:
..........
      # Build model...
      x_data = np.random.rand(100).astype(np.float32)
      y_data = x_data*0.1 + 0.3
      Weights = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
      biases = tf.Variable(tf.zeros([1]))
      y = Weights*x_data + biases
      loss = tf.reduce_mean(tf.square(y-y_data))
      global_step = tf.contrib.framework.get_or_create_global_step()
      train_op = tf.train.AdagradOptimizer(0.01).minimize(
          loss, global_step=global_step)
    # The StopAtStepHook handles stopping after running given steps.
    hooks=[tf.train.StopAtStepHook(last_step=50000)]

    # The MonitoredTrainingSession takes care of session initialization,
    # restoring from a checkpoint, saving to a checkpoint, and closing when done
    # or an error occurs.
    with tf.train.MonitoredTrainingSession(master=server.target,
                                           is_chief=(FLAGS.task_index == 0),
                                           checkpoint_dir=""./train_logs"",
                                           hooks=hooks) as mon_sess:
      while not mon_sess.should_stop():
..........

-----------------------------------------------------------------------------------------------
THE ERROR:
Error in worker server 0 (master): 
........
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:221] Started server                                                                                                              with target: grpc://localhost:22222
I tensorflow/core/distributed_runtime/master_session.cc:1012] Start master sessi                                                                                                             on f8c75e38e6e9419a with config:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.                                                                                                             py"", line 1022, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.                                                                                                             py"", line 1004, in _run_fn
    status, run_metadata)
  File ""/usr/local/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/error                                                                                                             s_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: ./train_logs/model.ckpt-0                                                                                                             _temp_0205a1571bdb4f9db000d0caf3139d5a/part-00000-of-00002.index
         [[Node: save/MergeV2Checkpoints = MergeV2Checkpoints[delete_old_dirs=tr                                                                                                             ue, _device=""/job:ps/replica:0/task:1/cpu:0""](save/MergeV2Checkpoints/checkpoint                                                                                                             _prefixes, _recv_save/Const_0_S63)]]
         [[Node: save/Identity_S65 = _Recv[client_terminated=false, recv_device=                                                                                                             ""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:ps/replica:0/task:1/cpu:                                                                                                             0"", send_device_incarnation=7747326126893392586, tensor_name=""edge_33_save/Ident                                                                                                             ity"", tensor_type=DT_STRING, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""0.1.py"", line 103, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/platform/app.py    
"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""0.1.py"", line 68, in main
    _, step, loss_v, weight, biase = mon_sess.run([train_op, global_step, loss,                                                                                                              Weights, biases])
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 462, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 786, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 744, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 899, in run
    run_metadata=run_metadata))
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/basic_                                                                                                             session_run_hooks.py"", line 355, in after_run
    self._save(global_step, run_context.session)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/basic_                                                                                                             session_run_hooks.py"", line 371, in _save
    self._get_saver().save(session, self._save_path, global_step=step)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.                                                                                                             py"", line 1363, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.                                                                                                             py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.                                                                                                             py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.                                                                                                             py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.                                                                                                             py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: ./train_logs/model.ckpt-0                                                                                                             _temp_0205a1571bdb4f9db000d0caf3139d5a/part-00000-of-00002.index
         [[Node: save/MergeV2Checkpoints = MergeV2Checkpoints[delete_old_dirs=tr                                                                                                             ue, _device=""/job:ps/replica:0/task:1/cpu:0""](save/MergeV2Checkpoints/checkpoint                                                                                                             _prefixes, _recv_save/Const_0_S63)]]
         [[Node: save/Identity_S65 = _Recv[client_terminated=false, recv_device=                                                                                                             ""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:ps/replica:0/task:1/cpu:                                                                                                             0"", send_device_incarnation=7747326126893392586, tensor_name=""edge_33_save/Ident                                                                                                             ity"", tensor_type=DT_STRING, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]

Caused by op 'save/MergeV2Checkpoints', defined at:
  File ""0.1.py"", line 103, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/platform/app.py                                                                                                             "", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""0.1.py"", line 62, in main
    hooks=hooks) as mon_sess:
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 315, in MonitoredTrainingSession
    return MonitoredSession(session_creator=session_creator, hooks=all_hooks)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 601, in __init__
    session_creator, hooks, should_recover=True)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 434, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 767, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 772, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 494, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             
red_session.py"", line 366, in create_session
    self._scaffold.finalize()
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 180, in finalize
    lambda: training_saver.Saver(sharded=True, allow_empty=True,
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 232, in get_or_default
    op = default_constructor()
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/monito                                                                                                             red_session.py"", line 181, in <lambda>
    write_version=saver_pb2.SaverDef.V2))
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.                                                                                                             py"", line 1040, in __init__
    self.build()
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.                                                                                                             py"", line 1070, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.                                                                                                             py"", line 669, in build
    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.                                                                                                             py"", line 356, in _AddShardedSaveOps
    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/training/saver.                                                                                                             py"", line 338, in _AddShardedSaveOpsForV2
    sharded_prefixes, checkpoint_prefix, delete_old_dirs=True)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.                                                                                                             py"", line 185, in merge_v2_checkpoints
    delete_old_dirs=delete_old_dirs, name=name)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/op_de                                                                                                             f_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.p                                                                                                             y"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.p                                                                                                             y"", line 1226, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): ./train_logs/model.ckpt-0_temp_0205a157                                                                                                             1bdb4f9db000d0caf3139d5a/part-00000-of-00002.index
         [[Node: save/MergeV2Checkpoints = MergeV2Checkpoints[delete_old_dirs=tr                                                                                                             ue, _device=""/job:ps/replica:0/task:1/cpu:0""](save/MergeV2Checkpoints/checkpoint                                                                                                             _prefixes, _recv_save/Const_0_S63)]]
         [[Node: save/Identity_S65 = _Recv[client_terminated=false, recv_device=                                                                                                             ""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:ps/replica:0/task:1/cpu:                                                                                                             0"", send_device_incarnation=7747326126893392586, tensor_name=""edge_33_save/Ident                                                                                                             ity"", tensor_type=DT_STRING, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]

Error in ps server 1:
........
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:221] Started server                                                                                                              with target: grpc://localhost:22222
W tensorflow/core/framework/op_kernel.cc:993] Not found: ./train_logs/model.ckpt                                                                                                             -0_temp_0205a1571bdb4f9db000d0caf3139d5a/part-00000-of-00002.index

"
9374,`tensorflow.python.client.device_lib.list_local_devices()` Bug,"I am trying to set up GPU configuration for Tensorflow. The step is very simple - Call `tensorflow.python.client.device_lib.list_local_devices()` to detect the number of gpu devices on the machine, and then set `config` for Tensorflow.  The following is the code for reproducing:

```
from logging import getLogger

import tensorflow as tf
from tensorflow.python.client import device_lib


log = getLogger(__name__)


def get_available_gpus():
    """""" Get available GPU devices info. """"""
    local_device_protos = device_lib.list_local_devices()
    return [x.name for x in local_device_protos if x.device_type == 'GPU']


def test_gpu_memory_usage():
    # Detect available GPU devices info.
    log.info(""On this machine, GPU devices: "", get_available_gpus())

    # Set Tensorflow GPU configuration.
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)
    tf_config=tf.ConfigProto(
        allow_soft_placement=True,
        device_count={'GPU': len(get_available_gpus())},
        gpu_options=gpu_options,
        log_device_placement=True)
    session = tf.Session(config=tf_config)

    # Mimick training process.
    while True:
        pass
        

test_gpu_memory_usage()
```
If you run the above code, you could notice that even though you set GPU memory fraction per process to 0.1, it still allocates the whole GPU memory by looking at command `nvidia-smi`. However, if you don't call `get_available_gpus()`, the memory allocation works fine. That means, there might be a bug in `device_lib.list_local_devices()` to prevent setting up Tensorflow GPU memory usage.

PS. My code runs on machine with GPU `GeForce GTX 1080`, CUDA 8.0, OS Ubuntu 16.04 and Python 3.5, and the above issue could be reproduced using either Tensorflow v.0.12, v.1.0 or v.1.1."
9372,TensorBoard does not load in Internet Explorer 11,"### System Information
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: Server is running on Ubuntu 14.04
- *TensorFlow installed from (source or binary)?*: Docker image
- *TensorFlow version* (use command below): 1.0.1-gpu
- *CUDA/cuDNN version*: CUDA 8 / cuDNN 6
- *GPU Model and Memory*: K520 (AWS g2.2xlarge)
- *Exact command to reproduce*: Launch TensorBoard and load in IE11

### Describe the problem clearly
Get a blank page when loading TensorBoard in IE11.  Works fine in Firefox/Chrome/Safari.
Get three errors from the IE console:
```
SCRIPT1002: Syntax error
File: javascript;charset=utf-8,%0A%20%20Polymer(%7B%0A%20%20%20%20is%3A%20%22tf-run-selector%22%2C%0A%20%20%20%20properties%3A%20%7B%0A%20%20%20%20%20%20backend%3A%20Object%2C%0A%20%20%20%20%20%20outSelected%3A%20%7Btype%3A%20Array%2C%20notify%3A%20true%7D%2C%0A%20%20%20%20%20%20%2F%2F%20runs%3A%20an%20array%20of%20strings%2C%20representing%20the%20run%20names%20that%20may%20be%20chosen%0A%20%20%20%20%20%20runs%3A%20Array%2C%0A%20%20%20%20%20%20colorScale%3A%20Object%2C%20%2F%2F%20TF.ColorScale%0A%20%20%20%20%20%20logdir%3A%20%7B%0A%20%20%20%20%20%20%20%20type%3A%20String%2C%0A%20%20%20%20%20%20%20%20notify%3A%20true%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%7D%2C%0A%20%20%20%20ready%3A%20function()%20%7B%0A%20%20%20%20%20%20%2F%2F%20Populate%20the%20logdir.%0A%20%20%20%20%20%20this.backend.logdir().then(logdirObject%20%3D%3E%20%7B%0A%20%20%20%20%20%20%20%20this.set(&apos;logdir&apos;%2C%20logdirObject.logdir)%3B%0A%20%20%20%20%20%20%7D).catch(e%20%3D%3E%20%7B%0A%20%20%20%20%20%20%20%20%2F%2F%20Fetching%20the%20logdir%20failed.%20Prevent%20the%20exception%20from%20logging%20to%0A%20%20%20%20%20%20%20%20%2F%2F%20console.%20The%20console%20already%20logs%20a%20404%20network%20event.%0A%20%20%20%20%20%20%7D)%3B%0A%20%20%20%20%7D%2C%0A%20%20%20%20_toggleAll%3A%20function()%20%7B%0A%20%20%20%20%20%20this.%24.multiCheckbox.toggleAll()%3B%0A%20%20%20%20%7D%2C%0A%20%20%20%20%2F%2F%20Break%20the%20string%20at%20natural%20points%2C%20including%20commas%2C%20equals%2C%20and%20slashes%0A%20%20%20%20_breakString%3A%20function(originalString)%20%7B%0A%20%20%20%20%20%20return%20originalString.replace(%2F(%5B%5C%2F%3D-_%2C%5D)%2Fg%2C%20%22%241%3Cwbr%3E%22)%0A%20%20%20%20%7D%2C%0A%20%20%7D)%3B%0A%20%20%0A%2F%2F%23%20sourceURL%3Dhttp%3A%2F%2Fec2-54-221-2-83.compute-1.amazonaws.com%3A6006%2Fdist%2Ftf-tensorboard.html-24.js%0A, Line: 17, Column: 48
```

```
SCRIPT1003: Expected ':'
File: javascript;charset=utf-8,%0A(function()%20%7B%0APolymer(%7B%0A%20%20is%3A%20&apos;vz-projector-dashboard&apos;%2C%0A%20%20properties%3A%20%7B%0A%20%20%20%20dataNotFound%3A%20Boolean%2C%0A%20%20%20%20routePrefix%3A%20String%0A%20%20%7D%2C%0A%20%20ready()%20%7B%0A%20%20%20%20var%20self%20%3D%20this%3B%0A%20%20%20%20d3.json(this.routePrefix%20%2B%20&apos;%2Fruns&apos;%2C%20function(err%2C%20runs)%20%7B%0A%20%20%20%20%20%20self.dataNotFound%20%3D%20(runs.length%20%3D%3D%3D%200)%3B%0A%20%20%20%20%7D)%3B%0A%20%20%7D%0A%7D)%3B%0A%7D)()%3B%0A%0A%2F%2F%23%20sourceURL%3Dhttp%3A%2F%2Fec2-54-221-2-83.compute-1.amazonaws.com%3A6006%2Fdist%2Ftf-tensorboard.html-70.js%0A, Line: 9, Column: 8
```

```
SCRIPT1014: Invalid character
File: javascript;charset=utf-8,%0A%20%20%20%20Polymer(%7B%0A%20%20%20%20%20%20is%3A%20%22tf-tensorboard%22%2C%0A%20%20%20%20%20%20behaviors%3A%20%5BTF.TensorBoard.AutoReloadBehavior%5D%2C%0A%20%20%20%20%20%20properties%3A%20%7B%0A%20%20%20%20%20%20%20%20router%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20type%3A%20Object%2C%0A%20%20%20%20%20%20%20%20%20%20value%3A%20function()%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20TF.Backend.router()%3B%0A%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20_backend%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20type%3A%20Object%2C%0A%20%20%20%20%20%20%20%20%20%20computed%3A%20%22_makeBackend(router%2C%20demoDir)%22%2C%0A%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%2F%2F%20Which%20tab%20is%20selected%20(scalars%2C%20graph%2C%20images%20etc).%0A%20%20%20%20%20%20%20%20mode%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20type%3A%20String%2C%0A%20%20%20%20%20%20%20%20%20%20computed%3A%20&apos;_getModeFromIndex(modeIndex)&apos;%2C%0A%20%20%20%20%20%20%20%20%20%20notify%3A%20true%2C%0A%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20tabs%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20type%3A%20Array%2C%0A%20%20%20%20%20%20%20%20%20%20readOnly%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20value%3A%20TF.Globals.TABS%2C%0A%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%2F%2F%20If%20this%20is%20set%20to%20a%20string%2C%20TensorBoard%20will%20switch%20to%20%22demo%20mode%22%0A%20%20%20%20%20%20%20%20%2F%2F%20and%20attempt%20to%20load%20serialized%20json%20data%20from%20that%20directory.%20You%20can%0A%20%20%20%20%20%20%20%20%2F%2F%20generate%20conformant%20json%20using%0A%20%20%20%20%20%20%20%20%2F%2F%20tensorboard%2Fscripts%2Fserialize_tensorboard.py%0A%20%20%20%20%20%20%20%20demoDir%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20type%3A%20String%2C%0A%20%20%20%20%20%20%20%20%20%20value%3A%20null%2C%0A%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%2F%2F%20Set%20this%20to%20true%20to%20store%20state%20in%20URI%20hash.%20Should%20be%20true%20for%20all%20non-test%20purposes.%0A%20%20%20%20%20%20%20%20useHash%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20type%3A%20Boolean%2C%0A%20%20%20%20%20%20%20%20%20%20value%3A%20false%2C%0A%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_getModeFromIndex%3A%20function(modeIndex)%20%7B%0A%20%20%20%20%20%20%20%20var%20mode%20%3D%20this.tabs%5BmodeIndex%5D%3B%0A%20%20%20%20%20%20%20%20TF.URIStorage.setString(TF.URIStorage.TAB%2C%20mode)%3B%0A%20%20%20%20%20%20%20%20return%20mode%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_makeBackend%3A%20function(router%2C%20demoDir)%20%7B%0A%20%20%20%20%20%20%20%20%2F%2F%20use%20the%20demoDir%20if%20it%20is%20set%2C%20otherwise%20use%20the%20provided%20router%0A%20%20%20%20%20%20%20%20if%20(demoDir%20!%3D%20null)%20%7B%0A%20%20%20%20%20%20%20%20%20%20router%20%3D%20TF.Backend.router(demoDir%2C%20true)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20return%20new%20TF.Backend.Backend(router)%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsScalars%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22scalars%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsImages%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22images%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsAudio%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22audio%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsGraphs%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22graphs%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsEmbeddings%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22embeddings%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsDistributions%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22distributions%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_modeIsHistograms%3A%20function(mode)%20%7B%0A%20%20%20%20%20%20%20%20return%20mode%20%3D%3D%3D%20%22histograms%22%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20selectedDashboard%3A%20function()%20%7B%0A%20%20%20%20%20%20%20%20var%20dashboard%20%3D%20this.%24%24(%22%23%22%20%2B%20this.mode)%3B%0A%20%20%20%20%20%20%20%20if%20(dashboard%20%3D%3D%20null)%20%7B%0A%20%20%20%20%20%20%20%20%20%20throw%20new%20Error(%60Unable%20to%20find%20dashboard%20for%20mode%3A%20%24%7Bthis.mode%7D%60)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20return%20dashboard%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20ready%3A%20function()%20%7B%0A%20%20%20%20%20%20%20%20TF.Globals.USE_HASH%20%3D%20this.useHash%3B%0A%0A%20%20%20%20%20%20%20%20this._getModeFromHash()%3B%0A%20%20%20%20%20%20%20%20window.addEventListener(&apos;hashchange&apos;%2C%20function()%20%7B%0A%20%20%20%20%20%20%20%20%20%20this._getModeFromHash()%3B%0A%20%20%20%20%20%20%20%20%7D.bind(this))%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20_getModeFromHash%3A%20function()%20%7B%0A%20%20%20%20%20%20%20%20var%20tabName%20%3D%20TF.URIStorage.getString(TF.URIStorage.TAB)%3B%0A%20%20%20%20%20%20%20%20var%20modeIndex%20%3D%20this.tabs.indexOf(tabName)%3B%0A%20%20%20%20%20%20%20%20if%20(modeIndex%20%3D%3D%20-1%20%26%26%20this.modeIndex%20%3D%3D%20null)%20%7B%0A%20%20%20%20%20%20%20%20%20%20%2F%2F%20Select%20the%20first%20tab%20as%20default.%0A%20%20%20%20%20%20%20%20%20%20this.set(&apos;modeIndex&apos;%2C%200)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20if%20(modeIndex%20!%3D%20-1%20%26%26%20modeIndex%20!%3D%20this.modeIndex)%20%7B%0A%20%20%20%20%20%20%20%20%20%20this.set(&apos;modeIndex&apos;%2C%20modeIndex)%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20reload%3A%20function()%20%7B%0A%20%20%20%20%20%20%20%20if%20(this.mode%20%3D%3D%3D%20%22graphs%22%20%7C%7C%20this.mode%20%3D%3D%3D%20%22embeddings%22)%20%7B%0A%20%20%20%20%20%20%20%20%20%20return%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20this.selectedDashboard().reload()%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20openSettings%3A%20function()%20%7B%0A%20%20%20%20%20%20%20%20this.%24.settings.open()%3B%0A%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%7D)%3B%0A%20%20%0A%2F%2F%23%20sourceURL%3Dhttp%3A%2F%2Fec2-54-221-2-83.compute-1.amazonaws.com%3A6006%2Fdist%2Ftf-tensorboard.html-72.js%0A, Line: 77, Column: 27
```
"
9371,load python saved model in java,"Hello,

I have created, trained and saved a tensorflow model using python 

`classifier = learn.DNNClassifier(hidden_units=[10, 20, 5], n_classes=5
                                 ,feature_columns=feature_columns
                                 ,model_dir= model_dir
                                 )
`

The model files are in :

`D:\java\workspace\APIJavaSampleCode\tfModels\dnn\ModelSave`

files :

checkpoint
events.out.tfevents.1492792287.BIRINHOS-PC
graph.pbtxt
model.ckpt-1.data-00000-of-00001
model.ckpt-1.index
model.ckpt-1.meta
model.ckpt-100.data-00000-of-00001
model.ckpt-100.index
model.ckpt-100.meta
 
in Java I have the line code :

`SavedModelBundle.load(""D:/java/workspace/APIJavaSampleCode/tfModels/dnn/ModelSave"");`

The result error is :

`Exception in thread ""main"" org.tensorflow.TensorFlowException: SavedModel not found in export directory: D:/java/workspace/APIJavaSampleCode/tfModels/dnn/ModelSave
	at org.tensorflow.SavedModelBundle.load(Native Method)
	at org.tensorflow.SavedModelBundle.load(SavedModelBundle.java:38)
	at tensorflow.HelloTF.main(HelloTF.java:32)
`

Can anyone help me loading a tf model in Java ? 

Thanks "
9370,Possibly serious bug in cuDNN RNNParamsSaveable,"`RNNParamsSaveable` appears to only save half of the weights when the RNN is bidirectional. See below.

When the RNN is unidirectional, `model.params_size()` matches the total size of weights + biases returned by `model.params_to_canonical(params)`

```
model = cudnn_rnn_ops.CudnnLSTM(num_layers=1, num_units=100, input_size=20, direction='unidirectional')
params = tf.get_variable('cudnn_rnn_params', initializer=tf.random_uniform([model.params_size()]), validate_shape=False)
model.params_size().eval(session=sess) # returns 48800
sum([wts.eval(session=sess).shape[0] for wtss in model.params_to_canonical(params) for wts in wtss]) # returns 48800
```

On the other hand, when the RNN is bidirectional, `model.params_size()` returns twice the size of the unidirectional case, which makes sense, but the size of `model.params_to_canonical(params)` is unchanged.

```
model = cudnn_rnn_ops.CudnnLSTM(num_layers=1, num_units=100, input_size=20, direction='bidirectional')
params = tf.get_variable('cudnn_rnn_params', initializer=tf.random_uniform([model.params_size()]), validate_shape=False)
model.params_size().eval(session=sess) # returns 97600
sum([wts.eval(session=sess).shape[0] for wtss in model.params_to_canonical(params) for wts in wtss]) # returns 48800
```

I believe this may have been missed by tests because, as this [TODO](https://github.com/tensorflow/tensorflow/blob/f0f7a1ef63c47075e3eb7eaeeb3588d057f3171d/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py#L37) suggests, both the canonical and non-canonical versions are being saved and restored, and so even if only half the weights are being restored from the canonical version, the non-canonical weights can compensate and hide the problem.

Am I missing something?"
9369,Sub-pixel shuffling tensor operation,"Is there interest in integrating a [subpixel shuffling](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shi_Real-Time_Single_Image_CVPR_2016_paper.pdf) operation as a core operation to Tensorflow? I've implemented such an operation on my [fork](https://github.com/jhetherly/tensorflow/tree/shuffle_op) and I think this could find widespread use. My implementation is a bit more generic than the one in the paper and is implemented using the C++ Tensorflow API. The operation I've defined is dimension agnostic and is found in the `contrib` portion of the source tree. Let me know if there is anything I need to do before making a pull request (i.e. better documentation, etc.)."
9368,PreventGradients in SoftmaxCrossEntropyWithLogit ops,"SparseSoftmaxCrossEntropyWithLogits cannot take second order gradients (It's not a beautiful hack, and I am not sure how much computational speed up it will bring). 
Adding PreventGradient node in the gradient graph seems to contaminate the computation graph structure, e.g. I am doing custom forward-mode automatic differentiation.
Reference: https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/python/ops/nn_grad.py#L334"
9367,[XLA] Ptxas Error when TF_CPP_MIN_VLOG_LEVEL=2 ,"### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: Linux Ubuntu 14.04
- *TensorFlow installed from (source or binary)?*: source
- *TensorFlow version* (use command below): `('v1.1.0-rc2-219-g623dd83', '1.1.0-rc2')`
- *Bazel version (if compiling from source)*: `0.4.5-jdk7`
- *CUDA/cuDNN version*: 7.5/5
- *GPU Model and Memory*: GeForce GTX TitanX 
- *Exact command to reproduce*: `python test.py --batch_size 16 --step 20`

### Describe the problem clearly
To make tensorflow print the logs in VLOG(2), I set the `TF_CPP_MIN_VLOG_LEVEL=2`. After doing that, the program throws a fatal error. It seems that there's something wrong when compiling xla hlo_instruction to ptx.

>2017-04-21 14:35:23.158362: I tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:219] ptxas fatal   : SM version specified by .target is higher than default SM version assumed
2017-04-21 14:35:23.158423: F tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:221] Invalid PTX. See the error message above for reasons.


### Source Code / Logs

Full log can be found [here](https://gist.github.com/pgplus1628/b257901de5af4bdd88fd78adab084177)
Reproduce with command `python test.py --batch_size 16 --step 20`  

Code:

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '2' # enable logging debug info
import inspect
import numpy as np
import tensorflow as tf


flags = tf.flags
logging = tf.logging
flags.DEFINE_integer(""batch_size"", 1, ""inference batch size"")
flags.DEFINE_integer(""step"", 1, ""step size for infernece"")
FLAGS = flags.FLAGS


def data_type():
    return tf.float32


class InputData(object):
    
    def __init__(self, config):
        self.batch_size = batch_size = config.batch_size
        self.num_steps = num_steps = config.num_steps
        self.hidden_size = hidden_size = config.hidden_size
        self.input_data = tf.placeholder(data_type(), [batch_size, num_steps, hidden_size], name = 'input_data')


class Config(object):
    num_layers = 1
    num_steps = 20
    hidden_size = 256
    batch_size = 20
    vocab_size = 10000
    init_scale = 0.1
    num_iter = 50
    warm_iter = 2


class LSTMModel(object):
    """""" Only forward, No Embedding
    """"""

    def __init__(self, config, input_):
        self._input = input_
        self._input_data = self._input.input_data
        
        batch_size = input_.batch_size
        num_steps =  input_.num_steps
        size = config.hidden_size
        vocab_size = config.vocab_size

        def lstm_cell():
            if 'reuse' in inspect.getargspec(
              tf.contrib.rnn.BasicLSTMCell.__init__).args:
                print(""reuse"")
                return tf.contrib.rnn.BasicLSTMCell(
                    size, forget_bias=0., state_is_tuple=True,
                    reuse = tf.get_variable_scope().reuse)
            else:
                print(""not reuse"")
                return tf.contrib.rnn.BasicLSTMCell(
                    size, forget_bias=0.0, state_is_tuple=True)

        attn_cell = lstm_cell
        cell = tf.contrib.rnn.MultiRNNCell(
            [attn_cell() for _ in range(config.num_layers)], state_is_tuple=True)

        self._initial_state = cell.zero_state(batch_size, data_type())

        outputs = []
        state = self._initial_state
        with tf.variable_scope(""RNN""):
            for time_step in range(num_steps):
                if time_step > 0 : tf.get_variable_scope().reuse_variables()
                (cell_output, state) = cell(self._input.input_data[:, time_step, :], state)
                outputs.append(cell_output)
        
        self._output = tf.reshape(tf.concat(axis=1, values=outputs), [-1, size])
        self._final_state = state
        softmax_w = tf.get_variable(
            ""softmax_w"", [size, vocab_size], dtype=data_type())
        softmax_b = tf.get_variable(""softmax_b"", [vocab_size], dtype=data_type())
        self._logits = tf.matmul(self._output, softmax_w) + softmax_b

        return

    @property
    def initial_state(self):
        return self._initial_state

    @property
    def logits(self):
        return self._logits
  
    @property
    def input_data(self):
        return self._input_data


def run_inference(session, model, input_data, sv) :
    # initialize with a clean state
    state = session.run(model.initial_state)

    fetches = {}
    fetches['logit'] = model.logits

    feed_dict = {}
    feed_dict[model.input_data] = input_data
    for i, (c, h) in enumerate(model.initial_state):
        feed_dict[c] = state[i].c
        feed_dict[h] = state[i].h

    session.run(fetches, feed_dict)


def main(_):
    # config
    eval_config = Config()
    eval_config.num_steps = FLAGS.step
    eval_config.batch_size = FLAGS.batch_size

    # generate random data
    input_data = np.random.rand(eval_config.batch_size, eval_config.num_steps, eval_config.hidden_size).astype(np.float32)

    with tf.Graph().as_default():
        initializer = tf.random_uniform_initializer(-eval_config.init_scale, 
                                                    eval_config.init_scale)
        with tf.name_scope('Inference'):
            _input = InputData(eval_config)
            with tf.variable_scope('Model', reuse=None, initializer=initializer):
                model = LSTMModel(config=eval_config, input_=_input)

        sv = tf.train.Supervisor()
        sess_config = tf.ConfigProto(allow_soft_placement=True,
                                     log_device_placement=False)
        # enable xla
        sess_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1

        # run inference
        with sv.managed_session(config=sess_config) as session:
            run_inference(session, model, input_data, sv)

if __name__ == '__main__':
    tf.app.run()
```"
9366,Check in tensorboard_bower_dependency_sync.py file,"Hi TF Developers,

Could you kindly check in the `tensorboard_bower_dependency_sync.py` file to the repo? We need to customize the build process and having that file would be really helpful. Thanks a lot in advance!

Ying"
9365,TensorFlow Retrain  Android Error,"I have my own custom created .pb file and string text using TensorFlow Retrain Model
https://www.tensorflow.org/versions/r0.10/how_tos/image_retraining/
Then i have created .so file By building tensorflow
bazel build -c opt //tensorflow/examples/android:tensorflow_demo
 
When i load both into androidstudio and run the app i get below error

No Operation named [input] in the Graph
                                                                                  at org.tensorflow.Session$Runner.operationByName(Session.java:297)
                                                                                  at org.tensorflow.Session$Runner.feed(Session.java:115)
                                                                                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.addFeed(TensorFlowInferenceInterface.java:439)
                                                                                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.fillNodeFloat(TensorFlowInferenceInterface.java:188)
                                                                                  at com.mindorks.tensorflowexample.TensorFlowImageClassifier.recognizeImage(TensorFlowImageClassifier.java:146)
                                                                                  at com.mindorks.tensorflowexample.MainActivity$1.onPictureTaken(MainActivity.java:81)
                                                                                  at com.flurgle.camerakit.CameraView$CameraListenerMiddleWare.onPictureTaken(CameraView.java:296)
                                                                                  at com.flurgle.camerakit.Camera1$2.onPictureTaken(Camera1.java:185)
                                                                                  at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1201)
                                                                                  at android.os.Handler.dispatchMessage(Handler.java:102)
                                                                                  at android.os.Looper.loop(Looper.java:135)
                                                                                  at android.app.ActivityThread.main(ActivityThread.java:5253)
                                                                                  at java.lang.reflect.Method.invoke(Native Method)
                                                                                  at java.lang.reflect.Method.invoke(Method.java:372)
                                                                                  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:900)
                                                                                  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:695)

I have created input_node as ""Mul:0"" and Out_put node as ""Final_result"" while building

"
9364,Error,"Trying to get tensorflow to work for my final bit on dissertation but anytime I try to install it in virtual box ubuntu linux 64bit, I get this error I've tried the CPU/GPU version but I can only seem to get the python3 version working but I need the python2.

I get this error message each time..  

 99% |████████████████████████████████| 44.1MB 14.8MB/s eta 0:00:01Exception:
Traceback (most recent call last):
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/commands/install.py"", line 353, in run
    wb.build(autobuilding=True)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/wheel.py"", line 749, in build
    self.requirement_set.prepare_files(self.finder)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/req/req_set.py"", line 380, in prepare_files
    ignore_dependencies=self.ignore_dependencies))
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/req/req_set.py"", line 620, in _prepare_file
    session=self.session, hashes=hashes)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 821, in unpack_url
    hashes=hashes
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 659, in unpack_http_url
    hashes)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 882, in _download_http_url
    _download_url(resp, link, content_file, hashes)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 605, in _download_url
    consume(downloaded_chunks)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/utils/__init__.py"", line 870, in consume
    deque(iterator, maxlen=0)
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 571, in written_chunks
    for chunk in chunks:
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/utils/ui.py"", line 139, in iter
    for x in it:
  File ""/home/tay/tensorflow/local/lib/python2.7/site-packages/pip/download.py"", line 560, in resp_read
    decode_content=False):
  File ""/home/tay/tensorflow/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/response.py"", line 432, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File ""/home/tay/tensorflow/share/python-wheels/urllib3-1.19.1-py2.py3-none-any.whl/urllib3/response.py"", line 380, in read
    data = self._fp.read(amt)
  File ""/home/tay/tensorflow/share/python-wheels/CacheControl-0.11.7-py2.py3-none-any.whl/cachecontrol/filewrapper.py"", line 63, in read
    self._close()
  File ""/home/tay/tensorflow/share/python-wheels/CacheControl-0.11.7-py2.py3-none-any.whl/cachecontrol/filewrapper.py"", line 50, in _close
    self.__callback(self.__buf.getvalue())
  File ""/home/tay/tensorflow/share/python-wheels/CacheControl-0.11.7-py2.py3-none-any.whl/cachecontrol/controller.py"", line 275, in cache_response
    self.serializer.dumps(request, response, body=body),
  File ""/home/tay/tensorflow/share/python-wheels/CacheControl-0.11.7-py2.py3-none-any.whl/cachecontrol/serialize.py"", line 87, in dumps
    ).encode(""utf8""),
MemoryError"
9363,"When I use the Bazel to compile the image_retraining project ,the error occurred.","Please go to Stack Overflow for help and support. http://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

1. It must be a bug or feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g. fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:no
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:Linux Ubuntu 16.04.2
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version* (use command below):tensorflow-1.1.0rc1-cp35-cp35m-linux_x86_64.whl
- *Bazel version (if compiling from source)*:0.4.5
- *CUDA/cuDNN version*:no
- *GPU Model and Memory*:no
- *Exact command to reproduce*:yes

You can collect some of this information using our environment capture script https://github.com/tensorflow/tensorflow/blob/master/tools/
You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```


### Describe the problem clearly
When I use the Bazel to compile the image_retraining project when the error occurred, how to solve, spec.json, head, branch_ref these documents are not in that directory, did you made some change that now cannot compile directory:
wei@wei-TA960:~/myprogramfile/TF-0.12/tensorflow-r0.12-1$ bazel build tensorflow/examples/image_retraining:retrain
ERROR: /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/core/BUILD:1117:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/core/BUILD:1117:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/core/BUILD:1117:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9362,[Bug report] ValueError: Variable does not exist on tf.layers.dense(reuse=True) after graph switch,"### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: macOS Sierra
- *TensorFlow installed from (source or binary)?*: binary, pip
- *TensorFlow version* (use command below): 1.0.0
- *Bazel version (if compiling from source)*: None
- *CUDA/cuDNN version*: not using GPU
- *GPU Model and Memory*: not using GPU
- *Exact command to reproduce*: None


### Describe the problem clearly
I built 2 networks that share some layers/variables. The best way that I learned was to treat them as separate graphs. I wasn't sure about whether 2 graphs can share variables but I tried `tf.get_variable(resue=True)` anyway. At least my program show create 2 separate graph with no variable sharing. But a ValueError(variable does not exist) was thrown instead.

### Source Code / Logs
* source code:
```python
# test code
model = DPGModel(3, 4)

# source code
class DPGModel(object):
    def __init__(self, state_size, action_size):
        self.sess = tf.Session()
        self.state_size = state_size
        self.action_size = action_size
        self.create_network()
        # other irrelevant code

    def create_network(self):
        self.state_tensor = tf.placeholder(tf.float64, [None, self.state_size], name=""state"")
        self.action_tensor = tf.placeholder(tf.float64, [None, self.action_size], name=""action"")
        self.actor_graph = tf.Graph()
        with self.actor_graph.as_default():
            print tf.get_variable_scope()
            state_h1 = tf.layers.dense(inputs=self.state_tensor, units=64, activation=tf.nn.relu, name=""state_h1"",
                                       reuse=True)
            state_h2 = tf.layers.dense(inputs=state_h1, units=32, activation=tf.nn.relu, name=""state_h2"", reuse=True)
            self.policy_tensor = tf.layers.dense(inputs=state_h2, units=self.action_size, activation=tf.nn.softmax,
                                                 name=""policy"")

        self.critic_graph = tf.Graph()
        with self.critic_graph.as_default():
            print tf.get_variable_scope()
            state_h1 = tf.layers.dense(inputs=self.state_tensor, units=64, activation=tf.nn.relu, name=""state_h1"",
                                       reuse=True)
            state_h2 = tf.layers.dense(inputs=state_h1, units=32, activation=tf.nn.relu, name=""state_h2"", reuse=True)
            action_h1 = tf.layers.dense(inputs=self.action_tensor, units=64, activation=tf.nn.relu, name=""action_h1"")
            action_h2 = tf.layers.dense(inputs=action_h1, units=32, activation=tf.nn.relu, name=""action_h2"")
            fc = tf.layers.dense(inputs=[state_h2, action_h2], units=32, activation=tf.nn.relu,
                                 name=""fully_connected"")
            self.value_tensor = tf.layers.dense(inputs=fc, units=1, activation=None, name=""value"")
```

* error log:
```
<tensorflow.python.ops.variable_scope.VariableScope object at 0x10fd20790>
Traceback (most recent call last):
  File ""/Users/niyan/code/routerRL/test.py"", line 16, in <module>
    model = DPGModel(state_dim, action_dim)
  File ""/Users/niyan/code/routerRL/DPGModel.py"", line 10, in __init__
    self.create_network()
  File ""/Users/niyan/code/routerRL/DPGModel.py"", line 37, in create_network
    reuse=True)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 216, in dense
    return layer.apply(inputs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 303, in apply
    return self.__call__(inputs, **kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 269, in __call__
    self.build(input_shapes[0])
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 123, in build
    trainable=True)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 988, in get_variable
    custom_getter=custom_getter)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 890, in get_variable
    custom_getter=custom_getter)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 341, in get_variable
    validate_shape=validate_shape)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 258, in variable_getter
    variable_getter=functools.partial(getter, **kwargs))
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 208, in _add_variable
    trainable=trainable and self.trainable)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 333, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 657, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable state_h1/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?

Process finished with exit code 1
```
"
9360,Understanding cast() in tensorflow,"### System Information

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary):**
Installed from source (v1.0.1)
- **TensorFlow version (use command below):**
('v1.0.1-0-ge895d5c-dirty', '1.0.1')
- **Bazel version (if compiling from source)**:
 bazel release 0.4.4-2017-04-10 (@80a07b5)
- **CUDA/cuDNN version:**
In disable mode
- **Exact command to reproduce**:
bazel test //tensorflow/python/kernel_tests:cast_op_test


### Describe the problem clearly 
This is regarding failure of test case testInfNan in cast_op_test.py file.While executing this test case on ppc64le, it was observed that following line returns unexpected results:

`self._compare(np.inf, np.int32, i4.min, False)`

i4.min value on x86 as well as on ppc64le is -2147483648. However ""np.inf"" on x86 is ""signed"" by default whereas on ppc64le it is ""unsigned"" by default. To make the results compatible with x86, somehow np.inf should be cast as ""signed"" on ppc64le. In my opinion there could be two ways of doing this.

1. Use a proper cast (python equivalent of ""(signed int) var"" in C) which    would always interprete np.inf as of type ""signed"" on ppc64le
-- or --
2. if we are on ppc64le platform, when dealing with np.inf, convert it explicitly to signed as ""-np.inf"" and then perform subsequent operations

Though I have not yet decided on which one to implement, I am trying to find a right place first to put this fix in tensorflow code. I guess the right place would be somewhere in the code related to following 2 lines in cast_op_test.py (line# 57 and 58, in function _cast):

```
val = constant_op.constant(x, self._toDataType(np.array([x]).dtype))
return math_ops.cast(val, self._toDataType(dtype), name=""cast"").eval()

```
However I am unable to grasp code details about constant() in python/framework/constant_op.py and cast() in python/ops/math_ops.py, similarly there is REGISTER_OP(""Cast"") in core/ops/math_ops.cc which I guess is the heart of cast functionality. Is my understanding correct?

So if I have to implement the changes for ppc64le, which could be the right place to do so?

### Source Code / Logs
```
`$ bazel test //tensorflow/python/kernel_tests:cast_op_test


exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py:62: ComplexWarning: Casting complex values to real discards the imaginary part
  np_ans = x.astype(dtype)
....F.W tensorflow/core/framework/op_kernel.cc:983] Unimplemented: Cast int64 to string is not supported
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Unimplemented: Cast int64 to string is not supported
         [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
........
======================================================================
FAIL: testInfNan (__main__.CastOpTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py"", line 150, in testInfNan
    self._compare(np.inf, np.int32, i4.min, False)
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py"", line 124, in _compare
    x, dst_dtype, use_gpu=use_gpu), dst_dtype(expected))
  File ""/usr/lib64/python2.7/site-packages/numpy/testing/utils.py"", line 425, in assert_equal
    raise AssertionError(msg)
AssertionError:
Items are not equal:
 ACTUAL: 2147483647
 DESIRED: -2147483648

----------------------------------------------------------------------
Ran 14 tests in 2.485s

FAILED (failures=1)`
```"
9359,Equality operator not overloaded,"It's unexpected and a gotcha that some comparison operators (`>`, `<`, `<=`, `=>`) are overloaded but not all (`==`, `!=`). Is there a particular reason for this? I think either all standard operators should be overloaded, or none at all.

```python
In [1]: import tensorflow as tf

In [2]: tensor = tf.zeros((3,5))

In [3]: tensor > 0
Out[3]: <tf.Tensor 'Greater:0' shape=(3, 5) dtype=bool>

In [4]: tensor == 0
Out[4]: False
```

This is on TensorFlow 1.1.0rc2."
9358,What is the process for converting my data set to the MINIST data set?,I have run “[Deep MNIST for Experts  |  TensorFlow](https://www.tensorflow.org/versions/r0.11/tutorials/mnist/beginners/)” this file. I have X_train ; Y_train ; X_text ;Y_text ; Now I want to convert those 4 files into one “mist” variable like link which is MNIST format . 
9357,init_op and concurrent.futures freeze forever,"## **System Information:**

OS Platform and Distribution: MAC OSX
TensorFlow installed from: `pip install tensorflow` 
TensorFlow version : 1.0.0
Python version : Python 3.6.1

I found a  bug trying to run multiple agent in parallel using python, it boiled down to the code below:
- If i try to init an agent asynchronously after init an agent synchronously, it freezes forever
- if i do it the other way around, everything is fine

Does anyone has an idea on this one?

## **Source Code:**
```python
import tensorflow as tf
import concurrent.futures

# Very basic model
class Agent(object):
    def __init__(self):
        graph = tf.Graph()
        with graph.as_default():
            self.Qs = tf.get_variable('Qs', shape=[1, 1])
            self.init_op = tf.global_variables_initializer()
        self.sess = tf.Session(graph=graph)

        print('Before init_op')
        self.sess.run(self.init_op)
        print('After init_op')


def execute_run():
    print('In execute')
    agent = Agent()

print('*** First: we create an agent asynchronously')
with concurrent.futures.ProcessPoolExecutor(1) as executor:
    concurrent.futures.wait([executor.submit(execute_run)])

print('*** Then: we create an agent synchronously')
agent = Agent()

print('So far, everything is fine')


print('*** Finally: we create an agent asynchronously again')
with concurrent.futures.ProcessPoolExecutor(1) as executor:
    concurrent.futures.wait([executor.submit(execute_run)])

print('You\'ll never see this as we  can\'t get passed the init_op')
```

## **output:**
```bash
*** First: we create an agent asynchronously
In execute
Before init_op
After init_op
*** Then: we create an agent synchronously
Before init_op
After init_op
So far, everything is fine
*** Finally: we create an agent asynchronously again
In execute
Before init_op
```"
9356,decode_image return tensor without shape in python,"
### System Information
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: CentOS Linux release 7.0.1406 (Core)
- *TensorFlow installed from (source or binary)?*: python3 pip
- *TensorFlow version* : v1.0.0-65-g4763edf-dirty 1.0.1
- *Python version* : Python 3.5.2 :: Anaconda custom (64-bit)

### Describe the problem clearly

When I decode a jpeg file to a tensor with decode_jpeg, the code ran normally.
but if I use decode_image instead of decode_jpeg for more compatibilities, It raised a ValueError as follow.
Is It a bug?
Thanks

### Source Code / Logs
```python
def preprocess_image(image_path):
    file_content = tf.read_file(image_path)
    
    #image = tf.image.decode_jpeg(file_content)
    image = tf.image.decode_image(file_content)
    image = tf.image.per_image_standardization(image)
    image = tf.image.resize_images(image, [480, 640])
```
output : 
```
Traceback (most recent call last):
  File ""/data/home/zhangbowen/is_vehicle/classify.py"", line 29, in <module>
    main()
  File ""/data/home/zhangbowen/is_vehicle/classify.py"", line 26, in main
    image = preprocess_image(image_file)
  File ""/data/home/zhangbowen/is_vehicle/classify.py"", line 15, in preprocess_image
    image = tf.image.resize_images(image, [480, 640])
  File ""/data/home/zhangbowen/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/image_ops_impl.py"", line 643, in resize_images
    raise ValueError('\'images\' contains no shape.')
ValueError: 'images' contains no shape.
```"
9355,list index out of range,"i am getting these warning while running neuroner

`epoch_elapsed_training_time: 331.644915 seconds
assess_model on dataset_type: train
C:\Users\erame\AppData\Local\Programs\Python\Python35\lib\site-packages\matplotlib\artist.py:233: MatplotlibDeprecationWarning: get_axes has been deprecated in mpl 1.5, please use the
axes property.  A removal date has not been set.
  stacklevel=1)
C:\Users\erame\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\metrics\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
C:\Users\erame\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\metrics\classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.
  'recall', 'true', average, warn_for)
assess_model on dataset_type: valid
assess_model on dataset_type: test
shell_command: perl .\conlleval < ..\output\en_2017-04-21_07-36-25-322798\000_014986_train.txt > ..\output\en_2017-04-21_07-36-25-322798\000_014986_train.txt_conll_evaluation.txt
'perl' is not recognized as an internal or external command,
operable program or batch file.
Traceback (most recent call last):
  File ""main.py"", line 442, in <module>
    main()
  File ""main.py"", line 383, in main
    conll_parsed_output = utils_nlp.get_parsed_conll_output(conll_output_filepath)
  File ""C:\Users\erame\AppData\Local\Programs\Python\Python35\NeuroNER-master\src\utils_nlp.py"", line 42, in get_parsed_conll_output
    line = conll_output[1].split()
IndexError: list index out of range`"
9354,Error: tensorflow/core/framework/resource_handle.pb.h file not found,"I have followed following instructions from this link: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile

- Before you start (All Platforms)
- Building on iOS
- Copy files from inception to data folders in benchmark, simple and camera project.
- Building by hand. (error in terminal: failed with exit code 1) in both compile_ios_protobuf and run make file. 

- download_dependencies.sh worked successfully.

If I open project from Simple or camera folder, I received the error:

tensorflow/core/framework/resource_handle.pb.h file not found.

This Post: https://github.com/tensorflow/tensorflow/issues/5095 
indicates that the problem is related to macOS Sierra. after that I installed the update from AppStore.

After that I updated macOS update which updated command line tools and now I receive following errors by running all things from scratch. (Delete old project, unzip new project and follow all instructions).

![error-list](https://cloud.githubusercontent.com/assets/27809940/25264970/f8eb8720-2687-11e7-90ee-f677e59d79df.png)"
9347,[Feature request] Add conv3d/conv3d_transpose wrapper to slim,"Please go to Stack Overflow for help and support. http://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

1. It must be a bug or feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g. fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:
Linux Ubuntu 14
- *TensorFlow installed from (source or binary)?*:
binary
- *TensorFlow version* (use command below):
1.0
- *Bazel version (if compiling from source)*:
N/A
- *CUDA/cuDNN version*:
8
- *GPU Model and Memory*:
Titan-X
- *Exact command to reproduce*:

You can collect some of this information using our environment capture script https://github.com/tensorflow/tensorflow/blob/master/tools/
You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```


### Describe the problem clearly
Simply request to add conv3d/conv3d_transpose wrapper to slim

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9343,Android Demo app & Yolo 2 - OutOfMemoryError ,"I have successfully run Android Demo with Tiny Yolo (_graph-tiny-yolo-voc.pb_ - 60mb),:

```
  private static final String YOLO_MODEL_FILE = ""file:///android_asset/graph-yolo-voc.pb"";
  private static final int YOLO_INPUT_SIZE = 416;
  private static final String YOLO_INPUT_NAME = ""input"";
  private static final String YOLO_OUTPUT_NAMES = ""output"";
  private static final int YOLO_BLOCK_SIZE = 32;
  private static final boolean USE_YOLO = true;
```

I also decided to try Yolo 2 (_graph-yolo-voc.pb_ - 193mb),
but I get _OutOfMemoryError_ when I run _TF Detect_
My phone has 3 GB of RAM 
But I know that is just android java limit and has nothing to do with current available/free memory
and we can use NDK to bypass this limit.

I also tried to run with:
```
     <activity android:name=""org.tensorflow.demo.DetectorActivity""
                  android:largeHeap=""true""
```
but didn't help

And also:
```
<activity android:name=""org.tensorflow.demo.DetectorActivity""
                  android:largeHeap=""true""
                  android:hardwareAccelerated=""false""
```
App runs ok, but nothing happens, it just shows black screen, no camera frames..

Is there a way to run app with big .pb files?  
_TensorFlowInferenceInterface_ needs _AssetManager_ and _string file name_, then I guess it just uses default java IO to read file,
mb it's better to process all of this with NDK somehow?"
9341,Tensorflow looks for wrong libcupti.so version,"- OS: Ubuntu 16.04
- *TensorFlow installed from: source
- *TensorFlow version*: 1.1.0-rc2
- *Bazel version (if compiling from source)*: 0.4.5
- *CUDA/cuDNN version*: 8.0/6.0
- *GPU Model and Memory*: NVIDIA GTX 1060, 6 GB RAM
- *Exact command to reproduce*:
------------------------
MNIST examples works fine, bute MNIST example with summaries crashes with:

```
(tensorflow) stefano@stefano-linux:~/Dokumente/Programming/Python/TensorflowCoreTutorial$ /home/stefano/tensorflow/bin/python3 /home/stefano/Dokumente/Programming/Python/TensorflowCoreTutorial/src/mnist_with_summaries.py
Extracting /home/stefano/Dokumente/Programming/Python/MNIST/train-images-idx3-ubyte.gz
Extracting /home/stefano/Dokumente/Programming/Python/MNIST/train-labels-idx1-ubyte.gz
Extracting /home/stefano/Dokumente/Programming/Python/MNIST/t10k-images-idx3-ubyte.gz
Extracting /home/stefano/Dokumente/Programming/Python/MNIST/t10k-labels-idx1-ubyte.gz
2017-04-20 19:16:15.388639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-04-20 19:16:15.389019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7085
pciBusID 0000:22:00.0
Total memory: 5.93GiB
Free memory: 4.97GiB
2017-04-20 19:16:15.389036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-04-20 19:16:15.389042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-04-20 19:16:15.389055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:22:00.0)
Accuracy at step 0: 0.0981
Accuracy at step 10: 0.7258
Accuracy at step 20: 0.8151
Accuracy at step 30: 0.8572
Accuracy at step 40: 0.879
Accuracy at step 50: 0.8949
Accuracy at step 60: 0.9052
Accuracy at step 70: 0.9058
Accuracy at step 80: 0.915
Accuracy at step 90: 0.9137
2017-04-20 19:16:20.708545: I tensorflow/stream_executor/dso_loader.cc:129] Couldn't open CUDA library libcupti.so.8.0. LD_LIBRARY_PATH: /usr/local/lib:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:/usr/lib/nvidia-375
2017-04-20 19:16:20.708600: F tensorflow/core/platform/default/gpu/cupti_wrapper.cc:59] Non-OK-status: ::tensorflow::Env::Default()->GetSymbolFromLibrary( GetDsoHandle(), kName, &f) status: Not found: /usr/local/lib/python3.5/dist-packages/tensorfl
ow/python/_pywrap_tensorflow_internal.so: undefined symbol: cuptiActivityRegisterCallbackscould not find cuptiActivityRegisterCallbacksin libcupti DSO
```

source code:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py

Problem is, that tensorflow looks for libcupti.so.8.0, but only libcupti.so.7.5 is installed:

```
stefano@stefano-linux:~$ ls /usr/lib/x86_64-linux-gnu | grep libcupti*
libcupti.so
libcupti.so.7.5
libcupti.so.7.5.18
```

I installed libcupti like described in the Install section on the Tensorflow website:

```
sudo apt-get install libcupti-dev
```

libcupti-dev 8.0 is not available for Ubuntu 16.04."
9339,Enable Fused Winograd by Default,"Right now [fused Winograd](https://github.com/tensorflow/tensorflow/pull/4901) is [disabled by default](https://github.com/tensorflow/tensorflow/blob/e69f71759adac4a794d5b159358af5253cb243bf/tensorflow/stream_executor/cuda/cuda_dnn.cc#L1970-L1976). This is even though enabling this speeds up models considerable in the 3x3 case (see https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295779638). What remains as far as issues, etc to get this faster conv enabled by default?

/CC @yangzihao @tfboyd"
9338,ideas - feature request,"**idea1**

feeding wavenet implementation in tensorflow simulatenous with the following things to do advanced music gestural recognition:

- elastic fusion dense slam
- audio data + audio advanced gestural recognition spectral classifiers

**plus:**
doing training in real time

**idea2**

implementing the following artificial intelligence model in tensorflow:

- deep convolutional recursive swarm of hybrid bdi and artificial neural networks"
9337,wide_n_deep meets kint32max bug.,"
I am trying to run a wide_n_deep model on a large dataset ------ I copy and paste adult.data 100 times as training data(adult.data.new 3256200 lines), and take adult.test as test data.

with command:
python wide_n_deep_tutorial.py --model_type=wide_n_deep --train_data=data/adult.data.new --test_data=data/adult.test

When I run the same model on original set of this, i.e. ~ 32562 set, the model runs fine. But when it tries on this 3256200 set, it throws up the following stack trace and exits.

Am I missing something here? The memory stats look fine when the program is running.

[libprotobuf ERROR google/protobuf/io/zero_copy_stream_impl_lite.cc:173] Cannot allocate buffer larger than kint32max for StringOutputStream.
Traceback (most recent call last):
  File ""/var/dl/runtime/script/wide_n_deep_tutorial.py"", line 234, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/var/dl/runtime/script/wide_n_deep_tutorial.py"", line 197, in main
    FLAGS.train_data, FLAGS.test_data)
  File ""/var/dl/runtime/script/wide_n_deep_tutorial.py"", line 186, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 280, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 426, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 984, in _train_model
    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 462, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 744, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 883, in run
    feed_dict, options)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 909, in _call_hook_before_run
    request = hook.before_run(run_context)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py"", line 340, in before_run
    ""graph.pbtxt"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/graph_io.py"", line 67, in write_graph
    file_io.atomic_write_string_to_file(path, str(graph_def))
ValueError: Unable to convert message to str"
9336,tflearn Incorrect Comment,"In the tflearn quick start guide here:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/tflearn.md

Below the section ""Describe the training input pipeline {#train-input}""

The first snippet:

```python
# Define the test inputs
def get_train_inputs():
  x = tf.constant(training_set.data)
  y = tf.constant(training_set.target)

  return x, y
```

Should be

```python
# Define the training inputs
def get_train_inputs():
  x = tf.constant(training_set.data)
  y = tf.constant(training_set.target)

  return x, y
```
where 

```python
# Define the test inputs -> # Define the training inputs
```
In the overall listing at the top of this file, it appears to have the correct comment. It's just here in this section where the comment is incorrect. 

"
9334,Custom operator can't define list(type),"hi, I am writing my custom operator, need to pass a list of int tensor into it, according to https://www.tensorflow.org/extend/adding_an_op and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/io_ops.cc#L59, I wrote the following code:
REGISTER_OP(""MyOwnOp"").Input(""my_variables: dtypes"").Attr(""dtypes: list(int)"")....
and build the code into one shared library, however error occurred when loading it through tf.load_op_library.
Here is the error message:

> tensorflow.python.framework.errors_impl.InvalidArgumentError: Reference to attr 'dtypes' with type list(int) that isn't type or list(type) from Input(""my_variables: dtypes"") for Op MyOwnOp

environment:
gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04)
Python 2.7.6
tensorflow '1.0.1'"
9333,gpu build not displaying cuda libs loading,"TF 1.1.0-rc1, CUDA 8.0 cuDNN8-0-v5.1, macOS 10.12

I built the  GPU version from source, but when I import tensorflow I don't get the usual loading cuda library messages like I would if I use the prebuilt tensorflow-gpu from pip. That said, it does appear to be using the GPU...

`~/Drive/project/image_keras$ python3 demo.py 
Using TensorFlow backend.
Found 2125 images belonging to 2 classes.
Found 832 images belonging to 2 classes.
demo.py:64: UserWarning: Update your fit_generator call to the Keras 2 API: fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=128, epochs=25, validation_steps=832)
  nb_val_samples=nb_validation_samples)
Epoch 1/25
2017-04-13 08:39:24.542434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:865] OS X does not support NUMA - returning NUMA node zero
2017-04-13 08:39:24.542538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: GeForce GT 750M
major: 3 minor: 0 memoryClockRate (GHz) 0.9255
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.77GiB
2017-04-13 08:39:24.542551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-04-13 08:39:24.542557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-04-13 08:39:24.542566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)
 49/128 [==========>...................] - ETA: 18s - loss: 0.7352 - acc: 0.5166 `

Does this look normal output or not? I can't find an answer anywhere."
9332,Cannot get Conv1D layer to work,"For the life of me, I cannot get Conv1D layer to work.  I am on windoze7 with theano backend and using MKL multithreading.  No issues with other layer types whatsoever.

The error I get is: convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=""valid"", activation=""relu"", strides=1)(embedded_sequences_1)
TypeError: __init__() takes at least 3 arguments (2 given)

Model code as below:
embedding_layer = Embedding(nb_words,
                            EMBEDDING_DIM,
                            weights=[embedding_matrix],
                            input_length=MAX_SEQUENCE_LENGTH,
                            trainable=False)
sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')
embedded_sequences_1 = embedding_layer(sequence_1_input)

sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM), dtype='int32')
embedded_sequences_2 = embedding_layer(sequence_2_input)

convx =[]
for sz in filter_sizes:
    convx1 = Conv1D(filters=num_filters, kernel_size=sz, padding=""valid"", activation=""relu"", strides=1)(embedded_sequences_1)
    convx1 = GlobalMaxPooling1D(pool_size=2)(convx1)
    convx1 = Flatten()(convx1)
    convx.append(convx1)   
x1 = merge(convx, mode='concat')

convy =[]
for sz in filter_sizes:
    convy1 = Conv1D(filters=num_filters,kernel_size=sz,padding=""valid"",activation=""relu"",strides=1)(embedded_sequences_2)
    convy1 = GlobalMaxPooling1D(pool_size=2)(convy1)
    convy1 = Flatten()(convy1)
    convy.append(convy1)   
y1 = merge(convy, mode='concat')                   

merged = merge([x1,y1], mode='concat')
merged = Dropout(0.5)(merged)
merged = BatchNormalization()(merged)
merged = Dense(num_dense, activation='relu')(merged)
merged = Dropout(0.15)(merged)
merged = BatchNormalization()(merged)
preds = Dense(1, activation='sigmoid')(merged)
model = Model(input=[sequence_1_input,sequence_2_input], output=preds)
model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])"
9331,"When I used keras to train a very large model, it was already done, but I found that the outputdim of the all-join layer was wrong, and what should I do? The The Without having to re-train the model #","When I used keras to train a very large model, it was already done, but I found that the outputdim of the all-join layer was wrong, and what should I do? The The Without having to re-train the model #"
9330,Getting error: Number of tensor does not match the number of lines in metadata,"Even though my metadata.tsv have 100k line but it still show up this message. I have try different amount of tensor and its work fine (eg. 40k, 50k). The problem occurred when the tensor values are roughly more than 70k. 
Beside, i try other data set and its work fine for 100k tensor values. Just doubt what makes the problem above happend.
![default](https://cloud.githubusercontent.com/assets/27762422/25224049/cfe357ec-25ef-11e7-96f0-6a7eb4242375.PNG)
![default](https://cloud.githubusercontent.com/assets/27762422/25224162/25ce4dd8-25f0-11e7-88d3-80d6b6849363.PNG)
"
9329,"Getting Error - Exception: No data provided for ""activation_2""  Need data for each key in: ['input2', 'aux_input', 'input1']","I am trying to concatenate auxiliary inputs with a siamese lstm.  I have verified the siamese lstm works fine, but cannot add in the auxiliary inputs.  Pleae see code below.

embedding_layer = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)
                            
shared_lstm = Bidirectional(LSTM(num_lstm))

sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input1')
embedded_sequences_1 = embedding_layer(sequence_1_input)
x1 = shared_lstm(embedded_sequences_1)

sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32',name='input2')
embedded_sequences_2 = embedding_layer(sequence_2_input)
y1 = shared_lstm(embedded_sequences_2)

merged_lstm = merge([x1,y1], mode='concat')
merged_lstm = Dropout(rate_drop_dense)(merged_lstm)
merged_lstm = BatchNormalization()(merged_lstm)

auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(merged_lstm)

auxiliary_input = Input(shape=(aux_train.shape[1],),name='aux_input')
foo = Activation('linear')(auxiliary_input)

merged = merge([merged_lstm,foo],mode='concat')
merged = Dropout(rate_drop_dense)(merged)
merged = BatchNormalization()(merged)
merged = Dense(num_dense, activation=act)(merged)
merged = Dropout(rate_drop_dense)(merged)
merged = BatchNormalization()(merged)

final = Dense(1, activation='sigmoid', name='main_output')(merged)

train = aux_train.as_matrix()

model = Model(input=[sequence_1_input,sequence_2_input,auxiliary_input], output=[final,auxiliary_output])
model.compile(loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'}, optimizer='nadam', metrics=['acc'], loss_weights=[1., 0.2])

hist = model.fit({'input1': data_1, 'input2': data_2, 'aux_input': train}, {'main_output':labels, 'aux_output':labels}, validation_split=VALIDATION_SPLIT, nb_epoch=50, batch_size=1024, shuffle=True,class_weight=class_weight,callbacks=[early_stopping, model_checkpoint])"
9328,Error in `python`: free(): invalid pointer,"TensorFlow Version: 1.0 and 1.0.1 (whl package)
Kubernetes Version: 1.5.1
Docker Version: 1.12.5
Container OS: ubuntu 14.04

I run tensorflow applications, say mnist_replica.py, in the kubernetes cluster and this error occured everytime when finishing the whole train step.

I attached the log of mnist_replica.py as below:
```
1492616963.574406: Worker 0: training step 5045 done (global step: 9999)
1492616963.583257: Worker 0: training step 5046 done (global step: 10001)
Training ends @ 1492616963.583282
Training elapsed time: 54.435048 s
After 10000 training step(s), validation cross entropy = 1170.07
*** Error in `/usr/bin/python': free(): invalid pointer: 0x0000000001e16c50 ***
```
And everything goes well when I run the mnist_replica.py in a physical machine with RHEL 7.0. I Guess the problem is that your google's environment is different with me. So the whl package that you compiled can not run well in the ubuntu 14.04 container, especially when it comes to the C program calling Python program "
9326,Update op_def_registry.py,"I am hoping that you can make an update to tensorflow/python/framework/op_def_registry.py (https://github.com/tensorflow/tensorflow/pull/9235/commits/133debe1e805e8d2a78600a9d5014900d429479c). 

I discovered this issue when I was building a seq2seq model with attention. Specifically, I believe the issue stems from tf.contrib.seq2seq.prepare_attention() (https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/prepare_attention) because the error message is: ""ValueError: No op named attn_add_fun_f32f32f32 in defined operations"" when I use ""bahdanau"" as my attention_option. When I used ""luong"" for the attention_option, the error is: ""ValueError: No op named attn_mul_fun_f32f32 in defined operations"".

This issue was also brought up here: http://stackoverflow.com/questions/42494695/tf-train-import-meta-graphmodel-meta-cannot-handle-seq2seq-models-with-atten. However, with my issue, I was using python3. 

Thanks for your help!"
9325,Cannot find python and other modules,"When I am running the code with `tf.python.framework.tensor_shape.scalar()` , I get the error message `AttributeError: 'module' object has no attribute 'python'`


### Source Code / Logs

Given below are minimum reproducible examples. 

```
(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.python'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'python'
```

This works
```
(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.contrib'
```

Others donot work
```
(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.core'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'core'
```

```
(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.examples'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'examples'
```

```
(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.include'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'include'
```

```
(tf1_0rc1_cpu) $python -c'import tensorflow as tf; tf.tools'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'tools'
```

But when I also tried importing python module. 

```
(tf1_0rc1_cpu) $python -c'import tensorflow.python'
```



### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: MacOS Sierra 
- *TensorFlow installed from (source or binary)?*:Binary 
- *TensorFlow version* (use command below): ('v1.0.0-65-g4763edf-dirty', '1.0.1')
- *Bazel version (if compiling from source)*: n/a
- *CUDA/cuDNN version*: release 8.0, V8.0.61
- *GPU Model and Memory*:NVIDIA GeForce GT 650M 1024 MB
- *Exact command to reproduce*:python -c ""import tensorflow as tf; tf.python""

"
9324,Tensorflow build error: not able to find ar in the compiler,"I'm trying to build Tensorflow from source, and I follow the instruction here:
https://gist.github.com/taylorpaul/3e4e405ffad1be8355bf742fa24b41f0#file-buildtf-sh-L118

But I fail to build it, and below are the command and error info. Could any one help me out?

```
$ bazel build -c opt --config=cuda --genrule_strategy=standalone --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package
```
```
WARNING: Output base '/home/xruan/.cache/bazel/_bazel_xruan/b83ca1b6fcc10c08548ef5b8ff5c75d2' is on NFS. This may lead to surprising failures and undetermined behavior.
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /home/xruan/tmp/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /home/xruan/tmp/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/xruan/tmp/tensorflow/tensorflow/core/BUILD:1268:1: Linking of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: ar failed: error executing command /opt/gcc/4.9.2/bin/ar @bazel-out/host/bin/tensorflow/core/liblib_hash_crc32c_accelerate_internal.a-2.params: com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
process-wrapper: execvp(""/opt/gcc/4.9.2/bin/ar"", ...): No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2.925s, Critical Path: 0.25s
```


------------------------

### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:No
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:Centos 6.5 Cluster
- *TensorFlow installed from (source or binary)?*:source
- *TensorFlow version* (use command below):r1.1
- *Bazel version (if compiling from source)*:0.4.5
- *CUDA/cuDNN version*:8.0
- *GPU Model and Memory*:GTX1080

"
9322,TensorFlow 60-80% slower than PyTorch on training Wide ResNet,"cc @tfboyd

From https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-295502315

On an AWS p2.xlarge, using the `tensorflow/tensorflow:1.0.1-devel-gpu` Docker image as a base, I see ~270 ms per epoch while training a WRN-16-4 without dropout on CIFAR-10.

Using a PyTorch implementation from https://github.com/xternalz/WideResNet-pytorch, I see instead ~150 ms per epoch for the same.

My implementation of Wide ResNets uses NCHW and fused batch norm. It does use `feed_dict` for data loading, but I've observed with `nvidia-smi` that my GPU utilization stays near 100%.

-----

To reproduce:

- Clone https://github.com/4Catalyzer/dl-papers, and go to that directory.
- Check out the [`benchmark`](https://github.com/4Catalyzer/dl-papers/tree/benchmark) branch.
- Build the Docker image, which is based on the Docker hub image above:
```
$ docker build -t dl-papers .
```
- Run the Docker image using NVIDIA Docker:
```
$ nvidia-docker run --rm -it dl-papers /bin/bash
```
- Run the TF WRN-16-4 training:
```
# python -m dl_papers.wide_resnet.train cifar10
```
- Observe the logged batch timings, then kill the process.
- In the same Docker container up the PyTorch Wide ResNet example:
```
# cd ..
# pip install http://download.pytorch.org/whl/cu80/torch-0.1.11.post5-cp27-none-linux_x86_64.whl
# pip install torchvision tensorboard_logger
# git clone https://github.com/xternalz/WideResNet-pytorch.git
# cd WideResNet-pytorch
```
- Run PyTorch training:
```
# python train.py --dataset cifar10 --layers 16 --widen-factor 4 -p 1
```
- Observe logged batch timings."
9321,Maximum points displaying on embedding,"Hi, 
I got a embedding file with 1.5 million points, its that possible to show all 1.5 million points instead of the first 100 thousand points only? I have been asking around Stackoverflow but no one can answer that question. Trying to check all those documentation but dosent help at all.
"
9320,Don't work. Please fix your install script.,"Please go to Stack Overflow for help and support. http://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

1. It must be a bug or feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g. fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version* (use command below):
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

You can collect some of this information using our environment capture script https://github.com/tensorflow/tensorflow/blob/master/tools/
You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```


### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9319,[feature] Mobile Integration with NNPACK,"Caffe2 use can use [NNPACK](https://github.com/Maratyszcza/NNPACK) for [which it says](http://caffe2.ai/docs/mobile-integration.html#null__performance-considerations):
>NNPACK, which specifically optimizes convolutions on ARM

>Currently Caffe2 is optimized for ARM CPUs with NEON (basically any ARM CPU since 2012). Perhaps surprisingly, ARM CPUs outperform the on-board GPUs (our NNPACK ARM CPU implementation outperforms Apple’s MPSCNNConvolution for all devices except the iPhone 7). 

>For a convolutional implementation, it is recommended to use NNPACK since that’s substantially faster (~2x-3x) than the standard im2col/sgemm implementation used in most frameworks. 

The readme for NNPACK lists Tensorflow as a framework that could potentially use it, though [that has not yet happened](https://github.com/Maratyszcza/NNPACK/issues/1).

I believe that TF also avoids using the im2col/sgemm approach on mobile and instead uses the Eigen TensorConvolution. It would be good to benchmark these two options against each other and see if TF performance can be improved by using the `NNPACK` conv instead of the eigen conv. There is an open ticket to do this benchmarking: https://github.com/Maratyszcza/NNPACK/issues/30.

As a feature I suggest offering an `NNPACK` backed kernel to allow comparing vs Eigen."
9318,Not all image ops accept image tensors with batch dimension,"It appears that only some of the image ops (e.g. `tf.image.random_saturation()`) only accept single images (rank-3 tensors), while others allow batches of images (rank-4 tensors). Should this be made more consistent so that all image ops allow for higher-rank tensors? There doesn't seem to be much about this in the API documentation (some ops just say that the last dimension needs to be 3).

### System Information
- *Have I written custom code?*: Yes
- *OS Platform and Distribution*: Ubuntu 16
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: 1.0.1
- *Bazel version (if compiling from source)*: N/A
- *CUDA/cuDNN version*: N/A
- *GPU Model and Memory*: N/A
- *Exact command to reproduce*:
```python
import tensorflow as tf
images = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='images')
# This is OK
x = tf.image.random_contrast(images, lower=0.5, upper=1.0)
# Throws an exception because `images` is rank-4
x = tf.image.random_saturation(images, lower=0.5, upper=1.0)
```"
9317,Explain what tf.nn.softplus does to integers,"[`tf.nn.softplus`](https://www.tensorflow.org/api_docs/python/tf/nn/softplus) computes `log(1 + exp(x))`.  Naively, I wouldn't expect this to work for integers, but it does.  On integers, it seems to degenerate to a poorly named version of `tf.relu`: it computes `max(0, x)`.

We probably can't eliminate the integer versions for backward compatibility reasons, but we should at least explain what they do."
9316,MultiRNNcell expected state to tuple but its a tensor,"i have define my lstm_cell as 

`def lstm(state, input_data, num_steps, hidden_size, num_layers, name):`
   ` # Input: (B, T, N) `
     `with tf.variable_scope(name) as scope: `
        ` multi_lstm = MultiRNNCell([BasicLSTMCell(hidden_size)] * num_layers) `
         `outputs = [] `
         `for t in range(num_steps): `
             `output, state = multi_lstm(input_data[:, t, :], state) `
            ` output = batch_normalization(output, [0, 1], ""batch"") `
            ` outputs.append(output) `
            ` scope.reuse_variables() `
         `return outputs`

Now after defining my inputs for lstm_cell as
`lstm_input = tf.reshape(c13, [B, M, -1])`
`lstm_state = tf.reduce_mean(lstm_input, [1])`

 and passing my values to lstm() , i am getting the following error 
` Expected state to be a tuple of length 6, but received: Tensor(""Mean:0"", shape=(25, 1568), dtype=float32)`"
9314,tf.get_collection documentation: argument description is confusing,"From https://www.tensorflow.org/api_docs/python/tf/get_collection:

""Items without a name attribute are never returned if a scope is supplied and the choice or re.match means that a scope without special tokens filters by prefix.""

What does this mean? Is there a typo here?"
9313,"`Evaluable` docs: name, checkpoint_path, and hooks should be new bullets.","See https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Evaluable - final params for evaluate() are not bullets, making reading the documentation less readable. I've seen this in other docs too (can comment if I come across more of them).

I wonder if the parser has some bug that causes it to not bullet-ify some params for functions."
9312,Typo in seq2seq.attention_wrapper.py,"Hi,
 I think there is a small typo in contrib.seq2seq.attention_wrapper.py, would someone like to check it?
code url: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L471]
I guess it should be _probability_fn_ rather than _cell_input_fn_ to be checked.

Thanks."
9310,Is tf.train.import_meta_graph() contextual with tf.global[local]_variables_initializer() ?,"**I can use these pieces of codes to continue my training with pre-trained model**:

     tf.reset_default_graph() 
     new_saver = tf.train.import_meta_graph(""xxx.meta"")
     new_saver.restore(sess, ""xxx.ckpt-yyy"")

Here the 'tf.reset_default_graph() is necessary'  to solve the 'redefine of ops' issues.But,**when I  launched  forward pass(in another .py file) like** :

     tf.reset_default_graph() 
     new_saver = tf.train.import_meta_graph(""xxx.meta"")
     new_saver.restore(sess, ""xxx.ckpt-yyy"")
     images_placeholder = tf.get_default_graph().get_tensor_by_name(""image_batch:0"")
     embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")

**with 'tf.reset_default_graph()' I got** :
""Cannot interpret feed_dict key as Tensor: The name 'save/Const:0' refers to a Tensor which does not exist. The operation, 'save/Const', does not exist in the graph""
**without 'tf.reset_default_graph()'  and with 'tf.global[local]_variables_initializer()' before or without it** like:

    sess.run(tf.global_variables_initializer())
    sess.run(tf.local_variables_initializer())
     new_saver = tf.train.import_meta_graph(""xxx.meta"")
     new_saver.restore(sess, ""xxx.ckpt-yyy"")
     images_placeholder = tf.get_default_graph().get_tensor_by_name(""image_batch:0"")
     embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")
 #Without initializer
 #sess.run(tf.global_variables_initializer())
 #sess.run(tf.local_variables_initializer())
     new_saver = tf.train.import_meta_graph(""xxx.meta"")
     new_saver.restore(sess, ""xxx.ckpt-yyy"")
     images_placeholder = tf.get_default_graph().get_tensor_by_name(""image_batch:0"")
     embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")

I got : ""**FailedPreconditionError: Attempting to use uninitialized value...**"".But like:
   new_saver = tf.train.import_meta_graph(""xxx.meta"")
   new_saver.restore(sess, ""xxx.ckpt-yyy"")
    sess.run(tf.global_variables_initializer())
    sess.run(tf.local_variables_initializer())
   images_placeholder = tf.get_default_graph().get_tensor_by_name(""image_batch:0"")
   embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")
I got neither warnings nor errors info,but the result is all features of embeddings is 0.Maybe 'tf.global[local]_variables_initializer()' has cleared the loaded weights ?
After that I **used the  frozen graph which was produced by pre-trained model to launch forward,like**:
 with tf.Graph().as_default():
        graph_def_ = graph_pb2.GraphDef()
        print('Model directory: %s' % os.path.expanduser(args.modelpb_file))
        with open(os.path.expanduser(args.modelpb_file),'rb') as f:
             graph_def_.ParseFromString(f.read())
             _ = importer.import_graph_def(graph_def_,name="""")
        with tf.Session() as sess:         
            images_placeholder = tf.get_default_graph().get_tensor_by_name(""image_batch:0"")
            embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")
I still got the ""**FailedPreconditionError: Attempting to use uninitialized value...**"" issues.
Really confusing,who can help ?


"
9309,Tensorflow slim - TypeError: softmax_cross_entropy() got an unexpected keyword argument 'weight' ,"Hi ,

I am using slim/train_image_classifier.py to train inception V1 model from scratch on my own dataset and fine-tuning inception V1 model from the link: https://github.com/tensorflow/models/blob/master/slim/README.md#Pretrained

**System Information:**
RAM : 4GB
TensorFlow Version : 1.0
OS  : Linux 14.04 

I am using following command for training from scratch but ended up in Error


```
python train_image_classifier.py     
     --train_dir=${TRAIN_DIR}
     --dataset_name=mydataset 
     --dataset_split_name=train
     --dataset_dir=${DATASET_DIR}
     --model_name=inception_v1 

```

**Note:** Here mydataset is same as flower.py except:

SPLITS_TO_SIZES = {'train': 4310. 'validation': 350}


**Error:**

```
Traceback (most recent call last):
  File ""train_image_classifier.py"", line 585, in <module>
    tf.app.run()
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train_image_classifier.py"", line 482, in main
    clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])
  File ""/home/purushoth/Downloads/models-master/slim/deployment/model_deploy.py"", line 195, in create_clones
    outputs = model_fn(*args, **kwargs)
File ""train_image_classifier.py"", line 476, in clone_fn
    logits, labels, label_smoothing=FLAGS.label_smoothing, weight=1.0)
 File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 117, in new_func
    return func(*args, **kwargs)
TypeError: softmax_cross_entropy() got an unexpected keyword argument 'weight'
```


I have tried 
      
- upgrading **train_image_classifier.py** file 

- fine - tuning the inception V1 model from existing checkpoint 
  
but still I am facing same error.

Am I doing something wrong ?? Thanks for any help.
"
9308,Trying to use tensorflow to classify multi-class data,"tensorflow is a new tool for me and this is my first try. I'm trying to train my model using jupyter notebook in 'mac' for a Multi-class problem (Bike Sharing Demand | Kaggle). I am using '1.0.1' tensorflow version and Python 3.5. I have this error: 
```
ValueError                                Traceback (most recent call last)
<ipython-input-364-b19ec441d9ef> in <module>()
      5 tf.global_variables_initializer().run()
      6 for _ in range(1000):
----> 7     sess.run(train_step, feed_dict={x: X, y_: Y})

ValueError: Cannot feed value of shape (10, 10886) for Tensor 'Placeholder_66:0', which has shape '(?, 10)'
```

My Feature size= (10886,10) & Label size= (10886,1).

My goal is to predict how many customers will rent the bike per day. I found 822 different number in the labels. I used this number to fix number of classes to fit the code. I am wondering if I did something wrong in the code or tensorflow doesn't work for this kind of problems?  

you can find my code written below:

```
X = np.array(train[['season','weather','temp','weekday','month','humidity','new_windspeed','hours','year','atemp']]) #My train input features
X = np.transpose(X)
Y = np.array(train['count']) # label
Y=np.reshape(Y,(1,10886))
learning_rate= 0.000001
training_epochs= 2000
display_step= 50
n_samples= Y.size
x= tf.placeholder(tf.float32,[None,10])
W = tf.Variable(tf.zeros([10,822])) 
b = tf.Variable(tf.zeros([822]))
y = tf.nn.softmax(tf.matmul(x,W)+b)
y_ = tf.placeholder(tf.float32, [None,822])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))
train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)
sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
for _ in range(1000):
    sess.run(train_step, feed_dict={x: X, y_: Y})
```"
9307,Segmentation fault in tensorflow::FileSystemRegistryImpl::Register,"Syntaxnet package was built, tf package ver 1.01 was installed from repo by pip as dependency. Fortunately tf installed following these instructions https://www.tensorflow.org/versions/r0.10/get_started/os_setup#create_the_pip_package_and_install works fine.
```
[New LWP 31764]
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
Core was generated by `python2 -c from syntaxnet import load_parser_ops'.
Program terminated with signal SIGSEGV, Segmentation fault.
#0  0x00007f3303cf0d47 in std::_Hash_bytes(void const*, unsigned long, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
(gdb) bt
#0  0x00007f3303cf0d47 in std::_Hash_bytes(void const*, unsigned long, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#1  0x00007f33065f509c in tensorflow::FileSystemRegistryImpl::Register(std::string const&, std::function<tensorflow::FileSystem* ()>) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#2  0x00007f33065f26b3 in tensorflow::Env::RegisterFileSystem(std::string const&, std::function<tensorflow::FileSystem* ()>) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007f3328d327b5 in _GLOBAL__sub_I_env.cc () from /usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so
#4  0x00007f3332df04ea in call_init (l=<optimized out>, argc=argc@entry=3, argv=argv@entry=0x7ffe61a27428, env=env@entry=0x265a8b0) at dl-init.c:72
#5  0x00007f3332df05fb in call_init (env=0x265a8b0, argv=0x7ffe61a27428, argc=3, l=<optimized out>) at dl-init.c:30
#6  _dl_init (main_map=main_map@entry=0x2a41360, argc=3, argv=0x7ffe61a27428, env=0x265a8b0) at dl-init.c:120
#7  0x00007f3332df5712 in dl_open_worker (a=a@entry=0x7ffe61a263e0) at dl-open.c:575
#8  0x00007f3332df0394 in _dl_catch_error (objname=objname@entry=0x7ffe61a263d0, errstring=errstring@entry=0x7ffe61a263d8, mallocedp=mallocedp@entry=0x7ffe61a263cf, 
    operate=operate@entry=0x7f3332df5300 <dl_open_worker>, args=args@entry=0x7ffe61a263e0) at dl-error.c:187
#9  0x00007f3332df4bd9 in _dl_open (file=0x7f332e1634cc ""/usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so"", mode=-2147483646, 
    caller_dlopen=0x7f33065fa9ea <tensorflow::internal::LoadLibrary(char const*, void**)+26>, nsid=-2, argc=<optimized out>, argv=<optimized out>, env=0x265a8b0)
    at dl-open.c:660
#10 0x00007f33325f6f09 in dlopen_doit (a=a@entry=0x7ffe61a26610) at dlopen.c:66
#11 0x00007f3332df0394 in _dl_catch_error (objname=0x252e0d0, errstring=0x252e0d8, mallocedp=0x252e0c8, operate=0x7f33325f6eb0 <dlopen_doit>, args=0x7ffe61a26610)
    at dl-error.c:187
#12 0x00007f33325f7571 in _dlerror_run (operate=operate@entry=0x7f33325f6eb0 <dlopen_doit>, args=args@entry=0x7ffe61a26610) at dlerror.c:163
#13 0x00007f33325f6fa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87
#14 0x00007f33065fa9ea in tensorflow::internal::LoadLibrary(char const*, void**) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#15 0x00007f33065f9b97 in tensorflow::(anonymous namespace)::PosixEnv::LoadLibrary(char const*, void**) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#16 0x00007f33064f6f93 in tensorflow::LoadLibrary(char const*, void**, void const**, unsigned long*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#17 0x00007f3304e11e67 in TF_LoadLibrary () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#18 0x00007f3304d1206a in _wrap_TF_LoadLibrary () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so
#19 0x00000000004c468a in PyEval_EvalFrameEx ()
#20 0x00000000004c2765 in PyEval_EvalCodeEx ()
#21 0x00000000004ca8d1 in PyEval_EvalFrameEx ()
#22 0x00000000004c2765 in PyEval_EvalCodeEx ()
#23 0x00000000004c2509 in PyEval_EvalCode ()
#24 0x00000000004c061b in PyImport_ExecCodeModuleEx ()
#25 0x00000000004bd6ee in ?? ()
#26 0x00000000004afbad in ?? ()
#27 0x00000000004af7e9 in PyImport_ImportModuleLevel ()
#28 0x00000000004b0f78 in ?? ()
#29 0x00000000004b0cb3 in PyObject_Call ()
#30 0x00000000004ce5d0 in PyEval_CallObjectWithKeywords ()
#31 0x00000000004c6ed6 in PyEval_EvalFrameEx ()
#32 0x00000000004c2765 in PyEval_EvalCodeEx ()
#33 0x00000000004c2509 in PyEval_EvalCode ()
#34 0x0000000000521186 in PyRun_StringFlags ()
#35 0x0000000000521dfc in PyRun_SimpleStringFlags ()
#36 0x000000000049de94 in Py_Main ()
#37 0x00007f333281a830 in __libc_start_main (main=0x49dab0 <main>, argc=3, argv=0x7ffe61a27428, init=<optimized out>, fini=<optimized out>, 
    rtld_fini=<optimized out>, stack_end=0x7ffe61a27418) at ../csu/libc-start.c:291
#38 0x000000000049d9d9 in _start ()
```"
9306,AttributeError: module 'tensorflow' has no attribute 'get_default_graph',"**Error Log:**
model = Sequential()

Traceback (most recent call last):

  File ""<ipython-input-50-24a4d47a09aa>"", line 1, in <module>
    model = Sequential()
...
/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 47, in get_uid
    if graph not in _GRAPH_UID_DICTS:

**_AttributeError: module 'tensorflow' has no attribute 'get_default_graph'_**


------------
**Versions:**
!pip3 show tensorflow
Name: tensorflow
Version: 1.0.1
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages
Requires: numpy, protobuf, six, wheel

------------
!pip3 show keras
Name: Keras
Version: 2.0.3
Summary: Deep Learning for Python
Home-page: https://github.com/fchollet/keras
Author: Francois Chollet
Author-email: francois.chollet@gmail.com
License: MIT
Location: /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages
Requires: six, theano, pyyaml

------------
**OS:**:  Mac OS
------------

I couldnt find any solution to it in ""existing issues"" nor on ""Stackoverflow"".
Any suggestions?"
9304,Problem displaying Chinese character in Tensorboard Embedding,"I am trying to display an embedding but what its show is all garbled. May i know does Tensorboard Embedding able to display Chinese character?
May i know its that possible to display more than 100K point? If yes, how to i do the configuration?
![default](https://cloud.githubusercontent.com/assets/27762422/25168360/cf775996-2515-11e7-8fa1-326d06e6d045.PNG)
"
9303,Import additional RNNCells in tf.contrib.rnn.__init__.py ,"Some RNNCells, like IntersectionRNNCell, NASCell, are implemented in tf.contrb.rnn.python.ops.rnn_cell. I would like to try these cells but found that these can't be used as the same way as LSTMCell, which I can import by ```from tf.contrib.rnn import LSTMCell```. I checked the code found that these cells are not imported by ```tf.contrib.rnn.__init__.py ```. 

Is there any way to try these cells? Or is it possible to import these cells in ```tf.contrib.rnn.__init__.py ```.

Thanks."
9302,TensorFlow reverting to GPU on a CPU machine on most recent nightly build,"I'm running tensorflow on windows. I continue to produce these errors around CUDA libraries and cuDNNs ,but I don't have a GPU and didn't install a GPU version of TF. 

I installed the latest nightly build of TF from jenkins (apr 17) but when that one failed on me I tried to pip3 uninstall and revert to [this one](https://ci.tensorflow.org/view/Nightly/job/nightly-win/DEVICE=cpu,OS=windows/134/) to no success.

I was up and running last night thanks to a solution on github from Derek, but cannot stop reproducing this CUDA error after playing around with the path variables in pycharm.


- Error is reproduced on both custom code and standard wide_n_deep TensorFlow examples
- Windows 10 64; Python 35
- TF installed from nightly build
- TF versions 1.1.0 and 1.0.1
- I have no GPU
- C:\Users\me>C:\Users\me\AppData\Local\Programs\Python\Python35\python.exe C:\Users\me\Desktop\wide_n_deep --model_type =""wide_n_deep""

### Source Code / Logs
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cublas64_80.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_blas.cc:2294] Unable to load cuBLAS DSO.
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cudnn64_5.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:3517] Unable to load cuDNN DSO
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cufft64_80.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_fft.cc:344] Unable to load cuFFT DSO.
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library nvcuda.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_diagnostics.cc:165] hostname: DESKTOP-HMIARON
Traceback (most recent call last):
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Larriva\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""C:\Users\Larriva\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Larriva\Desktop\wnd2.py"", line 15, in <module>
    import tensorflow as tf
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Larriva\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\Larriva\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""C:\Users\Larriva\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow'


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
9301,Quantized graph fails to work on NVIDIA Jetson TX1 architecture although it worked on a normal PC?,"### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
No
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:
Ubuntu 16.04 LTS on NVIDIA Jetson TX1 (Linux for Tegra 24.1)
- *TensorFlow installed from (source or binary)?*:
Compiled from source and installed via this wheel available here: https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hack
- *TensorFlow version* (use command below):
1.0 Alpha
- *CUDA/cuDNN version*:
8.0/5.1
- *GPU Model and Memory*:
Tegra X1, 4GB

### Describe the problem clearly
When I ran a quantized graph on my laptop, it works quite as expected (just slightly lower accuracy compared to the frozen graph, while much lower size). However, when I transferred the exact same quantized graph to run on an Jetson TX1, the file gives me a highly inaccurate class prediction, at a 100% probability for the random class. On the other hand, when I tried to perform inference from the frozen graph (from which the quantized graph was derived) on both my laptop and the Jetson TX1, I got the exact same answers as expected.

So I suspected it could have been an issue of data transfer causing the file to be slightly corrupted. I checked the files byte by byte at all points of transfer (from my laptop to memory stick, then memory stick to the Jetson), but I found the files are exactly the same. This is the command I used to check: `cmp $old_file $new_file || echo ""different files""`.

Thus, I am suspecting it could be an issue of how tensorflow performs on the Jetson TX1 ARM architecture (aarch64). Is there anyway to verify this, and if it is indeed a performance issue on an ARM architecture, is there a way to resolve this?

Thank you for your help.
"
9299,Making TF consume least GPU memory as default,"Hi there, 

By default, TF takes all GPU memory available on the machine, even if very few memory are actually needed. This would prevent running other processes and lead to Out of Memory errors. 

Although we can use GPU options to set the GPU amount, but sometimes we are running others' codes and do not want to bother or forget to add GPU configurations to make it consumes less memory. Consider most people are using shared machines, it would bring difficulties for other users of GPU server very often.

The default configuration of using all GPU memory may have some benefits that I am not totally aware of, but I wonder if the benefits outweigh the drawbacks of doing that. Therefore, I wonder if TF could make it consume least GPU memory as default. "
9298,[cmake/feature request] provide USE_SYSTEM_xxx flags to skip dependency builds,"Tensorflow's cmake build will download and compile all of its dependency. Julia[1] does something similar to maximize its performance. However Julia provided some optional flags such as `USE_SYSTEM_FFTW` so users can compile Julia against the FFTW library provided by system package manager (e.g. `apt/dpkg`). I wish Tensorflow's cmake build could provide similar options to skip building its dependencies and just use the system provided one.

[1] https://github.com/JuliaLang/julia/blob/master/Makefile#L243"
9297,Retrieve a graph or model without copying the graph construction code,"Hi,

Let's say I have defined a graph and trained the weights in file ""myTrain.py"" and I saved the model using `tf.train.saver()` in a directory.

I want to have a tester file (let's name it ""myTest.py"") which doesn't contain the definition of the graph, but be able to load the saved graph and also the trained weights and I can use it as I was using in ""myTrain.py"". For example, pass a new batch with `feed_dict` and get the desired outputs.

I know there are many sources about how to save and restore the graph, but all of them are confusing or they have the definition of the graph as a piece of code written before loading the saved model which I believe shouldn't be needed.

I appreciate any help.

Thanks
"
9296,Tensorflow 1.1 build breaks on CUDA code,"### System Information
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: Linux Ubuntu 17.04
- *TensorFlow installed from (source or binary)?*: source
- *TensorFlow version* (use command below): v1.1.0-rc2
- *Bazel version (if compiling from source)*: 0.4.5
- *CUDA/cuDNN version*: 8.0/5.1.5
- *GPU Model and Memory*:M2000M

### Describe the problem clearly

Fails to build after upgrade to Ubuntu 17.04 (from 16.10), using the same compiler (gcc 5.4.1) and compiler flags. 

Build command is `bazel build --config=opt --config=cuda //tensorflow/
tools/pip_package:build_pip_package`

I've tried compiling with the default -march=native and -march=core-avx-i as well as using command given [here](http://stackoverflow.com/a/41584791)

### Source Code / Logs
`From Compiling tensorflow/core/kernels/fake_quant_ops_gpu.cu.cc:
/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9218): error: argument of type ""const void *"" is incompatible with parameter of type ""const float *""`

Same error is then repeated for different parameter types (ex. const long/int *)
"
9294,Tutorial has error: Recurrent Neural Networks,"Tutorial URL: https://www.tensorflow.org/tutorials/recurrent
I'm going through the tutorial listed above and I think there is a mistake in the very first code example:
```
lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)
# Initial state of the LSTM memory.
state = tf.zeros([batch_size, lstm.state_size])
```
An error is reported for the third line:
```
ValueError: setting an array element with a sequence.
```
If one prints the `lstm.state_size` object (where say, lstm_size = 50) one finds:
```
LSTMStateTuple(c=50, h=50)
```
I'm guessing this should be:
```
lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)
# Initial state of the LSTM memory.
state = tf.zeros([batch_size, lstm_size])
```
But frankly there are numerous other errors in this tutorial as well, so I'm not sure.  I will continue to report them as I find them.
Version: tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl
Running on Ubuntu 14.04"
9292,xorshift128+ version of (stateless) random ops,"Currently, TensorFlow's random numbers use the Philox counter mode generator, which is extremely easy to parallelize on both CPU and GPU.  This applies to both the normal stateful ops and the new [`tf.contrib.stateless`](https://github.com/tensorflow/tensorflow/commit/cc45456e4ad0eff16127d1727d0cf48afb71ca0e) versions with custom seeding.

xorshift128+ is a simpler generator that could conceivably speed up random number generation.  Unfortunately, it is not a counter mode generator, and is thus difficult to parallelize or use safely in a random access setting.

Until now!  Commit https://github.com/girving/tensorflow/commit/60abb26f528f53e7692edb3e89489a69b59ae83e on branch https://github.com/girving/tensorflow/tree/xorshift implements random access into the xorshift128+ generator in a reasonably efficient manner, using some finite field machinery.  Specifically, jumps in xorshift128+ are represented as elements of the finite field GF(2^128), composed to produce other jumps, then mapped through linear maps to produce xorshift128+ values.

However, the code is a proof of concept.  A decent amount of further work would have to be done to get committed to TensorFlow.  In particular, the parallelism code on both CPU and GPU would have to be written, by computing one jump per thread of execution (many jumps can be computed more cheaply vs. one at a time).  The current code is also nonportable: it assumes special  instructions for carryless multiplication of polynomials over GF(2).  These instructions are available on recent Intel and AMD CPUs, but a slow path would need to be written to handle everything else.

Also, whether the result would actually be faster is an open question.

I don't have time to do the remaining work, so I am leaving this here as a project in case someone wants to take it on with my help."
9288,Java API - sophisticated example,"Dear All,

I have seen the [example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java) for importing model created and trained in Python imported into Java code and used for predictions.  However, I had some problems understanding what was actually going on especially in [this block](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java#L92-L101) and [this block](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/src/main/java/org/tensorflow/examples/LabelImage.java#L156-L207). Would it be possible to get some more documentation on it?
Moreover, I know the Java API is still under construction. However, I would be interested in if it is possible to see some more sophisticated examples, if it is possible including:

- importing model into Java and then performing training on the model

- implementing, training, evaluating, saving, loading a model from scratch in Java

Thank you for any help!

Cheers,
Peter"
9285,TensorBoard filter regresson,"### System information

Docker image `tensorflow/tensorflow:nightly` (or 1.1.0rc2)

### Describe the problem

Start a tensorboard process

```
tensorboard --logdir /efs/log/atari
```

and try and filter. It does not have any effect.

![image](https://cloud.githubusercontent.com/assets/6200749/25130135/6499f98c-2441-11e7-8050-34cce130fef0.png)
"
9284,Broadcasting support in `tf.where`,"`tf.where` does not support broadcasting like its numpy equivalent at the moment. How easy would it be to add broadcasting? 

Here are some examples.

```python
condition = np.random.normal(0, 1, (3, 5, 1, 1)) < 0
x = np.zeros((7, 11))
y = np.ones((7, 11))

np.where(condition, x, y).shape  # (3, 5, 7, 11)
tf.where(condition, x, y)

>>> InvalidArgumentError: Shapes must be equal rank, but are 2 and 4 for 'Select_2' 
>>> (op: 'Select')  with input shapes: [3,5,1,1], [7,11], [7,11].
```

```python
condition = np.random.normal(0, 1, (3, 5, 1, 1)) < 0
x = np.zeros((1, 1, 7, 11))
y = np.ones((1, 1, 7, 11))

np.where(condition, x, y).shape  # (3, 5, 7, 11)
tf.where(condition, x, y)

>>> InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 1 and 3 
>>> for 'Select_3' (op: 'Select') with input shapes: [3,5,1,1], [1,1,7,11], [1,1,7,11].
```
"
9283,Save model every fixed number of steps with MonitoredTrainingSession,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 0.12
- **CUDA/cuDNN version**: 7.5 / 5.1
- **GPU model and memory**: GTX 1080

### Describe the problem

Is it possible to save model every fixed number of steps with MonitoredTrainingSession?
If not, would be happy to see it as a feature.
"
9282,Check failed: NDIMS == dims() (2 vs. 1),"I get the following error after building the graph of my NN. when I try to execute :

loss, _ = self._sess.run([self.loss_op, self.train_op], feed_dict=feed_dict)

I get this error :

`F tensorflow/core/framework/tensor_shape.cc:36] Check failed: NDIMS == dims() (2 vs. 1) Asking for tensor of 2 dimensions from a tensor of 1 dimensions`

I don't succeed to know to which part of the graph this error is related to ... Because, normaly the graph is build, so shapes should be correct ... are not ? 

I am using Tensorflow version 1.0.0 with python API.

It could be a bug according to the first reply here : http://stackoverflow.com/questions/43413293/tensorflow-check-failed-ndims-dims-2-vs-1"
9280,Cannot cross compile tf so to android with ndk-r14b,"Some basic infos:
1. Linux 4.10.10-1-ARCH #1 SMP PREEMPT Wed Apr 12 18:50:28 CEST 2017 x86_64 GNU/Linux
2. tensorflow-r1.1 source code
3. bazel 0.4.5
4. android-ndk-r14b
5. clang-3.9
6. gcc 6.3.1
WHEN I cross compile with :""bazel build //tensorflow/contrib/android: libtensorflow_inference.so --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a --verbose_failures""
I got an issue:
ERROR: /home/mae/tensorflow-r1.1/tensorflow/core/kernels/BUILD:3869:1: C++ compilation of rule '//tensorflow/core/kernels:android_tensorflow_kernels' failed: clang failed: error executing command 
  (cd /home/mae/.cache/bazel/_bazel_mae/991fa79c990635f28b632a15ab1879cf/execroot/tensorflow-r1.1 && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/bin:/opt/cuda/bin:/usr/lib/jvm/default/bin:/usr/bin/site_perl:/usr/bin/vendor_perl:/usr/bin/core_perl \
  external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -fpic -ffunction-sections -funwind-tables -fstack-protector-strong -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -no-canonical-prefixes -fno-integrated-as -target armv7-none-linux-androideabi '-march=armv7-a' '-mfloat-abi=softfp' '-mfpu=vfpv3-d16' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/bin/tensorflow/core/kernels/_objs/android_tensorflow_kernels/tensorflow/core/kernels/meta_support.d '-frandom-seed=bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/bin/tensorflow/core/kernels/_objs/android_tensorflow_kernels/tensorflow/core/kernels/meta_support.o' -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles -iquote external/protobuf -iquote bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/local_config_sycl -iquote external/gemmlowp -iquote bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/gemmlowp -isystem external/protobuf/src -isystem bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/genfiles/external/eigen_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions '-mfpu=neon' '-std=c++11' -DTF_LEAN_BINARY -O2 '--sysroot=external/androidndk/ndk/platforms/android-16/arch-arm' -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -c tensorflow/core/kernels/meta_support.cc -o bazel-out/arm-linux-androideabi-clang3.8-v7a-gnu-libstdcpp-py3-opt/bin/tensorflow/core/kernels/_objs/android_tensorflow_kernels/tensorflow/core/kernels/meta_support.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from tensorflow/core/kernels/meta_support.cc:18:
In file included from ./tensorflow/core/kernels/meta_support.h:23:
In file included from external/gemmlowp/meta/transform_kernels.h:239:
external/gemmlowp/meta/transform_kernels_arm_32.h:7925:7: error: inline assembly requires more registers than available
      ""ldr r0, %[input_range_min]\n""
      ^
external/gemmlowp/meta/transform_kernels_arm_32.h:5506:7: error: inline assembly requires more registers than available
      ""ldr r0, %[input_range_min]\n""
      ^
2 errors generated.
Target //tensorflow/contrib/android: libtensorflow_inference.so failed to build

Tensorflow works well on my PC ,but I need to port my codes to android proj.
Anyone help ? Thanks a lot.





"
9278,Ability to Create New Device Context (GPU),"If I destroyed GPU context for any reason and tried to start new tensorflow session I got this error `CUDA_ERROR_CONTEXT_IS_DESTROYED ` and notebook kernel crashes. So, it will be a nice feature for python users if they can create a new context for tensorflow if one is destroyed."
9275,incorrect datasets path in tutorial: tf.contrib.learn.datasets.base.load_csv_with_header,"The path for loading the iris dataset "" tf.contrib.learn.datasets.base.load_csv_with_header"" in the tutorial is incorrect:

`# Load datasets.
  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
      filename=IRIS_TRAINING,
      target_dtype=np.int,
      features_dtype=np.float32)
  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
      filename=IRIS_TEST,
      target_dtype=np.int,
      features_dtype=np.float32)
`

I believe it should be something closer to the README here:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/README.md

`import tensorflow.contrib.learn.python.learn as learn
from sklearn import datasets, metrics

iris = datasets.load_iris()`"
9273,[Docs] Update wheels URLs to match latest TensorFlow release (1.1.0),The wheels available on the website are from the previous release (1.0.1) which still contain OpKernels errors that are solved at head (as well as on 1.1.0) and can be ignored but are confusing users prompting repeated reports of this issue.
9272,[idea] new Op: Conv2DWithBiasActivation for Backends that Support Higher Level Op,"This is a [repost of the comment here](https://github.com/tensorflow/tensorflow/pull/8673#issuecomment-290722014):

Along the lines of [`MklConv2DWithBias`](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645), I suggest defining a new primitive Op, `Conv2DWithBiasActivation` that can be used to define kernels on platforms that support a higher level primitive conv-bias-acitivation unit.

As far as the (new) fused `Conv2D` Op that I am using for my BNNS implementation, I used the [MKL Conv2D Op](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/core/ops/nn_ops.cc#L2632-L2645) as a predicate. In that case Intel has defined a new Op that includes both the convolution Op and the BiasAdd Op. My Conv Op actually isn't pulling in just the activation function, rather, my Op and the MKL both have the bias add has been fused as well.

I understand that the primitive `Conv2D` op in TF does not currently handle activations or bias addition, but this op may be ""too primitive"". In fact cuDNN is now moving in the direction of fusing these three into one kernel (see: https://github.com/tensorflow/tensorflow/issues/8828). Perhaps, a different FusedConv2D Op should be added that can be used by not just BNNS but also cuDNN v6 and any other underlying platform implementations that can take advantage of doing all three ops together. This would be  along the lines of batch norm, which now offers a `fused` version of the Op to reduce the number of primitive Ops used.

Addendum
There are even more implementations that can benefit from fusing Conv-Bias-Activation. Others include:
* Metal Performance Shaders (https://github.com/tensorflow/tensorflow/issues/7958). Here it might be extra extra important because of 1. avoiding extra copies back and forth from GPU memory (ie using the tuned `MPSTemporary​Image` and 2. because MPS uses a very weird memory layout and ideally transposing to this only needs to be done once.
* MKL (as linked above, perhaps the MKL specific Op (`MklConv2DWithBias`) can be unified with this new Op.
* [cuDNN v6](https://github.com/tensorflow/tensorflow/issues/8828)

/CC @drpngx @petewarden @flx42 @gunan "
9270,SVM output layer in tensor flow,The SVM output layer has been shown to accelerate model training in [https://arxiv.org/pdf/1306.0239.pdf](https://arxiv.org/pdf/1306.0239.pdf).  Is the SVM output layer available as an alternative for `tf.nn.softmax` in tensorflow at this moment?
9264,"Install on Windows 10 not working on power shell, but cmd","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10 Pro Version 1607 amd64 
- **TensorFlow installed from (source or binary)**:
Install via native pip or anaconda via:
```
conda create -n tensorflow python=3.5
```
- **TensorFlow version (use command below)**:
As described in the get started page:
```
pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl
```
- **Bazel version (if compiling from source)**: - 
- **CUDA/cuDNN version**: - 
- **GPU model and memory**: - 
- **Exact command to reproduce**: - 
Follow the install instructions [1] on windows using the **power shell** or **git bash** (with or without admin rights)
1: https://www.tensorflow.org/install/install_windows

You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
```
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow'
```
### Describe the problem

### Source code / logs
On running the pip install command, the classic ""... wheel is not supported"" error comes up:
```
PS C:\Users\user> pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl
tensorflow-1.0.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.
```

Using the cmd, everything works just fine and i think, that a lot of people are having this problem out there right now, imho the install doc page must be updated to contain some warnings about this.

Oh and by the way: tensorflow is fucking amazing!
"
9263,import tensorflow Segmentation fault,"I get 'Segmentation fault' everytime when import tensorflow.
No matter which tf's version, or which numpy's version i try. Or even 'import numpy' at first.
My computer is CentOS6.5 with python 2.7.3.
Current tensorflow's version is 'https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp27-none-linux_x86_64.whl'.
BTW: it happends after i try to update my glibc. cause i met ""version `GLIBC_2.14' not found"" and ""version `GLIBC_2.16' not found"" before."
9262,Estimator numpy_input_fn doesn't work when reading input with pytables,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Relatively straightforward attempt at using estimator flow with `input_fn`
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Gentoo Linux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: b'v1.0.0-2171-gbaa85cb' 1.0.1
- **Bazel version (if compiling from source)**: 0.4.4-
- **CUDA/cuDNN version**: 8.0.61
- **GPU model and memory**: GTX 970 4GB
- **Exact command to reproduce**: 

Other stuff: Python 3.4, pytables 3.3.0, numpy 1.12.1, hdf5-1.8.18

### Describe the problem

I have an issue when reading multidimensional arrays from hdf5 file using pytables. I can fix the issue for myself locally by changing `_OrderedDictNumpyFeedFn` class (line 173 in my version) from 

```python
 column[integer_indexes]
```

to

```python
np.take(column, integer_indexes, axis=0)
```

### Source code / logs

Relevant bit of code:

```python
def make_input_fn(data, batch_size):
    input_features = {node.name: node for node in data.get_node('/x')}
    ys = data.get_node('/y')
    return numpy_input_fn(input_features, ys, batch_size=batch_size, num_epochs=5, shuffle=False, num_threads=1)

def main(unused_argv):
    model_fn = make_train_model(feat)
    config = learn.RunConfig(save_checkpoints_secs=60)
    est = learn.Estimator(
        model_fn=model_fn, model_dir=""data/tf/try1"", config=config
    )
    training_data = tables.open_file('data/hdf5/training.h5')
    train_in = make_input_fn(training_data, 256)
    est.fit(
        input_fn=train_in,
        steps=100
    )
    training_data.close()
```

Error I get:

```
INFO:tensorflow:Using config: {'_is_chief': True, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 60, '_environment': 'local', '_num_ps_replicas': 0, '_master': '', '_task_type': None, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_num_worker_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff377eaf550>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_evaluation_master': '', '_model_dir': None, '_save_summary_steps': 100, '_tf_random_seed': None, '_task_id': 0}
INFO:tensorflow:Create CheckpointSaverHook.
2017-04-17 10:05:38.231511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-04-17 10:05:38.231863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: GeForce GTX 970
major: 5 minor: 2 memoryClockRate (GHz) 1.4305
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.45GiB
2017-04-17 10:05:38.232016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-04-17 10:05:38.232048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-04-17 10:05:38.232081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)
INFO:tensorflow:Restoring parameters from data/tf/try1/model.ckpt-4
INFO:tensorflow:Error reported to Coordinator: <class 'ValueError'>, operands could not be broadcast together with shapes (256,) (4,) 
INFO:tensorflow:Saving checkpoints for 4 into data/tf/try1/model.ckpt.
Traceback (most recent call last):
  File "".../venv/lib/python3.4/site-packages/tables/array.py"", line 651, in __getitem__
    startl, stopl, stepl, shape = self._interpret_indexing(key)
  File "".../venv/lib/python3.4/site-packages/tables/array.py"", line 408, in _interpret_indexing
    raise TypeError(""Non-valid index or slice: %s"" % key)
TypeError: Non-valid index or slice: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib64/python3.4/runpy.py"", line 170, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/usr/lib64/python3.4/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/zfs_data/Sources/betahex/betahex/training/supervised.py"", line 106, in <module>
    tf.app.run()
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/zfs_data/Sources/betahex/betahex/training/supervised.py"", line 99, in main
    steps=50
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py"", line 281, in new_func
    return func(*args, **kwargs)
  File "".../venvs/default/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 429, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File "".../venv/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 977, in _train_model
    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])
  File .../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 500, in __exit__
    self._close_internal(exception_type)
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 535, in _close_internal
    self._sess.close()
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 769, in close
    self._sess.close()
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py"", line 866, in close
    ignore_live_threads=True)
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/lib/python3.4/site-packages/six.py"", line 686, in reraise
    raise value
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py"", line 93, in _run
    feed_dict = None if feed_fn is None else feed_fn()
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py"", line 175, in __call__
    for column in self._ordered_dict_of_arrays.values()
  File "".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py"", line 175, in <listcomp>
    for column in self._ordered_dict_of_arrays.values()
  File "".../venv/lib/python3.4/site-packages/tables/array.py"", line 656, in __getitem__
    coords = self._point_selection(key)
  File "".../venv/lib/python3.4/site-packages/tables/leaf.py"", line 561, in _point_selection
    coords[idx] = (coords + self.shape)[idx]
ValueError: operands could not be broadcast together with shapes (256,) (4,) 
Closing remaining open files:data/hdf5/training.h5...done
```"
9260,Sampling from a categorical distribution without replacement,"Both `tf.multinomial()` and `tf.contrib.distributions.Categorical.sample()` allow to sample from a multinomial distribution. However, they only allow sampling with replacement.

In constrast, Numpy's `numpy.random.choice()` has a `replace` parameter that allows sampling without replacement. Would it be possible to add a similar functionality to TensorFlow?

One use case is sampling examples from the dataset proportional to the model's last loss on them. When an example generates a very large loss, the next batch will mainly consist of that example. Using sampling without replacement, we can avoid this problem.

I see that sampling with replacement can be parallelized and implemented in a vectorized way, but I don't think sampling speed is a bottleneck in most people's programs."
9259,TensorFlow on ARMv7 seems to be slower,"I have installed tensorflow on our custom board which is based on i.mx6 (ARMv7) processor. I have compiled the C++ module alone without python support and was able to run the ""tensorflow/pi_examples/label_image""

Command used:  **make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI**

The problem is that the application seems to be very slow compared to Laptop (Intel i5). The inference takes close to 60-70s while it takes only 0.6 - 0.7s in my Laptop. 

After that, I figured out that I missed to use compiler optimization flag to use Neon. I compiled with Neon support and now it takes around 10-17s for same example.

Command used: **make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI  OPTFLAGS=""-Os -mfpu=neon -funsafe-math-optimizations -ftree-vectorize""**

Is there anything I am missing?

### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Yocto debian flavour
- **TensorFlow installed from**:  source (27a9808)
- **TensorFlow version**: NA
- **Bazel version (if compiling from source)**: Not used
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: NA
"
9258,Create support for a score threshold in NonMaxSuppression to skip over boxes with low score,Right now tensorflow::ops::NonMaxSuppression only prunes away boxes that have a high IOU overlap with previously selected boxes. It would be nice to also support a threshold on score so that the algorithm can skip over boxes that have a score below that threshold. We strongly believe this feature will speed up nms. Is there a plan to add this score threshold as a parameter?
9257,InvalidArgumentError when running word2vec_basic.py,"### System information
- Just running the word2vec_basic.py
- Windows 10 64bir
- b'unknown' 0.12.head (I installed 0.12 first then uninstalled old version and install new version to 1.0)
- GTX 760 4GB


### Describe the problem

```
Invalid argument: indices[0] = 4575361316406883040 is not in [0, 50000)
         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[""loc:@Variable_1""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable_1/read, nce_loss/concat)]]
W c:\tensorflow\tensorflow\tensorflow\core\framework\op_kernel.cc:975] Invalid argument: indices[0] = 4575361316406883040 is not in [0, 50000)
         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[""loc:@Variable_1""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable_1/read, nce_loss/concat)]]
Traceback (most recent call last):
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1021, in _do_call
    return fn(*args)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1003, in _run_fn
    status, run_metadata)
  File ""C:\Anaconda3\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 4575361316406883040 is not in [0, 50000)
         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[""loc:@Variable_1""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable_1/read, nce_loss/concat)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "".\word2vec_basic.py"", line 232, in <module>
    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 766, in run
    run_metadata_ptr)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[0] = 4575361316406883040 is not in [0, 50000)
         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[""loc:@Variable_1""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable_1/read, nce_loss/concat)]]

Caused by op 'nce_loss/embedding_lookup', defined at:
  File "".\word2vec_basic.py"", line 199, in <module>
    num_classes=vocabulary_size))
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_impl.py"", line 1044, in nce_loss
    name=name)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\ops\nn_impl.py"", line 891, in _compute_sampled_logits
    weights, all_ids, partition_strategy=partition_strategy)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\ops\embedding_ops.py"", line 111, in embedding_lookup
    validate_indices=validate_indices)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 1293, in gather
    validate_indices=validate_indices, name=name)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2371, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1258, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): indices[0] = 4575361316406883040 is not in [0, 50000)
         [[Node: nce_loss/embedding_lookup = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=[""loc:@Variable_1""], validate_indices=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](Variable_1/read, nce_loss/concat)]]
```
It seems that somehow indices[num] point to a very large number that not in the vocabulary vector?

I found there are also two cases in https://github.com/dennybritz/cnn-text-classification-tf/issues/17 but cannot find the solution
"
9256,tf.contrib.learn example couldn't run correctly in tensforflow official website,"Hi, 
I'm testing the tf.contrib.learn example in the 
https://www.tensorflow.org/get_started/tflearn
But when I executing the statement:
classifier.fit(input_fn=get_train_inputs, steps=2000)
I get the following error logs:

WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
INFO:tensorflow:Create CheckpointSaverHook.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 960M
major: 5 minor: 0 memoryClockRate (GHz) 1.176
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.24GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 3.95G (4240965632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 3.55G (3816868864 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
E tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 280, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 426, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 984, in _train_model
    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 462, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 744, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 891, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 744, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4
	 [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]

Caused by op u'dnn/hiddenlayer_0/MatMul', defined at:
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 280, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 426, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 934, in _train_model
    model_fn_ops = self._call_legacy_get_train_ops(features, labels)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1003, in _call_legacy_get_train_ops
    train_ops = self._get_train_ops(features, labels)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1162, in _get_train_ops
    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1133, in _call_model_fn
    model_fn_results = self._model_fn(features, labels, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 143, in _dnn_model_fn
    scope=scope)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
    return func(*args, **current_args)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1409, in fully_connected
    outputs = layer.apply(inputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 303, in apply
    return self.__call__(inputs, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 273, in __call__
    outputs = self.call(inputs, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/core.py"", line 145, in call
    outputs = standard_ops.matmul(inputs, self.kernel)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 1855, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1454, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4
	 [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]

>>> 
>>> # Define the test inputs
... def get_test_inputs():
...     x = tf.constant(test_set.data)
...     y = tf.constant(test_set.target)
...     return x, y
... 
>>> classifier.fit(input_fn=get_train_inputs, steps=2000)
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.
INFO:tensorflow:Create CheckpointSaverHook.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0)
INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model/model.ckpt.
INFO:tensorflow:loss = 1.21915, step = 1
E tensorflow/stream_executor/cuda/cuda_blas.cc:472] failed to run cuBLAS routine cublasSgemm_v2: CUBLAS_STATUS_EXECUTION_FAILED
W tensorflow/core/framework/op_kernel.cc:993] Internal: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4
	 [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]
W tensorflow/core/framework/op_kernel.cc:993] Internal: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4
	 [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 280, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 426, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 984, in _train_model
    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 462, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 786, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 744, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 891, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 744, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4
	 [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]
	 [[Node: train_op/dnn/train/update/_198 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_175_train_op/dnn/train/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'dnn/hiddenlayer_0/MatMul', defined at:
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 280, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 426, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 934, in _train_model
    model_fn_ops = self._call_legacy_get_train_ops(features, labels)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1003, in _call_legacy_get_train_ops
    train_ops = self._get_train_ops(features, labels)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1162, in _get_train_ops
    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1133, in _call_model_fn
    model_fn_results = self._model_fn(features, labels, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py"", line 143, in _dnn_model_fn
    scope=scope)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
    return func(*args, **current_args)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 1409, in fully_connected
    outputs = layer.apply(inputs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 303, in apply
    return self.__call__(inputs, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 273, in __call__
    outputs = self.call(inputs, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/core.py"", line 145, in call
    outputs = standard_ops.matmul(inputs, self.kernel)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 1855, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1454, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(120, 4), b.shape=(4, 10), m=120, n=10, k=4
	 [[Node: dnn/hiddenlayer_0/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](dnn/input_from_feature_columns/input_from_feature_columns/concat, dnn/hiddenlayer_0/weights)]]
	 [[Node: train_op/dnn/train/update/_198 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_175_train_op/dnn/train/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]


It seems some APIs are obsolete, can you update some new tf.contrib.learn examples in the website and make it workable with the latest version tensorflow?
And where can I get the new examples for tf.contrib.learn? 

Thanks!"
9255,stack_bidirectional_dynamic_rnn input incorrect documentation,"Hi, this is really a documentation problem rather than problem with the actual code.
The [doc](https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/contrib/rnn/stack_bidirectional_dynamic_rnn) states that inputs should be of shape number of numSequences x batchSize x inputSize, but in reality it's batchSize x numSequences x inputSize."
9254,Reading each filter response from a 4-D Tensor,"```
`class MyLayer(Layer):
    def __init__(self, output_dim, **kwargs):
        self.output_dim = output_dim
        super(MyLayer, self).__init__(**kwargs)

 def build(self, input_shape):
        # Create a trainable weight variable for this layer.
        self.kernel = self.add_weight(shape=(input_shape[1], self.output_dim),
                                      initializer='uniform',
                                      trainable=True)
        super(MyLayer, self).build(input_shape)  # Be sure to call this somewhere!

    def call(self, x):
        s = x.get_shape()
        r = K.eval(x)
        print(r)
       # Convert to 64 (25 * 25) tensors.
       # Need to flatten each of these 64 tensors.
       # write some functions on these 64 tensors.
       return <tensor [?,64]>`
```

x is of shape [?,25,25,64]

I need 64 tensors of [?,25,25]

Will `keras.layers.Flatten()` work in the second step.

Can a Tensor be converted to an numpy array?

Please help me on this.

Note: I am using Functional APIs for Keras."
9253,no tensorflow/cc/ops/array_ops.h found,"in file tensorflow/cc/ops/standard_ops.h
include tensorflow/cc/ops/array_ops.h
but it seem that array_ops.h disappeared
I found array_ops.cc at ./core/ops/array_ops.cc
does it a bug?

I use youcompleteme to complete my c++ code, found this problem."
9251,"why there are not file ""decoder_fn.py""","why there are not file ""decoder_fn.py"",which mention in the tensorflow website(https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference).
"
9250,undefined reference,"Please go to Stack Overflow for help and support: http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9249,Why are there not dbn and rbm in tensorflow model zoo?,Can anyone add them to tensorflow to make it better?
9248,Old python version,I have python 3.6.0 but tensorflow only supports 3.5
9247,Exceptions for nest._recursive_assert_same_structure,"I see [`nest._recursive_assert_same_structure`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/nest.py#L102) is used as a validator that makes sure that two nested sequences have same structure. However, due to its direct use of `zip(nest1, nest2)`, it doesn't make any error in this simple case.
`_recursive_assert_same_structure([[1,2,3], [2,3,[4]]], [[1,2,3,3,4,5]], False)`

It can give ValueError when the second argument is changed as  below.
`_recursive_assert_same_structure([[1,2,3], [2,3,[4]]], [1,2,3,3,4,5], False)`
=> ValueError: The two structures don't have the same nested structure. First structure: [1, 2, 3], second structure: 1."
9246,Issue with OpenCL Supported Bazel Compilation of Tensorflow 1.1 (From Source) on UBUNTU 14.04.3,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: UBUNTU 14.04.3-->Trusty
- **TensorFlow installed from (source or binary)**:Source
- **TensorFlow version (use command below)**:1.1.0 (Used git to clone repo)
- **Bazel version (if compiling from source)**:0.4.5
- **CUDA/cuDNN version**:NA
- **OPENCL Version**:
			  Platform Version:				 OpenCL 2.0 AMD-APP (1800.11)
			  Platform Name:				 AMD Accelerated Parallel Processing
			  Platform Vendor:				 Advanced Micro Devices, Inc.
			  Platform Extensions:				 cl_khr_icd cl_amd_event_callback cl_amd_offline_devices 
- **GPU model and memory**:
			  Platform Name:				 AMD Accelerated Parallel Processing
			Number of devices:				 2
			  Device Type:					 CL_DEVICE_TYPE_GPU
			  Board name:					 AMD Radeon (TM) R5 M335
                          Memory: 4096 MB 

- **Exact command to reproduce**:
		bazel build --config opt --config=sycl //tensorflow/tools/pip_package:build_pip_package

- ** G++/GCC version**:
	g++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4

I have compiled CPP programs, they work fine.

-- ** Python**: I am using Anaconda distribution Python for 2.7.2. (Anaconda - 2.4.3)
### Describe the problem

I am trying to compile Tensorflow with OPENCL support (experimental) on UBUNTU 14.04.3. I have an AMD GPU. I have followed the instructions from this site: https://github.com/benoitsteiner/tensorflow-opencl/blob/master/tensorflow/g3doc/get_started/os_setup.md#installing-from-sources
Everything works ok till the bazel compile step. When I try to compile with the following command: bazel build --config opt --config=sycl //tensorflow/tools/pip_package:build_pip_package
I get the following error:
#################################################
..............................
WARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/sayantan/tensorflow/tensorflow/core/BUILD:1292:1: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: computecpp failed: error executing command external/local_config_sycl/crosstool/computecpp -Wall -msse3 -g0 -O2 -DNDEBUG -g0 '-std=c++11' -MD -MF ... (remaining 27 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/share/bash-completion/completions/g++: 41: /usr/share/bash-completion/completions/g++: Syntax error: ""("" unexpected (expecting ""fi"")
Traceback (most recent call last):
  File ""external/local_config_sycl/crosstool/computecpp"", line 88, in <module>
    sys.exit(main())
  File ""external/local_config_sycl/crosstool/computecpp"", line 59, in main
    return subprocess.call([CPU_CXX_COMPILER] + compiler_flags)
  File ""/home/sayantan/anaconda2/lib/python2.7/subprocess.py"", line 168, in call
    return Popen(*popenargs, **kwargs).wait()
  File ""/home/sayantan/anaconda2/lib/python2.7/subprocess.py"", line 390, in __init__
    errread, errwrite)
  File ""/home/sayantan/anaconda2/lib/python2.7/subprocess.py"", line 1024, in _execute_child
    raise child_exception
OSError: [Errno 8] Exec format error
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 146.513s, Critical Path: 3.91s
#################################################

When I execute with more verbosity, I get teh following error:(bazel build --config opt --config=sycl //tensorflow/tools/pip_package:build_pip_package --verbose_failures)
#################################################
WARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /home/sayantan/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/sayantan/.cache/bazel/_bazel_sayantan/6f05f78a1e215999d72e42c1e87a8c1d/external/protobuf/BUILD:241:1: C++ compilation of rule '@protobuf//:js_embed' failed: computecpp failed: error executing command 
  (cd /home/sayantan/.cache/bazel/_bazel_sayantan/6f05f78a1e215999d72e42c1e87a8c1d/execroot/tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/lib32:/usr/local/computecpp/lib \
    PATH=/home/sayantan/bin:/home/sayantan/anaconda2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/sayantan/bin \
  external/local_config_sycl/crosstool/computecpp -Wall -msse3 -g0 -O2 -DNDEBUG -g0 '-std=c++11' -MD -MF bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.d '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.o' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/protobuf/src/google/protobuf/compiler/js/embed.cc -o bazel-out/host/bin/external/protobuf/_objs/js_embed/external/protobuf/src/google/protobuf/compiler/js/embed.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/usr/share/bash-completion/completions/g++: 41: /usr/share/bash-completion/completions/g++: Syntax error: ""("" unexpected (expecting ""fi"")
Traceback (most recent call last):
  File ""external/local_config_sycl/crosstool/computecpp"", line 88, in <module>
    sys.exit(main())
  File ""external/local_config_sycl/crosstool/computecpp"", line 59, in main
    return subprocess.call([CPU_CXX_COMPILER] + compiler_flags)
  File ""/home/sayantan/anaconda2/lib/python2.7/subprocess.py"", line 168, in call
    return Popen(*popenargs, **kwargs).wait()
  File ""/home/sayantan/anaconda2/lib/python2.7/subprocess.py"", line 390, in __init__
    errread, errwrite)
  File ""/home/sayantan/anaconda2/lib/python2.7/subprocess.py"", line 1024, in _execute_child
    raise child_exception
OSError: [Errno 8] Exec format error
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 10.148s, Critical Path: 8.76s

################################################

Please let me know if there are any fixes or if I can do something to get round this issue.
Thanks and regards
Sayantan"
9245,AttributeError: module 'tensorflow.contrib.seq2seq' has no attribute 'rnn_decoder',"### System information
- **OS and Env**: Windows 7, Python 3.5.1
- **TensorFlow installed from**: binary, pip install tensorflow
- **TensorFlow version**: 1.0.1


### Describe the problem
After upgrading from TF 0.9 to TF 1.0.1, am unable to find `seq2seq.rnn_decoder()`. Updated the `imports` to include seq2seq module (TF 0.9: `tensorflow.python.ops`, TF 1.0: `tensorflow.contrib`). 

On exploring the new API, I noticed a _similar_ function: `dynamic_rnn_decoder`. Unfortunately, `dynamic_rnn_decoder` has different signature than `rnn_decoder`, and a simple function name change fails.

**The Ask**
What's the equivalent of `seq2seq.rnn_decoder()` in TF 1.0+?

### Source code (TF 0.9)
`seq2seq.rnn_decoder(inputs_split,              self.initial_state,
                                                                  self.cell,
                                                                  loop_function=loop if test else None,
                                                                  scope='lstm_vars')`
"
9243,tf.conv2d ValueError,"I believe the following is a bug

ValueError: Shape must be rank 4 but is rank 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [1,1,64,256], [4].

Full Traceback:
Traceback (most recent call last):
  File ""chat.py"", line 17, in <module>
    conv1 = tf.nn.conv2d(input=embed_a,filter=[1,8,256,128],strides=[1,1,8,256],padding=""VALID"")
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 396, in conv2d
    data_format=data_format, name=name)
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2329, in create_op
    set_shapes_for_outputs(ret)
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1717, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1667, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shape must be rank 4 but is rank 1 for 'Conv2D' (op: 'Conv2D') with input shapes: [1,1,64,256], [4].

I believe that a tensor of shape [1,1,64,256] should be Rank 4 not Rank 1."
9241,Module 'tensorflow' has no attribute 'constant' after local pip installation,"Please go to Stack Overflow for help and support: http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
>>>> Ubuntu 16 with Cuda 8 and Nvidia GEForce 780i, g++ 5.4.0, cudnn 6

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
>>>> no. simply following https://www.tensorflow.org/install/install_sources

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
>> Ubuntu 16 (xenial) 

- **TensorFlow installed from (source or binary)**:
>>>> masterbranch
- **TensorFlow version (use command below)**:
>>> 1.1.0rc0
- **Bazel version (if compiling from source)**:
>>> Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778

- **CUDA/cuDNN version**:
>>>> 6

- **GPU model and memory**:
>>>> Nvidia GEForce 780i, 2G
- **Exact command to reproduce**:
karun@karunlindev3:~/shadow/cuda-workspace$ python
Python 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'constant'

I tried to get tf version

karun@karunlindev3:~/shadow/cuda-workspace$ python
Python 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> print(tf.GIT_VERSION, tf.VERSION)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'GIT_VERSION'


You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

when i install tensor flow with gpu support from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.1-cp34-cp34m-linux_x86_64.whl
it works with some warnings that certain libraries could be faster.
when i install local pip pacakge following https://www.tensorflow.org/install/install_sources
i get this
karun@karunlindev3:~/shadow/cuda-workspace$ python
Python 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'constant'


   * I have looked on stackoverflow, tensorflow github and i have made sure my situation is different. i am not using tensorflow as a filename, nor I am in the source directory where config is launched. 
   * i have checked directory permissions on site-packages and it looks good.
   * i uninstalled the gpu package 1.0.1-cp34 before i installed local pip.

What am I missing?

### Source code / logs

local source
karun@karunlindev3:~/shadow/tensorflow$ ls
ACKNOWLEDGMENTS  AUTHORS    bazel-genfiles  bazel-tensorflow  bower.BUILD  configure        ISSUE_TEMPLATE.md  models.BUILD  RELEASE.md  third_party  util
ADOPTERS.md      bazel-bin  bazel-out       bazel-testlogs    BUILD        CONTRIBUTING.md  LICENSE            README.md     tensorflow  tools        WORKSPACE



Here is the output for installation of loca pip. I noticed that there are a __LOT__ more files from the gpu package on googlapis than local pip

__Successfully uninstalled tensorflow-gpu-1.0.1__

karun@karunlindev3:~/shadow/cuda-workspace$ pip install --upgrade /tmp/tensorflow_pkg/tensorflow-1.1.0rc0-cp36-cp36m-linux_x86_64.whl
Processing /tmp/tensorflow_pkg/tensorflow-1.1.0rc0-cp36-cp36m-linux_x86_64.whl
Requirement already up-to-date: bleach==1.5.0 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: protobuf>=3.2.0 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: wheel>=0.26 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: numpy>=1.11.0 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: werkzeug>=0.11.10 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: six>=1.10.0 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: html5lib==1.0b8 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: markdown==2.2.0 in /home/karun/anaconda3/lib/python3.6/site-packages (from tensorflow==1.1.0rc0)
Requirement already up-to-date: setuptools in /home/karun/anaconda3/lib/python3.6/site-packages (from protobuf>=3.2.0->tensorflow==1.1.0rc0)
Requirement already up-to-date: appdirs>=1.4.0 in /home/karun/anaconda3/lib/python3.6/site-packages (from setuptools->protobuf>=3.2.0->tensorflow==1.1.0rc0)
Requirement already up-to-date: packaging>=16.8 in /home/karun/anaconda3/lib/python3.6/site-packages (from setuptools->protobuf>=3.2.0->tensorflow==1.1.0rc0)
Requirement already up-to-date: pyparsing in /home/karun/anaconda3/lib/python3.6/site-packages (from packaging>=16.8->setuptools->protobuf>=3.2.0->tensorflow==1.1.0rc0)
Installing collected packages: tensorflow
  Found existing installation: tensorflow 1.1.0rc0
    Uninstalling tensorflow-1.1.0rc0:
      Successfully uninstalled tensorflow-1.1.0rc0

__Successfully installed tensorflow-1.1.0rc0__
"
9240,"spectral ops make freeze_graph tool trigger ""No OpKernel was registered ..."" error","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2 LTS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.1.0-rc1-253-gd5a9356 1.1.0-rc1
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: NVIDIA Geforce GTX 750 Ti
- **Exact command to reproduce**: bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=model.pb --input_checkpoint=model.ckpt --output_graph=frozen_model.pb --output_node_names=y_conv

### Describe the problem
The [`freeze_graph`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) tool malfunctions when processing a graph containing [spectral ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/api_guides/python/spectral_ops.md).
Without spectral ops, everything works just fine, all the way to inference.

Might this have something to do with the fact that spectral ops don't have a CPU implementation yet?
And if so, why would this lead to this error?

### Source code / logs
```
Traceback (most recent call last):
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1136, in _do_call
    return fn(*args)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1114, in _run_fn
    self._extend_graph()
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1163, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'RFFT' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: rfft = RFFT[](framesig, Const_1)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 218, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 150, in main
    FLAGS.variable_names_blacklist)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 128, in freeze_graph
    saver.restore(sess, input_checkpoint)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/training/saver.py"", line 1545, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 786, in run
    run_metadata_ptr)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 994, in _run
    feed_dict_string, options, run_metadata)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1129, in _do_run
    target_list, options, run_metadata)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1149, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'RFFT' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: rfft = RFFT[](framesig, Const_1)]]

Caused by op 'rfft', defined at:
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 218, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 150, in main
    FLAGS.variable_names_blacklist)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 103, in freeze_graph
    _ = importer.import_graph_def(input_graph_def, name="""")
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/importer.py"", line 308, in import_graph_def
    op_def=op_def)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'RFFT' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: rfft = RFFT[](framesig, Const_1)]]
```"
9239,Configure Failed: Timeout connecting to...,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.1
- **Bazel version (if compiling from source)**:0.4.5
- **CUDA/cuDNN version**: 8.0/5
- **GPU model and memory**: 1080 ti
- **Exact command to reproduce**: ./configure

### Describe the problem

Previous night I successfully configured and installed TensorFlow. Tonight I'm going to try the exact process but when configuring always the following error is appeared:

```
INFO: Timeout connecting to https://raw.githubusercontent.com/mrdoob/three.js/r77/examples/js/controls/\
OrbitControls.js
```

After I changed my proxy server, it timeout connecting to another url. It is related to [#6613](https://github.com/tensorflow/tensorflow/issues/6613).
Is it possible to download links locally?
"
9237,"In ExponentialMovingAverage class in python/training/moving_averages.py, which op will first be executed,  opt_op or maintain_average_op?","Recently, I checked the code about moving averages. But I confused about which operation will first be executed, the opt_op which apply the gradient to the variable, or the maintain_average_op which maintain and update the shadow variable? I find that the following code:
` with tf.control_dependencies([opt_op]):
      training_op = tf.group(maintain_averages_op)`
training_op depends on both opt_op and maintain_averages_op. But how about the relation of opt_op   and maintain_averages_op? Which one will be executed first? "
9234,Segfaults/NaN's in SVD,"I'm getting failures trying to run SVD on a particular matrix. The result is either all NaN's for u matrix, or it's segfaults like below.

To reproduce, run this script in Python3: [https://github.com/yaroslavvb/stuff/blob/master/svd_test.py](https://github.com/yaroslavvb/stuff/blob/master/svd_test.py)

I can't see anything special about this matrix beside the fact that it's badly conditioned. IE, I can perform SVD on this matrix in Mathematica [fine](https://www.wolframcloud.com/objects/f16d71a7-cc47-4a3d-b686-da440670eed3)
 @rmlarsen 

```
 #0  0x00007fffe320e121 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::perturbCol0(Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<long, 1, -1, 1, 1, -1>, 0, Eigen::InnerStride<1> > const&, Eigen::Matrix<float, -1, 1, 0, -1, 1> const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #1  0x00007fffe320fa81 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::computeSVDofM(long, long, Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Matrix<float, -1, 1, 0, -1, 1>&, Eigen::Matrix<float, -1, -1, 0, -1, -1>&) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #2  0x00007fffe321e21c in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::divide(long, long, long, long, long) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #3  0x00007fffe321dbb8 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::divide(long, long, long, long, long) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #4  0x00007fffe32220bd in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::compute(Eigen::Matrix<float, -1, -1, 1, -1, -1> const&, unsigned int) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
# #5  0x00007fffe32227a1 in tensorflow::SvdOp<float>::ComputeMatrix(tensorflow::OpKernelContext*, tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<float, -1, -1, 1, -1, -1> const, 0, Eigen::Stride<0, 0> >, 4> const&, tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<float, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>*) ()                                                                 from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so                                       #6  0x00007fffe3228c75 in tensorflow::LinearAlgebraOp<float>::ComputeTensorSlice(tensorflow::OpKernelContext*, long long, tensorflow::gtl::InlinedVector<tensorflow::Tensor const*, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorShape, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::Tensor*, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorShape, 4> const&) ()
#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so



```"
9233,"Hello All, i am using Floyd, yet I keep getting the error -  ImportError: No module named 'tensorflow'","Please go to Stack Overflow for help and support: http://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
9232,"One set of GPUs on same machine and same model work well, another gets OOM error","I am using multiple GPUs (num_gpus = 4) for training one model with multiple towers. The model is training well on one set of GPUs: `CUDA_VISIBLE_DEVICES = 0,1,2,3` while it gets OOM problem during the first graph evaluation with `CUDA_VISIBLE_DEVICES = 0,1,4,5`


Following options are used for creating a session
```python
session_config=tf.ConfigProto(
      allow_soft_placement=True,
      log_device_placement=False)
session_config.gpu_options.per_process_gpu_memory_fraction = 0.94
session_config.gpu_options.allow_growth=False
```

Batch size, is already super small, = 3



   
### System information
Tensorflow 1.0
Cuda 8.0
Ubuntu 14.04.5 LTS
All GPUs : GeForce GTX 1080 

### Source code / logs
```
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:07:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xcc4593a0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:08:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xd2404670
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:18:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xd25591b0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:1c:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:07:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:08:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:18:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:1c:00.0)

I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 47441 get requests, put_count=8461 evicted_count=1000 eviction_rate=0.118189 and unsatisfied allocation rate=0.844839
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.98GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.98GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.68GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.86GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2698 get requests, put_count=8709 evicted_c 
```"
9230,random ops across iterations of while loops execute in nondeterministic order,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes.  See below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: `('0.12.1-2106-gf7d07f5-dirty', '0.12.head')`
- **Bazel version (if compiling from source)**: (not a build issue)
- **CUDA/cuDNN version**: CuDNN5, CUDA8 (though this runs on CPU)
- **GPU model and memory**: 1x Titan X Pascal, 1x Titan X (though this runs on CPU)
- **Exact command to reproduce**: `../virtualenv/bin/python nnrandom.py --broken; ../virtualenv/bin/python nnrandom.py --broken`

### Describe the problem, source code, and logs

When using augmentation primitives, sometimes, they create run-to-run non-determinism by ignoring the system random seed.  This makes reproducing a run impossible, even when using `tf.set_random_seed`.  One case in which they seem to do this is inside a `tf.device()` block.  Consider the following snippet:

```python
import tensorflow as tf
import numpy as np

tf.app.flags.DEFINE_integer(""seed"", 1, ""RNG seed"")
FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_float(""augment_hue"", 0.5, ""hue augment factor"")
tf.app.flags.DEFINE_boolean(""no_augment"", False, ""whether to disable augmentation entirely"")
def mk_input():
  np.random.seed(0)
  a1s = np.random.uniform(size = [32, 128, 128, 3]).astype(np.float32)

  if not FLAGS.no_augment:
    def aug(img):
      img = tf.image.random_hue(img, FLAGS.augment_hue, seed = 50001)

      return img
    a1s = tf.map_fn(aug, a1s)

  return a1s

tf.app.flags.DEFINE_boolean('broken', False, '')
def main(argv=None):
  if len(argv) != 1:
    print ""argv was"",argv
    raise RuntimeError('unknown argument')
  print('nn: building graph')

  tf.set_random_seed(FLAGS.seed)

  with tf.Session(config=tf.ConfigProto(allow_soft_placement = True)) as sess:
    if FLAGS.broken:
      with tf.device('/cpu:0'):
        input = mk_input()
    else:
      input = mk_input()

    a = tf.reduce_mean(input)

    tf.global_variables_initializer().run()
    tf.train.start_queue_runners(sess = sess)
    print('nn: TF session initialized')

    for step in xrange(10):
      res = sess.run(a)
      print(res)

if __name__ == '__main__':
  tf.app.run()
```

If you run this without `--broken`, then you'll get the same result every time.  On my machine, the result without `--broken` starts 0.500045.  But if you run this with `--broken`, then you'll get a different result each time.  For instance:

```
jwise@jwise-dt:/home/scratch.jwise_dl$ ../virtualenv/bin/python nnrandom.py  --broken 2>&1 | tail -n5
0.500318
0.500236
0.500246
0.500185
0.500303
jwise@jwise-dt:/home/scratch.jwise_dl$ ../virtualenv/bin/python nnrandom.py  --broken 2>&1 | tail -n5
0.500279
0.500218
0.500164
0.500178
0.500106
```

I have not dug any deeper yet as to where, exactly, the nondeterminism is coming from, but I figured that this is pretty close to a minimal repro case based on TF primitives.

Thanks,
joshua"
9226,Keras + tensorflow + P100 : cudaErrorNotSupported = 71 error,"Allow me please to cross post, upon sugestion, an error faced in using keras with tensorflow with machine equipped with P100 https://github.com/fchollet/keras/issues/6054
Apologies if this has been reported already at some other place, I have been googling for it quite a bit, with my colleague without success.
While running the simple mnist example (https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py) with keras+tensorflow using P100 GPGPU we encounter an issue at the intersection of keras/tensorflow/cuda

Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:02:00.0
Total memory: 15.89GiB
Free memory: 15.51GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0: Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:02:00.0)
F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)
srun: error: nid02011: task 0: Aborted
srun: Terminating job step 1262138.0

we are using keras 2.0.2, tensorflow 1.0.0. cuda 8.0.53.
We seem to be having this issue both in python2.7.12 and python3.5.2 (keras 1.2 and 2.0 ...)
Bare tensorflow runtest are going fine, which lead us to think that this is really at the intersection of keras/tensorflow/cuda.
The same test runs fine on various machine with the same version of the software but with TitanX GPGPU.

 seem to be tracing this back to
https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/core/common_runtime/gpu/gpu_device.cc#L121

http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038

""""""
cudaErrorNotSupported = 71
This error indicates the attempted operation is not supported on the current system or device.
""""""

I am clueless on where to look next to solve this issue. I would greatly appreciate any feedback and guidance on this matter.
"
9225,Restoring RNN model from checkpoint fails when hidden layer width is not equal to input/output width,"Hi, I'm not sure whether this is actually a bug, or I'm doing something wrong, so please treat accordingly.

I have an RNN model defined as following:

```
import tensorflow as tf

nn_layers = 3

def RNN(x, weights, out_biases, input_size, n_steps, nn_hidden, keep_prob, forget_bias=0.0):
    # Input data shape: (batch_size, n_steps, input_size)
    # Output data shape: (batch_size, output_size)
    # Permute, reshape and split to get n_steps tensors of shape (batch_size, input_size)
    x = tf.transpose(x, [1, 0, 2])
    x = tf.reshape(x, [-1, input_size])
    x = tf.split(axis=0, num_or_size_splits=n_steps, value=x)
    
    # define RNN structure
    
    #layer_cell = tf.contrib.rnn.BasicLSTMCell(nn_hidden, forget_bias=forget_bias)
    layer_cell = tf.contrib.rnn.GRUCell(nn_hidden)
    
    cell = tf.contrib.rnn.DropoutWrapper(layer_cell, output_keep_prob=keep_prob)
    cell = tf.contrib.rnn.MultiRNNCell([cell] * nn_layers)
    output, state = tf.contrib.rnn.static_rnn(cell, x, dtype=tf.float32)
    
    pred = tf.matmul(output[-1], weights[""out""]) + out_biases[""out""]
    
    
    return pred

def vs3_RNN(x, input_size, n_steps, nn_hidden, output_size, keep_prob, forget_bias=0.0):
    
    # Define weights -- output layer
    weights = {
        'out': tf.Variable(tf.random_normal([nn_hidden, output_size]), name=""smax_w"")
    }
    out_biases = {
        'out': tf.Variable(tf.random_normal([output_size]), name=""smax_b"")
    }
    
    pred = RNN(x, weights, out_biases, input_size, n_steps, nn_hidden, keep_prob, forget_bias=forget_bias)
    
    return pred

```

I use the vs3_RNN method for both training and testing. The size of my input and output vectors (input_size, output_size) is 500. When I set the width of my hidden layer (nn_hidden) to 500, everything works great. However, when I set it to something else, I can train the model and save the checkpoint fine -- but when I try to restore the model from checkpoint, I get an error message.

Here's a stack trace with nn_hidden equal to 600:

```
Traceback (most recent call last):
  File ""thdvector/vs3_service.py"", line 43, in <module>
    saver.restore(sess, tf.train.latest_checkpoint(SAVEDIR))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1439, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [600]
	 [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[""loc:@rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases, save/RestoreV2)]]

Caused by op u'save/Assign', defined at:
  File ""thdvector/vs3_service.py"", line 41, in <module>
    saver = tf.train.Saver()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1051, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1081, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 675, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 414, in _AddRestoreOps
    assign_ops.append(saveable.restore(tensors, shapes))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 155, in restore
    self.op.get_shape().is_fully_defined())
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py"", line 47, in assign
    use_locking=use_locking, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2395, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [600]
	 [[Node: save/Assign = Assign[T=DT_FLOAT, _class=[""loc:@rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/cpu:0""](rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases, save/RestoreV2)]]


```

I have tried this with either GRUCell or BasicLSTMCell, and I get the error message regardless.

Here's the code that run that tries to restore the checkpoint and fails:

```
x = tf.placeholder(""float"", [1, n_steps, input_size], name=""x_in"")
    
    pred = vs_model.vs3_RNN(x, input_size, n_steps, nn_hidden, output_size, keep_prob=testing_keep_prob, forget_bias=forget_bias)
    
    init = tf.global_variables_initializer()
    
    with tf.Session() as sess:
        sess.run(init)
        print(""Variables initialized"")
        
        saver = tf.train.Saver()
        #saver = tf.train.import_meta_graph(META)
        saver.restore(sess, tf.train.latest_checkpoint(SAVEDIR))
        print(""Model restored from "" + str(SAVEDIR))
        ...
```

Thanks."
9224,Build Error: libcudnn.so.5: file not recognized: File truncated collect2: error: ld returned 1 exit status,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.2
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: master
- **Bazel version (if compiling from source)**: 0.4.5
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: 1080 Ti
- **Exact command to reproduce**: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Get the latest source code and running ""bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package"" to build GPU version. Cuda and CuDNN completely installed and all samples are passed.

### Source code / logs
ERROR: /home/amir/projects/tensorflow/tensorflow/python/BUILD:2534:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o ... (remaining 27 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/local_linux-py3-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudnn___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib/libcudnn.so.5: file not recognized: File truncated
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2259.385s, Critical Path: 2229.15s
"
9222,Bazel build  error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Traceback (most recent call last):,"I'm trying to build a simple script,  however while compiling i get the following error: 

ERROR: C:/users/john/downloads/tensorflow-master/tensorflow/loader/BUILD:1:1: error loading package 'tensorflow/core': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Traceback (most recent call last):
        File ""C:/users/john/downloads/tensorflow-master/tensorflow/workspace.bzl"", line 88
                _apply_patch(repo_ctx, repo_ctx.attr.patch_file)
        File ""C:/users/john/downloads/tensorflow-master/tensorflow/workspace.bzl"", line 79, in _apply_patch
                _execute_and_check_ret_code(repo_ctx, [""patch"", ""-p1"", ""-d"", r...), <2 more arguments>])
        File ""C:/users/john/downloads/tensorflow-master/tensorflow/workspace.bzl"", line 71, in _execute_and_check_ret_code
                fail(""Non-zero return code({1}) when ..., <2 more arguments>))
Non-zero return code(256) when executing 'patch -p1 -d C:/tools/msys64/tmp/_bazel_john/mzdlugz6/external/protobuf -i C:/users/john/downloads/tensorflow-master/third_party/protobuf/add_noinlines.patch':
Stdout:
Stderr: java.io.IOException: CreateProcess(): The system cannot find the file specified.
 and referenced by '//tensorflow/loader:test850.dll'.

protobuf is installed:

$ protoc --version
libprotoc 3.2.0

$ bazel version
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 13:02:06 2017 (1489669326)
Build timestamp: 1489669326
Build timestamp as int: 1489669326

I have build bazel with chocolatery as described on the bazel site.

Tried solution from issue #5029 (although the error is different). If i run the exact same script with bazel on a mac everything is fine and the build completes (no this is unfortunate not a solution). So i know the problem is with windows bazel and maybe the paths? 

Also tried to compile with CMAKE however with no succes 



"
9220,How to recompile eigen3 library,"I changed some code in the //tensorflow/third_party/eigen3, and recompile the C++ sample (label_image). I looked at the code of the `BUILD` file in label_image and it depends on the //tensorflow/core, and I think the latter depends on the eigen3. However when I run the recompiled label_image, the code I've changed in eigen3 doesn't work. I am not very familiar with bazel so I hope someone can help me on this. How can I recompile the eigen3 to be reflected in the example?"
9216,AssertionError: Items are not equal: ACTUAL: 2147483647 DESIRED: -2147483648,"
### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  
Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**: 
 Installed from source (v1.0.1)
- **TensorFlow version (use command below)**:    
('v1.0.1-0-ge895d5c-dirty', '1.0.1')
- **Bazel version (if compiling from source)**: 
bazel release 0.4.4-2017-04-10 (@80a07b5)
- **CUDA/cuDNN version**: 
In disable mode
- **Exact command to reproduce**:
bazel test //tensorflow/python/kernel_tests:cast_op_test



### Describe the problem
Built TF successfully , however I am getting `Items are not equal` error while running the `cast_op_test` 

To cross verify the test results , I ran this test on X86 vm and that passed successfully. This test is failing only on ppc64le platform . Here I would like to know your suggestions and comments. 

### Source code / logs
````
$ bazel test //tensorflow/python/kernel_tests:cast_op_test


exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py:62: ComplexWarning: Casting complex values to real discards the imaginary part
  np_ans = x.astype(dtype)
....F.W tensorflow/core/framework/op_kernel.cc:983] Unimplemented: Cast int64 to string is not supported
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Unimplemented: Cast int64 to string is not supported
         [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
........
======================================================================
FAIL: testInfNan (__main__.CastOpTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py"", line 150, in testInfNan
    self._compare(np.inf, np.int32, i4.min, False)
  File ""/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py"", line 124, in _compare
    x, dst_dtype, use_gpu=use_gpu), dst_dtype(expected))
  File ""/usr/lib64/python2.7/site-packages/numpy/testing/utils.py"", line 425, in assert_equal
    raise AssertionError(msg)
AssertionError:
Items are not equal:
 ACTUAL: 2147483647
 DESIRED: -2147483648

----------------------------------------------------------------------
Ran 14 tests in 2.485s

FAILED (failures=1)
`

```"
9215,encoder_inputs and decoder_inputs of a sequence to sequence model.,"Hello,
I've read the tutorial about seq2seq on the website and still can't figure out how my inputs have to be;
here's my problem:
each of my inputs is a matrix with fixed number of columns but a variable number of rows( each matrix has its number of rows). And the same thing for my outputs.
how to build the encoder and decoder inputs?
Thanks in advance.
"
9213,System hangs when computing gradients on GPU,"### Problem description

My system hangs when computing gradients on the GPU.  I am able to compute gradients on the CPU without issue.  I can compute all the nodes in my graph, including my loss function, on the GPU without issue.  My system hangs when computing gradients on the GPU irrespective of which optimizer I use.  The code that produces this issue is:

```{python}
sess = tf.Session()

# ...

cnn = CNNClass()

#...

step_size = tf.placeholder(tf.float32, name=""step_size"") 
global_step = tf.Variable(0, name=""global_step"", trainable=False) 
optimizer = tf.train.MomentumOptimizer(step_size, 0.9)

#...

# CRASHES WHEN I RUN THIS
grads_and_vars = optimizer.compute_gradients(cnn.loss)
sess.run([grads_and_vars], feed_dict)

# DOES NOT CRASH WHEN I RUN THIS
sess.run([cnn.loss])
```

### Further information

I tried setting `gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.333)` in my ConfigProto but that didn't help.  

Launching `watch -n 0.1 nvidia-smi` before running the code shows Volatile GPU-Util goes to 100% just before hanging.

Computing gradients on the CPU and printing them out shows normal output (I'm not getting any NaNs or 0's or anything like that).

### System information

- System: Ubuntu 16.04
- TensorFlow installed from: binary
- TensorFlow version: v1.0.0-65-g4763edf-dirty 1.0.1
- CUDA version: 8.0, V8.0.61
- cuDNN version: 5.1
- GPU model and memory: NVidia GeForce GTX TITAN X (12GB)
- Video card driver: 375.39"
9212,Provide wheel packages at pypi for python 3.6 on windows,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: binary(expect)

### Describe the problem

Providing wheel packages at pypi for python 3.6 on windows would be helpful. As it is the latest anaconda python version.
"
9210,Feature: Sparse matrix multiplications for Tensors with rank > 2,"## System Information:
Windows 10, x64, Tensorflow 1.1.0.rc1

## Description:
The 3-D sparse tensor (placeholder) multiply with 3-D dense tensor has bug, the operation will failed.

```python
x = tf.sparse_placeholder(tf.float32, shape=[None, 2, 2])
y = tf.constant(np.ones([3, 2, 1]), dtype=tf.float32)
z = tf.matmul(x, y, a_is_sparse=True)

indices = [[1, 1, 1], [2, 0, 0], [3, 0, 1]]
values = [1.0, 2.0, 3.0]
dense_shape = [3, 2, 2]
x_val = tf.SparseTensorValue(indices, values, dense_shape)

with tf.Session() as sess:
  res = sess.run(z, feed_dict={x: x_val})
  print(res)
```
expected result(3x2x1):
```
[[[ 0.][ 1.]]
 [[ 1.][ 0.]]
 [[ 1.][ 0.]]]
```
but output some errors actually :

```python
Traceback (most recent call last):
  File ""D:/Learning/master_project/clinicalText/SourceCode/Python/DNN_CWS/seg_dnn.py"", line 369, in <module>
    cws = SegDNN(constant.VOCAB_SIZE, embed_size, constant.DNN_SKIP_WINDOW)
  File ""D:/Learning/master_project/clinicalText/SourceCode/Python/DNN_CWS/seg_dnn.py"", line 76, in __init__
    self.loss = tf.reduce_sum(tf.matmul(self.slim_map_matrix,tf.expand_dims(tf.transpose(self.word_score),2),a_is_sparse=True))
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1755, in matmul
    a = ops.convert_to_tensor(a, name=""a"")
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\ops.py"", line 639, in convert_to_tensor
    as_ref=False)
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\ops.py"", line 704, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 113, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 102, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 444, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\tensor_util.py"", line 444, in <listcomp>
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\util\compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000195FA86B1D0>

```

change the `z` to 
```python
z = tf.sparse_tensor_dense_matmul(x,y)
```
also failed because the shape of sparse must 2-D,but `x`and`b`has 3-D"
9209,[Windows - Bazel] ERROR undeclared inclusion(s) in rule '//tensorflow/core/kernels:fake_quant_ops_gpu',"Windows 10
CUDA 8.0
cuDNN 5.1
TensorFlow at e8a34420ce06c7f99049b4e4fec4308aff8dd058
Bazel at [e565230](https://github.com/bazelbuild/bazel/commit/eecd7128f420b2d404ed2f42d549dea3bd198d9d)
Msys2

During build Bazel failed with

```
ERROR: C:/users/adriano/documents/tensorflow/tensorflow/core/kernels/BUILD:2809:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:fake_quant_ops_gpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/fake_quant_ops_gpu.cu.cc':
  'C:/windows/temp/tmpxft_0000426c_00000000-8_fake_quant_ops_gpu.cu.cudafe1.stub.c'
  'C:/windows/temp/tmpxft_0000426c_00000000-6_fake_quant_ops_gpu.cu.fatbin.c'
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\eigen\src/Core/products/Parallelizer.h(20): warning: variable ""m_maxThreads"" was set but never used
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\eigen\src/Core/ArrayWrapper.h(93): warning: __declspec attributes ignored
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/ThreadPool/SimpleThreadPool.h(139): warning: ""constexpr"" is ignored here in Microsoft mode
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/ThreadPool/NonBlockingThreadPool.h(151): warning: ""constexpr"" is ignored here in Microsoft mode
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\eigen\src/Core/products/Parallelizer.h(20): warning: variable ""m_maxThreads"" was set but never used
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\eigen\src/Core/ArrayWrapper.h(93): warning: __declspec attributes ignored
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/ThreadPool/SimpleThreadPool.h(139): warning: ""constexpr"" is ignored here in Microsoft mode
c:\tmp\_bazel_adriano\piryq3n9\execroot\tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/ThreadPool/NonBlockingThreadPool.h(151): warning: ""constexpr"" is ignored here in Microsoft mode
nvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 2078.109s, Critical Path: 104.55s
FAILED: Build did NOT complete successfully
+ exit 1

```

#### Steps to reproduce
- configure TensorFlow accordingly without XLA
- `export BUILD_OPTS='--cpu=x64_windows_msvc --host_cpu=x64_windows_msvc --copt=/w --verbose_failures --experimental_ui'`
- `./tensorflow/tools/ci_build/windows/gpu/pip/build_tf_windows.sh    `

"
9205,Results are corrupted when running multiple sessions on one GPU ,"Tensorflow generates corrupted results when running two sessions concurrently on gpu. Each session has a separate graph.

Code (thx to @bnoodle):
```
import tensorflow as tf
import numpy as np
from threading import Thread, Event

size = 10240
def myfunc(sess, name):
  values = set()
  count = 0
  while True:
    count += 1
    v = sess.run(name + ""/matmul4:0"", feed_dict={name + ""/input:0"": np.ones((1,1))})
    v = float(np.squeeze(v))
    old = len(values)
    values.add(v)
    if len(values) != old:
      print(values, name, count)

def create_graph(sess, name):
  with sess.graph.as_default():
    with tf.variable_scope(name):
      input = tf.placeholder(tf.float32, shape=[1,1], name = ""input"")
      tf.set_random_seed(1)

      matrix1 = tf.Variable(tf.truncated_normal([1, size]), name = 'matrix1')
      matrix2 = tf.Variable(tf.truncated_normal([size, size]), name = 'matrix2')
      matrix4 = tf.Variable(tf.truncated_normal([size, 1]), name = 'matrix4')

      matmul1 = tf.matmul(input, matrix1, name = 'matmul1')
      matmul2 = tf.matmul(matmul1, matrix2, name = 'matmul2')
      matmul4 = tf.matmul(matmul2, matrix4, name = ""matmul4"")
      sess.run(tf.global_variables_initializer())

sess1 = tf.Session()
with tf.device(""/gpu:0""):
  create_graph(sess1, ""s1"")

sess2 = tf.Session()
with tf.device(""/gpu:0""):
  create_graph(sess2, ""s2"")

t1 = Thread(target=myfunc, args=(sess1, 's1'))
t1.start()

t2 = Thread(target=myfunc, args=(sess2, 's2'))
t2.start()
```
sess1 should output -17430.388671875, sess2 should output -968.17529296875. But the output sets are nondeterministically growing:
```
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 3.94GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
((set([set([-968.17529296875]), 's2', 1-17430.388671875]))
, 's1', 1)
(set([-968.17529296875, -903.794921875]), 's2', 2)
(set([-17430.388671875, -17302.84375]), 's1', 2)
(set([-968.17529296875, -903.794921875, 2173.232177734375]), 's2', 511)
(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625]), 's2', 1723)
(set([-17430.388671875, -17302.84375, -211.60272216796875]), 's1', 1961)
(set([-968.17529296875, -903.794921875, 2173.232177734375, 841.5855712890625, -30.6038818359375]), 's2', 2180)
(set([-17430.388671875, -17302.84375, -1592.9022216796875, -211.60272216796875]), 's1', 2722)
(set([-968.17529296875, -903.794921875, 2173.232177734375, -287.991455078125, -30.6038818359375, 841.5855712890625]), 's2', 3337)
...
```

Tensorflow serving has a similar corrupted results issue https://github.com/tensorflow/serving/issues/335, but this seems to be a tensorflow gpu memory problem. With @yaroslavvb memory_util.py, it seems when sess1 and sess2 interleaving in memory allocation/deallocation and gpu memory address (the second to last column in the log) is reused, results will be corrupted. The shortest trace I found is
```
(set([-968.17529296875]), 's2', 1)
('**************', 's2', 2)
(set([-17430.388671875]), 's1', 1)
('**************', 's1', 2)
(set([-968.17529296875, -875.1435546875]), 's2', 2)
       11                     s2/matmul1(44-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation
       23                     s1/matmul1(46-gpu_bfc)       40960       81920 gpu_bfc 30103375360 MemoryLogTensorAllocation
       26                     s2/matmul2(47-gpu_bfc)       40960      122880 gpu_bfc 30103416320 MemoryLogTensorAllocation
       28                     s2/matmul1(44-gpu_bfc)      -40960       81920 gpu_bfc -1 MemoryLogTensorDeallocation
       31                     s2/matmul2(47-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation
       35                     s1/matmul2(49-gpu_bfc)       40960       81920 gpu_bfc 30103334400 MemoryLogTensorAllocation
       37                     s1/matmul1(46-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation
       40                     s1/matmul2(49-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation
       61                     s2/matmul1(52-gpu_bfc)       40960       40960 gpu_bfc 30103334400 MemoryLogTensorAllocation
       66                     s2/matmul2(53-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation
       71                     s2/matmul1(52-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation
       80                     s2/matmul2(53-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation
       81                     s1/matmul1(56-gpu_bfc)       40960       40960 gpu_bfc 30103334912 MemoryLogTensorAllocation
       85                     s1/matmul2(57-gpu_bfc)       40960       81920 gpu_bfc 30103170560 MemoryLogTensorAllocation
       87                     s1/matmul1(56-gpu_bfc)      -40960       40960 gpu_bfc -1 MemoryLogTensorDeallocation
       90                     s1/matmul2(57-gpu_bfc)      -40960           0 gpu_bfc -1 MemoryLogTensorDeallocation
```

### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*: Ubuntu 14.04
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version* (use command below): 1.0.1
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*: cuda 8.0/cudnn5.1.5
- *GPU Model and Memory*: GRID K520, 4GB
- *Exact command to reproduce*: python multi_session.py

"
9204,deleted,
9202,Add support for matrix square root,"Please consider adding a [matrix square root](https://en.wikipedia.org/wiki/Square_root_of_a_matrix) operation, with gradients.
It will make it possible to implement [stable whitening](https://arxiv.org/abs/1512.00809), which could be broadly useful, in addition to being useful for my particular problem :)
Note, Cholesky whitening is currently supported in TensorFlow, but I'm not aware of any guarantees it provides regarding the correspondences between whitened and non-whitened data.

It appears Eigen [already has a matrix square root function](https://eigen.tuxfamily.org/dox/unsupported/group__MatrixFunctions__Module.html#matrixbase_sqrt), so this might not be too hard to implement."
9201,Tensorflow Still Trying to use CUDA even when Session Created with device_count={'GPU': 0},"### System Information
Using the `tensorflow/tensorflow:1.0.1-devel-gpu` Docker image.
`('v1.0.0-65-g4763edf-dirty', '1.0.1')`
Host: `Driver Version: 367.57`, `3.13.0-57-generic`

### Issue
If I `Set compute mode to EXCLUSIVE_PROCESS` on the Nvidia device (`sudo nvidia-smi -c 1`), then even though I tell the `Session` not to use GPUs (`config=tf.ConfigProto(device_count={'GPU': 0})`), Tensorflow attempts to use the GPU resulting in an inability to create session:
```
InternalErrorTraceback (most recent call last)
<ipython-input-1-cabf26c1451a> in <module>()
      1 import tensorflow as tf
      2 from tensorflow.python.framework import ops
----> 3 with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:
      4     pass

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)
   1174 
   1175     """"""
-> 1176     super(Session, self).__init__(target, graph, config=config)
   1177     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.
   1178     self._default_graph_context_manager = None

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)
    550     try:
    551       with errors.raise_exception_on_not_ok_status() as status:
--> 552         self._session = tf_session.TF_NewDeprecatedSession(opts, status)
    553     finally:
    554       tf_session.TF_DeleteSessionOptions(opts)

/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)
     22         if type is None:
     23             try:
---> 24                 self.gen.next()
     25             except StopIteration:
     26                 return

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()
    464           None, None,
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:
    468     pywrap_tensorflow.TF_DeleteStatus(status)

InternalError: Failed to create session.
```
This can be demonstrated by running:
```
import tensorflow as tf
from tensorflow.python.framework import ops
with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:
    pass
```
when another process is using CUDA and the exclusive process mode is set.

If exclusive process mode is _not_ set, then the session is created but using `nvidia-smi`, I see that the process is using GPU ram (and CUDA):
```
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      2237    C   /usr/bin/python                                 61MiB |
```

The issue seems limited to TF trying to lock the CUDA device (an allocate ~61MB memory). Subsequent computations do happen correctly on the CPU."
9194,XLA: Help understanding compute path for HLO graph,"@aidan-plenert-macdonald and I are trying to figure out how the HLO graph is being passed around during xla computations. I'm moving computations over to a new device and am attempting to intercept the graph to see how it's represented, in order to replicate the structure.

A list of the files where I added print statements is included below. Almost none of them print (only Registrar initialization in hlo_graph_dumper.cc, the Transfer functions in client.cc and service.cc, and the CpuCompiler and XpuCompiler initializations), and I've added statements in almost every function in the attached files.

Where is the HLO graph being assembled and dumped? How do I access the HLO graph?

Note: the 'xpu' folder/files are for my new device - they're replicas of the 'cpu' folder/files in compiler/xla/service, with all mentions of 'cpu' changed to 'xpu'. List of files with print statements:
```
./compiler/aot/compile.cc
./compiler/jit/encapsulate_subgraphs_pass.cc
./compiler/jit/mark_for_compilation_pass.cc
./compiler/tf2xla/kernels/batch_matmul_op.cc
./compiler/tf2xla/kernels/gather_op.cc
./compiler/tf2xla/xla_compiler.cc
./compiler/xla/client/client.cc
./compiler/xla/service/cpu/cpu_compiler.cc
./compiler/xla/service/hlo_computation.cc
./compiler/xla/service/hlo_graph_dumper.cc
./compiler/xla/service/layout_assignment.cc
./compiler/xla/service/service.cc
./compiler/xla/service/user_computation.cc
./compiler/xla/service/xpu/xpu_compiler.cc
./compiler/xla/service/xpu/xpu_executable.cc
./compiler/xla/tests/hlo_test_base.cc
./core/common_runtime/function.cc
./core/common_runtime/graph_optimizer.cc
```"
9191,TensorFlow crashing when batching audio,"I have tried to create an audio processing model using tensorflow.contrib.ffmpeg. The code I wrote consistently crashes the python process on my OS X. I have provided both the code and a piece of crash report on this stackoverflow question. 

http://stackoverflow.com/questions/43377986/batching-audio-data-in-tensorflow/

Is this a bug or am I doing something wrong?"
9190,SpaceToBatchND / BatchToSpaceND Documentation Error,"
I think there is an error in the *documentation* for SpaceToBatchND and BatchToSpaceND.  (The op itself seems to be working fine.)

In example (3) from SpaceToBatchND:

> (3) For the following input of shape [1, 4, 4, 1], block_shape = [2, 2], and paddings = [[0, 0], [0, 0]]:
> 
> ```prettyprint x = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]], [[9], [10], [11], [12]], [[13], [14], [15], [16]]]] ```
> 
> The output tensor has shape [4, 2, 2, 1] and value:
> 
> ```prettyprint x = [[[[1], [3]], [[5], [7]]], [[[2], [4]], [[10], [12]]], [[[5], [7]], [[13], [15]]], [[[6], [8]], [[14], [16]]]] ```

Note how [[5],[7]] appears twice in the result and [[9],[11]] is missing.

The example (3) in BatchToSpaceND has the same problem in reverse.

If I actually try this op in TensorFlow, I get results that differ from the documentation but make sense to me:

```

>>> bshape = [2,2]
>>> paddings = [[0,0],[0,0]]
>>> x  = [[[[1], [2], [3], [4]], [[5], [6], [7], [8]], [[9], [10], [11], [12]], [[13], [14], [15], [16]]]]
>>> s2btest = tf.space_to_batch_nd(x,bshape,paddings)
>>> sess.run(s2btest)
array([[[[ 1],
         [ 3]],

        [[ 9],
         [11]]],


       [[[ 2],
         [ 4]],

        [[10],
         [12]]],


       [[[ 5],
         [ 7]],

        [[13],
         [15]]],


       [[[ 6],
         [ 8]],

        [[14],
         [16]]]], dtype=int32)

```


Example tried with TensorFlow from source / Linux Ubuntu Xenial / v1.1.0-rc1-168-g0054c39 1.1.0-rc1
.

Documentation from https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/batch-to-space-n-d and https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/space-to-batch-n-d 

Looking at the doc string this may be fixed in master (d1ba01f8) and just not updated on the 1.0 branch web docs yet.

"
9188,Improving tf.cond,"Currently `tf.cond` requires a function for each branch, which makes no difference semantically but serves as an optimization hint. Such requirement becomes quite inconvenient in some cases, for example,

```
def build_graph(p1, p2):
    a = a_fn() # Redundant when p1 and p2 are both false.
    b1 = tf.cond(p1, lambda: a, b1_fn)
    b2 = tf.cond(p2, lambda: a, b2_fn)
    return b1, b2

# An alternative
def build_graph(p1, p2):
    # Redundant computation when p1 and p2 are both true.
    b1 = tf.cond(p1, a_fn, b1_fn)
    b2 = tf.cond(p2, a_fn, b2_fn)
    return b1, b2
```

Though possible, it is not so straightforward to transform the above graph into an efficient one. In fact, we don't really need the optimization hint. Once target nodes are known, the exact execution condition for each node can be readily calculated. Furthermore, these conditions can be implemented using existing `Switch` and `Merge` ops. I have made a prototype to illustrate the idea at https://github.com/tensorflow/tensorflow/pull/9189."
9187,README.md has a deprecated API call,"### System Information
Tensorflow ('v1.0.0-65-g4763edf-dirty', '1.0.1')


### Describe the problem clearly
In README.md line `predictions = vgg.vgg16(images, is_training=True)` should be `predictions = vgg.vgg_16(images, is_training=True)` (see [source code for vgg](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/vgg.py)). 
"
9186,TFRecordReader num_records_produced() and num_work_units_completed() do not work,"Hey guys, since I've been dealing a lot with TFRecord files lately, I stumbled upon the following bug:

```
file_queue = init_queue(dataset)

records_reader = tf.TFRecordReader(name='...')

_, record = records_reader.read(file_queue, name='...')

 #do something with record in a while loop
```




And when I call the two aforementioned functions they always return 0. I am sure I have used the records since I have seen the end results dumped to an excel spreadsheet.

Cheers, Kris

"
9185,Windows: //tensorflow/python/estimator:estimator_test failing in Bazel build,"http://ci.tensorflow.org/job/tf-master-win-bzl/751/consoleFull

It has been failing on ci for a while with:
```
22:36:33 ======================================================================
22:36:33 ERROR: test_train_save_copy_reload (__main__.EstimatorTrainTest)
22:36:33 ----------------------------------------------------------------------
22:36:33 Traceback (most recent call last):
22:36:33   File ""\\?\c:\tmp\Bazel.runfiles_r2z2r52c\runfiles\org_tensorflow\py_test_dir\tensorflow\python\estimator\estimator_test.py"", line 267, in test_train_save_copy_reload
22:36:33     os.renames(model_dir1, model_dir2)
22:36:33   File ""C:\Program Files\Anaconda3\lib\os.py"", line 288, in renames
22:36:33     rename(old, new)
22:36:33 PermissionError: [WinError 5] Access is denied: 'c:\\tmp\\tmp8f7qnomv\\model_dir1' -> 'c:\\tmp\\tmp8f7qnomv\\model_dir2'
```
@gunan Can we fix this test case on Windows? Otherwise we'd better disable this test on Windows."
9184,"tensorflow 1.0.1 + Python3 - TypeError: string argument expected, got 'NoneType'","Hi all,
I am trying to install tensorflow 1.0.1 from source on RHEL 6.6 with CUDA 7.5 & CUDNN 5.0.5.
I am repeatedly getting following error-

$ pip3 install ./tensorflow-1.0.1-cp36-cp36m-linux_x86_64.whl --root=""$INSTALL_ROOT_DIR"" 
Processing ./tensorflow-1.0.1-cp36-cp36m-linux_x86_64.whl
Requirement already satisfied: protobuf>=3.1.0 in /home/apps/PYTHONPACKAGES/3.6.0/ucs4/gnu/493/PROTOBUF/3.2.0/gnu/lib/python3.6/site-packages/protobuf-3.2.0-py3.6.egg (from tensorflow==1.0.1)
Exception:
Traceback (most recent call last):
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/site-packages/pip/commands/install.py"", line 335, in run
    wb.build(autobuilding=True)
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/site-packages/pip/wheel.py"", line 749, in build
    self.requirement_set.prepare_files(self.finder)
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/site-packages/pip/req/req_set.py"", line 380, in prepare_files
    ignore_dependencies=self.ignore_dependencies))
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/site-packages/pip/req/req_set.py"", line 666, in _prepare_file
    check_dist_requires_python(dist)
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/site-packages/pip/utils/packaging.py"", line 48, in check_dist_requires_python
    feed_parser.feed(metadata)
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/email/feedparser.py"", line 175, in feed
    self._input.push(data)
  File ""/home/soft/PYTHON/3.6.0/ucs4/gnu/447/lib/python3.6/email/feedparser.py"", line 103, in push
    self._partial.write(data)
TypeError: string argument expected, got 'NoneType'


Please let me know if any further information is required from my side to debug this issue.
Though, I  have previously compiled tf-1.0.1 using python 2.7, but currently, I have to stick to python3 for this installation.
"
9183,The running speed of Windows is lower than that in Linux,"Please go to Stack Overflow for help and support. http://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

1. It must be a bug or feature request.
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g. fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### System Information
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *OS Platform and Distribution (i.e. Linux Ubuntu 16.0)*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version* (use command below):
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

You can collect some of this information using our environment capture script https://github.com/tensorflow/tensorflow/blob/master/tools/
You can collect the TensorFlow version with
```sh
python -c ""import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)""
```


### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9182,tf.layers.conv3d channels_first not supported,"Hi , 

When I use tf.layers.conv3d function, I meet a problem, there is a data_format setting in this function, and I want to set this to 'channels_first' , however error occurred: Data format ""channels_first"" not supported for inputs with rank 5.
The tensorflow version I used is 1.0.0, I wonder in which version does 'channels_first' is supported in 3d convolution?

Thanks

Qiang"
9180,Make `py_func` accept `SparseTensor`,"### Describe the problem clearly
According to the [doc](https://www.tensorflow.org/api_docs/python/tf/py_func), `py_func` accepts `inp` as a list of tensors (or convertible to tensor). However `SparseTensor` is not one of them. Could we support `SparseTensor` as well? Semantically there is no reason to treat `SparseTensor` differently.

### Source Code / Logs
```
my_sparse_tensor = tf.SparseTensor(...)
tf.py_func(my_py_func, [my_sparse_tensor, ...], [tf.float32])
```
What I got:

`TypeError: Tensors in list passed to 'input' of 'PyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, ...] that are invalid`.
"
9179,Failed to add dependency with tf.identity,"### System Information
ArchLinux, TensorFlow 1.0.1 binary for py3.6
- *Exact command to reproduce*:
```python
import tensorflow as tf
a = tf.get_variable('a', shape=[])
update_op = a.assign_add(1.0)

cost = tf.reduce_mean(tf.get_variable('x', shape=[10]))
with tf.control_dependencies([update_op]):
    cost = tf.identity(cost)

train = tf.train.GradientDescentOptimizer(0.1).minimize(cost)
sess = tf.Session()
sess.run(tf.global_variables_initializer())

for k in range(10):
    sess.run([cost])
    print(sess.run([a]))    # a increases

for k in range(10):
    sess.run([train])
    print(sess.run([a]))    # a doesn't increase
```
Looks like the `train` op doesn't depend on `update_op`.
In terms of computation, backprop doesn't depend on the value of cost.  Is this intended?

UPDATE: Turns out that `tf.gradients` doesn't have a dependency over its first argument, although intuitively I thought the opposite. This is a feature. Closing.."
9178,Unable to use ci_build to build tensorflow,"### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No
- *TensorFlow installed from (source or binary)?*: Source
- *TensorFlow version*: `master` and  `f8dce81aeaff40dc78d398741854ad8766806f91`
- *Bazel version (if compiling from source)*: 0.4.5 
- *CUDA/cuDNN version*: N/A
- *GPU Model and Memory*: N/A
- *Exact command to reproduce*:

`tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`

Note: make sure you run with a clean state machine

### Describe the problem clearly

I'm trying to use ci_build tool to build tensorflow from source, but I am always got the error at step `/install/install_buildifier.sh`

```
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
____Loading package: buildifier
____Loading package: @bazel_tools//tools/cpp
____Loading package: @bazel_tools//tools/jdk
____Loading package: @local_config_xcode//
____Loading package: @local_jdk//
____Loading package: @local_config_cc//
____Loading complete.  Analyzing...
____Loading package:
____Loading package: @bazel_tools//tools/genrule
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 4,184,939 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 8,690,539 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 14,736,235 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 19,537,920 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 24,485,888 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 29,597,696 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 34,791,424 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 39,903,232 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 45,064,192 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 50,339,840 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 55,648,256 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 61,497,344 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 67,166,208 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 73,048,064 bytes
____Downloading https://storage.googleapis.com/golang/go1.7.4.linux-amd64.tar.gz: 78,733,312 bytes
____Loading package: @io_bazel_rules_go_toolchain//
ERROR: /buildifier/build/BUILD.bazel:4:1: no such package '@org_golang_x_tools//cmd/goyacc': no such package '@io_bazel_rules_go_repository_tools//': Traceback (most recent call last):
    File ""/root/.cache/bazel/_bazel_root/972a279007c925820266f3ac7b1d6afd/external/io_bazel_rules_go/go/private/go_repositories.bzl"", line 85
        _fetch_repository_tools_deps(ctx, goroot, gopath)
    File ""/root/.cache/bazel/_bazel_root/972a279007c925820266f3ac7b1d6afd/external/io_bazel_rules_go/go/private/go_repositories.bzl"", line 54, in _fetch_repository_tools_deps
        ctx.download_and_extract('%s/archive/%s.zip' % (dep.repo,...), <4 more arguments>)
java.io.IOException: Prefix buildifier-4190564903f61ddc94bcfda3dc2cdd32d4b330e5 was given, but not found in the zip and referenced by '//build:parse.y.go_yacc'.
ERROR: Analysis of target '//buildifier:buildifier' failed; build aborted.
____Elapsed time: 10.455s
```

I did google around and may be this is root cause https://github.com/bazelbuild/rules_go/issues/361"
9177,How to add an external java library(.jar) into Bazel build path.,"### Describe the problem clearly
I follow the rule in [Bazel website](https://bazel.build/versions/master/docs/be/android.html#android_binary.shrink_resources) to add a JAR into Bazel build path, this is my script:

...
android_binary(
    ...
    deps = [
        "":tensorflow_native_libs"",
        ""//tensorflow/contrib/android:android_tensorflow_inference_java"",
	**"":libs/nd4j-api-0.8.0.jar""**
    ],
)
...

but the log says that my JAR is misplaced.
How should I do to add a JAR library into build path or do I miss out something ?

Thanks,

### Source Code / Logs
ERROR: /home/bob/deep_learning/tensorflow/tensorflow/examples/android/BUILD:76:12: in deps attribute of android_binary rule //tensorflow/examples/android:tensorflow_demo: file '//tensorflow/examples/android:libs/nd4j-api-0.8.0.jar' is misplaced here (expected no files).
ERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted.

"
9176,ImportError: No module named 'tensorflow.python.debug.lib',"C:\Users\varada.vamsi\AppData\Local\Programs\Python\Python35\python.exe C:/Users/varada.vamsi/PycharmProjects/untitled/test.py
Traceback (most recent call last):
  File ""C:/Users/varada.vamsi/PycharmProjects/untitled/test.py"", line 31, in <module>
    from tensorflow.python import debug as tf_debug
  File ""C:\Users\varada.vamsi\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\debug\__init__.py"", line 37, in <module>
    from tensorflow.python.debug.lib.debug_data import DebugDumpDir
ImportError: No module named 'tensorflow.python.debug.lib'

Process finished with exit code 1"
9172,possible doc inconsistency `tf.contrib.framework.load_variable`,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly
In my experience, this function `tf.contrib.framework.load_variable` returns a `numpy.ndarray` instead of a `Tensor` as the [doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/framework/python/framework/checkpoint_utils.py#L74) suggests. Furthermore according to the [unit test](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/framework/python/framework/checkpoint_utils_test.py#L96), it is expected to return the value of a tensor instead of a `Tensor` object itself. I think the behavior of returning tensor values is desired (to load select variables from arbitrary checkpoints without a session), so this should be a minor doc issue.

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9171,tf.set_random_seed does not reset random op state,"TF Version: 1.1.0rc1 (installed from nightly: `Apr 10, 2017 1:03 AM`)
(run on CPU, Python 2)

```
import tensorflow as tf
import numpy as np

sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

tf.set_random_seed(1)
a = tf.truncated_normal_initializer(seed=None)([1])
print(a.eval())

tf.set_random_seed(1)
b = tf.truncated_normal_initializer(seed=None)([1])
print(b.eval())
```

Output:
```
[ 1.05293429]
[-0.4487586]
```

Expected:
The same value, since...
> If the graph-level seed is set, but the operation seed is not: The system deterministically picks an operation seed in conjunction with the graph-level seed so that it gets a unique random sequence.

The values are identical in repeated runs of the whole script, but not after resetting the graph-level seed (as in the example above).

(possibly related to https://github.com/tensorflow/tensorflow/issues/9003)"
9170,[Windows] `import tensorflow` error messages are uninformative.,"When a user runs `import tensorflow`, we attempt to dynamically load the DLL `_pywrap_tensorflow.pyd`. If this fails, the user gets an uninformative (perhaps downright misleading) message:

```
Traceback (most recent call last): 
File ""C:\...\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)])
File ""C:\...\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'
```

This error can happen for several reasons:

* (Rare) The package has not been installed correctly, and the file `_pywrap_tensorflow.pyd` is not present in the expected location.
* The package has been installed for an incompatible version of Python (e.g. installed on Python 3.6, but built for 3.5, as in #9167). I suspect this is because it fails to load `python35.dll`.
* The library has been installed correctly, but one or more of its native dependencies is missing. Common examples include:
  * `MSVCP140.dll` (the Microsoft Visual C++ redistributable library). The compiled C++ code depends on this library being present, but it is not installed as standard, unless you use Anaconda. (See [this Stack Overflow question](http://stackoverflow.com/a/42011114/3574081), for example.)
  * CUDA libraries. The user's `%PATH%` may not include the directory that contains the CUDA DLLs.
  * `cudnn64_5.dll`. This is typically installed in a different directory from the CUDA libraries, and must be added to the user's `%PATH%` explicitly.

It would be helpful if we could provide more information about the cause of an `ImportError`, and in particular we would like to show the name of the missing DLL to aid the user in diagnosing the problem. It's less clear to me how we achieve this, since the error is reported by `LoadLibrary()` of our compiled code before we have the chance to execute anything.

A couple of thoughts spring to mind:

1. Can we use [`/DELAYLOAD`](https://msdn.microsoft.com/en-us/library/151kt790.aspx) during the build process so that (at least) we have the chance to probe the CUDA-related libraries before using them? Are there any performance consequences to doing this? 
2. Alternatively, can we implement a sanity check in Python before we import `_pywrap_tensorflow.pyd` to ensure that the relevant files will be found? 

/cc @guschmue @vit-stepanovs in case they have any smart ideas!"
9169,"Loading LSTM ""SavedModel"" from golang results in crash","NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: 1.0.1
- *Bazel version (if compiling from source)*: -
- *CUDA/cuDNN version*: - 
- *GPU Model and Memory*: -
- *Exact command to reproduce*: -

### Describe the problem clearly

I have a 'saved model' of a NN that look like this (keras - model.summary()):
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 15, 300)           0         
_________________________________________________________________
masking_1 (Masking)          (None, 15, 300)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 300)               721200    
_________________________________________________________________
dropout_1 (Dropout)          (None, 300)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 145)               43645     
_________________________________________________________________
activation_1 (Activation)    (None, 145)               0         
=================================================================
Total params: 764,845.0
Trainable params: 764,845.0
Non-trainable params: 0.0
_________________________________________________________________
```
When I try to load it using the golang bindings, it results in a crash:
```
$ go run example.go 
I tensorflow/cc/saved_model/loader.cc:194] Loading SavedModel from: ./load
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/cc/saved_model/loader.cc:114] Restoring SavedModel bundle.
I tensorflow/cc/saved_model/loader.cc:148] Running LegacyInitOp on SavedModel bundle.
I tensorflow/cc/saved_model/loader.cc:238] Loading SavedModel: success. Took 150044 microseconds.
fatal error: unexpected signal during runtime execution
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x8c1a6cc]

runtime stack:
runtime.throw(0x40cadf9, 0x2a)
	/usr/local/go/src/runtime/panic.go:596 +0x95
runtime.sigpanic()
	/usr/local/go/src/runtime/signal_unix.go:274 +0x2db

goroutine 1 [syscall, locked to thread]:
runtime.cgocall(0x4094920, 0xc420053dd0, 0x40cabb6)
	/usr/local/go/src/runtime/cgocall.go:131 +0xe2 fp=0xc420053d90 sp=0xc420053d50
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_LoadSessionFromSavedModel(0x4516690, 0x0, 0x45167c0, 0xc42000e030, 0x1, 0x4515e50, 0x0, 0x45135f0, 0x0)
	github.com/tensorflow/tensorflow/tensorflow/go/_obj/_cgo_gotypes.go:438 +0x51 fp=0xc420053dd0 sp=0xc420053d90
github.com/tensorflow/tensorflow/tensorflow/go.LoadSavedModel.func1(0x4516690, 0x0, 0x45167c0, 0xc42000e030, 0x1, 0x4515e50, 0x0, 0x45135f0, 0x414d0f0)
	/Users/berset/git/gopath/src/github.com/tensorflow/tensorflow/tensorflow/go/saved_model.go:56 +0x156 fp=0xc420053e28 sp=0xc420053dd0
github.com/tensorflow/tensorflow/tensorflow/go.LoadSavedModel(0x40c5552, 0x6, 0xc420053f68, 0x1, 0x1, 0x0, 0x0, 0x4124480, 0x40a49e0)
	/Users/berset/git/gopath/src/github.com/tensorflow/tensorflow/tensorflow/go/saved_model.go:56 +0x1b4 fp=0xc420053ed8 sp=0xc420053e28
main.main()
	/Users/berset/git/gopath/src/github.com/campanja/ssinet/example.go:9 +0x8e fp=0xc420053f88 sp=0xc420053ed8
runtime.main()
	/usr/local/go/src/runtime/proc.go:185 +0x20a fp=0xc420053fe0 sp=0xc420053f88
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:2197 +0x1 fp=0xc420053fe8 sp=0xc420053fe0

goroutine 17 [syscall, locked to thread]:
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:2197 +0x1
exit status 2
$ 
```


### Source Code / Logs

The go code looks like this:

```
package main

import (
    ""fmt""
    tf ""github.com/tensorflow/tensorflow/tensorflow/go""
)

func main() {
    m, err := tf.LoadSavedModel(""./load"", []string{""serve""}, nil)
    if err != nil {
        fmt.Println(err)
    }
    fmt.Println(m)
    fmt.Println(""load successful!"")
}
```

I'm attaching a sample saved model and the code to generate the crash.

[sample.zip](https://github.com/tensorflow/tensorflow/files/917065/sample.zip)

I can use the same code/bundling process to save / load NNs with only Dense layers for example.
I also did try to printf debug this and I think the problem arises around the ""TensorArrayV3"" or ""TensorArrayReadV3"" or some such operation."
9168,"When I use the Bazel to compile the image_retraining project when the error occurred, ","NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly
When I use the Bazel to compile the image_retraining project when the error occurred, how to solve, spec.json, head, branch_ref these documents are not in that directory, did you made some change that now cannot compile directory:
wei@wei-TA960:~/myprogramfile/TF-0.12/tensorflow-r0.12-1$ bazel build tensorflow/examples/image_retraining:retrain
ERROR: /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/core/BUILD:1117:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/core/BUILD:1117:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/core/BUILD:1117:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /home/wei/myprogramfile/TF-0.12/tensorflow-r0.12-1/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9167,Windows 7: No module named '_pywrap_tensorflow',"My problem is with import TF module. Here is my configuration: Python 3.6.1, Windows 7 64-bit. I've MSVCP140.dll library in 'C:\Windows\System32\' and 'C:\Windows\SysWOW64\' folders. I also have instaled Update 3 for VS2015 C++.

In Windows PATH varitable I have such value related to python:
C:\Users\Jacek\AppData\Local\Programs\Python\Python36\Scripts\
C:\Users\Jacek\AppData\Local\Programs\Python\Python36\

Steps which I made:

I've installed TensorFlow by command (in power shell). It works.

`python -m pip install --upgrade tensorflow`
But when I run python environment and try import Tensor Flow

`import tensorflow as tf`
I get errors, this error raise another errors related with it, but at the beginning I want to resolve this first

> Traceback (most recent call last): File ""C:\Users\Jacek\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)]) File ""C:\Users\Jacek\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 296, in find_module raise ImportError(_ERR_MSG.format(name), name=name) ImportError: No module named '_pywrap_tensorflow'"
9166,Example Cluster Spec for Distributed YoutTube-8m challenge training,"Hi,

Can you please post a  ClusterSpec for distributed training of the models defined in  the [YouTube-8m Challenge code](https://github.com/google/youtube-8m)? 
The [code](https://github.com/google/youtube-8m/blob/master/train.py#L628) tries to load a cluster spec from TF_CONFIG environment variable. However, I'm not sure what the value for TF_CONFIG should be. I have access to 2 GPUs on one machine and just want to run the model with data-level parallelism.

"
9164,tf.slim should not use relu as a default activation function,"It's hard to understand the reason why relu is chosen as a default activation function. It looks like the choice of default activation function is against common sense. If someone never read the actual code or forget about it, it's so easy to make a mistake.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L1387
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L822"
9162,Stop gradient for some entry of a tensor,"As far as I know, the tf.stop_gradient function can only stop the gradient of a whole tensor. I recently wanted to implement a model that requires the stop of gradient for some entry of a tensor (not the whole tensor). and I have come up with an workaround,
```
def entry_stop_gradients(target, mask):
    mask_h = tf.logical_not(mask)
    
    mask = tf.cast(mask, dtype=target.dtype)
    mask_h = tf.cast(mask_h, dtype=target.dtype)
    
    return tf.stop_gradient(mask_h * target) + mask * target
```
 
hope somebody could implement a low level version of this feature."
9161,"Hi, I am unable to access the documentation","NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9160,"bazel build macOS failing ""ld: unknown option: -zmuldefs""","- *TensorFlow installed from (source or binary)?*: source
- *TensorFlow version*: latest one checked out from git
- *Bazel version (if compiling from source)*:  0.4.5-homebrew
- *CUDA/cuDNN version*: 8.0 / 5.1 (6.0 fails earlier in the build)
- *GPU Model and Memory*: GeForce 750M 2GB
- *Exact command to reproduce*:bazel build --config=cuda --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem clearly
So I followed this general guide https://gist.github.com/ageitgey/819a51afa4613649bd18, after which I solved some compilation issues with http://stackoverflow.com/questions/39865212/dyld-library-not-loaded-rpath-libcudart-8-0-dylib-while-building-tensorflow?rq=1.

Doing this allowed me to compile more, but then the following errors occur.
### Source Code / Logs
```
ERROR: /Users/chris/git/tensorflow/tensorflow/python/BUILD:2533:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o ... (remaining 472 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
clang: warning: argument unused during compilation: '-pthread'
ld: unknown option: -zmuldefs
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1592.901s, Critical Path: 1309.60s
```
"
9159,[C++ API] safe string to int64 conversion,"In short:
```c++ 
strings::safe_strto64(""+1"", &value)
```
Throws an error because of the `+`.


I wrote an Op to read data in the LIBSVM format, which is the following:
`<label> <index1>:<value1> <index2>:<value2> ....`

The sample data provided at the [LIBSVM site](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/) uses `+1` as label instead of only a `1`.
The safe conversion throws an error because of the `+`:
```c++
int64 value;
string label(""+1"");
OP_REQUIRES(ctx, strings::safe_strto64(label, &value),
            errors::InvalidArgument(""Label "", label, 
                                    "" is not a valid int64.""));  
```
Traceback when calling the op in python:
```
Traceback (most recent call last):
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1022, in _do_call
    return fn(*args)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1004, in _run_fn
    status, run_metadata)
  File ""/usr/lib64/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Label +1 is not a valid int64.
	 [[Node: DecodeLibsvm = DecodeLibsvm[OUT_TYPE=DT_INT64, num_features=123, _device=""/job:localhost/replica:0/task:0/cpu:0""](shuffle_batch)]]
```

Is this the wanted behaviour and should I handle this before calling the conversion?"
9156,"hi everyone! im having this issue when trying to import tensorflow, i've tried all the techniques i've found on stackoverflow and here at GH but they still don't work","Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AM
D64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: Le module spécifié est introuvable.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\python35\lib\site-packages\tensorflow\python\__init__.py"", line 66, i
n <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""C:\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\python35\lib\site-packages\tensorflow\__init__.py"", line 24, in <modu
le>
    from tensorflow.python import *
  File ""C:\python35\lib\site-packages\tensorflow\python\__init__.py"", line 72, i
n <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: Le module spécifié est introuvable.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\python35\lib\site-packages\tensorflow\python\__init__.py"", line 66, i
n <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", l
ine 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""C:\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow'


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_st
arted/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>>"
9155,[Android Example] Demo does not perform well in low light,"Android [demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android) does not perform well in low light. I think a button for flashlight is needed.
For example:-
![demo](https://cloud.githubusercontent.com/assets/6515036/24878880/7b447f26-1e52-11e7-9b7f-df01f2e9f9d6.jpg)



"
9154,"consecutive calls of saver.restore(sess,path) slows down","### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: no
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: 0.12.1
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*: cpu

### Describe the problem clearly
Hi I was building and evaluating ensemble models about 45 very simple neural networks.

when evaluating, I noticed that consecutive calls to ```saver.restore(sess, path)``` slows down

at first it spent about 0.08 seconds but after 45 calls to  ```saver.restore()```, time spent on restore increased to 0.5 seconds. It kept increasing to 1 second and beyond. 

Is anyone having the same problem? In the source code, I called ```test_model()``` consecutively. Other part didn't slow down but only the part with saver.restore() did

### Source Code / Logs
```python
def test_model(model, batch_gen, batch_num, batch_size, num_class, model_id):

    saver = tf.train.Saver()
    start_time = time.time()

    print('## Testing model : {}'.format(model_id))
    with tf.Session() as sess:
        ot = time.time()
        sess.run(tf.global_variables_initializer())
        # Load latest model to evaluate
        checkpoint_dir = CHECKPOINTS_DIR+str(model_id)+'/'

        ckpt = tf.train.get_checkpoint_state(os.path.dirname(checkpoint_dir))

        
        if ckpt and ckpt.model_checkpoint_path:
            saver.restore(sess, ckpt.model_checkpoint_path)
        else:
            print('# No trained weight found')
            return
        nt = time.time()
        print('1 : {}'.format(nt-ot))

        vote_list = []
        for i in xrange(batch_num):
            X_batch, Y_batch = batch_gen.next()
            _, loss_batch, softmax_batch = sess.run([model.optimizer, model.loss, model.softmax], feed_dict={model.input: X_batch, model.output:Y_batch}) 
            
            vote_batch = dense_to_one_hot(np.argmax(softmax_batch,1), num_class)
            vote_list.append(vote_batch)

        total_vote_list = np.concatenate(vote_list, 0)
   
        print('# time elapsed :{:.1f} seconds'.format(time.time() - start_time ))
    return total_vote_list
```

------------------EDIT------------------

Problem was not ```saver.restore()``` but consecutive calling of
```python
sess.run(tf.global_variables_initializer())
````
session is suppose to free all the memories right?
so I think there has to be no performance slow down but there is when making multiple sessions

```python
import time
import tensorflow as tf

a = tf.Variable([1,2,3,4,5])

def test():
    for i in range(1000):
        with tf.Session() as sess:
            ot = time.time()
            sess.run(tf.global_variables_initializer())
            nt = time.time()
            print('test : {:.3f}'.format(nt-ot))
```
running time of `tf.global_varaiables_initializer()` op slowly increases"
9153,Docker Build Error,"
I am building tf dockerimages for both cuda 8.0 and 7.5 from source. But both cames error at bazel build procedure with message:

> The command '/bin/sh -c tensorflow/tools/ci_build/builds/configured GPU     bazel build -c opt --config=cuda tensorflow/tools/pip_package:build_pip_package &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &&     pip --no-cache-dir install --upgrade /tmp/pip/tensorflow-*.whl &&     rm -rf /tmp/pip &&     rm -rf /root/.cache' returned a non-zero code: 2


some times there would be an additional message like:

> ERROR: Evaluation of query ""deps(((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...))"" failed: errors were encountered while computing transitive closure

I cloned r1.1 branch and mainly followed the scripts in original dockerfile(devel-gpu version), with only python and cuda env modified. Also I found that original dockerfile would also meet same issue. 
I guess it might be caused by some download error when getting dependencies from bazel-mirror on googleapis. 
Is that possible to manually download those packages or try some alternative way like disable some function? Any hint?"
9152,"can not run mnistcnn.py, servers waiting for eachother ","Hello everyone, I tried to run this script on three AWS machines. One parameter server and two workers.
However, the ps is always in ""Initializing session..."" and workers always waiting for the ps.

I believe the challenge is from here: 
ps definitions:
flags.DEFINE_integer(""worker_index"", 0,
                     ""Worker task index, should be >= 0. worker_index=0 is ""
                     ""the master worker task the performs the variable ""
                     ""initialization "")

flags.DEFINE_string(""workers"", ""34.205.143.107:2222,54.83.142.82:2222"",
                    ""The worker url list, separated by comma (e.g. tf-worker1:2222,1.2.3.4:2222)"")

flags.DEFINE_string(""parameter_servers"", ""http://54.86.223.142:2222"",
                    ""The ps url list, separated by comma (e.g. tf-ps2:2222,1.2.3.5:2222)"")

flags.DEFINE_string(""worker_grpc_url"", ""grpc://54.86.223.142:2222"",
                    ""Worker GRPC URL (e.g., grpc://1.2.3.4:2222, or ""
                    ""grpc://tf-worker0:2222)"")

worker definitions:
flags.DEFINE_integer(""worker_index"", 1,
                     ""Worker task index, should be >= 0. worker_index=0 is ""
                     ""the master worker task the performs the variable ""
                     ""initialization "")

flags.DEFINE_string(""workers"", ""34.205.143.107:2222,54.83.142.82:2222"",
                    ""The worker url list, separated by comma (e.g. tf-worker1:2222,1.2.3.4:2222)"")

flags.DEFINE_string(""parameter_servers"", ""http://54.86.223.142:2222"",
                    ""The ps url list, separated by comma (e.g. tf-ps2:2222,1.2.3.5:2222)"")

flags.DEFINE_string(""worker_grpc_url"", ""grpc://34.205.143.107:2222"",
                    ""Worker GRPC URL (e.g., grpc://1.2.3.4:2222, or ""
                    ""grpc://tf-worker0:2222)"")
second worker
flags.DEFINE_integer(""worker_index"", 2,
                     ""Worker task index, should be >= 0. worker_index=0 is ""
                     ""the master worker task the performs the variable ""
                     ""initialization "")

flags.DEFINE_string(""workers"", ""34.205.143.107:2222,54.83.142.82:2222"",
                    ""The worker url list, separated by comma (e.g. tf-worker1:2222,1.2.3.4:2222)"")

flags.DEFINE_string(""parameter_servers"", ""http://54.86.223.142:2222"",
                    ""The ps url list, separated by comma (e.g. tf-ps2:2222,1.2.3.5:2222)"")

flags.DEFINE_string(""worker_grpc_url"", ""grpc://83.142.82:2222"",
                    ""Worker GRPC URL (e.g., grpc://1.2.3.4:2222, or ""
                    ""grpc://tf-worker0:2222)"")
[mnistcnn.txt](https://github.com/tensorflow/tensorflow/files/915085/mnistcnn.txt)


We appreciate any assistance .


"
9150,C API Tensors,"I am currently using the C API and building a Scala API on top of it. It seems that what is done in the Python API and the Java API is that the tensors fed into sessions are being copied to buffers internal to the native library. I am also currently doing that in the Scala library but I was wondering if we can do the following:

Let's assume we can share a pointer to the underlying data structure between C and Scala (through a Java NIO DirectMemoryBuffer for example). Then, is there any functionality to obtain a tensor ""view"" that is a slice of that tensor, directly using that buffer? I imagine that since the TF op kernels are implemented in C++, it should be possible to use the StridedSlice op directly on a tensor data structure (without needing to use a session). The same idea can be extended to other ops. So, first of all, is that true?

Secondly, if it is, where is that functionality available in the C API (or exposed elsewhere) so that I can use it from within my Scala library? I currently do the indexing on the byte buffer myself, but that can be painful for arbitrary slices.

One main issue with sharing a pointer is how to deal with the Java garbage collector. I haven't figured that out yet, but even if I can't do that, the above comment still applies. How can I use op kernels directly in order to manipulate tensors outside of the symbolic graph? That is useful for languages other than Python, where a library as powerful as numpy is not available.

Thank you!"
9149,Optimization flags are erroneously ignored in compilation of Tensorflow 1.1.0-rc1,"I am getting a large number of optimization flag related warnings in compilation of Tensorflow 1.1.0-rc1 from source

```
/usr/include/features.h:330:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]
 #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)
    ^
```
System Information:  
OS:CentOS 7
GCC: gcc 4.8.5
Python: python3.5
Tensorflow version:  TensorFlow 1.1.0-rc1
Bazel:  version 0.4.5
CUDA: CUDA 8.0 with GTX 1080 GPU

in the prompt of ./configure:

```
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3.5
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] Y
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
```
explicitly typing `-march=native -O2` or `-O2` in the line `Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: `""doesn't help. 

to compile I used:

`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

I tried as early as tensorflow version 1.0.0 and I always get the ""`warning _FORTIFY_SOURCE requires compiling with optimization (-O)`"". Tensorflow version 0.12.1 doesn't seem to have this problem for me. 

Related issue:
#2153 
"
9148,Feature Request - conv1d_transpose,Would make things easier
9147,`model_checkpoint_dir` in `ProjectorConfig` is not implemented,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly
`model_checkpoint_dir` is defined in the [projector_config.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/plugins/projector/projector_config.proto#L45) definition but currently, it is not functional. I believe there is missing logic in [tensorboard/plugins/projector/projector_plugin.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/plugins/projector/projector_plugin.py): in fact, a quick search reveals that `model_checkpoint_dir` does not appear in source. There is good reason to support this (seemingly planned) feature as checkpoint files and summary event files are often saved under different directories. 

I would love to contribute a solution.

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9146,Cannot move checkpoint files saved with an absolute path,"When the checkpoint save path is an absolute path, moving the checkpoint results in a failure. 

TensorFlow was installed from source branch v1.0.1

Python script to reproduce:

```python
#!/usr/bin/env python
from __future__ import print_function

import sys

import os
import tensorflow as tf


def load_and_save(saver, session, model_dir):
    print(""Looking for models in : "" + model_dir)
    incumbent = tf.train.latest_checkpoint(model_dir)
    if incumbent is not None:
        print(""Loading incumbent: "" + incumbent)
        saver.restore(session, incumbent)
    else:
        print(""No incumbent found..."")
        tf.global_variables_initializer().run()

    out_path = os.path.join(model_dir, 'model')
    print(""Saving to: "" + out_path)
    saver.save(session, out_path)


def test(first_dir, second_dir):
    # clean up for idempotence
    os.system('rm -rf {}'.format(second_dir))

    if not os.path.exists(first_dir):
        os.makedirs(first_dir)

    with tf.Graph().as_default(), tf.Session() as session:
        test_var = tf.get_variable('test', [50, 50], dtype=tf.float32, initializer=tf.random_normal_initializer())
        saver = tf.train.Saver([test_var])

        # save to the first abs path dir
        load_and_save(saver, session, first_dir)

        # move to to the second dir
        mv_command = 'mv {} {}'.format(first_dir, second_dir)
        print(mv_command)
        os.system(mv_command)

        # attempt to load from the second dir
        load_and_save(saver, session, second_dir)


def main():
    # WORKS
    test('./FIRST_DIR', './SECOND_DIR')

    # BUG?
    test(os.path.abspath('./FIRST_DIR'), './SECOND_DIR')


if __name__ == ""__main__"":
    sys.exit(main())

```

Log output

```
Looking for models in : ./FIRST_DIR
No incumbent found...
Saving to: ./FIRST_DIR/model
mv ./FIRST_DIR ./SECOND_DIR
Looking for models in : ./SECOND_DIR
Loading incumbent: ./SECOND_DIR/model
Saving to: ./SECOND_DIR/model
Looking for models in : /home/rklopfer/REPORT/FIRST_DIR
No incumbent found...
Saving to: /home/rklopfer/REPORT/FIRST_DIR/model
mv /home/rklopfer/REPORT/FIRST_DIR ./SECOND_DIR
Looking for models in : ./SECOND_DIR
Traceback (most recent call last):
  File ""./bug_report.py"", line 57, in <module>
    sys.exit(main())
  File ""./bug_report.py"", line 53, in main
    test(os.path.abspath('./FIRST_DIR'), './SECOND_DIR')
  File ""./bug_report.py"", line 45, in test
    load_and_save(saver, session, second_dir)
  File ""./bug_report.py"", line 12, in load_and_save
    incumbent = tf.train.latest_checkpoint(model_dir)
  File ""/home/rklopfer/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1482, in latest_checkpoint
    if file_io.get_matching_files(v2_path) or file_io.get_matching_files(
  File ""/home/rklopfer/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 269, in get_matching_files
    compat.as_bytes(filename), status)]
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/home/rklopfer/.virtualenvs/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: /home/rklopfer/REPORT/FIRST_DIR


```
"
9144,regarding error message of tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform,"I have created a Python development environment support Python 2.7,

```
(py2.7) [abcd@cluster1830 ~]$ python --version
Python 2.7.9
```
Then I was trying to install Tensorflow following [this guide ](https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package)

> (py2.7) [abcd@cluster1830 ~]$ pip install --upgrade /data/pythonlibs/tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl
> tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.
> (py2.7) [abcd@cluster1830 ~]$ pip install /data/pythonlibs/tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl
> tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.
> (py2.7) [abcd@cluster1830 ~]$ pip2 install /data/pythonlibs/tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl
> tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.
> 

None of the above options works, what can be the reason underlying this failure?


"
9142,Make bounding box operators consistent,"Right now, the bounding box operators (tf.image.draw_bounding_boxes, tf.image.non_max_suppression and tf.image.sample_distorted_bounding_box) expect bounding boxes in the form of [ymin, xmin, ymax, xmax], with the origin (0,0) being the lower left corner of the image. But images themselves are tensors, and the pixel with index [0,0] in the tensor is in the top left, so bounding box coordinates are the opposite in the y direction to tensor indices.

Additionally, the operations tf.image.pad_to_bounding_box and tf.image.crop_to_bounding_box take coordinates in the form of [ymin, xmin, height, width], with the origin being the top-left corner, so the coordinates are inconsistent even within the image ops themselves (plus the parametrization of the bounding boxes is different, too).

And the tf.image.crop_and_resize op doesn't specify what origin it uses (though I think it's bottom left too)

I feel like this sort of inconsistency is unnecessarily confusing and a high risk for introducing errors.

It's especially bad since, if you supply bounding boxes the wrong way around to draw_bounding_boxes, it'll still draw them correctly (

All bounding box operators should use the same coordinate system and preferably the same parametrization, and preferably the coordinates should be consistent with image tensor indexing."
9141,Fused batch renormalization,"Recently introduced batch renormalization could be very useful, but without support for a fused batch norm, it has limited use (XLA JIT still has too many problems to be used instead of a fused version)"
9139,Incorrect results when graph is split across several GPUs.,"Background info:
- Custom code
- Tensorflow r1.0 installed from binaries on Windows
- CUDA 8.0, cuDNN 5.1.5
- 2 GPUs: GTX Titan X and Titan X Pascal

Problem:

I have a model that is small enough to be trained on a single GPU with 12GB memory. Training works fine and converges.

However, when I evaluate the model with a validation set that is too large to fit on one of my GPUs, TensorFlow seems to use both of my GPUs (one GTX Titan X and one Titan X Pascal). When this happens, **a large fraction of the results returned by TensorFlow are incorrect**. The returned values are not completely missing, i.e. not all zero or something like that, but so inaccurate that the validation performance is terrible. 

More specifically, my model consists of a shared initial stage, followed by a list of ~50 sub-networks that all receive input from the shared stage, but are otherwise independent. Data is split using `tf.dynamic_partition()`. From the results that I get, it appears that TensorFlow moves some of the 50 sub-networks to the second GPU if the memory on the first one isn't sufficient. The moved sub-models then return incorrect results (the others are unchanged).

If I instead force evaluation to be performed on the CPU, all results are as expected. All I need to do is add `with tf.device('/cpu:0')` to the very top of my script. The results also look good if I reduce the size of the validation set so that it fits onto one GPU.

I am sorry for not providing a working example. I will try to create one, but it might take a while since, by nature of the problem, it needs to be a fairly large/complex model.


"
9138,Issues found by PVS-Studio,"Hello,
Developers of PVS-Studio C/C++/C# static analyzer present their check report of the source code of 'TensorFlow' in the article, containing the review of the most suspicious code fragments they discovered.

You can read article at the official site:
https://www.viva64.com/en/b/0497/

I have provided links to GitHub for each code fragment to make viewing more comfortable. The article doesn't cover all the issues that were found by the analyzer, so perhaps it would be interesting for you to review them yourself. In case you have questions, feel free to ask them.

Best regards,
Sergey Vasiliev"
9137,"""undefined symbol"" when compiling the example Op","- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: 1.0.1
- *Bazel version (if compiling from source)*: NA
- *CUDA/cuDNN version*: NA
- *GPU Model and Memory*: NA
- *Exact command to reproduce*: 

### Describe the problem clearly
Trying to build and compile the example in ""adding a new op""
https://www.tensorflow.org/extend/adding_an_op
This was moved to
tensorflow/examples/adding_an_op
and was not updated in the tutorial page.
After compiling the zero_out_op_kernel_1.cc example, I'm trying to run the zero_out_1_test.py. Yet this returns the following error

  File ""zero_out_1_test.py"", line 25, in <module>
    import zero_out_op_1
  File ""/home/me/tf_compile/tensorflow/tensorflow/examples/adding_an_op/zero_out_op_1.py"", line 26, in <module>
    'zero_out_op_kernel_1.so'))
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: /home/me/tf_compile/tensorflow/tensorflow/examples/adding_an_op/zero_out_op_kernel_1.so: undefined symbol: _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev

Any ideas what could that symbol be?"
9136,Issues when using Queues + tf.train.Server,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: 1.0.0 CPU / 1.0.1 (CPU and GPU enabled) / 1.1.0rc1 (CPU)
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*: N/A
- *GPU Model and Memory*: N/A
- *Exact command to reproduce*: cf below.

This problem has been reproduced on both Linux and various Mac OS machines.

### Describe the problem clearly

We seem to experience issues when using both queues + `tf.train.Server`. When executed in a simple python 3.5.3 console, the following script hangs:

```
import tensorflow as tf
import time

cluster = tf.train.ClusterSpec({""cpu1"" : ['localhost:2222']})
server = tf.train.Server(cluster, job_name=""cpu1"", task_index=0)

with tf.Graph().as_default() as graph:
    # Queue
    input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))

    # Useless variable
    variable = tf.Variable(1., dtype=tf.float32, trainable=False, name=""variable"")

    # Session and queue runners
    session = tf.Session(target=server.target)
    session.run(tf.global_variables_initializer())
    tf.train.start_queue_runners(session)

print(session.run(variable))  # this works
print(session.run(tf.assign(variable, 2)))  # this also works, but only if called directly

# any pause between creating and running the session breaks it
time.sleep(1)

print(session.run(variable))  # retrieving a variable still works, but...
print(session.run(tf.assign(variable, 3)))  # ... assigning a variable will make the program hang.
```

It outputs:

```
1
2
2
```

and then hangs forever. The problem vanishes when either commenting the `input_queue=...` line, or when writing `session = tf.Session()` instead of passing the `server.target`.

The problems seems to happen not only with variable assignments, but also saving the model using `tf.train.Saver().save(session, 'my_model')` for instance (and possibly other operations). Note that reading a variable works fine.

In the example script, the `time.sleep`command simulates a pause between creating the session and running it to set a variable. The same effect is achieved, for example, when splitting session creation and running code across two Jupyter notebook cells. When executing the whole code in one cell, it works fine.


### Source Code / Logs
The source code to reproduce the problem is displayed above. I have attached a traceback using gdb, which shows that the program is hanging while trying to acquire a lock.

[tf-issue-gdb-bt.txt](https://github.com/tensorflow/tensorflow/files/913097/tf-issue-gdb-bt.txt)
[tf-issue-gdb-stack-threads.txt](https://github.com/tensorflow/tensorflow/files/913102/tf-issue-gdb-stack-threads.txt)

"
9135,YoloDetector example needs java_test() rule,"Hi:
   when I use android studio to compile TensorflowYoloDetector, the following error occurs:

E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate()

 (tried Java_org_tensorflow_contrib_android_RunStats_allocate and  Java_org_tensorflow_contrib_android_RunStats_allocate__)

TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference
TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)

TensorFlowInferenceInterface: Failed to load model from 'file:///android_asset/graph-tiny-yolo-voc.pb': java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef

tensorflow: TensorFlowYoloDetector: TF init status: 1.

　　 Look forward to your reply. 

"
9134,Broken link in Python API documentation on RNN and Cells (contrib),"
There's a broken link in the Python API documentation on RNN and Cells (contrib).

The link appears at the very bottom of this page: www.tensorflow.org/api_guides/python/contrib.rnn
Title of link: tf.contrib.rnn.stack_bidirectional_dynamic_rnn
URL of link: https://www.tensorflow.org/api_guides/python/BROKEN_LINK
"
9132,Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) only in the test mode,"When I fine tuned the resnet50 with keras 2.0.3 and tensorflow 1.1.0. 
CUDNN: 5.1
CUDA: 8.0
Every time when I directly try to test it, I just got the error:
017-04-11 17:35:03.446611: E tensorflow/stream_executor/cuda/cuda_dnn.cc:359] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2017-04-11 17:35:03.446639: E tensorflow/stream_executor/cuda/cuda_dnn.cc:326] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2017-04-11 17:35:03.446647: F tensorflow/core/kernels/conv_ops.cc:665] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) 
Aborted (core dumped)
But, if I test it after the training, there is no problem. "
9131,NotFoundError while restoring inception_v3 model,"Hi,

I am trying to make use of `inception_v3` model from `https://github.com/tensorflow/models/tree/master/slim`

After downloading the model as described in the webpage, I wanted to restore the model using 

    saver = tf.train.Saver()
    saver.restore(sess, 'model/inception_v3.ckpt')

And I get this error: 

    NotFoundError (see above for traceback): Tensor name ""InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/biases"" not found in checkpoint files model/inception_v3.ckpt

Upon inspection of `tf.trainable_variables()`, i find the variable with name -    

    ""InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/biases:0""

Is the suffix `:0` causing this error ? If not how can i load this model ? 

I raised this issue @tensorflow/models, but unfortunately, I did not get any response. 
Thanks in advance!"
9130,r.0.11 avro missing files ,"Hi

I am trying to install tf r0.11 in a Centos 7 without GPU support from sources. I have a similar problem like the https://github.com/tensorflow/tensorflow/issues/4312. I followed the recommended actions, yet I get the same error. BESIDES, I get the following (not described in the issue 4312) error:

`Error downloading from http://www-us.apache.org/dist/avro/avro-1.8.0/cpp/avro-cpp-1.8.0.tar.gz` 

I tryed to find this file using the web browser and I coudn't find it. The online repository doesn't have it anymore. Just the avro-1.8.1 and avro-1.7.7 are available.

Thanks
Regards
A

"
9129,tensorflow1.1 rnn lstm:ValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights....,"Environment info

Operating System: Ubuntu 14.04.5 LTS

Installed version of CUDA and cuDNN:
No CUDA, I use CPU-only.

Pip version: pip 1.5.4
Python version: 2.7.6
Operating System: Ubuntu 14.04.5 LTS
Tensorflow version: tensorflow-1.1.0rc0-cp27-none-linux_x86_64 , CPU-only
Description:

I was testing the tutorial example of LSTM .
my main function  train_rnn_classify.py:
```
import tensorflow as tf
import numpy as np
import os
import time
import datetime
from rnn_model import RNN_Model
import data_helper


flags =tf.app.flags
FLAGS = flags.FLAGS


flags.DEFINE_integer('batch_size',64,'the batch_size of the training procedure')
flags.DEFINE_float('lr',0.1,'the learning rate')
flags.DEFINE_float('lr_decay',0.6,'the learning rate decay')
flags.DEFINE_integer('vocabulary_size',20000,'vocabulary_size')
flags.DEFINE_integer('emdedding_dim',128,'embedding dim')
flags.DEFINE_integer('hidden_neural_size',128,'LSTM hidden neural size')
flags.DEFINE_integer('hidden_layer_num',1,'LSTM hidden layer num')
flags.DEFINE_string('dataset_path','/home/hadoop/lstm/subj0.pkl','dataset path')
flags.DEFINE_integer('max_len',40,'max_len of training sentence')
flags.DEFINE_integer('valid_num',100,'epoch num of validation')
flags.DEFINE_integer('checkpoint_num',1000,'epoch num of checkpoint')
flags.DEFINE_float('init_scale',0.1,'init scale')
flags.DEFINE_integer('class_num',2,'class num')
flags.DEFINE_float('keep_prob',0.5,'dropout rate')
flags.DEFINE_integer('num_epoch',60,'num epoch')
flags.DEFINE_integer('max_decay_epoch',30,'num epoch')
flags.DEFINE_integer('max_grad_norm',5,'max_grad_norm')
flags.DEFINE_string('out_dir',os.path.abspath(os.path.join(os.path.curdir,""runs"")),'output directory')
flags.DEFINE_integer('check_point_every',10,'checkpoint every num epoch ')

class Config(object):

    hidden_neural_size=FLAGS.hidden_neural_size
    vocabulary_size=FLAGS.vocabulary_size
    embed_dim=FLAGS.emdedding_dim
    hidden_layer_num=FLAGS.hidden_layer_num
    class_num=FLAGS.class_num
    keep_prob=FLAGS.keep_prob
    lr = FLAGS.lr
    lr_decay = FLAGS.lr_decay
    batch_size=FLAGS.batch_size
    num_step = FLAGS.max_len
    max_grad_norm=FLAGS.max_grad_norm
    num_epoch = FLAGS.num_epoch
    max_decay_epoch = FLAGS.max_decay_epoch
    valid_num=FLAGS.valid_num
    out_dir=FLAGS.out_dir
    checkpoint_every = FLAGS.check_point_every


def evaluate(model,session,data,global_steps=None,summary_writer=None):


    correct_num=0
    total_num=len(data[0])
    for step, (x,y,mask_x) in enumerate(data_helper.batch_iter(data,batch_size=FLAGS.batch_size)):

         fetches = model.correct_num
         feed_dict={}
         feed_dict[model.input_data]=x
         feed_dict[model.target]=y
         feed_dict[model.mask_x]=mask_x
         model.assign_new_batch_size(session,len(x))
         state = session.run(model._initial_state)
         for i , (c,h) in enumerate(model._initial_state):
            feed_dict[c]=state[i].c
            feed_dict[h]=state[i].h
         count=session.run(fetches,feed_dict)
         correct_num+=count

    accuracy=float(correct_num)/total_num
    dev_summary = tf.scalar_summary('dev_accuracy',accuracy)
    dev_summary = session.run(dev_summary)
    if summary_writer:
        summary_writer.add_summary(dev_summary,global_steps)
        summary_writer.flush()
    return accuracy

def run_epoch(model,session,data,global_steps,valid_model,valid_data,train_summary_writer,valid_summary_writer=None):
    for step, (x,y,mask_x) in enumerate(data_helper.batch_iter(data,batch_size=FLAGS.batch_size)):

        feed_dict={}
        feed_dict[model.input_data]=x
        feed_dict[model.target]=y
        feed_dict[model.mask_x]=mask_x
        model.assign_new_batch_size(session,len(x))
        fetches = [model.cost,model.accuracy,model.train_op,model.summary]
        state = session.run(model._initial_state)
        for i , (c,h) in enumerate(model._initial_state):
            feed_dict[c]=state[i].c
            feed_dict[h]=state[i].h
        cost,accuracy,_,summary = session.run(fetches,feed_dict)
        train_summary_writer.add_summary(summary,global_steps)
        train_summary_writer.flush()
        valid_accuracy=evaluate(valid_model,session,valid_data,global_steps,valid_summary_writer)
        if(global_steps%100==0):
            print(""the %i step, train cost is: %f and the train accuracy is %f and the valid accuracy is %f""%(global_steps,cost,accuracy,valid_accuracy))
        global_steps+=1

    return global_steps





def train_step():

    print(""loading the dataset..."")
    config = Config()
    eval_config=Config()
    eval_config.keep_prob=1.0

    train_data,valid_data,test_data=data_helper.load_data(FLAGS.max_len,batch_size=config.batch_size)

    print(""begin training"")

    # gpu_config=tf.ConfigProto()
    # gpu_config.gpu_options.allow_growth=True
    with tf.Graph().as_default(), tf.Session() as session:
        initializer = tf.random_uniform_initializer(-1*FLAGS.init_scale,1*FLAGS.init_scale)
        with tf.variable_scope(""model"",reuse=None,initializer=initializer):
            model = RNN_Model(config=config,is_training=True)

        with tf.variable_scope(""model"",reuse=True,initializer=initializer):
            valid_model = RNN_Model(config=eval_config,is_training=False)
            test_model = RNN_Model(config=eval_config,is_training=False)

        #add summary
        # train_summary_op = tf.merge_summary([model.loss_summary,model.accuracy])
        train_summary_dir = os.path.join(config.out_dir,""summaries"",""train"")
        train_summary_writer =  tf.train.SummaryWriter(train_summary_dir,session.graph)

        # dev_summary_op = tf.merge_summary([valid_model.loss_summary,valid_model.accuracy])
        dev_summary_dir = os.path.join(eval_config.out_dir,""summaries"",""dev"")
        dev_summary_writer =  tf.train.SummaryWriter(dev_summary_dir,session.graph)

        #add checkpoint
        checkpoint_dir = os.path.abspath(os.path.join(config.out_dir, ""checkpoints""))
        checkpoint_prefix = os.path.join(checkpoint_dir, ""model"")
        if not os.path.exists(checkpoint_dir):
            os.makedirs(checkpoint_dir)
        saver = tf.train.Saver(tf.all_variables())


        tf.initialize_all_variables().run()
        global_steps=1
        begin_time=int(time.time())

        for i in range(config.num_epoch):
            print(""the %d epoch training...""%(i+1))
            lr_decay = config.lr_decay ** max(i-config.max_decay_epoch,0.0)
            model.assign_new_lr(session,config.lr*lr_decay)
            global_steps=run_epoch(model,session,train_data,global_steps,valid_model,valid_data,train_summary_writer,dev_summary_writer)

            if i% config.checkpoint_every==0:
                path = saver.save(session,checkpoint_prefix,global_steps)
                print(""Saved model chechpoint to{}\n"".format(path))

        print(""the train is finished"")
        end_time=int(time.time())
        print(""training takes %d seconds already\n""%(end_time-begin_time))
        test_accuracy=evaluate(test_model,session,test_data)
        print(""the test data accuracy is %f""%test_accuracy)
        print(""program end!"")



def main(_):
    train_step()


if __name__ == ""__main__"":
    tf.app.run()
```
model code rnn_model.py   :
```
`
import tensorflow as tf

import numpy as np



class RNN_Model(object):







    def __init__(self,config,is_training=True):



        self.keep_prob=config.keep_prob

        self.batch_size=tf.Variable(0,dtype=tf.int32,trainable=False)



        num_step=config.num_step

        self.input_data=tf.placeholder(tf.int32,[None,num_step])

        self.target = tf.placeholder(tf.int64,[None])

        self.mask_x = tf.placeholder(tf.float32,[num_step,None])



        class_num=config.class_num

        hidden_neural_size=config.hidden_neural_size

        vocabulary_size=config.vocabulary_size

        embed_dim=config.embed_dim

        hidden_layer_num=config.hidden_layer_num

        self.new_batch_size = tf.placeholder(tf.int32,shape=[],name=""new_batch_size"")

        self._batch_size_update = tf.assign(self.batch_size,self.new_batch_size)



        #build LSTM network



        lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_neural_size,forget_bias=0.0,state_is_tuple=True)

        if self.keep_prob<1:

            lstm_cell =  tf.contrib.rnn.DropoutWrapper(

                lstm_cell,output_keep_prob=self.keep_prob

            )



        cell = tf.contrib.rnn.MultiRNNCell([lstm_cell]*hidden_layer_num,state_is_tuple=True)



        self._initial_state = cell.zero_state(self.batch_size,dtype=tf.float32)



        #embedding layer

        with tf.device(""/cpu:0""),tf.name_scope(""embedding_layer""):

            embedding = tf.get_variable(""embedding"",[vocabulary_size,embed_dim],dtype=tf.float32)

            inputs=tf.nn.embedding_lookup(embedding,self.input_data)



        if self.keep_prob<1:

            inputs = tf.nn.dropout(inputs,self.keep_prob)



        out_put=[]

        state=self._initial_state

        with tf.variable_scope(""LSTM_layer""):

            for time_step in range(num_step):

                if time_step>0: tf.get_variable_scope().reuse_variables()

                (cell_output,state)=cell(inputs[:,time_step,:],state)

                out_put.append(cell_output)



        out_put=out_put*self.mask_x[:,:,None]



        with tf.name_scope(""mean_pooling_layer""):



            out_put=tf.reduce_sum(out_put,0)/(tf.reduce_sum(self.mask_x,0)[:,None])



        with tf.name_scope(""Softmax_layer_and_output""):

            softmax_w = tf.get_variable(""softmax_w"",[hidden_neural_size,class_num],dtype=tf.float32)

            softmax_b = tf.get_variable(""softmax_b"",[class_num],dtype=tf.float32)

            self.logits = tf.matmul(out_put,softmax_w)+softmax_b



        with tf.name_scope(""loss""):

            self.loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.target,logits=self.logits+1e-10,)

            self.cost = tf.reduce_mean(self.loss)



        with tf.name_scope(""accuracy""):

            self.prediction = tf.argmax(self.logits,1)

            correct_prediction = tf.equal(self.prediction,self.target)

            self.correct_num=tf.reduce_sum(tf.cast(correct_prediction,tf.float32))

            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name=""accuracy"")



        #add summary

        loss_summary = tf.contrib.deprecated.scalar_summary(""loss"",self.cost)

        #add summary

        accuracy_summary=tf.contrib.deprecated.scalar_summary(""accuracy_summary"",self.accuracy)



        if not is_training:

            return



        self.globle_step = tf.Variable(0,name=""globle_step"",trainable=False)

        self.lr = tf.Variable(0.0,trainable=False)



        tvars = tf.trainable_variables()

        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),

                                      config.max_grad_norm)





        # Keep track of gradient values and sparsity (optional)

        grad_summaries = []

        for g, v in zip(grads, tvars):

            if g is not None:

                grad_hist_summary = tf.summary.histogram(""{}/grad/hist"".format(v.name), g)

                sparsity_summary = tf.contrib.deprecated.scalar_summary(""{}/grad/sparsity"".format(v.name), tf.nn.zero_fraction(g))

                grad_summaries.append(grad_hist_summary)

                grad_summaries.append(sparsity_summary)

        self.grad_summaries_merged = tf.summary.merge(grad_summaries)



        self.summary =tf.summary.merge([loss_summary,accuracy_summary,self.grad_summaries_merged])







        optimizer = tf.train.GradientDescentOptimizer(self.lr)

        optimizer.apply_gradients(zip(grads, tvars))

        self.train_op=optimizer.apply_gradients(zip(grads, tvars))



        self.new_lr = tf.placeholder(tf.float32,shape=[],name=""new_learning_rate"")

        self._lr_update = tf.assign(self.lr,self.new_lr)



    def assign_new_lr(self,session,lr_value):

        session.run(self._lr_update,feed_dict={self.new_lr:lr_value})

    def assign_new_batch_size(self,session,batch_size_value):

        session.run(self._batch_size_update,feed_dict={self.new_batch_size:batch_size_value})`
```
  data handle code  data_helper.py:

```

import numpy as np

import cPickle as pkl



#file path

dataset_path='/home/hadoop/lstm/subj0.pkl'



def set_dataset_path(path):

    dataset_path=path









def load_data(max_len,batch_size,n_words=20000,valid_portion=0.1,sort_by_len=True):

    f=open(dataset_path,'rb')

    print ('load data from %s',dataset_path)

    train_set = np.array(pkl.load(f))

    test_set = np.array(pkl.load(f))

    f.close()



    train_set_x,train_set_y = train_set









    #train_set length

    n_samples= len(train_set_x)

    #shuffle and generate train and valid dataset

    sidx = np.random.permutation(n_samples)

    n_train = int(np.round(n_samples * (1. - valid_portion)))

    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]

    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]

    train_set_x = [train_set_x[s] for s in sidx[:n_train]]

    train_set_y = [train_set_y[s] for s in sidx[:n_train]]





    train_set = (train_set_x, train_set_y)

    valid_set = (valid_set_x, valid_set_y)





    #remove unknow words

    def remove_unk(x):

        return [[1 if w >= n_words else w for w in sen] for sen in x]



    test_set_x, test_set_y = test_set

    valid_set_x, valid_set_y = valid_set

    train_set_x, train_set_y = train_set



    train_set_x = remove_unk(train_set_x)

    valid_set_x = remove_unk(valid_set_x)

    test_set_x = remove_unk(test_set_x)







    def len_argsort(seq):

        return sorted(range(len(seq)), key=lambda x: len(seq[x]))



    if sort_by_len:

        sorted_index = len_argsort(test_set_x)

        test_set_x = [test_set_x[i] for i in sorted_index]

        test_set_y = [test_set_y[i] for i in sorted_index]



        sorted_index = len_argsort(valid_set_x)

        valid_set_x = [valid_set_x[i] for i in sorted_index]

        valid_set_y = [valid_set_y[i] for i in sorted_index]





        sorted_index = len_argsort(train_set_x)

        train_set_x = [train_set_x[i] for i in sorted_index]

        train_set_y = [train_set_y[i] for i in sorted_index]



    train_set=(train_set_x,train_set_y)

    valid_set=(valid_set_x,valid_set_y)

    test_set=(test_set_x,test_set_y)









    new_train_set_x=np.zeros([len(train_set[0]),max_len])

    new_train_set_y=np.zeros(len(train_set[0]))



    new_valid_set_x=np.zeros([len(valid_set[0]),max_len])

    new_valid_set_y=np.zeros(len(valid_set[0]))



    new_test_set_x=np.zeros([len(test_set[0]),max_len])

    new_test_set_y=np.zeros(len(test_set[0]))



    mask_train_x=np.zeros([max_len,len(train_set[0])])

    mask_test_x=np.zeros([max_len,len(test_set[0])])

    mask_valid_x=np.zeros([max_len,len(valid_set[0])])







    def padding_and_generate_mask(x,y,new_x,new_y,new_mask_x):



        for i,(x,y) in enumerate(zip(x,y)):

            #whether to remove sentences with length larger than maxlen

            if len(x)<=max_len:

                new_x[i,0:len(x)]=x

                new_mask_x[0:len(x),i]=1

                new_y[i]=y

            else:

                new_x[i]=(x[0:max_len])

                new_mask_x[:,i]=1

                new_y[i]=y

        new_set =(new_x,new_y,new_mask_x)

        del new_x,new_y

        return new_set



    train_set=padding_and_generate_mask(train_set[0],train_set[1],new_train_set_x,new_train_set_y,mask_train_x)

    test_set=padding_and_generate_mask(test_set[0],test_set[1],new_test_set_x,new_test_set_y,mask_test_x)

    valid_set=padding_and_generate_mask(valid_set[0],valid_set[1],new_valid_set_x,new_valid_set_y,mask_valid_x)



    return train_set,valid_set,test_set





#return batch dataset

def batch_iter(data,batch_size):



    #get dataset and label

    x,y,mask_x=data

    x=np.array(x)

    y=np.array(y)

    data_size=len(x)

    num_batches_per_epoch=int((data_size-1)/batch_size)

    for batch_index in range(num_batches_per_epoch):

        start_index=batch_index*batch_size

        end_index=min((batch_index+1)*batch_size,data_size)

        return_x = x[start_index:end_index]

        return_y = y[start_index:end_index]

        return_mask_x = mask_x[:,start_index:end_index]

        # if(len(return_x)<batch_size):

        #     print(len(return_x))

        #     print return_x

        #     print return_y

        #     print return_mask_x

        #     import sys

        #     sys.exit(0)

        yield (return_x,return_y,return_mask_x)
```


When I open a terminal and run
`  python train_rnn_classify.py`
then  has error:
```
Traceback (most recent call last):
  File ""train_rnn_classify.py"", line 176, in <module>
    tf.app.run()
  File ""/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train_rnn_classify.py"", line 172, in main
    train_step()
  File ""train_rnn_classify.py"", line 128, in train_step
    valid_model = RNN_Model(config=eval_config,is_training=False)
  File ""/home/hadoop/lstm/rnn_model.py"", line 51, in __init__
    (cell_output,state)=cell(inputs[:,time_step,:],state)
  File ""/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 953, in __call__
    cur_inp, new_state = cell(cur_inp, cur_state)
  File ""/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 235, in __call__
    with _checked_scope(self, scope or ""basic_lstm_cell"", reuse=self._reuse):
  File ""/home/hadoop/anaconda2/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 93, in _checked_scope
    ""the argument reuse=True."" % (scope_name, type(cell).__name__))
ValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'model/LSTM_layer/multi_rnn_cell/cell_0/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.
```

Why can't I run this example?How to solve this  problem?
Thank you all for your kind help!!!"
9128,Problem with label_image.py ,"
I used docker toolbox on windows 10 64-bit and used this command 
docker run -it gcr.io/tensorflow/tensorflow:latest-devel  
to install tensorflow image. 
After retraining of model is successfully done and when I run label_image.py it gives following message
![capture](https://cloud.githubusercontent.com/assets/20141573/24899312/27d5b654-1ea0-11e7-8df6-517c4df18bfb.PNG)

I used this line 
curl -L https://goo.gl/tx3dqg > $HOME/tf_files/label_image.py
and then
docker run -it -v $HOME/tf_files:/tf_files  gcr.io/tensorflow/tensorflow:latest-devel 






NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9127,How to reinitialize state prior to inference with RNN,"I have an RNN graph which has been trained in TF with good accuracy, but when it runs in Android (using libtensorflow_inference.so) it runs poorly.  I have a hypothesis that the problem is due to the statefulness of the RNN.  It is my understanding that during training the RNN state is reinitialized to a fresh state with each minibatch.  However, when running in reallife, it is running continuously without the state being refreshed.  Thus causing anomalous results.
Is there a way to force the state to be refreshed when running in an Android environment?  I note that the java interface (tensorflowinferenceinterface.java) has no such method.
I have also documented this inquiry in SO nine days ago, but had no response: [link](http://stackoverflow.com/questions/43159921/tensorflow-initializing-state-for-rnn-between-inferences-in-android)."
9126,How to run TF learn (skflow) Kmeans clustering in multi-machine multi-gpu environment?,"Is there any example / guide which shows how to implement skflow(tf.contrib.learn) in distributed GPUs? For example :- I want to implement KMeansClustring using skflow(tf.contrib.learn) in a distributed GPU environment. How should I proceed?

Stackoverflow questions :- [here](http://stackoverflow.com/questions/43339285/how-to-run-tf-learn-skflow-kmeans-clustering-in-multi-machine-multi-gpu-enviro)  and [here](http://stackoverflow.com/questions/42516334/implement-skflowtf-contrib-learn-in-a-distributed-gpu-environment)


"
9125,KeyError in tf.contrib.graph_editor.graph_replace,"When applying `graph_replace` to graphs containing ops with the `_original_op` attribute, it can fail with a `KeyError`. The error occurs in `Transformer._copy_ops` when trying to copy an op whose `_original_op` has not yet been copied. The ordering of ops that are copied is not deterministic so this error pops up somewhat randomly.

The `_original_op` attributes appear to be created by `tf.gradients` to point back to the op from the forward pass.

Example code snippet (note: you may need to run this multiple times to get a failure):
```python
import tensorflow as tf
graph_replace = tf.contrib.graph_editor.graph_replace
w = tf.Variable(0.0, name=""w"")
y = tf.multiply(tf.multiply(w, w, name=""mul1""), w, name=""mul2"")
g = tf.gradients(y, w)[0]
g_new = graph_replace(g, {w.value(): g})
```

Error:
```
/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/graph_editor/transform.py in transform_op_if_inside_handler(info, op, keep_if_possible)
    122   """"""
    123   if op in info.sgv.ops:
--> 124     return info.transformed_ops[op]
    125   else:
    126     if keep_if_possible and info.graph is info.graph_:

KeyError: <tf.Operation 'mul1' type=Mul>
```

I see three possible fixes:
1. Remove `_original_op` attributes in the copied graph (I don't see anywhere in the TF codebase where it is used)
2. Move the creation of the `_original_op` attribute from the `copy_op_handler` function to the end of `Transformer._copy_ops` after all ops have been copied.
3. Topologically sort the ops being copied so that ops that are `_original_op` attributes are created before their children.

My [implementation](https://github.com/poolio/tensorflow/pull/1/files) of option 2 seems to fix this problem, but I might be missing something about the usage of `_original_op`."
9123,no such package '@gmock_archive//': Error downloading in Tensorflow (on ubuntu_X86 14.04) ,"I'm getting the following error when trying to run the configure command (on ubuntu_X86:14.04):

ERROR: /root/tf/tensorflow/tensorflow/workspace.bzl:221:3: no such package '@gmock_archive//': Error downloading

Please find the attached log for more details.
[logfile.txt](https://github.com/tensorflow/tensorflow/files/912026/logfile.txt)


Note- On ubuntu-ppc64le vm , configure command ran successfully.

Any suggestion/solution ?"
9116,Problem with label_image.py,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.
![capture](https://cloud.githubusercontent.com/assets/20141573/24884907/07d2d32c-1e4c-11e7-9568-fbaae2459860.PNG)


### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9115,Documentation link issue,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.
under this link 
https://www.tensorflow.org/api_docs/python/tf/contrib/deprecated/scalar_summary

the webpage is not found 

https://www.tensorflow.org/code/tensorflow/contrib/deprecated/__init__.py


### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9114,Help,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9113,Asynchronous Training Issue for Distributed Tensorflow,"I guess this issue may not be supposed to show up here, and I apologize for opening the ticket here, but really want to be clear about asynchronous training with Distributed Tensorflow. I posted my question on StackOverflow: http://stackoverflow.com/questions/43147435/how-does-asynchronous-training-work-in-distributed-tensorflow, but I got two opposite answers and didn't know which one is the correct. I read the TF docs and example code multiple times, but they're still confused me. So I really appreciate if I could get some official interpretations on asynchronous training."
9111,tensorflow installation issue,"I have been following the [Tensorflow installation guide](https://www.tensorflow.org/install/install_linux#InstallingVirtualenv) to install tensorflow r.1.0. Since out network system does not have direct internet access to outside, so I installed it as following in the active virtualenv environment

```
(virtualenv-test) bash-4.1$ pip3 install -t --upgrade /data/pythonlibs/tensorflow-1.0.1-cp34-cp34m-linux_x86_64.whl
Processing /data/dsp_emerging/ugwz/pythonlibs/tensorflow-1.0.1-cp34-cp34m-linux_x86_64.whl
```
However, I got the following error message, what does it mean?

> Collecting six>=1.10.0 (from tensorflow==1.0.1)
>   Retrying (Retry(total=4, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e22bcc0>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/
>   Retrying (Retry(total=3, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e22bd68>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/
>   Retrying (Retry(total=2, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e113fd0>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/
>   Retrying (Retry(total=1, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e115358>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/
>   Retrying (Retry(total=0, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e115438>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/
>   Could not find a version that satisfies the requirement six>=1.10.0 (from tensorflow==1.0.1) (from versions: )
> No matching distribution found for six>=1.10.0 (from tensorflow==1.0.1)
> "
9110,RNN Tutorial references defunct library,"[In the RNN tutorial](https://www.tensorflow.org/tutorials/recurrent), the sample code has line:

`lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)`

According to issue #6432, this should be replaced by:

`lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)`"
9108,tf.while_loop giving unexpected result when used with tf.assign() during run time,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: 1.0.0
- *Bazel version (if compiling from source)*: NA
- *CUDA/cuDNN version*:  NA
- *GPU Model and Memory*: NA
- *Exact command to reproduce*:


### Describe the problem clearly
tf.while_loop with is not working as expected when used with tf.assign()

In the below example code, the reset_x operation seems to be preventing the variable 'x' from updating as per per logic in loop1. if I print the output after loop1 has been run, I can see that x is still zero. However I I confirmed that the loop is working by printing output of loop1. It seems resent_x op is being used inside the tf.while_loop() during run time instead of only resetting x back to 0 after loop has finished. If I were to remove reset_x then the variable x is getting updated by the loop.

body = lamda x: tf.assign_add(x,1)
loop1 = tf.while_loop(cond,body, [x])
x_op = tf.reduce_sum(tf.abs(x))
reset_x = tf.assign(x,[0])
with tf.Session() as sess:
......
......
       for in range (100):
              sess.run(loop1)
              print(sess.run(x))
              sess.run(x_op) 
              sess.run(reset_x)

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9107,Tensorflow tests failing on s390x (Farmhash related),"Below tests are failing on big endian s390x platform.
The tests are failing due to farmhash doesn't support s390x platform.
We have already raised an [issue ](https://github.com/google/farmhash/issues/10) with farmhash. Test are passing after applying [patch](https://github.com/google/farmhash/issues/10#issuecomment-272068176) provided there. 

However, we would like to know if the testcases are used  for some complex functionality of TensorFlow?

Tests:
```
 //tensorflow/contrib/layers:sparse_feature_cross_op_test 
 //tensorflow/contrib/learn:tensorflow_dataframe_test 
 //tensorflow/contrib/linear_optimizer:sdca_ops_test 
 //tensorflow/core:platform_fingerprint_test

```


Tensorflow version: v0.10.0"
9105,Blas SGEMM launch failed,"I just installed  TensorFlow-GPU 1.0.1 on Win10 GTX GEFORCE 850M with CUDA 8.0 and Cudnn v5.1, Anaconda3 4.2.0 64bit
when I try to figure out if the installation was successful, I run the 

> mnist_with_summaries.py
in 
[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py](url)

When I run the code in Jupyter Notebook, it prints 

> Accuracy at step 0: 0.068
Accuracy at step 10: 0.6795
Accuracy at step 20: 0.8062
Accuracy at step 30: 0.8455
Accuracy at step 40: 0.8737
Accuracy at step 50: 0.8735
Accuracy at step 60: 0.8851
Accuracy at step 70: 0.8815
Accuracy at step 80: 0.8863
Accuracy at step 90: 0.8918

And the kernel just died.

When I try to run the code in command prompt, I get following error:

> >I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally
> Extracting /tmp/tensorflow/mnist/input_data\train-images-idx3-ubyte.gz
> Extracting /tmp/tensorflow/mnist/input_data\train-labels-idx1-ubyte.gz
> Extracting /tmp/tensorflow/mnist/input_data\t10k-images-idx3-ubyte.gz
> Extracting /tmp/tensorflow/mnist/input_data\t10k-labels-idx1-ubyte.gz
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
> name: GeForce GTX 850M
> major: 5 minor: 0 memoryClockRate (GHz) 0.9015
> pciBusID 0000:0a:00.0
> Total memory: 4.00GiB
> Free memory: 3.35GiB
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 850M, pci bus id: 0000:0a:00.0)
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""BestSplits"" device_type: ""CPU""') for unknown op: BestSplits
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""CountExtremelyRandomStats"" device_type: ""CPU""') for unknown op: CountExtremelyRandomStats
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""FinishedNodes"" device_type: ""CPU""') for unknown op: FinishedNodes
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""GrowTree"" device_type: ""CPU""') for unknown op: GrowTree
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ReinterpretStringToFloat"" device_type: ""CPU""') for unknown op: ReinterpretStringToFloat
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""SampleInputs"" device_type: ""CPU""') for unknown op: SampleInputs
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ScatterAddNdim"" device_type: ""CPU""') for unknown op: ScatterAddNdim
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNInsert"" device_type: ""CPU""') for unknown op: TopNInsert
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNRemove"" device_type: ""CPU""') for unknown op: TopNRemove
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TreePredictions"" device_type: ""CPU""') for unknown op: TreePredictions
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""UpdateFertileSlots"" device_type: ""CPU""') for unknown op: UpdateFertileSlots
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
> W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support
> Traceback (most recent call last):
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1022, in _do_call
>     return fn(*args)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1004, in _run_fn
>     status, run_metadata)
>   File ""C:\Users\airfo\Anaconda3\lib\contextlib.py"", line 66, in __exit__
>     next(self.gen)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
>     pywrap_tensorflow.TF_GetCode(status))
> tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(10000, 784), b.shape=(784, 500), m=10000, n=500, k=784
>          [[Node: layer1/Wx_plus_b/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_input/x-input_0/_45, layer1/weights/Variable/read)]]
>          [[Node: accuracy/accuracy/Mean/_49 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_69_accuracy/accuracy/Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""mnist_with_summaries.py"", line 209, in <module>
>     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 44, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""mnist_with_summaries.py"", line 185, in main
>     train()
>   File ""mnist_with_summaries.py"", line 160, in train
>     summary, acc = sess.run([merged, accuracy], feed_dict=feed_dict(False))
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 767, in run
>     run_metadata_ptr)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 965, in _run
>     feed_dict_string, options, run_metadata)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1015, in _do_run
>     target_list, options, run_metadata)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1035, in _do_call
>     raise type(e)(node_def, op, message)
> tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(10000, 784), b.shape=(784, 500), m=10000, n=500, k=784
>          [[Node: layer1/Wx_plus_b/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_input/x-input_0/_45, layer1/weights/Variable/read)]]
>          [[Node: accuracy/accuracy/Mean/_49 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_69_accuracy/accuracy/Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
> 

> Caused by op 'layer1/Wx_plus_b/MatMul', defined at:
>   File ""mnist_with_summaries.py"", line 209, in <module>
>     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py"", line 44, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""mnist_with_summaries.py"", line 185, in main
>     train()
>   File ""mnist_with_summaries.py"", line 101, in train
>     hidden1 = nn_layer(x, 784, 500, 'layer1')
>   File ""mnist_with_summaries.py"", line 95, in nn_layer
>     preactivate = tf.matmul(input_tensor, weights) + biases
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1765, in matmul
>     a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 1454, in _mat_mul
>     transpose_b=transpose_b, name=name)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
>     op_def=op_def)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2327, in create_op
>     original_op=self._default_original_op, op_def=op_def)
>   File ""C:\Users\airfo\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1226, in __init__
>     self._traceback = _extract_stack()
> 
> InternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(10000, 784), b.shape=(784, 500), m=10000, n=500, k=784
>          [[Node: layer1/Wx_plus_b/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/gpu:0""](_recv_input/x-input_0/_45, layer1/weights/Variable/read)]]
>          [[Node: accuracy/accuracy/Mean/_49 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_69_accuracy/accuracy/Mean"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
> And this Internal error message appears three times.It shows that all dll files were successfully opened. ( too many error message, I just write down something I think useful. If anyone need more information, tell me).
> 

I found an answer on stackoverflow [http://stackoverflow.com/questions/41117740/tensorflow-crashes-with-cublas-status-alloc-failed](url), and I add :
```
`config = tf.ConfigProto()
config.gpu_options.allow_growth = True
session = tf.Session(config=config, ...)`
```
just after:
`if __name__ == '__main__':`
this time the error is:

> > I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library cublas64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library cudnn64_5.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library cufft64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library nvcuda.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:135] successfully opened CUDA library curand64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
> name: GeForce GTX 850M
> major: 5 minor: 0 memoryClockRate (GHz) 0.9015
> pciBusID 0000:0a:00.0
> Total memory: 4.00GiB
> Free memory: 3.35GiB
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 850M, pci bus id: 0000:0a:00.0)
> Extracting /tmp/tensorflow/mnist/input_data\train-images-idx3-ubyte.gz
> Extracting /tmp/tensorflow/mnist/input_data\train-labels-idx1-ubyte.gz
> Extracting /tmp/tensorflow/mnist/input_data\t10k-images-idx3-ubyte.gz
> Extracting /tmp/tensorflow/mnist/input_data\t10k-labels-idx1-ubyte.gz
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 850M, pci bus id: 0000:0a:00.0)
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""BestSplits"" device_type: ""CPU""') for unknown op: BestSplits
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""CountExtremelyRandomStats"" device_type: ""CPU""') for unknown op: CountExtremelyRandomStats
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""FinishedNodes"" device_type: ""CPU""') for unknown op: FinishedNodes
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""GrowTree"" device_type: ""CPU""') for unknown op: GrowTree
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ReinterpretStringToFloat"" device_type: ""CPU""') for unknown op: ReinterpretStringToFloat
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""SampleInputs"" device_type: ""CPU""') for unknown op: SampleInputs
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ScatterAddNdim"" device_type: ""CPU""') for unknown op: ScatterAddNdim
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNInsert"" device_type: ""CPU""') for unknown op: TopNInsert
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNRemove"" device_type: ""CPU""') for unknown op: TopNRemove
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TreePredictions"" device_type: ""CPU""') for unknown op: TreePredictions
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""UpdateFertileSlots"" device_type: ""CPU""') for unknown op: UpdateFertileSlots
> Accuracy at step 0: 0.0886
> Accuracy at step 10: 0.6844
> Accuracy at step 20: 0.7995
> Accuracy at step 30: 0.8564
> Accuracy at step 40: 0.876
> Accuracy at step 50: 0.8819
> Accuracy at step 60: 0.8892
> Accuracy at step 70: 0.8881
> Accuracy at step 80: 0.8843
> Accuracy at step 90: 0.8912
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:126] Couldn't open CUDA library cupti64_80.dll
> F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\default\gpu\cupti_wrapper.cc:59] Check failed: ::tensorflow::Status::OK() == (::tensorflow::Env::Default()->GetSymbolFromLibrary( GetDsoHandle(), kName, &f)) (OK vs. Not found: cuptiActivityRegisterCallbacks not found)could not find cuptiActivityRegisterCallbacksin libcupti DSO

 I am totally lost. Could someone tell me why?"
9103,BUG: tensorflow.placeholder shape does not serialize with protobuf,"**Profobuf serialization(json)** 
{
      ""attr"": {
        ""dtype"": {
          ""type"": ""DT_FLOAT""
        },
        ""shape"": {
          ""shape"": {}
        }
      },
      ""name"": ""x"",
      ""op"": ""Placeholder""
    },

**Tensorflow code** 
x = tf.placeholder(tf.float32, shape=None, name=""x"")"
9102,Problems freezing the graph,"- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
   Please see below for how to replicate the problems. Zip attachment contains two pieces of very small code.
- *TensorFlow installed from (source or binary)?*:
   binary - 1.1
- *TensorFlow version*:
     1.1
- *Bazel version (if compiling from source)*:
      Not applicable
- *CUDA/cuDNN version*:
       Recent but not latest.  8.0, V8.0.44 
- *GPU Model and Memory*:
   Tesla K20 4 GB
- *Exact command to reproduce*:
   See below....
### Describe the problem clearly
We have a problem related to saving the operations as constants while freezing using the algorithm in the attached files.
The problem can be easily replicated by trying to freeze the graphs generated by the toy example in textsum https://github.com/tensorflow/models/tree/master/textsum .

Models are trained with the following command:
bazel-bin/textsum/seq2seq_attention --mode=train --article_key=article --abstract_key=abstract --data_path=textsum/data/data --vocab_path=textsum/data/vocab --log_root=textsum/log_root --train_dir=textsum/log_root/train

Then freeze_2_textsum.py is called with the following syntax:
python freeze_2_textsum.py 
Command in our case was:
python freeze_2_textsum.py --model_folder=./log_root/ --outputnodes=global_step

In this case, we are able to find the saved constants in the frozen_model.pb file.
But when we try the same syntax for the trained graph in our project, we could not find the constants in the frozen model.pb file, while the freeze_2_textsum.py script prints the log message that ""13 ops were converted to constants""
This problem leads to the following error while running the session in our test script:
""Attempting to use uninitialized value model/generate_embedding_RNN_output/BiRNN/BW/BasicLSTMCell/Linear/Bias""
cmd line for test script:

python test_tf_frozen_txtsum.py


### Source Code / Logs

[Freezing_problem.zip](https://github.com/tensorflow/tensorflow/files/909961/Freezing_problem.zip)
"
9101,Why `tf.nn.nce_loss` cannot run on GPU?,"The code `tensorflow/examples/tutorials/word2vec/word2vec_basic.py` has a comment `# Ops and variables pinned to the CPU because of missing GPU implementation`.  I have also found that the operation `tf.nn.nce_loss` cannot be implemented by GPU. So why `tf.nn.nce_loss` cannot run on GPU?  My guess is the `log_uniform_candidate_sampler` cannot run on GPU. But I still don't know which part of it cause this problem. 

Tensorflow version: 1.0.1
CUDA version: 7.5
GPU: Tesla K40c
"
9100,Why is there NO input_data in the file?,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:
My question is irrelevant to these. 

### Describe the problem clearly
I am learning the MNIST based on the tutorial on the [TensorFlow website](https://www.tensorflow.org/get_started/mnist/prosl)
the first line of code is: 
`from tensorflow.examples.tutorials.mnist import input_data`

But when I open the file in [GitHub](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist.py)
I do not see the function Input_data in the file. WHY? 



### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9099,Nearest neighbor interpolation method for tf.image.crop_and_resize ?,"At the moment, only bilinear interpolation is supported by crop_and_resize. 
However, when working with little images (and with labeled images), it sometimes makes more sense to use a nearest neighbor interpolation.
Any plans of adding a nearest neighbor interpolation for the method in the near future ? 
"
9098,tensorflow/core/util/ctc/ctc_loss_calculator.cc:144] No valid path found,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9097,Android: Invalid argument: No OpKernel was registered to support Op 'PaddingFIFOQueue' with these attrs,"I encountered a problem when using a multibox model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:

tensorflow_jni.cc:361 Error during inference: Invalid argument: No OpKernel was registered to support Op 'PaddingFIFOQueue' with these attrs
                                                                       	 [[Node: prefetch_queue = PaddingFIFOQueue[capacity=500, component_types=[DT_FLOAT, DT_FLOAT, DT_BOOL, DT_UINT8, DT_STRING, DT_INT64], container="""", shapes=[[-1], [-1,4], [-1], [-1,-1,3], [], [-1]], shared_name=""""]()]]
"
9096,android libtensorflow_inference.so run crash (signal 6 (SIGABRT)),"04-10 14:37:38.954   331   331 F DEBUG   : Build fingerprint: 'Xiaomi/virgo/virgo:6.0.1/MMB29M/7.3.30:user/release-keys'
04-10 14:37:38.954   331   331 F DEBUG   : Revision: '0'
04-10 14:37:38.954   331   331 F DEBUG   : ABI: 'arm'
04-10 14:37:38.954   331   331 F DEBUG   : pid: 24044, tid: 24335, name: pool-1-thread-1  >>> cmmc.com.styletransfer <<<
04-10 14:37:38.954   331   331 F DEBUG   : signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------
04-10 14:37:38.983   331   331 F DEBUG   :     r0 00000000  r1 00005f0f  r2 00000006  r3 a08bf978
04-10 14:37:38.983   331   331 F DEBUG   :     r4 a08bf980  r5 a08bf930  r6 0000000c  r7 0000010c
04-10 14:37:38.983   331   331 F DEBUG   :     r8 9d8fca90  r9 a06a7bf8  sl a08bdbd0  fp a08bdb30
04-10 14:37:38.985   331   331 F DEBUG   :     ip 00000006  sp a08bd930  lr b6ceec69  pc b6cf1058  cpsr 400f0010
04-10 14:37:39.101   331   331 F DEBUG   :
04-10 14:37:39.101   331   331 F DEBUG   : backtrace:
04-10 14:37:39.101   331   331 F DEBUG   :     #00 pc 00042058  /system/lib/libc.so (tgkill+12)
04-10 14:37:39.101   331   331 F DEBUG   :     #01 pc 0003fc65  /system/lib/libc.so (pthread_kill+32)
04-10 14:37:39.102   331   331 F DEBUG   :     #02 pc 0001c403  /system/lib/libc.so (raise+10)
04-10 14:37:39.102   331   331 F DEBUG   :     #03 pc 000195b5  /system/lib/libc.so (__libc_android_abort+34)
04-10 14:37:39.102   331   331 F DEBUG   :     #04 pc 00017508  /system/lib/libc.so (abort+4)
04-10 14:37:39.102   331   331 F DEBUG   :     #05 pc 00775457  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.103   331   331 F DEBUG   :     #06 pc 0075780d  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.103   331   331 F DEBUG   :     #07 pc 00757855  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.103   331   331 F DEBUG   :     #08 pc 0075794d  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.103   331   331 F DEBUG   :     #09 pc 00757d0f  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.105   331   331 F DEBUG   :     #15 pc 00257b13  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.105   331   331 F DEBUG   :     #16 pc 0063f655  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.105   331   331 F DEBUG   :     #17 pc 0063f8d3  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.105   331   331 F DEBUG   :     #18 pc 006342e3  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.106   331   331 F DEBUG   :     #19 pc 0063c49f  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.106   331   331 F DEBUG   :     #20 pc 0063c591  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.106   331   331 F DEBUG   :     #21 pc 0063c81d  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.106   331   331 F DEBUG   :     #22 pc 0063fc19  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.106   331   331 F DEBUG   :     #23 pc 006390c9  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.106   331   331 F DEBUG   :     #24 pc 0008c0e9  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.107   331   331 F DEBUG   :     #25 pc 0008c4eb  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so
04-10 14:37:39.107   331   331 F DEBUG   :     #26 pc 0008579f  /data/app/cmmc.com.styletransfer-2/lib/arm/libtensorflow_inference.so (Java_org_tensorflow_Session_run+650)
04-10 14:37:39.107   331   331 F DEBUG   :     #27 pc 0056e0c7  /data/app/cmmc.com.styletransfer-2/oat/arm/base.odex (offset 0x391000) (byte[] org.tensorflow.Session.run(long, byte[], long[], long[],
int[], long[], int[], long[], boolean, long[])+306)

I stylize image crashed((the image size is 576x768 or more bigger, but 384x512 not crash)
The Model based on A Neural Algorithm of Artistic Style(Stylize) paper

"
9095,Problem with seq2seq models in prediction,"@mrry Hi, I am confused with a prediction problem implemented in TensorFlow seq2seq. "
9094,Uncaught TypeError: Cannot read property 'toString' of undefined when use TensorBoard projector,"- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes. I was training a tree based network using Tensorflow Fold to train word embeddings for SQL parse tree. But this shouldn't be a problem because the TensorBoard can correctly read the checkpoint file.
- *TensorFlow installed from (source or binary)?*: binary (installed using pip)
- *TensorFlow version*: 1.0.0
- *Bazel version (if compiling from source)*: N/A
- *CUDA/cuDNN version*: N/A
- *GPU Model and Memory*: CPU only
- *Exact command to reproduce*:

  * Open the log folder [tflogs.zip](https://github.com/tensorflow/tensorflow/files/908728/tflogs.zip) using TensorBoard (Seems the absolute path is hardcoded in the checkpoint file, the absolute path should be `/tmp/workspace/tflogs`):
`tensorboard --logdir=tflogs`
  * Switch to embedding tab
  * Enable 3D label on the top left corner of the projector

### Describe the problem clearly
Before enabling 3D label
![image](https://cloud.githubusercontent.com/assets/1519759/24842868/0194f2ec-1d6b-11e7-8786-9f83737d99d0.png)

After enabling 3D label
![image](https://cloud.githubusercontent.com/assets/1519759/24842880/18ed6f32-1d6b-11e7-9cfc-81281a074217.png)


Expected result: label shown
Actual result: the projector becomes blank, while the following error shown in the js console:
```
Uncaught TypeError: Cannot read property 'toString' of undefined
    at ProjectorScatterPlotAdapter.getLabelText (tf-tensorboard.html:20587)
    at ProjectorScatterPlotAdapter.generate3DLabelsArray (tf-tensorboard.html:20582)
    at ProjectorScatterPlotAdapter.createVisualizers (tf-tensorboard.html:20613)
    at ProjectorScatterPlotAdapter.set3DLabelMode (tf-tensorboard.html:20245)
    at HTMLElement.<anonymous> (tf-tensorboard.html:24813)
ProjectorScatterPlotAdapter.getLabelText @ tf-tensorboard.html:20587
ProjectorScatterPlotAdapter.generate3DLabelsArray @ tf-tensorboard.html:20582
ProjectorScatterPlotAdapter.createVisualizers @ tf-tensorboard.html:20613
ProjectorScatterPlotAdapter.set3DLabelMode @ tf-tensorboard.html:20245
(anonymous) @ tf-tensorboard.html:24813
```"
9092,problem with wide_n_deep_tutorial.py on Tensorflow 1.0,"Using Python 3.6.0 (Anaconda x64), Tensorflow 1.0, macOS Sierra version 10.12.4, I get the following error:

> 
> >  python wide_deep.py
> Training data is downloaded to /var/folders/h2/727s56vx40s_6n2z9ldl6kx00000gs/T/tmp76m50o3h
> Test data is downloaded to /var/folders/h2/727s56vx40s_6n2z9ldl6kx00000gs/T/tmpwzhof_zb
> model directory = /var/folders/h2/727s56vx40s_6n2z9ldl6kx00000gs/T/tmpclbsc2wm
> Traceback (most recent call last):
>   File ""wide_deep.py"", line 234, in <module>
>     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
>   File ""/Users/CBrauer/anaconda/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 44, in run
>     _sys.exit(main(_sys.argv[:1] + flags_passthrough))
>   File ""wide_deep.py"", line 197, in main
>     FLAGS.train_data, FLAGS.test_data)
>   File ""wide_deep.py"", line 185, in train_and_eval
>     m = build_estimator(model_dir, model_type)
>   File ""wide_deep.py"", line 132, in build_estimator
>     fix_global_step_increment_bug=True)
> TypeError: __init__() got an unexpected keyword argument 'fix_global_step_increment_bug'
> > 

Charles"
9091,Memory Leak Running simple feed_dict graph,"In a series simple tensorflow programs I obtain memory leaks (unbounded growth of CPU memory).
On original program on a computer with 64GB of RAM this leak is about 640 megabytes per hour (1% of total memory).

### Plots of computer's memory over time:
#### Long time scale picture:
![unknown-1](https://cloud.githubusercontent.com/assets/1411079/24841025/1064f380-1d2f-11e7-8738-943be211bb1b.png)
####  short time scale picture:
![unknown](https://cloud.githubusercontent.com/assets/1411079/24841026/12d78984-1d2f-11e7-8efd-62bd8e46b46c.png)


## Problem description

The original program was more advanced and included RNNs/Saving/Loading etc.. but I ""narrowed it down"" to a simple for loop with no gradient descent where memory grows over time without bound. 
Tested on Fedora 25 and Mac OSX 10.11.5. Issue occurs when running on single GPU (Titan X Pascal) or on CPU. Varying the sizes of the variables in the graph only changes the degree of growth, but does not prevent the effect from occurring. This issue occurs on tensorflow 0.12 and on current tensorflow 1.0.1. No custom code was used. Tensorflow was installed using pip in both cases (pre-compiled binary. Each time this was `pip3 install tensorflow-gpu`). Using CUDA 8.0,  CuDNN v5 [though this should not impact the use-case, since no cudnn kernels are being used]. GPU is a Titan X Pascal 12GB of VRAM (not Titan Xp).

## To reproduce:

```
import argparse
import psutil

from os import getpid
import tensorflow as tf
import numpy as np

def fc(inputs, output_size):
    with tf.variable_scope(""FC""):
        input_size = inputs.get_shape()[-1].value
        W = tf.get_variable(""W"", shape=[input_size, output_size])
        b = tf.get_variable(""b"", shape=[output_size], initializer=tf.constant_initializer(0))
        out = tf.nn.xw_plus_b(inputs, W, b)
    return out

def create_model(input_size, output_size):
    # model placeholders:
    with tf.variable_scope(""Inputs""):
        input_placeholder = tf.placeholder(
            tf.float32, [None, input_size], name=""input_placeholder""
        )
    # meaningless function of inputs
    op = tf.reduce_mean(tf.reduce_sum(fc(input_placeholder, output_size), 1))
    return input_placeholder, op

def parse_args(args=None):
    parser = argparse.ArgumentParser()
    parser.add_argument('--max_epochs', type=int, default=1000)
    parser.add_argument('--batch_size', type=int, default=7000)
    parser.add_argument('--input_size', type=int, default=100)
    parser.add_argument('--output_size', type=int, default=100)
    parser.add_argument('--device', type=str, default=""gpu:0"")
    return parser.parse_args(args=args)

def create_batches(inputs, input_size, batch_size, n):
    batches = []
    for i in range(n):
        X = np.random.uniform(-1.0, 1.0, size=(batch_size, input_size))
        batches.append({inputs: X})
    return batches

def main():
    args = parse_args()
    session_conf = tf.ConfigProto(allow_soft_placement=True)
    np.random.seed(1234)
    process = psutil.Process(getpid())

    with tf.Session(config=session_conf) as session, tf.device(args.device):
        inputs, op = create_model(args.input_size, args.output_size)
        session.run(tf.global_variables_initializer())
        batches = create_batches(inputs, args.input_size, args.batch_size, 20)

        for epoch in range(args.max_epochs):
            before = process.memory_percent()
            for feed_dict in batches:
                session.run(op, feed_dict)
            after = process.memory_percent()
            print(""MEMORY CHANGE %.4f -> %.4f"" % (before, after))

if __name__ == ""__main__"":
    main()
```

Output will be (exact numbers are percentages of computer's ram, so should change based on hardware, but main point is that memory continues to grow when the program has no variation between graph runs, batches are all the same size, no randomness is left in the program, etc.):

```
MEMORY CHANGE 1.2427 -> 1.3101
MEMORY CHANGE 1.3101 -> 1.3103
MEMORY CHANGE 1.3103 -> 1.3104
MEMORY CHANGE 1.3104 -> 1.3106
MEMORY CHANGE 1.3106 -> 1.3108
MEMORY CHANGE 1.3108 -> 1.3108
MEMORY CHANGE 1.3108 -> 1.3108
...
MEMORY CHANGE 1.3108 -> 1.3109
...
MEMORY CHANGE 1.3109 -> 1.3110
...
```

How can I fix this? I currently suspect a CPU memory pool issue inside tensorflow since the problem is fairly generic, and does not depend on the ops inside the graph (much). From what I've gathered most likely candidate is the `tf.asarray`/copying of numpy arrays in `feed_dict`, leading to memory fragmentation etc. Supposing this were the case, I've heard that `tcmalloc` should alleviate this, but no dice (note: I've also checked that `objgraph` shows no growth in program over time).

"
9090,Saver/Summary: The process cannot access the file because it is being used by another process.,"Hey guys!

I have been banging my head for a couple of days with the following:

I am using a MonitoredTrainingSession with a single local server (but bug is identical even if using Supervisor and/or distributed architecture).

`#...
sess  = tf.train.MonitoredTrainingSession(...)\
while True:\
   sess.run(train_op)`

Assuming sequential runs of the python client without changing a single line of code,  the problem is that I sometimes get the error: 
`Tensorflow.python.framework.errors_impl.FailedPreconditionError: Failed to rename: .../graph.pbtxt.tmp23e44d8fdce844e6822a56dc886588e6 to: .../graph.pbtxt : The process cannot access the file because it is being used by another process.`

... and the interesting thing is that sometimes this does not occur and training begins, but it then happens just as the first before_run call of the checkpoint hook tries to save the initial state (as seen in the MonitoredSession source code): 

`Failed to rename: .../model.ckpt-1_temp_4fcb775402bc44568b86836d94747b27/part-00000-of-00001.data-00000-of-00001.tempstate17529973146728747180 to: .../model.ckpt-1_temp_4fcb775402bc44568b86836d94747b27/part-00000-of-00001.data-00000-of-00001 : The process cannot access the file because it is being used by another process.`

SOLVED: don't ever store log data and checkpoints in dropbox (:
"
9089,cpp protobuf instructions out-of-date for MacOS,"Instructions to upgrade to cpp protobuf implementation on Mac from https://www.tensorflow.org/install/install_mac#protobuf_pip_package_31 don't work work, makes TF fails with following stacktrace

```
Traceback (most recent call last):
  File ""kronecker_benchmark.py"", line 3, in <module>
    import tensorflow as tf
  File ""/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 54, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/google/protobuf/descriptor.py"", line 46, in <module>
    from google.protobuf.pyext import _message
ImportError: dlopen(/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-darwin.so, 2): Library not loaded: /usr/local/lib/libprotobuf.10.dylib
  Referenced from: /Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-darwin.so
  Reason: image not found

```

Work-around is to use older link:
pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp35-none-macosx_10_11_x86_64.whl

Check that it works
`python -c ""from google.protobuf.internal import api_implementation; print(api_implementation._default_implementation_type)""
`

MacOS: 10.12.4 (16E195), TensorFlow, latest nightly from today installed as:
`pip install --upgrade https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.1.0rc1-py3-none-any.whl
`
"
9088,'tensorboard' command not found (raspberry pi 3),"Bug in installation (tensorflow python code runs fine)

here are the step I used to install TensorFlow :

```
sudo apt-get install python-pip python-dev
wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v1.0.1/tensorflow-1.0.1-cp27-none-linux_armv7l.whl
pip install --user tensorflow-1.0.1-cp27-none-linux_armv7l.whl
pip uninstall mock
pip install --user mock
sudo pip install --user git+https://github.com/tflearn/tflearn.git
```
the machine is a raspberrry pi v3 (raspbian v 8.0)
tensorflow v 1.0.1

problem :

I try to run tensorboard, I get a command not found

I tried locate, find, whereis, .... nothing, seems like it did not get installed with tensorflow

logs :

dont know if there are any install logs, if yes let me know where to find them"
9087,ValueError: Restore called with invalid save path,"I had saved the model after each epoch using:

savernew = tf.train.Saver(max_to_keep=10000)
sp=""/ models/epoch""+str(i+1)+""/""
savernew.save(session, sp,global_step=sv.global_step)

Now I want to restore the epoch 88:

new_saver = tf.train.Saver()
new_saver.restore(sess, ""/models/epoch88/"")

I am getting the  error:

ValueError: Restore called with invalid save path: '/ models/epoch88/'. File path is: ' /models/epoch88/'

My tensorflow version is 0.11
"
9083,"Feature request: In tensorboard, move ""Image"" and ""Audio"" columns","A *very* minor feature request: it would make sense to move the Image and Audio columns to the right, and let the first columns be: Scalar, Histogram and Distribution. Those two columns are arguably not as frequently used, and switching between looking at scalars and histograms get tiring sometimes.

(but if there's plans to allow for visualising different types of variables together, that might be even better)"
9082,"OSX compile from sources: ""dyld: Library not loaded: @rpath/libcudart.8.0.dylib""","Hi,
I'm trying to complile TF from sources I recieve the following error:
`dyld: Library not loaded: @rpath/libcudart.8.0.dylib`
I know for a fact that cuda is correctly installed as I'm currently using TF on my machine (pip).

I've been following those steps:
1. clone master
2. select X-code 7.2
3. ./configure, all defaults except:
     - compile options: -march=native -mavx -mavx2 -mfma 
     - support cuda [Y]
4. bazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

what I'm I doing wrong ? 

Thanks

```
Cesare:tensorflow-master cesare$ bazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

WARNING: /Users/cesare/Projects/ml/tensorflow-master/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /Users/cesare/Projects/ml/tensorflow-master/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /Users/cesare/Projects/ml/tensorflow-master/tensorflow/contrib/factorization/BUILD:106:1: Executing genrule //tensorflow/contrib/factorization:gen_factorization_ops_pygenrule failed: bash failed: error executing command 
  (cd /private/var/tmp/_bazel_cesare/bcc912c27d26c81cd2b264ad18985527/execroot/tensorflow-master && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/local/cuda \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    PATH=/usr/local/cuda/bin:/opt/local/bin:/opt/local/sbin:/usr/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/MacGPG2/bin \
    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \
    TF_CUDA_VERSION='' \
    TF_CUDNN_VERSION='' \
    TF_NEED_CUDA=1 \
    TMPDIR=/var/folders/n5/2dz3mvjj1cs6cn6j93_vj_mc0000gn/T/ \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/contrib/factorization/gen_gen_factorization_ops_py_wrappers_cc 0 > bazel-out/local_darwin-py3-opt/genfiles/tensorflow/contrib/factorization/python/ops/gen_factorization_ops.py'): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 6.
dyld: Library not loaded: @rpath/libcudart.8.0.dylib
  Referenced from: /private/var/tmp/_bazel_cesare/bcc912c27d26c81cd2b264ad18985527/execroot/tensorflow-master/bazel-out/host/bin/tensorflow/contrib/factorization/gen_gen_factorization_ops_py_wrappers_cc
  Reason: image not found
/bin/bash: line 1: 63383 Abort trap: 6           bazel-out/host/bin/tensorflow/contrib/factorization/gen_gen_factorization_ops_py_wrappers_cc 0 > bazel-out/local_darwin-py3-opt/genfiles/tensorflow/contrib/factorization/python/ops/gen_factorization_ops.py
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1.018s, Critical Path: 0.04s
```

```
Cesare:tensorflow-master cesare$ ls -la /usr/local/cuda/lib/libcudart.8.0.dylib 

lrwxr-xr-x@ 1 cesare  staff  50 Sep 27  2016 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
```

```
Cesare:tensorflow-master cesare$ echo $DYLD_LIBRARY_PATH 

/usr/local/cuda/extras/CUPTI/lib:/usr/local/cuda/lib:/usr/local/cuda
```"
9080,Support for nvidia-cuda-mps-server ,"I'm experimenting with multiple Tensorflow GPU processes and the NVIDIA Multi-Process Server. 
https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdf

I have the following MNIST example as a benchmark (neural.py)

```
import tensorflow as tf
import os

from tensorflow.examples.tutorials.mnist import input_data
data = input_data.read_data_sets('MNIST_data_%d' % os.getpid(), one_hot=True)

# construction phase
x = tf.placeholder(tf.float32, shape=[None, 784])
y = tf.placeholder(tf.float32, shape=[None, 10])

with tf.name_scope('fc_1'):
  W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))
  b1 = tf.Variable(tf.truncated_normal([200], stddev=0.1))
  h = tf.sigmoid(tf.matmul(x, W1) + b1)

with tf.name_scope('fc_2'):
  W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))
  b2 = tf.Variable(tf.truncated_normal([10], stddev=0.1))
  y_predict = tf.nn.softmax(tf.matmul(h, W2) + b2)

with tf.name_scope('eval'):
  with tf.name_scope('loss'):
    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_predict), reduction_indices=[1]))

learning_rate = 0.5

backprop = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)

correct = tf.equal(tf.argmax(y, 1), tf.argmax(y_predict, 1))
accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))

#execution

sess = tf.Session()

sess.run(tf.initialize_all_variables())

train_steps = 2000
batch_size = 50

for i in range(train_steps):
  batch_x, batch_y = data.train.next_batch(batch_size)
  sess.run(backprop, feed_dict={x: batch_x, y: batch_y})

print(sess.run(accuracy, feed_dict={x: data.test.images, y: data.test.labels}))
```

And I'm running two processes like this:
`$ time python neural.py &
     time python neural.py
`

Without `nvidia-cuda-mps-control` running as a daemon, this is the output:
```
0.9483
0.947

real    0m15.602s
user    0m6.172s
sys     0m5.092s

real    0m15.861s
user    0m6.288s
sys     0m1.964s
```

With `nvidia-cuda-mps-control` running as a daemon, I'm getting an internal error:

```
F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)
F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)
-bash: line 76: 47018 Aborted                 (core dumped) python neural.py
```

I can verify from the nvidia-mps logs in /var/log/nvidia-mps that the tensorflow Cuda context successfully started an nvidia-cuda-mps-server and connected to it.

**/var/log/nvidia-mps/control.log**
> [2017-04-09 10:05:09.539 Control 46322] Start
> [2017-04-09 10:05:21.023 Control 46322] Accepting connection...
> [2017-04-09 10:05:21.024 Control 46322] NEW CLIENT 46325 from user 1000: Server is not ready, push client to pending list
> [2017-04-09 10:05:21.024 Control 46322] Starting new server 46348 for user 1000

The MPS server should be compatible with the Cuda API which Tensorflow uses, so I'm uncertain about why I'm getting this error.

**Tensorflow version: 1.01**
**Ubuntu 16.04**
**Cuda 8.0, CuDNN**

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.39                 Driver Version: 375.39                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 8915:00:00.0     Off |                  Off |
| N/A   51C    P8    28W / 149W |     82MiB / 12205MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```"
9078,module 'tensorflow' has no attribute 'summaries',"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from (source or binary)?*:
- *TensorFlow version*:
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9077,"Any idea why ""failed to create cublas handle""?","When I run a demo of Faster R-CNN,I meet an error,I have spend a whole week on it,but not work:

Env:
- *OS*:Ubuntu16.04
- *TensorFlow version*:1.0.1
- *TensorFlow installed from (source or binary)?*:binary
- *CUDA/cuDNN version*:CUDA8.0 cuDNN5.1
- *GPU Model and Memory*: GTX 950 2G
- *Exact command to reproduce*:python ./tools/demo.py --model model_path

See https://github.com/smallcorgi/Faster-RCNN_TF

The error as follows:

W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 791.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
E tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
W tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS support
Traceback (most recent call last):
  File ""./tools/demo.py"", line 126, in <module>
    _, _= im_detect(sess, net, im)
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/fast_rcnn/test.py"", line 179, in im_detect
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=1369, n=18, k=512
	 [[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]
	 [[Node: cls_score/cls_score/_109 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_357_cls_score/cls_score"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'rpn_cls_score/Conv2D', defined at:
  File ""./tools/demo.py"", line 114, in <module>
    net = get_network(args.demo_net)
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/factory.py"", line 28, in get_network
    return networks.VGGnet_test()
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py"", line 16, in __init__
    self.setup()
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py"", line 40, in setup
    .conv(1,1,len(anchor_scales)*3*2,1,1,padding='VALID',relu = False,name='rpn_cls_score'))
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 25, in layer_decorated
    layer_output = op(self, layer_input, *args, **kwargs)
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 109, in conv
    conv = convolve(input, kernel)
  File ""/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 100, in <lambda>
    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 396, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

InternalError (see above for traceback): Blas SGEMM launch failed : m=1369, n=18, k=512
	 [[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]]
	 [[Node: cls_score/cls_score/_109 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_357_cls_score/cls_score"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

"
9076,ImportError: No module named 'tensorflow.models',"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes
- *TensorFlow installed from (source or binary)?*: binary (anaconda)
- *TensorFlow version*: 1.0.1
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*: 8.0
- *GPU Model and Memory*: GTX 1080 8GB
- *Exact command to reproduce*: import tensorflow.models

### Describe the problem clearly
$ python
Python 3.5.3 |Continuum Analytics, Inc.| (default, Mar  6 2017, 11:58:13) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow.models
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named 'tensorflow.models'

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9075,TensorBoard : Scalars have tags but no content,"can see the graph and Scalars tags，but  no Scalar content .

**Environment info**

ubuntu 15.04
virtualenv Python 2.7
Tensoflow installed from binary pip package,version 1.0.1
Chrome  45.0.2454.101 Ubuntu 15.04 (64-bit)

**About the code**

copy and run tensorflow/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py ,
then 
tensorboard --logdir /tmp/tensorflow/mnist/logs/mnist_with_summaries

**The following is output by adding ""--debug"":**

 DEBUG:tensorflow:No more events in /tmp/tensorflow/mnist/logs/mnist_with_summaries/test/events.out.tfevents.1491699349.amtb
INFO:tensorflow:No path found after /tmp/tensorflow/mnist/logs/mnist_with_summaries/test/events.out.tfevents.1491699349.amtb
DEBUG:tensorflow:Opening a record reader pointing at /tmp/tensorflow/mnist/logs/mnist_with_summaries/train/events.out.tfevents.1491699347.amtb
DEBUG:tensorflow:No more events in /tmp/tensorflow/mnist/logs/mnist_with_summaries/train/events.out.tfevents.1491699347.amtb
INFO:tensorflow:No path found after /tmp/tensorflow/mnist/logs/mnist_with_summaries/train/events.out.tfevents.1491699347.amtb
INFO:tensorflow:Finished with EventMultiplexer.Reload()
INFO:tensorflow:TensorBoard done reloading. Load took 14.782 secs
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: /tmp/tensorflow/mnist/logs/mnist_with_summaries
INFO:tensorflow:Adding events from directory /tmp/tensorflow/mnist/logs/mnist_with_summaries/train
INFO:tensorflow:Adding events from directory /tmp/tensorflow/mnist/logs/mnist_with_summaries/test
INFO:tensorflow:Done with AddRunsFromDirectory: /tmp/tensorflow/mnist/logs/mnist_with_summaries
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
INFO:tensorflow:Beginning EventMultiplexer.Reload()
DEBUG:tensorflow:No more events in /tmp/tensorflow/mnist/logs/mnist_with_summaries/test/events.out.tfevents.1491699349.amtb
INFO:tensorflow:No path found after /tmp/tensorflow/mnist/logs/mnist_with_summaries/test/events.out.tfevents.1491699349.amtb
DEBUG:tensorflow:No more events in /tmp/tensorflow/mnist/logs/mnist_with_summaries/train/events.out.tfevents.1491699347.amtb
INFO:tensorflow:No path found after /tmp/tensorflow/mnist/logs/mnist_with_summaries/train/events.out.tfevents.1491699347.amtb
INFO:tensorflow:Finished with EventMultiplexer.Reload()
INFO:tensorflow:TensorBoard done reloading. Load took 0.003 secs

**The following is output by adding ""--inspect"":**


Processing event files... (this can take a few minutes)

Found event files in:
/tmp/tensorflow/mnist/logs/mnist_with_summaries/train
/tmp/tensorflow/mnist/logs/mnist_with_summaries/test

These tags are in /tmp/tensorflow/mnist/logs/mnist_with_summaries/train:
audio -
histograms
   layer1/Wx_plus_b/pre_activations
   layer1/activations
   layer1/biases/summaries/histogram
   layer1/weights/summaries/histogram
   layer2/Wx_plus_b/pre_activations
   layer2/activations
   layer2/biases/summaries/histogram
   layer2/weights/summaries/histogram
images
   input_reshape/input/image/0
   input_reshape/input/image/1
   input_reshape/input/image/2
   input_reshape/input/image/3
   input_reshape/input/image/4
   input_reshape/input/image/5
   input_reshape/input/image/6
   input_reshape/input/image/7
   input_reshape/input/image/8
   input_reshape/input/image/9
scalars
   accuracy_1
   cross_entropy_1
   dropout/dropout_keep_probability
   layer1/biases/summaries/max
   layer1/biases/summaries/mean
   layer1/biases/summaries/min
   layer1/biases/summaries/stddev_1
   layer1/weights/summaries/max
   layer1/weights/summaries/mean
   layer1/weights/summaries/min
   layer1/weights/summaries/stddev_1
   layer2/biases/summaries/max
   layer2/biases/summaries/mean
   layer2/biases/summaries/min
   layer2/biases/summaries/stddev_1
   layer2/weights/summaries/max
   layer2/weights/summaries/mean
   layer2/weights/summaries/min
   layer2/weights/summaries/stddev_1


Event statistics for /tmp/tensorflow/mnist/logs/mnist_with_summaries/train:
audio -
graph
   first_step           0
   last_step            0
   max_step             0
   min_step             0
   num_steps            1
   outoforder_steps     []
histograms
   first_step           1
   last_step            999
   max_step             999
   min_step             1
   num_steps            900
   outoforder_steps     []
images
   first_step           1
   last_step            999
   max_step             999
   min_step             1
   num_steps            900
   outoforder_steps     []
scalars
   first_step           1
   last_step            999
   max_step             999
   min_step             1
   num_steps            900
   outoforder_steps     []
sessionlog:checkpoint -
sessionlog:start -
sessionlog:stop -


These tags are in /tmp/tensorflow/mnist/logs/mnist_with_summaries/test:
audio -
histograms
   layer1/Wx_plus_b/pre_activations
   layer1/activations
   layer1/biases/summaries/histogram
   layer1/weights/summaries/histogram
   layer2/Wx_plus_b/pre_activations
   layer2/activations
   layer2/biases/summaries/histogram
   layer2/weights/summaries/histogram
images
   input_reshape/input/image/0
   input_reshape/input/image/1
   input_reshape/input/image/2
   input_reshape/input/image/3
   input_reshape/input/image/4
   input_reshape/input/image/5
   input_reshape/input/image/6
   input_reshape/input/image/7
   input_reshape/input/image/8
   input_reshape/input/image/9
scalars
   accuracy_1
   cross_entropy_1
   dropout/dropout_keep_probability
   layer1/biases/summaries/max
   layer1/biases/summaries/mean
   layer1/biases/summaries/min
   layer1/biases/summaries/stddev_1
   layer1/weights/summaries/max
   layer1/weights/summaries/mean
   layer1/weights/summaries/min
   layer1/weights/summaries/stddev_1
   layer2/biases/summaries/max
   layer2/biases/summaries/mean
   layer2/biases/summaries/min
   layer2/biases/summaries/stddev_1
   layer2/weights/summaries/max
   layer2/weights/summaries/mean
   layer2/weights/summaries/min
   layer2/weights/summaries/stddev_1


Event statistics for /tmp/tensorflow/mnist/logs/mnist_with_summaries/test:
audio -
graph -
histograms
   first_step           0
   last_step            990
   max_step             990
   min_step             0
   num_steps            100
   outoforder_steps     []
images
   first_step           0
   last_step            990
   max_step             990
   min_step             0
   num_steps            100
   outoforder_steps     []
scalars
   first_step           0
   last_step            990
   max_step             990
   min_step             0
   num_steps            100
   outoforder_steps     []
sessionlog:checkpoint -
sessionlog:start -
sessionlog:stop -


**issue picture**:
![issue](https://cloud.githubusercontent.com/assets/4977856/24833889/94f2d2e2-1d08-11e7-8c11-aa91917549c4.png)"
9074,Documentation: broken links and image in documentation,"The URL:  https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_sum has a broken link labelled ""the section on Segmentation"".  Also, there is a broken image on that page as well.

Same problems here too (except not all have an image to be broken):
   https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_prod
   https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_min
   https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_max
   https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_mean
   https://www.tensorflow.org/versions/master/api_docs/python/tf/unsorted_segment_sum
   https://www.tensorflow.org/versions/master/api_docs/python/tf/sparse_segment_sum
   https://www.tensorflow.org/versions/master/api_docs/python/tf/sparse_segment_mean
   https://www.tensorflow.org/versions/master/api_docs/python/tf/sparse_segment_sqrt_n

The page I believe they should link back to is here: https://www.tensorflow.org/versions/master/api_guides/python/math_ops#Segmentation

I came here because I haven't grokked just what segmented operations are yet.  So I would be much obliged if the explanation of segmentation were more thoroughly be explained there, perhaps with a couple of examples.

I found [a few places] in the code where this could be address.  And I would have attempted a pull request to fix these, but I'm not up on how to generate the documentation to verify that it was fixed."
9073,Errors when building iOS binaries with selective registration,"The header file generated by [print_selective_registration_header.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py) makes use of strcmp, which causes an error when compiling TensorFlow for iOS with selective registration enabled (`-DSELECTIVE_REGISTRATION`)

Apparently this was fixed in [a commit back in October](https://github.com/tensorflow/tensorflow/commit/c37847c1e5aedf5f33151895bdcbf9de89bbd759) but that commit was [reverted the same day](https://github.com/tensorflow/tensorflow/commit/3510b3060abef6b99fe4bc0656d8dc9406d6c46d) for some reason.

I’ve tried building the tool from the commit of TensorFlow that has the fix, but `./configure` fails for me on that version (missing targets & zlib download). I’ve also tried replacing calls to strcmp with a constexpr variant, but I’m not much help with C++ and couldn’t get anything to work there.

This prevents me from compiling a slimmed down TensorFlow binary for iOS.

cc @petewarden @cwhipkey 

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No, just following the instructions in [print_selective_registration_header.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/print_selective_registration_header.py) and [selective_registration.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/selective_registration.h)
- *TensorFlow installed from (source or binary)?*: Source
- *TensorFlow version*: master (45115c0a985815feef3a97a13d6b082997b38e5d)
- *Bazel version (if compiling from source)*: 0.4.5
- *CUDA/cuDNN version*: N/A
- *GPU Model and Memory*: N/A
- *Exact command to reproduce*:
    ```bash
    $ bazel build tensorflow/python/tools/print_selective_registration_header
    $ bazel-bin/tensorflow/python/tools/print_selective_registration_header \
      --graphs=graph.pb > tensorflow/core/framework/ops_to_register.h
    $ tensorflow/contrib/makefile/compile_ios_tensorflow.sh ""-Os -DSELECTIVE_REGISTRATION""

### Source Code / Logs
Here is the relevant log output on the last command:

```
In file included from ./tensorflow/core/framework/selective_registration.h:46:
./tensorflow/core/framework/ops_to_register.h:4:23: error: constexpr function never produces a
      constant expression [-Winvalid-constexpr]
constexpr inline bool ShouldRegisterOp(const char op[]) {
                      ^
./tensorflow/core/framework/ops_to_register.h:6:10: note: non-constexpr function 'strcmp' cannot
      be used in a constant expression
     || (strcmp(op, ""Add"") == 0)
         ^
/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS10.2.sdk/usr/include/string.h:77:6: note:
      declared here
int      strcmp(const char *__s1, const char *__s2);
         ^
```
"
9072,"bezel build problem for OSX: ""No toolchain corresponding to 'local_darwin' found for cpu darwin"" ","NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No, this is an installation issue.  
- *TensorFlow installed from (source or binary)?*: Source  
- *TensorFlow version*: 1.0.1  
- *Bazel version (if compiling from source)*: Build label: 0.4.5-homebrew  
- *CUDA/cuDNN version*: 8.0.71  
- *GPU Model and Memory*: NVIDIA GeForce GT 750M, 2048 MB  
- *Exact command to reproduce*: From Installing Tensorflow from sources (https://www.tensorflow.org/install/install_sources#PrepareMac): bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package  

### Describe the problem clearly
Receiving the following error when trying to build from source:  
```
  $ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package  
    ERROR: Inconsistent crosstool configuration; no toolchain corresponding to 'local_darwin' found for cpu 'darwin'.  
    INFO: Elapsed time: 0.101s  
```

I'm wondering if 'local_darwin' is an incorrect parameter in the TensorFlow bazel build setup files.  If so, they need to be corrected and updated.  

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem

Input and output pasted in previous questions.  

"
9071,ImportError: libnvidia-fatbinaryloader.so.375.51: cannot open shared object file,"- OS: Ubuntu 17.04
- *TensorFlow installed from: source
- *TensorFlow version*: 1.1.0rc1
- *Bazel version (if compiling from source)*: 0.4.5
- *CUDA/cuDNN version*: 8.0/5.1
- *GPU Model and Memory*: NVIDIA GTX 1060, 6 GB RAM
- *Exact command to reproduce*:

```python
import tensorflow as tf
```

### Describe the problem clearly
I installed Tensorflow from source in order to have all CPU instructions supported.

```
(tensorflow) stefano@stefano-PC:~$ python3
Python 3.5.3 (default, Jan 19 2017, 14:11:04) 
[GCC 6.3.0 20170118] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/stefano/tensorflow/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/stefano/tensorflow/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libnvidia-fatbinaryloader.so.375.51: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/stefano/tensorflow/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/stefano/tensorflow/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libnvidia-fatbinaryloader.so.375.51: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>> 
```

My bashrc:
```
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/lib:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:/usr/lib/nvidia-375
export LIBRARY_PATH=${LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu:/usr/lib/nvidia-375
```

Problem is, that Tensorflow tries to load libnvidia-fatbinaryloader.so.375.51, but it exists only libnvidia-fatbinaryloader.so.375.38. I'm puzzled why TF tries to load a newer version, because right now, version 375.38 is the latest driver available!"
9069,Does Tensorflow support learning of embeddings for output classes in multi-class classification? ,"Hi,

I came across this research paper released by YouTube, on how they use deep learning neural networks for recommendations. It's located here: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf

In the paper, the candidate generation neural network model outputs a softmax with 256 dimensions, which acts as an ""output embedding"" of each of the 1M video classes.

How is this possible to implement in Tensorflow, for example? Isn't softmax supposed to be only 1-Dimensional. If the model outputs an ""embedding"" like this, as they say it does, how would the training data's labels be formatted as 256-dimensional? In other words, how do they compute the 256-dimensional vector for each of the videos in their training dataset?

Also, is it possible to create an output embedding layer when the labels in the training dataset are one-hot encodings of a particular class. In other words, can the output layer automatically learn embeddings for the output class?

Thank you so much for your time and help, guys! I have also asked this question on StackOverflow here: http://stackoverflow.com/questions/43297567/how-to-create-a-multi-dimensional-softmax-output-in-tensorflow

Tensorflow details: Windows, version 1.01, binary (via pip)"
9068,Building tensorflow for Windows 10,"Hello All
I am trying to build tensorflow for my windows machine. I tried building it from source on ubuntu 16.04, but then that wheel doesn't support on windows. 
My machine is windows 10 
python 3.5.2

I dont know what the problem is, Can someone help me with this."
9067,Tensorflow 1.1rc/1.01 too many epochs cause error?,"Software:Tensorflow 1.1rc Python3.5.27&Tensorflow 1.0.1 Python3.5.3 (Anaconda3) CUDA8.0+Cudnn5.1
OS:Windows 10 X64 1607
HW:i5 6400 Z170 16G 1070

### Describe the problem clearly
When I train my mlp or lenet5, if I choose a large epoch number, then it will get a bad result?

### Source Code / Logs
```
from tensorflow.examples.tutorials.mnist import  input_data
import  tensorflow as tf
mnist=input_data.read_data_sets(""MNIST_data/"",one_hot=True)
sess=tf.InteractiveSession()
in_units=784
h1_units=300
W1=tf.Variable(tf.truncated_normal([in_units,h1_units],stddev=0.1))
b1=tf.Variable(tf.zeros([h1_units]))
W2=tf.Variable(tf.zeros([h1_units,10]))
b2=tf.Variable(tf.zeros([10]))
x=tf.placeholder(tf.float32,[None,in_units])
keep_prob=tf.placeholder(tf.float32)
hidden1=tf.nn.relu(tf.matmul(x,W1)+b1)
hidden1_drop=tf.nn.dropout(hidden1,keep_prob)
y=tf.nn.softmax(tf.matmul(hidden1_drop,W2)+b2)
y_=tf.placeholder(tf.float32,[None,10])
cross_entropy=tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=[1]))
train_step=tf.train.AdagradOptimizer(0.03).minimize(cross_entropy)
tf.global_variables_initializer().run()
correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))
accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
for i in range(200000):
    batch_xs,batch_ys=mnist.train.next_batch(500)
    train_step.run({x:batch_xs,y_:batch_ys,keep_prob:0.8})
    if i % 500==0:
        print(i,""--"",accuracy.eval({x:batch_xs,y_:batch_ys, keep_prob: 1.0}))

correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))
accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))
print(accuracy.eval({x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))
```




> C:\Anaconda3\envs\TensorflowRC\python.exe D:/DL/3/mlp.py
> Extracting MNIST_data/train-images-idx3-ubyte.gz
> Extracting MNIST_data/train-labels-idx1-ubyte.gz
> Extracting MNIST_data/t10k-images-idx3-ubyte.gz
> Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
> 2017-04-08 18:07:28.117898: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.118165: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.118511: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.118745: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.120818: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.121070: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.121354: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.121578: W c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
> 2017-04-08 18:07:28.511257: I c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:887] Found device 0 with properties: 
> name: GeForce GTX 1070
> major: 6 minor: 1 memoryClockRate (GHz) 1.645
> pciBusID 0000:01:00.0
> Total memory: 8.00GiB
> Free memory: 6.65GiB
> 2017-04-08 18:07:28.511561: I c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:908] DMA: 0 
> 2017-04-08 18:07:28.511694: I c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:918] 0:   Y 
> 2017-04-08 18:07:28.511840: I c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
> 0 -- 0.404
> 500 -- 0.914
> 1000 -- 0.932
> 1500 -- 0.95
> 2000 -- 0.966
> 2500 -- 0.944
> 3000 -- 0.952
> 3500 -- 0.966

> 
> 80500 -- 1.0
> 81000 -- 1.0
> 81500 -- 1.0
> 82000 -- 1.0
> 82500 -- 0.094
> 83000 -- 0.112
> 83500 -- 0.106
> 84000 -- 0.094
> 84500 -- 0.118
> 85000 -- 0.096
> 85500 -- 0.088
> 86000 -- 0.114
> 86500 -- 0.114
> 87000 -- 0.092
> 87500 -- 0.114
> 88000 -- 0.1
> 88500 -- 0.104"
9066,tensorflow-gpu rc0 import tensorflow error windows 10 64bit nvidia 1080 TI,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
No
- *TensorFlow installed from (source or binary)?*:
binary
- *TensorFlow version*:
pip rc0 or rc1 
nightly
- *Bazel version (if compiling from source)*:
NA
- *CUDA/cuDNN version*:
8.0
- *GPU Model and Memory*:
Nvidia 1080 ti
- *Exact command to reproduce*:
install tensorflow from nightly or using tensorflow==1.1.0rc0 or 1.1.0rc1 through pip (I'm using conda to create the environment)
start python
import tensorflow

### Describe the problem clearly
I followed the suggestion of installing nightly due to the warnings regarding unknown OP
see #8500
The install is successful however the import tensorflow fails with the following log

### Source Code / Logs
```
Python 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 914, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 914, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\tools\Anaconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```"
9064,Distributed tensorflow,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:Yes
- *TensorFlow installed from (source or binary)?*:binary
- *TensorFlow version*:1.0.0
- *Bazel version (if compiling from source)*:No
- *CUDA/cuDNN version*:No
- *GPU Model and Memory*:No
- *Exact command to reproduce*:

### Describe the problem clearly
I am trying to apply distributed tensorflow and want to distribute my task on two pc.
pc1 ip: 192.168.43.6->>>>ps
pc2 ip:192.168.43.107->>>worker

Code snippet:

tf.train.ClusterSpec({
    ""worker"": [
        ""192.168.43.107:2223""
            ],
    ""ps"": [
        ""192.168.43.6:2222""
        
    ]})

cluster = tf.train.ClusterSpec({""local"": [""192.168.43.6:2222"",""192.168.43.107:2223""]})
server = tf.train.Server(cluster, job_name=""local"", task_index=0)


with tf.device(""/job:ps/task:0""):
    
    weights = {
        
        'wc1': tf.Variable(tf.random_normal([5,5, 5, 1, 32])),
 
        'wc2': tf.Variable(tf.random_normal([5,5, 5, 32, 64])),
        
        'wd1': tf.Variable(tf.random_normal([1216, 1024])),
        
        'out': tf.Variable(tf.random_normal([1024,n_classes]))
    }
    
    biases = {
        'bc1': tf.Variable(tf.random_normal([32])),
        'bc2': tf.Variable(tf.random_normal([64])),
        'bd1': tf.Variable(tf.random_normal([1024])),
        'out': tf.Variable(tf.random_normal([n_classes]))
    }


with tf.device(""/job:worker/task:0""):


    def conv3d(x, W, b, strides=1):
        x = tf.nn.conv3d(x, W, strides=[1, strides, strides,strides, 1], padding='SAME')
        x = tf.nn.bias_add(x, b)
        return tf.nn.relu(x)


    def maxpool3d(x, k=3):
        return tf.nn.max_pool3d(x, ksize=[1,2,2,2,1], strides=[1,2,2,2,1], padding='SAME')


    # Create model
    def conv_net(x, weights, biases, dropout):
        x = tf.reshape(x, shape=[1,20,149,239, 1])
    
        conv1 = conv3d(x, weights['wc1'], biases['bc1'])
        print (""conv1"",conv1)
        conv1 = maxpool3d(conv1, k=3)
        print (""max1"",conv1)
        conv2 = conv3d(conv1, weights['wc2'], biases['bc2'])
        print (""conv2"",conv2)
        conv2 = maxpool3d(conv2, k=3)
        print (""max2"",conv2)
        fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])
        print (""fc1"",fc1)
        fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])
        fc1 = tf.nn.relu(fc1)
        print (""relu"",fc1)
        fc1 = tf.nn.dropout(fc1, dropout)
    
        out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])
        print (""out"",out)
        return out
    
    x = tf.placeholder(tf.float32)
    y = tf.placeholder(tf.float32)
    keep_prob = tf.placeholder(tf.float32) 

    # Construct model
    pred = conv_net(x, weights, biases, keep_prob)
    print (""pred"",pred)
    cost = tf.reduce_mean(tf.nn.softmax(logits=pred))
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
    correct_pred = tf.equal(tf.argmax(pred, -1), tf.argmax(y, -1))
    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))
    init = tf.global_variables_initializer()

    print (""time1"",time.clock())
    saver = tf.train.Saver()

with tf.Session('grpc://192.168.43.107:2222') as sess:
    sess.run(init)

Command line on ps machine->> python train3d5.py --job_name=""ps"" --task_index=0

Command line on ps machine->> python train3d5.py --job_name=""worker"" --task_index=0

Please provide a solution how to distribute training in tensorflow.
We also using hadoop multi-cluster.

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem

Error on worker machine:

CreateSession still working for response from worker: /job:local/replica:0/task:1

"
9062,Getting more done in GitHub with ZenHub,"Hola! @yucao100 has created a [ZenHub](http://www.zenhub.com) account for the **tensorflow** organization. ZenHub is the only project management tool integrated natively in GitHub – created specifically for fast-moving, software-driven teams.

----

#### How do I use ZenHub?

To get set up with ZenHub, all you have to do is **[download the browser extension](https://www.zenhub.com?utm_source=ZHOnboarding)** and log in with your GitHub account. Once you do, you’ll get access to ZenHub’s complete feature-set immediately.

#### What can ZenHub do?

ZenHub adds a series of enhancements directly inside the GitHub UI:

- Real-time, customizable task boards for GitHub issues;
- Multi-Repository burndown charts, estimates, and velocity tracking based on GitHub Milestones;
- Personal to-do lists and task prioritization;
- Time-saving shortcuts – like a quick repo switcher, a “Move issue” button, and much more.

### [Add ZenHub to GitHub](https://www.zenhub.com?utm_source=ZHOnboarding)

_Still curious? See [more ZenHub features](https://www.zenhub.com/features?utm_source=ZHOnboarding) or read [user reviews](https://chrome.google.com/webstore/detail/zenhub-for-github/ogcgkffhplmphkaahpmffcafajaocjbd/reviews). This issue was written by your friendly ZenHub bot, posted by request from @yucao100._

![ZenHub Board](https://cloud.githubusercontent.com/assets/8771909/11153956/233ac4a8-89f1-11e5-94b1-1569d3f38b4d.png)
"
9061,"Tensorflow Training Freezes for sometime, then continue on its own, happen multiple times when training a model","I recently upgraded to Tensorflow 0.12.1, Python3, Ubuntu 14.04, Cuda 8.0, Cudnn 5.1

Then I run my old code written for Tensorflow 0.10.1, which is a simple sequence-to-sequence model. And the training keeps freeze in the middle.

After some time the training will continue normally. Sometimes it 1 or 2 minutes, and sometimes it takes about 5 to 6 hours.

Anyone has opinion on how to trouble-shoot this?"
9060,No toolchain found for cpu 'arm64-v8a' when building android demo app,"Hi,

I'm trying to build the android demo app with target cpu of 'arm64-v8a', from a mac. With command ""bazel build -c opt //tensorflow/examples/android:tensorflow_demo --cpu=arm64-v8a"", I got the following error:
```
ERROR: No toolchain found for cpu 'arm64-v8a'. Valid cpus are: [
  darwin,
  armeabi-v7a,
  x64_windows_msvc,
  s390x,
  ios_x86_64,
].
```
I am able to build with the default target ""armeabi-v7a"". Any advice?

I'm on a fairly recent SHA: 55a1f26547f18ddc5c5b5c8a07479591a4ba789d (the master as of Mar 29). My bazel version is 0.4.5
I specified the NDK path in the WORKSPACE file as the following:
```
android_ndk_repository(
    name = ""androidndk"",
    path = ""/Users/_user_/Downloads/android-ndk-r12b"",
    api_level = 14)
```
I searched the toolchains under folder `/Users/_user_/Downloads/android-ndk-r12b/toolchains` and found `android-ndk-r12b/toolchains/llvm/prebuilt/darwin-x86_64/bin/arm64-v8a`. Not sure why bazel does not use it."
9058,AdadeltaOptimizer numeric issue,"Hi,

I tested it with following script, and expected the model update to be -sqrt(0+1)/sqrt(1+1)*1 = -0.7071. However, the output is -0.866. Input gradient is 1, and confirmed with GradientDescentOptimizer. I also verified in rho=1/epsilon=1 the output is -1 as expected, and rho=1/epsilon=0 the output is nan as expected. Reading the implementation of adadelta didn't tell me why the output is -0.866 for rho=0/epsilon=1. What am I missing?

    def test_tf():
        data  = [0.5]
        label = [0]
        dim   = 1
        batch_size = 1
        import tensorflow as tf
        tf.reset_default_graph()

        x = tf.placeholder(tf.float32, [batch_size, dim])
        l = tf.placeholder(tf.int32, [batch_size, dim])
        W = tf.Variable(tf.zeros((dim,)), name='W')
        logits = x + W
        print(logits)
        loss = tf.losses.mean_squared_error(logits, l)
        #optimizer = tf.train.GradientDescentOptimizer(1)
        optimizer = tf.train.AdadeltaOptimizer(1, rho=0, epsilon=1)
        train = optimizer.minimize(loss)

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            input_map = {x:[data], l:[label]}
            print('loss', loss.eval(input_map))
            sess.run(train, input_map)
            print('\n'.join([' {}\n'.format(p.eval()) for p in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)]))
        sess.close()

    test_tf()
"
9056,tensorboard doesnt display y-axis correctly.,"![image](https://cloud.githubusercontent.com/assets/11971499/24820310/61102b8a-1bb6-11e7-8128-36ac5ab99bf4.png)

This plot makes it look like AUC is greater than 1.0 when it is not.

c:\Python35\Scripts>pip show tensorflow-gpu
Name: tensorflow-gpu
Version: 1.1.0rc1
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: c:\python35\lib\site-packages
Requires: numpy, wheel, protobuf, six, werkzeug
"
9055,tf.matmul should be extended for rank 1 tensors,"This:

    import numpy as np
    a = np.array([1, 2, 1])
    w = np.array([[.5, .6], [.7, .8], [.7, .8]])
    
    print(np.dot(a, w))
    # [ 2.6  3. ] # plain nice old matrix multiplication n x (n, m) -> m
    
    import tensorflow as tf
    
    a = tf.constant(a, dtype=tf.float64)
    w = tf.constant(w)
    
    with tf.Session() as sess:
        print(tf.matmul(a, w).eval())
    
results in:

    ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].

That's surprising and keeps tripping people up (see: http://stackoverflow.com/q/34908033/281545,  http://stackoverflow.com/q/43284897/281545, for instance), which is natural as matrix multiplication should not have any constraints apart from dimension alignment. Workarounds are verbose and complicated:

```
  print(tf.matmul(tf.expand_dims(a,0), w).eval())
  print((tf.reduce_sum(tf.multiply(tf.expand_dims(a,-1), w), axis=0)).eval())
  print((tf.reduce_sum(tf.multiply(a, tf.transpose(w)), axis=1)).eval())
```

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes
- *TensorFlow installed from (source or binary)?*: pip
- *TensorFlow version*: `tf.__version__` gives '1.0.1' - windows and python 3.5.2
- *Bazel version (if compiling from source)*: -
- *CUDA/cuDNN version*: -
- *GPU Model and Memory*: -
- *Exact command to reproduce*: see above

### Source Code / Logs

Full traceback (why printing the same error twice ?)

```
C:\_\Python35\python.exe C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_31.py
[ 2.6  3. ]
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""BestSplits"" device_type: ""CPU""') for unknown op: BestSplits
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""CountExtremelyRandomStats"" device_type: ""CPU""') for unknown op: CountExtremelyRandomStats
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""FinishedNodes"" device_type: ""CPU""') for unknown op: FinishedNodes
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""GrowTree"" device_type: ""CPU""') for unknown op: GrowTree
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ReinterpretStringToFloat"" device_type: ""CPU""') for unknown op: ReinterpretStringToFloat
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""SampleInputs"" device_type: ""CPU""') for unknown op: SampleInputs
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""ScatterAddNdim"" device_type: ""CPU""') for unknown op: ScatterAddNdim
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNInsert"" device_type: ""CPU""') for unknown op: TopNInsert
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TopNRemove"" device_type: ""CPU""') for unknown op: TopNRemove
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""TreePredictions"" device_type: ""CPU""') for unknown op: TreePredictions
E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: ""UpdateFertileSlots"" device_type: ""CPU""') for unknown op: UpdateFertileSlots
Traceback (most recent call last):
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 671, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\_\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_31.py"", line 14, in <module>
    print(tf.matmul(a, w).eval())
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1765, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 1454, in _mat_mul
    transpose_b=transpose_b, name=name)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2329, in create_op
    set_shapes_for_outputs(ret)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1717, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1667, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 676, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].

Process finished with exit code 1

```"
9053,Split on / Has Unexpected Behavior,"Repost from: https://github.com/tensorflow/tensorflow/issues/8993#issuecomment-292632184 /CC @dandelionmane

So it looks like using `/`only works if the keys on the left does not already exist. 
For example this works (both on 1.1rc1):
![image](https://cloud.githubusercontent.com/assets/51059/24816749/f09f96e6-1ba7-11e7-9c1c-e36dd81bb0d0.png)

but this does not:
![image](https://cloud.githubusercontent.com/assets/51059/24816764/01af4b98-1ba8-11e7-8dad-eca20d0ffb5d.png)
"
9050,How to execute distributed training where each node has multiple workers,"Hi, what is the command to run distributed training on multiple nodes where each node has multiple GPUs.
The example in https://github.com/tensorflow/models/tree/master/inception only shows the case where each node has 1 GPU/1 worker. In my cluster, each node has 4 GPUs which should require 4 workers.

I tried the following command:
on **node 0**:
bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=$HOME/imagenet-data \
--job_name='worker' \
--task_id=0 \
--ps_hosts='ps0.example.com:2222' \
--worker_hosts='worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222' &
......

bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=$HOME/imagenet-data \
--job_name='worker' \
--task_id=3 \
--ps_hosts='ps0.example.com:2222' \
--worker_hosts='worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222'

on **node 1**:
bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=$HOME/imagenet-data \
--job_name='worker' \
--task_id=4 \
--ps_hosts='ps0.example.com:2222' \
--worker_hosts='worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222' &
......

bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=$HOME/imagenet-data \
--job_name='worker' \
--task_id=7 \
--ps_hosts='ps0.example.com:2222' \
--worker_hosts='worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker0.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222,worker1.example.com:2222'

Note that there is & at the end of each command so that they can be executed in parallel, but it has out of GPU memory error.

I also tried to use only 1 worker in each node and each worker uses 4 GPU:
on **node 0**:
bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=$HOME/imagenet-data \
--job_name='worker' \
--gpus=4
--task_id=0 \
--ps_hosts='ps0.example.com:2222' \
--worker_hosts='worker0.example.com:2222,worker1.example.com:2222'

on **node 1**:
bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=$HOME/imagenet-data \
--job_name='worker' \
--gpus=4
--task_id=1 \
--ps_hosts='ps0.example.com:2222' \
--worker_hosts='worker0.example.com:2222,worker1.example.com:2222'

But in the end each node only uses 1 GPU. 

So what is the exact command I should use? Thanks.
"
9049,Android example using CMake on Windows not working,"I installed CPU-only Tensorflow version 1.0 on Windows using the pip installer. I am trying to get the Android example to run using CMake as explained in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android/cmake. I cloned the newest version of the tensorflow repository and created a new Android studio project and followed the instructions from the webpage above by modifying the gradle files.  I already found out that it should be 
`debugCompile project(path: ':TensorFlow-Android-Inference', configuration: 'debug')
releaseCompile project(path: ':TensorFlow-Android-Inference', configuration: 'release')`
instead of 
`debugCompile project(path: ':tensorflow_inference', configuration: 'debug')
releaseCompile project(path: ':tensorflow_inference', configuration: 'release')`
Now, however, I get a build error stating ""Error:Project :app declares a dependency from configuration 'releaseCompile' to configuration 'release' which is not declared in the descriptor for project :TensorFlow-Android-Inference.""
Has anyone tried this or could anyone point me to a proper explanation of how to use cMake to build the project. 
Any help would be very much appreciated. Thanks. 
"
9047,beta2_power is applied incorrectly in Adam optimizer,"In `adam.py` and in the `ApplyAdam` op, the denominator is effectively:

```
(tf.sqrt(v_t) + epsilon_t) / tf.sqrt(1 - beta2_power)
```

However, this appears incorrect – per the paper, the correct EMA adjustment should give:

```
tf.sqrt(v_t / (1 - beta2_power)) + epsilon_t
```

Otherwise, when `epsilon_t` is large relative to `tf.sqrt(v_t)`, the effective epsilon used in the denominator is also scaled up by the correction factor, which doesn't match what's in the paper.

Does this seem right, or am I missing something here?"
9045,[FeatureRequest ] Add sparse_column_with_cat_prob to tensorflow.contrib.layers.python.layers.feature_column_ops.py,"Hi there,

working on deep learning for recommender systems I came across the Google Wide and Deep model (see [1] and [2]).

## Problem
In my application context there are users and items as well as the interactions between those entities. Furthermore there are item and user features, that are both, continuous and categorical. Here, we have **_item_features = user_features_** (user_features derived from user interactions).

A big problem is the **representation of categorical user features as a result from their interaction with different items with respectively different item features.** (Some intuition to be found below)

- tf.contrib.layers.python.layers.**sparse_column_with_keys**
- tf.contrib.layers.python.layers.**sparse_column_with_hash_bucket**

allow to define or induce keys for categorical features that are then one-hot encoded behind the scenes - as far as I understood
This works for items that can just have one feature value, but users can have a multivalent preference that should be reflected by a categorcial probability distribution (cpd).

To capture this result we need TF to capture this cpd and compare it with the one-hot-encoded movie features. The latter is provided internally, but for realizing user profiles I couldn't find proper means meaning that within tensorflow.contrib.layers.python.layers there are no sparse columns providing this possibility which in fact is petty relevant.

## Proposed Solution
Add following method feature column:
sparse_column_with_cat_prob(column_name, value_prob_dict, counterpart)

- **column_name**: see sparse_column_with_keys for example
- **value_prob_dict**: dictionary containing feature values (value) and associated probabilities (prob)
- **counterpart**:  eventually, name of the one-hot-encoded sparse column this one is refering to

This would allow for building user features for categorcial user interaction data, especially within recommendation contexts.

## Intuition
To give some intuition see the following example from a movie recommendation context:
user 1 interacts with movies A, B, C, D, and E
movie_features: genre {Romance, Action}, 

```
   movie_id movie_genre  movie_length
0         0     Romance           120
1         1      Action            95
2         2      Action           130
3         3     Romance           150
4         4     Romance           110
```
```
   user_id user_genre user_length
0        0    unknown      unknown
1        1    unknown      unknown
```
**Observed interactions:**
```
   user_id  movie_id
0        0         0
1        0         1
2        1         1
3        1         2
4        1         3
5        1         4
```
Merge, group by size and calculation the shares produces:
```
user_id  movie_genre
0        Action         0.333333
         Romance        0.666667
1        Action         0.500000
         Romance        0.500000
```
So, as we can observe user 0 rather prefers Romance movies whereas user 1 is indifferent between genres. As a learning outcome user 0 should be recommended more Romance than Action movies, analogously for user 1.

These should be handed over to sparse_column_with_cat_prob to solve this problem.

Resources
[1] https://arxiv.org/abs/1606.07792
[2] https://www.tensorflow.org/tutorials/wide_and_deep"
9044,hang in google/protobuf/pyext/_message.so at exit,"This is TensorFlow 1.0.1 installed via pip.
It runs via an embedded CPython (libpython).

Sometimes (maybe 30% of my runs) it hangs in `Py_Finalize()`, and I see this backtrace:

```
/work/asr2/zeyer/sprint-executables/20160902.235443.fad8965.linux-x86_64-standard/Flf/flf-tool.linux-intel-standard(_ZN17AssertionsPrivate15safe_stackTraceEi+0x21)[0xc5b891]
/work/asr2/zeyer/sprint-executables/20160902.235443.fad8965.linux-x86_64-standard/Flf/flf-tool.linux-intel-standard[0xc5b8ef]
/u/zeyer/tools/glibc217/libpthread.so.0(+0x113d0)[0x2b6d89bad3d0]
/u/zeyer/tools/glibc217/libpthread.so.0(raise+0x29)[0x2b6d89bad2a9]
/u/zeyer/py-envs/py2-ubuntu16/local/lib/python2.7/site-packages/faulthandler.so(+0x3198)[0x2b6dc2372198]
/u/zeyer/tools/glibc217/libpthread.so.0(+0x113d0)[0x2b6d89bad3d0]
/u/zeyer/py-envs/py2-ubuntu16/local/lib/python2.7/site-packages/google/protobuf/pyext/_message.so(+0xaa943)[0x2b6dc14f0943]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(+0x160f6b)[0x2b6d8b23af6b]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(+0xc8f0e)[0x2b6d8b1a2f0e]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(+0x15d747)[0x2b6d8b237747]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(PyDict_SetItem+0x7b)[0x2b6d8b23becb]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(_PyModule_Clear+0xb5)[0x2b6d8b278565]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(PyImport_Cleanup+0x437)[0x2b6d8b2280e7]
/usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0(Py_Finalize+0xfe)[0x2b6d8b1fed9e]
/work/asr2/zeyer/sprint-executables/20160902.235443.fad8965.linux-x86_64-standard/Flf/flf-tool.linux-intel-standard(_ZN6Python11Initializer19AtExitUninitHandlerEv+0x2e)[0xff80de]
/u/zeyer/tools/glibc217/libc.so.6(+0x39fe8)[0x2b6d8bc39fe8]
/u/zeyer/tools/glibc217/libc.so.6(+0x3a035)[0x2b6d8bc3a035]
/u/zeyer/tools/glibc217/libc.so.6(__libc_start_main+0xf7)[0x2b6d8bc20837]
/work/asr2/zeyer/sprint-executables/20160902.235443.fad8965.linux-x86_64-standard/Flf/flf-tool.linux-intel-standard[0x7d6991]
```
or with GDB:
```
(gdb) bt full
#0  0x00002b6dc14f0943 in std::tr1::_Hashtable<google::protobuf::DescriptorPool const*, std::pair<google::protobuf::DescriptorPool const* const, google::protobuf::python::PyDescriptorPool*>, std::allocator<std::pair<google::protobuf::DescriptorPool const* const, google::protobuf::python::PyDescriptorPool*> >, std::_Select1st<std::pair<google::protobuf::DescriptorPool const* const, google::protobuf::python::PyDescriptorPool*> >, std::equal_to<google::protobuf::DescriptorPool const*>, google::protobuf::hash<google::protobuf::DescriptorPool const*>, std::tr1::__detail::_Mod_range_hashing, std::tr1::__detail::_Default_ranged_hash, std::tr1::__detail::_Prime_rehash_policy, false, false, true>::erase (
    __k=@0x7ffd1bbea740: 0x8269780, this=0x2b6dc1826e40 <google::protobuf::python::descriptor_pool_map>)
    at /opt/rh/devtoolset-2/root/usr/include/c++/4.8.2/tr1/hashtable.h:1041
        __slot = <optimized out>
        __saved_slot = <optimized out>
        __code = 136746880
        __n = 0
        __result = 0
#1  google::protobuf::python::cdescriptor_pool::Dealloc (self=0x2b6dc0d86880)
    at google/protobuf/pyext/descriptor_pool.cc:152
No locals.
#2  0x00002b6d8b23af6b in ?? () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#3  0x00002b6d8b1a2f0e in ?? () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#4  0x00002b6d8b237747 in ?? () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#5  0x00002b6d8b23becb in PyDict_SetItem () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#6  0x00002b6d8b278565 in _PyModule_Clear () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#7  0x00002b6d8b2280e7 in PyImport_Cleanup () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#8  0x00002b6d8b1fed9e in Py_Finalize () from /usr/lib/x86_64-linux-gnu/libpython2.7.so.1.0
No symbol table info available.
#9  0x0000000000ff80de in Python::Initializer::AtExitUninitHandler() ()
No symbol table info available.
#10 0x00002b6d8bc39fe8 in ?? () from /u/zeyer/tools/glibc217/libc.so.6
No symbol table info available.
#11 0x00002b6d8bc3a035 in exit () from /u/zeyer/tools/glibc217/libc.so.6
No symbol table info available.
#12 0x00002b6d8bc20837 in __libc_start_main () from /u/zeyer/tools/glibc217/libc.so.6
No symbol table info available.
#13 0x00000000007d6991 in _start ()
No symbol table info available.
```

I.e. it happens in `_PyModule_Clear`, and then inside `google/protobuf/pyext/_message.so`, that's why I think this is TF related.

In the case when it does not hang, I see this output:

```
Exception AttributeError: AttributeError(""'NoneType' object has no attribute 'raise_exception_on_not_ok_status'"",) in <bound method Session.__del__ of <tensorflow.python.client.session.Session object at 0x2afd625b12d0>> ignored
```

"
9042,Compiling a custom Op - Eigen including-loop,"### System Info.
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Yes
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*: latest
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*: 8.0/5.1
- *GPU Model and Memory*: Quadro k1100m
- *Exact command to reproduce*: trying to build

### The problem

I'm tyring to build the code in
https://github.com/davidstutz/tensorflow-cpp-op-example
for Windows. The Windows version of Tf does not install with the source code so I cloned the repo and added the path to CMake. I then executed CMake as described in
https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake
Yet the problem seems to be that the Eigen files don't do anything but re-including themselves. 

Were they not meant to be included? Am I using some wrong flags that result in those imports? Other ideas? suggestions?

Cheers,
"
9041,import error in ipython but not in python,"-*I have installed TensorFlow installed with virtualenv Linux(Ubuntu 16.10) with this codes*
```shell
 sudo apt-get install python-pip python-dev python-virtualenv
(tensorflow)$ pip install --upgrade tensorflow      # for Python 2.7
```
- *TensorFlow version 1.0.1
- *Command to reproduce the error after installing the module through pip*
```python
import tensorflow as tf
```

### I can import tensorflow module in python in my virtualenv but i can't import it in ipython

### Logs from ipython
```ipython
Python 2.7.12+ (default, Sep 17 2016, 12:08:02) 
Type ""copyright"", ""credits"" or ""license"" for more information.

IPython 5.3.0 -- An enhanced Interactive Python.
?         -> Introduction and overview of IPython's features.
%quickref -> Quick reference.
help      -> Python's own help system.
object?   -> Details about 'object', use 'object??' for extra details.

In [1]: import tensorflow as tf
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-1-41389fad42b5> in <module>()
----> 1 import tensorflow as tf

/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py in <module>()
     70 for some common reasons and solutions.  Include the entire stack trace
     71 above this error message when asking for help."""""" % traceback.format_exc()
---> 72   raise ImportError(msg)
     73 
     74 # Protocol buffers

ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 61, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
"
9039,Who can help me fix the problem of 'Net Crash' ?,"I am training a convolutional network, but suddenly that happened. I retry for 3 times, same scene happened. The network looks as if it crashed ! Who can help me fix this problem?
The scene looks like the following:
Epoch:100 training_accuracy:0.975 validation_accuracy:0.94242
Epoch:101 training_accuracy:0.075 validation_accuracy:0.103736
Epoch:102 training_accuracy:0.075 validation_accuracy:0.103736"
9038,Can't install tensorflow successfully,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No
- *TensorFlow installed from (source or binary)?*: binary
- *TensorFlow version*:1.0
- *Bazel version (if compiling from source)*: 
- *CUDA/cuDNN version*:NA
- *GPU Model and Memory*:HD5500 /  intrel core i5-5200
- *Exact command to reproduce*:  NA

### Describe the problem clearly
I try to install tensorflow with Anaconda in my win10 following the instructions on [install_windows]https://www.tensorflow.org/install/install_windows).  When i move to step4:
I type the code
 `pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl`

it fails and shows
`tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.`

How can I fix it?

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
"
9035,can't copy tensorflow/python/pywrap_tensorflow_internal.py,"```
porter@fattire:~/Projects/tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Thu Apr 6 17:10:48 PDT 2017 : === Using tmpdir: /tmp/tmp.kCYPVwxjU5
~/Projects/tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles ~/Projects/tensorflow
~/Projects/tensorflow
/tmp/tmp.kCYPVwxjU5 ~/Projects/tensorflow
Thu Apr 6 17:10:49 PDT 2017 : === Building wheel
error: can't copy 'tensorflow/python/pywrap_tensorflow_internal.py': doesn't exist or not a regular file
```

This happens after building tensorflow with bazel and running the binary build by bazel:

`bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg`

pywrap_tensorflow_internal.py doesn't exist in the source directories:

Tensorflow commit f8dce81
Bazel 0.4.5
CUDA release 8.0, V8.0.26, cuDNN 5105
GPU: NVIDIA Titan 6GB"
9034,Computing 2nd-order tf.gradients of tensors throws Exception when used with batch_norm,"### Describe the problem clearly

If the `updates_collections` of a `batch_norm` layer is set other than `tf.GraphKeys.UPDATE_OPS`, it is no longer possible to compute 2nd-order `tf.gradients` with respect to the weights of a `fully_connected` layer.

p.s. It is okay when `updates_collections` is set as `tf.GraphKeys.UPDATE_OPS`. I think `updates_collections` should not affect the ability to compute gradients?

### Environments

- Ubuntu 16.04 64bit
- Python 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) 
- [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
- tensorflow-gpu 1.0.1 installed from pip
- libcublas.so.8.0, libcudnn.so.5, libcufft.so.8.0,  libcuda.so.1, libcurand.so.8.0

### Source Code
```python
import tensorflow as tf

with tf.Session() as sess:
    X = tf.placeholder(tf.float32, [None, 2])
    is_training = tf.placeholder(tf.bool, [], name='is_training')

    outputs = tf.contrib.layers.fully_connected(inputs=X, num_outputs=1)
    outputs = tf.contrib.layers.batch_norm(
        inputs=outputs,
        is_training=is_training,
        updates_collections='bad_collections')
    # get gradients of X with respect to outputs values
    grads = tf.gradients(outputs, [
        X,
    ])[0]
    bad_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
    # get gradients of weights with respect to gradients of X
    bad_grads = tf.gradients(grads, bad_vars) # this line
```

## Logs
```
Traceback (most recent call last):
  File ""test.py"", line 18, in <module>
    bad_grads = tf.gradients(grads, bad_vars)
  File ""$HOME/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 474, in gradients
    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)
  File ""$HOME/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1303, in ZerosLikeOutsideLoop
    pred = op_ctxt.pred
AttributeError: 'NoneType' object has no attribute 'pred'
```"
9033,"Problem anaconda tensorflow Windows : Traceback <most recent call last>:   File ""<stdin>"", line 1, in <module> ModuleNotFoundError: No module named 'tensorflow'","Hi Guys!  [ # if you don't won't to read everything go down directly to # SOLUTION ]
here is the way how i fixed the problem of installing tensorflow on Windows. I will start 👍from the begining 👍 
1. I downloaded the Anaconda 4.3.1 For Windows with Python 3.6 version. 
2. Create a conda environment named tensorflow by invoking the following command:
C:> conda create -n tensorflow 

3. Activate the conda environment by issuing the following command:
C:> activate tensorflow
 (tensorflow)C:>  # Your prompt should change 

3. Issue the appropriate command to install TensorFlow inside your conda environment. To install the CPU-only version of TensorFlow, enter the following command:

(tensorflow)C:> pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl 

Message appear : can not install this wheel ......... [ i forgot the message, it's just couldn't find the point]
To install the GPU version of TensorFlow, enter the following command (on a single line):
(tensorflow)C:> pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl  

same message appear couldn't install 

so after that i wanted to write my first code 👍 
c>python
python version 3.6 .... (anaconda).............
>>> import tensorflow as tf
[it appears this Error : ]

Traceback <most recent call last>:
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow'

-----------------------------------------------------------------------------
SOLUTION
Fix The Problem :
https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.1-cp35-cp35m-win_amd64.whl

tensorflow-1.0.1 -cp35-cp35m-win_amd64.whl
tensorflow version 1.0.1 
-cp 35 : python version needed
win_amd64 : windows x64 

so the Anaconda 4.3.1 For Windows with Python 3.6 version so we need python 3.5 i downloaded it from other this web site cause anaconda has only the version 4.3.1 &  for python 2.7 : 
so this anaconda for python 3.5 : http://www.gurobi.com/downloads/get-anaconda 
then i followed the other steps & everything worked fine :), i hope everything will work with you 
"
9032,Documentation for tf.contrib.learn's learn_runner,"### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes
- *TensorFlow installed from (source or binary)?*: source
- *TensorFlow version*: 1.0.1
- *Bazel version (if compiling from source)*: 0.4.4
- *CUDA/cuDNN version*: 8.0, 5.1
- *GPU Model and Memory*: GTX 1080
- *Exact command to reproduce*: n/a

### Describe the problem clearly
This is a feature request to add documentation.

As recommended by the GCP Cloud ML Engine documentation (specifically the code used by [this tutorial](https://cloud.google.com/ml-engine/docs/how-tos/getting-started-training-prediction)), I am attempting to use `tf.contrib.learn`'s `learn_runner` interface for training. However, I cannot figure out how to configure the checkpoint saving behaviour. Normally, I would just post a Stackoverflow question, but I feel that this interface would benefit greatly from some official documentation, especially as it is being recommended by GCP.

The closest I could get to documentation on this specific issue is a [cryptic comment](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/run_config.py#L198).
"
9031,Move MNIST pointers to the CVDF mirror,"The [Common Visual Data Foundation](http://www.cvdfoundation.org/) now hosts a [mirror](https://github.com/cvdfoundation/mnist) of MNIST, which should alleviate the issue with occasional unavailability of the NYU website.
Many thanks to Serge Belongie and Yann LeCun for making it happen.
This bug tracks moving all references to MNIST in the TensorFlow codebase to the CVDF mirror.
"
9028,XLA with tower parallelization,"### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes
- *TensorFlow installed from (source or binary)?*: source
- *TensorFlow version*: 1.1rc1
- *Bazel version (if compiling from source)*: 0.4.5
- *CUDA/cuDNN version*: 8.0/5.1
- *GPU Model and Memory*: Titan X (12 GB)
- *Exact command to reproduce*: NA

### Describe the problem clearly

Using the automatic XLA option`sess_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1` causes an 8x performance improvement for my model (while training) when running with 1 GPU, amazing! I would like to parallelize this with a standard tower setup, without XLA this scales linearly (using 4 GPUs) but with XLA I see no difference. The timeline profiler (`chrome://tracing`) indicates that it just executes each tower one at the time on each GPU.

The example in [tensorflow/models/neural_gpu/neural_gpu.py](https://github.com/tensorflow/models/blob/master/neural_gpu/neural_gpu.py) indicates that one can use the manual `tf.contrib.compiler.jit.experimental_jit_scope` context creator, using this causes a x6 times performance peanality compared to not using XLA, but does scale with multiple GPUs.

I would like a feature where `experimental_jit_scope` works similarly to the automatic `sess_config` XLA option or the `sess_config` works with multiple GPUs.

### Source Code / Logs

My model is almost identical to the one in [https://github.com/buriburisuri/ByteNet](https://github.com/buriburisuri/ByteNet/blob/master/train.py).
"
9027,"Windows: tf.gfile methods (tf.gfile.Exists, tf.gfile.IsDirectory) are not Windows friendly","(Windows 10) in saver.py  train.save() takes a sess_path but on windows it returns an empty result.
I had to modify to the following (around line 1354)
    if not gfile.IsDirectory(os.path.dirname(os.path.abspath(save_path))):
similar issue found here:
http://stackoverflow.com/questions/7783308/os-path-dirname-file-returns-empty

this is via pip install --upgrade tensorflow-gpu"
9026,Unable to start the Tensor Flow,"Team,

I have installed anaconda on Redhat 6.8. I am following the installation steps of tensorflow from (https://www.tensorflow.org/install/install_linux#InstallingAnaconda). As the process of installation I am giving the command (conda create -n tensorflow). Because our cluster is protected I am unable to download the .conda directory. Can you please help me on this.

$ export PATH=/opt/app/anaconda2/python27/bin:$PATH
$ conda create -n tensorflow
Fetching package metadata ...

CondaHTTPError: HTTP None None for url https://repo.continuum.io/pkgs/free/linux-64/repodata.json.bz2
Elapsed: None

An HTTP error occurred when trying to retrieve this URL.
HTTP errors are often intermittent, and a simple retry will get you on your way.
ConnectionError(MaxRetryError(""HTTPSConnectionPool(host='repo.continuum.io', port=443): Max retries exceeded with url: /pkgs/free/linux-64/repodata.json.bz2 (Caused by ProtocolError('Connection aborted.', error(97, 'Address family not supported by protocol')))"",),)

$ cd /opt/app/anaconda2/python27/pkgs/tensorflow-0.10.0rc0-np111py27_0/
$ ll
total 12
drwxrwxr-x 2 python python 4096 Mar 31 11:20 bin
drwxrwxr-x 3 python python 4096 Dec 14 22:46 info
drwxrwxr-x 3 python python 4096 Dec 14 22:45 lib
$ pwd
 @shyamraj242
     
and also
Where can I find this URL in the tensor flow.

https://repo.continuum.io"
9025,Slim train_image_classifier or eval_image_classifier does not use any GPU,"When I am using regular tensorflow codes there are no problem of using the GPU. But when I use slim, both train_image_classifier.py and eval_image_classifier.py does not use GPU. In my computer, there are 16 CPUs and One GPU. All CPUs are used, but the GPU is not used at all.

My environment is:
OS: Windows 10
Tensorflow 1.10rc0
Python 3.5
Cuda 8.0
cuDNN: 8.0
GPU Model: Nvidia Quadro M4000, 8G Mem

I am just use the default settings in train_image_classifier.py and eval_image_classifier.py. I tested different models, and GPU is always not used. Is this a bug or did I set something wrong? Thank you."
9024,Tensorboard to Latex,"It would be nice if there was an export option in tensorboard that would export a latex-ready version of the visible graph - perhaps using SVG, Pgfplots or something similar. It's possible now to export CSV, and create the graphic by hand... but having it baked into tensorboard would be nice."
9023,how could I processing financial datas,"I want to deal with financial time series, but I do not have a clue"
9022,Softmax Regressions: Please don't talk about probabilities,"[This](https://www.tensorflow.org/get_started/mnist/beginners) tutorial talks about probabilities on softmax regression. This is a common mistake. A classifier talks about its confidence, but it is not a real probability of some kind of _distribution_. Please don't teach something wrong, only to make it some kind of simple.
_Confidence_ is simple enough."
9020,tf.image.crop_and_resize not working with uint8 images,"### Installation
- Custom code
- Pip install
- *TensorFlow version*: 1.0.1
- Python 2.7.9
- CPU based
- Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux

### Problem 

When reading images with opencv and then trying to use crop_and_resize on a tensor of uint8 data type, i get the following error : 

```
InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CropAndResize' with these attrs.  Registered devices: [CPU], Registered kernels:
  device='CPU'; T in [DT_FLOAT]

	 [[Node: generate_resized_crop = CropAndResize[T=DT_UINT8, extrapolation_value=0, method=""bilinear""](ExpandDims, stack, zeros_like, generate_resized_crop/crop_size)]]
```

However, when casting my tensor in float32, the program works perfectly.
But the [documentation](https://www.tensorflow.org/versions/master/api_docs/python/tf/image/crop_and_resize) specifies that it should work with uint8 datatype. 

### Source Code
```Python
import cv2
import tensorflow as tf

frame=cv2.imread('path to img.jpg',-1)
raw_image=tf.placeholder(dtype=tf.uint8, shape=frame.shape, name='input_image')

def img2batch(input_image):
    raw_sample_tensor_4d=tf.expand_dims(input_image, 0)
    patches_top=[0,0.5]
    patches_bottom =[0.25,0.75]
    boxes=tf.stack([patches_top, patches_top, patches_bottom, patches_bottom], axis=1)
    crops=tf.image.crop_and_resize(raw_sample_tensor_4d, boxes, box_ind=tf.zeros_like(patches_top, dtype=tf.int32), crop_size=[200,200], method=""bilinear"", extrapolation_value=None, name=""generate_resized_crop"")
    return crops

with tf.Session() as sess:
    myBatchedImage=sess.run(img2batch(raw_image), feed_dict={raw_image:frame})
```
Problem solved with : 
```Python
crops=tf.image.crop_and_resize(tf.cast(raw_sample_tensor_4d, dtype=tf.float32), boxes, box_ind=tf.zeros_like(patches_top, dtype=tf.int32), crop_size=[200,200], method=""bilinear"", extrapolation_value=None, name=""generate_resized_crop"")
```"
9017,re2 repo: no such file when running download_dependencies.sh,"Hi 

When running the download_dependencies.sh script it fail at downloading the repo at re2. 
sed: can't read : No such file or directory
I cant find any other mention of this. I've attached the buildlog. Please advise.

Thanks

Chris"
9016,Problem compiling for android,"Compiling for android example. Not sure if its a bug 
After Trying for  tensorflow/contrib/makefile/compile_android_protobuf.sh -c

checking whether to enable maintainer-specific portions of Makefiles... yes
checking build system type... x86_64-pc-linux-gnu
checking host system type... arm-unknown-linux-androideabi
checking target system type... arm-unknown-linux-androideabi
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for arm-linux-androideabi-strip... arm-linux-androideabi-strip
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether UID '1000' is supported by ustar format... yes
checking whether GID '1000' is supported by ustar format... yes
checking how to create a ustar tar archive... gnutar
checking for arm-linux-androideabi-gcc...  arm-linux-androideabi-gcc --sysroot ../android-ndk-r14b//platforms/android-21/arch-arm
checking whether the C compiler works... no
configure: error: in `/home/vishal/Downloads/tensorflowandroid/tensorflow/tensorflow/contrib/makefile/downloads/protobuf':
configure: error: C compiler cannot create executables
See `config.log' for more details

Config.log is attached
[config.txt](https://github.com/tensorflow/tensorflow/files/902101/config.txt)

Can someone look into it



"
9015,"build tensorflow failed,may be the problem of compiler?","### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
- *TensorFlow installed from source *:
- *TensorFlow version*:1.0.1
- *Bazel version :0.4.5
- *CUDA/cuDNN version*:8.0/5.1
- *GPU Model and Memory*:GeForce 920M total memory 2048 MB
### Describe the problem clearly
hi ,I am attempting to build the tensorflow ,but it can't work ,it seems like relates to compiler of jit.
but why can't i see the TF_CUDA_VERSION='' and TF_CUDNN_VERSION='' ? I did install CUDA and CUDNN and I really add path in .bashrc .what's wrong with it? what can I do ?
### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
`bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures
WARNING: /home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING: /home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/EI/tensorflow/tensorflow/compiler/jit/BUILD:96:1: C++ compilation of rule '//tensorflow/compiler/jit:common' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/EI/.cache/bazel/_bazel_EI/2e0782785985dd9cb1b5d0cb62ad2606/execroot/tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    LD_LIBRARY_PATH='/usr/local/cuda-8.0/lib64:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin:/snap/bin:/usr/local/cuda/bin:/usr/local/cuda/lib64' \
    PATH='/usr/local/cuda-8.0/bin:/home/EI/anaconda3/bin:/home/EI/anaconda2/bin:/home/EI/bin:/home/EI/.local/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin:/snap/bin:/usr/local/cuda/bin:JAVA_HOME/bin:/usr/lib/Java/jdk1.8.0_121/jre/bin:/home/EI/anaconda3/bin:/home/EI/anaconda2/bin:/usr/local/cuda/bin:/home/EI/bin:JAVA_HOME/bin:/usr/lib/Java/jdk1.8.0_121/jre/bin' \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \
    TF_CUDA_VERSION='' \
    TF_CUDNN_VERSION='' \
    TF_NEED_CUDA=1 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/compiler/jit/_objs/common/tensorflow/compiler/jit/defs.pic.d '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/compiler/jit/_objs/common/tensorflow/compiler/jit/defs.pic.o' -fPIC -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c tensorflow/compiler/jit/defs.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/compiler/jit/_objs/common/tensorflow/compiler/jit/defs.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error trying to exec 'cc1plus': execvp: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 4.918s, Critical Path: 3.31s `

"
9014,Freshly built tfcompile core dumps,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: No
- *TensorFlow installed from (source or binary)?*: Source
- *TensorFlow version*: docker image: ""tensorflow/tensorflow:nightly-devel"" - `git describe` = 0.6.0-16017-ga9b7946 (aka: `docker-pullable://tensorflow/tensorflow@sha256:5b568f7dd9890bb0b86101bb27779c539f608724c7d4ecf4fdfbbab289bc29de`)
- *Bazel version (if compiling from source)*: Build label: 0.4.5
- *CUDA/cuDNN version*: - 
- *GPU Model and Memory*: - 
- *Exact command to reproduce*: cd /tensorflow; bazel build tensorflow/compiler/aot:tfcompile ; bazel-bin/tensorflow/compiler/aot/tfcompile 

### Describe the problem clearly
I'm trying to use tfcompile, when I build it in a Pod on my kubernetes cluster, the resulting binary exits with `Aborted (core dumped)` after displaying the help message.

### Source Code / Logs
I create a pod like this:
```
apiVersion: v1
kind: Pod
metadata:
  labels:
    name: tfcompile
  name: tfcompile
spec:
  containers:
  - args:
    - sh
    - -c
    - cd /tensorflow; bazel build tensorflow/compiler/aot:tfcompile ; sleep 864000
    image: tensorflow/tensorflow:nightly-devel
    name: tfcompile
    resources:
      limits:
        cpu: ""1""
        memory: 16Gi
      requests:
        cpu: ""1""
        memory: 16Gi
```

and then when the build is finished, I execute into the pod and try the resulting binary: `bazel-bin/tensorflow/compiler/aot/tfcompile`

full output:

```
root@tfcompile-1266760932-s2dht:/tensorflow# bazel-bin/tensorflow/compiler/aot/tfcompile                                         
2017-04-06 08:08:02.798285: F tensorflow/compiler/aot/tfcompile_main.cc:136] Check failed: argc == 1 && !flags.config.empty() && (flags.dump_fetch_nodes || (!flags.graph.empty() && !flags.entry_point.empty())) 
tfcompile performs ahead-of-time compilation of a TensorFlow graph,
resulting in an object file compiled for your target architecture, and a
header file that gives access to the functionality in the object file.
A typical invocation looks like this:

   $ tfcompile --graph=mygraph.pb --config=myfile.pbtxt

usage: bazel-bin/tensorflow/compiler/aot/tfcompile
Flags:
	--graph=""""                       	string	Input GraphDef file.  If the file ends in '.pbtxt' it is expected to be in the human-readable proto text format, otherwise it is expected to be in the proto binary format.
	--config=""""                      	string	Input file containing Config proto.  If the file ends in '.pbtxt' it is expected to be in the human-readable proto text format, otherwise it is expected to be in the proto binary format.
	--dump_fetch_nodes=false         	bool	If set, only flags related to fetches are processed, and the resulting fetch nodes will be dumped to stdout in a comma-separated list.  Typically used to format arguments for other tools, e.g. freeze_graph.
	--debug_dir=""""                   	string	Specifies a directory to dump debugging information, including rewritten graphs and the XLA HLO module.
	--target_triple=""x86_64-pc-linux""	string	Target platform, similar to the clang -target flag.  The general format is <arch><sub>-<vendor>-<sys>-<abi>.  http://clang.llvm.org/docs/CrossCompilation.html#target-triple.
	--target_cpu=""""                  	string	Target cpu, similar to the clang -mcpu flag.  http://clang.llvm.org/docs/CrossCompilation.html#cpu-fpu-abi
	--target_features=""""             	string	Target features, e.g. +avx2, +neon, etc.
	--entry_point=""""                 	string	Name of the generated function.  If multiple generated object files will be linked into the same binary, each will need a unique entry point.
	--cpp_class=""""                   	string	Name of the generated C++ class, wrapping the generated function.  The syntax of this flag is [[<optional_namespace>::],...]<class_name>.  This mirrors the C++ syntax for referring to a class, where multiple namespaces may precede the class name, separated by double-colons.  The class will be generated in the given namespace(s), or if no namespaces are given, within the global namespace.
	--out_object=""out.o""             	string	Output object file name.
	--out_header=""out.h""             	string	Output header file name.
	--xla_debug_cpu_dump_ir=""""       	string	Dump IR, before optimizations to a path
	--xla_cpu_llvm_opt_level=2       	int32	The LLVM optimization level for the CPU XLA backend. Valid range is from 0 to 3 where 0 means no optimizations.
	--xla_cpu_llvm_cl_opts=""""        	string	Comma-separated list of command line options to pass to LLVM.
	--xla_cpu_embed_ir=false         	bool	Embed the LLVM IR module string in the resultant CpuExecutable.
	--xla_cpu_parallel=false         	bool	Use the multi-threaded CPU backend.
	--xla_cpu_use_eigen=true         	bool	Use Eigen for matrix multiply on the CPU platform. This is a useful hack for performance comparisons against XLA's implementation.
	--xla_cpu_multi_thread_eigen=true	bool	When generating calls to Eigen for matmul and conv, should single or multi-threaded eigen be used? Only used when --xla_cpu_use_eigen is true.

Aborted (core dumped)
root@tfcompile-1266760932-s2dht:/tensorflow#
```

I've actually been trying this sporadically with different nightly/release builds for the past few weeks, hoping that this would be resolved, but it still does not work, so here is my GH issue ;) "
9012,BiasGradOp mistakenly put on CPU,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*:
custom code
- *TensorFlow installed from (source or binary)?*: from binary
- *TensorFlow version*: 1.0.1
- *Bazel version (if compiling from source)*: N/A
- *CUDA/cuDNN version*: CUDA 8.0, cuDNN v5.1
- *GPU Model and Memory*: GTX 1080, 8GB
- *Exact command to reproduce*:
Here is a sample script in Python that can reproduce the problem:

```import numpy as np
import tensorflow as tf
import numpy as np
ly = tf.layers


def lrelu(x, leak=0.2, name=""lrelu""):
    with tf.variable_scope(name):
        f1 = 0.5 * (1 + leak)
        f2 = 0.5 * (1 - leak)
        return f1 * x + f2 * tf.abs(x)
        # return tf.maximum(leak*x, x)

x = np.ones([16, 3, 32, 32], dtype=np.float32)

with tf.device('/gpu:0'):
    input = tf.placeholder(tf.float32, shape=[16, 3, 32, 32])
    output = ly.conv2d(input, 3, kernel_size=1, data_format='channels_first',
                       strides=1, activation=lrelu)
    loss = tf.gradients(input - output, input)[0]
    optimizer = tf.train.AdamOptimizer()
    gradients = optimizer.compute_gradients(loss)
    grad_op = optimizer.apply_gradients(gradients)


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    out = sess.run(grad_op, feed_dict={input: x})
```

### Describe the problem clearly
I am on Ubuntu 16.04. While running the above script, despite the device has been specified to be GPU, tensorflow still try to do the `BiasGradOp` on CPU and will cause an error because of the data format. If I change the implementation of `lrelu()` to `return tf.maximum(leak*x, x)` then the problem goes away.

### Source Code / Logs
Here is the output from console:
```
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.797
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.21GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.
	 [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=""NCHW"", _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]
E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC.
	 [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format=""NCHW"", _device=""/job:localhost/replica:0/task:0/gpu:0""](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]
```
"
9011,"compilation from sources, is broken too","```
# bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
.
INFO: Found 1 target...
[224 / 2,346] Compiling external/pcre/pcre_byte_order.c [for host]

Server terminated abruptly (error code: 14, error message: '', log file: '/root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/server/jvm.out')

# cat /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/server/jvm.out
#
```

Ubuntu Xenial, all times.
"
9010,I hope pre-1.1 `tf.contrib.seq2seq` is kept somewhere for legacy support,"I am disappointed by the fact that pre-1.1 `seq2seq` has been completely scraped in the latest build and has been replaced by some object-oriented redesign that seems half-finished right now. We have tonnes of codes that are based on pre-1.1 `seq2seq` interface, so this change would completely break our code base. But we can't just stick to old versions because there are some improvements in other areas that we desperately need also. Why not keep the original design somewhere for legacy (`tf.contrib.legacy_seq2seq` already exists, so need to think of another name), so those who heavily rely on the module do not have to re-implement the entire codebase? Since 1.1 is still far away from being officially released, I hope a right decision is made."
9009,Wrap python code into a tf operation,"
I have described my issue in the keras group [issue 6163](https://github.com/fchollet/keras/issues/6163) but was re-directed here. I am trying to wrap a non-tf function (actually a class) into a tf operation to use in a custom keras layer. When using py_func it always returns  ""ValueError: None values not supported."" Is it generally possible to wrap an arbitrary piece of python code, which takes a list of numpy arrays as input and delivers a list of numpy arrays , into a tf op?


- *I have written custom code.*
- *TensorFlow installed from binary.*
- *TensorFlow version is 1.0.1*
- *No CUDA/cuDNN used.*
- *Currently no GPU.*



"
9008,Instalation is broken,"```
# pip install tensorflow
Collecting tensorflow
  Downloading tensorflow-1.0.1-cp27-cp27mu-manylinux1_x86_64.whl (44.1MB)
    99% |████████████████████████████████| 44.1MB 28.6MB/s eta 0:00:01Killed
```

Ubuntu Xenial. all times."
9007,Takes more than 2min to load a small model.,"NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.

### You must complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: Y
- *TensorFlow installed from (source or binary)?*:  Installing with native pip
- *TensorFlow version*:   libcurand.so.8.0 locally 1.0.1
- *Bazel version (if compiling from source)*:
- *CUDA/cuDNN version*:
- *GPU Model and Memory*:
- *Exact command to reproduce*:

### Describe the problem clearly
After shows following, the program waiting for more than 2min to load a small model.  

I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
 
And at the end it shows like this:

I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
model loaded!


### Source Code / Logs
`
# If you have already created the dataset:
if os.path.exists('train_data.npy'):
    train_data = np.load('train_data.npy')
else:
    train_data = create_train_data()

if os.path.exists('test_data.npy'):
    test_data = np.load('test_data.npy')
else:
    test_data = process_test_data()

# Convlotion model----------------
convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')
# ----------------
convnet = conv_2d(convnet, 32, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)
# ----------------
convnet = conv_2d(convnet, 64, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)
# ----------------
convnet = conv_2d(convnet, 32, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)
# ----------------
convnet = conv_2d(convnet, 64, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)
# ----------------
convnet = conv_2d(convnet, 32, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)
# ----------------
convnet = conv_2d(convnet, 64, 5, activation='relu')
convnet = max_pool_2d(convnet, 5)
# ----------------
convnet = fully_connected(convnet, 1024, activation='relu')
convnet = dropout(convnet, 0.8)
# ----------------
convnet = fully_connected(convnet, 512, activation='relu')
convnet = dropout(convnet, 0.6)
# ----------------
convnet = fully_connected(convnet, 2, activation='softmax')
convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')
# ----------------
model = tflearn.DNN(convnet, tensorboard_dir='log')

if os.path.exists('{}.meta'.format(MODEL_NAME)):
    model.load(MODEL_NAME)
    print('model loaded!')
else:
    print ""Nothing loaded""

train = train_data[:-500]
test = train_data[-500:]
# print train

`
"
9006,wer is different on test ,"
When I use the distributed tensorflow and keras combined training, each epoch will be saved on the worker0 model for the keras model, but on the validation set, before saving the model, its wer is 0.17, when saved as keras model, I use a separate program to load keras model, using the same proof set, why its wer becomes 0.22"
9003,set_random_seed bug,"python2, TF 1.0.0
python3 TF 1.0.1
CUDA8, cudnn 5ish
gtx 980ti

program A:
```
import tensorflow as tf

tf.set_random_seed(0)
biases = tf.Variable(tf.random_normal([1], seed=0))

sess = tf.Session()
sess.run(tf.global_variables_initializer())
print(sess.run(biases))

```
program B:
```
import tensorflow as tf

biases = tf.Variable(tf.random_normal([1], seed=0))
tf.set_random_seed(0)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
print(sess.run(biases))
```

### Program B outputs the same value at every run, program A outputs different values at each run. I  hope this is not expected behaviour.

### logs for python2 and TF 1.0.0
program A logs:
```
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.2405
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 4.92GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
[-1.33033025]
```

program B logs:
```
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.2405
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 4.92GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
[-0.39915758]
```
"
9002,"Unable to compile TF, CUBLAS_GEMM_ALGO? not declared in scope","- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: no
- *TensorFlow installed from (source or binary)?*: source
- *TensorFlow version*: 1.1.0rc1 (master as of April 5, 2017)
- *Bazel version (if compiling from source)*: 0.4.5
- *CUDA/cuDNN version*: 8/5.1
- *GPU Model and Memory*: Titan X (PASCAL) 12GB
- *Exact command to reproduce*: `bazel build -c opt --copt=-mavx --copt=-mfma --copt=-mfpmath=both --config=cuda -k //tensorflow/tools/pip_package:build_pip_package`

Here's the compile config:

```txt
$ ./configure 
Please specify the location of python. [Default is /path/to/anaconda2/bin/python]: 
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 
Do you wish to use jemalloc as the malloc implementation? [Y/n] n
jemalloc disabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] 
No XLA support will be enabled for TensorFlow
Found possible Python library paths:
/path/to/python/site-packages
Please input the desired Python library path to use.  Default is [/path/to/python/site-packages]
/path/to/python/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] 
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N] 
nvcc will be used as CUDA compiler
Please specify which gcc should be used by nvcc as the host compiler. [Default is /opt/gcc/4.9.2/bin/gcc]: 
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 
Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /opt/cuda-8.0
Please specify the cuDNN version you want to use. [Leave empty to use system default]: 
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /opt/cuda-8.0]: /opt/cudnn-8.0
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.5,5.2,6.1
Warning: ignoring LD_PRELOAD in environment.
............
INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.
Configuration finished

```

### Describe the problem clearly
CentOS 6.6, compiling using instructions from https://github.com/tensorflow/tensorflow/issues/110#issuecomment-274586644 gives an error as mentioned later.
I have been able to compile TF upto 1.0.1 successfully on the same machine.
Also, same issue was mentioned in https://github.com/tensorflow/tensorflow/issues/8790#issuecomment-290094265, but I'm not sure if the OP opened an issue 

### Source Code / Logs

```txt
ERROR: /path/to/tensorflow/stream_executor/BUILD:39:1: Couldn't build file tensorflow/stream_executor/_objs/cuda_platform/tensorflow/stream_executor/cuda/cuda_blas.pic.o: C++ compila
tion of rule '//tensorflow/stream_executor:cuda_platform' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D
_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 118 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/stream_executor/cuda/cuda_blas.cc: In member function 'virtual bool perftools::gputools::cuda::CUDABlas::GetBlasGemmAlgorithms(std::vector<long long int>*)':
tensorflow/stream_executor/cuda/cuda_blas.cc:1916:9: error: 'CUBLAS_GEMM_ALGO5' was not declared in this scope
         CUBLAS_GEMM_ALGO5, CUBLAS_GEMM_ALGO6, CUBLAS_GEMM_ALGO7}) {
         ^
tensorflow/stream_executor/cuda/cuda_blas.cc:1916:28: error: 'CUBLAS_GEMM_ALGO6' was not declared in this scope
         CUBLAS_GEMM_ALGO5, CUBLAS_GEMM_ALGO6, CUBLAS_GEMM_ALGO7}) {
                            ^
tensorflow/stream_executor/cuda/cuda_blas.cc:1916:47: error: 'CUBLAS_GEMM_ALGO7' was not declared in this scope
         CUBLAS_GEMM_ALGO5, CUBLAS_GEMM_ALGO6, CUBLAS_GEMM_ALGO7}) {
                                               ^
tensorflow/stream_executor/cuda/cuda_blas.cc:1916:64: error: unable to deduce 'std::initializer_list<_Tp>&&' from '{CUBLAS_GEMM_DFALT, CUBLAS_GEMM_ALGO0, CUBLAS_GEMM_ALGO1, CUBLAS_GEMM_ALGO2, CUBLAS_GEMM_ALGO3, CUBLAS_GEMM_ALGO4, <express
ion error>, <expression error>, <expression error>}'
         CUBLAS_GEMM_ALGO5, CUBLAS_GEMM_ALGO6, CUBLAS_GEMM_ALGO7}) {
```"
8994,Reload Button in Tensorboard 1.1rc1 Resets Chart Scales,"In tensorboard 1.1rc1, hitting the ""reload button"",  ![image](https://cloud.githubusercontent.com/assets/51059/24721828/7f66e63a-1a0f-11e7-9942-15d4609e0e46.png), causes the scaling on the charts to reset. That was not the case in 1.0.1.

For example if I zoom in here:
![image](https://cloud.githubusercontent.com/assets/51059/24721857/9772cd7a-1a0f-11e7-8e4a-3f6535df7edb.png)
to:
![image](https://cloud.githubusercontent.com/assets/51059/24721867/9cedb1a2-1a0f-11e7-9a0d-24d57648d242.png)
this zoom is lost."
8993,"""Split on underscores"" is Missing in Tensorboard 1.1rc1","Old Tensorboard:
![image](https://cloud.githubusercontent.com/assets/51059/24721612/dff607b6-1a0e-11e7-9023-314a8e50661c.png)

New Tensorboard:
![image](https://cloud.githubusercontent.com/assets/51059/24721635/ed11cf0c-1a0e-11e7-969a-ad945d587eac.png)

Note that ""Split on underscores"" appears missing. I see no issues, etc related to the removal of this feature."
8986,"Inception v1, v2 - ValueError: Can not squeeze dim[1], expected a dimension of 1, got 2 for 'InceptionV2/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes: [1,2,2,1000].","Hello,

I'm trying to run a few different inception models with their checkpoints from the pretrained models table [here](https://github.com/tensorflow/models/tree/master/slim). I've managed to get v3, v4, and resnet v2 working. v1 and v2 however I'm getting the issue above. I'm using the latest tensorflow and pulled the latest off the repo. Below is the code I use to load the model.

```
checkpoint_file = os.getcwd() + '\inception_v2.ckpt'
#Load the model
sess = tf.Session()
arg_scope = inception_v2_arg_scope()

with slim.arg_scope(arg_scope):
      logits, end_points = inception_v2(scaled_input_tensor, is_training=False)
saver = tf.train.Saver()
saver.restore(sess, checkpoint_file)
```"
8985,ValueError while restoring pre-trained SyntaxNet language parser,"- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: yes, but closely following [this](https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph) example.
- *TensorFlow installed from (source or binary)?*: binary.  `tf.__version__` == `1.0.0`
- *TensorFlow version*: 1.0.0 (installed with `pip install tensorflow-gpu`
- *CUDA/cuDNN version*: cuda 8/ cudnn 5.1.10
- *GPU Model and Memory*: GeForce GTX 1080 (8 GB), nvidia driver 367.57
- *Exact command to reproduce*:

### Describe the problem clearly
I'm attempting to play with the ParseySaurus pre-trained ConLL17 models from [here](https://github.com/tensorflow/models/blob/master/syntaxnet/g3doc/conll2017/README.md).   Attempting to reconstitute them from a `*.meta` file results in an error.
### Source Code / Logs
prep: 
```
wget https://drive.google.com/file/d/0BxpbZGYVZsEeSFdrUnBNMUp1YzQ/view?usp=sharing
tar xzf conll17.tar.gz
```

ipython transcript follows
```python
import tensorflow as tf
%cd conll17/English
with tf.Session() as sess:
    saver = tf.train.import_meta_graph('segmenter/checkpoint.meta')
    saver.restore(sess,'segmenter/checkpoint.data-00000-of-00001')
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)                  
---------------------------------------------------------------------------                                                   
ValueError                                Traceback (most recent call last)           
<ipython-input-15-325bf8959c4e> in <module>()                 
      1 with tf.Session() as sess:                            
----> 2     saver = tf.train.import_meta_graph('segmenter/checkpoint.meta')                                                   
      3     saver.restore(sess,'segmenter/checkpoint.data-00000-of-00001')                                                    
      4       

/home/gvoysey/.local/share/virtualenvs/DeepSpeech/local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)    
   1575                                       clear_devices=clear_devices,                    
   1576                                       import_scope=import_scope,                      
-> 1577                                       **kwargs)       
   1578   if meta_graph_def.HasField(""saver_def""):            
   1579     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)                                               

/home/gvoysey/.local/share/virtualenvs/DeepSpeech/local/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name)                                                      
    496     importer.import_graph_def(                        
    497         input_graph_def, name=(import_scope or """"), input_map=input_map,                                                              
--> 498         producer_op_list=producer_op_list)            
    499       
    500     # Restores all the other collections.             

/home/gvoysey/.local/share/virtualenvs/DeepSpeech/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)                    
    257       # Set any default attr values that aren't present.                                                              
    258       if node.op not in op_dict:                      
--> 259         raise ValueError('No op named %s in defined operations.' % node.op)                                           
    260       op_def = op_dict[node.op]                       
    261       for attr_def in op_def.attr:                    

ValueError: No op named GetSession in defined operations.        
```
"
8983,Tensorboard not showing embeddings,"I am trying to create embeddings visualization from a pretrained network called FaceNet although nothing shows up when I open it in Tensorboard. Here is my source code
```
import tensorflow as tf
import os
from tensorflow.contrib.tensorboard.plugins import projector

MODEL_DIR = ""20170216-091149""
meta_file, ckpt_file = facenet.get_model_filenames(MODEL_DIR)
with tf.Graph().as_default():
    with tf.Session().as_default() as sess: 
        # Importing the graph
        model_dir_exp = os.path.expanduser(MODEL_DIR)
        print(model_dir_exp)
        saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file))
        
        # Restoring and retrieving needed layers
        saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))
        images_placeholder = tf.get_default_graph().get_tensor_by_name(""input:0"")
        embeddings = tf.get_default_graph().get_tensor_by_name(""embeddings:0"")
        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(""phase_train:0"") 
        
        # Create variables needed for Tensorboard
        embedding = tf.Variable(tf.zeros([33, 128]), name = ""embedding"") 
        assignment = embedding.assign(embeddings)
        
        # Create writer class
        writer = tf.summary.FileWriter(os.path.join(MODEL_DIR, ""model""))
        writer.add_graph(sess.graph)
        
        # Setup the embeddings
        config = projector.ProjectorConfig()
        embedding_config = config.embeddings.add()
        embedding_config.tensor_name = embedding.name
        embedding_config.metadata_path = os.path.join(os.getcwd(), MODEL_DIR, 'labels.tsv')
        embedding_config.sprite.image_path = os.path.join(os.getcwd(), MODEL_DIR,'sprite.png')
        embedding_config.sprite.single_image_dim.extend([160, 160])
        projector.visualize_embeddings(writer, config)
        
        # Create the embeddings
        sess.run(assignment, feed_dict = {images_placeholder : face_images, phase_train_placeholder : False})
```

I have read the FAQs and this is what I got when I ran `tensorboard --logdir 20170216-091149/ --debug`

```
INFO:tensorflow:TensorBoard is in debug mode.
INFO:tensorflow:Starting TensorBoard in directory /Users/kevinlu/Documents/Facial-Recognition/facial_recognition
INFO:tensorflow:TensorBoard path_to_run is: {'/Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149': None}
INFO:tensorflow:Event Multiplexer initializing.
INFO:tensorflow:Event Multiplexer done initializing
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149
INFO:tensorflow:Adding events from directory /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149/model
INFO:tensorflow:Constructing EventAccumulator for /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149/model
INFO:tensorflow:Done with AddRunsFromDirectory: /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
INFO:tensorflow:Beginning EventMultiplexer.Reload()
DEBUG:tensorflow:Opening a record reader pointing at /Users/kevinlu/Documents/Facial-Recognition/facial_recognition/20170216-091149/model/
```

The TensorBoard path_to_run seems correct as that is where I am storing my checkpoint files, the metadata file and sprite image.

Then I ran`find 20170216-091149/ | grep tfevents` and I got 

```20170216-091149/model/events.out.tfevents.1491408129.Kevins-MacBook-Pro.local``` 


Note the `model` folder contains the `tfevents` file and the `projector_config.pbtxt` file
So my data also exists. The last thing I did as per the troubleshooting was: 
`tensorboard --inspect --logdir=20170216-091149/` and I got this as the output


```
======================================================================
Processing event files... (this can take a few minutes)
======================================================================

Found event files in:
20170216-091149/model

These tags are in 20170216-091149/model:
audio -
histograms -
images -
scalars -
======================================================================

Event statistics for 20170216-091149/model:
audio -
graph
   first_step           0
   last_step            0
   max_step             0
   min_step             0
   num_steps            1
   outoforder_steps     []
histograms -
images -
scalars -
sessionlog:checkpoint -
sessionlog:start -
sessionlog:stop -
======================================================================
```

The code I used is exactly the same as the Hands On Tensorboard video code, and when I ran the debug commands as recommended by the FAQ the output of the MNIST tutorial is the same as above."
8982,log_device_placement not working in some cases,"Hey guys, thank you for working on TensorFlow so hard!

I think I found a small bug, but it might be so that I just don't understand ConfigProto correctly.
So:

```
config = tf.ConfigProto(log_device_placement=True)
server = tf.train.Server.create_local_server()
with tf.Session(server.target, config=config):
```

outputs the device placement correctly, but

```
config = tf.ConfigProto(log_device_placement=True)
server = tf.train.Server.create_local_server(config=config)
with tf.Session(server.target):
```

doesn't (at all).

While this is not groundbreaking, just wanted to let you know.

Cheers, Kris"
8979,"Compilation Error when building tensorflow with opencl, with computecpp(SYCL)","### Environment info
Operating System: Ubuntu 16.10 64bit
Hardware: i7-2600k + R9 290X
computecpp 0.1.3
tensorflow branch r1.1
python 3.5

git rev-parse HEAD
```
36a47f2bdcbbdf302da6f292ceee366ebd9640d2

```
Bazel Version
```
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778

```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Compilation with
```
bazel build -c opt --config=sycl //tensorflow/tools/pip_package:build_pip_package
```
results in this Error

```
ERROR: /home/flo/Workspace/tensorflow/tensorflow/contrib/tensor_forest/BUILD:97:1: C++ compilation of rule '//tensorflow/contrib/tensor_forest:python/ops/_tensor_forest_ops.so' failed: computecpp failed: error executing command external/local_config_sycl/crosstool/computecpp -Wall -msse3 -g0 -O2 -DNDEBUG '-std=c++11' -MD -MF ... (remaining 56 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:
In file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:471:67: error: pack expansion contains parameter packs '_Elements' and '_UElements' that have different lengths (1 vs. 3)
      return __and_<is_constructible<_Elements, const _UElements&>...>::value;
                                     ~~~~~~~~~        ~~~~~~~~~~  ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:664:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_ConstructibleTuple<int, int, int>' requested here```
                    _ConstructibleTuple<_UElements...>()
                    ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:670:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]
        constexpr tuple(const tuple<_UElements...>& __in)
                  ^~~~~
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]
    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }
                                   ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here
                                      std::forward_as_tuple(std::move(__k)),
                                           ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here
      { return _M_h[std::move(__k)]; }
               ^
tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here
          split_delta[make_tuple(accumulator, split, column)] += w;
                     ^
In file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:
In file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:477:65: error: pack expansion contains parameter packs '_UElements' and '_Elements' that have different lengths (3 vs. 1)
      return __and_<is_convertible<const _UElements&, _Elements>...>::value;
                                         ~~~~~~~~~~   ~~~~~~~~~ ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:666:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_ImplicitlyConvertibleTuple<int, int, int>' requested here
                    _ImplicitlyConvertibleTuple<_UElements...>()
                    ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:670:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]
        constexpr tuple(const tuple<_UElements...>& __in)
                  ^~~~~
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]
    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }
                                   ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here
                                      std::forward_as_tuple(std::move(__k)),
                                           ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here
      { return _M_h[std::move(__k)]; }
               ^
tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here
          split_delta[make_tuple(accumulator, split, column)] += w;
                     ^
In file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:
In file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:483:62: error: pack expansion contains parameter packs '_Elements' and '_UElements' that have different lengths (1 vs. 3)
      return __and_<is_constructible<_Elements, _UElements&&>...>::value;
                                     ~~~~~~~~~  ~~~~~~~~~~   ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:688:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_MoveConstructibleTuple<int, int, int>' requested here
                    _MoveConstructibleTuple<_UElements...>()
                    ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:694:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]
        constexpr tuple(tuple<_UElements...>&& __in)
                  ^~~~~
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]
    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }
                                   ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here
                                      std::forward_as_tuple(std::move(__k)),
                                           ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here
      { return _M_h[std::move(__k)]; }
               ^
tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here
          split_delta[make_tuple(accumulator, split, column)] += w;
                     ^
In file included from tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:20:
In file included from /usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/unordered_map:41:
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:489:60: error: pack expansion contains parameter packs '_UElements' and '_Elements' that have different lengths (3 vs. 1)
      return __and_<is_convertible<_UElements&&, _Elements>...>::value;
                                   ~~~~~~~~~~    ~~~~~~~~~ ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:690:21: note: in instantiation of function template specialization 'std::_TC<true, std::tuple<int, int, int> &&>::_ImplicitlyMoveConvertibleTuple<int, int, int>' requested here
                    _ImplicitlyMoveConvertibleTuple<_UElements...>()
                    ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:694:19: note: while substituting prior template arguments into non-type template parameter [with _UElements = <int, int, int>, _Dummy = void]
        constexpr tuple(tuple<_UElements...>&& __in)
                  ^~~~~
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/tuple:1400:36: note: while substituting deduced template arguments into function template 'tuple' [with _UElements = <int, int, int>, _Dummy = (no value), $2 = (no value)]
    { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }
                                   ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/hashtable_policy.h:621:16: note: in instantiation of function template specialization 'std::forward_as_tuple<std::tuple<int, int, int> >' requested here
                                      std::forward_as_tuple(std::move(__k)),
                                           ^
/usr/lib/gcc/x86_64-linux-gnu/6.2.0/../../../../include/c++/6.2.0/bits/unordered_map.h:908:16: note: in instantiation of member function 'std::__detail::_Map_base<std::tuple<int, int, int>, std::pair<const std::tuple<int, int, int>, float>, std::allocator<std::pair<const std::tuple<int, int, int>, float> >, std::__detail::_Select1st, std::equal_to<std::tuple<int, int, int> >, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[]' requested here
      { return _M_h[std::move(__k)]; }
               ^
tensorflow/contrib/tensor_forest/kernels/count_extremely_random_stats_op.cc:421:22: note: in instantiation of member function 'std::unordered_map<std::tuple<int, int, int>, float, tensorflow::CountExtremelyRandomStats::TupleIntHash, std::equal_to<std::tuple<int, int, int> >, std::allocator<std::pair<const std::tuple<int, int, int>, float> > >::operator[]' requested here
          split_delta[make_tuple(accumulator, split, column)] += w;
                     ^
4 errors generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 853.100s, Critical Path: 837.41s
```

### What other attempted solutions have you tried?
Tried different compilers(clang,gcc) and a older version of computecpp

Is this a issue with Tensorflow or ComputeCPP, Can someone reproduce that behaviour ?
Regards Flo"
8978,Synchronous Training using SyncReplicasOptimizer,"I'm trying to implement a synchronous distributed Recurrent Neural Network using TensorFlow on multiple servers. Here's the link to my code: https://github.com/tushar00jain/spark-ml/blob/master/rnn-sync.ipynb. I've also provided the relevant part below.

I want the computations within the same batch to happen in parallel but I think it's still computing separate RNNs on each worker server and updating the parameters on the parameter server separately. I know this because I am printing the _current_state variable after I run the graph for each batch. Also, the _total_loss for the same global step is different on each worker server.

I'm following the instructions provided at the following links: https://www.tensorflow.org/deploy/distributed#replicated_training https://www.tensorflow.org/api_docs/python/tf/train/SyncReplicasOptimizer

Is this a bug or is there something wrong with my code?

        sess = sv.prepare_or_wait_for_session(server.target)
        queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)
        sv.start_queue_runners(sess, queue_runners)

        tf.logging.info('Started %d queues for processing input data.',
                        len(queue_runners))

        if is_chief:
                sv.start_queue_runners(sess, chief_queue_runners)
                sess.run(init_tokens_op)

        print(""{0} session ready"".format(datetime.now().isoformat()))
        #####################################################################

        ########################### training loop ###########################
        _current_state = np.zeros((batch_size, state_size))
        for batch_idx in range(args.steps):
            if sv.should_stop() or tf_feed.should_stop():
                break

            batchX, batchY = feed_dict(tf_feed.next_batch(batch_size))

            print('==========================================================')
            print(_current_state)

            if args.mode == ""train"":
                _total_loss, _train_step, _current_state, _predictions_series, _global_step = sess.run(
                [total_loss, train_step, current_state, predictions_series, global_step],
                feed_dict={
                    batchX_placeholder:batchX,
                    batchY_placeholder:batchY,
                    init_state:_current_state
                })

                print(_global_step, batch_idx)
                print(_current_state)
                print('==========================================================')

                if _global_step % 5 == 0:
                    print(""Step"", _global_step, ""Loss"", _total_loss)  "
8977,"When running ./configure, no Opencl Support Option","NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
8976,Illegal instruction when importing tensorflow,"After compiling tensorflow from source I get an ""illegal instruction"" error. 
I traced it back to this error with gdb:

> Thread 1 ""python"" received signal SIGILL, Illegal instruction.
> 0x00007fffdc684d16 in google::protobuf::SimpleDescriptorDatabase::DescriptorIndex<std::pair<void const*, int> >::AddFile(google::protobuf::FileDescriptorProto const&, std::pair<void const*, int>) ()
>   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so

I can successfully install and import the latest nightly build (and I have been able to compile and import tensorflow from source in the past on the same machine). I tried uninstalling all the dependencies and let pip install them again when I install the tensorflow wheel to no avail. I also tried to install the protobuf 3.1 wheel as suggested in the documentation, as well as the latest 3.2 wheel.
Any suggestion is welcome.

Here the details of my system:

Operating System: Linux Ubuntu 16.04
CUDA and CuDNN version
> ls -l /usr/local/cuda/lib64/libcud*
> -rw-r--r-- 1 root root   556000 Jan 27 00:48 /usr/local/cuda/lib64/libcudadevrt.a
> lrwxrwxrwx 1 root root       16 Jan 27 00:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
> lrwxrwxrwx 1 root root       19 Jan 27 00:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
> -rw-r--r-- 1 root root   415432 Jan 27 00:48 /usr/local/cuda/lib64/libcudart.so.8.0.61
> -rw-r--r-- 1 root root   775162 Jan 27 00:48 /usr/local/cuda/lib64/libcudart_static.a
> lrwxrwxrwx 1 root root       13 Sep 24  2016 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
> lrwxrwxrwx 1 root root       17 Sep 24  2016 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
> -rwxr-xr-x 1 root root 79337624 Sep 24  2016 /usr/local/cuda/lib64/libcudnn.so.5.1.5
> -rw-r--r-- 1 root root 69756172 Sep 24  2016 /usr/local/cuda/lib64/libcudnn_static.a

Tensorflow commit: a9b7946540a27cc53bbdc9db1564196979fe30ae
Bazel version
> Build label: 0.4.5
> Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
> Build time: Thu Mar 16 12:19:38 2017 (1489666778)
> Build timestamp: 1489666778
> Build timestamp as int: 1489666778"
8975,Tensorflow build fails with bazel 0.3.2,"**i am getting include file issue, have installed latest zlib1g-dev, but no luck** any help will be appreciated 

**Bazel binaries built from source V0.3.2,**
**TF command:  bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package**

ERROR is ERROR: tensorflow/core/BUILD:853:1: undeclared inclusion(s) in rule '//tensorflow/core:lib_internal':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/lib/png/png_io.cc':
~/.cache/bazel/_bazel_madhu/a9aabe45cf3d94341ef4fb777deb58c5/external/zlib_archive/zlib.h'
~/.cache/bazel/_bazel_madhu/a9aabe45cf3d94341ef4fb777deb58c5/external/zlib_archive/zconf.h'.""

**output from echo | gcc -E -xc++ - -v ** 



Using built-in specs.
COLLECT_GCC=gcc
Target: x86_64-linux-gnu
Configured with: ../src/configure -v --with-pkgversion='Ubuntu 5.4.0-6ubuntu1~16.04.4' --with-bugurl=file:///usr/share/doc/gcc-5/README.Bugs --enable-languages=c,ada,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-5 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --with-default-libstdcxx-abi=new --enable-gnu-unique-object --disable-vtable-verify --enable-libmpx --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-5-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-5-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-5-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --disable-werror --with-arch-32=i686 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu
Thread model: posix
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4)
COLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'
 /usr/lib/gcc/x86_64-linux-gnu/5/cc1plus -E -quiet -v -imultiarch x86_64-linux-gnu -D_GNU_SOURCE - -mtune=generic -march=x86-64 -fstack-protector-strong -Wformat -Wformat-security
ignoring duplicate directory ""/usr/include/x86_64-linux-gnu/c++/5""
ignoring nonexistent directory ""/usr/local/include/x86_64-linux-gnu""
ignoring nonexistent directory ""/usr/lib/gcc/x86_64-linux-gnu/5/../../../../x86_64-linux-gnu/include""
#include ""..."" search starts here:
#include <...> search starts here:
 /usr/include/c++/5
 /usr/include/x86_64-linux-gnu/c++/5
 /usr/include/c++/5/backward
 /usr/lib/gcc/x86_64-linux-gnu/5/include
 /usr/local/include
 /usr/lib/gcc/x86_64-linux-gnu/5/include-fixed
 /usr/include/x86_64-linux-gnu
 /usr/include
End of search list.
# 1 ""<stdin>""
# 1 ""<built-in>""
# 1 ""<command-line>""
# 1 ""/usr/include/stdc-predef.h"" 1 3 4
# 1 ""<command-line>"" 2
# 1 ""<stdin>""
COMPILER_PATH=/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/
LIBRARY_PATH=/usr/lib/gcc/x86_64-linux-gnu/5/:/usr/lib/gcc/x86_64-linux-gnu/5/../../../x86_64-linux-gnu/:/usr/lib/gcc/x86_64-linux-gnu/5/../../../../lib/:/lib/x86_64-linux-gnu/:/lib/../lib/:/usr/lib/x86_64-linux-gnu/:/usr/lib/../lib/:/usr/lib/gcc/x86_64-linux-gnu/5/../../../:/lib/:/usr/lib/
COLLECT_GCC_OPTIONS='-E' '-v' '-mtune=generic' '-march=x86-64'
"
8973, C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: ,"I am installing tensorflow with GPU and meeting some problems:

WARNING: /home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': Use SavedModel Builder instead.
WARNING:  #/home/EI/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': Use SavedModel instead.
INFO: Found 1 target...
ERROR: /home/EI/tensorflow/tensorflow/core/BUILD:1280:1: C++ compilation of rule '//tensorflow/core:lib_hash_crc32c_accelerate_internal' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 41 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error trying to exec 'cc1plus': execvp: No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1994.312s, Critical Path: 8.68s

Operating System: Ubuntu 16.04LTS
gcc  4.9.3
bazel :0.4.5
python:3.6.0
CUDA:8.0.61_375.62
cuDNN:5.1.1
"
8972,conv2d_transpose output shape more undefined than input shape,"I have posted [this on StackOverflow](http://stackoverflow.com/questions/43113984/output-shape-of-tf-nn-conv2d-transpose-is-entirely-undefined-even-though-only-ba) already but haven't gotten an answer yet, plus it feels like a bug very similar to https://github.com/tensorflow/tensorflow/issues/5807 which is why I'm posting it here as well.

Basically the problem is that the output shape of `tf.nn.conv2d_transpose` is entirely undefined, even if e.g. only one dimension in the input is unknown. So in the following code snippet, the shape of `out` is `[3, 10, 5, 5]` as expected if using the static shape to get the size of the first dimension. However if you use the dynamic shape (commented line in the snippet below), then the shape of `out` is `[?, ?, ?, ?]` instead of `[?, 10, 5, 5]`.

This is a problem for me because I am using `out` in a batch-normalization layer with `tf.contrib.layers.python.layers.batch_norm` for which certain dimensions must be defined.

```
import tensorflow as tf

input_ = tf.Variable(tf.random_normal([3, 10, 5, 1]))
w = tf.get_variable('w', initializer=tf.truncated_normal([3, 3, 5, 1], mean=0.0, stddev=0.01, dtype=tf.float32))

# output_shape = [tf.shape(input_)[0], 10, 5, 5]
output_shape = [input_.get_shape()[0].value, 10, 5, 5]
out = tf.nn.conv2d_transpose(input_,
                             filter=w,
                             output_shape=tf.pack(output_shape),
                             strides=[1, 1, 1, 1],
                             padding='SAME')
```

I am using TF v0.12 on Ubuntu 14.04, Python 3.5.2, installed in Anaconda environment through pip."
8971,html5lib dependency issue,"Install Tensorflow from source, met `html5lib` dependency issue:

```
Processing dependencies for tensorflow==1.1.0rc0
error: html5lib 1.0b8 is installed but html5lib!=0.9999,!=0.99999,<0.99999999,>=0.999 is required by {'bleach'}
```

## 1. Env:
### 1.1 OS:
Linux Mint 18.1 Cinnamon 64-bit
### 1.2 CUDA & CUDNN:
GPU: Nvidia Titan X Pascal
```
$ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   556000 Apr  5 00:46 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Apr  5 00:46 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Apr  5 00:46 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
-rwxr-xr-x 1 root root   415432 Apr  5 00:46 /usr/local/cuda/lib64/libcudart.so.8.0.61
-rw-r--r-- 1 root root   775162 Apr  5 00:46 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Apr  5 00:47 /usr/local/cuda/lib64/libcudnn_static.a
```
### 1.3 Tensorflow git version
```
$ git rev-parse HEAD
a9b7946540a27cc53bbdc9db1564196979fe30ae
```

### 1.4 Bazel version
```
$ bazel version
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778
```

### 1.5 Installed html4lib
```
$sudo -H pip3 list
...
html5lib (0.9999999)
...
```

## 2. Reproduction
After clone the git, executing a script with the following commands to install [developer mode] :

```
bazel clean
./configure
bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k //tensorflow/tools/pip_package:build_pip_package
#bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
sudo rm -r _python_build
mkdir _python_build
cd _python_build
ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .
ln -s ../tensorflow/tools/pip_package/* .
sudo -H python3 setup.py develop
```
"
8969,Broken link in README.md,"In https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/README.md

 > ...In addition to the types of scope mechanisms in TensorFlow (name_scope, variable_scope, TF-Slim adds a...

Link of variable_scope ( https://www.tensorflow.org/api_docs/python/state_layers#variable_scope ) is broken.

"
8967,using gabor filter in tensorflow,"I want to use gabor filter in my first layer of  network in convolution layer. 
and idea how can I use it?"
8966,Can't Link Shared Libraries Located in /usr/local/include Folder,"Folks,
I can't add any libraries in the /usr/local/include (or /lib) to the BUILD file. Bazel complains it cannot find the headers, nor the *.so files.
Are you planning on adding support for that?

Thanks,"
8964,Is there a bug in tf.layers.batch_normalization?,"Since TF 1.0 API came out, I have been trying to use `tf.layers.batch_normalization` instead of the version in tf.contrib.layers. However, I found this layer works abnormally in my case.

Here is my simple code that uses `tf.layers.batch_normalization`.

```
output = tf.nn.bias_add(tf.matmul(input_tensor, self._weight), self._bias)

  if self._use_batch_norm:
       output = tf.layers.batch_normalization(
             output,
             momentum=0.9,
             training=training,
             name=self._name + ""_bn"",
             reuse=reuse
        )

 output = tf.nn.relu(output)
```

However, when I enabled the batch_normalization on this layer. I found that my model maps all raw data to a single point in the hidden representation space. When I disabled batch_normalization, this cannot happen at all.

Here is a final view of my data in the latent space:

array([[ 0.46338093,  0.53661913],
       [ 0.46339276,  0.53660733],
       [ 0.46329296,  0.53670704],
       ...,
       [ 0.4633435 ,  0.53665644],
       [ 0.46335611,  0.53664398],
       [ 0.4633027 ,  0.53669727]], dtype=float32)

The input data are generated from a multivariate gaussian distribution so that their hidden representations should be different as well. I searched the usage of this function on stackoverflow but the example is so trivial and it doesn't help. I think there may be a bug in this layer object or I may misuse it somehow.

In the contrib.layers's version, the batch_norm layer should be linked with update_ops collection. But I read the source code of this implementation and it seems that it is not necessary. Is there anyone has some thoughts on this?
"
8963,mputecpp,
8962,Graph Collections in the C API,"Hi,

In Python we have graph collections (e.g., TRAINABLE_VARIABLES) which are stored in the Graph class. I assume that these are somehow serialized in the graph protobuf so that when a GraphDef is imported, the relevant collections are imported too. However, I do not see any option in the C API for defining such collections? Is there something that I am missing? If not, why not include that functionality in the C API?

Thank you,
Anthony"
8961,"ValueError(""No variables provided."") for apply_gradients","In [optimizer.p](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/optimizer.py)y, the first part of code segment is

```
def apply_gradients(self, grads_and_vars, global_step=None, name=None):

   grads_and_vars = tuple(grads_and_vars)  # Make sure repeat iteration works.
   if not grads_and_vars:
      raise ValueError(""No variables provided."")
```
Running my program, I got the error message caused by this specific error. I then printed out `tuple(grads_and_vars)`, part of which is. I don't know why it can cause the error of no variables provided.

> ((<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_0:0' shape=(3, 3, 3, 64) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2afc746b5c50>), (<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_1:0' shape=(64,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2affd48189b0>), (<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_2:0' shape=(3, 3, 64, 64) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2affd486d940>), (<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_3:0' shape=(64,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2affd488cf98>), (<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_4:0' shape=(3, 3, 64, 128) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2afc746b5d68>), (<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_5:0' shape=(128,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2affd48f4278>), (<tf.Tensor 'Optimizer/training/clip_by_global_norm/Optimizer/training/clip_by_global_norm/_6:0' shape=(3, 3, 128, 128) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x2affd4915e10>), 
"
8959,Gradients of Gradients throws 'NAN' outputs for LSTM's,"
### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

Cuda 8.0, tensorflow 1.0

If you try to take the gradient of a gradient such as needed in Improved Techniques of Wasserstien GAN's (https://arxiv.org/abs/1704.00028) for LSTMs in the generator, throws a NAN error. If you use convolutions, then there is no error. 

Author's source code for language model:

https://github.com/igul222/improved_wgan_training/blob/master/gan_language.py
"
8957,Tensorflow multi-GPU training and variable scope,"### Context

I'm working on a detector model on multiple GPUs using Tensorflow 1.0. As suggested [here](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py), Gradients are computed on multiple GPUs individually and are averaged on CPU. To share the trainable variables (e.g. weights and biases) across the GPU towers, the `reuse` flag is turned on using `tf.get_variable_scope().reuse_variables()`, as in the cifar10 example. The difference is that I am using an `AdamOptimizer` instead of `GradientDescentOptimizer`.


### Problem

When I run the training job, it prints out a long stacktrace and raise the following error at `opt.apply_gradients()`:

```
ValueError: Variable conv1_1/kernel/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```

Looking into the source code I found that the `AdamOptimizer` is creating a number of zero-initialized slots within the `_create_slots()` method, wherein it calls the `_zeros_slot()`. This calls a separate module called the [`slot_creator`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/slot_creator.py#L62) (source code linked).

**In `line 62` of the `slot_creator`, it uses `variable_scope.get_variable()`. This used to be `tf.Variable()` in 0.12.**

My understanding of variable scopes is that `variable_scope.get_variable()` would fail to create a variable **if `reuse` flag is on`. See [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/variable_scope.py#L669) for source code.**

But the cifar10 example by Tensorflow creators seems to suggest enabling reuse to share variables across the GPU towers using `tf.get_variable_scope().reuse_variables()`. This happens **before** we average and apply the gradients. It looks like Tensorflow 1.0 refuses to create variables for the `AdamOptimizer`.

This happens for all optimizers that directly or indirectly call the `slot_creator` module.

### Question
As a quick fix, I added a custom function into the `VariableScope` class to disable the `_reuse` flag right before calling `opt.apply_gradients`. However, I am sure there is a merit to forcing the `reuse` flag to be only set to `True`. I am not sure what the better workaround would be. Any suggestions?


### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I created question [here](http://stackoverflow.com/questions/43212725/tensorflow-multi-gpu-training-and-variable-scope)

### Environment info
Operating System: Ubuntu 14.04 LTS

Installed version of CUDA and cuDNN: 8.0 and 5.1 respectively
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

The commit hash (`git rev-parse HEAD`): 1cb96893a64f59b7265f9def9968f7bed1e57662#diff-a25cc0fc9d475568e0069e5dc0b67d85 (see `slot_creator`)"
8956,Linking errors when using Tensorflow/Bazel to call Python from C++,"I am writing a C++ application (based on Tensorflow Serving) in which I need to call Python and Numpy functions (from `Python.h` and `numpy.h`).

This application is built with Bazel.

So I include the header: 

`#include ""tensorflow/python/lib/core/numpy.h""`

which in turn includes `Python.h`. 

This file seems to wrap numpy to fix an issue described in [this](http://stackoverflow.com/questions/31971185/segfault-when-import-array-not-in-same-translation-unit) Stack Overflow post.

Any other C++ code within the Tensorflow project which needs to make calls to `Python.h` also does not directly include it, but only includes `tensorflow/python/lib/core/numpy.h`. On the Bazel side, it seems to suffice to simply add `//util/python:python_headers` to the `deps` of the build.

My `BUILD` file looks like this:

```

...

cc_library(
	name = ""my_library"",
	srcs = [""my_library.cc""],
	hdrs = [""my_library.h""],
	deps = [
		@org_tensorflow//util/python:python_headers"",
		@org_tensorflow//third_party/py/numpy:headers"",
			] + SOME_OTHER_DEPS + TENSORFLOW_DEPS + SUPPORTED_TENSORFLOW_OPS,
)

cc_binary(
	name = ""my_main"",
	srcs = [""my_main.cc""],
	deps = ["":my_library""],
)

...

```

Building the library with `bazel build :my_library` works fine.
Building the binary the same way does not work, I get the following errors:

```
bazel-out/local-fastbuild/bin/servable/_objs/my_library/servable/my:library.pic.o:my_library.cc:function tensorflow::serving::NumpyInitializer::init(): error: undefined reference to 'Py_Initialize'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::MakeArgTuple(tensorflow::(anonymous namespace)::PyCall*, _object**): error: undefined reference to 'PyList_New'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::MakeArgTuple(tensorflow::(anonymous namespace)::PyCall*, _object**): error: undefined reference to 'PyList_SetItem'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::MakeArgTuple(tensorflow::(anonymous namespace)::PyCall*, _object**): error: undefined reference to 'Py_BuildValue'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::IsSingleNone(_object*): error: undefined reference to 'PyType_IsSubtype'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::IsSingleNone(_object*): error: undefined reference to '_Py_NoneStruct'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::DoCallPyFunc(tensorflow::(anonymous namespace)::PyCall*): error: undefined reference to 'PyEval_CallObjectWithKeywords'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::DoCallPyFunc(tensorflow::(anonymous namespace)::PyCall*): error: undefined reference to 'PyErr_Occurred'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::DoCallPyFunc(tensorflow::(anonymous namespace)::PyCall*): error: undefined reference to 'PyErr_Print'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::DoCallPyFunc(tensorflow::(anonymous namespace)::PyCall*): error: undefined reference to 'PyList_Size'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::DoCallPyFunc(tensorflow::(anonymous namespace)::PyCall*): error: undefined reference to 'PyList_GetItem'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::(anonymous namespace)::DoCallPyFunc(tensorflow::(anonymous namespace)::PyCall*): error: undefined reference to 'PyType_IsSubtype'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::ConvertNdarrayToTensor(_object*, tensorflow::Tensor*): error: undefined reference to 'PyString_AsStringAndSize'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::ConvertTensorToNdarray(tensorflow::Tensor const&, _object**): error: undefined reference to 'PyString_FromStringAndSize'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::PyFuncOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'PyGILState_Ensure'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/py_func_lib/external/org_tensorflow/tensorflow/python/lib/core/py_func.pic.o:py_func.cc:function tensorflow::PyFuncOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'PyGILState_Release'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/numpy_lib/external/org_tensorflow/tensorflow/python/lib/core/numpy.pic.o:numpy.cc:function _import_array: error: undefined reference to 'PyImport_ImportModule'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/numpy_lib/external/org_tensorflow/tensorflow/python/lib/core/numpy.pic.o:numpy.cc:function _import_array: error: undefined reference to 'PyExc_ImportError'
bazel-out/local-fastbuild/bin/external/org_tensorflow/tensorflow/python/_objs/numpy_lib/external/org_tensorflow/tensorflow/python/lib/core/numpy.pic.o:numpy.cc:function _import_array: error: undefined reference to 'PyErr_SetString'


```

So there is obviously linking errors against `Python.h`. However, compiling any Tensorflow-internal goals works fine. I find it weird that it now can not link to `Python.h` even inside Tensorflow files.

After spending a few days looking into Tensorflow and their `BUILD` files I am out of ideas how to make this work.

## So now I ask here: where and how exactly is the correct inclusion of Python defined in Tensorflow (and its Bazel files?).

Some clues seem to be in the definitions in `util/python/BUILD` and `tensorflow/tensorflow.bzl`.

There seems to be quite a bit of Bazel magic going on there.

"
8953,Enable full message with tf.Print,"**Operating System:** Debian 4.8.15-2
**Installed version of CUDA and cuDNN:** CUDA 8, cuDNN 5
**python3 -c ""import tensorflow; print(tensorflow.__version__)"":** 1.0.1

**Minimal reproducible example**
```
import tensorflow as tf
ph = tf.placeholder(tf.float32, [3,4,5,6])
ts = tf.shape(ph)
tp = tf.Print(ts, [ts])
tm = tf.reduce_mean(tp)
sess = tf.Session()
res = sess.run(tm)
```

**Output**
`I tensorflow/core/kernels/logging_ops.cc:79] [3 4 5...]`

Maybe there is some obvious way around this, but I couldn't find any on the [docs](https://www.tensorflow.org/api_docs/python/tf/Print). To state the obvious : I'm trying to see the full shape of the tensor, and not only the first 3 positions. In this example its size is 4, but I would like to be able to see whatever I want with whatever size it has.

Furthermore, debugging into TensorFlow did became a problem when I got to line [62 of logging_ops.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/logging_ops.py#L62), where `gen_logging_ops` is used but it doesn't seem to be declared anywhere — and older versions already had this, I'm probably missing some link, because `grep` and `find` couldn't find anything useful:

**Output of `grep`**
```
tensorflow$ grep -R ""gen_logging_ops"" .
./tensorflow/python/framework/function_test.py:from tensorflow.python.ops import gen_logging_ops
./tensorflow/python/framework/function_test.py:      check = gen_logging_ops._assert(math_ops.greater(x, 0), [x])
./tensorflow/python/ops/control_flow_ops.py:from tensorflow.python.ops import gen_logging_ops
./tensorflow/python/ops/control_flow_ops.py:      return gen_logging_ops._assert(
./tensorflow/python/ops/control_flow_ops.py:        return gen_logging_ops._assert(
./tensorflow/python/ops/summary_ops.py:from tensorflow.python.ops import gen_logging_ops
./tensorflow/python/ops/summary_ops.py:from tensorflow.python.ops.gen_logging_ops import *
./tensorflow/python/ops/summary_ops.py:    val = gen_logging_ops._tensor_summary(
./tensorflow/python/ops/logging_ops.py:from tensorflow.python.ops import gen_logging_ops
./tensorflow/python/ops/logging_ops.py:from tensorflow.python.ops.gen_logging_ops import *
./tensorflow/python/ops/logging_ops.py:  return gen_logging_ops._print(input_, data, message, first_n, summarize, name)
./tensorflow/python/ops/logging_ops.py:    val = gen_logging_ops._histogram_summary(
./tensorflow/python/ops/logging_ops.py:    val = gen_logging_ops._image_summary(
./tensorflow/python/ops/logging_ops.py:    val = gen_logging_ops._audio_summary_v2(tag=tag,
./tensorflow/python/ops/logging_ops.py:    val = gen_logging_ops._merge_summary(inputs=inputs, name=name)
./tensorflow/python/ops/logging_ops.py:    val = gen_logging_ops._scalar_summary(tags=tags, values=values, name=scope)
./tensorflow/python/kernel_tests/control_flow_ops_py_test.py:from tensorflow.python.ops import gen_logging_ops
./tensorflow/python/kernel_tests/control_flow_ops_py_test.py:        unguarded_assert = gen_logging_ops._assert(
./tensorflow/python/summary/summary.py:from tensorflow.python.ops import gen_logging_ops as _gen_logging_ops
./tensorflow/python/summary/summary.py:    val = _gen_logging_ops._scalar_summary(
./tensorflow/python/summary/summary.py:    val = _gen_logging_ops._image_summary(
./tensorflow/python/summary/summary.py:    val = _gen_logging_ops._histogram_summary(
./tensorflow/python/summary/summary.py:    val = _gen_logging_ops._audio_summary_v2(
./tensorflow/python/summary/summary.py:    val = _gen_logging_ops._merge_summary(inputs=inputs, name=name)
```

**Output of `find`**
```
tensorflow$ find . -iname ""*logging_ops*""
./tensorflow/core/ops/logging_ops.cc
./tensorflow/core/kernels/logging_ops_test.cc
./tensorflow/core/kernels/logging_ops.cc
./tensorflow/python/ops/logging_ops.py
./tensorflow/python/kernel_tests/logging_ops_test.py
```

Besides evaluating what I want with `sess.run` and manually printing it with python, is there any tensorflow-friendly solution to this? Debugging should be easier. :)"
8952,AttributeError: module 'tensorflow.python.ops.array_ops' has no attribute 'pack' ,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
8951,Using output of `tf.argmax` as index raises TypeError,"### Minimal example
```
a = tf.constant([1, 2, 3], dtype=tf.float32)
b = tf.argmax(a)
tf.Session().run(a[b])
```
This raises a `TypeError`
```
TypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.
```
The solution is to `tf.cast` `b` into a `tf.int32` before using it as an index. The output of `tf.argmax` should be usable as an index immediately. I feel that the current state is not consistent, is there some hidden reason for this?"
8950,Execution Stuck after few steps in sess.run(),"
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Execution is stuck in between steps. For few steps, it seems to run fine but after that the execution just halts without throwing any exception or the error.

### Environment info
Operating System: Ubuntu 14.04
GPU: NVIDIA TITAN X (Pascal)
GPU Memory: 12GB

Installed version of CUDA and cuDNN: 
-rw-r--r-- 1 root root   556000 Mar 29 05:10 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mar 29 05:10 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Mar 29 05:10 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
-rwxr-xr-x 1 root root   415432 Mar 29 05:10 /usr/local/cuda/lib64/libcudart.so.8.0.61
-rw-r--r-- 1 root root   775162 Mar 29 05:10 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       18 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10
-rwxr-xr-x 1 root root 84163560 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn.so.5.1.10
lrwxrwxrwx 1 root root       18 Apr  4 12:55 /usr/local/cuda/lib64/libcudnn.so.6 -> libcudnn.so.6.0.20
-rwxrwxrwx 1 root root 84163560 Apr  4 13:17 /usr/local/cuda/lib64/libcudnn.so.6.0.20
-rwxrwxrwx 1 root root 70364814 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn_static.a


If installed from binary pip package, provide:

1. A link to the pip package you installed:

https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
1.0.1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I ran the mnist_deep.py script provided in tutorials.

### What other attempted solutions have you tried?
Previously, the display used to get hang showing error CUDA_LAUNCH_ERROR_TIMEOUT. On nvidia forum, someone suggested to switch off the X-server. I switched it off, but the problem still persisted.
I noticed that the script was hogging full memory of GPU, I tried to limit the allocation by using ""allow_growth"" flag. But the problem still persists. 

### Logs or other output that would be helpful
step 47, training accuracy 0.64
step 48, training accuracy 0.72
step 49, training accuracy 0.7
step 50, training accuracy 0.68
step 51, training accuracy 0.76
step 52, training accuracy 0.66
step 53, training accuracy 0.82
step 54, training accuracy 0.82
step 55, training accuracy 0.64
step 56, training accuracy 0.64
step 57, training accuracy 0.74
step 58, training accuracy 0.76
step 59, training accuracy 0.8
step 60, training accuracy 0.68
step 61, training accuracy 0.88
step 62, training accuracy 0.62
step 63, training accuracy 0.84
step 64, training accuracy 0.72
step 65, training accuracy 0.76
step 66, training accuracy 0.74
step 67, training accuracy 0.86
step 68, training accuracy 0.76
step 69, training accuracy 0.9
step 70, training accuracy 0.84
step 71, training accuracy 0.82
step 72, training accuracy 0.7

Attached is the screenshot of ""nvidia-smi""
![nvidia-smi](https://cloud.githubusercontent.com/assets/1628210/24651492/a5b54ada-194b-11e7-8ba2-9c3ff6dc2901.PNG)

"
8949,ResourceExhausted,"I get the following error when running in GPU on AWS p2-xlarge:
```
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1205162d00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x120517b100 of size 73984
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a5ba00 of size 96000
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a8a800 of size 96000
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215affb00 of size 263424
I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 24 Chunks of size 256 totalling 6.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 512 totalling 6.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 12 Chunks of size 1280 totalling 15.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 1792 totalling 8.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2560 totalling 2.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 3584 totalling 17.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6144 totalling 6.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 25600 totalling 200.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 29184 totalling 28.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1386 Chunks of size 96000 totalling 126.89MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 131328 totalling 128.2KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 233 Chunks of size 192000 totalling 42.66MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 7 Chunks of size 204800 totalling 1.37MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 232192 totalling 226.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 257792 totalling 251.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2640128 totalling 2.52MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200000 totalling 91.55MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 265.87MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                   279314432
InUse:                   278784768
MaxInUse:                278976768
NumAllocs:                    4097
MaxAllocSize:             19200000

W tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************
W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 375.0KiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[300,320]
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3720 get requests, put_count=1106 evicted_count=1000 eviction_rate=0.904159 and unsatisfied allocation rate=0.998387
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
```
I'm using TensorFlow R0.12.1 and Session code is:
```
# Launch the graph
config = tf.ConfigProto(log_device_placement=True)
config.gpu_options.allocator_type = 'BFC'
sess = tf.Session(config = config)
init = tf.global_variables_initializer()
sess.run(init)
timestart = datetime.datetime.now() # Start time in seconds
timeprev  = datetime.datetime.now() # Start time in seconds
countprev = 0
ratelist = []
boxcarcount = 10
X_train = X_train.astype(np.float32)  # Cast to float32 from float64

print(""Starting training..."")
# Perform Training steps with ""batch_size"" iterations at each loop
step = 1
while step * batch_size <= training_iters:
    # Note: type(X_train) = float32
    # Note: type(y_train) = int32
    # Note: type(step)       = int
    # Note: type(batch_size) = int
    batch_xs =         extract_batch_size(X_train, step, batch_size)
    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size),LabelMax)

    # Fit training using batch data
    output, loss, acc = sess.run(
        [optimizer, cost, accuracy],
        feed_dict={
            Xin   : batch_xs, 
            Ytrue : batch_ys,
            keep_prob: DO_keep_prob
        }
    )
    train_losses.append(loss)
    train_accuracies.append(acc)
```
My question: is there a way to allocate more memory in the GPU?
This seems like a really small data set to be using?!?!?
Thanks."
8948,Feature Request: Erosion2d and Dilation2d implemented on GPU,"Hi everybody!
Erosion2d and Dilation2d can be used for various reason. e.g. [Ronneberg et al.](https://arxiv.org/abs/1505.04597) compute a weight map using morphological operations for their cost function. This can be done using morphological Erosions and Dilations but those operations are quite slow on CPU. It seems Tensorflow do not use the GPU for those operation. Would it be possible to have those two operations implemented on GPU?"
8947,XLA: Could not open input file: Is a directory,"XLA failed with Could not open input file: Is a directory



### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```bash
.opt/anaconda/lib64/libcudadevrt.a
.opt/anaconda/lib64/libcudart.so
.opt/anaconda/lib64/libcudart.so.8.0
.opt/anaconda/lib64/libcudart.so.8.0.61
.opt/anaconda/lib64/libcudart_static.a
.opt/anaconda/lib64/libcudnn.so
.opt/anaconda/lib64/libcudnn.so.6
.opt/anaconda/lib64/libcudnn.so.6.0.20
.opt/anaconda/lib64/libcudnn_static.a
```

### code setup


If installed from binary pip package, provide:

1. http://q-phantom.com/conda/linux-64/tensorflow-1.1.0rc0-py36_3.tar.bz2
2. 1.1.0-rc0

### code init

```
import os
os.environ[""CUDA_VISIBLE_DEVICES""]=""0""
tf.reset_default_graph()
tl.layers.set_name_reuse(True)
placehold_mapping, networks = c_network(None, label_indices=label_index, feature_indices=feature_index)
network = networks[0]
config = tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
sess = tf.Session(config=config)
tl.layers.initialize_global_variables(sess)
```

### Log

```bash
2017-04-04 16:26:48.275644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-04-04 16:26:48.275648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-04-04 16:26:48.275653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:0a:00.0)
2017-04-04 16:26:48.479102: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-04-04 16:26:48.479122: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-04-04 16:26:48.481008: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x5dd4360 executing computations on platform Host. Devices:
2017-04-04 16:26:48.481021: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): <undefined>, <undefined>
2017-04-04 16:26:48.481138: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 1 visible devices
2017-04-04 16:26:48.481146: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devices
2017-04-04 16:26:48.482239: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x5f0f950 executing computations on platform CUDA. Devices:
2017-04-04 16:26:48.482248: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
GEN DATASET: 0.00 seconds elapsed
ROUND:  0
2017-04-04 16:26:57.149563: F tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/utils.cc:31] -1:-1: Could not open input file: Is a directory
```
"
8946,Tensorflow results in Segmenation fault ,"Hello

I have installed tensorflow gpu version with python2.7. It results in following error once i define Session. I am unable to train my model. Please assist


```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library lib                                                                                                         cublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library lib                                                                                                         cudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library lib                                                                                                         cufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library lib                                                                                                         cuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library lib                                                                                                         curand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node rea                                                                                                         d from SysFS had negative value (-1), but there must be at least one NUMA node, so r                                                                                                         eturning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties                                                                                                         :
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:02:00.0
Total memory: 11.17GiB
Free memory: 11.10GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is c                                                                                                         urrently active; existing: 0x248a6e0
Segmentation fault (core dumped)

```"
8945,Bazel test failure in TF (Assertion errors) on Ubuntu 16.04 on pcc64le architecture,"###Environment info:
Operating System: Ubuntu 16.04 (ppc64le)

###Installed version of CUDA and cuDNN: cuda & OpenCL disabled and all other features enabled

###Build and test INFO
Built TF (version 1.0.1) successfully on Ubuntu 16.04 and RHEL 7.3. 
Now I am trying to run the bazel tests -  12 tests are failing out of 1044. Please find the attachment for log details.

Thanks!

[C-C++Test Failure  analysis for TF.xlsx](https://github.com/tensorflow/tensorflow/files/892266/C-C.Test.Failure.analysis.for.TF.xlsx)
"
8941,Log Selected Convolution Algorithm,"Reposting from https://github.com/tensorflow/tensorflow/issues/8928#issuecomment-291330814:

>It might make sense for the selected algorithm to be logged either to the logging system or maybe in the RunMetadata protocol buffer. 

/CC @asimshankar "
8938,New issue template.,"### Please complete this information or else your issue will be closed
- *Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?*: 
- *TensorFlow installed from (source or binary)?*: 
- *TensorFlow version*: 
- *Operating system*:
- *Bazel version (if compiling from source)*:  
- *CUDA/cuDNN version*: 
- *GPU Model and Memory*: 
- *Exact command to reproduce*: 

If you are unsure how to obtain this information, some of it can be obtained by running our collection script and copying and pasting the appropriate data.

### Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. Large logs and files should be attached. Include full tracebacks. Please keep your examples as short as possible, because longer code makes the chance of your issue being answered lower."
8937,Has complex MVN been implemented?,"I have below error for my code , where muC and SigmaC are complex vector and matrix
```
dist = tf.contrib.distributions.MultivariateNormalFull(muC, SigmaC)
```
```
TypeError: Value passed to parameter 'input' has DataType complex64 not in list of allowed values: float64, float32
```"
8934,complex weight for LSTM?,"I am having complex input and output for LSTM, and it looks like I have to initialize LSTM weights as complex tensor. Below is my code:
```
rnn_size = 128
cell = core_rnn_cell.BasicLSTMCell(rnn_size, state_is_tuple=False)
print 'initiate LSTM cell: ',cell
num_layers = 1
batch_size = 1
seq_length = T.shape[0]
initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)
learning_rate = 0.003
input_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name='input_data')
target_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name = 'target_data')
lr = tf.Variable(learning_rate, trainable=False, name=""learning_rate"")
K = 3
output_size = K + K*(K+1)/2 
embedding_size = 128
with tf.variable_scope(""coordinate_embedding""):
#     real_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = ""complex_weight_real"")
#     imag_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = ""complex_weight_imag"")
#     matrix = tf.complex(real_w, imag_w)
    real_embedding_w = tf.get_variable(""real_embedding_w"", [K, embedding_size])
    imag_embedding_w = tf.get_variable(""imag_embedding_w"", [K, embedding_size])
    embedding_w = tf.complex(real_embedding_w, imag_embedding_w)
    real_embedding_b = tf.get_variable(""real_embedding_b"", [embedding_size])
    imag_embedding_b = tf.get_variable(""imag_embedding_b"", [embedding_size])
    embedding_b = tf.complex(real_embedding_b, imag_embedding_b)

with tf.variable_scope(""rnnlm""): 
    real_output_w = tf.get_variable(""real_output_w"", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)
    imag_output_w = tf.get_variable(""imag_output_w"", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)
    output_w = tf.complex(real_output_w, imag_output_w)
    real_output_b = tf.get_variable(""real_output_b"", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)
    imag_output_b = tf.get_variable(""imag_output_b"", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)
    output_b = tf.complex(real_output_b, imag_output_b)
inputs = tf.split(input_data, seq_length-1, 0)
states = []
initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)
state = initial_state
outputs = []
predict_initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)
predict_input =  tf.placeholder(tf.complex64, [1,  2])
predict_sequence = 100
index =0
predict_outputs = []
output, new_state = cell(inputs[i], state)
```
But I have the below error, but I checked the documentation and didn't find out how to initialize the weights of LSTM cell as complex tensors.
```
ValueError: An initializer for variable basic_lstm_cell/weights of <dtype: 'complex64'> is required
```

Could anyone give me some hint on this? Thanks in advance!"
8933,Prediction based on day / time with tensorFlow,"I did some digging but I couldn't find anything (maybe i just didn't know what do search exactly),
I'm in my final year of study and I am starting my final year project in Software engineering,
My plain is to (lets take smart house as an example) create a machine that will learn the householders habits and then do that action based on what they did (e.g: at Sunday, 7 AM turn on the boiler for 30 minutes because only one resident need to take a shower).

Can TensorFlow learn and act like that?

Please help.

Thanks."
8932,Can't register new xla device,"I'm trying to register a fake 'xpu' device to use with xla, but it hasn't been working. I've gotten Tensorflow to build after making the changes found in the attached file ([diffOutput.txt](https://github.com/tensorflow/tensorflow/files/891147/diffOutput.txt), the output from git diff). But, when I run the following sample code:
```
import argparse
import sys

import tensorflow as tf

from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.python.client import timeline

FLAGS = None


def main(_):
    config = tf.ConfigProto(log_device_placement=True)
    jit_level = 0
    if FLAGS.xla:
        # Turns on XLA JIT compilation.
        jit_level = tf.OptimizerOptions.ON_1
        print('XLA flag on')

    config.graph_options.optimizer_options.global_jit_level = jit_level
    run_metadata = tf.RunMetadata()
    # Creates a session with log_device_placement set to True.
    with tf.Session(config=config) as sess:
        # Creates a graph.
        with tf.device('/job:localhost/replica:0/task:0/device:XLA_XPU:0'):
        #with tf.device('/device:CPU:0'):
            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0],
                            shape=[2, 3], name='a')

            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0],
                            shape=[3, 2], name='b')
            c = tf.matmul(a, b)

        # Runs the op.
        print(sess.run(c,
              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
              run_metadata=run_metadata))
        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
        with open('timeline.ctf.json', 'w') as trace_file:
            trace_file.write(trace.generate_chrome_trace_format())

if __name__ == ""__main__"":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str,
            default='/tmp/tensorflow/mnist/input_data',
            help='Directory for storing input data')
    parser.add_argument(
              '--xla', type=bool, default=True, help='Turn xla via JIT on')
    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

```

I get the error:
```
InvalidArgumentError (see above for traceback): Cannot assign a device to node 'MatMul': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:XLA_XPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0
	 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:XLA_XPU:0""](a, b)]]
```
What else needs to change in order for my code to work?"
8928,cudnnFindConvolutionForwardAlgorithmEx vs cudnnGetConvolutionForwardAlgorithm,"Following up on https://github.com/tensorflow/tensorflow/issues/7187#issuecomment-290284053, why does Tensorflow use [`cudnnGetConvolutionForwardAlgorithm`](https://github.com/tensorflow/tensorflow/blob/904edee4456a61d50d5b1ffe9858a7772acc423e/tensorflow/stream_executor/cuda/cuda_dnn.cc#L1844) rather than `cudnnFindConvolutionForwardAlgorithmEx`?  It looks like [Tensorflow tries to do the more complete profiling itself](https://github.com/tensorflow/tensorflow/blob/f8d8172c0086a42dfc1ed732fcf083dbd62c42e4/tensorflow/core/kernels/conv_ops.cc#L664-L689). 

For reference, `cudnnGetConvolutionForwardAlgorithm` serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionForward for the given layer specifications. Based on the input preference, this function will either return the fastest algorithm or the fastest algorithm within a given memory limit. For an exhaustive search for the fastest algorithm, please use `cudnnFindConvolutionForwardAlgorithm`.

Whereas:
`cudnnFindConvolutionForwardAlgorithmEx` function attempts all available cuDNN algorithms for cudnnConvolutionForward, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnConvolutionFwdAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time.

Looking at a number of other DNN, they seem to use `cudnnFindConvolutionForwardAlgorithmEx` / `cudnnFindConvolutionForwardAlgorithm`:
* [pytorch](https://github.com/pytorch/pytorch/blob/e50a1f19b3dc735f0710929b97b0af384aafe09b/torch/csrc/cudnn/Conv.cpp#L214) (when benchmark is on): 
* [Theano](https://github.com/Theano/Theano/blob/c6ffa460d43b6650aefbe7939f332084caafeaa4/theano/gpuarray/dnn_fwd.c#L125) (if `time_once` or `time_on_shape_change`)
* [cntk](https://github.com/Microsoft/CNTK/blob/5651d574c8f3fecf2533cf01beebaaa6e07453e2/Source/Math/CuDnnConvolutionEngine.cu#L229) (non-static finder)

/CC @Yangqing @zheng-xq"
8926,Image Distortions should be able to be applied to batches. [Feature Request?],"The tf.image distortion functions only accept a single image as an input whereas it would be much more useful to be able to place the distortion within your graph flow so any batches of images that pass through it get distorted too. I believe a current solution is as suggeested by @mrry [here on Stack Overflow](http://stackoverflow.com/questions/38920240/tensorflow-image-operations-for-batches) however it feels like, much like the other ops for images work, being able to take batches would be much more useful.

Is the solution proposed by @mrry the accepted method or should the distortion functions be taking batches?"
8925,RuntimeError when executing models/tutorials/image/cifar10/cifar10_train.py,"### Environment info
Operating System:
Ubuntu Server 16.04LTS

Installed version of CUDA and cuDNN: 
CUDA 8.0 cuDNN 5.1
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   560184 Mar  7 09:54 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mar  7 09:54 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Mar  7 09:54 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Mar  7 09:54 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Mar  7 09:54 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 84163560 Mar  9 03:26 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 84163560 Mar  9 03:26 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 84163560 Mar  9 03:26 /usr/local/cuda/lib64/libcudnn.so.5.1.10
-rw-r--r-- 1 root root 70364814 Mar  9 03:26 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
1.0.1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I followed this [tutorial](https://www.tensorflow.org/tutorials/deep_cnn#launching_and_training_the_model) to launch the model:
```
python cifar10_train.py
```

### Logs or other output that would be helpful
```
Traceback (most recent call last):
  File ""cifar10_train.py"", line 124, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""cifar10_train.py"", line 120, in main
    train()
  File ""cifar10_train.py"", line 110, in train
    log_device_placement=FLAGS.log_device_placement)) as mon_sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 315, in MonitoredTrainingSession
    return MonitoredSession(session_creator=session_creator, hooks=all_hooks)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 601, in __init__
    session_creator, hooks, should_recover=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 434, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 767, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 772, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 494, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 375, in create_session
    init_fn=self._scaffold.init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 272, in prepare_session
    msg))
RuntimeError: Init operations did not make model ready for local_init.  Init op: group_deps, init fn: None, error: Variables not initialized: global_step, conv1/weights, conv1/biases, conv2/weights, conv2/biases, local3/weights, local3/biases, local4/weights, local4/biases, softmax_linear/weights, softmax_linear/biases, conv1/weight_loss/avg, conv2/weight_loss/avg, local3/weight_loss/avg, local4/weight_loss/avg, softmax_linear/weight_loss/avg, cross_entropy/avg, total_loss/avg, conv1/weights/ExponentialMovingAverage, conv1/biases/ExponentialMovingAverage, conv2/weights/ExponentialMovingAverage, conv2/biases/ExponentialMovingAverage, local3/weights/ExponentialMovingAverage, local3/biases/ExponentialMovingAverage, local4/weights/ExponentialMovingAverage, local4/biases/ExponentialMovingAverage, softmax_linear/weights/ExponentialMovingAverage, softmax_linear/biases/ExponentialMovingAverage
```"
8923,Hiding the re2 symbols from libtensorflow.so,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

This recent issue [8320](https://github.com/tensorflow/tensorflow/issues/8320) is related but asked for the opposite (more symbol visibility rather than less symbol visibility).

### Environment info
Operating System: Linux

Installed version of CUDA and cuDNN: n/a

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Running the following command line on the [pre-built linux binaries](https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-1.0.0.tar.gz) returns quite a few symbols.
 objdump -T libtensorflow.so  | grep re2

It looks like libtensorflow.so is using re2 internally and exposing its symbols. This is annoying when linking with some existing code that uses a different version of re2 as it could easily result in the wrong symbol being called depending on the order of the linker flags. In my case, the re2 calls made by my code ended up using the tensorflow exposed symbols and failing because the version was different.

Maybe the visibility of the re2 symbols embedded in libtensorflow.so could be set to hidden ? (I don't know much about symbol visibility but happy to help if you think it makes sense)"
8922,Android tiny-yolo model,"I was successfully able to run tiny-yolo-voc.pb on android. However, when I tried to run tiny-yolo.pb (which is for coco dataset) generated from https://github.com/thtrieu/darkflow , the app crashes with java.nio.BufferOverflowException.

Could you please point out what needs to be changed in the code to be able to run tiny-yolo. 

Thanks"
8921,Python test failure in TF (KeyError: 'TEST_SRCDIR') on Ubuntu 16.04 ,"### Environment info: 
Operating System: Ubuntu 16.04 (ppc64le)

###Installed version of CUDA and cuDNN:  CUDA support is disabled 

###Build and test INFO
Built TF (version 1.0.1) successfully on Ubuntu 16.04 and RHEL 7.3. Now I am trying to run the python tests , but 3 tests are failing with the same error :
         [Test name:
                           1) python ./python/saved_model/saved_model_test.py
	                   2) python ./contrib/session_bundle/session_bundle_test.py
	                   3) python ./contrib/session_bundle/bundle_shim_test.py ]
##############################Error log########################################
ERROR: testMaybeSavedModelDir (__main__.SavedModelTest)
           ----------------------------------------------------------------------
          Traceback (most recent call last):
          File ""./python/saved_model/saved_model_test.py"", line 112, in testMaybeSavedModelDir
          base_path = test.test_src_dir_path(""/python/saved_model"")
          File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/test.py"", line 84, in test_src_dir_path
          return _googletest.test_src_dir_path(relative_path)
          File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/googletest.py"", line 112, in test_src_dir_path
          return os.path.join(os.environ['TEST_SRCDIR'],
          File ""/usr/lib64/python2.7/UserDict.py"", line 23, in __getitem__
          raise KeyError(key)
          KeyError: 'TEST_SRCDIR' 


Any suggestion/solution ?"
8920,problem with exemple in API documentation for tf.contrib.distributions.bijector.ScaleAndShift,"Hello

I am currently using tensorflow version 1.0.0 (from conda vanilla installation),
and I am running a snippet code fromAPI documentation :
https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/TransformedDistribution?authuser=3

I get an AttributeError which seems an accurate error since I can't seem to find ScaleAndShift on the github repo for tensorflow r1.0 


    >>> ds.TransformedDistribution(
    ...   distribution=ds.Normal(mu=0., sigma=1.),
    ...   bijector=ds.bijector.ScaleAndShift(loc=mu, scale=sigma,   event_ndims=0),
    ...   name=""NormalTransformedDistribution"")
    Traceback (most recent call last):
      File ""<stdin>"", line 3, in <module>
    AttributeError: 'module' object has no attribute 'ScaleAndShift'


"
8919,TensorFlow Windows Bazel build is failing,"http://ci.tensorflow.org/job/tf-master-win-bzl/709/console
```
ERROR: C:/jenkins/workspace/tensorflow/bazel_version/head/platform_name/windows-x86_64/tensorflow/tools/pip_package/BUILD:61:1: error loading package 'tensorflow/python': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Traceback (most recent call last):
	File ""C:/jenkins/workspace/tensorflow/bazel_version/head/platform_name/windows-x86_64/tensorflow/workspace.bzl"", line 88
		_apply_patch(repo_ctx, repo_ctx.attr.patch_file)
	File ""C:/jenkins/workspace/tensorflow/bazel_version/head/platform_name/windows-x86_64/tensorflow/workspace.bzl"", line 79, in _apply_patch
		_execute_and_check_ret_code(repo_ctx, [""patch"", ""-p1"", ""-d"", r...), <2 more arguments>])
	File ""C:/jenkins/workspace/tensorflow/bazel_version/head/platform_name/windows-x86_64/tensorflow/workspace.bzl"", line 71, in _execute_and_check_ret_code
		fail(""Non-zero return code({1}) when ..., <2 more arguments>))
Non-zero return code(256) when executing 'patch -p1 -d C:/tmp/_bazel_system/wgutbc48/external/protobuf -i C:/jenkins/workspace/tensorflow/bazel_version/head/platform_name/windows-x86_64/third_party/protobuf/add_noinlines.patch':
Stdout: 
Stderr: java.io.IOException: CreateProcess(): The system cannot find the file specified.
```
Culprit: 8d393ea2fab0ea88ecd11e36d89f186cbc884dbe
Reason: patch command is not installed in MSYS
Solution: run `pacman -Syuu --noconfirm patch`
@gunan "
8917,how to join the tf.string SparseTensor to 1-D dense tensor,"tensorflow has tf.string_split function that can split dense tensor to SparseTensor, but not provided the opposite function.

anyone knows how to do it? thanks~

for example: SparseTensor:
```
[[""a"", ""b"", ""c""]
 [""d"", ""e""]
 [""f"", ""g"", ""h"", ""i""]]
```

join SparseTensor with separator "" "" to dense tensor:
```
[""a b c"",
 ""d e"",
 ""f g h i""]
```"
8916,Cannot assign a device to node 'Variable',"### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
/usr/local/cuda-8.0/lib64/libcudadevrt.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/lib64/libcudnn.so.5
/usr/local/cuda-8.0/lib64/libcudart.so
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudnn_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0
/usr/local/cuda-8.0/lib64/libcudnn.so

Tensorflow version: 1.0.1

### If possible, provide a minimal reproducible example
with tf.device('/gpu:0'):
    a = tf.Variable([[1, 1]], tf.float32)

with tf.device('/cpu:0'):
    b = tf.Variable([[0, 0]], tf.float32)

It will get:
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'Variable': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
...

### What other attempted solutions have you tried?
with tf.device('/gpu:0'):
    a = tf.Variable([[1.0, 1.0]], tf.float32)

with tf.device('/cpu:0'):
    b = tf.Variable([[0.0, 0.0]], tf.float32)
If I change the contents of the initial value from integer to float, everything will be fine.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce 940M
major: 5 minor: 0 memoryClockRate (GHz) 1.176
pciBusID 0000:04:00.0
Total memory: 1.96GiB
Free memory: 1.60GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940M, pci bus id: 0000:04:00.0)
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce 940M, pci bus id: 0000:04:00.0
I tensorflow/core/common_runtime/direct_session.cc:257] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce 940M, pci bus id: 0000:04:00.0

Variable_1: (VariableV2): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Variable_1: (VariableV2)/job:localhost/replica:0/task:0/cpu:0
Variable_1/read: (Identity): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Variable_1/read: (Identity)/job:localhost/replica:0/task:0/cpu:0
Print_1: (Print): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Print_1: (Print)/job:localhost/replica:0/task:0/cpu:0
Variable_1/Assign: (Assign): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] Variable_1/Assign: (Assign)/job:localhost/replica:0/task:0/cpu:0
init/NoOp: (NoOp): /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:841] init/NoOp: (NoOp)/job:localhost/replica:0/task:0/cpu:0
Traceback (most recent call last):
  File ""test.py"", line 20, in <module>
    sess.run(tf.global_variables_initializer())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 767, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1015, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1035, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'Variable': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
Assign: CPU 
Identity: CPU 
VariableV2: CPU 
	 [[Node: Variable = VariableV2[container="""", dtype=DT_INT32, shape=[1,2], shared_name="""", _device=""/device:GPU:0""]()]]

Caused by op u'Variable', defined at:
  File ""test.py"", line 8, in <module>
    a = tf.Variable([[1, 1]], tf.float32)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 197, in __init__
    expected_shape=expected_shape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 293, in _init_from_args
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 128, in variable_op_v2
    shared_name=shared_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 708, in _variable_v2
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2327, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1226, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device to node 'Variable': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
Assign: CPU 
Identity: CPU 
VariableV2: CPU 
	 [[Node: Variable = VariableV2[container="""", dtype=DT_INT32, shape=[1,2], shared_name="""", _device=""/device:GPU:0""]()]]

"
8914,TensorFlow iOS apps crash at launch on iPhone 4s/iPhone 5 simulators,"Running [the simple iOS example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/ios_examples/simple) provided by this repository will crash if I target any iPhone 4s/iPhone 5 **simulator**. The app will crash immediately at launch, before entering `didFinishLaunchingWithOptions`. The last call I can identify in the debugger is usually `tensorflow::internal::LogMessageFatal::~LogMessageFatal:`.

The crashes happen on iPhone 5 simulators running iOS 10.2, 9.3, and 9.1. And on iPhone 4s simulators running iOS 9.3, 9.1, and 8.4.

I can reproduce this behavior with other TensorFlow iOS apps.

The same apps that crash in an iPhone 4s/iPhone 5 simulator, will build & run fine on other simulators & devices, _e.g._ on iPad Air simulator running 10.2, a physical iPad Air running 10.2, or physical iPhone 6s Plus running 10.2. Tests on a device farm including iPhone 4s & iPhone 5 devices were inconclusive… I’m seeing a very similar crash happen, [mostly affecting devices running 9.3.5](https://docs.google.com/spreadsheets/d/1a1Erp-KPNA5bZuin5Fokzx0rVoqr2EEFEbKSEjEVpTw/edit), but the devices/iOS combos that fail on physical devices are slightly inconsistent from run to run (in the simulator the same devices crash 100% of the time no matter what OS I use, and from run to run).

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
This [issue](https://github.com/tensorflow/tensorflow/issues/4640 ) is the only hit I get, but seems unrelated.

### Environment info
* Operating System: macOS Sierra 10.12.13
* Commit hash: b393fd79fd43242ea9be3ff3141f1809c412fd71 (master as of this writing)
* Bazel Version: 
    ```
    Build label: 0.4.3-jdk7
    Build target: bazel-out/local-    fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
    Build time: Thu Dec 22 12:31:38 2016 (1482409898)
    Build timestamp: 1482409898
    Build timestamp as int: 1482409898
    ```

### Minimal reproducible example

1. Prepare the simple iOS example provided by Tensorflow
    ```bash
    $ git clone https://github.com/tensorflow/tensorflow.git
    $ cd tensorflow
    $ tensorflow/contrib/makefile/download_dependencies.sh
    $ tensorflow/contrib/makefile/build_all_ios.sh
    $ open tensorflow/contrib/ios_examples/simple/tf_ios_makefile_example.xcodeproj
    ```
2. Download the Inception graph per the [instructions](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#ios)
3. Target the iPhone 5 simulator on iOS 10.2, and Run.
4. The app will crash before entering `didFinishLaunchingWithOptions`.
5. (If you target the iPad Air simulator on iOS 10.2, it will work.)"
8913,"Segmentation fault: 11 (Python3, Conda env, GPU)","### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I've tried importing numpy or scipy before importing tensorflow, but it does not help from [issue #2034](https://github.com/tensorflow/tensorflow/issues/2034)

### Environment info
Operating System: Max OSX 10.12.3

Installed version of CUDA and cuDNN: 
```
(bigfish) jenniferstark@Jennifers-MacBook-Pro:~/Documents/Repositories/bigfish$ brew cask info cuda
cuda: 8.0.61
https://developer.nvidia.com/cuda-zone
Not installed
From: https://github.com/caskroom/homebrew-cask/blob/master/Casks/cuda.rb
==> Name
Nvidia CUDA
==> Artifacts
(bigfish) jenniferstark@Jennifers-MacBook-Pro:~/Documents/Repositories/bigfish$ 
```
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
(bigfish) jenniferstark@Jennifers-MacBook-Pro:~/Documents/Repositories/bigfish$ ls -l /Users/jenniferstark/cuda/lib*
total 289880
lrwxr-xr-x  1 jenniferstark  staff    13B Mar  4 19:32 libcuda.1.dylib@ -> libcuda.dylib
-rwxr-xr-x@ 1 jenniferstark  staff    78M Nov  7 02:58 libcudnn.5.dylib*
lrwxr-xr-x@ 1 jenniferstark  staff    16B Nov  7 03:19 libcudnn.dylib@ -> libcudnn.5.dylib
-rw-r--r--@ 1 jenniferstark  staff    63M Nov  7 02:58 libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed: 
* https://www.tensorflow.org/versions/master/install/install_mac#NVIDIARequirements  
* Installing for Anaconda, GPU, Python3  inside a conda environment.
using command:
```
/bigfish$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.0.1-py3-none-any.whl
Collecting tensorflow-gpu==1.0.1 from https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.0.1-py3-none-any.whl
  Downloading https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.0.1-py3-none-any.whl (89.0MB)
    100% |████████████████████████████████| 89.0MB 9.7kB/s 
Collecting protobuf>=3.1.0 (from tensorflow-gpu==1.0.1)
  Using cached protobuf-3.2.0-py2.py3-none-any.whl
Collecting numpy>=1.11.0 (from tensorflow-gpu==1.0.1)
  Using cached numpy-1.12.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
Collecting six>=1.10.0 (from tensorflow-gpu==1.0.1)
  Using cached six-1.10.0-py2.py3-none-any.whl
Collecting wheel>=0.26 (from tensorflow-gpu==1.0.1)
  Using cached wheel-0.29.0-py2.py3-none-any.whl
Collecting setuptools (from protobuf>=3.1.0->tensorflow-gpu==1.0.1)
  Downloading setuptools-34.3.3-py2.py3-none-any.whl (389kB)
    100% |████████████████████████████████| 399kB 1.8MB/s 
Collecting appdirs>=1.4.0 (from setuptools->protobuf>=3.1.0->tensorflow-gpu==1.0.1)
  Using cached appdirs-1.4.3-py2.py3-none-any.whl
Collecting packaging>=16.8 (from setuptools->protobuf>=3.1.0->tensorflow-gpu==1.0.1)
  Using cached packaging-16.8-py2.py3-none-any.whl
Collecting pyparsing (from packaging>=16.8->setuptools->protobuf>=3.1.0->tensorflow-gpu==1.0.1)
  Using cached pyparsing-2.2.0-py2.py3-none-any.whl
Installing collected packages: appdirs, six, pyparsing, packaging, setuptools, protobuf, numpy, wheel, tensorflow-gpu
Successfully installed appdirs-1.4.3 numpy-1.12.1 packaging-16.8 protobuf-3.2.0 pyparsing-2.2.0 setuptools-34.3.3 six-1.10.0 tensorflow-gpu-1.0.1 wheel-0.29.0
```

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```
(bigfish) jenniferstark@Jennifers-MacBook-Pro:~/Documents/Repositories/bigfish$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.8.0.dylib locally
Segmentation fault: 11
(bigfish) jenniferstark@Jennifers-MacBook-Pro:~/Documents/Repositories/bigfish$ 
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:52:12) 
[GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy
>>> numpy.__version__
'1.12.1'
>>> import tensorflow
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.8.0.dylib locally
Segmentation fault: 11
```

### What other attempted solutions have you tried?
* Installing the equivalent version for CPU Python3 version based on [these](https://www.tensorflow.org/versions/master/install/install_mac#NVIDIARequirements  ) instructions worked fine. e.g.: 
```/bigfish$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.1-py3-none-any.whl
```
Seems like the solution for issue #2034 was for python2 and solved by using an older version of numpy, so not relevant here."
8910,regarding the ValueError: inputs must be a list of at least one Tensor with the same dtype and shape,"There is a program that defines the loss function as follows:
```
reg_loss_col = tf.GraphKeys.REGULARIZATION_LOSSES
weight_loss = tf.add_n(tf.get_collection(reg_loss_col),name='reg_loss')

```

Running the program raises the following error message

> File ""/home/ decoder/kitti_multiloss.py"", line 86, in loss
>     name='reg_loss')
>   File ""/devl /tensorflow/tf_0.12/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py"", line 1827, in add_n
>     raise ValueError(""inputs must be a list of at least one Tensor with the ""
> ValueError: inputs must be a list of at least one Tensor with the same dtype and shape
> 

I am curious how to print out the tensor information of the first parameter `tf.get_collection(reg_loss_col)` in `tf.add_n`, so that I can figure out why this cause the error."
8908,Bijectors in contrib.distributions not available,"In 1.1.0rc0 and beyond, all bijectors are moved into a subdirectory in contrib.distributions. This seems to make it unavailable?
```python
ds = tf.contrib.distributions
ds.bijectors
## Traceback (most recent call last):
##   File ""<stdin>"", line 1, in <module>
## AttributeError: 'module' object has no attribute 'bijectors'

ds.Bijector
## Traceback (most recent call last):
##   File ""<stdin>"", line 1, in <module>
## AttributeError: 'module' object has no attribute 'Bijector'
```
In my install location of `/Users/dvt/Envs/tf1.1/lib/python2.7/site-packages/tensorflow/contrib/distributions`, it seems like it would be imported, as the following line exists:
```python
from tensorflow.contrib.distributions.python.ops.bijectors import *
```
However, inspecting the `ds` submodule, no bijectors are available.
```python
ds.__dict__.keys()
## ['Deterministic', '__path__', 'QuantizedDistribution', 'softplus_inverse', 'Mixture', 'ExpRelaxedOneHotCategorical', 'ConditionalTransformedDistribution', 'Exponential', 'ConditionalDistribution', '__file__', 'StudentTWithAbsDfSoftplusScale', 'RelaxedOneHotCategorical', 'StudentT', 'ReparameterizationType', 'Categorical', 'MultivariateNormalTriL', 'VectorDeterministic', 'TransformedDistribution', 'Chi2', 'MultivariateNormalDiagPlusLowRank', '_allowed_symbols', 'Gamma', 'normal_conjugates_known_scale_predictive', '__builtins__', 'WishartFull', '__name__', 'Normal', 'ExponentialWithSoftplusRate', 'InverseGamma', 'WishartCholesky', 'Distribution', 'RelaxedBernoulli', 'Bernoulli', 'Beta', 'Binomial', '__doc__', 'BetaWithSoftplusConcentration', 'MultivariateNormalDiagWithSoftplusScale', 'NOT_REPARAMETERIZED', 'BernoulliWithSigmoidProbs', 'Laplace', 'GammaWithSoftplusConcentrationRate', 'Poisson', 'FULLY_REPARAMETERIZED', 'DirichletMultinomial', 'matrix_diag_transform', 'RegisterKL', 'InverseGammaWithSoftplusConcentrationRate', 'Uniform', 'NegativeBinomial', 'Geometric', 'LaplaceWithSoftplusScale', '__package__', 'Dirichlet', 'MultivariateNormalDiag', 'Logistic', 'Chi2WithAbsDf', 'NormalWithSoftplusScale', 'normal_conjugates_known_scale_posterior', 'kl', 'Multinomial', 'OneHotCategorical']
```
"
8905,SVD float64 NaN bug,"I've encountered a tf.float64 matrix (of size 60 x 200) such that tf.svd of it returns NaNs, while
np.linalg.svd works fine.
Converting the matrix into tf.float32 and then converting back to tf.float64 makes everything works with TF too (while being a tiny perturbation).

Here is an example Jupyter notebook: https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/mf9e2eqg2isupce/Scary%20matrix.ipynb?dl=0

You can download pickled matrix here: https://www.dropbox.com/s/b8wex6voladtgw1/scary_matrix.cPickle?dl=0

I'm using Conda Python 2.7.13 (tried on Mac and Ubuntu) and a fresh version of tensorflow from pip (tried both cpu and gpu versions)."
8904,Support Kernels for SVM,"Kernels in support vector machines are really usefull. I would like to test some object detection algorithms in tensorflow using svm and a radial basis kernel.

I am willing to help implementing kernels for support vector machines, though I am not familiar with the sdca optimization. 

Is there any design doc, or plan how to add more features to the svm estimator api?"
8903,How to change  a classification model to a regression model ? ,"I am using pre-trained Alexnet as shown below. I want to use that model for regression with 6 outputs (Xcoordinate (range (0,227),Ycoordinate (range (0,227),height (range (20,50), width (range (20,50), sine(theta), cos(theta)). (range of theta is -180 to 180 degrees)
These are the following things I change - 
1. changed loss function to MSE. 
2. changed the output layer from 1000 to 6. 
3. changed from RELU to linear activation function last layer. 
Now, I am not getting proper valued of sine and cosine above (it should be in the range of (-1 to 1)), I am getting out of bound values. What should I do, How should I keep a bound one the values. Also, should I keep a bout on other parameters as well. What should I do incorporate those changes?  
What are the other changes should I make to use this model for regression.? 

```

import tensorflow as tf
import numpy as np

class AlexNet(object):

  def __init__(self, x, keep_prob, num_classes, skip_layer,
               weights_path = 'DEFAULT'):

    # Parse input arguments into class variables
    self.X = x
    self.NUM_CLASSES = num_classes
    self.KEEP_PROB = keep_prob
    self.SKIP_LAYER = skip_layer

    if weights_path == 'DEFAULT':
      self.WEIGHTS_PATH = 'bvlc_alexnet.npy'
    else:
      self.WEIGHTS_PATH = weights_path

    # Call the create function to build the computational graph of AlexNet
    self.create()

  def create(self):

    # 1st Layer: Conv (w ReLu) -> Pool -> Lrn
    conv1 = conv(self.X, 11, 11, 96, 4, 4, padding = 'VALID', name = 'conv1')
    pool1 = max_pool(conv1, 3, 3, 2, 2, padding = 'VALID', name = 'pool1')
    norm1 = lrn(pool1, 2, 2e-05, 0.75, name = 'norm1')

        # 2nd Layer: Conv (w ReLu) -> Pool -> Lrn with 2 groups
    conv2 = conv(norm1, 5, 5, 256, 1, 1, groups = 2, name = 'conv2')
    pool2 = max_pool(conv2, 3, 3, 2, 2, padding = 'VALID', name ='pool2')
    norm2 = lrn(pool2, 2, 2e-05, 0.75, name = 'norm2')

        # 3rd Layer: Conv (w ReLu)
    conv3 = conv(norm2, 3, 3, 384, 1, 1, name = 'conv3')

        # 4th Layer: Conv (w ReLu) splitted into two groups
    conv4 = conv(conv3, 3, 3, 384, 1, 1, groups = 2, name = 'conv4')

        # 5th Layer: Conv (w ReLu) -> Pool splitted into two groups
    conv5 = conv(conv4, 3, 3, 256, 1, 1, groups = 2, name = 'conv5')
    pool5 = max_pool(conv5, 3, 3, 2, 2, padding = 'VALID', name = 'pool5')

        # 6th Layer: Flatten -> FC (w ReLu) -> Dropout
    flattened = tf.reshape(pool5, [-1, 6*6*256])
    fc6 = fc(flattened, 6*6*256, 4096, name='fc6',relu =True)
    dropout6 = dropout(fc6, self.KEEP_PROB)

        # 7th Layer: FC (w ReLu) -> Dropout
    fc7 = fc(dropout6, 4096, 4096, name = 'fc7',relu =False)
    dropout7 = dropout(fc7, self.KEEP_PROB)

        # 8th Layer: FC and return unscaled activations (for tf.nn.softmax_cross_entropy_with_logits)
    self.fc8 = fc(dropout7, 4096, self.NUM_CLASSES, relu = False, name='fc8')



  def load_initial_weights(self, session):
    """"""
    As the weights from http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/ come
    as a dict of lists (e.g. weights['conv1'] is a list) and not as dict of
    dicts (e.g. weights['conv1'] is a dict with keys 'weights' & 'biases') we
    need a special load function
    """"""

    # Load the weights into memory
    weights_dict = np.load(self.WEIGHTS_PATH, encoding = 'bytes').item()

    # Loop over all layer names stored in the weights dict
    for op_name in weights_dict:

      # Check if the layer is one of the layers that should be reinitialized
      if op_name not in self.SKIP_LAYER:

        with tf.variable_scope(op_name, reuse = True):

          # Loop over list of weights/biases and assign them to their corresponding tf variable
          for data in weights_dict[op_name]:

            # Biases
            if len(data.shape) == 1:

              var = tf.get_variable('biases', trainable = False)
              session.run(var.assign(data))

            # Weights
            else:

              var = tf.get_variable('weights', trainable = False)
              session.run(var.assign(data))



""""""
Predefine all necessary layer for the AlexNet
""""""
def conv(x, filter_height, filter_width, num_filters, stride_y, stride_x, name,
         padding='SAME', groups=1):
  """"""
  Adapted from: https://github.com/ethereon/caffe-tensorflow
  """"""
  # Get number of input channels
  input_channels = int(x.get_shape()[-1])

  # Create lambda function for the convolution
  convolve = lambda i, k: tf.nn.conv2d(i, k,
                                       strides = [1, stride_y, stride_x, 1],
                                       padding = padding)

  with tf.variable_scope(name) as scope:
    # Create tf variables for the weights and biases of the conv layer
    weights = tf.get_variable('weights', shape = [filter_height, filter_width, input_channels/groups, num_filters])
    biases = tf.get_variable('biases', shape = [num_filters])


    if groups == 1:
      conv = convolve(x, weights)

    # In the cases of multiple groups, split inputs & weights and
    else:
      # Split input and weights and convolve them separately
      #input_groups = tf.split(value=x, num_split= groups, split_dim=3)
      #input_groups = tf.split(split_dim=3, num_split= groups,value=x)
      input_groups = tf.split(axis = 3, num_or_size_splits=groups, value=x)
     # weight_groups = tf.split(value =weights, num_split=groups, split_dim=3)
      weight_groups = tf.split(axis = 3, num_or_size_splits=groups, value=weights)

      output_groups = [convolve(i, k) for i,k in zip(input_groups, weight_groups)]

      # Concat the convolved output together again
      #conv = tf.concat( values = output_groups,concat_dim = 3)
      conv = tf.concat(axis = 3, values = output_groups)


    # Add biases
    bias = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape().as_list())

    # Apply relu function
    relu = tf.nn.relu(bias, name = scope.name)

    return relu

#def fc(x, num_in, num_out, name, relu = True):
def fc(x, num_in, num_out, name, relu):
  with tf.variable_scope(name) as scope:

    # Create tf variables for the weights and biases
    weights = tf.get_variable('weights', shape=[num_in, num_out], trainable=True)
    biases = tf.get_variable('biases', [num_out], trainable=True)

    # Matrix multiply weights and inputs and add bias
    act = tf.nn.xw_plus_b(x, weights, biases, name=scope.name)

    if relu == True:
      # Apply ReLu non linearity
      relu = tf.nn.relu(act)
      return relu
    else:
      return act


def max_pool(x, filter_height, filter_width, stride_y, stride_x, name, padding='SAME'):
  return tf.nn.max_pool(x, ksize=[1, filter_height, filter_width, 1],
                        strides = [1, stride_y, stride_x, 1],
                        padding = padding, name = name)

def lrn(x, radius, alpha, beta, name, bias=1.0):
  return tf.nn.local_response_normalization(x, depth_radius = radius, alpha = alpha,
                                            beta = beta, bias = bias, name = name)

def dropout(x, keep_prob):
  return tf.nn.dropout(x, keep_prob)

```

Now the code for the loss function ad optimizer is

```
    # Op for calculating the loss
with tf.name_scope(""cross_ent""):
    loss = tf.reduce_mean(tf.squared_difference(score, y))

    # Train op
with tf.name_scope(""train""):
      # Get gradients of all trainable variables
    gradients = tf.gradients(loss, var_list)
    gradients = list(zip(gradients, var_list))

      # Create optimizer and apply gradient descent to the trainable variables
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    train_op = optimizer.apply_gradients(grads_and_vars=gradients)

``` 
Anything I should change in this part? 
Or any comments, or anything I should take care of to change the model from classifcation to regression. 
I am new to tensorflow and deep learning"
8900,ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory ,"I am trying to use tensorflow-gpu on my system. I have re-installed it many times, it gives the error give below. But when I use tensorflow-cpu it works fine. I have cuda 8.0 toolkit installed and cudnn 5.1
```
Traceback (most recent call last):
  File ""finetune.py"", line 17, in <module>
    import tensorflow as tf
  File ""/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 61, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```"
8899,da nda activate tensorflow,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
8898,Import Error  Couldn't open CUDA library libcudnn.so.5.,"

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
i was installing tensorflow  GPU version on ubuntu x86-64
but I found an error:

` >>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcudnn.so.5. LD_LIBRARY_PATH: /home/lunasdejavu/Downloads:/usr/local/cuda-8.0/lib64
I tensorflow/stream_executor/cuda/cuda_dnn.cc:3517] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally`

i tried to install again and again follow the instructions 
it is still useless.
I tried the NVIDIA_CUDA-8.0_Samples then make. no error after `all`

can somebody help me... i was working on this setting for almost 24 hours....
### Environment info
Operating System:
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) 
64 bit
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
i can't use the command

but the packages are cuda-repo-ubuntu1604-8-0-local-ga2_8.0.61-1_amd64.deb
cudnn-8.0-linux-x64-v6.0.tgz

If installed from binary pip package, provide:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 
 
1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?
i searched the manual of th
 cd <installpath>
    export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH

    Add <installpath> to your build and link process by adding -I<installpath> to your compile
    line and -L<installpath> -lcudnn to your link line.
### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
8897,outputs indifferent to input when applying `merge_duplicate_nodes`,"I think I might have located the root of #8698
It seems that `merge_duplicate_nodes` is the reason that `quantize_nodes` malfunctions.
Whatever I do, whenever I apply a `merge_duplicate_nodes` somewhere during a graph transformation, the output becomes completely indifferent to the input.

(Unfortunately) I don't get any error messages concerning this..."
8895,image_retraining/retrain.py not found,"### Environment info
Operating System: Windows 10

Installed version of CUDA and cuDNN: 

- cuda_8.0.61_win10.exe
- cudnn-8.0-windows10-x64-v5.1
I have installed tensorflow for gpu using pip install tensorflow-gpu( also downloaded the nightly for vanishing certain warnings)
- tensorflow_gpu-1.1.0rc0-cp35-cp35m-win_amd64.whl


## What am I trying to do?
I want to use the tensorflow for poets for transfer learning on my images **## ### WITHOUT USING DOCKER**
## What my problem is?
The tensorflow directory in the site-packages does not have the image_retraining folder at all.
But the **tensorflow-master-cpu on github** has examples/image_retraining. It has many other files and directories.
 
### My question is..
Can I copy and paste the tensorflow/examples/image_retraining or the tensorflow subfolder to my tensorflow folder in site-packages?
or
Do I install tensorflow for cpu ? Will the retraining work?
I don't want to use docker. Please help me @Carmezim 
"
8894,tensorflow/core/kernels/split_op.cc:159:26: error: non-constant-expression cannot be narrowed from type 'int64' (aka 'long long') to 'int' in initializer list [-Wc++11-narrowing],"Building tensorflow android error:
*  os: ubuntu16.04
* tensorflow: 1.0.1

Before error comes, I followed the tips in [android README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md)

```
 bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so \
   --crosstool_top=//external:android/crosstool \
   --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
   --cpu=armeabi-v7a

```

then I just got these error:

```
ERROR: /media/work/CodeSpace/AISpace/tensorflow/tensorflow/core/kernels/BUILD:3944:1: C++ compilation of rule '//tensorflow/core/kernels:android_tensorflow_kernels' failed: clang failed: error executing command external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -fpic -ffunction-sections ... (remaining 73 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from tensorflow/core/kernels/resize_nearest_neighbor_op.cc:20:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:4:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:152:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMap.h:242:106: error: non-constant-expression cannot be narrowed from type 'long long' to 'int' in initializer list [-Wc++11-narrowing]
        const Index index = m_dimensions.IndexOfRowMajor(array<Index, NumDims>{{firstIndex, secondIndex, otherIndices...}});
                                                                                                         ^~~~~~~~~~~~
tensorflow/core/kernels/resize_nearest_neighbor_op.cc:69:24: note: in instantiation of function template specialization 'Eigen::TensorMap<Eigen::Tensor<const int, 4, 1, int>, 16, MakePointer>::operator()<long long, int>' requested here
          std::copy_n(&input_data(b, in_y, in_x, 0), st.channels,

```
I installed android sdk and ndk via android-studio, and here is my settings in WORKSPACE:
```
android_sdk_repository(
    name = ""androidsdk"",
    api_level = 23,
    # Ensure that you have the build_tools_version below installed in the
    # SDK manager as it updates periodically.
    build_tools_version = ""25.0.2"",
    # Replace with path to Android SDK on your system
    path = ""/media/work/android/android-sdk"",
)
#
# Android NDK r12b is recommended (higher may cause issues with Bazel)
android_ndk_repository(
    name=""androidndk"",
    path=""/media/work/android/android-sdk/ndk-bundle"",
    # This needs to be 14 or higher to compile TensorFlow. 
    # Note that the NDK version is not the API level.
    api_level=14)
```

Anybody occurred this problem too? I don't know what happed.
"
8893,cuDNN 6.0 compatibility,"cuDNN v6.0 was released on Mar 23, are there any plans for adding compatibility (building against compatibility version 6000)?"
8892,Error when building Tensorflow,"When I use `bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package` to build tensorflow, I got so many unknown warnings and one error as follow.
```
ERROR: /home/jackie/.cache/bazel/_bazel_jackie/c3ef17997092dfc0d7384ef6a12887e6/external/nccl_archive/BUILD:33:1: C++ compilation of rule '@nccl_archive//:nccl' failed: clang failed: error executing command /usr/bin/clang -MD -MF bazel-out/local_linux-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/broadcast.cu.pic.d ... (remaining 56 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
clang: error: Unsupported CUDA gpu architecture: sm_61
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 162.278s, Critical Path: 35.42s
```

For more information,
```
Ubuntu 16.04
CUDA 8.0
cuDNN v5.1
GTX-1080
tensorflow-gpu-1.1
```
bazel
```
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778
```
clang
```
clang version 3.8.0-2ubuntu4 (tags/RELEASE_380/final)
Target: x86_64-pc-linux-gnu
Thread model: posix
InstalledDir: /usr/bin
Found candidate GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/5.4.0
Found candidate GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/6.0.0
Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/5.4.0
Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/6.0.0
Selected GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/5.4.0
Candidate multilib: .;@m64
Selected multilib: .;@m64
Found CUDA installation: /usr/local/cuda
```
configure
```
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 6.1
```"
8890,tensorboard shows nothing ,"I am using tensorflow 1.0.1and python 3.4
When I run my code, it shows no error. However tensorboard show that ""No graph definition files were found. ""

My tensorboard debug is as follows:

INFO:tensorflow:TensorBoard is in debug mode.
INFO:tensorflow:Starting TensorBoard in directory /home/swx/lk
**INFO:tensorflow:TensorBoard path_to_run is: {'/home/swx/lk/=': None}**
INFO:tensorflow:Event Multiplexer initializing.
INFO:tensorflow:Event Multiplexer done initializing
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: /home/swx/lk/=
INFO:tensorflow:Done with AddRunsFromDirectory: /home/swx/lk/=
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
**INFO:tensorflow:Beginning EventMultiplexer.Reload()
INFO:tensorflow:Finished with EventMultiplexer.Reload()**
INFO:tensorflow:TensorBoard done reloading. Load took 0.002 secs
INFO:tensorflow:TensorBoard is tag: b'41'



can any one offer some help?


NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link)."
8888,Tensorboard broken on latest source,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
-rw-r--r-- 1 root root   556000 Mar  4 15:04 libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mar  4 15:04 libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Mar  4 15:04 libcudart.so.8.0 -> libcudart.so.8.0.61
-rwxr-xr-x 1 root root   415432 Mar  4 15:04 libcudart.so.8.0.61
-rw-r--r-- 1 root root   775162 Mar  4 15:04 libcudart_static.a
-rwxr-xr-x 1 root root 84163560 Mar  4 15:06 libcudnn.so
-rwxr-xr-x 1 root root 84163560 Mar  4 15:06 libcudnn.so.5
-rwxr-xr-x 1 root root 84163560 Mar  4 15:06 libcudnn.so.5.1.10
-rw-r--r-- 1 root root 70364814 Mar  4 15:06 libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
9738902a46f633c10149d02584484db0b1f2626a

2. The output of `bazel version`
```
Build label: 0.4.5
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Mar 16 12:19:38 2017 (1489666778)
Build timestamp: 1489666778
Build timestamp as int: 1489666778
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
Fails with the following error.
```
Traceback (most recent call last):
  File ""/usr/local/bin/tensorboard"", line 7, in <module>
    from tensorflow.tensorboard.tensorboard import main
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py"", line 33, in <module>
    from tensorflow.tensorboard.backend import application
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/application.py"", line 47, in <module>
    from tensorflow.tensorboard.plugins.projector import projector_plugin
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/projector/projector_plugin.py"", line 30, in <module>
    from tensorflow.contrib.tensorboard.plugins.projector import projector_config_pb2
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py"", line 59, in <module>
    from tensorflow.contrib import tensorboard
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/__init__.py"", line 22, in <module>
ragha@ragha-gpu:~/dsb-2017$ tensorboard
Traceback (most recent call last):
  File ""/usr/local/bin/tensorboard"", line 7, in <module>
    from tensorflow.tensorboard.tensorboard import main
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py"", line 33, in <module>
    from tensorflow.tensorboard.backend import application
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/application.py"", line 47, in <module>
    from tensorflow.tensorboard.plugins.projector import projector_plugin
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/projector/projector_plugin.py"", line 30, in <module>
    from tensorflow.contrib.tensorboard.plugins.projector import projector_config_pb2
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py"", line 59, in <module>
    from tensorflow.contrib import tensorboard
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/__init__.py"", line 22, in <module>
    from tensorflow.contrib.tensorboard import plugins
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/plugins/__init__.py"", line 22, in <module>
    from tensorflow.contrib.tensorboard.plugins import projector
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/plugins/projector/__init__.py"", line 34, in <module>
    from tensorflow.tensorboard.plugins.projector import projector_plugin
ImportError: cannot import name projector_plugin
```"
8887,Embedding visualizations for hi-res images training (feature request),"Hi Tensorflow people, thank you all.
I wonder if I could train my image classification model on my normal sized images (1080px X 1920px) but still use Tensorboard's cool embedding visualizations. I prefer to keep the images with the highest resolution possible since it proved to be important for the classification.

In the tutorial (https://www.tensorflow.org/get_started/embedding_viz) the developers specify tensorflow currently supports sprites up to 8192px X 8192px, meaning you can either use a lot of low-res images (fine for MNIST 28X28 and CIFAR-10 32X32) or a few high-res images (a too small training set size). So, I was wondering if there could be a way around it.

**What if, we could use full-res photos for training, but downsize them for the thumbnails needed to make up the sprite?**
That way we could still get a sense of which picture is which in the visualization, but let the model train on higher quality data.

1. Can I do it myself, by creating a low-res (down-sized) copy of my entire database beforehand, and use it to create the sprite etc., will the embedding event still correlate to the same source image (and the right label in the metadata)?
2. Instead, should I put inside the training code itself, a small procedure for resizing of the full-res image after each bottleneck calculation, and then store that thumbnail in a separate folder - making sure the embedding log in the metadata actually corresponds to the right thumbnail?

***************************************
Environment info:

Ubuntu 16.04.02 (64 bit)
tensorflow 0.12.1 CPU only (64 bit). I have a NVIDIA GTX 1050ti waiting to be used if crucial for this task.

I'm am a kind of a coding noob so forgive my inaccuracies and ignorance. I'm relatively new (6 months) to tensorflow and CNNs in general. I've been transfer-training inception V3 on classification of large (1080px X 1920px) images, divided to 10 labels (folders). 
The reason I'm asking and not just diving deep into it is that I'll have to spend a lot of time to resize my images and create the perfect sprite image and metadata file, but won't have the confidence that the trained data corresponds to the sprite image. So I want to see if it's even possible to begin with - **to get full certainty of visualized thumbnail corresponding to actual full-res image used for training.**

Thank you for this great platform!! Tensorboard is a very powerful tool and I'm very excited to unlock the embedding visualizations' potential. @dandelionmane
"
8884,8-bit quantized atrous conv2d op not supported,"It looks like that 8-bit quantized atrous conv2d op is not supported. As per the latest API,  there are only 4 quantized ops supported namely quantized_conv2d, quantized_relu_x, quantized_max_pool and quantized_avg_pool.  Any target date by which 8-bit atrous conv2d op will be available?


"
8879,could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR,"Hi,
I installed tensorflow 1.0.1 GPU version on my Macbook Pro with GeForce GT 750M. Also installed CUDA 8.0.71 and cuDNN 5.1. I am running  a tf code that works fine with non CPU tensorflow but on GPU version , I get this error (once a while it works too).

I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
E tensorflow/stream_executor/cuda/cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
F tensorflow/core/kernels/conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)

What is happening here? Is there a bug in tensorflow. Please advise.

Thanks
"
8878,contrib.learn.Estimators needs updating to summary.scalar,"### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   556000 Mar 27 15:57 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Mar 27 15:57 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Mar 27 15:57 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
-rwxr-xr-x 1 root root   415432 Mar 27 15:57 /usr/local/cuda/lib64/libcudart.so.8.0.61
-rw-r--r-- 1 root root   775162 Mar 27 15:57 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Mar 30 20:42 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       18 Mar 30 20:42 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10
-rwxr-xr-x 1 root root 84163560 Mar 30 20:42 /usr/local/cuda/lib64/libcudnn.so.5.1.10
-rw-r--r-- 1 root root 70364814 Mar 30 20:42 /usr/local/cuda/lib64/libcudnn_static.a
```

git rev ersion
```
ddef51c1c93f66989ac7a88b88b89f5b2a9df599
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Using the example at https://www.tensorflow.org/get_started/tflearn triggers the warning

### What other attempted solutions have you tried?
I'll make a PR for this
"
8877,nvidia-smi: No running processes found     ,"I'm running Ubuntu 14.04 LTS on AWS g2.2xlarge


$ python neural_gpu_trainer.py --problem=bmul
 
...

modprobe: ERROR: could not insert 'nvidia_375_uvm': Invalid argument
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
http://stackoverflow.com/questions/33970755/tensorflow-not-using-gpu

### Environment info
Operating System:
Ubuntu 14.04 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 179466 Mar 27 16:01 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Mar 27 16:01 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.0
lrwxrwxrwx 1 root root     19 Mar 27 16:01 /usr/local/cuda/lib/libcudart.so.7.0 -> libcudart.so.7.0.28
-rwxr-xr-x 1 root root 303052 Mar 27 16:01 /usr/local/cuda/lib/libcudart.so.7.0.28
-rw-r--r-- 1 root root 546514 Mar 27 16:01 /usr/local/cuda/lib/libcudart_static.a


If installed from binary pip package, provide:
$ conda install -c jjh_cio_testing tensorflow-gpu

1. A link to the pip package you installed:

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
ubuntu@ip-10-0-1-131:~/cuda/lib64$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.7.5 locally
1.0.1

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
ubuntu@ip-10-0-1-131:~/models/neural_gpu$ python neural_gpu_trainer.py --problem=bmul
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.7.5 locally
Generating data for bmul.
cut 1.20 lr 0.100 iw 0.80 cr 0.30 nm 64 d0.1000 gn 4.00 layers 2 kw 3 h 4 kh 3 batch 32 noise 0.00
Creating model.
Creating backward pass for the model.
WARNING:tensorflow:Tried to colocate gpu0/gradients/gpu0/Gather_2_grad/Shape with an op target_embedding/read that had a different device: /device:GPU:0 vs /device:CPU:0. Ignoring colocation property.
Created model for gpu 0 in 6.46 s.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
modprobe: ERROR: could not insert 'nvidia_375_uvm': Invalid argument
E tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: ip-10-0-1-131
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: ip-10-0-1-131
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 346.46.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:363] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  346.46  Tue Feb 17 17:56:08 PST 2015
GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: 346.46.0
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:300] kernel version seems to match DSO: 346.46.0
Created model. Checkpoint dir /tmp/neural_gpu
Reading model parameters from /tmp/neural_gpu/neural_gpu.ckpt-500
step 600 step-time 1.15 train-size 0.051 lr 0.100000 grad-norm 1.3013 len 6 ppl 1.335808 errors 29.08 sequence-errors 23.34
  bin 0 (2)	bmul	ppl 1.08 errors 0.00 seq-errors 0.00
  bin 1 (3)	bmul	ppl 1.07 errors 0.00 seq-errors 0.00
  bin 2 (4)	bmul	ppl NA errors NA seq-errors NA
  bin 3 (5)	bmul	ppl 1.14 errors 2.90 seq-errors 5.47
  bin 4 (6)	bmul	ppl NA errors NA seq-errors NA
  bin 7 (9)	bmul	ppl 1.67 errors 23.42 seq-errors 61.72
  bin 10 (12)	bmul	ppl NA errors NA seq-errors NA
  bin 13 (15)	bmul	ppl 1.94 errors 36.26 seq-errors 96.88
  bin 16 (18)	bmul	ppl NA errors NA seq-errors NA
  bin 19 (21)	bmul	ppl 2.07 errors 41.34 seq-errors 100.00
  bin 22 (24)	bmul	ppl NA errors NA seq-errors NA
  bin 25 (27)	bmul	ppl 2.11 errors 44.47 seq-errors 100.00
  bin 28 (30)	bmul	ppl NA errors NA seq-errors NA
  bin 31 (33)	bmul	ppl 2.14 errors 44.22 seq-errors 100.00
  bin 34 (36)	bmul	ppl NA errors NA seq-errors NA
  bin 37 (39)	bmul	ppl 2.16 errors 46.27 seq-errors 100.00
  bin 40 (42)	bmul	ppl NA errors NA seq-errors NA
  bin 43 (45)	bmul	ppl 2.17 errors 45.92 seq-errors 100.00
  bin 46 (48)	bmul	ppl NA errors NA seq-errors NA
step 700 step-time 1.04 train-size 0.051 lr 0.100000 grad-norm 1.2822 len 7 ppl 1.305894 errors 24.70 sequence-errors 20.28
  bin 0 (2)	bmul	ppl 1.08 errors 0.00 seq-errors 0.00
  bin 1 (3)	bmul	ppl 1.07 errors 0.00 seq-errors 0.00
  bin 2 (4)	bmul	ppl NA errors NA seq-errors NA
  bin 3 (5)	bmul	ppl 1.09 errors 0.00 seq-errors 0.00
  bin 4 (6)	bmul	ppl NA errors NA seq-errors NA
  bin 7 (9)	bmul	ppl 1.65 errors 25.41 seq-errors 59.38
  bin 10 (12)	bmul	ppl NA errors NA seq-errors NA
  bin 13 (15)	bmul	ppl 1.94 errors 35.41 seq-errors 100.00
  bin 16 (18)	bmul	ppl NA errors NA seq-errors NA
  bin 19 (21)	bmul	ppl 2.08 errors 42.48 seq-errors 100.00
  bin 22 (24)	bmul	ppl NA errors NA seq-errors NA
  bin 25 (27)	bmul	ppl 2.14 errors 44.49 seq-errors 100.00
  bin 28 (30)	bmul	ppl NA errors NA seq-errors NA
  bin 31 (33)	bmul	ppl 2.16 errors 46.73 seq-errors 100.00
  bin 34 (36)	bmul	ppl NA errors NA seq-errors NA
  bin 37 (39)	bmul	ppl 2.20 errors 47.76 seq-errors 100.00
  bin 40 (42)	bmul	ppl NA errors NA seq-errors NA
  bin 43 (45)	bmul	ppl 2.22 errors 49.13 seq-errors 100.00
  bin 46 (48)	bmul	ppl NA errors NA seq-errors NA
step 800 step-time 1.64 train-size 0.051 lr 0.100000 grad-norm 1.3836 len 8 ppl 1.393354 errors 30.55 sequence-errors 30.53
  bin 0 (2)	bmul	ppl 1.08 errors 0.00 seq-errors 0.00
  bin 1 (3)	bmul	ppl 1.08 errors 0.00 seq-errors 0.00
  bin 2 (4)	bmul	ppl NA errors NA seq-errors NA
  bin 3 (5)	bmul	ppl 1.11 errors 0.00 seq-errors 0.00
  bin 4 (6)	bmul	ppl NA errors NA seq-errors NA
  bin 7 (9)	bmul	ppl 1.65 errors 23.67 seq-errors 63.28
  bin 10 (12)	bmul	ppl NA errors NA seq-errors NA
  bin 13 (15)	bmul	ppl 1.91 errors 37.00 seq-errors 97.66
  bin 16 (18)	bmul	ppl NA errors NA seq-errors NA
  bin 19 (21)	bmul	ppl 2.07 errors 43.81 seq-errors 100.00
  bin 22 (24)	bmul	ppl NA errors NA seq-errors NA
  bin 25 (27)	bmul	ppl 2.10 errors 44.66 seq-errors 100.00
  bin 28 (30)	bmul	ppl NA errors NA seq-errors NA
  bin 31 (33)	bmul	ppl 2.13 errors 45.06 seq-errors 100.00
  bin 34 (36)	bmul	ppl NA errors NA seq-errors NA
  bin 37 (39)	bmul	ppl 2.16 errors 45.51 seq-errors 100.00
  bin 40 (42)	bmul	ppl NA errors NA seq-errors NA
  bin 43 (45)	bmul	ppl 2.21 errors 47.88 seq-errors 100.00
  bin 46 (48)	bmul	ppl NA errors NA seq-errors NA

```

### What other attempted solutions have you tried?
```
ubuntu@ip-10-0-1-131:~/cuda/lib64$ nvidia-smi
Fri Mar 31 17:22:46 2017       
+------------------------------------------------------+                       
| NVIDIA-SMI 346.46     Driver Version: 346.46         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |
| N/A   37C    P0    35W / 125W |     10MiB /  4095MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+--------------------------------------------
### Logs or other output that would be helpful

```
(If logs are large, please upload as attachment or provide link).
"
8876,DNNClassifier init failed TypeError,"Following the tutorial, when I define the classifier:

classifier = skflow.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3)

it triggers the following error:

init() takes at least 3 arguments (3 given)"
8873,Arbitrary dimension support for tf.tile and binary operators,"`tf.transpose` uses template specialization for dimensions <= 5, then falls back to a slightly slower generic implementation which works for any dimension:

https://github.com/tensorflow/tensorflow/blob/504b91de8fa9a9cc4a4e17e59ed753ab677a1410/tensorflow/core/kernels/transpose_functor_cpu.cc#L23

It would be nice to use the same mechanism for `tf.tile` and the various binary operators."
8872,Tensorboard showing problems under keras callbacks,"
My code runs well without any errors showing. However, when I use the command 
tensorboard --logdir = ""my path"", it shows nothing. I want someone to help me! Thanks.

tensorflow 1.0.1 keras 2.0  and python 3.4

And I found the debug shows:

```
INFO:tensorflow:TensorBoard is in debug mode.
INFO:tensorflow:Starting TensorBoard in directory /home/lk/lk
INFO:tensorflow:TensorBoard path_to_run is: {'/home/lk/lk/=': None}
INFO:tensorflow:Event Multiplexer initializing.
INFO:tensorflow:Event Multiplexer done initializing
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: /home/lk/lk/=
INFO:tensorflow:Done with AddRunsFromDirectory: /home/lk/lk/=
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
_INFO:tensorflow:Beginning EventMultiplexer.Reload()
INFO:tensorflow:Finished with EventMultiplexer.Reload()_
INFO:tensorflow:TensorBoard done reloading. Load took 0.002 secs
INFO:tensorflow:TensorBoard is tag: b'41'
Starting TensorBoard b'41' on port 6006
(You can navigate to http://127.0.1.1:6006)

```
of which between INFO:tensorflow:Beginning EventMultiplexer.Reload() and INFO:tensorflow:Finished with EventMultiplexer.Reload(). There is no debuging information. "
8871,text_classification.py doesn't works ," ....

  File ""C:\Users\danie\Anaconda3\lib\site-packages\tensorflow\contrib\layers\python\ops\sparse_feature_cross_op.py"", line 21, in <module>
    from tensorflow.contrib.framework import deprecated_arg_values
    ImportError: cannot import name 'deprecated_arg_values'

I'm using Spider.



  "
8870,Bugs when dequeue a 3-D input tensor from FIFOQueue,"```python
x = tf.random_normal([time_length, batch_size, feature_size], mean=0, stddev=1)
## prepare data
q = tf.FIFOQueue(capacity=4, dtypes=tf.float32) 
enqueue_op = q.enqueue(x)
num_threads = 1 
qr = tf.train.QueueRunner(q, [enqueue_op] * num_threads)
tf.train.add_queue_runner(qr)
inputs = q.dequeue() 
```
As above code shows, when I use FIFOQueue and Cordinator to do input pipeline, the input is a 3-D tensor variable, but when I dequeue it from the FIFOQueue, errors comes:
```python
ValueError: as_list() is not defined on an unknown TensorShape.
```

Thus, I go to the source code of FIFOQueue, I found that FIFOQueue.enqueue method doesn't use a shape function. So, I add a line of code as following, it works well.
```python
x = tf.random_normal([time_length, batch_size, feature_size], mean=0, stddev=1)

## prepare data
q = tf.FIFOQueue(capacity=4, dtypes=tf.float32) 
enqueue_op = q.enqueue(x)
num_threads = 1 
qr = tf.train.QueueRunner(q, [enqueue_op] * num_threads)
tf.train.add_queue_runner(qr)
inputs = q.dequeue() 
inputs.set_shape(x.get_shape())
```

But if I change my input from 3-D tensor into 2-D tensor, the code runs very well without set_shape function manually. So I want to know why my 3-D input tensor can't work well but 2-D tensor input work well? Can the source code of FIFOQueue or QueueBase support shape function? "
8866,"How to print and write ""Predictions"" into a file?","```python
    predictions = tf.argmax(logits, 1) ######this predictions!!!!!!!!!!!!!!
    labels = tf.squeeze(labels)

    # Define the metrics:
    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({
        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),
        'Predictions': slim.metrics.streaming_precision(predictions, labels),
        'Recall@5': slim.metrics.streaming_recall_at_k(
            logits, labels, 5)
    })

    # Print the summaries to screen.
    for name, value in names_to_values.iteritems():
      summary_name = 'eval/%s' % name
      op = tf.summary.scalar(summary_name, value, collections=[])
      op = tf.Print(op, [value], summary_name)
      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)
```
I try lots of ways, but I fail to print or write ""predictions"".
I want to print  the test results(""predictions"")  of a model and write it into aaa.txt, and how?

THANKS."
8865,[FeatureRequest] Decode gzipped files in tf.FixedLengthRecordReader,"My dataset is stored in binary format that is easily compressible (from 100 MB down to ~0.5 MB), but I currently cannot make use of this in TF, unless I write a TFRecords file, which is way more cumbersome and leads to a lot of duplication -- I need to work with those files in other programs as well, so the binary format is the easiest solution for me. It would be nice if  tf.FixedLengthRecordReader would support on-the-fly decompression."
8861,How can i export model into HDFS,"The issue have beed submitted in [#381](https://github.com/tensorflow/serving/issues/381), thanks all kind of you"
