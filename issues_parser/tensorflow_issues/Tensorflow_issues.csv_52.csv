Issue Number,Issue Title,Issue Body
20188,there is no idct implementation in tensorflow,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: b'v1.8.0-0-g93bc2e2072' 1.8.0
- **Python version**:  3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  9.0
- **GPU model and memory**: GTX 780 6G
- **Exact command to reproduce**: none

### Describe the problem
We have tf.spectral.dct but no tf.spectral.idct.
What's wrong?

### Source code / logs
None"
20187,SetNumThreads() with float models has no observable effect in TFLite,"### Describe the problem
When running (a slightly tweaked version of) the example code in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md, I noticed that no matter what `interpreter->SetNumThreads()` is called with, it __only__ creates (and uses) 4 threads. The only exception is when I set it to 1, in which case the main thread is used. CPU usage is never at or near 100%.

Here's the code I'm running:
```c++
#include <tensorflow/contrib/lite/kernels/register.h>
#include <tensorflow/contrib/lite/model.h>
#include <memory>

int main()
{
	std::unique_ptr<tflite::FlatBufferModel> model =
		tflite::FlatBufferModel::BuildFromFile(""model.tflite"");

	tflite::ops::builtin::BuiltinOpResolver resolver;
	std::unique_ptr<tflite::Interpreter> interpreter;
	tflite::InterpreterBuilder(*model, resolver)(&interpreter);

	interpreter->SetNumThreads(8);
	interpreter->AllocateTensors();

	while (true)
		interpreter->Invoke();
}
```

Tensorflow Lite is built with `make -f tensorflow/contrib/lite/Makefile`, from branch r1.9.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.9.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.14.1
- **GCC/Compiler version (if compiling from source)**: 8.1.1
- **CUDA/cuDNN version**: CPU only
- **GPU model and memory**: CPU only
- **Exact command to reproduce**: (Build the C++ example in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md)"
20177,Tensorflow won't compile on windows c++,"when I try to compile tensorflow master on windows10 with vs2015, I got below errors after compiling for half an hour.

""D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj"" (default target) (1) ->
""D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\array_ops_gen_cc.vcxproj"" (default target) (2) ->
""D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\tf_array_ops.vcxproj"" (default target) (3) ->
""D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj"" (default target) (4) ->
(CustomBuild target) -> 
  C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: ""cmd.exe"" exited with code 3. [D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj]


""D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj"" (default target) (1) ->
""D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\force_rebuild_target.vcxproj"" (default target) (81) ->
  C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: ""cmd.exe"" exited with code 3. [D:\Documents\GitHub\tensorflow\tensorflow\contrib\cmake\build\force_rebuild_target.vcxproj]

    148 Warning(s)
    2 Error(s)

Attached please find the full log
Thanks for your help!
[msbuild.log](https://github.com/tensorflow/tensorflow/files/2122908/msbuild.log
"
20176,Mobilenet V2 SSDLite inference test with Android,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS Sierra version 10.12.6
- **TensorFlow installed from (source or binary)**:
from source
- **TensorFlow version (use command below)**:
1.8.0 to train and 1.9.0 to build the inference library
- **Python version**: 
3.6.5
- **Bazel version (if compiling from source)**:
0.13.0
- **GCC/Compiler version (if compiling from source)**:
GCC 4.2.1
- **CUDA/cuDNN version**:
using CPU only
- **GPU model and memory**:
using CPU only
- **Exact command to reproduce**:
command to create the appropriate Ops for the Mobilenet V2 SSDLlite (since the default Ops are not enough to make it work on Android) :
```
 bazel build tensorflow/python/tools:print_selective_registration_header && \
 bazel-bin/tensorflow/python/tools/print_selective_registration_header \
  --graphs=path/to/graph.pb > ops_to_register.h 
```

command to build `tensorflow_inference.so` (I build it for all possible CPU types): 
```
      bazel build -c opt --copt=""-DSELECTIVE_REGISTRATION"" \
    --copt=""-DSUPPORT_SELECTIVE_REGISTRATION"" \
    //tensorflow/contrib/android:libtensorflow_inference.so \
    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain \
    --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a 
```
command to optimize the graph for inference : 
```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=$DETECT_PB \
--out_graph=$STRIPPED_PB \
--inputs='image_tensor' \
--outputs='detection_boxes,detection_scores,detection_classes,num_detections' \
--transforms='
  strip_unused_nodes(type=float, shape=""1,300,300,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms'
```
### Describe the problem
I'm working with the Object Detection Demo for android and I'm using my custom trained model (used Mobilenet V1 SSD for the training part) and everything works as expected. As the Tensorflow team released the Mobilenet V2 SSDLite (supposed to be 35% faster than the V1 SSD version) I wanted to give it a try and retrained my model. I optimized the graph for inference and tested it but I was disappointed with the results. 

**Test device Pixel 2 :** 

Mobilenet V2 SSDLite
- nodes observed : 1185
- inference time : around 1200ms  

Mobilenet V1 SSD 
- nodes observed : 893
- inference time : around 300ms

Instead of adding the Tensorflow dependency in my Gradle I'm using the latest stable Nightly build for both test use cases but when testing with the V2 model I replace the `libtensorflow_inference.so` with the manually built one.

any idea why I'm getting these results ?
"
20175,Where should I learn C++ API？,"Hello, where should I learn C++ API， Where is the TensorFlow C++ detailed manual ? How Could Learn Train Code. There are a lot python code , but Few C++ code for reference or learn."
20174,Checking of layer objects in seq2seq modules,"Currently the modules in seq2seq checks the layers as an instance of tensorflow.python.layers.base.Layer. However, the docstrings says that it is a legacy and that one must inherit the keras layers directly (The tensorflow base layer also inherits this keras layers). I might it might be better if it checks for the keras one instead of the tensorflow one."
20173,Importing error with tensorflow1.8.0 and protobuf 3.6.0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary pip
- **TensorFlow version (use command below)**:1.8
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0 / 7.0
- **GPU model and memory**: GeForce GTX 1080Ti 11GB
- **Exact command to reproduce**: import tensorflow as tf


### Problem description
Importing tensorflow gives me following error. This error is only reproducible in a file where a computational graph is defined.
```
KeyError: ""Couldn't find field google.protobuf.FileOptions.php_metadata_namespace""
```

### Solution
I already found a solution to this problem. It is related to the pip package protobuf 3.6.0. I solved this problem by issuing following commands:
```
pip3 uninstall protobuf
pip3 install protobuf==3.5.2
```"
20170,bundled jsoncpp version is ancient and has a security issue,"When I was going through the dependencies in workspace.bzl, I noticed that the bundled version of jsoncpp is super old. it points to https://github.com/open-source-parsers/jsoncpp/commit/11086dd6a7eba04289944367ca82cea71299ed70 which is from 2014. ie before version 0.7.0.

Some quick searching also turned up these security issues:
https://github.com/open-source-parsers/jsoncpp/issues/88
https://github.com/open-source-parsers/jsoncpp/issues/56
which were fixed only in 0.8.0 at the earliest. Looks like an unbounded stack overflow; I have not looked much into the specifics but a security issue is a security issue so this should be fixed ASAP.

https://github.com/open-source-parsers/jsoncpp/releases
As of right now the latest version is 1.8.4. When I tried unbundling jsoncpp, using 1.8.4 failed to compile so there is some API change that will need porting too. There appear to have been a few soversion bumps along the way so probably best off to skip straight to the latest 1.8.4.

I'm filing this dep separately since its a high priority, I will follow up with notes on other not-up-to-date dependencies later on. @martinwicke @gunan @ewilderj "
20169,E1101:Module 'tensorflow.tools.api.generator.api.contrib' has no 'lite' member even though i'm using version 1.8.0,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
20168,"Exception in thread ""main"" java.lang.UnsatisfiedLinkError: C:\Users\Luke\AppData\Local\Temp\tensorflow_native_libraries-1529547871141-0\tensorflow_jni.dll:  ­U","I have search on SO what could be the reason why i am having this issue, but have not reached on the right answer. 
My System Info:
Windows 7 6bit
Jdk 8u111

I have created a Maven Project and added dependencies  for tensorflow 
`	<dependency>
		<groupId>org.tensorflow</groupId>
		<artifactId>tensorflow</artifactId>
		<version>1.8.0</version>
	</dependency>   
		<dependency>
		    <groupId>org.tensorflow</groupId>
		    <artifactId>libtensorflow_jni</artifactId>
		    <version>1.8.0</version>
     </dependency>`

and when i clean and build the application
i run the program
`  public static void main(String[] args) throws Exception {

    try (Graph g = new Graph()) {

      final String value = ""Hello from "" + TensorFlow.version();

      // Construct the computation graph with a single operation, a constant

      // named ""MyConst"" with a value ""value"".

      try (Tensor t = Tensor.create(value.getBytes(""UTF-8""))) {

        // The Java API doesn't yet include convenience functions for adding operations.

        g.opBuilder(""Const"", ""MyConst"").setAttr(""dtype"", t.dataType()).setAttr(""value"", t).build();

      }

      // Execute the ""MyConst"" operation in a Session.

      try (Session s = new Session(g);

           Tensor output = s.runner().fetch(""MyConst"").run().get(0)) {

        System.out.println(new String(output.bytesValue(), ""UTF-8""));

      }

    }

  }`
the error i am having is this:
`Exception in thread ""main"" java.lang.UnsatisfiedLinkError: C:\Users\Luke\AppData\Local\Temp\tensorflow_native_libraries-1529547871141-0\tensorflow_jni.dll:  ­U`"
20167,Improvements to the 1st tutorial ,"Regarding the very first tutorial: https://www.tensorflow.org/get_started/eager

You should add the import: 

import tensorflow.contrib.eager as tfe;

and change the types for example_default to:

example_defaults = [[0.], [0.], [0.], [0.], [0]]  # set field types (the labels are integers: https://stackoverflow.com/questions/50184145/tensorflow-sparsesoftmaxcrossentropywithlogits-error)
"
20162,Improper attribution for GPLv3 in non-existent directory,"### Describe the problem
You are declaring GPLv3 attribution at https://github.com/tensorflow/tensorflow/blob/v1.8.0/third_party/eigen3/LICENSE#L1011 for a directory that you have removed. The license attributed is also improperly identified as GPLv3 but instead should be GPLv2 as per Eigen's own repo, https://github.com/eigenteam/eigen-git-mirror/blob/master/bench/btl/COPYING.
The later isn't of much concern since you already removed the directory, but the former shows that you need to update your attribution to correctly reflect what is in the package. Thanks!"
20160,TF Debug Session Wrapper has no attribute '_make_callable_from_options',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 18
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
v1.8.0-3410-g79d7e11f3e, 1.10.0-dev20180616
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
CUDA 9.0, cuDNN 7.0
- **GPU model and memory**:
NVIDIA GeForce 1080
- **Exact command to reproduce**:
Running the provided script should produce the error. The attached file shows the output.

### Describe the problem
It's not possible to debug Keras models since `BaseDebugWrapperSession` in `tensorflow/python/debug/wrappers/framework.py` does not implement the `_make_callable_from_options` method.

### Source code / logs
- **Script**:
```python
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.python import debug as tf_debug


inputs = np.zeros((10, 3))
targets = np.zeros((10, 4))
dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))
dataset = dataset.repeat(100)
dataset = dataset.batch(5)

with tf_debug.LocalCLIDebugWrapperSession(tf.Session()) as sess:
    keras.backend.set_session(sess)

    x = keras.layers.Input(shape=(3,), name='input')
    flat = keras.layers.Flatten()(x)
    y = keras.layers.Dense(4, name='dense')(flat)

    model = keras.Model(x, y)
    model.compile(loss='mse', optimizer='rmsprop')

    model.fit(dataset, epochs=1, steps_per_epoch=2, verbose=1)
```
- **Output**:
[tfdbg_output.txt](https://github.com/tensorflow/tensorflow/files/2120950/tfdbg_output.txt)
"
20158,Feature Request: Initialize tables when passing a Dataset as input to a Keras model,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 18
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
v1.8.0-3410-g79d7e11f3e, 1.10.0-dev20180616
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
CUDA 9.0, cuDNN 7.0
- **GPU model and memory**:
NVIDIA GeForce 1080
- **Exact command to reproduce**:
Running the provided script should produce this error.

### Describe the problem
tf.keras.Model will throw a `FailedPreconditionError: Table not initialized.` error when passing a Dataset that includes a lookup table to Model.fit(). This can be worked around by creating a Session and running `tf.tables_initializer()` and `keras.backend.set_session`, but it would be nice if Keras could check for tables and initialize them automatically.

### Source code / logs
- **Script**:
```python
import tensorflow as tf
import numpy as np
from tensorflow.python.ops import lookup_ops
from tensorflow import keras

alphabet = ['A', 'B', 'C']
table = lookup_ops.index_table_from_tensor(tf.constant(alphabet))
# generate samples of strings of different lengths
inputs = [''.join([np.random.choice(alphabet) for _ in range(5)]) for _ in range(10)]
targets = np.zeros((10, 4))

dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))
def map_fn(x, y):
    x = tf.string_split([x], delimiter="""").values
    x = table.lookup(x)
    x = tf.nn.embedding_lookup(tf.eye(3), x)
    return x, y
dataset = dataset.map(lambda x, y: map_fn(x, y))
dataset = dataset.repeat(100)
dataset = dataset.batch(5)

x = keras.layers.Input(shape=(5, 3), name='input')
flat = keras.layers.Flatten()(x)
y = keras.layers.Dense(4, name='dense')(flat)

model = keras.Model(x, y)
model.compile(loss='mse', optimizer='rmsprop')

model.fit(dataset, epochs=1, steps_per_epoch=2, verbose=1)
```

- **Output**:
```bash
Script started on 2018-06-20 16:09:12-0400
dillon@dillon-linux:~/github/dillondaudert$ python keras_table_init_ex.py 
2018-06-20 16:09:20.610136: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-06-20 16:09:20.717933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:883] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-06-20 16:09:20.718316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8475
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.17GiB
2018-06-20 16:09:20.788286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:883] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-06-20 16:09:20.788649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 1 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8475
pciBusID: 0000:02:00.0
totalMemory: 7.93GiB freeMemory: 7.81GiB
2018-06-20 16:09:20.789264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0, 1
2018-06-20 16:09:21.112863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-20 16:09:21.112890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 1 
2018-06-20 16:09:21.112895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N Y 
2018-06-20 16:09:21.112899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 1:   Y N 
2018-06-20 16:09:21.113086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6917 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-06-20 16:09:21.169182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7537 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1)
Epoch 1/1
2018-06-20 16:09:21.490711: W tensorflow/core/framework/op_kernel.cc:1328] OP_REQUIRES failed at lookup_table_op.cc:675 : Failed precondition: Table not initialized.
Traceback (most recent call last):
  File ""keras_table_init_ex.py"", line 29, in <module>
    model.fit(dataset, epochs=1, steps_per_epoch=2, verbose=1)
  File ""/home/dillon/.conda/envs/tf1.10-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1353, in fit
    validation_steps=validation_steps)
  File ""/home/dillon/.conda/envs/tf1.10-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 195, in fit_loop
    outs = f(ins)
  File ""/home/dillon/.conda/envs/tf1.10-nightly/lib/python3.6/site-packages/tensorflow/python/keras/backend.py"", line 2897, in __call__
    fetched = self._callable_fn(*array_vals)
  File ""/home/dillon/.conda/envs/tf1.10-nightly/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1382, in __call__
    run_metadata_ptr)
  File ""/home/dillon/.conda/envs/tf1.10-nightly/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 519, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.FailedPreconditionError: Table not initialized.
	 [[Node: hash_table_Lookup = LookupTableFindV2[Tin=DT_STRING, Tout=DT_INT64](hash_table_lookup_placeholder, StringSplit:1, hash_table_lookup_placeholder_1)]]
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,3], [?,4]], output_types=[DT_FLOAT, DT_DOUBLE], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
	 [[Node: IteratorGetNext/_17 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_IteratorGetNext"", tensor_type=DT_DOUBLE, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
dillon@dillon-linux:~/github/dillondaudert$ exit
exit

Script done on 2018-06-20 16:09:29-0400
```
"
20157,TensorRT integration doesn't optimize conv2d_transpose,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source. Build toward TensorRT 3.0.4.
- **TensorFlow version (use command below)**:
1.7
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.11.1
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
CUDA 9.0, cuDNN 7.1.4
- **GPU model and memory**:
NVIDIA 1080 Ti
- **Exact command to reproduce**:
First train a example model use [mnist_conv_deconv.py](https://gist.github.com/qinyao-he/573254f8e225a09114b7408cc1c984aa)
Then use tensorflow built-in tools to freeze the graph:
```
python -m tensorflow.python.tools.freeze_graph --input_graph log/graph.pbtxt --input_checkpoint log/model.ckpt-20000 --output_node_names L2Loss --output_graph log/freeze_graph.pb
```
Finally use [tensorrt.py](https://gist.github.com/qinyao-he/28ddedb7f561bb3cb4ba880833f14a89) to optimize the graph use TensorRT engine.

### Describe the problem
The original graph contains 4 convolution and 4 deconvolution layers.
<img width=""179"" alt=""snipaste_2018-06-20_12-39-15"" src=""https://user-images.githubusercontent.com/6523975/41680987-1e912d1e-7488-11e8-8a25-6f8e112cc2e6.png"">

After optimizing, convolution layers was converted into trt_op (successfully optimized by TensorRT), while all deconvolution layers (conv2d_transpose) remains unchanged.
<img width=""244"" alt=""snipaste_2018-06-20_12-39-46"" src=""https://user-images.githubusercontent.com/6523975/41681041-4bba6a08-7488-11e8-970c-2773fedea98a.png"">

I think TensorRT support deconvolution as shown in their official guide [TensorRT Developer Guide](https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html)

> TensorFlow
> The following list describes the operations that are supported in a TensorFlow framework.
> Placeholder
> Const
> Add, Sub, Mul, Div, Minimum and Maximum
> BiasAdd
> Negative, Abs, Sqrt, Rsqrt, Pow, Exp and Log
> FusedBatchNorm
> ReLU, TanH, Sigmoid
> SoftMax
> Mean
> ConcatV2
> Reshape
> Transpose
> Conv2D
> DepthwiseConv2dNative
> ConvTranspose2D
> MaxPool
> AvgPool
> Pad is supported if followed by one of these TensorFlow layers: Conv2D, DepthwiseConv2dNative, MaxPool, and AvgPool

So is there any problem in tensorflow integrations?"
20154,TF.RECORDS IMAGES TENSORFLOW,"I'm doing a tensorflow cnn, at the time of reading my tf.records I do not know what type of data is appropriate when I decode my images, and I saw in multiple tutorials that a reshape should be done before entering the model , I'd like to know if I'm doing it the right way, this is my code

    `def read_file(filename_queue):
 
        #Funcion para leer el archivo tf.record, y retornamos el next recrod
         reader=tf.TFRecordReader()
         _,serialized_example=reader.read(filename_queue)

        #Se decodifica el tf.record retornando un diccionario 
        feature={'train/image':tf.FixedLenFeature([],tf.string),
                        'train/label':tf.FixedLenFeature([],tf.int64)}
        features=tf.parse_single_example(serialized_example,features=feature)

        #Convertimos el string a numeros de los decodificados features
         image=tf.decode_raw(features['train/image'],tf.float32)* (1 / 255.0)

        #Convertimos a datos
        label=tf.cast(features['train/label'],dtype=tf.int32)

         #Reshape data
          image=tf.reshape(image,[224,224,3])   

          return image,label`"
20150,unable to cast to quantized data types uint8 -> quint8,"The `Cast` operator doesn't support casting to quantized data types such as `quint8`. This makes it a pain to implement custom quantization logic in Tensorflow. Since both quint8 and uint8 have the same underlying data type it should be fairly easy to implement conversion between them.

```
tensor_test.go:33: Cast uint8 to quint8 is not supported
  [[Node: QuantizeProbabilistic/Quint8/Cast = Cast[DstT=DT_QUINT8, SrcT=DT_UINT8, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](QuantizeProbabilistic/Cast)]]
```

You can work around it by casting to uint8, export from tensorflow in to the host language and then create a new tensor with the specified data type, but that's certainly less than ideal.

On a side note: I ran into this problem while trying to implement a randomized quantize that when averaged returns the original number. Maybe that's something that should be in the core tensorflow library?

Template:
Have I written custom code? No
OS Platform and Distribution? Linux, Arch
TensorFlow installed from? Master
TensorFlow version? Master
Bazel version? 0.14.1- (@non-git)
CUDA/cuDNN version? N/A
GPU model and memory? N/A
Exact command to reproduce?

"
20149,Tensorflow on GCP instance,"I'm trying to setup my GCP instance for working with TF and Keras. I installed Cuda-toolkit, libcupti-dev and cudnn.
I also installed the *tensorflow-gpu* but when I import Tensorflow, I get the following.

Operating System : Ubuntu 16.04 LTS
Tensorflow Installation Method : ```pip install tensorflow-gpu```
Tensorflow Version: 1.8
Pip Version: 10.0
Cuda version 9.2
Cudnn  version: 7
GPU: Nvidia Tesla K80 - 12 GB


```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory
Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/install_sources#common_installation_problems
```


 cudnn and CUDA are setup as precribed in the documentation. Could you help me with this?


```
import tensorflow as tf
```
gives me the above error on server"
20148,Retraining explanation with tf-hub,"Trying to go through this tutorial below to retrain ssd_inception_v2_coco_11_06_2017 to fine tune and retrain on coco + additional set of images:
https://www.tensorflow.org/tutorials/image_retraining#creating_a_set_of_training_images

This tutorial seems to be different from others I've seen where labelling images and creation of tfrecord are necessary steps. However, this tutorial seems to accept a directory of images and retrains the model with the image dir. 
Question: Is the tf-hub automating the tfrecord creation process using the directory name. If so, is it using the full image size and not tagging the bounding boxes of contained boxes?
"
20146,tf.extract_image_patches() gradient very slow at graph construction time,"### System information
- **Have I written custom code**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Fedora 28
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-1-g8753e2e
- **Python version**: 3.5
- **Bazel version**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see below

### Problem
When building the graph, taking the gradient with respect to the input of `tf.extract_image_patches` is unusually slow (see minimal example below, where it takes ~2min). 

### How to reproduce
```python
import tensorflow as tf

tf.reset_default_graph()

batch_size = 4
height = width = 1024
ksize = 5

inputs = tf.get_variable('inputs', (batch_size, height, width, 1))
patches = tf.extract_image_patches(inputs, 
                                   ksizes=[1,ksize,ksize,1], 
                                   strides=[1,1,1,1], 
                                   rates=[1,1,1,1], 
                                   padding='SAME')
print(patches.shape)
%time gradients = tf.gradients(patches, inputs)
```
Result:
```
(4, 1024, 1024, 25)
CPU times: user 1min 42s, sys: 2.07 s, total: 1min 44s
Wall time: 1min 44s
```
"
20145,Tf lite: EXC_BAD_ACCESS when invoking the interpreter in iOS,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS X High Sierra
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.9.0
- **Python version**: 3.5

### Describe the problem
I created a feedforward neural network in Python and then exported the tflite model using:

```
bazel run --config=opt \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=frozen_graphdef.pb \
  --output_file=model.tflite \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --input_shape=1,200 \
  --input_array=inputs \
  --output_array=prediction  
```

I'm now trying to use it in iOS following the guidelines of your examples. This is my code:

```

  float* _fInput;
  std::unique_ptr<tflite::Interpreter> _interpreter;

  std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(sModel_path.c_str());
  
  if (!model) {
    std::cout << ""Failed to map model "" << sModel_path << std::endl;
    exit(-1);
  }
  std::cout << ""Loaded model "" << sModel_path << std::endl;
  
  tflite::ops::builtin::BuiltinOpResolver resolver;
  
  tflite::InterpreterBuilder(*model, resolver)(&_interpreter);
  
  if (!_interpreter) {
    std::cout << ""Failed to construct interpreter."" << std::endl;
    exit(-1);
  }
  
  int input_idx = _interpreter->inputs()[0];
  
  std::vector<int> sizes = {1, NUM_FEAT};
  std::string input_layer_type = ""float"";
  
  if (input_layer_type != ""string"") {
    _interpreter->ResizeInputTensor(input_idx, sizes);
  }

  if (_interpreter->AllocateTensors() != kTfLiteOk) {
    printf(""Failed to allocate tensors!\n"");
  }
  
  _fInput = _interpreter->typed_tensor<float>(input_idx);

  // receive vFeatures, an std::vector<float> of size NUM_FEAT

  for(int i = 0; i < NUM_FEAT; ++i)
    _fInput[i] = vFeatures[i];
  
  if (_interpreter->Invoke() != kTfLiteOk) {
    std::cout << ""Failed to invoke!"" << std::endl;
    exit(-1);
  }

```

For some reason, the execution fails on the line _interpreter->Invoke(), I get an ""EXC_BAD_ACCESS"" error. 

On a sidenote, do I need the ResizeInputTensor and AllocateTensors lines? It seems to me that the resizing is not necessary since I already stated the input size when exporting the tflite model, and I've seen some examples in which these lines were not present.
"
20144,lack using namespace std,"/opt/tensorflow/tensorflow/core/graph/default_device.h:29:36: error: 'string' does not name a type; did you mean 'stdin'?
 inline void SetDefaultDevice(const string& device, GraphDef* graph_def) {
                                    ^~~~~~
                                    stdin
"
20143,Estimator.export_savedmodel problem,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I have attached a ZIP file
[CaseStudy.zip](https://github.com/tensorflow/tensorflow/files/2118856/CaseStudy.zip)

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
1.8
- **TensorFlow version (use command below)**:
b'v1.8.0-0-g93bc2e2072' 1.8.0
- **Python version**: 
3.6(64bit)
- **CUDA/cuDNN version**:
9.0
- **GPU model and memory**:
Gtx660 2GB
- **Exact command to reproduce**:
CaseStudy.py


 i Try to use Estimator.export_savedmodel() to export the model, but i receive the error: AttributeError(""'dict' object has no attribute 'dtype'"",)
This is happening because export_savedmodel() calls model_fn() with the dict of the features and not the features themselves. If this is not a bug then i am missing something very fundamental. What is this?

I have attached a VS solution for you to run

[CaseStudy.zip](https://github.com/tensorflow/tensorflow/files/2118856/CaseStudy.zip)


Thank you

"
20142, use the stream builder to invoke FFT library fail in custom op ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Centos /Linux
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA Version 9.0.176  cuDNN 7.0.5
- **GPU model and memory**:
GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.076
- **Exact command to reproduce**:
I'm writing a custom op performing image alignment. The module is performing several FFT operations on GPU .  I created a simple custom op to reproduce the issue with the stream builder method.
I didn't find any real example, I followed the comments given in the code  stream_executor/fft.h  

The portion of the code that is causing the error  is bellow  ( Create1dPlan ...)  with the corresponding trace log.
I also attached the full code  to produce the custom op at the bottom.
Thanks for any help !
``` javascript
void launchFFT(
  OpKernelContext* context,
  const Tensor& x,
   Tensor* y)
{
auto dev_ctx = context->op_device_context();
OP_REQUIRES(context, dev_ctx->stream(), errors::Internal(""No stream available.""));
auto stream_exec=dev_ctx->stream()->parent();
perftools::gputools::DeviceMemory<std::complex<float>>X=stream_exec>AllocateArray<std::complex<float>>(1024);
perftools::gputools::DeviceMemory<std::complex<float>>Y=stream_exec>AllocateArray<std::complex<float>>(1024);
 /* ... populate x and y ... TBD*/
Stream stream{stream_exec};
printf(""Create1dPlan and ... die\n"");
std::unique_ptr<Plan> plan =stream_exec->AsFft()->Create1dPlan(&stream, 1024,Type::kC2CForward,false);
stream.Init().ThenFft(plan.get(), X, &Y);
SE_CHECK_OK(stream.BlockHostUntilDone());
}
```


018-06-20 02:12:43.373297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-06-20 02:12:43.524101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-20 02:12:43.524119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-06-20 02:12:43.524123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-06-20 02:12:43.524320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11431 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0, compute capability: 5.2)
launchFFT
Create1dPlan and ... die
**2018-06-20 02:12:43.603606: F tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:112] Check failed: cuda_exec != nullptr** 

Process finished with exit code 134 (interrupted by signal 6: SIGABRT) 

The sources of the custom op to reproduce the problem are bellow:
**dummyFFT.cc**
```javascript
#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/framework/register_types.h""
#include ""tensorflow/core/framework/shape_inference.h""

namespace tensorflow
{
typedef Eigen::GpuDevice GPUDevice;

using shape_inference::ShapeHandle;
using shape_inference::InferenceContext;
using shape_inference::DimensionHandle;

REGISTER_OP(""DummyFft"")
.Input(""float: float32"")
.Output(""output: float32"")
.SetShapeFn([](InferenceContext* ctx) {
    // Get shapes and ensure correct dimensionality
    ShapeHandle in_shape;
    TF_RETURN_IF_ERROR(ctx->WithRank(ctx->input(0), 2, &in_shape));
    // Construct and set the output shape
   ctx->set_output(0, in_shape);
    return Status::OK();
});

void launchFFT(
  OpKernelContext* ctx,
  const Tensor& x,
  Tensor* y);

class launchFFTOp : public OpKernel
{
 public:
  explicit launchFFTOp(OpKernelConstruction* ctx) : OpKernel(ctx) { }

  void Compute(OpKernelContext* ctx) override
  {
    // Get inputs
    const Tensor& input = ctx->input(0);
    // Setup output shape
    const TensorShape& input_shape(input.shape());
    TensorShape output_shape(input.shape());
    // Allocate output tensor
    Tensor* output = nullptr;
    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, output_shape, &output));
    printf(""launchFFT\n"");
    launchFFT(ctx, input,output);

  }
};
```
**dummyFFT.cu.cc**
```javascript
#if GOOGLE_CUDA
#define EIGEN_USE_GPU

#include ""third_party/eigen3/unsupported/Eigen/CXX11/Tensor""
#include ""tensorflow/core/framework/register_types.h""
#include ""tensorflow/core/platform/types.h""
#include ""tensorflow/core/util/cuda_kernel_helper.h""
#include ""tensorflow/core/platform/stream_executor.h""

using namespace perftools::gputools::fft;

using namespace perftools::gputools;



typedef Eigen::GpuDevice GPUDevice;
namespace tensorflow
{
namespace {

template <typename T>
	perftools::gputools::DeviceMemory<T> AsDeviceMemory(const T* cuda_memory) {
	perftools::gputools::DeviceMemoryBase wrapped(const_cast<T*>(cuda_memory));
	perftools::gputools::DeviceMemory<T> typed(wrapped);
  return typed;
}

}  // end namespace


void launchFFT(
  OpKernelContext* context,
  const Tensor& x,
   Tensor* y)
{
auto dev_ctx = context->op_device_context();
OP_REQUIRES(context, dev_ctx->stream(), errors::Internal(""No stream available.""));
auto stream_exec=dev_ctx->stream()->parent();
perftools::gputools::DeviceMemory<std::complex<float>>X=stream_exec>AllocateArray<std::complex<float>>(1024);
perftools::gputools::DeviceMemory<std::complex<float>>Y=stream_exec>AllocateArray<std::complex<float>>(1024);
 /* ... populate x and y ... TBD*/
Stream stream{stream_exec};
printf(""Create1dPlan and ... die\n"");
std::unique_ptr<Plan> plan =stream_exec->AsFft()->Create1dPlan(&stream, 1024,Type::kC2CForward,false);
stream.Init().ThenFft(plan.get(), X, &Y);
SE_CHECK_OK(stream.BlockHostUntilDone());
}


}  // namespace TensorFlow
#endif
```

**makefile**
```
TF_CFLAGS := $(shell python3 -c 'import tensorflow as tf; print("" "".join(tf.sysconfig.get_compile_flags()))')
TF_LIB := $(shell python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')

CUDA_LIB=/usr/local/cuda/lib64

all: dummyFFT.cu.o dummyFFT.cu.cc dummyFFT.cc 
	nvcc -std=c++11 -c -o dummyFFT.cu.o dummyFFT.cu.cc  $(TF_CFLAGS) -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC --expt-relaxed-constexpr -ltensorfow_framework -I /usr/local -I /usr/local/cuda/include -O3
	g++ -std=c++11 -shared -o dummyFFT_op.so dummyFFT.cc dummyFFT.cu.o   $(TF_CFLAGS) -fPIC -O3 -L$(CUDA_LIB) -lcudart -L$(TF_LIB) -ltensorflow_framework
```
The Python functions:

**test.py** The main python  file to run the custom op
```javascript
import tensorflow as tf
import numpy as np

from dummyFFT import dummy_fft


def test():

    x = np.random.rand(10,10).astype(np.float32)
    x_ph = tf.placeholder(tf.float32, (10,10))
    out=dummy_fft(x_ph)

    with tf.Session() as sess:
        _out = sess.run(out, feed_dict={x_ph: x})


if __name__ == ""__main__"":
    test()
```

**dummyFFT.py**  used to load the library 
```javascript
import tensorflow as tf
from tensorflow.python.framework import ops

op_module = tf.load_op_library('dummyFFT_op.so')


def dummy_fft(x):
    return op_module.dummy_fft(x)
```




"
20141,Resnet20: add fake quantization nodes,"System information
------------------------------------------
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS Linux release 7.2
TensorFlow installed from (source or binary):Anaconda python 3.6.5(conda install)
TensorFlow version (use command below):1.8.0
Python version: 3.6.5
Bazel version (if compiling from source): 0.7.0
GCC/Compiler version (if compiling from source): 4.8.5
CUDA/cuDNN version:cuda-9.0
GPU model and memory: P40
Phone: N/A

Hi~ 
When I use 'tf.contrib.quantize.experimental_create_training_graph'  it will add fake quantization in the graph.  reference this picture(find positions to insert fake quantization nodes). 
![image](https://user-images.githubusercontent.com/9084403/41646572-c5a48d8a-74a6-11e8-81bf-d1fee67d5c4a.png)

I think it will add a fake quantization node in the bypass, but I can not find it in the tensorboard graph(in the red box, it is the bypass). In other convs, I can find the quantization node. 
![image](https://user-images.githubusercontent.com/9084403/41649732-d6f538d4-74ae-11e8-87b5-66b2b49904a7.png)

My network architecture is ResNet20,  tensorflow version is 1.8.0

pls help me. thank you.



"
20140,Find a bug in tensorflow,"write the code below, and save it to  a ,ckpt as a model
```
import tensorflow as tf`
v1 = tf.Variable(tf.constant(1.0, shape=[1]), name = ""v1"")
v2 = tf.Variable(tf.constant(2.0, shape=[1]), name = ""v2"")
v3 = tf.Variable(tf.constant(3.0, shape=[1]), name = ""v3"")
result=v1+v2
result2= result + v3

init_op = tf.global_variables_initializer()
saver = tf.train.Saver()

with tf.Session() as sess:
    sess.run(init_op)
    writer = tf.summary.FileWriter('./graphs/const_add', sess.graph)
    saver.save(sess, ""Saved_model/model.ckpt"")`
```
then in another .py， we restore the model from the model.ckpt file
```
import tensorflow as tf
saver = tf.train.import_meta_graph(""Saved_model/model.ckpt.meta"")
with tf.Session() as sess:
    saver.restore(sess, ""Saved_model/model.ckpt"")
    print (sess.run(tf.get_default_graph().get_tensor_by_name(""add:0"")))
    #sess.run(tf.assign(v1,[10])) #直接这样使用v1，会提示v1没有定义
    
    #with tf.variable_scope("""",reuse=tf.AUTO_REUSE):
    with tf.variable_scope("""",reuse=False):
        v1=tf.get_variable(name=""v1"",shape=[1])
        print(v1.name)
    sess.run(tf.assign(v1,[10]))
    """"""④输出所有可训练的变量名称，也就是神经网络的参数""""""
    trainable_variables=tf.trainable_variables()
    variable_list_name = [c.name for c in tf.trainable_variables()]
    variable_list = sess.run(variable_list_name)
    for k,v in zip(variable_list_name,variable_list):
        print(""variable name:"",k)
        print(""shape:"",v.shape)
            #print(v) 
    """"""④输出所有可训练的变量名称，也就是神经网络的参数""""""
    print (sess.run(tf.get_default_graph().get_tensor_by_name(""v1:0"")))
    print (sess.run(tf.get_default_graph().get_tensor_by_name(""add:0"")))
    print (sess.run(tf.get_default_graph().get_tensor_by_name(""add_1:0"")))
    print (sess.run(tf.get_default_graph().get_tensor_by_name(""v1_1:0"")))
```
the results will be as below:
![image](https://user-images.githubusercontent.com/7501074/41644510-d1957e98-74a0-11e8-9327-7e2cd5ccd438.png)
we will find that:
if we restore some variables from the already existed model file """"Saved_model/model.ckpt.meta"")"",
such as v1,v2,v3 in this example.
it will influence the process of calling get_variable. Because of these two causes as below:
1. the variables restored from the model file such as v1,v2 and v3 will not exist in the scope of get_variable, it means you can only use
```
with tf.variable_scope("""",reuse=False):
        v1=tf.get_variable(name=""v1"",shape=[1])
```
and create a new variable.  you can not  reuse the restored variable v1 from the model file unless you define a v1 , before you restore from the model file. like below
```
v1=tf.get_variable(name=""v1"",shape=[1])
saver = tf.train.Saver()
with tf.Session() as sess:
    saver.restore(sess, ""Saved_model/model.ckpt"")
    print (sess.run(result))
```
that is , you can not reuse the restored variable v1 which is from restoring the model file unless you define it befor you restore.
2.  although tensorflow doesnot allow reusing the restored variable v1 which is from restoring the model file if you don't define v1 before you restore the model file.
But if you call get_varialbe after you restore the model file, it will create a variable whose name is ""v1_1"" but not as name='v1' which you specify.
    in my opinion, it should be corrected because it is so confusing.  how to correct it?
i think get_variable should also reuse the variables which is loaded by restoring some model file.
the last sentence is what i finally want to say. 
My english is to bad, you can run the code i offer and will find what i want to convey. 
Thanks.

"
20139,Aborted (core dumped) while running tftrt test case with tensorflow 1.9.0-rc1,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.9.0-rc1
- **Python version**: 
both 2.7 and 3.5
- **Bazel version (if compiling from source)**:
0.11.1
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
cuda 9.0 / cuDNN7.0
- **GPU model and memory**:
TitanXp 12G
- **Exact command to reproduce**:
env TEST_TMPDIR=/tmp/bazel n=1 TF_NEED_GCP=0 TF_NEED_HDFS=1 \
    TF_NEED_S3=0 TF_ENABLE_XLA=1 TF_NEED_GDR=1 TF_NEED_VERBS=1 \
    TF_NEED_JEMALLOC=1 \
    TF_NEED_OPENCL=0 TF_NEED_CUDA=1 TF_NEED_MPI=0 \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/local/lib/python3.5/dist-packages \
    TF_NEED_OPENCL_SYCL=0 \
    CC_OPT_FLAGS=""-march=native"" \
    TF_CUDA_VERSION=9.0 \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    TF_CUDNN_VERSION=7 \
    TF_CUDA_CLANG=0 \
    TF_SET_ANDROID_WORKSPACE=false \
    CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu/ \
    TF_NEED_KAFKA=0 \
    TF_NEED_TENSORRT=1 \
    TF_NCCL_VERSION=2 \
    NCCL_INSTALL_PATH=/usr/local/nccl2/ \
    TENSORRT_INSTALL_PATH=/usr/lib/x86_64-linux-gnu/ \
    TF_CUDA_COMPUTE_CAPABILITIES=6.1  ./configure 

bazel build -c opt --copt=-mavx --copt=-mavx2  \
--copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 \
--config=cuda --config=mkl --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" \
//tensorflow/tools/pip_package:build_pip_package

build_pip_package then pip3 install 

python3 tensorflow/tensorflow/contrib/tensorrt/test/test_tftrt.py

### Describe the problem
I built tensorflow from source with above script, there is no problem with git branch r1.8, after I checked out to branch r1.9 and rebuilt, tftrt test case will crash.

### Source code / logs
root@5f4922d0faef:~/share/tensorflow/tensorflow/contrib/tensorrt/test# python test_tftrt.py 
2018-06-20 06:58:51.032087: F tensorflow/core/framework/op.cc:55] Non-OK-status: RegisterAlreadyLocked(op_data_factory) status: Already exists: Op with name _ScopedAllocator
Aborted (core dumped)
"
20138,Can I insert a node in a graph with graph_editor?,"For example:

I have a graph like:

```
A -> B -> C
```

And I want to select some indices of the output of B to , like that:

```
A -> B -> tf.gather(B, indices) -> C
```

Is it possilbe?"
20137,Segfault in tensorflow,"Hello,
I  got one segfault so many times. I've just installed gdb and got a back trace below. My system is a fresh Ubuntu 16.04 (newly installed), keras 2.2, tf 1.9.0rc1, numpy 1.14.5 (compiled from source). Please help.
Thanks in advance.

`Thread 20 ""python3.5"" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fff779bf700 (LWP 2911)]
0x0000000000000045 in ?? ()
(gdb) bt
#0  0x0000000000000045 in ?? ()
#1  0x00007fffaf185466 in tensorflow::Tensor::~Tensor() ()
   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/../libtensorflow_framework.so
#2  0x00007fffaf3180db in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()
   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/../libtensorflow_framework.so
#3  0x00007fffaf319a2a in std::_Function_handler<void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(tensorflow::gtl::InlinedVector<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8> const&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/../libtensorflow_framework.so
#4  0x00007fffaf377fba in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/../libtensorflow_framework.so
#5  0x00007fffaf377062 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /usr/local/lib/python3.5/dist-packages/tensorflow/python/../libtensorflo---Type <return> to continue, or q <return> to quit---
w_framework.so
#6  0x00007ffff253bc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#7  0x00007ffff7bc16ba in start_thread (arg=0x7fff779bf700)
    at pthread_create.c:333
#8  0x00007ffff78f741d in clone ()
    at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109`"
20135,TENSOR FLOW CNN MNIST EXAMPLE: HOW BATCH SIZE WORKS IN THE MODEL,"In the CNN MNIST example of tensorflow I do not understand how batch size works, when they call the model they specify the size of the bach in 100:

`train_input_fn = tf.estimator.inputs.numpy_input_fn(
x={""x"": train_data},
y=train_labels,
batch_size=100,
num_epochs=None,shuffle=True)
mnist_classifier.train(input_fn=train_input_fn,steps=20000,hooks=[logging_hook])`

But when the model is called

`def cnn_model_fn(features, labels, mode):
  input_layer = tf.reshape(features[""x""], [-1, 28, 28, 1])`

They put -1 in batch size , I read in tensorflow tutorials and -1 they used it when they told the computer to infer that dimension What I do not understand is that before we put 100 and now because -1 do not understand how is entering the batch size to the model could you help me explaining? Thank you."
20134,IndexError: tuple index out of range CNN Tensor flow,"I'm working on a convolutional network in tensor flow and I get the following error:

 IndexError: tuple index out of range

when I feed my data to the model  for training I do not know how to fix it. Below is the main function code. I think that my error is in y (labels). I think that the problem is the format of the labels that I can get from input_pipeline function, but I don't know how to fix it.

`def main(unused_argv):

    images_batch,labels_batch=input_pipeline(train_path,batch_size,num_epochs)

    with tf.Session() as sess:

        #Inicializamos las variables
        init_op=tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())
        sess.run(init_op)

        #Corremos las filas(queue) que se crearon en el grafico computacional 
        tf.train.start_queue_runners(sess=sess)

       detector=tf.estimator.Estimator(model_fn=cnn_model,model_dir=""/tmp/gun_cnn_detector"")

        train_fn=tf.estimator.inputs.numpy_input_fn(
            x={""x"":images_batch.eval()},
            y=labels_batch.eval(),
            batch_size=10,
            num_epochs=None,
            shuffle=True)
       detector.train(
            input_fn=train_fn,
            steps=2)

        writer = tf.summary.FileWriter('.')
        writer.add_graph(tf.get_default_graph())`

`def input_pipeline(filenames,batch_size,num_epochs):
    filename_queue=tf.train.string_input_producer([filenames],num_epochs=num_epochs,shuffle=True)
    images,labels=read_file(filename_queue)

    return images,labels`

I tried a lot of things. Below is the read function. Also I have another question: when I decode my image, what is the correct format? float32 or uint8?

`def read_file(filename_queue):

    #Funcion para leer el archivo tf.record, y retornamos el next recrod
    reader=tf.TFRecordReader()
    _,serialized_example=reader.read(filename_queue)

    #Se decodifica el tf.record retornando un diccionario 
    feature={'train/image':tf.FixedLenFeature([],tf.string),
             'train/label':tf.FixedLenFeature([],tf.int64)}
    features=tf.parse_single_example(serialized_example,features=feature)

    #Convertimos el string a numeros de los decodificados features
    image=tf.decode_raw(features['train/image'],tf.float32)* (1 / 255.0)

    #Convertimos a datos
    label=tf.cast(features['train/label'],dtype=tf.int32)

    #Reshape data
    image=tf.reshape(image,[224,224,3]) 

    return image,label`


This is the error I get:

`/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type. from ._conv import register_converters as _register_converters Traceback (most recent call last): File ""/Users/David/Desktop/David/General/Tesis/Practica/Programas/CNN/CNN.py"", line 113, in tf.app.run() File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 126, in run _sys.exit(main(argv)) File ""/Users/David/Desktop/David/General/Tesis/Practica/Programas/CNN/CNN.py"", line 104, in main steps=2) File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train loss = self._train_model(input_fn, hooks, saving_listeners) File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 843, in _train_model return self._train_model_default(input_fn, hooks, saving_listeners) File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 853, in _train_model_default input_fn, model_fn_lib.ModeKeys.TRAIN)) File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 691, in _get_features_and_labels_from_input_fn result = self._call_input_fn(input_fn, mode) File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 798, in _call_input_fn return input_fn(**kwargs) File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py"", line 175, in input_fn if len(set(v.shape[0] for v in ordered_dict_data.values())) != 1: File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/numpy_io.py"", line 175, in if len(set(v.shape[0] for v in ordered_dict_data.values())) != 1: IndexError: tuple index out of range [Finished in 3.9s with exit code 1]`
"
20132,tfevents not generated if specifying model_dir for tf.estimator.Estimator,"### System information
- I've been following the tutorial to create a custom estimator on this page: https://www.tensorflow.org/get_started/custom_estimators
- OS: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: installed through pip
- **TensorFlow version (use command below)**: ('v1.8.0-0-g93bc2e2072', '1.8.0')
- **Python version**: Python 2.7

### Describe the problem
tfevents file is not found in the `model_dir` if I specify `model_dir` when creating the Estimator. However, graph file and checkpoints are present.

```
autoencoder = tf.estimator.Estimator(
    model_fn = my_model_fn,
    #model_dir = logs_path, # <--- tfevents not created if I specify model_dir here...
    params = {
        'feature_columns': feature_columns,
        'input_units_num': num_input
    },
    #config = tf.estimator.RunConfig(model_dir = logs_path) # <--- ... nor if I specify model_dir here.
)
```

However, if I don't specify `model_dir` parameter neither in the config, nor as one of the Estimator parameters, tfevents file is written into the `/tmp/<folder>` along with graph and checkpoints.

Many thanks!"
20131,Computation Paths of different attention mechanism,"I was checking the computation paths of the different attention mechanism and compared them with the attention wrapper implementation. I noticed that the computation paths follows the Luong implementation more closely. People brought up this issue in [9635](https://github.com/tensorflow/tensorflow/issues/9635)  but the thread was closed since the main issue was answered already.

To summarize there were two attention mechanisms. Luong uses the computation path  h(t)->a(t)->c(t)->h˜(t) while Bahnadau uses the h(t-1)->a(t)->c(t)->h(t).

I seems that right now this is not a priority to implement as the people in the discussion are saying that there is no significant difference.  However I think it would be better to document that the attention wrapper implementation is more similar the the Luong attention just so people are aware. Also the output_attention does not really change the computation paths so I think the description for the flag should be changed.

That being said, this is my first time to read deeply into the internal tensorflow code. If just me misunderstanding the implementation, then feel free to point out the things I might have missed. Thanks.

Edit:
I looked at the code once again. It seems like the I was just having trouble due to the recursive nature of the code.
When using output_attention=True, the recursion goes to h(t)->a(t)->c(t)->h˜(t).
When using output_attention=False, the recursion goes to c(t)->h(t)->a(t+1)->c(t+1) which is the same if to h(t-1)->a(t)->c(t)->h(t).

If things work like my edit, feel free to close the issue.

Edit 2:
In [issues 9635](https://github.com/tensorflow/tensorflow/issues/9635) other people also saw this the first time I saw it (that the paths are different) so a verification or second opinion will be helpful."
20128,Created Tflite file is empty,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.8.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 4.8.4
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**: bazel run --config = opt //tensorflow/contrib/lite/toco:toco -- --input_format=TENSORFLOW_GRAPHDEF --input_file=/emulator/tensorflow_xtensa/test/assets/conv_actions_frozen.pb --output_format=TFLITE --output_file=/emulator/tensorflow_xtensa/tensorflow/tensorflow/contrib/lite/examples/android/assets/conv_actions_frozen.pb --output_file=/emulator/tensorflow_xtensa/tensorflow/tensorflow/contrib/lite/examples/android/assets/conv_actions_frozen.tflite --output_array=add_2 --input_array=Conv2D 

### Describe the problem
I am trying to create the speech model tflite for anrdoid from the .pb file. I noticed that when I give --allow_custom_ops, it creates a tflite file of 3MB. But, without that, the created tflite files is zero bytes.
When I upload this tflite file with --allow_custom_ops, it gives a run time error asking for the custom ops to be defined. 
"
20126,Using MirroredStrategy to distribute GPU processing causes assertion error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Running Amazon Deep Learning AMI (Amazon Linux) Version 10.0 - ami-9d0d7fe2
> uname -a
Linux ip-172-30-4-195 4.9.93-41.60.amzn1.x86_64 #1 SMP Fri Apr 13 21:58:27 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
> cat /etc/os-release
NAME=""Amazon Linux AMI""
VERSION=""2017.09""
ID=""amzn""
ID_LIKE=""rhel fedora""
VERSION_ID=""2017.09""
PRETTY_NAME=""Amazon Linux AMI 2017.09""
ANSI_COLOR=""0;33""
CPE_NAME=""cpe:/o:amazon:linux:2017.09:ga""
HOME_URL=""http://aws.amazon.com/amazon-linux-ami/""

- **TensorFlow installed from (source or binary)**:
Pre-installed on Amazon instance.  

- **TensorFlow version (use command below)**:
v1.8.0-3-gf91bd2f8c4 1.8.0

- **Python version**: 
Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)

- **Bazel version (if compiling from source)**:
Build label: 0.11.1- (@non-git)

- **GCC/Compiler version (if compiling from source)**:
> gcc --version
gcc (GCC) 4.8.5

- **CUDA/cuDNN version**:
>  nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Sep__1_21:08:03_CDT_2017
Cuda compilation tools, release 9.0, V9.0.176

- **GPU model and memory**:
Tesla K80, 11439MiB

- **Exact command to reproduce**:
Unzip the test_distributed.zip.  It should unzip to a script called ""test_distributed.py"".  Run the script using Python3.  It is completely self-contained.  It will throw the assertion error described below.

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I ported word2vec training code from low-level tensorflow flow API to the Estimator framework, where it ran OK, making use of the GPUs. When I modified the code to use multiple GPU's however (e.g., putting a MirroredStrategy in the configuration to the Estimator), it threw an assertion error, apparently not finding that a variable was of type MirroredVariable.  The stack trace is below.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Traceback (most recent call last):
  File ""test_distributed.py"", line 54, in <module>
    classifier.train(input_fn=lambda:input_fn(train_features,train_labels,batch_size))
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 841, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 884, in _train_model_distributed
    self.config)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/distribute.py"", line 756, in call_for_each_tower
    return self._call_for_each_tower(fn, *args, **kwargs)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 254, in _call_for_each_tower
    coord.join(threads)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/six.py"", line 693, in reraise
    raise value
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 248, in _call_for_each_tower
    self, *merge_args, **merge_kwargs)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 702, in _distributed_apply
    for grad, var in grads_and_vars
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 703, in <listcomp>
    for op in distribution.unwrap(distribution.update(var, update, grad))
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/training/distribute.py"", line 838, in update
    return self._update(var, fn, *args, **kwargs)
  File ""/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 300, in _update
    assert isinstance(var, values.MirroredVariable)
AssertionError



[test_distributed.zip](https://github.com/tensorflow/tensorflow/files/2116330/test_distributed.zip)
"
20125,WishartCholesky with 1-D batch shape fails to calculate mean,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: Python 3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See source below

### Describe the problem
Initializing a `tf.contrib.distributions.WishartCholesky` distribution with parameters identical to those provided in the one of the examples, the `mean()` function fails an attempted multiplication.

### Source code / logs
```
# Initialize two 3x3 Wisharts with Cholesky factored scale matrices.
df = [5, 4]
chol_scale = tf.cholesky(tf.ones([2.,3.,3.]))  # Shape is [2, 3, 3].
dist = tf.contrib.distributions.WishartCholesky(df=df, scale=chol_scale)
dist.mean()
```

```
Traceback (most recent call last):
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1567, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 2 and 3 for 'WishartCholesky/WishartCholesky/mean/mul' (op: 'Mul') with input shapes: [2], [2,3,3].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py"", line 923, in mean
    return self._mean()
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/contrib/distributions/python/ops/wishart.py"", line 375, in _mean
    return self.df * self._square_scale_operator()
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 979, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py"", line 1211, in _mul_dispatch
    return gen_math_ops.mul(x, y, name=name)
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4759, in mul
    ""Mul"", x=x, y=y, name=name)
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1734, in __init__
    control_input_ops)
  File ""/Users/equint/interpretable-classification/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1570, in _create_c_op
    raise ValueError(str(e))
ValueError: Dimensions must be equal, but are 2 and 3 for 'WishartCholesky/WishartCholesky/mean/mul' (op: 'Mul') with input shapes: [2], [2,3,3].
```"
20124,Stacking lstm/gru cells of different sizes using MultiRNN cell,"I want to stack 2 lstm or GRU cells with size 64 and 32 respectively, however the multiple rnn cell throws this error-
ValueError: Dimension 2 in both shapes must be equal, but are 64 and 32. Shapes are [2,128,64] and [2,128,32].
	From merging shape 0 with other shapes. for 'Variable_1/initial_value' (op: 'Pack') with input shapes: [2,128,64], [2,128,32].

Is there any work around for this problem?
Right now I'm just specifying 64 and 32 as num_units in LSTMCell.
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No, I have followed the tensorflow tutorials and taken some inspiration from stackoverflow answers to stack the LSTM cells
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**:
Installed using pip3
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.5.2
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A using CPU only version
- **Exact command to reproduce**:
N/A more info added in the next comment"
20121,Readme of the docker directory points to dead http links,"There seems to be a problem with the readme of the docker directory. The variable TF_DOCKER_BUILD_CENTRAL_PIP is initialized with HTTP links that are dead (404). This is preventing building at least the gpu image.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/README.md#rebuilding-the-containers"
20120,TensorRT - TRTEngineOp error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.9.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: CUDA 9.0, cuDNN 7.0
- **GPU model and memory**: GeForce GTX 1070, 8GB
- **Exact command to reproduce**:

### Describe the problem
I've used the code [here](https://github.com/tensorflow/models/tree/master/research/tensorrt) and I am able to run it. My problem is that I can't visualise the graph in Tensorboard anymore (I'm using the `import_pb_to_tensorboard` script) to check the architecture and I can't load it to use it afterwards.

### Source code / logs

```
Traceback (most recent call last):

  File ""/tensorflow/tensorflow/python/tools/import_pb_to_tensorboard.py"", line 76, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))

  File ""/tensorflow/tensorflow/python/tools/import_pb_to_tensorboard.py"", line 58, in main
    import_to_tensorboard(FLAGS.model_dir, FLAGS.log_dir)

  File ""/tensorflow/tensorflow/python/tools/import_pb_to_tensorboard.py"", line 49, in import_to_tensorboard
    importer.import_graph_def(graph_def)

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)

  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/importer.py"", line 418, in import_graph_def
    graph._c_graph, serialized, options)  # pylint: disable=protected-access

tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'TRTEngineOp' in binary running on 5b451011e68a. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) 'tf.contrib.resampler' should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
```

I've seen this error in a post on Stackoverflow ([here](https://stackoverflow.com/a/50461127/9052343)) but that didn't help me. Does anyone have an idea how to solve this issue ?

Thanks."
20119,toco aborts on converting quantized graph to TFLite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.5
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.1
- **Python version**: 2.7.10
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 
```
toco \
--input_file=tmp/killfie_detector.pb \
--output_file=tmp/quantized_killfie_detector.lite \
--input_format=TENSORFLOW_GRAPHDEF \
--output_format=TFLITE \
--input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \
--input_array=input1 \
--output_array=output_node0 \
--inference_type=FLOAT \
--input_data_type=FLOAT \
--inference_type=QUANTIZED_UINT8 \
--quantize_weights=true \
--mean_value=127.5 \
--std_value=127.5
```

### Describe the problem
I am trying to convert a ResNet-50 model to TFLite after quantization. The quantized graph was obtained using `transform_graph` and `--transforms='quantize_weights'` on a .pb file. However, on running `toco` on the quantized graph using the command above, I am first asked to enter the max/min values and the following error:
```
Array input_1, which is an input to the Conv operator producing the output array conv1/convolution, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.
```

On adding `--default_ranges_min=0` and `--default_ranges_max=6` based on the suggestions [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md#use-dummy-quantization-to-try-out-quantized-inference-on-a-float-graph-).

When I ran that script, I got this error message:
```
F tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:519] Unimplemented: this graph contains an operator of type (Unsupported TensorFlow op: Dequantize) for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).
```

Is there any way around this to get a quantized TFLite model?
"
20118,Keras softmax function is not supported by tensorflow-gpu 1.4.1,"I have a nvidia GeForce 940M which supports only CUDA 8.
CUDA 8 needs cudnn 7 to work.
CUDA 8 only supports tensorflow-gpu 1.4.1 and older.
tensorflow-gpu 1.4.1 does not support the Keras softmax function. (throws an error saying recieved extra positional argument)

My only option here seems to be to buy a new GPU which supports CUDA 9, please help."
20117,tflite's  output is far from tf's,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N
- **OS Platform and Distribution**: Linux 4.16.13-2-ARCH
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:'v1.8.0-3238-g52bf2fe0f6' 1.9.0-rc0
- **Python version**:  3.6.5
- **Bazel version (if compiling from source)**: v0.12.0
- **GCC/Compiler version (if compiling from source)**: gcc-7.1
- **CUDA/cuDNN version**: cuda-9.2,cuDNN-7.1
- **GPU model and memory**: 16G
- **Exact command to reproduce**:
###
I trained my model on mobilenet_v2-ssd with codes in models/research/object_detection/ ,export and convert the model from node `Preprocessor/sub` to `concat,concat_1` for the reason that tflite doesn't support some ops.
**With the same input image and same preprocessing** I print out the values of `concat_` whose shape is [1,1917,2] (there is only one ground truth class in my dataset,so the last dimension is 1+1 == 2)
the tf's output is `[[[8.46199608 -9.81417]...`,but the tflite's is `[[[17.357746 -17.360010]...`
The only different obviously I can find is **the training network used  `FusedBatchNorm` 
but in the exported tflite model the `FusedBatchNorm` was replaced by `{'fused_activation_function': 'NONE'} | ADD (opcode=0)`**
Does this differ care? Anyone help?



"
20116,TensorFlow eager execution API give a wrong answer for some function,"Why TensorFlow eager execution API give a wrong answer for this function?
``` python
def dp1_f1(x):
    return 64*x*(1-x)*(math.pow((1-2*x),2) )*math.pow((1-8*x+8*x*x), 2)
```
I want to get dy/dx value. I can get this value by numeric method just as below:
``` python
def dp_numeric_diff(x):
    delta_x = 0.0001
    return (dp1_f1(x+delta_x)-dp1_f1(x))/delta_x
```
I use TensorFlow eager execution API to calculate this value:
``` python
def dp_ad_tfe(x):
    tf.enable_eager_execution()
    tfe = tf.contrib.eager
    grad_lx = tfe.gradients_function(dp1_f1)
    x = 3.0
    y = dp1_f1(x)
    rst = grad_lx(x)
    return y, rst[0]
```
I call this function with code below:
``` python
numeric_diff = dp_numeric_diff(x)
print('Numeric method：{0}'.format(numeric_diff))
v, d = dp_ad_tfe(x)
print('TFE：{0}'.format(d))
```
It will display something like this:
```
Numeric method：-75290405.66440672
TFE：-19208000.0
```
I am sure that the numeric method is right. What's wrong with my TensorFlow eager execution code? By the way the same TensorFlow eager execution code can get correct answer for simple function like x^2."
20115,AttributeError: module 'tensorflow' has no attribute 'test',"import tensorflow as tf
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-32-d1680108c58e> in <module>()
      1 import tensorflow as tf
----> 2 device_name = tf.test.gpu_device_name()
      3 if device_name != '/device:GPU:0':
      4   raise SystemError('GPU device not found')
      5 print('Found GPU at: {}'.format(device_name))

AttributeError: module 'tensorflow' has no attribute 'test'"
20113,Failed to load the native TensorFlow runtime error in python..,"As i try importing Tensorflow i get following import error. Someone please help me.

`Traceback (most recent call last):
  File ""C:\Python34\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Python34\lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow' 

During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""C:\Python34\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python34\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Python34\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred: 

Traceback (most recent call last):
  File ""<pyshell#0>"", line 1, in <module>
    import tensorflow as tens
  File ""C:\Python34\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Python34\lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Python34\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Python34\lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python34\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Python34\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Python34\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named '_pywrap_tensorflow' `


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.`"
20111,ResnetV2 quantization,"System information
------------------------------------------
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS Linux release 7.2
TensorFlow installed from (source or binary):Anaconda python 3.6.5(conda install)
TensorFlow version (use command below):1.8.0
Python version: 3.6.5
Bazel version (if compiling from source): 0.7.0
GCC/Compiler version (if compiling from source): 4.8.5
CUDA/cuDNN version:cuda-9.0
GPU model and memory: P40
Phone: N/A

Describe the problem
-----------------------------
Hi ~

When I used API 'tf.contrib.quantize.experimental_create_training_graph' to add quantization nodes, it will match some layers**(not all convs layers)** to add quantization nodes. This will lead to some layers using float32, but some with float8(quantization bit is 8). When I use 'toco_convert', it just support inference_type: Currently must be {FLOAT, QUANTIZED_UINT8}. I think it need all layers to be FLOAT or QUANTIZED_UINT8. So it will raise this errors.

Error log
------------------------
F tensorflow/contrib/lite/toco/tooling_util.cc:1445] Array model/resnet_model/Relu, which is an input to the Conv operator producing the output array model/resnet_model/conv2d_1/Conv2D, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\n'

So I think **it is contradictory in the API**. pls help me, thank you.

Network
-----------------
Network: ResNet20 

TF version: r1.8(I find it dose not support --default_ranges_min and --default_ranges_max in the python api of r1.8. But in r1.9 it supports)"
20110,"operators not supported by tflite: CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile.","This is a feature request issue.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

CentOS 7

- **TensorFlow installed from (source or binary)**:

From `pip install tensorflow-gpu==1.6`

- **TensorFlow version (use command below)**:

tensorflow-gpu-1.6

- **Python version**:

Python 2.7.5
 
- **Bazel version (if compiling from source)**: None

- **GCC/Compiler version (if compiling from source)**: None

- **CUDA/cuDNN version**:  

CUDA: 9.0 

- **GPU model and memory**:

NVIDIA GTX 1080Ti, 11178MiB

- **Exact command to reproduce**:

```
toco --input_file=/tmp/mymodels/model_frozen.pb --output_file=/tmp/mymodels/converted_model.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --input_shape=1,320,320,3 --input_array=input_images --output_array=output_num_array --inference_type=FLOAT --input_data_type=FLOAT
```

### Describe the problem

I want to convert a trained model, which works on my GPU workstation, to a tflite model to work on Android phone. But I found that there are lots of operation not supported (see also the log below): **CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile**. Do I need to provide customized operator for that (that is a lot of job...)? Or do newer version of toco support that? By the way, `toco` seems to not supported batch normalization either, see [this issue](https://github.com/tensorflow/tensorflow/issues/15336).

### Source code / logs

After running the command above, 

```
2018-06-19 10:17:59.783022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: RandomUniform
2018-06-19 10:17:59.920127: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1171] Converting unsupported operation: Pow
2018-06-19 10:17:59.964930: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 306 operators, 577 arrays (0 quantized)
2018-06-19 10:17:59.971329: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 306 operators, 577 arrays (0 quantized)
2018-06-19 10:18:02.355631: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 216 operators, 476 arrays (0 quantized)
2018-06-19 10:18:02.360368: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 216 operators, 476 arrays (0 quantized)
2018-06-19 10:18:02.364625: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:311] Total transient array allocated size: 78643200 bytes, theoretical optimal value: 78643200 bytes.
2018-06-19 10:18:02.365858: F tensorflow/contrib/lite/toco/tflite/export.cc:304] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: CAST, ExpandDims, FLOOR, Fill, Pow, RandomUniform, SPLIT, Stack, TensorFlowGreater, TensorFlowMaximum, TensorFlowMinimum, TensorFlowShape, TensorFlowSum, TensorFlowTile.
Aborted (core dumped)
```"
20109,NotFoundError when using python to call funtion in .so file,"Hi,
   when I using TF1.5(compiled with ubuntu 14.04 cuda8.0 cudnn5.1 gcc4.8,blaze),I met error like this:
  _hough_voting_gpu_module = tf.load_op_library(filename)
  File ""/home/sky/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py"", line 56, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)
  File ""/home/sky/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: <exception str() failed>
in other test examples,errors are
 _hough_voting_gpu.so: undefined symbol: _ZN2cv6String8allocateEm
and this function does exist in opencv(stl.cpp),Is the problem of ubuntu version?or something else?Thank you!"
20106,Negative Axis Support for tf.manip.roll and other ops,"tf.manip.roll does not support a negative axis argument. Some ops have had support for negative axes added (e.g. see #6022 regarding argmin), so perhaps tf.manip.roll should be modified, or maybe it should warn the user that the axis argument must not be negative. 

In general, is there a guideline for knowing when a negative axis is supported by a TensorFlow op? 

### System information
I am using TensorFlow 1.8 installed from binary, Python 3.6, and macOS 10.13.4.

### The problem

I expected tf.manip.roll to behave the same as numpy.roll when given a negative axis argument. As shown in the following code, this is not the case.

```python
x = tf.placeholder(tf.float32, [None, 5])
y = tf.manip.roll(x,1,1)
z = tf.manip.roll(x,1,-1)

with tf.Session() as sess:
    print(sess.run([y,z], feed_dict={x:[range(5)]}))
```

[array([[4., 0., 1., 2., 3.]], dtype=float32), array([[0., 1., 2., 3., 4.]], dtype=float32)]

```python
x= np.array([range(5)])
y = np.roll(x,1, axis=1)
z = np.roll(x,1, axis=-1)

print(y, z)
```
[[4 0 1 2 3]] [[4 0 1 2 3]]

Thank you!"
20099,QR factorization unstable on GPU,"### Describe the problem
Performing QR factorization of relatively large matrices on the GPU is numerically unstable. I am unsure if it's a tensorflow issue, or an upstrea cuSOLVE issue, as I don't have the time to write a custom cuSOLVE C call to test. The issue is neither present on the CPU, nor in numpy.

Steps to reproduce:

```
import tensorflow as tf
tf.enable_eager_execution()

with tf.device('/gpu:0'):
    q, r = tf.qr(tf.random_normal((2048, 1024))
    print(tf.norm(q, axis=0))
    print(tf.reduce_sum(tf.cast(tf.abs(tf.norm(q, axis=0) - 1) > 1, tf.float32)))
```

Run this multiple times and you get *wildly* different results, sometimes all norms are almost 1.0, sometimes the last entries have ""slightly"" larger norms 1-10, sometimes the last norms are huge (example: 3.1662303e+11), and sometimes they are NaN.

Running in float64 does not solve the issue.

Running on the CPU does solve the issue.

### System information

Tensorflow version as per `print(tf.GIT_VERSION, tf.VERSION)`:  `v1.7.0-3-g024aecf414 1.7.0` 

What follows is the output of `tf_env_collect.sh`:

Note 1: I cannot upgrade to latest TF to check it there right now.
Note 2: Multiple cuda versions are shown below, but only 9.0 is the first one in all `*PATH` variables.

```
== cat /etc/issue ===============================================
Linux grimbergen 4.4.0-116-generic #140~14.04.1-Ubuntu SMP Fri Feb 16 09:25:20 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""14.04.5 LTS, Trusty Tahr""
VERSION_ID=""14.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux grimbergen 4.4.0-116-generic #140~14.04.1-Ubuntu SMP Fri Feb 16 09:25:20 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy              1.14.2      
protobuf           3.5.2.post1 
tensorflow-gpu     1.7.0       

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.7.0
tf.GIT_VERSION = v1.7.0-3-g024aecf414
tf.COMPILER_VERSION = v1.7.0-3-g024aecf414
/home/beyer/.pyenv/versions/tensorflow-latest/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters

== env ==========================================================
LD_LIBRARY_PATH /home/beyer/inst/cudnn7/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64/:/usr/local/cuda-9.0/lib64:/home/beyer/inst/cudnn6/lib64:/usr/local/cuda-8.0/extras/CUPTI/lib64/:/usr/local/cuda-8.0/lib64:/home/beyer/inst/lib64:/home/beyer/inst/lib:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Mon Jun 18 18:14:33 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.111                Driver Version: 384.111                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 00000000:01:00.0 Off |                  N/A |
| 30%   50C    P8    22W / 250W |  11591MiB / 12187MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
| 44%   39C    P2    60W / 250W |  10625MiB / 11172MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      4713      C   ...3.6.2/envs/tensorflow-latest/bin/python 11581MiB |
|    1      4713      C   ...3.6.2/envs/tensorflow-latest/bin/python 10615MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.0/lib64/libcudart_static.a
/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176
/usr/local/cuda-7.5/lib/libcudart_static.a
/usr/local/cuda-7.5/lib/libcudart.so.7.5.18
/usr/local/cuda-7.5/doc/man/man7/libcudart.7
/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7
/usr/local/cuda-7.5/lib64/libcudart_static.a
/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18

"
20098,Feature Request: Document Best Practice For Feeding New Data to a Restored Metagraph,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes, custom code

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**:

Binary

- **TensorFlow version (use command below)**:

1.7

- **Python version**: 

3.x


### Describe the problem
I would like to produce and persist a model, represented by a metagraph, then restore it and feed it from a different data source, such as from a different Dataset. Despite being a natural thing to want to do, it is not easy to find out how to do this from official documentation. In particular, there's no  'best practice' shown anywhere in the docs.

Today, the only way I have found of doing this is to build the graph with a feedable iterator (as described in the comments to #11679), and then saving+restoring the iterator _handle_ so that I can feed in new iterator by handle on every train step.

As a secondary issue, I think it would make more sense to save and restore a reinitializable iterator to the metagraph. Then, in the restored session, I could pull that reinitializable iterator out of the restored metagraph and reinitialize it from a new dataset.  No way that I tried of doing this actually worked. Although I could save the iterator with `make_saveable_from_iterator_`, the necessary `make_initializer` function wasn't present on the restored object; it didn't survive the roundtrip to disk.


### Source code / logs
@annarailton gives a full source code for the handle-based method of iterator persistence in this comment:
https://github.com/tensorflow/tensorflow/issues/11679#issuecomment-395722710

I independently came up with functionally equivalent code after several hours of work, then found her code by searching to see if anyone else was doing it with feedables. I was searching because it felt wrongish (inefficient) and the docs gave no endorsement for this approach.

So in the end, I have two related requests:

1. Document the current best practice for attaching new data to the inputs of a restored metagraph.

e.g. https://www.tensorflow.org/programmers_guide/datasets#saving_iterator_state should show this best practice. I believe this is by far the most common thing to want to do with a restored metagraph, likely to be far more common than resuming an existing iterator as shown in the docs.

2. Provide an efficient way to attach a new data to a restored metagraph.

It may be that the handle lookup in the feedable iterator method is efficient. In that case, this second request is a no-op. 

Finally, I'm happy to give you a PR for datasets#saving_iterator_state to show the handle based feeding method, if you'd like one."
20096,ModuleNotFoundError: No module named 'tensorflow.keras',"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (CPU linux wheel)
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5

### Describe the problem

Using Tensorflow 1.8.0, running:
```python
from tensorflow.keras.utils import Progbar
```

raises an error:
```
ModuleNotFoundError: No module named 'tensorflow.keras'
```

Of course, `from tensorflow import keras` works fine.

This is a minor nit since there's an obvious workaround, but IMO this is pretty unintuitive behavior for how modules work in Python. I'm not sure what kind of sorcery is going on to end up with this result :laughing:."
20094,"Wrong Results for tf.matmul(X,Y) with X.shape[0]>2^21","

------------------------

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win 10, 64bit
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8.0 (same issue with 1.5.x)
- **Python version**: 3.5.3
- **GPU model and memory**: GTX 1080 


### Describe the problem
When using `tf.matmul(X,Y)` with `X.shape==[n,2]` ,`Y.shape==[2,2]` **AND** `n>2^21 #=2097152` only the first `[0:2^21 , : ]` results are correct

- Does only occur on GPU
- Does not occur if Y==tf.eye(2)
- it is possible to circumvent the problem by splitting the operation into chunks of `n<=2**21`

-> i guess a solution would be to automaticaly split the operation or warn the user 

### Source code
`import tensorflow as tf`

`X=tf.ones([10+2**21,2],dtype=tf.float32)`
`Y=tf.constant([[1,0],[0.01,1]],dtype=tf.float32)`
`mul=tf.matmul(X,Y)`

`sess=tf.Session()`
`sess.run(tf.global_variables_initializer())`
`result=sess.run(mul)`
`sess.close()`

`print(""These are ok: "" + str(result[2**21-2:2**21,:]))`

`print(""These are wrong: "" + str(result[2**21:2**21+2,:]))`


### Output Log

_2018-06-18 14:49:53.627009: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-06-18 14:49:53.868050: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:03:00.0
totalMemory: 8.00GiB freeMemory: 6.61GiB
2018-06-18 14:49:53.868514: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1435] Adding visible gpu devices: 0
2018-06-18 14:49:54.450846: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-18 14:49:54.451158: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:929]      0 
2018-06-18 14:49:54.451346: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:942] 0:   N 
2018-06-18 14:49:54.451641: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6384 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)_

These are ok: [[1.01 1.  ]
 [1.01 1.  ]]
These are wrong: [[0. 0.]
 [0. 0.]]
"
20093,Feature request: add Tensorflow.js,"Thanks for this tutorial, found it super-useful and helped me understand a lot. It would be great to see a version that uses Tensorflow.js / for Node, and how this works differently."
20092,Tensorflow Website XSRF Token missing or incorrect,"The error occurs when I click develop button in ""www.tensorflow.org/programmers_guide/variables"" or in everywhere. My default lang is set to English(but it does not matter and has influence only on the bottom menu). But when I'm trying to change the language to Chinese I get the following error message:

- XSRF Token missing or incorrect

![image](https://user-images.githubusercontent.com/19337606/41533342-02b6581e-732d-11e8-95a9-afbe28a40dbe.png)

![image](https://user-images.githubusercontent.com/19337606/41533370-1cda29dc-732d-11e8-9912-2eb9583feb71.png)

Windows 10
Version 67.0.3396.87 (Official Build) (64-bit)

"
20091,NaN appearing on tf.gradients calculation with tf.where and division by zero on the false branch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, script is below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux 4.15.0-23-generic #25-Ubuntu SMP Wed May 23 18:02:16 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""18.04 LTS (Bionic Beaver)""
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: 
Python 3.6.5
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a, using CPU version
- **GPU model and memory**: n/a using CPU
- **Exact command to reproduce**: just run ""python3 script.py""

### Describe the problem
When using the tf.where function where a division by zero exists in one of the two where branches, you get a NaN gradient even if the division by zero was on the where branch which was not executed.

This seems similar to https://github.com/tensorflow/tensorflow/issues/2540 but the workarounds suggested there (e.g. using tf.boolean_mask) did not work.

### Source code / logs

```
import tensorflow as tf
sess = tf.Session()
W1 = tf.Variable([2.0])
W2 = tf.Variable([0.0])
output=tf.where(W1>4, W1/W2, tf.zeros_like(W1))  # gives correct answer (zero) since W1>4 is false
gradient=tf.gradients(output, W2)[0] # should be zero, but it gives NaN
sess.run(tf.global_variables_initializer())
print(sess.run([output, gradient]))
```

# Program output:
#[array([0.], dtype=float32), array([nan], dtype=float32)]
"
20090,Error reported to Coordinator: /dbfs/FileStore/tables/TFOS/trainData/checkpoint.tmpb97208e81436466b80430829067e21d8; Input/output error,"018-06-12 14:59:28,653 INFO (MainThread-2183) global step 75: loss = 1.4016 (7.176 sec/step)
2018-06-12 14:59:35,636 INFO (MainThread-2183) global step 76: loss = 1.3862 (6.978 sec/step)
2018-06-12 14:59:43,038 INFO (MainThread-2183) global step 77: loss = 3.2210 (7.398 sec/step)
2018-06-12 14:59:50,353 INFO (MainThread-2183) global step 78: loss = 1.3114 (7.311 sec/step)
2018-06-12 14:59:57,775 INFO (MainThread-2183) global step 79: loss = 1.3847 (7.417 sec/step)
2018-06-12 15:00:05,181 INFO (MainThread-2183) global step 80: loss = 1.3856 (7.402 sec/step)
2018-06-12 15:00:12,513 INFO (MainThread-2183) global step 81: loss = 1.2985 (7.327 sec/step)
2018-06-12 15:00:20,160 INFO (MainThread-2183) global step 82: loss = 1.2625 (7.643 sec/step)
2018-06-12 15:00:27,564 INFO (MainThread-2183) global step 83: loss = 1.2674 (7.400 sec/step)
2018-06-12 15:00:32,553 INFO (Thread-4-2183) Error reported to Coordinator: /dbfs/FileStore/tables/TFOS/trainData/checkpoint.tmpb97208e81436466b80430829067e21d8; Input/output error
Traceback (most recent call last):
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
    yield
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 495, in run
    self.run_loop()
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 1104, in run_loop
    global_step=self._sv.global_step)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1686, in save
    save_relative_paths=self._save_relative_paths)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1041, in _update_checkpoint_state
    text_format.MessageToString(ckpt))
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 431, in atomic_write_string_to_file
    rename(temp_pathname, filename, overwrite)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 410, in rename
    compat.as_bytes(oldname), compat.as_bytes(newname), overwrite, status)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.UnknownError: /dbfs/FileStore/tables/TFOS/trainData/checkpoint.tmpb97208e81436466b80430829067e21d8; Input/output error
2018-06-12 15:00:34,910 INFO (MainThread-2183) global step 84: loss = 2.6778 (7.342 sec/step)
2018-06-12 15:00:34,913 INFO (MainThread-2183) Finished training! Saving model to disk.
18/06/12 15:02:02 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 990, in managed_session
    yield sess
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/contrib/slim/python/slim/learning.py"", line 780, in train
    sv.saver.save(sess, sv.save_path, global_step=sv.global_step)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1686, in save
    save_relative_paths=self._save_relative_paths)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1041, in _update_checkpoint_state
    text_format.MessageToString(ckpt))
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 431, in atomic_write_string_to_file
    rename(temp_pathname, filename, overwrite)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py"", line 410, in rename
    compat.as_bytes(oldname), compat.as_bytes(newname), overwrite, status)
  File ""/databricks/python/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.UnknownError: /dbfs/FileStore/tables/TFOS/trainData/checkpoint.tmp51f40c3652e54c3b93209b402acfc49a; Input/output error

"
20089,Keras predict_on_batch() won't work on the first call,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: see source code

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Calling `model.predict_on_batch(x)` the first time results in the following error:

```
Traceback (most recent call last):
  File ""C:\Users\user\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2963, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-ae1592c2ea28>"", line 22, in <module>
    model.predict_on_batch(x)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\python\keras\_impl\keras\engine\training.py"", line 1459, in predict_on_batch
    return self(inputs)  # pylint: disable=not-callable
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\python\keras\_impl\keras\engine\base_layer.py"", line 314, in __call__
    output = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""C:\Users\user\Anaconda3\lib\site-packages\tensorflow\python\layers\base.py"", line 630, in __call__
    in_deferred_mode = isinstance(input_list[0], _DeferredTensor)
IndexError: list index out of range
```
However, executing the same line a second time gives the expected results.

### Source code / logs

```
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()

class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.dense1 = tf.keras.layers.Dense(10)
        self.dense2 = tf.keras.layers.Dense(2, activation='softmax')

    def call(self, inputs, training=None, mask=None):
        results = self.dense1(inputs)
        results = self.dense2(results)

        return results


x = tf.random_uniform((100, 10))

model = MyModel()
model.predict_on_batch(x)
```
"
20088,"Tensorflow 1.8.0, GPU Build fails with error C2872: 'GPUDevice': ambiguous symbol","### Describe the problem
Trying to compile Tensorflow 1.8.0 with GPU support using CUDA 9.0 and CUDNN 7.1 on Windows. Compilation fails.

### Source code / logs
```
ERROR: C:/l/tensorflow-gpu-base_1529265306395/work/tensorflow/contrib/fused_conv/BUILD:82:1: C++ compilation of rule '//tensorflow/contrib/fused_conv:python/ops/_fused_conv2d_bias_activation_op.so' failed (Exit 2): msvc_cl.bat failed: error executing command
  cd C:/t/_bazel_nwani/0uz4ee68/execroot/org_tensorflow
  SET CUDA_COMPUTE_CAPABILITIE=None
    SET CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0
    SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0
    SET CUDNN_INSTALL_PATH=C:/Users/nwani/Downloads/cudnn-9.0-windows10-x64-v7.1/cuda
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.10240.0\ucrt;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\8.1\include\\shared;C:\Program Files (x86)\Windows Kits\8.1\include\\um;C:\Program Files (x86)\Windows Kits\8.1\include\\winrt;
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\LIB\amd64;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\LIB\amd64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.10240.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\lib\um\x64;C:\Program Files (x86)\Windows Kits\8.1\lib\winv6.3\um\x64;
    SET NO_WHOLE_ARCHIVE_OPTION=1
    SET PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0/bin;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team Tools\Performance Tools;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;C:\Program Files (x86)\Windows Kits\8.1\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;;C:\WINDOWS\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/l/tensorflow-gpu-base_1529265306395/_h_env/python.exe
    SET PYTHON_LIB_PATH=C:/l/tensorflow-gpu-base_1529265306395/_h_env/Lib/site-packages
    SET TEMP=C:\Users\nwani\AppData\Local\Temp
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0,3.5,5.2,6.0,6.1,7.0
    SET TF_CUDA_VERSION=9.0
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
    SET TMP=C:\Users\nwani\AppData\Local\Temp
  external/local_config_cc/wrapper/bin/msvc_cl.bat /c tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.cc /Fobazel-out/x64_windows-py3-opt/bin/tensorflow/contrib/fused_conv/_objs/python/ops/_fused_conv2d_bias_activation_op.so/tensorflow/contrib/fused_conv/kernels/fused_conv2d_bias_activation_op.o /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 -Xcompilation-mode=opt -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -w /I. /Ibazel-out/x64_windows-py3-opt/genfiles /Iexternal/protobuf_archive /Ibazel-out/x64_windows-py3-opt/genfiles/external/protobuf_archive /Iexternal/bazel_tools /Ibazel-out/x64_windows-py3-opt/genfiles/external/bazel_tools /Iexternal/eigen_archive /Ibazel-out/x64_windows-py3-opt/genfiles/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-py3-opt/genfiles/external/local_config_sycl /Iexternal/local_config_cuda /Ibazel-out/x64_windows-py3-opt/genfiles/external/local_config_cuda /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-py3-opt/genfiles/external/protobuf_archive/src /Iexternal/eigen_archive /Ibazel-out/x64_windows-py3-opt/genfiles/external/eigen_archive /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-py3-opt/genfiles/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-py3-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-py3-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt /DEIGEN_MPL2_ONLY /showIncludes /MD /O2 /DNDEBUG -DGOOGLE_CUDA=1 -DTENSORFLOW_MONOLITHIC_BUILD /D__VERSION__=""MSVC"" /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /U_HAS_EXCEPTIONS /D_HAS_EXCEPTIONS=1 /EHsc /DNOGDI /UTF_COMPILE_LIBRARY
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(305): error C2872: 'GPUDevice': ambiguous symbol
.\tensorflow/core/kernels/conv_ops_gpu.h(181): note: could be 'Eigen::GpuDevice tensorflow::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(46): note: or       'tensorflow::`anonymous-namespace'::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(631): error C2872: 'GPUDevice': ambiguous symbol
.\tensorflow/core/kernels/conv_ops_gpu.h(181): note: could be 'Eigen::GpuDevice tensorflow::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(46): note: or       'tensorflow::`anonymous-namespace'::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(632): error C2872: 'GPUDevice': ambiguous symbol
.\tensorflow/core/kernels/conv_ops_gpu.h(181): note: could be 'Eigen::GpuDevice tensorflow::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(46): note: or       'tensorflow::`anonymous-namespace'::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(645): error C2872: 'GPUDevice': ambiguous symbol
.\tensorflow/core/kernels/conv_ops_gpu.h(181): note: could be 'Eigen::GpuDevice tensorflow::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(46): note: or       'tensorflow::`anonymous-namespace'::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(654): error C2872: 'GPUDevice': ambiguous symbol
.\tensorflow/core/kernels/conv_ops_gpu.h(181): note: could be 'Eigen::GpuDevice tensorflow::GPUDevice'
C:\t\_bazel_nwani\0uz4ee68\execroot\org_tensorflow\tensorflow\contrib\fused_conv\kernels\fused_conv2d_bias_activation_op.cc(46): note: or       'tensorflow::`anonymous-namespace'::GPUDevice'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1314.928s, Critical Path: 343.16s
FAILED: Build did NOT complete successfully
+ exit 1
```"
20087,Python double free or corruption,"Hi, 

I try tensorflow-gpu 1.9.0rc1, but got the following error. I use ubuntu 16.04 (fresh install last night), numpy=1.13.3 (as required by 1.9.0rc1). Anyone tell me what the reason for this error? Thanks in advance.

Tuan 

`*** Error in `python': double free or corruption (out): 0x00007ff8980021b0 ***
*** Error in `python': double free or corruption (out): 0x00007ff898001d20 ***
======= Backtrace: =========
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7ff9781137e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7ff97811c37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7ff97812053c]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow8EventMgr10PollEventsEbPNS_3gtl13InlinedVectorINS0_5InUseELi4EEE+0x6fb)[0x7ff943fcb14b]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow7GPUUtil18CopyGPUTensorToCPUEPNS_6DeviceEPKNS_13DeviceContextEPKNS_6TensorEPS6_St8functionIFvRKNS_6StatusEEE+0x3ff)[0x7ff93e95241f]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow16GPUDeviceContext21CopyDeviceTensorToCPUEPKNS_6TensorENS_11StringPieceEPNS_6DeviceEPS1_St8functionIFvRKNS_6StatusEEE+0x82)[0x7ff93e953a72]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x5f59ef)[0x7ff93e97e9ef]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow10CopyTensor6ViaDMAENS_11StringPieceEPNS_13DeviceContextES3_PNS_6DeviceES5_NS_19AllocatorAttributesES6_PKNS_6TensorEPS7_St8functionIFvRKNS_6StatusEEE+0x67a)[0x7ff93e97f53a]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow22IntraProcessRendezvous18SameWorkerRecvDoneERKNS_10Rendezvous9ParsedKeyERKNS1_4ArgsES7_RKNS_6TensorEPS8_St8functionIFvRKNS_6StatusEEE+0x4cc)[0x7ff93e9c7cac]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x63f2bd)[0x7ff93e9c82bd]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow19LocalRendezvousImpl9RecvAsyncERKNS_10Rendezvous9ParsedKeyERKNS1_4ArgsESt8functionIFvRKNS_6StatusES7_S7_RKNS_6TensorEbEE+0x961)[0x7ff93e7ebaf1]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN10tensorflow22IntraProcessRendezvous9RecvAsyncERKNS_10Rendezvous9ParsedKeyERKNS1_4ArgsESt8functionIFvRKNS_6StatusES7_S7_RKNS_6TensorEbEE+0x473)[0x7ff93e9c8903]
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7ff9781137e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7ff97811c37a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7ff97812053c]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x6036b9)[0x7ff93e98c6b9]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x606ba8)[0x7ff93e98fba8]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x60c8c3)[0x7ff93e9958c3]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(+0x60ca2a)[0x7ff93e995a2a]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x21a)[0x7ff93e9f3fba]
/home/anhnt/tf-190/venv/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x32)[0x7ff93e9f3062]
/usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb8c80)[0x7ff921537c80]
/lib/x86_64-linux-gnu/libpthread.so.0(+0x76ba)[0x7ff97846d6ba]
/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7ff9781a341d]`"
20086,Potential overflow in libhdfs wrapper,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see below

### Describe the problem

The following snippet works fine until 2^30; 2^31 results in EINVAL, and >2^31 it produces zero-sized files. I wonder if this is an issue in the TF wrapper or rather in libhdfs itself.

```python
>>> for size in [2**30, 2**31, 2**32]:
...     try:
...         result = write_read(""hdfs://root/user/s.lebedev/test"", size)
...     except Exception as e:
...         result = e
...     print("">"", size, ""<"", result)
...
> 1073741824 < 1073741824
> 2147483648 < hdfs://root/user/s.lebedev/test; Invalid argument
> 4294967296 < 0
```

### Source code / logs

```python
def write_read(path, size):
    b = bytes(memoryview(np.ones(size, dtype=np.uint8)))
    with tf.gfile.Open(path, ""wb"") as f:
        f.write(b)
    return len(tf.gfile.Open(path, ""rb"").read())
```"
20085,Codelab: Tensorlab for Poets not working due to incomplete documentation,"on Tensor flow for poets step 3: 
https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3

It appears to be missing some vital steps

It says: 
```Start your retraining with one big command (note the --summaries_dir option, sending training progress reports to the directory that tensorboard is monitoring) :

python -m scripts.retrain \
  --bottleneck_dir=tf_files/bottlenecks \
  --how_many_training_steps=500 \
  --model_dir=tf_files/models/ \
  --summaries_dir=tf_files/training_summaries/""${ARCHITECTURE}"" \
  --output_graph=tf_files/retrained_graph.pb \
  --output_labels=tf_files/retrained_labels.txt \
  --architecture=""${ARCHITECTURE}"" \
  --image_dir=tf_files/flower_photos```
This fails with the following errror: 
```
/Users/grantkemp/tensorflow/bin/python: Error while finding module specification for 'scripts.retrain' (ModuleNotFoundError: No module named 'scripts')
```

**Solution  ( It should say!)** 

In order to continue - you need to cd ..
 till you get to the folder with scripts in it before continuing

"
20081,ghfcxzcgvhbjkojhghjuhbgbhgb       Zxcvbn./ ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
20080,TF1.9rc missing headers,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.9.0-rc0-35-g17d6639b55 1.9.0-rc1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
```
HOROVOD_WITH_TENSORFLOW=1 HOROVOD_CUDA_HOME=/xx/cuda/9.0/ HOROVOD_NCCL_HOME=/xx/NCCL/2.2.13/ HOROVOD_GPU_ALLREDUCE=NCCL pip install --no-cache-dir horovod --user -U
```

Logs:
```
 In file included from /xx/.local/lib/python3.6/site-packages/tensorflow/include/tensorflow/stream_executor/dnn.h:33:0,
                     from /xx/.local/lib/python3.6/site-packages/tensorflow/include/tensorflow/stream_executor/stream.h:30,
                     from horovod/tensorflow/mpi_ops.cc:29:
    /xx/.local/lib/python3.6/site-packages/tensorflow/include/tensorflow/stream_executor/lib/statusor.h:21:46: fatal error: tensorflow/compiler/xla/statusor.h: No such file or di
rectory
    compilation terminated.
```

Looks like some necessary headers are missing in this release."
20075,error in running a LSTM programme,"i am writing a basic LSTM program for text generation. when i am writing line:
model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2]), return_sequences=True))
following error occurring, may i know what is wrong with this:
python /home/srinath/char_gen.py 
Using TensorFlow backend.
Total Characters 144413
Total Vocab 45
Total Patterns: 144313
Traceback (most recent call last):
  File ""/home/srinath/char_gen.py"", line 63, in <module>
    model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2]), return_sequences=True))
  File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py"", line 166, in add
    layer(x)
  File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 500, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 460, in __call__
    output = self.call(inputs, **kwargs)
  File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 2112, in call
    initial_state=initial_state)
  File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 609, in call
    input_length=timesteps)
  File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2957, in rnn
    maximum_iterations=input_length)
TypeError: while_loop() got an unexpected keyword argument 'maximum_iterations'
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):
<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f75882d7da0>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
['File ""/home/srinath/char_gen.py"", line 63, in <module>\n    model.add(LSTM(256, input_shape=(x.shape[1], x.shape[2]), return_sequences=True))', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py"", line 166, in add\n    layer(x)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 500, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py"", line 460, in __call__\n    output = self.call(inputs, **kwargs)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 2112, in call\n    initial_state=initial_state)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/layers/recurrent.py"", line 609, in call\n    input_length=timesteps)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py"", line 2877, in rnn\n    input_ta = input_ta.unstack(inputs)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py"", line 413, in unstack\n    indices=math_ops.range(0, num_elements), value=value, name=name)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 170, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 139, in _add_should_use_warning\n    wrapped = TFShouldUseWarningWrapper(x)', 'File ""/home/srinath/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py"", line 96, in __init__\n    stack = [s.strip() for s in traceback.format_stack()]']
==================================
please help me if possible.
"
20074,Colocation bug for distributed training(NMT model),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.6.1
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.13.0
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**: 
9/7
- **GPU model and memory**:
TitanXP/ 12G
- **Exact command to reproduce**:

### Describe the problem
I saw the lines in [NMT](https://github.com/tensorflow/nmt/blob/365e7386e6659526f00fa4ad17eefb13d52e3706/nmt/model_helper.py#L310). If embedding parameter is set in parameter server, embedding_lookup must follow the device placement but the result is opposite(embedding parameter follows embedding_lookup). I think the placement of colocation group in `placer.cc` is wrong so I tried to fix it but it's complicated. Do you have any plan to fix it? or Can you give a suggestion?

### Source code / logs
"
20073,Can't load hdf5 files when using tf.keras.SequentialModel.add() and ModelCheckpoint(),"Bug.  Compiled Tensorflow 1.8 and 1.9rc0 both fail. Linux Mint 18.2.  Python-3.5.2  CUDA 9.0/CuDNN 7.0

Have I written custom code: I've attached a file
OS Platform and Distribution: Linux Mint 18.2
TensorFlow installed from: source
TensorFlow version: 1.8 and 1.9rc0
Bazel version: 0.13.1
CUDA/cuDNN version: 9.0/7.0
GPU model and memory: Nvidia 1080Ti
Exact command to reproduce: run the attached script.


When using tf.keras.SequentialModel to build a network, and using tf.keras.callbacks.ModelCheckpoint to save the model/weights during training, the saved hdf5 file cannot be loaded into the same model.

I believe the same problem was observed in keras-1.0
See here: https://github.com/keras-team/keras/issues/2281
And reportedly fixed here: https://github.com/keras-team/keras/commit/1206120d1084cbe45dc2876f002cb572a97e3844

I've attached a minimal script which will readily reproduce the problem here: [save-bug.txt](https://github.com/tensorflow/tensorflow/files/2107894/save-bug.txt)

The output error I receive when attempting to load the model weights into the same model which I saved them from is:

```
Traceback (most recent call last):
  File ""./save-bug.py"", line 38, in <module>
    predict()
  File ""./save-bug.py"", line 31, in predict
    model.load_weights('test.hdf5');
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/network.py"", line 1190, in load_weights
    saving.load_weights_from_hdf5_group(f, self.layers)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/saving.py"", line 697, in load_weights_from_hdf5_group
    ' layers.')
ValueError: You are trying to load a weight file containing 1 layers into a model with 0 layers.
```
"
20072,Partial model loaded SavedModelBundle without exception,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: None
- **Python version**:  None
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None

### Describe the problem
Background

I am training a tensorflow with python and trying to load it in java for serving with SavedModelBundle.

Sample mode directory
.
├── saved_model.pb
└── variables
    ├── variables.data-00000-of-00001
    └── variables.index

Problem

The thing is my model is published on hdfs and during downloading, some instances of the prediction server downloaded a partial model path with incomplete variables. Somehow SavedModelBundle is still able to load the partial model path into memory. Then when I actually query the service, I will get a lot of java.lang.IllegalStateException: Attempting to use uninitialized value *** in some node.

My question is how can I prevent this from happening? I can think of

I need to check if downloading is successful before loading it.
Have a way to throw an exception in SavedModelBundle when loading the partial model.

### Source code / logs
Exceptions like 
java.lang.IllegalStateException: Attempting to use uninitialized value ***
"
20071,Tensorflow failed when build with CMake,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 7
- **TensorFlow installed from (source or binary)**:Source
- **TensorFlow version (use command below)**:1.8
- **Python version**: Anaconda 5.1.0 (Python 3.6 64-bit)
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:VS2015
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:GeFore GTX 1080
- **Exact command to reproduce**:N/A


### Describe the problem
 I compile according to the document and report an error when ""MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj""is executed: 

CUSTOMBUILD : error : RPC failed;curl 18 transfer closed with outstanding read data remaining [E:\Tensorflow\tensorflow\tensorflow
contrib\cmake\build\grpc.vcxproj]

[screenshot](https://note.youdao.com/yws/public/resource/103710ae2f5c53643adf49949dd427b2/xmlnote/B89834353E21430BBB709FD8777C0414/3698)
could you please help take a look at this?Thanks!


"
20070,tf.set_shape bug for 3D data space?,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 3.6.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0/cuDNN 7.1.4
- **GPU model and memory**: NVIDIA Tesla K80 on GCP
- **Exact command to reproduce**:

### Describe the problem

Have bugs in TF_GraphSetTensorShape_wrapper function when dealing with high-dimensional shapes.

<img width=""858"" alt=""error1"" src=""https://user-images.githubusercontent.com/19757981/41492650-59506ac0-70f8-11e8-95dd-9f0d3c29d071.png"">

In my code, the images_in is a tensor which represents a 3D model. I use tf.set_shape but after I print out the result, the shape is wrong. I set num_channels as 1 and it also shows 1 when I print it out. But the second shape of the images_in is 8 which not equals to num_channels. 

![error4](https://user-images.githubusercontent.com/19757981/41492752-1109bd7e-70f9-11e8-80bf-926b8582a223.png)

I looked into tf.set_shape() below and found if I use unknown shape, it will call a function called: TF_GraphSetTensorShape_wrapper. 

<img width=""505"" alt=""error2"" src=""https://user-images.githubusercontent.com/19757981/41492836-a849466e-70f9-11e8-9ce1-7b4af79ccb66.png"">

But I cannot see what this function does exactly since it might be a c-embedded function.

<img width=""742"" alt=""error3"" src=""https://user-images.githubusercontent.com/19757981/41492962-a1e25d32-70fa-11e8-9271-4f38627f61c3.png"">

I have tried this function in 2D data space if I use images_in.set_shape([None, num_channels, resolution, resolution]) and the shapes are correct.

So I assume there might be something wrong with TF_GraphSetTensorShape_wrapper function when dealing with high-dimensional shapes? Or does it hard code somewhere and cause the problem?

Thanks.
"
20068,streaming data from google cloud storage to tensorflow input pipeline is slow,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04 and MacOS High Sierra 10.13.4
- **TensorFlow installed from (source or binary)**: docker and virtualenv
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: N/A

Describe the problem:
My data is stored on google cloud storage (millions of small audios); my tensorflow input pipeline sample code is below.
 
tf.data.Dataset.from_generator(generator_filename_func).\
map(signal_processing_func, num_parallel_calls=CPU_NUM).\
batch(100).\
make_one_shot_iterator()

The pipeline starts with a generator (a generator that generates audio filenames from google cloud storage); then run signal processing with map function and multithread. 

The input pipeline is fast when reading data from local disk (download audios to cloud compute engine VM), however, reading data from mounted folder (mount google cloud storage to the folder with gcsfuse command) is slow (about 5-10 times slower). I know google cloud supports using python multithread to read data, but it does not seem to be compatible with tensorflow input pipeline. I also tried google.cloud.storage to stream data, it's also very slow for small files. How should I stream data from google cloud storage to tensorflow input pipeline with low latency? What tools/library is recommended and compatible with tensorflow input pipeline?

The other weird thing is that the pipeline speed does not change much as I add more CPU and SSD. I believe the bottleneck is reading files, how can I optimize reading many small files in the tensorflow input pipeline?

"
20067,Fail to find the dnn implementation.,"Last keras, tensorflow.
Using anaconda with jupiter notebook.
It sometimes breaks then I use CuDNNGRU.
Restarting jupiter helps.








UnknownError: Fail to find the dnn implementation.
	 [[Node: cu_dnngru_1/CudnnRNN = CudnnRNN[T=DT_FLOAT, direction=""unidirectional"", dropout=0, input_mode=""linear_input"", is_training=true, rnn_mode=""gru"", seed=87654321, seed2=0, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](cu_dnngru_1/transpose, cu_dnngru_1/ExpandDims_1, cu_dnngru_1/Const_1, cu_dnngru_1/concat)]]
	 [[Node: loss/mul/_73 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_618_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'cu_dnngru_1/CudnnRNN', defined at:
  File ""e:\neuro_projects\anaconda3\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""e:\neuro_projects\anaconda3\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel_launcher.py"", line 16, in <module>
    app.launch_new_instance()
  File ""e:\neuro_projects\anaconda3\lib\site-packages\traitlets\config\application.py"", line 658, in launch_instance
    app.start()
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel\kernelapp.py"", line 486, in start
    self.io_loop.start()
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tornado\platform\asyncio.py"", line 127, in start
    self.asyncio_loop.run_forever()
  File ""e:\neuro_projects\anaconda3\lib\asyncio\base_events.py"", line 421, in run_forever
    self._run_once()
  File ""e:\neuro_projects\anaconda3\lib\asyncio\base_events.py"", line 1431, in _run_once
    handle._run()
  File ""e:\neuro_projects\anaconda3\lib\asyncio\events.py"", line 145, in _run
    self._callback(*self._args)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tornado\platform\asyncio.py"", line 117, in _handle_events
    handler_func(fileobj, events)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tornado\stack_context.py"", line 276, in null_wrapper
    return fn(*args, **kwargs)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 450, in _handle_events
    self._handle_recv()
  File ""e:\neuro_projects\anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 480, in _handle_recv
    self._run_callback(callback, msg)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 432, in _run_callback
    callback(*args, **kwargs)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tornado\stack_context.py"", line 276, in null_wrapper
    return fn(*args, **kwargs)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 233, in dispatch_shell
    handler(stream, idents, msg)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel\ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\ipykernel\zmqshell.py"", line 537, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2662, in run_cell
    raw_cell, store_history, silent, shell_futures)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2785, in _run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2903, in run_ast_nodes
    if self.run_code(code, result):
  File ""e:\neuro_projects\anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2963, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-982a486f943a>"", line 44, in <module>
    i = CuDNNGRU(128)(i)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\keras\layers\recurrent.py"", line 500, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\keras\engine\base_layer.py"", line 460, in __call__
    output = self.call(inputs, **kwargs)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\keras\layers\cudnn_recurrent.py"", line 90, in call
    output, states = self._process_batch(inputs, initial_state)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\keras\layers\cudnn_recurrent.py"", line 297, in _process_batch
    is_training=True)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\ops\cudnn_rnn_ops.py"", line 1552, in __call__
    seed=self._seed)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\ops\cudnn_rnn_ops.py"", line 941, in _cudnn_rnn_no_input_c
    direction, dropout, seed, name)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\ops\cudnn_rnn_ops.py"", line 855, in _cudnn_rnn
    name=name)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\python\ops\gen_cudnn_rnn_ops.py"", line 143, in cudnn_rnn
    is_training=is_training, name=name)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 3309, in create_op
    op_def=op_def)
  File ""e:\neuro_projects\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1669, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnknownError (see above for traceback): Fail to find the dnn implementation.
	 [[Node: cu_dnngru_1/CudnnRNN = CudnnRNN[T=DT_FLOAT, direction=""unidirectional"", dropout=0, input_mode=""linear_input"", is_training=true, rnn_mode=""gru"", seed=87654321, seed2=0, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](cu_dnngru_1/transpose, cu_dnngru_1/ExpandDims_1, cu_dnngru_1/Const_1, cu_dnngru_1/concat)]]
	 [[Node: loss/mul/_73 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_618_loss/mul"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]"
20062,Memory leak using loss in Eager Execution,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Xubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.8.0-3211-g1aea422 1.9.0-rc0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.1 / 7.1
- **GPU model and memory**: GeForce GTX 960M - 2GB
- **Exact command to reproduce**: The following code:

```python
import tensorflow as tf
tf.enable_eager_execution()

layer = tf.keras.layers.Dense(5)
inputs = tf.zeros([32, 100], tf.float32)
labels = tf.zeros([32], tf.int64)

for i in range(100000):
  with tf.GradientTape() as tape:
    logits = layer(inputs)
    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)
```

### Describe the problem

I observe a memory leak when computing the loss using the code above. I also tried using other losses, such as `tf.losses.mean_squared_error` and `tf.losses.hinge_loss`, and I observed similar leaks. Using memory_profiler produces the following plot:
![mplot_leak_entropy](https://user-images.githubusercontent.com/24420973/41473326-53606eb2-708f-11e8-9618-2f7696781828.png)

I tried to use the workaround suggested by @allenlavoie in #19671, but it does not seem to work in this case.

### Source code / logs

I used pympler to track the memory usage, by adding it to the code:

```python
import tensorflow as tf
from pympler.tracker import SummaryTracker
tf.enable_eager_execution()

layer = tf.keras.layers.Dense(5)
inputs = tf.zeros([32, 100], tf.float32)
labels = tf.zeros([32], tf.int64)

tracker = SummaryTracker()

for i in range(100000):
  with tf.GradientTape() as tape:
    logits = layer(inputs)
    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)
  if i % 1000 == 0:
    tracker.print_diff()
```

After a few rounds, it starts to produce the following output:
```bash
                types |   # objects |   total size
===================== | =========== | ============
  <class 'EagerTensor |        1000 |    156.25 KB
         <class 'list |           0 |      7.14 KB
```

So it seems an EagerTensor is being created and not released at every iteration, which may be the cause of the leak.

I thank @allenlavoie and @akshaym for solving my previous issues in #19385. I think this problem is related to those."
20061,Wide Deep model erased all my files?,"I downloaded the models-master folder to my harddrive and ran the wide-deep.py script.  Next thing I know, all the files on my harddrive are wiped out.  Is there a script that deletes the directory? "
20060,quantized model throw exception: max_y must be larger than min_y,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Tensorflow docker image 1.7.1-devel-gpu
- **TensorFlow installed from (source or binary)**:
Tensorflow docker image 1.7.1-devel-gpu
- **TensorFlow version (use command below)**:
Tensorflow docker image 1.7.1-devel-gpu
- **Python version**: 
Python 2.7 from Tensorflow docker image 1.7.1-devel-gpu
- **Bazel version (if compiling from source)**:
Bazel from Tensorflow docker image 1.7.1-devel-gpu
- **GCC/Compiler version (if compiling from source)**:
GCC from Tensorflow docker image 1.7.1-devel-gpu
- **CUDA/cuDNN version**:
9.0/7.5
- **GPU model and memory**:
GTX 1080Ti
- **Exact command to reproduce**:
See below

### Describe the problem

Inference with quantized graph(transform_graph tool with below command). 
```
/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=../transformer/train/freeze_model_fixed.pb --out_graph=../transformer/train/quantized_graph.pb --inputs='inputs' --outputs='strided_slice_9,Select_1' --transforms='add_default_attributes remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes strip_unused_nodes  sort_by_execution_order'
```

### Source code / logs

The exception:
>>> InvalidArgumentError (see above for traceback): max_y must be larger than min_y.
[[Node: while/add_1/eightbit = QuantizedAdd[T1=DT_QUINT8, T2=DT_QUINT8, Toutput=DT_QINT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](while/add_1_eightbit/while/Min/quantize, while/mul_1/eightbit/requantize, while/add_1_eightbit/while/Min/quantize:1, while/add_1_eightbit/while/Min/quantize:2, while/mul_1/eightbit/requantize:1, while/mul_1/eightbit/requantize:2)]] 
[[Node: while/body/parallel_0/body/decoder/layer_4/encdec_attention/multihead_attention/Reshape/_3663 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_12502...on/Reshape"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](^_cloopwhile/truediv/_6)]]"
20059,map_and_batch slower than map + batch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Docker (tensorflow/tensorflow:1.8.0-gpu-py3)
- **TensorFlow version (use command below)**: `v1.8.0-0-g93bc2e2072`
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: GTX 1080 Ti 11 Gb
- **Exact command to reproduce**: n/a

### Describe the problem

Using `map_and_batch` in my use case results in a slower input pipeline than using normal `map` followed by `batch`. `batch_size=512`

Here is my code. The `augment_data` and `padding_inputs_width` are [quite heavy](https://github.com/cipri-tom/tf-crnn/blob/15b9aa5cce440a4e4f4df0dcffc77ce4cd9b913d/src/data_handler.py#L92)

```python
def parse_example(serialized_example, output_shape=None):
    features = tf.parse_single_example(serialized_example, feature_spec)
    label = features.pop('label')

    # Replace image_raw with the decoded & preprocessed version
    image = features.pop('image_raw')
    image = tf.image.decode_png(image, channels=1)
    image = augment_data(image)
    image, orig_width = padding_inputs_width(image, output_shape, ...)
    features['image'] = image
    features['image_width'] = orig_width
    return features, label


def make_input_fn(files_pattern, batch_size, output_shape):
    shaped_parse_example = partial(parse_example, output_shape=output_shape)

    def input_fn():
        files = tf.data.Dataset.list_files(files_pattern, shuffle=True)
        ds = files.apply(tf.contrib.data.parallel_interleave(
            tf.data.TFRecordDataset,
            cycle_length=4, block_length=16, sloppy=True))

        # NOTE: using map_and_batch seems to decrease performance
        ds = (ds.shuffle(buffer_size=128) # small buffer since files were also shuffled
                .apply(tf.contrib.data.map_and_batch(
                    shaped_parse_example, batch_size,
                    num_parallel_batches=4, drop_remainder=True))

                # separate calls version, comment the above apply
                # .map(shaped_parse_example, num_parallel_calls=4)
                # .apply(tf.contrib.data.batch_and_drop_remainder(batch_size))
              )
        features, labels = ds.prefetch(2).make_one_shot_iterator().get_next()
        return features, labels

    return input_fn
```


While I use the same number of _parallel_ stuff, I think the difference comes from the fact that the map function is heavy and when using `map_and_batch` only one thread is used for producing each batch.

### How much slower ?

It is hard to quantify. With `map_and_batch` I just see lower numbers for GPU utilisation and even reaching zero at times. I tried increasing the `prefetch` to 4 to make up for this, but no improvement.

Here I ran with the first input pipeline for a bit and then with the `map_and_batch`. You can see a difference of about 30%.

<img width=""361"" alt=""screen shot 2018-06-15 at 14 13 36"" src=""https://user-images.githubusercontent.com/2991890/41467345-733f37ec-70a6-11e8-89f7-21be1d8eda66.png"">


### Feature request

The reason for this issue is that the documentation for `map_and_batch` says it will be done automatically in future versions. I think that in its current version, this can be a regression, as shown above. I believe (though I'm most probably wrong) that there should be a parameter in `map_and_batch` controlling the number of threads for the `map` operation, and another one for the `num_parallel_batches`. Or along those lines...

Edit: Python version is 3.5.2"
20058,[C++ API] tf.reset_default_graph() equivalent,"Does the C++ API has an equivalent method to `tf.reset_default_graph()` ? 
"
20057,"Feature request: Add ""warm_start_from"" to tf.keras.estimator.model_to_estimator","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
I can create an estimator either direct or from a keras model using the initialisers:
```
tf.estimator.estimator(
    model_fn,
    model_dir=None,
    config=None,
    params=None,
    warm_start_from=None
)
```
```
tf.keras.estimator.model_to_estimator(
    keras_model=None,
    keras_model_path=None,
    custom_objects=None,
    model_dir=None,
    config=None
)
```
However with the keras approach there is no option to warm start the model from a previously saved checkpoint. I am requesting a feature that makes it possible to do this with a call such as:
```
tf.keras.estimator.model_to_estimator(
    keras_model=None,
    keras_model_path=None,
    custom_objects=None,
    model_dir=None,
    config=None,
    warm_start_from=None
)
```

Without this I cannot see how to start an estimator in a pre-trained state.

I have also tried to do this by just calling an untrained estimator to do .predict which causes it to attempt to load from a checkpoint. When I provide the checkpoint from previous estimator training I get an error as not all data seems to be available. This is described in more detail at stackoverflow here https://stackoverflow.com/questions/50855256/keras-estimator-model-to-estimator-cannot-warm-start-or-load-previous-checkpoi
"
20055,Speech_commands conv model depthwise_conv operation slow in tensorflow lite,"System information
Have I written custom code: Yes
OS Platform and Distribution: Linux Ubuntu 16.04
TensorFlow installed from (source): tensorflow v1.8.0
Python version: 3.6
Bazel version (if compiling from source): 0.11.1
GCC/Compiler version (if compiling from source): 5.4
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

#**Describe the problem**

I am trying to use Speech_commands conv model (conv_actions_frozen.pb from ""http://download.tensorflow.org/models/speech_commands_v0.01.zip"")
to inference on tensorflow lite. 
I use TOCO to convert conv_actions_frozen.pb to conv_actions_frozen.tflite, and it convert the conv to 
depthwise_conv  + conv operation.

Below is inference log (depthwise_conv  + conv ) :

Loaded model conv_actions_frozen.tflite
resolved reporter
Resizing input tensor
AUDIO_SPECTROGRAM computing time: 1.42 ms 
Mfcc computing time: 2.143 ms 
Reshape computing time: 0.003 ms 
DepthWise_Conv computing time: 68.609 ms 
MaxPool computing time: 0.484 ms 
EvalFloat 
EvalFloat kMultithreadOptimized 
Conv computing time: 21.343 ms 
invoked 
average time: 102.171 ms 

I found  that DepthWise_Conv operation took so long to compute , so i modify TOCO (toco_tooling.cc) to 
let converting process without ConvToDepthwise transformation. 
//transformations.Add(new ConvertPureConvToDepthwise);

Here is the inference log (conv + conv ) :

Loaded model noDSconv.tflite
resolved reporter
Resizing input tensor
AUDIO_SPECTROGRAM computing time: 1.083 ms 
Mfcc computing time: 1.551 ms 
Reshape computing time: 0.002 ms 
EvalFloat 
EvalFloat kMultithreadOptimized 
Conv computing time: 10.334 ms 
MaxPool computing time: 0.454 ms 
EvalFloat 
EvalFloat kMultithreadOptimized 
Conv computing time: 18.243 ms 
invoked 
average time: 32.628 ms 


I would expect the inference on tflite should be fast after TOCO converting the model.
Is there any reason or clue can check this?
Thanks.

"
20054,Doc feature request: How to build Tensorflow Slim,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

In https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim I see no steps on how to compile this module. In the case of Tensorflow serving I see the complete set of commands to build it. Could you add some steps on how to build Slim? Thanks in advance.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
20053,error : tf.nn.ctc_beam_search_decoder,"if classes size is small ，tf.nn.ctc_beam_search_decoder can run normally.

if classes size is big (example: 3800), tf.nn.ctc_beam_search_decoder Will not end

cpu: 8
memory: 32
gpu: 1080ti

Please anyone help me
"
20052,tflite: output tensor size is not variable.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: tensorflow 1.8
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: 6.4
- **CUDA/cuDNN version**: None
- **GPU model and memory**: GeForce GTX 750
- **Exact command to reproduce**: run mtcnn pnet model in tflite android demo of tflitecamerademo.

### Describe the problem
Use mtcnn pnet source code to generate pnet.pb file, 
then convert pnet.pb to pnet.tflite file.
when run pnet.tflite in  tflitecamerademo and input size is not the same as the number of when converting the tflite, the error log is ""num_input_elements != num_output_elements (42050 != 48050)"".
I guess output tensor need resize because I resize the input tensor.
But I can't find the API of output tensor resize.

### Source code / logs
The pnet code as below:
    (self.feed('data')  #pylint: disable=no-value-for-parameter, no-member
    .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')
     .prelu(name='PReLU1')
     .max_pool(2, 2, 2, 2, name='pool1')
     .conv(3, 3, 16, 1, 1, padding='VALID', relu=False, name='conv2')
     .prelu(name='PReLU2')
     .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv3')
     .prelu(name='PReLU3')
     .conv(1, 1, 2, 1, 1, relu=False, name='conv4-1')
      .softmax(3,name='prob1'))

    (self.feed('PReLU3') #pylint: disable=no-value-for-parameter
    .conv(1, 1, 4, 1, 1, relu=False, name='conv4-2'))
generate pb file as below:
   data = tf.placeholder(name=""input"", dtype=tf.float32, shape=(None, None, None, 3))
   pnet = PNet({'data':data})
   pnet.load(os.path.join(model_path, 'det1.npy'), sess)

    frozen_graphdef = tf.graph_util.convert_variables_to_constants(
            sess, sess.graph_def, ['pnet/conv4-2/BiasAdd', 'pnet/prob1'])
   model_f = tf.gfile.GFile(""/home/hwh/pnet_none.pb"", ""wb"")

convert to tflite file as below:
./bazel-bin/tensorflow/contrib/lite/toco/toco    --input_file=/home/hwh/pnet.pb   --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE   --output_file=/home/hwh/pnet.tflite --inference_type=FLOAT   --input_type=FLOAT --input_arrays=pnet/input   --output_arrays=pnet/prob1,pnet/conv4-2/BiasAdd --input_shapes=1,320,320,3

then I run this tflite file in tflitecamerademo, and before tflite run, 
I resize input tensor to (1, 299, 299, 3).

when run the error log as below:
    06-15 16:14:36.500 12080-12275/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground
    Process: android.example.com.tflitecamerademo, PID: 12080
    java.lang.NullPointerException: Internal error: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/reshape.cc:68 num_input_elements != num_output_elements (42050 != 48050)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:123)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:166)
        at com.example.android.tflitecamerademo.ImageClassifierFloatInception.runInference(ImageClassifierFloatInception.java:121)
        at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:117)
        at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:697)
        at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)
        at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:592)
        at android.os.Handler.handleCallback(Handler.java:815)
        at android.os.Handler.dispatchMessage(Handler.java:104)
        at android.os.Looper.loop(Looper.java:194)
        at android.os.HandlerThread.run(HandlerThread.java:61)

"
20050,tf.contrib.rnn.LSTMCell wrong documentation and unclear naming  ,"### Describe the problem
1.
In the documentation at [https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell](url) it says: 

> Long short-term memory unit (LSTM) recurrent network cell. The default non-peephole implementation is based on: http://www.bioinf.jku.at/publications/older/2604.pdf S. Hochreiter and J. Schmidhuber. ""Long Short-Term Memory"". Neural Computation, 9(8):1735-1780, 1997

This is not true since the implementation already contains the forget gate which was not mentioned in the original paper but in this one: 

> ""Learning to Forget: Continual Prediction with LSTM"" by Gers et al.

2.
The naming of the parameter `num_units` or the `LSTMcell` is  is unclear and causes a lot of confusion. (google ""num_units lstm cell"" and you will find countless posts with the same question: what does it mean?)

Since the number of units within an LSTM cell is fixed, `num_units` should either be `memory_cell_block_size` as it is described in the ""Long Short-Term Memory"" paper and/or rename `LSTMcell` into `LSTMMemoryCellBlock`

### Request
1. Add the Paper:
> ""Learning to Forget: Continual Prediction with LSTM"" by Gers et al.

 to the Documention and mention that the implementation already contains forget gates.

2. Rename `num_units` and/or  `LSTMcell` or at the very least add a comment"
20049,Failed to Load the Native Tensorflow runtime,"I am using WINDOWS10 64bit, Anaconda 4.5.4 and PyCharm as an IDE. I have NVIDIA Quadro4000m GPU installed. Now I want to use Keras-GPU with tensorflow as backend and I am getting the following error?
One more thing I could not create environment with tensorflow versionb 1.8.0 with keras-gpu all versions as it shows unsatisfiable error due to conflicts in dependency. It is related to mkl file version  I dont know how to fix the dependancy.

Thanks

Using TensorFlow backend.
```
Traceback (most recent call last):
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/pav7rt/PycharmProjects/CADImage_Classification/CAD_Classification.py"", line 5, in <module>
    import keras
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\keras\backend\__init__.py"", line 84, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.
```
During handling of the above exception, another exception occurred:

```
Traceback (most recent call last):
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\pav7rt\AppData\Local\Continuum\anaconda3\envs\CADImageClassification\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
"
20047,"[bug]Using ""tensorflow/models/research/object_detection/sample.config/faster_rcnn_resnet50_coco.config"" produce "".pb"" to ""sess.run""","Please go to Stack Overflow for help and support:

http://stackoverflow.com/questions/tagged/tensorflow

Also, please understand that many of the models included in this repository are experimental and research-style code. If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win7
- **TensorFlow installed from (source or binary)**:source 
- **TensorFlow version (use command below)**:tensorflow-1.8.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Using ""faster_rcnn_resnet50_coco.config"" to train model by my own dataset,then i freeze model.ckpt to pb.When i used pb and tensorlfow-1.8.0 and tensorflow-1.7.0 to derive result,it reported error:
![image](https://user-images.githubusercontent.com/10041362/41454685-ec935d34-70ac-11e8-96ca-6f0d34cb3ef1.png)
But when i used pb and tensorflow-1.4.0,tensorflow-1.5.0,tensorflow-1.6.0 to derive result,it was ok.And I used ""faster_rcnn_inception_resnet_v2_atrous_coco.config"" to train model,then freeze it.Tensorflow-1.8.0 and Tensorflow-1.4.0 were useful,it did't report error.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
20043,[BUG] tf.train.Saver in non-local filesystem,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.0 release
- **Python version**: python2.7
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: gcc4.8.5
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: -

In Tensorflow source code tensorflow/python/training/saver.py, there are some function call like ""os.path.isabs()"". If saving to non-local filesystem such as ""hdfs://"" and using save_relative_paths=True, the behavior is not expected. The checkpoint file still save ""hdfs://.../.../..."" instead of relative_path

source code: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L982

It doesn't have any ""IsAbs()"" Interface in tensorflow::FileSystem, I think some solution:
1. Add IsAbs() Interface in tensorflow::FileSystem
2. add IsAbs() Interface in tensorflow::FileStatistics, we can call tensorflow::FileSystem::Stat() to get this info.

Thanks"
20042,"Failed to convert to Tensorflow Lite - TensorFlowMax, TensorFlowMinimum, TensorFlowSum not supported","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.4
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.14.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=.tfmodel --output_file=/Users/plun/Downloads/mobilenet_v2.tflite --input_shape=1,224,224,3 --input_array=input_1 --output_array=reshape_2/Reshape --inference_type=FLOAT

I am trying to convert a MobileNetV2 model to Tensorflow Lite. I was able to convert the model here: https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models, but when I try to convert a model trained by myself using Keras, the following error occurs:

""Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: **TensorFlowMax**, **TensorFlowMinimum**, **TensorFlowSum**.""

I ran `convert_variables_to_constants` to freeze the model, and ` bazel-bin/tensorflow/contrib/lite/toco/toco` to do conversion. I inspected the structure of the frozen graph, and found that TensorFlowMax, TensorFlowMinimum, TensorFlowSum are in relu layers and softmax layer. Are they really unsupported yet, or did I miss some steps?

Complete console output:
![screen shot 2018-06-14 at 4 39 54 pm](https://user-images.githubusercontent.com/24245729/41443425-9e22e676-6ff1-11e8-90eb-583c9e209698.png)
"
20041,Failed to create CUPTI subcriber when profiling on servers with no GPU's,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Custom i guess? I took the first example on the [Using GPUs](https://www.tensorflow.org/programmers_guide/using_gpu) page and added profiling to it (code below).

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Red Hat Enterprise Linux Server release 6.7 (Santiago)

- **TensorFlow installed from (source or binary)**:

Source

- **TensorFlow version (use command below)**:

>>> import tensorflow as tf
>>> print(tf.GIT_VERSION, tf.VERSION)
('unknown', '1.8.0')


- **Python version**:

Built for both version of python same outcome for both
2.7.14
3.6.5

- **Bazel version (if compiling from source)**:

0.11.1

- **GCC/Compiler version (if compiling from source)**:

4.9.3

- **CUDA/cuDNN version**:

CUDA: 9.1.85
cuDNN: 7.0.5

- **GPU model and memory**:

My GPU test server has the following GPU's and driver version

```bash
$ nvidia-smi
Thu Jun 14 12:58:15 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K40m          On   | 00000000:0B:00.0 Off |                    0 |
| N/A   24C    P8    19W / 235W |    207MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K40m          On   | 00000000:81:00.0 Off |                    0 |
| N/A   25C    P8    20W / 235W |    207MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

- **Exact command to reproduce**:

Run the following script with TF built with GPU support on a server without GPU's with the cuda stub and cupti extras library path's in your LD_LIBRARY_PATH environment variable.

```python
import tensorflow as tf
import os
trace_dir = '/tmp/tf_trace'

builder = tf.profiler.ProfileOptionBuilder
opts = builder(builder.time_and_memory()).order_by('micros').build()

with tf.contrib.tfprof.ProfileContext(trace_dir, trace_steps=[], dump_steps=[]) as pctx:
    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
    c = tf.matmul(a, b)
    with tf.Session() as sess:
        pctx.trace_next_step()
        pctx.dump_next_step()
        _ = sess.run(c)
        pctx.profiler.profile_operations(options=opts)

```

Works perfect on servers with GPU's fails on servers without GPU's

### Describe the problem

I am attempting to make a single, portable version of TensorFlow 1.8.0 with XLA and GPU support. Everything works as expected on servers with GPU's.
The only thing that’s not working on servers without GPU's is when you run a session in a profiler context, you get the below message.

The error seems fairly straight forward. The calls to the libcupti are failing since there are no GPU's or cuda drivers installed.

How feasible would it be to have TensorFlow fallback(or do a pre-check) to CPU only profiling if TensorFlow was built with GPU support but there are no GPU's on the servers?


### Source code / logs

Note: I manually truncated the paths of the log files up until the lib directory.

$ python ~/tmp/tfprof.py
2018-06-14 17:32:07.348377: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-06-14 17:32:07.354865: E tensorflow/stream_executor/cuda/cuda_driver.cc:406] failed call to cuInit: CUresult(-1)
2018-06-14 17:32:07.354921: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:145] kernel driver does not appear to be running on this host (HOST_NAME): /proc/driver/nvidia/version does not exist
None
2018-06-14 17:32:07.360597: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcupti.so.9.1 locally
2018-06-14 17:32:07.460813: E tensorflow/core/platform/default/device_tracer.cc:134] cuda call ActivityRegisterCallbacks(BufferRequested, BufferCompleted) failed 15
Failed to create CUPTI subcriber.
Traceback (most recent call last):
  File ""lib/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/o594256/tmp/tf18/lib/tensorflow/python/client/session.py"", line 1308, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""lib/tensorflow/python/client/session.py"", line 1411, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InternalError: Failed to create CUPTI subcriber.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/tmp/tfprof.py"", line 24, in <module>
    _ = sess.run(c)
  File ""lib/tensorflow/python/profiler/profile_context.py"", line 74, in _profiled_run
    fetches, feed_dict, options, run_metadata)
  File ""lib/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""lib/tensorflow/python/client/session.py"", line 1136, in _run
    feed_dict_tensor, options, run_metadata)
  File ""lib/tensorflow/python/client/session.py"", line 1317, in _do_run
    run_metadata)
  File ""lib/tensorflow/python/client/session.py"", line 1337, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Failed to create CUPTI subcriber.
"
20040,Same loss different/incorrect results,"TF version: 1.8
Installation: tensorflow/tensorflow:latest-gpu
OS details: 
Distributor ID:	Ubuntu
Description:	Ubuntu 16.04.4 LTS
Release:	16.04
Codename:	xenial

AWS instance: p2.xlarge
GPU details:
```
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 16086859869116902206
, name: ""/device:GPU:0""
device_type: ""GPU""
memory_limit: 11285974221
locality {
  bus_id: 1
  links {
  }
}
incarnation: 13890740079777279899
physical_device_desc: ""device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7""
]
```

Custom code:
This works
```python
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=keras.optimizers.Adam(lr=0.01, clipnorm=1., amsgrad=True),
              metrics=['acc'])
```
This works too
```python
model.compile(loss=keras.losses.sparse_categorical_crossentropy,
              optimizer=keras.optimizers.Adam(lr=0.01, clipnorm=1., amsgrad=True),
              metrics=['acc'])
```
This doesn't work. The loss value looks fine but the accuracy stays at 0 or very low value.
```python
def sparse_cate_loss(y_true, y_pred):
    return keras.losses.sparse_categorical_crossentropy(y_true, y_pred)

model.compile(loss=sparse_cate_loss,
              optimizer=keras.optimizers.Adam(lr=0.01, clipnorm=1., amsgrad=True),
              metrics=['acc'])
```"
20032,Failed to find any matching files for slim_pretrained\inception_v1.ckpt," Unsuccessful TensorSliceReader constructor: Failed to
find any matching files for slim_pretrained\inception_v1.ckpt
         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_
FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:
0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_
and_slices)]]"
20028,"decode_png function. palette png & channels=0, force into grayscale.","tf.image.decode_png function.
In the case of palette png & args channels=0, force into grayscale.

# sample

```
import tensorflow as tf
sess = tf.InteractiveSession()
src_png_data = tf.read_file(""rgb_png8.png"")
image = tf.image.decode_png(src_png_data, 0)
dst_png_data =  tf.image.encode_png(image)
with open(""output.png"", 'wb') as f:
        f.write(dst_png_data.eval())
```
- input:rgb_png8.png <= Palette PNG has RGB.
- output: output.png => Grayscale PNG

# correctness except for this

case 1)
- input <= Palette PNG has RGB.
- output: => RGB PNG

case 2)
- input <= Palette PNG has RGB & A(tRNS)
- output: => RGBA PNG

case Otherwise)
-  same as before

# environment

- macOS high sierra.
- TensorFlow 1.8
"
20026,tf.contrib.graph_editor Shape error,"Using tf.contrib.graph_editor for pruning, specifically the graph_replace function, raises ValueErrors.

As a trivial example, consider a 2-layer network with weight matrices W0 [3,4] and W1 [4,1] that we want to prune one node from and replace with new weight matrices W0' [3,3] and W1' [3,1]. From the documentation, this appears be straight-forward to do using graph_replace and the resulting graph in theory shouldn't have any shape incompatibilities.

The documentation should be updated to clarify this limitation and a proper function for use with pruning should be identified if it exists."
20024,How to get activation values of fully connected layers?,"I want to extract the neural activation from the Fully connected layers. In caffe i was doing like this net.blobs[layer_name].data

How can i do the same in tensorflow?
"
20023,tf.keras.layers.DepthwiseConv2D fail when bias is enabled,"It seems that a little mistake is present in tf.keras.layers.DepthwiseConv2D, in the call procedure:

https://github.com/tensorflow/tensorflow/blob/17d6639b550cdcedf31ee01bd6eb26c592aeac42/tensorflow/python/keras/layers/convolutional.py#L1727

In my understanding self.bias should be replaced by self.use_bias on this line, as self.bias is a tensor, wheras self.use_bias is a boolean value.

After replacing it, the DepthwiseConv2D seems to works fine here.
@fchollet what do you think ?


Have I written custom code N/A
OS Platform and Distribution N/A
TensorFlow installed from N/A
TensorFlow version N/A
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce N/A"
20022,Keras fit method not working with dataset iterator,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.9-rc0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: `model.fit(get_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)`
and
`model.fit(get_iterator,get_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)`

### Describe the problem
When I pass one dataset iterator to `fit` method, I get:
 

> Please provide data as a list or tuple of 2 elements  - input and target pair. Received Tensor(""IteratorGetNext_4:0"", shape=(2, ?), dtype=float32)


When I pass two iterators I get the error:

> ValueError: You passed a dataset or dataset iterator (<tensorflow.python.data.ops.iterator_ops.Iterator object at 0x000001FEABE88748>) as input `x` to your model. In that case, you should not specify a target (`y`) argument, since the dataset or dataset iterator generates both input data and target data. Received: <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x000001FEABE88748>

When I create a new dataset after zipping the original x and y data set and pass that to `fit `I get the error described in https://github.com/tensorflow/tensorflow/issues/19912

According to 1.9-rc0 method release notes iterators should be usable with keras training methods. Please provide a solution or provide clarification in the documentation.

### Source code / logs
```
dataset= tf.contrib.data.make_csv_dataset(file_name,48,select_columns= ['Load_residential_multi_0','Load_residential_multi_1'],shuffle=False)
dataset = dataset.map(lambda x: tf.stack(list(x.values())))
get_iterator = dataset.make_one_shot_iterator()
get_batch = get_iterator.get_next()

#Building and training a single layer model using Keras (Available within TensorFlow)
model = Sequential() 
#Input Layer
model.add(InputLayer(input_shape=(48,),name='InputLayer'))#,input_tensor =dataset
#model.add(BatchNormalization(axis=1))  #Normalizing values
#Layer1 
model.add(Dense(units=5,activation='relu',name='FeedForward1'))  #Add a feed forward layer
#Layer2 
model.add(Dense(units=5,activation='relu',name='FeedForward2'))  #Add a feed forward layer
#Output layer 
model.add(Dense(units=48,name='OutputLayer'))

#Specify los function and optimizer
model.compile(loss='mse',optimizer='adam',metrics=['mae'])

#Summarize model
model.summary()
#Train the model
model.fit(get_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)
#model.fit(get_iterator,get_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)
```"
20021,[BUG] TensorFlow crashed when using tf.cast() in dataset's map() function,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
pip
- **TensorFlow version (use command below)**:
1.8.0 GPU
- **Python version**: 
3.6.4
- **Bazel version (if compiling from source)**:
No
- **GCC/Compiler version (if compiling from source)**:
No
- **CUDA/cuDNN version**:
9.0/7
- **GPU model and memory**:
GPU: GPU 0: GeForce GTX 1080 Ti x2
RAM: 16GB
- **Exact command to reproduce**:
No

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
When I using TensorFlow eager execution with gpu, I want to read some data, so I use `tf.data.Dataset`. Then I want to pre-process the data before training, then I use `dataset.map()` and `tfe.py_func()`. Also, I use `dataset.prefetch(1)` to read data with pipelining,
Everything is fine so far. But when I using `tf.cast()` in map function, the program will crash.

### Source code / logs
```python
import tensorflow as tf
from tensorflow.contrib.eager.python import tfe
tf.enable_eager_execution()


def main():
    data = tf.range(0, 100, dtype=tf.float32)

    def map_fn(n):
        def fn(nn):
            int_tensor = tf.constant(1, tf.int32)
            float_tensor = tf.cast(int_tensor, tf.float32)
            return float_tensor
        return tfe.py_func(fn, [n], [tf.float32])

    dataset = tf.data.Dataset.from_tensor_slices(data)
    dataset = dataset.map(map_fn).prefetch(1)

    for i in dataset:
        print(i)


if __name__ == '__main__':
    main()
```

run the code:
```shell
$ python xxx.py
```

output:
> 2018-06-14 13:29:48.784627: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2018-06-14 13:29:48.925618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
totalMemory: 10.92GiB freeMemory: 10.45GiB
2018-06-14 13:29:49.063957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
totalMemory: 10.92GiB freeMemory: 10.44GiB
2018-06-14 13:29:49.064088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
2018-06-14 13:29:49.449500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-14 13:29:49.449552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
2018-06-14 13:29:49.449562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y 
2018-06-14 13:29:49.449570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N 
2018-06-14 13:29:49.449834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10108 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2018-06-14 13:29:49.543343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10107 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
[1]    84561 segmentation fault (core dumped)  python dataset_eager_bug.py"
20019,tflite mult_thread,"Describe the problem
How can we use tflite code in android to test the mult_thread testing.
The set thread code doen't work.

Source code / logs
public void setNumThreads(int num_threads) {
if (tflite != null)
tflite.setNumThreads(num_threads);
}"
20018,tflite multi_thread,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
How can we use tflite code in android to test the mult_thread testing.
The set thread code doen't work.

### Source code / logs
public void setNumThreads(int num_threads) {
    if (tflite != null)
      tflite.setNumThreads(num_threads);
  }
"
20016,Fail to convert from .pb to .toco,"The error message is:
2018-06-14 20:36:34.054067: F tensorflow/contrib/lite/toco/tooling_util.cc:939] Check failed: name.substr(colon_pos + 1).find_first_not_of(""0123456789"") == string::npos (1 vs. 18446744073709551615)Array name must only have digits after colon
Aborted (core dumped)

Does anyone know what this message is about?
Thanks

----
update:
Sorry about wrong typing in the issue title. It should be ""Fail to convert from .pb to .tflite""
Add info:
1. Have I written custom code
No, I use the original toco.
2. OS Platform and Distribution
Ubuntu 16.04 
3. TensorFlow installed from
Cloned from tensorflow official github
4. TensorFlow version
1.8.0
5. Bazel version
Build label: 0.14.0
6. CUDA/cuDNN version
I didn't use GPU.
7. GPU model and memory
N/A
8. Exact command to reproduce
I'm sorry that the .pb model I tried to transform is a privately built model, and I have no right to
upload it online. 
The commands transforming the model is just like the Basic example given in
""https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md"".
Except the model name and output node names were changed to that of my model.

Thanks.
"
20015,Feature request: Length normalisation  in ctc_beam_search_decoder,"I  read that length normalisation improves the result of beam search. So, is there any plan of adding length normalisation in ctc_beam_search_decoder? 

Have I written custom code: No
OS Platform and Distribution: N/A
TensorFlow installed from: N/A
TensorFlow version:N/A
Bazel version:N/A
CUDA/cuDNN version: N/A
GPU model and memory:N/A
Exact command to reproduce:N/A

"
20014,TensorFlow master build failure on s390x,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: s390x Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.12.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: `bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem
TensorFlow Master build is failing on s390x due to BoringSSL (which is not supported on s390x).
Seems like error comes while compiling gRPC. 
Changes causing build failure can be checked [here](https://ibmz-ci.osuosl.org/job/TensorFlow_IBMZ_CI/126/)

@gunan , Could you please help in redirecting this to the relevant person?

### Source code / logs
```
ERROR: /home/js/.cache/bazel/_bazel_jenkins/14d9bef57f8e4d2a0eef0de174c4144b/external/grpc/BUILD:1628:1: C++ compilation of rule '@grpc//:alts_frame_protector' failed (Exit 1)
In file included from external/boringssl/src/include/openssl/bio.h:60:0,
                 from external/grpc/src/core/tsi/alts/crypt/aes_gcm.cc:23:
external/boringssl/src/include/openssl/base.h:114:2: error: #error ""Unknown target CPU""
 #error ""Unknown target CPU""
  ^
```"
20013,//tensorflow/contrib/distributions:matrix_inverse_tril_test fails on ppc64le,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
      Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source
- **TensorFlow version (use command below)**:
      TF master
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
     bazel-0.11.1
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
 `bazel test -c opt --jobs 1 -k --cache_test_results=no --test_output=errors  //tensorflow/contrib/distributions:matrix_inverse_tril_test`

### Describe the problem
Getting error `InvalidArgumentError: assertion failed: [Input must be lower triangular.] [Condition x == y did not hold element-wise:]`.
Not sure what exactly causing this issue, need to investigate.

### Source code / logs
```
E.......
======================================================================
ERROR: testBatch (__main__.MatrixInverseTriLBijectorTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 625, in decorated
    f(self, **kwargs)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/kernel_tests/bijectors/matrix_inverse_tril_test.py"", line 110, in testBatch
    y_, x_back_, fldj_, ildj_ = self.evaluate([y, x_back, fldj, ildj])
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 864, in evaluate
    return sess.run(tensors)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 877, in run
    run_metadata_ptr)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1100, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1272, in _do_run
    run_metadata)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1291, in _do_call
    raise type(e)(node_def, op, message)
InvalidArgumentError: assertion failed: [Input must be lower triangular.] [Condition x == y did not hold element-wise:] [x (matrix_inverse_tril_1/inverse/MatrixBandPart:0) = ] [[[[0 2.77555756e-17][0]]]...] [y (matrix_inverse_tril_1/inverse/zeros_like:0) = ] [[[[0 0][0]]]...]
         [[Node: matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_FLOAT, DT_STRING, DT_FLOAT], summarize=3, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/Switch, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_0, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_1, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_2, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/Switch_1, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_4, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/Switch_2)]]

Caused by op u'matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert', defined at:
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/kernel_tests/bijectors/matrix_inverse_tril_test.py"", line 190, in <module>
    test.main()
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/platform/test.py"", line 64, in main
    return _googletest.main(argv)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py"", line 100, in main
    benchmark.benchmarks_main(true_main=main_wrapper)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py"", line 344, in benchmarks_main
    true_main()
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py"", line 99, in main_wrapper
    return app.run(main=g_main, argv=args)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py"", line 70, in g_main
    return unittest_main(argv=argv)
  File ""/usr/lib/python2.7/unittest/main.py"", line 95, in __init__
    self.runTests()
  File ""/usr/lib/python2.7/unittest/main.py"", line 232, in runTests
    self.result = testRunner.run(self.test)
  File ""/usr/lib/python2.7/unittest/runner.py"", line 151, in run
    test(result)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 70, in __call__
    return self.run(*args, **kwds)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 108, in run
    test(result)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 70, in __call__
    return self.run(*args, **kwds)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 108, in run
    test(result)
  File ""/usr/lib/python2.7/unittest/case.py"", line 393, in __call__
    return self.run(*args, **kwds)
  File ""/usr/lib/python2.7/unittest/case.py"", line 329, in run
    testMethod()
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 625, in decorated
    f(self, **kwargs)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/kernel_tests/bijectors/matrix_inverse_tril_test.py"", line 106, in testBatch
    x_back = inv.inverse(x_inv_)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/distributions/bijector_impl.py"", line 800, in inverse
    return self._call_inverse(y, name)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/distributions/bijector_impl.py"", line 779, in _call_inverse
    mapping = mapping.merge(x=self._inverse(y, **kwargs))
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/ops/bijectors/matrix_inverse_tril.py"", line 80, in _inverse
    return self._forward(y)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/ops/bijectors/matrix_inverse_tril.py"", line 74, in _forward
    with ops.control_dependencies(self._assertions(x)):
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/ops/bijectors/matrix_inverse_tril.py"", line 138, in _assertions
    message=""Input must be lower triangular."")
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/check_ops.py"", line 382, in assert_equal
    return control_flow_ops.Assert(condition, data, summarize=summarize)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/util/tf_should_use.py"", line 118, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/control_flow_ops.py"", line 151, in Assert
    guarded_assert = cond(condition, no_op, true_assert, name=""AssertGuard"")
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/control_flow_ops.py"", line 2049, in cond
    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/control_flow_ops.py"", line 1890, in BuildCondBranch
    original_result = fn()
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/control_flow_ops.py"", line 149, in true_assert
    condition, data, summarize, name=""Assert"")
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/ops/gen_logging_ops.py"", line 51, in _assert
    name=name)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 3206, in create_op
    op_def=op_def)
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/matrix_inverse_tril_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1701, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): assertion failed: [Input must be lower triangular.] [Condition x == y did not hold element-wise:] [x (matrix_inverse_tril_1/inverse/MatrixBandPart:0) = ] [[[[0 2.77555756e-17][0]]]...] [y (matrix_inverse_tril_1/inverse/zeros_like:0) = ] [[[[0 0][0]]]...]
         [[Node: matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert = Assert[T=[DT_STRING, DT_STRING, DT_STRING, DT_FLOAT, DT_STRING, DT_FLOAT], summarize=3, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/Switch, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_0, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_1, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_2, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/Switch_1, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/data_4, matrix_inverse_tril_1/inverse/assert_equal_1/Assert/AssertGuard/Assert/Switch_2)]]


----------------------------------------------------------------------
Ran 8 tests in 3.177s
```"
20012,//tensorflow/python:cluster_test test fails on ppc64le,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
      Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source
- **TensorFlow version (use command below)**:
      TF master
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
     bazel-0.11.1
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
 `bazel test -c opt --jobs 1 -k --cache_test_results=no --test_output=errors  //tensorflow/python:cluster_test`

### Describe the problem
This test is passing on X86 , however it's failing on ppc64le.

The test fails at line https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/grappler/cluster_test.py#L84 i.e. ` self.assertEqual(52, peak_usage)`.
On x86 we are getting peak_usage=52 and test is passing.However on ppc64le peak_usage=48 hence test fails.

Currently I'm looking into source code to find the root cause. 
Need to understand, how they are calculated peak_usage in this test.
Any comments/suggestions appreciated.Thanks! 

### Source code / logs
```
======================================================================
FAIL: testMemoryEstimates (__main__.ClusterTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/cluster_test.runfiles/org_tensorflow/tensorflow/python/grappler/cluster_test.py"", line 84, in testMemoryEstimates
    self.assertEqual(52, peak_usage)
AssertionError: 52 != 48L

----------------------------------------------------------------------
Ran 1 test in 0.030s

FAILED (failures=1)
```"
20010,"unclear doc: precision_at_k, recall_at_k in metric function (for estimator.add_metrics)","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:  1.7
- **Python version**: 3
- **GPU model and memory**: GPU:0 (not using GPU)
- **Exact command to reproduce**:
tf.metrics.precision_at_k(labels=labels, predictions=predictions, k=5)
tf.metrics.precision_at_k(labels=labels, predictions=predictions['logits'], k=5)

### Describe the problem
May I ask if it is possible to have clearer documentation on what is expected for the metric_fn for prebuilt metrics? (perhaps there is documentation that I have missed out, or perhaps I just did not understand them). For example, the link below demonstrates that auc can be calculated from predictions['logistic'] obtained from the estimator.
https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/add_metrics
`  def my_auc(labels, predictions):
    return {'auc': tf.metrics.auc(labels, predictions['logistic'])}

  estimator = tf.estimator.DNNClassifier(...)
  estimator = tf.contrib.estimator.add_metrics(estimator, my_auc)`

However, when I try to add precision_at_k and recall_at_k, I could not get the desired result.
https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/metrics_impl.py
`predictions: Float `Tensor` with shape [D1, ... DN, num_classes] where
      N >= 1. Commonly, N=1 and predictions has shape [batch size, num_classes].
      The final dimension contains the logit values for each class. [D1, ... DN]
      must match `labels``

I tried the following metric functions:
Case A.
`def precision_at_5(labels, predictions):
      labels = tf.to_int64(labels)
      return {'precision_at_5': tf.metrics.precision_at_k(labels=labels, predictions=predictions, k=5)}
`
Case B.
`def precision_at_5(labels, predictions):
      labels = tf.to_int64(labels)
      return {'precision_at_5': tf.metrics.precision_at_k(labels=labels, predictions=predictions['logits'], k=5)} #or predictions['probabilities']
`


### Source code / logs
The estimator that uses the metric function above is as follows
`estimator = tf.estimator.DNNLinearCombinedClassifier(
        model_dir=model_dir,
        linear_feature_columns=wide_columns,
        dnn_feature_columns=deep_columns,
        dnn_hidden_units=hidden_units,
        config=run_config)
    estimator = tf.contrib.estimator.add_metrics(estimator, precision_at_5)
    estimator = tf.contrib.estimator.add_metrics(estimator, recall_at_5)
    estimator = tf.contrib.estimator.add_metrics(estimator, average_precision_at_5)
    return estimator`

Errors for the 3 examples are as follows:
Case A.
`File ""wide_deep.py"", line 165, in precision_at_5
    return {'precision_at_5': tf.metrics.precision_at_k(labels=labels, predictions=predictions, k=5)}
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/metrics_impl.py"", line 3405, in precision_at_k
    _, top_k_idx = nn.top_k(predictions, k)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 2354, in top_k
    return gen_nn_ops.top_kv2(input, k=k, sorted=sorted, name=name)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 7631, in top_kv2
    ""TopKV2"", input=input, k=k, sorted=sorted, name=name)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 513, in _apply_op_helper
    raise err
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 510, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1040, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/constant_op.py"", line 235, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/constant_op.py"", line 214, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/tensor_util.py"", line 522, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'logistic': <tf.Tensor 'head/predictions/logistic:0' shape=(?, 1) dtype=float32>, 'logits': <tf.Tensor 'add:0' shape=(?, 1) dtype=float32>, 'classes': <tf.Tensor 'head/predictions/str_classes:0' shape=(?, 1) dtype=string>, 'probabilities': <tf.Tensor 'head/predictions/probabilities:0' shape=(?, 2) dtype=float32>, 'class_ids': <tf.Tensor 'head/predictions/ExpandDims:0' shape=(?, 1) dtype=int64>}. Consider casting elements to a supported type.`

Case B.
`File ""wide_deep.py"", line 161, in precision_at_5
    return {'precision_at_5': tf.metrics.precision_at_k(labels=labels, predictions=predictions['logits'], k=5)}
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/metrics_impl.py"", line 3405, in precision_at_k
    _, top_k_idx = nn.top_k(predictions, k)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py"", line 2354, in top_k
    return gen_nn_ops.top_kv2(input, k=k, sorted=sorted, name=name)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 7631, in top_kv2
    ""TopKV2"", input=input, k=k, sorted=sorted, name=name)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 3292, in create_op
    compute_device=compute_device)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 3332, in _create_op_helper
    set_shapes_for_outputs(op)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2496, in set_shapes_for_outputs
    return _set_shapes_for_outputs(op)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2469, in _set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2399, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""/Users/jinyunsoo/tensorflow/lib/python3.4/site-packages/tensorflow/python/framework/common_shapes.py"", line 691, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: input must have last dimension >= k = 5 but is 1 for 'precision_at_5/TopKV2' (op: 'TopKV2') with input shapes: [?,1], [] and with computed input tensors: input[1] = <5>.`


Thank you very much!"
20009,tf.get_variable(reuse=tf.AUTO_REUSE) is not working in the eager execution mode.,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Darwin localhost 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64
Mac OS X 10.13.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: See below


### Describe the problem

When calling get_variable() function in tensorflow, the behavior of the ""reuse"" flag is defined in the [tensorflow api doc](https://www.tensorflow.org/api_docs/python/tf/variable_scope) to be AUTO_REUSE:

> reuse: True, None, or tf.AUTO_REUSE; ... **When eager execution is enabled, this argument is always forced to be tf.AUTO_REUSE**.

However when I run the demo code as suggested in the api doc:

```
tf.enable_eager_execution()
def foo():
  with tf.variable_scope(""foo"", reuse=tf.AUTO_REUSE):
    v = tf.get_variable(""v"", [1])
  return v
v1 = foo()  # Creates v.
v2 = foo()  # Gets the same, existing v.
assert v1 == v2
```

It fails. (It passes if the first line is removed, as expected.)

Not sure whether it is a bug or expected behavior, but at least the api doc seems kind of misleading. If it's expected, then what's the correct way to reuse a variable in eager mode? (and can this be included in the api doc?)"
20008,//tensorflow/python:cost_analyzer_test test fails on ppc64le,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
      Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source
- **TensorFlow version (use command below)**:
      TF master
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
     bazel-0.11.1
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
 `bazel test -c opt --jobs 1 -k --cache_test_results=no --test_output=errors  //tensorflow/python:cost_analyzer_test`

### Describe the problem
FAIL: testBasicMemory (__main__.CostAnalysisTest)
Make sure arguments can be passed correctly.
AssertionError: False is not true

I have started looking into this. 
Any comments/suggestions appreciated.Thanks! 
### Source code / logs
```
INFO: Analysed target //tensorflow/python:cost_analyzer_test (0 packages loaded).
INFO: Found 1 test target...
FAIL: //tensorflow/python:cost_analyzer_test (see /root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/testlogs/tensorflow/python/cost_analyzer_test/test.log)
INFO: From Testing //tensorflow/python:cost_analyzer_test:
==================== Test output for //tensorflow/python:cost_analyzer_test:
2018-06-14 09:10:09.134980: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 0
2018-06-14 09:10:09.135207: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2018-06-14 09:10:09.136755: I tensorflow/core/grappler/clusters/single_machine.cc:349] Cleaning up previous session
2018-06-14 09:10:09.138122: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2018-06-14 09:10:09.147635: I tensorflow/core/grappler/clusters/single_machine.cc:349] Cleaning up previous session
2018-06-14 09:10:09.148782: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
.2018-06-14 09:10:09.157410: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 0
2018-06-14 09:10:09.157507: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
F2018-06-14 09:10:09.352496: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 0
2018-06-14 09:10:09.352692: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2018-06-14 09:10:09.359070: I tensorflow/core/grappler/clusters/single_machine.cc:349] Cleaning up previous session
2018-06-14 09:10:09.360080: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2018-06-14 09:10:09.566104: I tensorflow/core/grappler/clusters/single_machine.cc:349] Cleaning up previous session
2018-06-14 09:10:09.569427: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session

Total time measured in ns (serialized):                           5000
Total time measured in ns (actual):                             281002
Total time analytical in ns (upper bound):        -9223372036854775000
Total time analytical in ns (lower bound):                           0
Overall efficiency (analytical upper/actual):             -3.28232e+13
Overall efficiency (analytical lower/actual):                        0

                                 Op,          Count,  Measured time (ns),    Time percent,     Acc percent,    Analytical upper,    Analytical lower,      Overall eff      Compute eff       Memory eff
                               AddN,              1,                5000,          1e+02%,          1e+02%,-9223372036854775000,                   0,       -1.8e+17%,       -1.8e+17%,              0%,

Below is the per-node report summary:
                                 Op,  Measured time (ns),   Compute time (ns),    Memory time (ns),     Compute eff,      Memory eff,    Inputs
                               AddN,                5000,-9223372036854775000,                   0,       -1.8e+17%,           -inf%,    []


Peak usage for device /job:localhost/replica:0/task:0/device:CPU:0: 12 bytes
  a:0 uses 4 bytes
  b:0 uses 4 bytes
  c:0 uses 4 bytes


Total time measured in ns (serialized):                        8460000
Total time measured in ns (actual):                            5328500
Total time analytical in ns (upper bound):        -9223372036854519848
Total time analytical in ns (lower bound):        -9223372036854655544
Overall efficiency (analytical upper/actual):             -1.73095e+12
Overall efficiency (analytical lower/actual):             -1.73095e+12

                                 Op,          Count,  Measured time (ns),    Time percent,     Acc percent,    Analytical upper,    Analytical lower,      Overall eff      Compute eff       Memory eff
                             MatMul,              3,             2160000,             26%,             26%,-9223372036854676232, 9223372036854773384,       -4.3e+14%,        4.3e+14%,            4.7%,
                          ApplyAdam,              4,             1422000,             17%,             42%,              128232,              125000,              9%,           0.23%,            8.8%,
               Conv2DBackpropFilter,              1,             1040000,             12%,             55%, 9223372036854775000, 9223372036854775000,        8.9e+14%,        8.9e+14%,              0%,
                           ReluGrad,              1,              958000,             11%,             66%,-9223372036854767616, 9223372036854775000,       -9.6e+14%,        9.6e+14%,           0.94%,
                             Conv2D,              1,              604000,            7.1%,             73%,-9223372036854773616, 9223372036854775000,       -1.5e+15%,        1.5e+15%,            0.5%,
                         VariableV2,             14,              537000,            6.3%,             79%,                   0,                   0,              0%,              0%,              0%,
                                Sum,              4,              513000,            6.1%,             86%,               12232,                9000,            2.4%,           0.63%,            1.8%,
                              Const,             10,              465000,            5.5%,             91%,                   0,                   0,              0%,              0%,              0%,
                                Mul,              6,              415000,            4.9%,             96%,               -4848,               -4848,           -1.2%,           -1.2%,              0%,
                                Add,              2,              205000,            2.4%,             98%,                4384,               -1616,            2.1%,          -0.79%,            2.9%,
                               Relu,              1,               35000,           0.41%,             99%,-9223372036854770616, 9223372036854775000,       -2.6e+16%, .2018-06-14 09:10:09.738459: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 0
2018-06-14 09:10:09.738574: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2018-06-14 09:10:09.739464: I tensorflow/core/grappler/clusters/single_machine.cc:349] Cleaning up previous session
2018-06-14 09:10:09.740389: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2018-06-14 09:10:09.747818: I tensorflow/core/grappler/clusters/single_machine.cc:349] Cleaning up previous session
2018-06-14 09:10:09.749965: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
..
======================================================================
FAIL: testBasicMemory (__main__.CostAnalysisTest)
Make sure arguments can be passed correctly.
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/78afe71156c58ea89dc510bdb03ba2b0/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/cost_analyzer_test.runfiles/org_tensorflow/tensorflow/python/grappler/cost_analyzer_test.py"", line 152, in testBasicMemory
    in report)
AssertionError: False is not true

----------------------------------------------------------------------
Ran 5 tests in 0.639s

FAILED (failures=1)
       2.6e+16%,             17%,
                         Reciprocal,              1,               25000,            0.3%,             99%, 9223372036854775000, 9223372036854775000,        3.7e+16%,        3.7e+16%,              0%,
                           Identity,              6,               24000,           0.28%,             99%,                   0,                   0,              0%,              0%,              0%,
                            Reshape,              6,               22000,           0.26%,          1e+02%,                   0,                   0,              0%,              0%,              0%,
                             Assign,              2,               10000,           0.12%,          1e+02%,                1616,                   0,             16%,             16%,              0%,
                            Softmax,              1,                9000,           0.11%,          1e+02%,-9223372036854775000,                   0,         -1e+17%,         -1e+17%,              0%,
                               Tile,              1,                7000,          0.083%,          1e+02%,-9223372036854775000,                   0,       -1.3e+17%,       -1.3e+17%,              0%,
                                Sub,              1,                5000,          0.059%,          1e+02%, 9223372036854775000, 9223372036854775000,        1.8e+17%,        1.8e+17%,              0%,
                               NoOp,              2,                4000,          0.047%,          1e+02%,                   0,                   0,              0%,              0%,              0%,



Total time measured in ns (serialized):                           5000
Total time measured in ns (actual):                             149014
Total time analytical in ns (upper bound):        -9223372036854775000
Total time analytical in ns (lower bound):                           0
Overall efficiency (analytical upper/actual):              -6.1896e+13
Overall efficiency (analytical lower/actual):                        0

                                 Op,          Count,  Measured time (ns),    Time percent,     Acc percent,    Analytical upper,    Analytical lower,      Overall eff      Compute eff       Memory eff
                               AddN,              1,                5000,          1e+02%,          1e+02%,-9223372036854775000,                   0,       -1.8e+17%,       -1.8e+17%,              0%,

Below is the full per-node report:
op_performance {
  op {
    op: ""AddN""
    attr {
      key: ""N""
      value {
        i: 2
      }
    }
    attr {
      key: ""T""
      value {
        type: DT_INT32
      }
    }
    inputs {
      shape {
        unknown_rank: true
      }
      value {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 20
      }
    }
    inputs {
      shape {
        unknown_rank: true
      }
    }
    device {
      type: ""CPU""
      model: ""0""
      num_cores: 4
      environment {
        key: ""cpu_instruction_set""
        value: ""VSX""
      }
      environment {
        key: ""eigen""
        value: ""3.3.90""
      }
      l1_cache_size: 16384
      l2_cache_size: 524288
      l3_cache_size: 524288
      memory_size: 993132544
    }
  }
  compute_cost: 5000
  compute_efficiency: -1844674407370955
  node: ""d""
  compute_time: -9223372036854775000
  memory_efficiency: -inf
  op_memory {
    output_memory: 4
    persistent_memory: 4
  }
}

================================================================================
Target //tensorflow/python:cost_analyzer_test up-to-date:
  bazel-bin/tensorflow/python/cost_analyzer_test
INFO: Elapsed time: 1.835s, Critical Path: 1.36s
INFO: Build completed, 1 test FAILED, 2 total actions
//tensorflow/python:cost_analyzer_test                                   FAILED in 1.4s
```
"
20007,non random operation should not change the graph random state(1.5 cpu python 2.7）,"Not sure why the random state changed for non random operation like tf.constant

`pip freeze|grep ""python\|tensorflow""`
python-dateutil==2.7.2
tensorflow==1.5.0
tensorflow-tensorboard==1.5.1

cat test.py
```
import tensorflow as tf
print(tf.__version__)
seed = 0
def test1():
    graph = tf.Graph()
    with graph.as_default():
        tf.set_random_seed(seed)
        aaa = tf.random_uniform([1])
    sess = tf.Session(graph = graph)
    print(sess.run(aaa))
    print(sess.run(aaa))

def test2():
    graph = tf.Graph()
    with graph.as_default():
        tf.set_random_seed(seed)
        bbb = tf.constant([1,2])
        aaa = tf.random_uniform([1])
    sess = tf.Session(graph = graph)
    print(sess.run(aaa))
    print(sess.run(aaa))
if __name__ == ""__main__"":
    test1()
    test1()
    test2()
```
python test.py
/home/tom/pyenv/anti/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
1.5.0
2018-06-14 16:06:47.429664: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[0.3206401]
[0.012326]
[0.3206401]
[0.012326]
[0.2773143]
[0.92967796]
"
20006,C++ load and running Tensorflow Model Crash,"I use C++ load and running tensorflow model , but it`s crash.
the core is :
![304826260213283160](https://user-images.githubusercontent.com/19491069/41392235-15e627ce-6fd2-11e8-98c8-461d430ce05d.png)
please tell me how to solve it
Thinks!!!"
20005,tf lite demo throw the error: Op builtin_code out or range: 59,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: tensorflow 1.8
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)** : 6.4
- **CUDA/cuDNN version**: None
- **GPU model and memory**: GeForce GTX 750
- **Exact command to reproduce**: run mtcnn pnet model in tflite android demo of tflitecamerademo.

### Describe the problem
Tflite generate is ok.
But run in tflitecamerademo error:
""Op builtin_code out or range: 59. Are you using old TFLite binary with newer model?Registration failed.""
For the version of 3daa07aa2dde379388beb2a557a78bc5dd1b86ba on June 6.
It is strange that running demo ok on June 6. 
on June 11, I download new code to another folder to run the demo,
it was error as below log.
Then, I use the demo of June 6, 
the error appeared.
I checked the jar file, it is not changed.
So now I will reproduce the error both the version of June 6, and June 11.
I don't know how the June 6 be changed, 
and how to resolve the error  about ""Op builtin_code out or range: 59""

### Source code / logs
The error log in adb as below:
   
    Caused by: java.lang.IllegalArgumentException: Cannot create interpreter: Op builtin_code out or range: 59. Are you using old TFLite binary with newer model?Registration failed.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:51)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:90)
        at com.example.android.tflitecamerademo.ImageClassifier.<init>(ImageClassifier.java:96)
        at com.example.android.tflitecamerademo.ImageClassifierFloatInception.<init>(ImageClassifierFloatInception.java:50)
        at com.example.android.tflitecamerademo.Camera2BasicFragment.onActivityCreated(Camera2BasicFragment.java:335)
        at android.app.Fragment.performActivityCreated(Fragment.java:2077)
        at android.app.FragmentManagerImpl.moveToState(FragmentManager.java:917)
        at android.app.FragmentManagerImpl.moveToState(FragmentManager.java:1072)
        at android.app.BackStackRecord.run(BackStackRecord.java:852)
        at android.app.FragmentManagerImpl.execPendingActions(FragmentManager.java:1478)
        at android.app.Activity.performStart(Activity.java:6107)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2491)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2608) 
        at android.app.ActivityThread.access$800(ActivityThread.java:178) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1470) 
        at android.os.Handler.dispatchMessage(Handler.java:111) 
        at android.os.Looper.loop(Looper.java:194) 
        at android.app.ActivityThread.main(ActivityThread.java:5637) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at java.lang.reflect.Method.invoke(Method.java:372) 
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:959) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:754) 
"
19998,Install Tensorflow x86 with pip,Can i install tensorflow for python x86 with pip?
19996,Feature Request: untruncated normal in variance scaling initializer,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**: N/A
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**:N/A

Currently the ""normal"" mode of `variance_scaling_initializer` actually produces truncated normal distribution. 
Despite that I saw Google suggest in several places that a truncated normal might be better than a true normal distribution, truncated normal is NOT what is used in the initialization literature such as:

[1] Glorot, Xavier, and Yoshua Bengio. ""Understanding the difficulty of training deep feedforward neural networks."" In Proceedings of the thirteenth international conference on artificial intelligence and statistics, pp. 249-256. 2010.
[2] He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. ""Delving deep into rectifiers: Surpassing human-level performance on imagenet classification."" In Proceedings of the IEEE international conference on computer vision, pp. 1026-1034. 2015.

I found that this difference is affecting some of my experiments. To be more consistent with literature, I would request a new mode in variance_scaling_initializer that produces untruncated normal distribution. I'm OK to implement it If someone can give it a good name."
19992,The DepthwiseConv2dNative() function ignores the dilations argument,"Hi!

I am using Tensorflow v1.7.0.

I am invoking the DepthwiseConv2dNative() function with a dilations argument that is [1, 2, 2, 1]. Despite of this, the dilations value is being ignored.

Looking at the tensorflow source code, it is evident that the dilations argument is presumably being disregarded (depthwise_conv_op.cc, around line 400) in both CUDNN and non-CUDNN scenarios. Yet, there is no mention of this in the documentation.

Thanks!"
19991,Incorrect name returned in Tensorflow causes “Tensor which does not exist” error while invoking get_tensor_by_name,"As per the [documentation](https://www.tensorflow.org/programmers_guide/graphs#naming_operations) TensorFlow would append ""_1"", ""_2"", and so on to the name in tf.Graph namespace, in order to make it unique. Here I define two convolutional operations. It is expected that the first one will be named as ""conv2d"" and second one ""conv2d_1"". But when I try to obtain the name of the second convolution it returns ""conv2d_2"". I causes error when I try to invoke get_tensor_by_name. Here is the code:

import numpy as np
import tensorflow as tf
import os

x = tf.constant(np.random.randn(1,2,2,1), dtype=tf.float32)
kernel_size = (1,1)
no_of_out = 20
strides = (1,1)
conv_out1 = tf.layers.conv2d(x, 10, (1,1), (1,1))
conv_out2 = tf.layers.conv2d(x, 10, (1,1), (1,1))

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print conv_out1.name # conv2d/BiasAdd:0 .  This value is correct
    print conv_out2.name # conv2d_2/BiasAdd:0 .  This value is incorrect.  It should be conv2d_1/BiasAdd:0
    conv_weights1 = tf.get_default_graph().get_tensor_by_name(os.path.split(conv_out1.name)[0] + '/kernel:0')
    conv_weights2 = tf.get_default_graph().get_tensor_by_name('conv2d_1/kernel:0')  
    conv_weights2 = tf.get_default_graph().get_tensor_by_name(os.path.split(conv_out2.name)[0] + '/kernel:0')

I get error

""KeyError: ""The name 'conv2d_2/kernel:0' refers to a Tensor which does not exist. The operation, 'conv2d_2/kernel', does not exist in the graph.""

**Issue Template**
1. Have I written custom code : No. I did not customize any part of TensorFlow. Directly using it as described above
2. OS Platform and Distribution : Ubuntu 14.04
3. TensorFlow installed from : N/A
4. TensorFlow version : 1.4.0-rc1
5. Bazel version : N/A
6. CUDA/cuDNN version : N/A
7. GPU model and memory : N/A
8. Exact command to reproduce : As described above with exact code."
19989,S3 backend request fails on small object (at least) against Minio S3 storage implementation,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian 9 (Stretch)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.8.0-5-gcfd0ea3bfb 1.8.0
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**:gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516 / clang version 4.0.1
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

### Describe the problem
At least when using [minio](https://minio.io) for S3 storage, small object requests initiated from TFRecordDataset() fail with following error:
2018-06-13 17:02:04.857500: W tensorflow/core/platform/s3/aws_logging.cc:57] Encountered Unknown AWSError 'InvalidRange': The requested range is not satisfiable
Reason is that TF is requesting the object with buffer size Range header and when the object is smaller than the buffer (256 kB) the system is not satisfied with the smaller response size, although response HTTP header clearly indicates that the object was received in full. Instead there's an attempt to try to fetch next chunk with Range that begins at the end of object and reaches further beyond end of the object. Naturally this request will fail. This will cause the entire request fail.

### Source code / logs
2018-06-13 17:02:04.857500: W tensorflow/core/platform/s3/aws_logging.cc:57] Encountered Unknown AWSError 'InvalidRange': The requested range is not satisfiable
"
19988,Official profile python API not work on the official mnist example,"Hi! I was using the official minist summaries example which uses run_metadata to track model runtime statistics:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py

I tried to add simple profiler python API as suggest by 

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/python_api.md

So, my code is:
https://github.com/MrWanter/mnist-proflie/blob/c0f5b59403fbf3258e8236fa7c983750623354e6/mnist-profile.py#L175-L184

but running the model gives 
```
Added profiling by user
Parsing Inputs...
Incomplete shape.
Incomplete shape.
Options -step=199 not found.
Available steps: 0 
Adding run metadata for 199
```
but tensorboard shows the memory consumption of nodes, which suggests runtime statistics are captured:
![image](https://user-images.githubusercontent.com/18298163/41357872-b3d623fe-6f59-11e8-91c2-539f55340e8a.png)

what is incomplete shape, the input shape has None for batch size, but since it is runtime statistics, I thought it would work, but it does not, can someone help?

As in #19962, it is hard to know how to deal with profiler problem since documentation is not enough and    codes are hard to read as it is implemented with C++ and heavily wrapped

**UPDATA**:
Th problem is caused by input shape of None for batch size, change it to fixed shape solve the problem, but there would inevitably be a large amount of None in tensors since we have to deal with variable sized inputs, in those cases, it should be reasonable for the profiler to capture runtime statistics, so how can we do it? where am I wrong?

**UPDATE**
Found a quote on the official profiler doc:
> It must have known ""shape"" information for RegisterStatistics('flops') to calculate the statistics. It is suggested to pass in -run_meta_path if shape is only known during runtime. tfprof can fill in the missing shape with the runtime shape information from RunMetadata. Hence, it is suggested to use -account_displayed_op_only option so that you know the statistics are only for the operations printed out.

seems profiler can fill in the missing shape with runtime shape information, but how to pass in `-
run_meta_path`,  I did not find anything relevant in the profiler options:
```
      self._options = {'max_depth': 100,
                       'min_bytes': 0,
                       'min_micros': 0,
                       'min_params': 0,
                       'min_float_ops': 0,
                       'min_occurrence': 0,
                       'order_by': 'name',
                       'account_type_regexes': ['.*'],
                       'start_name_regexes': ['.*'],
                       'trim_name_regexes': [],
                       'show_name_regexes': ['.*'],
                       'hide_name_regexes': [],
                       'account_displayed_op_only': False,
                       'select': ['micros'],
                       'step': -1,
                       'output': 'stdout'}
```"
19986,Caused by: java.lang.IllegalArgumentException: Expects arg[0] to be uint8 but float is provided,"Caused by: java.lang.IllegalArgumentException: Expects arg[0] to be uint8 but float is provided

I am developping on Android Studio and the model input is : Found 1 possible inputs: (name=image_tensor, type=uint8(4), shape=[?,?,?,3])

In my android code what I am trying to get is the array float of the values of pixels of an image stored as Bitmap and then I am trying to feed the model. I am getting that error .
Please anyone could help me how I can fix this?
I have tried to convert each float into array of byte[4] and then send the bytes but it seems I do not get the good images as a result.
Tensorflow version: 1.8.0"
19982,Can't allocate memory for the interpreter in tflite,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Nope, using tensorflow-for-poets
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.1
- **Python version**: Python 2.7.10
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: I added a custom tflite model (converted .pb using TOCO) and replaced graph.lite with the new custom model and built the app, but it crashes on runtime.

### Detailed Description
I created a custom TensorFlow model and converted it to TOCO (as described in the tensorflow-for-poets tutorial) and I replaced the old graph.lite file with my custom model and changed nothing else in the code. When I run the app, I get the following runtime error:

```
Process: android.example.com.tflitecamerademo, PID: 29160
    java.lang.RuntimeException: Unable to start activity ComponentInfo{android.example.com.tflitecamerademo/com.example.android.tflitecamerademo.CameraActivity}: java.lang.NullPointerException: Can not allocate memory for the interpreter
```

### Fixes Already Tried
- Ensuring that Android Studio/Gradle pick up on tensorflow-lite:0.1.7 changes (#19051). Currently, my build.gradle file says `compile 'org.tensorflow:tensorflow-lite:+'`, but changing it to `compile 'org.tensorflow:tensorflow-lite:0.1.7'` doesn't resolve the issue either.
- Running TOCO with the `--change_concat_input_ranges=false` flag."
19981,Feature Request: erosion and dilation such as scipy.ndimage.grey_erosion and scipy.ndimage.grey_dilation,"tf.image.erosion and tf.image.dilation. I find tf.nn.dilation2d is too slow when the kernel size is [20,20,1]."
19975,Runtime Error on TFLite Sample App,"### System information
* Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.4 LTS
* TensorFlow installed from (source or binary): pip/binary
* TensorFlow version (use command below): 1.8.0
* Python version: 3.5.2
* Bazel version (if compiling from source): N/A
* CUDA/cuDNN version: N/A
* GPU model and memory: N/A
* Exact command to reproduce: Please see the description.

### Describe the problem
I'm developing an android application based on the tensorflow-lite [object detection examples](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android
).

I trained `ssd_mobilenet_v1` and converted that model by following [this instructions](https://github.com/tensorflow/tensorflow/issues/15633#issuecomment-377652630).

Now I modified some lines which are shown the folloing before building and deploying the app.

### Source code

```diff
diff --git a/tensorflow/contrib/lite/examples/android/BUILD b/tensorflow/contrib/lite/examples/android/BUILD
index 5700007..85b58fc 100644
--- a/tensorflow/contrib/lite/examples/android/BUILD
+++ b/tensorflow/contrib/lite/examples/android/BUILD
@@ -34,7 +34,8 @@ android_binary(
         ""@tflite_mobilenet//:mobilenet_quant_v1_224.tflite"",
         ""@tflite_conv_actions_frozen//:conv_actions_frozen.tflite"",
         ""//tensorflow/contrib/lite/examples/android/assets:conv_actions_labels.txt"",
-        ""@tflite_mobilenet_ssd//:mobilenet_ssd.tflite"",
+        # ""@tflite_mobilenet_ssd//:mobilenet_ssd.tflite"",
+        ""//tensorflow/contrib/lite/examples/android/assets:ssd.tflite"",
         ""//tensorflow/contrib/lite/examples/android/assets:box_priors.txt"",
         ""//tensorflow/contrib/lite/examples/android/assets:coco_labels_list.txt"",
     ],
diff --git a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java
index de997e4..95710ff 100644
--- a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java
+++ b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/DetectorActivity.java
@@ -50,7 +50,8 @@ public class DetectorActivity extends CameraActivity implements OnImageAvailable

   // Configuration values for the prepackaged SSD model.
   private static final int TF_OD_API_INPUT_SIZE = 300;
-  private static final String TF_OD_API_MODEL_FILE = ""mobilenet_ssd.tflite"";
+  // private static final String TF_OD_API_MODEL_FILE = ""mobilenet_ssd.tflite"";
+  private static final String TF_OD_API_MODEL_FILE = ""ssd.tflite"";
   private static final String TF_OD_API_LABELS_FILE = ""file:///android_asset/coco_labels_list.txt"";

   // Which detection model to use: by default uses Tensorflow Object Detection API frozen
diff --git a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java
index bfb4a0a..b21e753 100644
--- a/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java
+++ b/tensorflow/contrib/lite/examples/android/src/org/tensorflow/demo/TFLiteObjectDetectionAPIModel.java
@@ -47,8 +47,8 @@ public class TFLiteObjectDetectionAPIModel implements Classifier {

   // Only return this many results.
   private static final int NUM_RESULTS = 1917;
-  private static final int NUM_CLASSES = 91;
-
+  // private static final int NUM_CLASSES = 91;
+  private static final int NUM_CLASSES = 22;
   private static final float Y_SCALE = 10.0f;
   private static final float X_SCALE = 10.0f;
   private static final float H_SCALE = 5.0f;
```

### logs
Under those conditions, I faced the following Runtime Error.
```JAVA
06-13 15:38:39.120 21951-21971/org.tensorflow.lite.demo E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.demo, PID: 21951
    java.lang.IllegalArgumentException: Output error: Shape of output target [1, 1917, 4] does not match with the shape of the Tensor [1, 1917, 1, 4].
        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:44)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:178)
        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:222)
        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:243)
        at android.os.Handler.handleCallback(Handler.java:761)
        at android.os.Handler.dispatchMessage(Handler.java:98)
        at android.os.Looper.loop(Looper.java:156)
        at android.os.HandlerThread.run(HandlerThread.java:61)
```

Actually I applied another dataset to the model (`ssd.tflite`), but I just used [train.py](https://github.com/tensorflow/models/blob/master/research/object_detection/train.py) as is, so I'm wondering why it was happened.

I hope someone would help me.

Thank you."
19974,"profiler op view: how to interpret the two numbers of (xx%, xx%) in the output","Hi! I'm using the tf profiler, a typical output for the `op` view with the code:
```
profiler.profile(
    tf.get_default_graph(),
    run_meta=run_metadata,
    cmd='op',
    options=opts)
```
would be 
```
Profile:
node name | # float_ops
MatMul                   81.40m float_ops (100.00%, 96.29%)
Mean                     795.12k float_ops (3.71%, 0.94%)
Mul                      648.40k float_ops (2.77%, 0.77%)
Add                      548.00k float_ops (2.00%, 0.65%)
Sub                      397.51k float_ops (1.36%, 0.47%)
Square                   397.51k float_ops (0.89%, 0.47%)
RealDiv                  200.00k float_ops (0.42%, 0.24%)
Sum                      100.79k float_ops (0.18%, 0.12%)
Neg                      50.00k float_ops (0.06%, 0.06%)
ArgMax                     900 float_ops (0.00%, 0.00%)
Equal                      102 float_ops (0.00%, 0.00%)
Greater                      1 float_ops (0.00%, 0.00%)

======================End of Report==========================
```
but I really cannot figure out what the two percent numbers in the output means, I googled it a while, no lucky, when I tried to read the source code of profiler, I find it wrapped too heavy..."
19973,How to add a threshold in softmax scores,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.8
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
When doing multi-classcification usually I got a softmax score and predictoins with below,
```
softmax_scores = tf.nn.softmax(logits=self.scores, dim=-1)
prediction=tf.argmax(self.scores, 1, name=""predictions"")
```
If the softmax_socres I got is [0.5,0.2,0.3].The prediction is [0]. Now I want to add thresholds 0.6 to softmax_socres.Which means the prediction expected here is [4] which means others.
The only way that I can figure out is to convert softmax_scores to numpy and handle it. Which is out of the model defination.

### Source code / logs
This is only a demo, the full code is too long.
```
import tensorflow as tf
import numpy as np
a=tf.constant(np.arange(6),shape=(3,2))
b=tf.reduce_max(a,1)
c=tf.to_int32(a>3)
d=tf.argmax(c,1)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(c.eval(),d.eval())
```
Here the result I expect is [4,4,2]"
19971,Pd turns tflite to report all kinds of errors. Have you done the test?,"Download the network model

MobileNet_v1_1.0_224_quant

https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
Turn tflite error

bazel run toco -- 
--input_file=/Users/dchealth/Desktop/mobilenet_v1_1.0_224_quant/mobilenet_v1_1.0_224_quant_frozen.pb 
--output_file=/Users/dchealth/Desktop/mobilenet_v1_1.0_224_quant/mobilenetnew.tflite 
--input_format=TENSORFLOW_GRAPHDEF 
--inference_type=FLOAT 
--output_format=TFLITE 
--input_shapes=1,224,224,3 
--input_arrays=input 
--output_arrays=MobilenetV1/Predictions/Reshape_1
--inference_type=QUANTIZED_UINT8
--std_values=128
--mean_values=128
------------------------

System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac os 10.13.5

TensorFlow installed from (source or binary):pip

TensorFlow version (use command below):'1.8.0

Python version: 3.6.4

Bazel version (if compiling from source):
Build label: 0.14.0-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 1 14:26:58 2018 (1527863218)
Build timestamp: 1527863218
Build timestamp as int: 1527863218

GCC/Compiler version (if compiling from source):no

CUDA/cuDNN version:no

GPU model and memory:no

Exact command to reproduce:no

End of run log:

./tensorflow/contrib/lite/builtin_op_data.h:122:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:125:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:161:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:164:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:203:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
5 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/model.cc:
In file included from tensorflow/contrib/lite/model.cc:25:
./tensorflow/contrib/lite/builtin_op_data.h:122:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:125:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:161:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:164:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
./tensorflow/contrib/lite/builtin_op_data.h:203:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]
typedef struct {
^
5 warnings generated.
INFO: From Linking external/protobuf_archive/libprotobuf.a:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf.a(gzip_stream.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf.a(error_listener.o) has no symbols
INFO: From Linking external/protobuf_archive/libprotobuf_lite.a:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf_lite.a(arenastring.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf_lite.a(atomicops_internals_x86_msvc.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/external/protobuf_archive/libprotobuf_lite.a(io_win32.o) has no symbols
INFO: From Compiling tensorflow/core/lib/strings/numbers.cc:
tensorflow/core/lib/strings/numbers.cc:394:34: warning: format specifies type 'unsigned long ' but the argument has type 'uint64_t ' (aka 'unsigned long long ') [-Wformat]
if (sscanf(s.c_str(), ""%lx%c"", &result, &junk) == 1) {
~~~ ^~~~~~~
%llx
1 warning generated.
INFO: From Linking tensorflow/core/liblib_internal_impl.a:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/liblib_internal_impl.a(android_armv7a_cpu_utils_helper.o) has no symbols
INFO: From Compiling tensorflow/core/util/command_line_flags.cc:
tensorflow/core/util/command_line_flags.cc:73:37: warning: format specifies type 'long ' but the argument has type 'int64_t ' (aka 'long long ') [-Wformat]
if (sscanf(arg.data(), ""%ld%c"", &parsed_int64, &extra) != 1) {
~~~ ^~~~~~~~~~~~~
%lld
1 warning generated.
INFO: From Compiling tensorflow/core/util/strided_slice_op.cc:
tensorflow/core/util/strided_slice_op.cc:270:33: warning: lambda capture 'i' is not used [-Wunused-lambda-capture]
auto canonical = [stride_i, i, dim_i, masks, valid_range](int64 x, int c) {
^
1 warning generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_default_min_max.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_default_min_max.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/dump_graphviz.cc:
In file included from tensorflow/contrib/lite/toco/dump_graphviz.cc:15:
In file included from ./tensorflow/contrib/lite/toco/dump_graphviz.h:20:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_stack.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_stack.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_activation_function_into_constants.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_activation_function_into_constants.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_merge.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_merge.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_slice_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_slice_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_array_data_types.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_array_data_types.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tooling_util.cc:
In file included from tensorflow/contrib/lite/toco/tooling_util.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tooling_util.h:31:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_binary.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_binary.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/reorder_elementwise_unary.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_addn_to_add.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_addn_to_add.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_fake_quant.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_fake_quant.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_slice.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_slice.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/ensure_uint8_weights_safe_for_fast_int8_kernels.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/ensure_uint8_weights_safe_for_fast_int8_kernels.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/reorder_reshape_transpose.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/reorder_reshape_transpose.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
tensorflow/contrib/lite/toco/graph_transformations/reorder_reshape_transpose.cc:51:6: warning: unused function 'Filter' [-Wunused-function]
void Filter(std::vector vec, int value) {
^
3 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_strided_slice.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_strided_slice.cc:18:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_assert.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_assert.cc:19:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/experimental_shuffle_fc_weights.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/experimental_shuffle_fc_weights.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_following_affine.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_following_affine.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/drop_im2col_arrays.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/drop_im2col_arrays.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/fuse_binary_into_preceding_affine.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_activation_func.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_activation_func.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_multiply_by_zero.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_multiply_by_zero.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fill.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fill.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_shape_or_rank.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_shape_or_rank.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation_input.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation_input.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_l2_pool.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_l2_pool.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_squeeze_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_squeeze_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_range.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_range.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_concatenation.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/merge_reshape_into_preceding_transpose.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/merge_reshape_into_preceding_transpose.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_binary.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_binary.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/unroll_batch_matmul.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/unroll_batch_matmul.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_to_space_nd_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_to_space_nd_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_reshape.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_reshape.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_split_inputs.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_split_inputs.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_stack_to_reshape.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_stack_to_reshape.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/make_initial_dequantize_operator.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/make_initial_dequantize_operator.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_reshape.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_reshape.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_passthrough.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_passthrough.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/quantization_util.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/quantization_util.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_transpose.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_transpose.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_final_dequantize_op.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_final_dequantize_op.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:23:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_slice.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_slice.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/lstm_utils.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/lstm_utils.cc:15:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/lstm_utils.h:22:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_reorder_axes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_reorder_axes.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/unpartition_embedding_lookup.cc:19:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_unary.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_unary.cc:23:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_mean_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_mean_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/read_fake_quant_min_max.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/read_fake_quant_min_max.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/create_im2col_arrays.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/create_im2col_arrays.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_concat.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_concat.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/dequantize.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/dequantize.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/drop_fake_quant.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/drop_fake_quant.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_dilated_conv.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_dilated_conv.cc:18:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_reshape_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_reshape_attributes.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_pure_conv_to_depthwise.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_pure_conv_to_depthwise.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_l2_normalization.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_l2_normalization.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_merge_inputs.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_lstm_merge_inputs.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_prelu.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_prelu.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_relu1.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_relu1.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_unused_op.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_unused_op.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/unfuse_activation_functions.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/unfuse_activation_functions.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/fuse_activation_functions.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/fuse_activation_functions.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_fake_quant_num_bits.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_fake_quant_num_bits.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_pad_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_pad_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_fake_quant.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/identify_lstm.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/identify_lstm.cc:19:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_gather.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_gather.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_transpose_to_reshape.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_trivial_transpose_to_reshape.cc:17:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_space_to_batch_nd_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_space_to_batch_nd_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_matmul.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_matmul.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_padv2_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_padv2_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_squeeze_to_reshape.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_squeeze_to_reshape.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_concatenation.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_concatenation.cc:22:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_tile.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_tile.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_identity.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_tensorflow_identity.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/ensure_bias_vectors.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/ensure_bias_vectors.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:24:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_transpose_attributes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_transpose_attributes.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/resolve_constant_random_uniform.cc:18:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_expanddims_to_reshape.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_expanddims_to_reshape.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/convert_reorder_axes.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/convert_reorder_axes.cc:21:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_min_max.cc:
In file included from tensorflow/contrib/lite/toco/graph_transformations/remove_trivial_quantized_min_max.cc:20:
In file included from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.cc:
In file included from tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.h:21:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_cluster.cc:
In file included from tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_cluster.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_cluster.h:22:
In file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/cluster.h:21:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.cc:
In file included from tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tensorflow_graph_matching/resolve_svdf.h:21:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tflite/types.cc:
In file included from tensorflow/contrib/lite/toco/tflite/types.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tflite/types.h:19:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tflite/import.cc:
In file included from tensorflow/contrib/lite/toco/tflite/import.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tflite/import.h:19:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
tensorflow/contrib/lite/toco/tflite/import.cc:168:6: warning: unused function 'Verify' [-Wunused-function]
bool Verify(const void buf, size_t len) {
^
3 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tflite/export.cc:
In file included from tensorflow/contrib/lite/toco/tflite/export.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tflite/export.h:18:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/tflite/operator.cc:
In file included from tensorflow/contrib/lite/toco/tflite/operator.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tflite/operator.h:20:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/core/kernels/priority_queue.cc:
In file included from tensorflow/core/kernels/priority_queue.cc:25:
In file included from ./tensorflow/core/kernels/priority_queue.h:27:
./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::deque& sq) {
^
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/kernels/fifo_queue.cc:
In file included from tensorflow/core/kernels/fifo_queue.cc:26:
In file included from ./tensorflow/core/kernels/fifo_queue.h:26:
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/padding_fifo_queue.cc:
In file included from tensorflow/core/kernels/padding_fifo_queue.cc:26:
In file included from ./tensorflow/core/kernels/padding_fifo_queue.h:27:
In file included from ./tensorflow/core/kernels/fifo_queue.h:26:
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
1 warning generated.
INFO: From Compiling tensorflow/core/framework/reader_base.cc:
tensorflow/core/framework/reader_base.cc:205:17: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
context, [this, context, &n, &work](const QueueInterface::Tuple& tuple) {
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/initializable_lookup_table.cc:
In file included from tensorflow/core/kernels/initializable_lookup_table.cc:16:
./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
Status ExportValues(OpKernelContext context) {
^
./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here
virtual Status ExportValues(OpKernelContext ctx) = 0;
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/lookup_util.cc:
In file included from tensorflow/core/kernels/lookup_util.cc:16:
In file included from ./tensorflow/core/kernels/lookup_util.h:21:
./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
Status ExportValues(OpKernelContext context) {
^
./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here
virtual Status ExportValues(OpKernelContext ctx) = 0;
^
1 warning generated.
INFO: From Linking tensorflow/core/kernels/libfused_batch_norm_util_gpu.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libfused_batch_norm_util_gpu.lo(fused_batch_norm_op.cu.o) has no symbols
warning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libfused_batch_norm_util_gpu.lo the table of contents is empty (no object file members in the library define global symbols)
INFO: From Compiling tensorflow/core/kernels/boosted_trees/prediction_ops.cc:
tensorflow/core/kernels/boosted_trees/prediction_ops.cc:115:41: warning: lambda capture 'batch_size' is not used [-Wunused-lambda-capture]
&output_node_ids, batch_size,
^
tensorflow/core/kernels/boosted_trees/prediction_ops.cc:225:21: warning: lambda capture 'batch_size' is not used [-Wunused-lambda-capture]
batch_size, latest_tree](int32 start, int32 end) {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/kernels/collective_ops.cc:
tensorflow/core/kernels/collective_ops.cc:143:28: warning: lambda capture 'col_exec' is not used [-Wunused-lambda-capture]
auto actual_done = [c, col_exec, done](const Status& s) {
^
tensorflow/core/kernels/collective_ops.cc:197:28: warning: lambda capture 'col_exec' is not used [-Wunused-lambda-capture]
auto actual_done = [c, col_exec, done](const Status& s) {
^
tensorflow/core/kernels/collective_ops.cc:247:28: warning: lambda capture 'col_exec' is not used [-Wunused-lambda-capture]
auto actual_done = [c, col_exec, done](const Status& s) {
^
3 warnings generated.
INFO: From Linking tensorflow/core/kernels/libself_adjoint_eig_v2_op.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libself_adjoint_eig_v2_op.lo(self_adjoint_eig_v2_op_gpu.o) has no symbols
INFO: From Linking tensorflow/core/kernels/libcudnn_rnn_kernels.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libcudnn_rnn_kernels.lo(cudnn_rnn_ops.o) has no symbols
warning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libcudnn_rnn_kernels.lo the table of contents is empty (no object file members in the library define global symbols)
INFO: From Compiling tensorflow/contrib/tensorboard/db/summary_db_writer.cc:
tensorflow/contrib/tensorboard/db/summary_db_writer.cc:812:22: warning: private field 'meta_' is not used [-Wunused-private-field]
RunMetadata* const meta_;
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/sdca_internal.cc:
tensorflow/core/kernels/sdca_internal.cc:49:9: warning: suggest braces around initialization of subobject [-Wmissing-braces]
Eigen::IndexPair(1, 0)};
^~~~~~~~~~~~~~~~~~~~~~~~~~~
{ }
tensorflow/core/kernels/sdca_internal.cc:210:11: warning: suggest braces around initialization of subobject [-Wmissing-braces]
Eigen::IndexPair(1, 1)};
^~~~~~~~~~~~~~~~~~~~~~~~~~~
{ }
2 warnings generated.
INFO: From Linking tensorflow/core/kernels/libgather_functor.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libgather_functor.lo(gather_functor.o) has no symbols
warning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libgather_functor.lo the table of contents is empty (no object file members in the library define global symbols)
INFO: From Compiling tensorflow/core/kernels/adjust_saturation_op.cc:
tensorflow/core/kernels/adjust_saturation_op.cc:196:12: warning: lambda capture 'channel_count' is not used [-Wunused-lambda-capture]
[channel_count, &input_data, &output_data, scale_h](
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/adjust_hue_op.cc:
tensorflow/core/kernels/adjust_hue_op.cc:219:12: warning: lambda capture 'channel_count' is not used [-Wunused-lambda-capture]
[channel_count, &input_data, &output_data, delta_h](
^
1 warning generated.
INFO: From Linking tensorflow/core/kernels/libconcat_lib.a:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libconcat_lib.a(concat_lib_gpu.o) has no symbols
INFO: From Linking tensorflow/core/kernels/libscatter_functor.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libscatter_functor.lo(scatter_functor.o) has no symbols
warning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libscatter_functor.lo the table of contents is empty (no object file members in the library define global symbols)
INFO: From Linking tensorflow/core/kernels/libscatter_nd_op.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libscatter_nd_op.lo(scatter_nd_op_cpu_impl_0.o) has no symbols
INFO: From Compiling tensorflow/core/common_runtime/collective_rma_local.cc:
In file included from tensorflow/core/common_runtime/collective_rma_local.cc:15:
./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
void StartAbort(const Status& s);
^
./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here
virtual void StartAbort(const Status& s) = 0;
^
tensorflow/core/common_runtime/collective_rma_local.cc:40:13: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
key, [this, to_tensor, to_device_ctx, to_device, to_alloc_attr, done](
^
2 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/executor.cc:
tensorflow/core/common_runtime/executor.cc:2082:19: warning: calling function 'ActivateNodes' requires holding mutex 'output_frame->mu' exclusively [-Wthread-safety-precise]
output_frame->ActivateNodes(item, is_dead, output_iter, outputs, ready);
^
tensorflow/core/common_runtime/executor.cc:2082:19: note: found near match 'input_frame->mu'
tensorflow/core/common_runtime/executor.cc:2147:21: warning: calling function 'ActivateNodes' requires holding mutex 'output_frame->mu' exclusively [-Wthread-safety-precise]
output_frame->ActivateNodes(item, is_dead, output_iter, outputs, ready);
^
tensorflow/core/common_runtime/executor.cc:2147:21: note: found near match 'input_frame->mu'
2 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/ring_reducer.cc:
In file included from tensorflow/core/common_runtime/ring_reducer.cc:17:
./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
void StartAbort(const Status& s);
^
./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here
virtual void StartAbort(const Status& s) = 0;
^
tensorflow/core/common_runtime/ring_reducer.cc:166:19: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
output_, [this, &note, &status](const Status& s) {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/accumulate_n_optimizer.cc:
tensorflow/core/common_runtime/accumulate_n_optimizer.cc:77:31: warning: lambda capture 'g' is not used [-Wunused-lambda-capture]
auto base_make_node = [n, g, &n_attrs](const string& op,
^
tensorflow/core/common_runtime/accumulate_n_optimizer.cc:89:30: warning: lambda capture 'n_attrs' is not used [-Wunused-lambda-capture]
auto make_node = [n, g, &n_attrs, &base_make_node](string op) {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/broadcaster.cc:
In file included from tensorflow/core/common_runtime/broadcaster.cc:17:
./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
void StartAbort(const Status& s);
^
./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here
virtual void StartAbort(const Status& s) = 0;
^
tensorflow/core/common_runtime/broadcaster.cc:148:25: warning: lambda capture 'recv_from_rank' is not used [-Wunused-lambda-capture]
[this, recv_from_rank, &mu, &note](const Status& s) {
^
tensorflow/core/common_runtime/broadcaster.cc:166:18: warning: lambda capture 'target_rank' is not used [-Wunused-lambda-capture]
[this, target_rank, &mu, &pending_count, &all_done](const Status& s) {
^
3 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/parallel_concat_optimizer.cc:
tensorflow/core/common_runtime/parallel_concat_optimizer.cc:53:33: warning: lambda capture 'g' is not used [-Wunused-lambda-capture]
auto base_make_node = [n, g, &n_attrs](const string& op,
^
tensorflow/core/common_runtime/parallel_concat_optimizer.cc:63:32: warning: lambda capture 'n_attrs' is not used [-Wunused-lambda-capture]
auto make_node = [n, g, &n_attrs, &base_make_node](string op) {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/collective_executor_mgr.cc:
In file included from tensorflow/core/common_runtime/collective_executor_mgr.cc:19:
./tensorflow/core/common_runtime/collective_rma_local.h:37:8: warning: 'StartAbort' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
void StartAbort(const Status& s);
^
./tensorflow/core/framework/collective.h:305:16: note: overridden virtual function is here
virtual void StartAbort(const Status& s) = 0;
^
1 warning generated.
INFO: From Compiling tensorflow/core/common_runtime/function.cc:
tensorflow/core/common_runtime/function.cc:911:12: warning: lambda capture 'item' is not used [-Wunused-lambda-capture]
[item, frame, exec_args](DoneCallback done,
^
tensorflow/core/common_runtime/function.cc:911:18: warning: lambda capture 'frame' is not used [-Wunused-lambda-capture]
[item, frame, exec_args](DoneCallback done,
^
2 warnings generated.
INFO: From Compiling tensorflow/core/common_runtime/collective_param_resolver_local.cc:
tensorflow/core/common_runtime/collective_param_resolver_local.cc:534:47: warning: lambda capture 'gr' is not used [-Wunused-lambda-capture]
irec->init_waiters.push_back([this, gr, cp, done](InstanceRec* irec) {
^
tensorflow/core/common_runtime/collective_param_resolver_local.cc:534:51: warning: lambda capture 'cp' is not used [-Wunused-lambda-capture]
irec->init_waiters.push_back([this, gr, cp, done](InstanceRec* irec) {
^
tensorflow/core/common_runtime/collective_param_resolver_local.cc:669:50: warning: reading variable 'source_rank' requires holding mutex 'ir->out_mu' [-Wthread-safety-precise]
source_rank = ir->source_rank;
^
tensorflow/core/common_runtime/collective_param_resolver_local.cc:669:50: note: found near match 'irec->out_mu'
tensorflow/core/common_runtime/collective_param_resolver_local.cc:662:29: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
[this, ir, device, cp, done](InstanceRec* irec) {
^
4 warnings generated.
INFO: From Linking tensorflow/core/libcore_cpu_impl.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libcore_cpu_impl.lo(mkl_cpu_allocator.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libcore_cpu_impl.lo(mkl_layout_pass.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libcore_cpu_impl.lo(mkl_tfconversion_pass.o) has no symbols
INFO: From Compiling tensorflow/core/common_runtime/gpu/process_state.cc:
tensorflow/core/common_runtime/gpu/process_state.cc:56:6: warning: unused function 'useCudaMallocAllocator' [-Wunused-function]
bool useCudaMallocAllocator() {
^
tensorflow/core/common_runtime/gpu/process_state.cc:62:6: warning: unused function 'useCudaMemoryGuardAllocator' [-Wunused-function]
bool useCudaMemoryGuardAllocator() {
^
2 warnings generated.
INFO: From Linking tensorflow/core/libgpu_runtime_impl.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libgpu_runtime_impl.lo(gpu_device_factory.o) has no symbols
INFO: From Compiling tensorflow/contrib/lite/toco/tensorflow_util.cc:
In file included from tensorflow/contrib/lite/toco/tensorflow_util.cc:15:
In file included from ./tensorflow/contrib/lite/toco/tensorflow_util.h:21:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/export_tensorflow.cc:
In file included from tensorflow/contrib/lite/toco/export_tensorflow.cc:25:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
tensorflow/contrib/lite/toco/export_tensorflow.cc:1731:6: warning: unused function 'ConvertSparseToDenseOperator' [-Wunused-function]
void ConvertSparseToDenseOperator(const Model& model,
^
3 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:
In file included from tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:23:
In file included from ./tensorflow/contrib/lite/toco/allocate_transient_arrays.h:18:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/toco_tooling.cc:
In file included from tensorflow/contrib/lite/toco/toco_tooling.cc:15:
In file included from ./tensorflow/contrib/lite/toco/toco_tooling.h:21:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/contrib/lite/toco/import_tensorflow.cc:
In file included from tensorflow/contrib/lite/toco/import_tensorflow.cc:15:
In file included from ./tensorflow/contrib/lite/toco/import_tensorflow.h:20:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/core/grappler/optimizers/remapper.cc:
In file included from tensorflow/core/grappler/optimizers/remapper.cc:16:
./tensorflow/core/grappler/optimizers/remapper.h:42:26: warning: private field 'opt_level' is not used [-Wunused-private-field]
RewriterConfig::Toggle opt_level;
^
1 warning generated.
INFO: From Compiling tensorflow/core/grappler/optimizers/shape_optimizer.cc:
In file included from tensorflow/core/grappler/optimizers/shape_optimizer.cc:16:
./tensorflow/core/grappler/optimizers/shape_optimizer.h:48:26: warning: private field 'opt_level' is not used [-Wunused-private-field]
RewriterConfig::Toggle opt_level;
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/data/parallel_map_dataset_op.cc:
tensorflow/core/kernels/data/parallel_map_dataset_op.cc:343:24: warning: lambda capture 'result_index' is not used [-Wunused-lambda-capture]
[result, result_index](Status ret_status) {
^
1 warning generated.
INFO: From Linking tensorflow/core/libsycl_runtime.a:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_allocator.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_device.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_device_context.o) has no symbols
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a(sycl_device_factory.o) has no symbols
warning: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: warning for library: bazel-out/darwin-opt/bin/tensorflow/core/libsycl_runtime.a the table of contents is empty (no object file members in the library define global symbols)
INFO: From Compiling tensorflow/core/kernels/fifo_queue_op.cc:
In file included from tensorflow/core/kernels/fifo_queue_op.cc:26:
In file included from ./tensorflow/core/kernels/fifo_queue.h:26:
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/random_shuffle_queue_op.cc:
In file included from tensorflow/core/kernels/random_shuffle_queue_op.cc:28:
./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::deque& sq) {
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/padding_fifo_queue_op.cc:
In file included from tensorflow/core/kernels/padding_fifo_queue_op.cc:27:
In file included from ./tensorflow/core/kernels/padding_fifo_queue.h:27:
In file included from ./tensorflow/core/kernels/fifo_queue.h:26:
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/tensor_array_ops.cc:
tensorflow/core/kernels/tensor_array_ops.cc:330:21: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
auto creator = [this, key, tensor_array, array_size, marked_size,
^
tensorflow/core/kernels/tensor_array_ops.cc:332:21: warning: lambda capture 'output_handle' is not used [-Wunused-lambda-capture]
output_handle](TensorArray** ret) -> Status {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/kernels/priority_queue_op.cc:
In file included from tensorflow/core/kernels/priority_queue_op.cc:25:
In file included from ./tensorflow/core/kernels/priority_queue.h:27:
./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::deque& sq) {
^
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
2 warnings generated.
INFO: From Compiling tensorflow/core/kernels/barrier_ops.cc:
tensorflow/core/kernels/barrier_ops.cc:512:33: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
ComputeAsync(ctx, barrier, this, callback, barrier {
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManyEigen::half' requested here
barrier->TryInsertMany(keys, component_index_, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOpEigen::half::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOpEigen::half::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManytensorflow::bfloat16' requested here
barrier->TryInsertMany(keys, component_index_, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::bfloat16::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::bfloat16::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(keys, component_index_, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(keys, component_index_, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany<std::_1::complex >' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::complex >::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::complex >::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany<std::_1::complex >' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::complex >::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::_1::complex >::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertMany<std::_1::basic_string >' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::__1::basic_string >::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOp<std::1::basic_string >::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManytensorflow::ResourceHandle' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::ResourceHandle::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::ResourceHandle::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
tensorflow/core/kernels/barrier_ops.cc:183:31: warning: lambda capture 'component_index' is not used [-Wunused-lambda-capture]
this, ctx, callback, component_index {
^
tensorflow/core/kernels/barrier_ops.cc:552:14: note: in instantiation of function template specialization 'tensorflow::barrier::Barrier::TryInsertManytensorflow::Variant' requested here
barrier->TryInsertMany(*keys, component_index, values, ctx, callback);
^
tensorflow/core/kernels/barrier_ops.cc:526:12: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::Variant::ComputeAsync' requested here
explicit InsertManyOp(OpKernelConstruction context)
^
tensorflow/core/kernels/barrier_ops.cc:565:19: note: in instantiation of member function 'tensorflow::barrier::InsertManyOptensorflow::Variant::InsertManyOp' requested here
TF_CALL_ALL_TYPES(REGISTER_INSERTMANY);
^
In file included from tensorflow/core/kernels/barrier_ops.cc:28:
In file included from ./tensorflow/core/kernels/priority_queue.h:27:
./tensorflow/core/kernels/typed_queue.h:83:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::deque& sq) {
^
./tensorflow/core/kernels/typed_queue.h:91:7: warning: unused function 'SizeOf' [-Wunused-function]
int64 SizeOf(const std::vector& sq) {
^
19 warnings generated.
INFO: From Compiling tensorflow/core/kernels/lookup_table_init_op.cc:
In file included from tensorflow/core/kernels/lookup_table_init_op.cc:17:
In file included from ./tensorflow/core/kernels/lookup_table_init_op.h:19:
./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
Status ExportValues(OpKernelContext context) {
^
./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here
virtual Status ExportValues(OpKernelContext ctx) = 0;
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/generate_vocab_remapping_op.cc:
In file included from tensorflow/core/kernels/generate_vocab_remapping_op.cc:23:
In file included from ./tensorflow/core/kernels/lookup_table_init_op.h:19:
./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
Status ExportValues(OpKernelContext context) {
^
./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here
virtual Status ExportValues(OpKernelContext ctx) = 0;
^
1 warning generated.
INFO: From Compiling tensorflow/core/kernels/lookup_table_op.cc:
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
In file included from ./tensorflow/core/kernels/lookup_table_op.h:25:
In file included from ./tensorflow/core/kernels/lookup_util.h:21:
./tensorflow/core/kernels/initializable_lookup_table.h:54:10: warning: 'ExportValues' overrides a member function but is not marked 'override' [-Winconsistent-missing-override]
Status ExportValues(OpKernelContext* context) {
^
./tensorflow/core/framework/lookup_interface.h:74:18: note: overridden virtual function is here
virtual Status ExportValues(OpKernelContext* ctx) = 0;
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle_' requires holding mutex 'mu_' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle_.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, double>, std::__1::basic_string, double>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:815:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::_1::basic_string, double>, std::1::basic_string, double>::LookupTableOp' requested here
REGISTER_KERNEL(string, double);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:816:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here
REGISTER_KERNEL(string, float);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, int>, std::__1::basic_string, int>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:817:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::_1::basic_string, int>, std::1::basic_string, int>::LookupTableOp' requested here
REGISTER_KERNEL(string, int32);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, long long>, std::__1::basic_string, long long>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:818:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::1::basic_string, long long>, std::1::basic_string, long long>::LookupTableOp' requested here
REGISTER_KERNEL(string, int64);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, std::1::basic_string >, long long, std::1::basic_string >::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:819:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, std::1::basic_string >, long long, std::1::basic_string >::LookupTableOp' requested here
REGISTER_KERNEL(int64, string);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, long long>, long long, long long>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:820:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, long long>, long long, long long>::LookupTableOp' requested here
REGISTER_KERNEL(int64, int64);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, float>, long long, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:821:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<long long, float>, long long, float>::LookupTableOp' requested here
REGISTER_KERNEL(int64, float);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, std::__1::basic_string >, std::__1::basic_string, std::__1::basic_string >::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:822:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, std::__1::basic_string >, std::_1::basic_string, std::1::basic_string >::LookupTableOp' requested here
REGISTER_KERNEL(string, string);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::__1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:823:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here
REGISTER_KERNEL(string, bool);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<int, int>, int, int>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:824:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::HashTable<int, int>, int, int>::LookupTableOp' requested here
REGISTER_KERNEL(int32, int32);
^
tensorflow/core/kernels/lookup_table_op.cc:805:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::HashTable<key_dtype, value_dtype>, key_dtype, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:845:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here
REGISTER_KERNEL(string, float);
^
tensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::__1::basic_string, long long>, std::__1::basic_string, long long>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:846:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::_1::basic_string, long long>, std::1::basic_string, long long>::LookupTableOp' requested here
REGISTER_KERNEL(string, int64);
^
tensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, std::__1::basic_string >, long long, std::__1::basic_string >::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:847:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, std::1::basic_string >, long long, std::1::basic_string >::LookupTableOp' requested here
REGISTER_KERNEL(int64, string);
^
tensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:848:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here
REGISTER_KERNEL(string, bool);
^
tensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, float>, long long, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:849:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, float>, long long, float>::LookupTableOp' requested here
REGISTER_KERNEL(int64, float);
^
tensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, tensorflow::Variant>, long long, tensorflow::Variant>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:850:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfScalars<long long, tensorflow::Variant>, long long, tensorflow::Variant>::LookupTableOp' requested here
REGISTER_KERNEL(int64, Variant);
^
tensorflow/core/kernels/lookup_table_op.cc:835:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfScalars<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:871:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here
REGISTER_KERNEL(string, float);
^
tensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::__1::basic_string, long long>, std::__1::basic_string, long long>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:872:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::_1::basic_string, long long>, std::1::basic_string, long long>::LookupTableOp' requested here
REGISTER_KERNEL(string, int64);
^
tensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<long long, std::_1::basic_string >, long long, std::1::basic_string >::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:873:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<long long, std::1::basic_string >, long long, std::1::basic_string >::LookupTableOp' requested here
REGISTER_KERNEL(int64, string);
^
tensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:874:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableHashTableOfTensors<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here
REGISTER_KERNEL(string, bool);
^
tensorflow/core/kernels/lookup_table_op.cc:861:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableHashTableOfTensors<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, long long>, long long, long long>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:895:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, long long>, long long, long long>::LookupTableOp' requested here
REGISTER_KERNEL(int64, int64);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, float>, long long, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:896:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, float>, long long, float>::LookupTableOp' requested here
REGISTER_KERNEL(int64, float);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, double>, long long, double>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:897:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, double>, long long, double>::LookupTableOp' requested here
REGISTER_KERNEL(int64, double);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::__1::basic_string, float>, std::__1::basic_string, float>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:898:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::_1::basic_string, float>, std::1::basic_string, float>::LookupTableOp' requested here
REGISTER_KERNEL(string, float);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::__1::basic_string, bool>, std::1::basic_string, bool>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:899:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<std::1::basic_string, bool>, std::1::basic_string, bool>::LookupTableOp' requested here
REGISTER_KERNEL(string, bool);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, bool>, long long, bool>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:900:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, bool>, long long, bool>::LookupTableOp' requested here
REGISTER_KERNEL(int64, bool);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
In file included from tensorflow/core/kernels/lookup_table_op.cc:16:
./tensorflow/core/kernels/lookup_table_op.h:68:39: warning: reading variable 'table_handle' requires holding mutex 'mu' [-Wthread-safety-analysis]
container->MemoryUsed() + table_handle.AllocatedBytes());
^
./tensorflow/core/kernels/lookup_table_op.h:42:12: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, tensorflow::Variant>, long long, tensorflow::Variant>::Compute' requested here
explicit LookupTableOp(OpKernelConstruction* ctx)
^
tensorflow/core/kernels/lookup_table_op.cc:901:1: note: in instantiation of member function 'tensorflow::LookupTableOp<tensorflow::lookup::MutableDenseHashTable<long long, tensorflow::Variant>, long long, tensorflow::Variant>::LookupTableOp' requested here
REGISTER_KERNEL(int64, Variant);
^
tensorflow/core/kernels/lookup_table_op.cc:885:7: note: expanded from macro 'REGISTER_KERNEL'
LookupTableOp<lookup::MutableDenseHashTable<key_dtype, value_dtype>, 
^
28 warnings generated.
[1,781 / 2,012] 4 actions running
Compiling tensorflow/core/kernels/sparse_tensors_map_ops.cc; 13s local
INFO: From Compiling tensorflow/core/kernels/deep_conv2d.cc:
tensorflow/core/kernels/deep_conv2d.cc:1005:30: warning: lambda capture 'tile_rows' is not used [-Wunused-lambda-capture]
out_depth, tile_rows, tile_cols, out_tile_rows, out_tile_cols,
^
tensorflow/core/kernels/deep_conv2d.cc:1154:26: note: in instantiation of member function 'tensorflow::functor::DeepConv2D<Eigen::ThreadPoolDevice, float>::operator()' requested here
template struct functor::DeepConv2D<CPUDevice, float>;
^
tensorflow/core/kernels/deep_conv2d.cc:1005:41: warning: lambda capture 'tile_cols' is not used [-Wunused-lambda-capture]
out_depth, tile_rows, tile_cols, out_tile_rows, out_tile_cols,
^
tensorflow/core/kernels/deep_conv2d.cc:436:55: warning: lambda capture 'out_depth' is not used [-Wunused-lambda-capture]
&num_filters_transform, &in_depth, &out_depth,
^
tensorflow/core/kernels/deep_conv2d.cc:974:5: note: in instantiation of member function 'tensorflow::TransformFilters::operator()' requested here
TransformFilters()(ctx, args, transform.get(), filter_shards_row,
^
tensorflow/core/kernels/deep_conv2d.cc:535:20: warning: lambda capture 'tile_spatial_size' is not used [-Wunused-lambda-capture]
&tile_spatial_size, &in_depth, &out_depth, &filter_shards_row,
^
tensorflow/core/kernels/deep_conv2d.cc:979:5: note: in instantiation of member function 'tensorflow::PackFilters::operator()' requested here
PackFilters()(ctx, args, tile_spatial_size, filter_shards_row,
^
4 warnings generated.
INFO: From Linking tensorflow/core/kernels/libpooling_ops.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libpooling_ops.lo(cudnn_pooling_gpu.o) has no symbols
INFO: From Compiling tensorflow/core/kernels/topk_op.cc:
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, long long>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, long long>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, long long>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, int>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, int>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, int>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned short>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned short>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned short>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, short>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, short>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, short>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, unsigned char>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned char>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, unsigned char>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, signed char>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, signed char>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, signed char>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, Eigen::half>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, Eigen::half>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, Eigen::half>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, tensorflow::bfloat16>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, float>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, float>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, float>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
tensorflow/core/kernels/topk_op.cc:137:28: warning: lambda capture 'context' is not used [-Wunused-lambda-capture]
auto SortIndices = [&, context](int start_batch, int limit_batch) {
^
tensorflow/core/kernels/topk_op.cc:90:49: note: in instantiation of member function 'tensorflow::functor::TopKFunctor<Eigen::ThreadPoolDevice, double>::Compute' requested here
Status s = functor::TopKFunctor<Device, T>::Compute(
^
tensorflow/core/kernels/topk_op.cc:42:12: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, double>::Compute' requested here
explicit TopK(OpKernelConstruction* context) : OpKernel(context) {
^
tensorflow/core/kernels/topk_op.cc:241:27: note: in instantiation of member function 'tensorflow::TopK<Eigen::ThreadPoolDevice, double>::TopK' requested here
TF_CALL_REAL_NUMBER_TYPES(REGISTER_KERNELS);
^
10 warnings generated.
INFO: From Linking tensorflow/core/kernels/libconv_ops.lo:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib: file: bazel-out/darwin-opt/bin/tensorflow/core/kernels/libconv_ops.lo(conv_ops_using_gemm.o) has no symbols
INFO: From Compiling tensorflow/contrib/lite/toco/toco.cc:
In file included from tensorflow/contrib/lite/toco/toco.cc:20:
In file included from ./tensorflow/contrib/lite/toco/model.h:26:
In file included from ./tensorflow/contrib/lite/toco/runtime/types.h:18:
In file included from ./tensorflow/contrib/lite/kernels/internal/common.h:42:
external/arm_neon_2_x86_sse/NEON_2_SSE.h:4750:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
external/arm_neon_2_x86_sse/NEON_2_SSE.h:5431:27: warning: implicit conversion from 'int' to 'char' changes value from 128 to -128 [-Wconstant-conversion]
c128 = _mm_set1_epi8 (128);
~~~~~~~~~~~~~ ^~~
2 warnings generated.
INFO: From Compiling tensorflow/core/kernels/batch_kernels.cc:
tensorflow/core/kernels/batch_kernels.cc:979:10: warning: lambda capture 'this' is not used [-Wunused-lambda-capture]
[this](UnbatchGradResource** r) {
^
1 warning generated.
Target //tensorflow/contrib/lite/toco:toco up-to-date:
bazel-bin/tensorflow/contrib/lite/toco/toco
INFO: Elapsed time: 2814.103s, Critical Path: 164.73s
INFO: 2000 processes, local.
INFO: Build completed successfully, 2012 total actions
INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/Users/dchealth/Desktop/mobilenet/frozen_graph.pb' '--output_file=/Users/dchealth/Desktop/mobilenet/mobilenetnew.tflite' '--input_format=TENSORFLOW_GRAPHDEF' '--inference_type=FLOAT' '--output_format=TFLITE' '--input_type=FLOAT' '--input_shapes=1,224,224,3' '--input_arrays=input' '--output_arrays=MobilenetV1/PredINFO: Build completed successfully, 2012 total actions
2018-06-13 10:34:42.340286: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:251] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.
2018-06-13 10:34:42.460038: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 416 operators, 583 arrays (0 quantized)
2018-06-13 10:34:42.470369: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 416 operators, 583 arrays (0 quantized)
2018-06-13 10:34:42.507758: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 31 operators, 89 arrays (0 quantized)
2018-06-13 10:34:42.508374: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 31 operators, 89 arrays (0 quantized)
2018-06-13 10:34:42.508942: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 6422528 bytes, theoretical optimal value: 4816896 bytes.
2018-06-13 10:34:42.509181: I tensorflow/contrib/lite/toco/toco_tooling.cc:373] Estimated count of arithmetic ops: 1.14264 billion (note that a multiply-add is counted as 2 ops).
DCHealthdeMac-mini:toco dchealth$ --inference_type=QUANTIZED_UINT8
-bash: --inference_type=QUANTIZED_UINT8: command not found
DCHealthdeMac-mini:toco dchealth$ --std_values=128
-bash: --std_values=128: command not found
DCHealthdeMac-mini:toco dchealth$ --mean_values=128。"
19970,Install OSError: [Errno 13] Permission denied:,"I'm trying to install tensorflow on my ubuntu os. The configuration of my machine is ubuntu14.04LTS ,NVIDIA K40*8 gpu,cuda8.0 with cudnn6.0.First,I install with Virtualenv,I follow the instructions on **https://www.tensorflow.org/install/install_linux#installing_with_virtualenv** step by step,
but after the last step,I got the error:
_

> Exception:
> Traceback (most recent call last):
>   File ""/usr/lib/python2.7/dist-packages/pip/basecommand.py"", line 215, in main
>     status = self.run(options, args)
>   File ""/usr/lib/python2.7/dist-packages/pip/commands/install.py"", line 324, in run
>     requirement_set.prepare_files(finder)
>   File ""/usr/lib/python2.7/dist-packages/pip/req/req_set.py"", line 380, in prepare_files
>     ignore_dependencies=self.ignore_dependencies))
>   File ""/usr/lib/python2.7/dist-packages/pip/req/req_set.py"", line 554, in _prepare_file
>     require_hashes
>   File ""/usr/lib/python2.7/dist-packages/pip/req/req_install.py"", line 281, in populate_link
>     self.link = self._wheel_cache.cached_wheel(self.link, self.name)
>   File ""/usr/lib/python2.7/dist-packages/pip/wheel.py"", line 68, in cached_wheel
>     self._cache_dir, link, self._format_control, package_name)
>   File ""/usr/lib/python2.7/dist-packages/pip/wheel.py"", line 129, in cached_wheel
>     wheel_names = os.listdir(root)
> OSError: [Errno 13] Permission denied: '/home/cs/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6'

_
What's the matter?"
19969,"Is there a way to load a TF graph just once, and run it multiple times?","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 

Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Windows 10 Home, running TF on Colab and on VM on GCP.

- **TensorFlow installed from (source or binary)**: 

Binary
- **TensorFlow version (use command below)**:

1.8.0
- **Python version**: 

3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Tesla K80, 12 GB
- **Exact command to reproduce**:


### Describe the problem

I have a TF model that was saved with the tf.train.Saver class, and so I have the .meta file, the data-00000-of-00001 file, the index file and the checkpoint file.

I use it for inference like this :

```
    graph_num = tf.Graph()
    with graph_num.as_default():
        sess = tf.Session()
        with sess.as_default():

            new_saver = tf.train.import_meta_graph('{}.meta'.format(model_path), clear_devices=True)
            new_saver.restore(sess, ('{}'.format(model_path)))
            sess.run(tf.tables_initializer())

            arr_placeholder = graph_num.get_operation_by_name('arr_placeholder/inp_array').outputs[0]
            str_placeholder = graph_num.get_operation_by_name('str_placeholder/inp_string').outputs[0]
            dropout_keep_prob = graph_num.get_operation_by_name('dropout_keep_prob/keep_prob').outputs[0]

            logis = graph_num.get_tensor_by_name('logits/preds/BiasAdd:0')

            def model_api(input_data):
                # ...preprocessing the input_data...

                a = sess.run(tf.nn.softmax(logis),
                             feed_dict={
                                 arr_placeholder:
                                     np.array(list_of_primary_inputs).reshape(len(list_of_primary_inputs), 142),
                                 dropout_keep_prob: 1.0, str_placeholder: input_string
                             })

                return a
```

So far so good, but then I call the function like this: 

```
tf.reset_default_graph()
result = model_api(test_input_data)
```
and each time I call it, it gives me different results for the same test data.

But when I instantiate the graph again and then call the function, it gives me the same numbers.

This behaviour is rather odd, and I don't want to re load the graph every time I want to pass in a new instance(s).

I can't use a for loop within the session, because the instances to be predicted come in real time, and so I have to use a function that supports arguments.

I saw this post too : https://stackoverflow.com/questions/42124000/reuse-graph-and-use-it-multiple-times but that wasn't helping my case.

I tried freezing the graph ( converting the existing meta graph into .pb ) but that too was giving me an error with one of the lookup tables that I have. And that is filed as a separate issue on GitHub, and unfortunately the workaround mentioned there didn't work for me. That issue is still open : https://github.com/tensorflow/tensorflow/issues/8665

I have even set tf.set_random_seed to a constant value while training, and tried doing the same to the inference part as well, but to no avail.

So right now I'm at my wits end.


I have asked this question on SO ( https://stackoverflow.com/questions/50812641/load-a-tensorflow-graph-once-and-use-it-multiple-times ) too, but that hasn't been helpful.

Why does it give me different results each time? And is there a way to load the graph once, and then keep running new instances without running into this issue of inconsistent outputs?

I couldn't find such a query while researching on this topic, so if there is currently no way to load a graph and run it multiple times all the while producing consistent outputs, can this be considered a feature request?

"
19968,Error raised in renaming the chekpont files while converting tensorflow to tflite. an i/o error,"Error and logs:-
%run ""C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py""
[[ 70.   1.   4. ...,   2.   3.   3.]
 [ 67.   0.   3. ...,   2.   0.   7.]
 [ 57.   1.   2. ...,   1.   0.   7.]
 ..., 
 [ 56.   0.   2. ...,   2.   0.   3.]
 [ 57.   1.   4. ...,   2.   0.   6.]
 [ 67.   1.   4. ...,   2.   3.   3.]]
[2 1 2 1 1 1 2 2 2 2 1 1 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 2 2 2 2
 2 1 1 2 1 1 1 2 1 2 2 2 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 2 2 1 1 1
 1 2 1 1 1 1 2 2 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 1 1 1 2 1 2 2 2 1 2 2 1 2
 1 2 1 1 1 2 2 1 2 2 2 2 1 1 1 2 1 1 2 2 2 1 2 1 1 1 2 1 1 2 1 2 1 2 2 2 2
 2 1 1 1 1 1 1 1 2 1 1 2 2 2 1 2 1 1 1 1 1 2 1 2 2 1 1 2 2 2 2 1 1 2 2 1 1
 1 2 1 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2 2
 1 2 1 1 2 2 1 1 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 2 1 2 2 2 1 2 1 1 1 1 2 2
 1 1 2 2 1 2 1 1 1 1 2]
C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py:36: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=""relu"", input_dim=13, units=7, kernel_initializer=""uniform"")`
  model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu',input_dim =13))
C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py:37: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=""relu"", units=7, kernel_initializer=""uniform"")`
  model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu'))
C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=""sigmoid"", units=1, kernel_initializer=""uniform"")`
  model.add(Dense(output_dim = 1,init ='uniform',activation = 'sigmoid'))
Train on 216 samples, validate on 54 samples
Epoch 1/100
216/216 [==============================] - 2s 11ms/step - loss: 0.6799 - acc: 0.5509 - val_loss: 0.6642 - val_acc: 0.5741
Epoch 2/100
216/216 [==============================] - 0s 440us/step - loss: 0.6428 - acc: 0.5509 - val_loss: 0.6127 - val_acc: 0.5741
Epoch 3/100
216/216 [==============================] - 0s 468us/step - loss: 0.5682 - acc: 0.5509 - val_loss: 0.5131 - val_acc: 0.5741
Epoch 4/100
216/216 [==============================] - 0s 435us/step - loss: 0.4277 - acc: 0.5509 - val_loss: 0.3245 - val_acc: 0.5741
Epoch 5/100
216/216 [==============================] - 0s 491us/step - loss: 0.1722 - acc: 0.5509 - val_loss: 0.0395 - val_acc: 0.5741
Epoch 6/100
216/216 [==============================] - 0s 773us/step - loss: -0.1989 - acc: 0.5509 - val_loss: -0.3623 - val_acc: 0.5741
Epoch 7/100
216/216 [==============================] - 0s 699us/step - loss: -0.7056 - acc: 0.5509 - val_loss: -0.8693 - val_acc: 0.5741
Epoch 8/100
216/216 [==============================] - 0s 690us/step - loss: -1.3514 - acc: 0.5509 - val_loss: -1.5298 - val_acc: 0.5741
Epoch 9/100
216/216 [==============================] - 0s 722us/step - loss: -2.1595 - acc: 0.5509 - val_loss: -2.4054 - val_acc: 0.5741
Epoch 10/100
216/216 [==============================] - 0s 736us/step - loss: -3.2236 - acc: 0.5509 - val_loss: -3.4721 - val_acc: 0.5741
Epoch 11/100
216/216 [==============================] - 0s 727us/step - loss: -4.4167 - acc: 0.5509 - val_loss: -4.1341 - val_acc: 0.5741
Epoch 12/100
216/216 [==============================] - 0s 694us/step - loss: -5.1895 - acc: 0.5509 - val_loss: -4.5694 - val_acc: 0.5741
Epoch 13/100
216/216 [==============================] - 0s 778us/step - loss: -5.6066 - acc: 0.5509 - val_loss: -4.8527 - val_acc: 0.5741
Epoch 14/100
216/216 [==============================] - 0s 801us/step - loss: -5.8476 - acc: 0.5509 - val_loss: -5.0201 - val_acc: 0.5741
Epoch 15/100
216/216 [==============================] - 0s 833us/step - loss: -6.0103 - acc: 0.5509 - val_loss: -5.1307 - val_acc: 0.5741
Epoch 16/100
216/216 [==============================] - 0s 769us/step - loss: -6.1466 - acc: 0.5509 - val_loss: -5.2282 - val_acc: 0.5741
Epoch 17/100
216/216 [==============================] - 0s 838us/step - loss: -6.2473 - acc: 0.5509 - val_loss: -5.3047 - val_acc: 0.5741
Epoch 18/100
216/216 [==============================] - 0s 769us/step - loss: -6.3216 - acc: 0.5509 - val_loss: -5.3923 - val_acc: 0.5741
Epoch 19/100
216/216 [==============================] - 0s 495us/step - loss: -6.4006 - acc: 0.5509 - val_loss: -5.4703 - val_acc: 0.5741
Epoch 20/100
216/216 [==============================] - 0s 426us/step - loss: -6.4667 - acc: 0.5509 - val_loss: -5.5194 - val_acc: 0.5741
Epoch 21/100
216/216 [==============================] - 0s 421us/step - loss: -6.5198 - acc: 0.5509 - val_loss: -5.5850 - val_acc: 0.5741
Epoch 22/100
216/216 [==============================] - 0s 519us/step - loss: -6.5789 - acc: 0.5509 - val_loss: -5.6267 - val_acc: 0.5741
Epoch 23/100
216/216 [==============================] - 0s 764us/step - loss: -6.6248 - acc: 0.5509 - val_loss: -5.6667 - val_acc: 0.5741
Epoch 24/100
216/216 [==============================] - 0s 722us/step - loss: -6.6704 - acc: 0.5509 - val_loss: -5.7129 - val_acc: 0.5741
Epoch 25/100
216/216 [==============================] - 0s 713us/step - loss: -6.7225 - acc: 0.5509 - val_loss: -5.7570 - val_acc: 0.5741
Epoch 26/100
216/216 [==============================] - 0s 685us/step - loss: -6.7649 - acc: 0.5509 - val_loss: -5.7932 - val_acc: 0.5741
Epoch 27/100
216/216 [==============================] - 0s 699us/step - loss: -6.7995 - acc: 0.5509 - val_loss: -5.8360 - val_acc: 0.5741
Epoch 28/100
216/216 [==============================] - 0s 787us/step - loss: -6.8323 - acc: 0.5509 - val_loss: -5.8789 - val_acc: 0.5741
Epoch 29/100
216/216 [==============================] - 0s 769us/step - loss: -6.8675 - acc: 0.5509 - val_loss: -5.9081 - val_acc: 0.5741
Epoch 30/100
216/216 [==============================] - 0s 602us/step - loss: -6.8975 - acc: 0.5509 - val_loss: -5.9513 - val_acc: 0.5741
Epoch 31/100
216/216 [==============================] - 0s 639us/step - loss: -6.9255 - acc: 0.5509 - val_loss: -5.9945 - val_acc: 0.5741
Epoch 32/100
216/216 [==============================] - 0s 778us/step - loss: -6.9587 - acc: 0.5509 - val_loss: -6.0355 - val_acc: 0.5741
Epoch 33/100
216/216 [==============================] - 0s 773us/step - loss: -6.9862 - acc: 0.5509 - val_loss: -6.0792 - val_acc: 0.5741
Epoch 34/100
216/216 [==============================] - 0s 662us/step - loss: -7.0091 - acc: 0.5509 - val_loss: -6.1337 - val_acc: 0.5741
Epoch 35/100
216/216 [==============================] - 0s 653us/step - loss: -7.0404 - acc: 0.5509 - val_loss: -6.1758 - val_acc: 0.5741
Epoch 36/100
216/216 [==============================] - 0s 463us/step - loss: -7.0644 - acc: 0.5509 - val_loss: -6.2262 - val_acc: 0.5741
Epoch 37/100
216/216 [==============================] - 0s 454us/step - loss: -7.0898 - acc: 0.5509 - val_loss: -6.2752 - val_acc: 0.5741
Epoch 38/100
216/216 [==============================] - 0s 477us/step - loss: -7.1028 - acc: 0.5509 - val_loss: -6.3258 - val_acc: 0.5741
Epoch 39/100
216/216 [==============================] - 0s 468us/step - loss: -7.1160 - acc: 0.5509 - val_loss: -6.3659 - val_acc: 0.5741
Epoch 40/100
216/216 [==============================] - 0s 426us/step - loss: -7.1259 - acc: 0.5509 - val_loss: -6.4014 - val_acc: 0.5741
Epoch 41/100
216/216 [==============================] - 0s 426us/step - loss: -7.1340 - acc: 0.5509 - val_loss: -6.4243 - val_acc: 0.5741
Epoch 42/100
216/216 [==============================] - 0s 500us/step - loss: -7.1385 - acc: 0.5509 - val_loss: -6.4578 - val_acc: 0.5741
Epoch 43/100
216/216 [==============================] - 0s 727us/step - loss: -7.1431 - acc: 0.5509 - val_loss: -6.4915 - val_acc: 0.5741
Epoch 44/100
216/216 [==============================] - 0s 745us/step - loss: -7.1482 - acc: 0.5509 - val_loss: -6.5163 - val_acc: 0.5741
Epoch 45/100
216/216 [==============================] - 0s 708us/step - loss: -7.1525 - acc: 0.5509 - val_loss: -6.5387 - val_acc: 0.5741
Epoch 46/100
216/216 [==============================] - 0s 676us/step - loss: -7.1557 - acc: 0.5509 - val_loss: -6.5558 - val_acc: 0.5741
Epoch 47/100
216/216 [==============================] - 0s 769us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5746 - val_acc: 0.5741
Epoch 48/100
216/216 [==============================] - 0s 732us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5855 - val_acc: 0.5741
Epoch 49/100
216/216 [==============================] - 0s 745us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5863 - val_acc: 0.5741
Epoch 50/100
216/216 [==============================] - 0s 681us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741
Epoch 51/100
216/216 [==============================] - 0s 1ms/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741
Epoch 52/100
216/216 [==============================] - 0s 838us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741
Epoch 53/100
216/216 [==============================] - 0s 824us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5866 - val_acc: 0.5741
Epoch 54/100
216/216 [==============================] - 0s 704us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5868 - val_acc: 0.5741
Epoch 55/100
216/216 [==============================] - 0s 565us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5868 - val_acc: 0.5741
Epoch 56/100
216/216 [==============================] - 0s 500us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5868 - val_acc: 0.5741
Epoch 57/100
216/216 [==============================] - 0s 574us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5870 - val_acc: 0.5741
Epoch 58/100
216/216 [==============================] - 0s 556us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5870 - val_acc: 0.5741
Epoch 59/100
216/216 [==============================] - 0s 676us/step - loss: -7.1589 - acc: 0.5509 - val_loss: -6.5870 - val_acc: 0.5741
Epoch 60/100
216/216 [==============================] - 0s 514us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5872 - val_acc: 0.5741
Epoch 61/100
216/216 [==============================] - 0s 532us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5874 - val_acc: 0.5741
Epoch 62/100
216/216 [==============================] - 0s 565us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5874 - val_acc: 0.5741
Epoch 63/100
216/216 [==============================] - 0s 593us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5874 - val_acc: 0.5741
Epoch 64/100
216/216 [==============================] - 0s 611us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5877 - val_acc: 0.5741
Epoch 65/100
216/216 [==============================] - 0s 634us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5877 - val_acc: 0.5741
Epoch 66/100
216/216 [==============================] - 0s 657us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5877 - val_acc: 0.5741
Epoch 67/100
216/216 [==============================] - 0s 542us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5879 - val_acc: 0.5741
Epoch 68/100
216/216 [==============================] - 0s 528us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5879 - val_acc: 0.5741
Epoch 69/100
216/216 [==============================] - 0s 523us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5879 - val_acc: 0.5741
Epoch 70/100
216/216 [==============================] - 0s 796us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741
Epoch 71/100
216/216 [==============================] - 0s 653us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741
Epoch 72/100
216/216 [==============================] - 0s 676us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741
Epoch 73/100
216/216 [==============================] - 0s 644us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5881 - val_acc: 0.5741
Epoch 74/100
216/216 [==============================] - 0s 431us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5884 - val_acc: 0.5741
Epoch 75/100
216/216 [==============================] - 0s 417us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5884 - val_acc: 0.5741
Epoch 76/100
216/216 [==============================] - 0s 440us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5884 - val_acc: 0.5741
Epoch 77/100
216/216 [==============================] - 0s 468us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5886 - val_acc: 0.5741
Epoch 78/100
216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5886 - val_acc: 0.5741
Epoch 79/100
216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5888 - val_acc: 0.5741
Epoch 80/100
216/216 [==============================] - 0s 523us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5891 - val_acc: 0.5741
Epoch 81/100
216/216 [==============================] - 0s 482us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5891 - val_acc: 0.5741
Epoch 82/100
216/216 [==============================] - 0s 449us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5891 - val_acc: 0.5741
Epoch 83/100
216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5893 - val_acc: 0.5741
Epoch 84/100
216/216 [==============================] - 0s 426us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5893 - val_acc: 0.5741
Epoch 85/100
216/216 [==============================] - 0s 477us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5893 - val_acc: 0.5741
Epoch 86/100
216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5896 - val_acc: 0.5741
Epoch 87/100
216/216 [==============================] - 0s 454us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5896 - val_acc: 0.5741
Epoch 88/100
216/216 [==============================] - 0s 421us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5896 - val_acc: 0.5741
Epoch 89/100
216/216 [==============================] - 0s 745us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5898 - val_acc: 0.5741
Epoch 90/100
216/216 [==============================] - 0s 704us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5898 - val_acc: 0.5741
Epoch 91/100
216/216 [==============================] - 0s 801us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5898 - val_acc: 0.5741
Epoch 92/100
216/216 [==============================] - 0s 1ms/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5901 - val_acc: 0.5741
Epoch 93/100
216/216 [==============================] - 0s 843us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5901 - val_acc: 0.5741
Epoch 94/100
216/216 [==============================] - 0s 801us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5901 - val_acc: 0.5741
Epoch 95/100
216/216 [==============================] - 0s 690us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5906 - val_acc: 0.5741
Epoch 96/100
216/216 [==============================] - 0s 634us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5906 - val_acc: 0.5741
Epoch 97/100
216/216 [==============================] - 0s 542us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5906 - val_acc: 0.5741
Epoch 98/100
216/216 [==============================] - 0s 546us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5908 - val_acc: 0.5741
Epoch 99/100
216/216 [==============================] - 0s 546us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5908 - val_acc: 0.5741
Epoch 100/100
216/216 [==============================] - 0s 528us/step - loss: -7.1590 - acc: 0.5509 - val_loss: -6.5908 - val_acc: 0.5741
2018-06-13 10:25:20.269185: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1318] OP_REQUIRES failed at save_restore_v2_ops.cc:137 : Unknown: Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.
; Input/output error
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1321     try:
-> 1322       return fn(*args)
   1323     except errors.OpError as e:
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1306       return self._call_tf_sessionrun(
-> 1307           options, feed_dict, fetch_list, target_list, run_metadata)
   1308 
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1408           self._session, options, feed_dict, fetch_list, target_list,
-> 1409           run_metadata)
   1410     else:
UnknownError: Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.
; Input/output error
[[Node: save_7/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_7/Const_0_0, save_7/SaveV2/tensor_names, save_7/SaveV2/shape_and_slices, Adam/beta_1, Adam/beta_2, Adam/decay, Adam/iterations, Adam/lr, Adam_1/beta_1, Adam_1/beta_2, Adam_1/decay, Adam_1/iterations, Adam_1/lr, Adam_2/beta_1, Adam_2/beta_2, Adam_2/decay, Adam_2/iterations, Adam_2/lr, Adam_3/beta_1, Adam_3/beta_2, Adam_3/decay, Adam_3/iterations, Adam_3/lr, Adam_4/beta_1, Adam_4/beta_2, Adam_4/decay, Adam_4/iterations, Adam_4/lr, dense_1/bias, dense_1/kernel, dense_10/bias, dense_10/kernel, dense_11/bias, dense_11/kernel, dense_12/bias, dense_12/kernel, dense_13/bias, dense_13/kernel, dense_14/bias, dense_14/kernel, dense_15/bias, dense_15/kernel, dense_2/bias, dense_2/kernel, dense_3/bias, dense_3/kernel, dense_4/bias, dense_4/kernel, dense_5/bias, dense_5/kernel, dense_6/bias, dense_6/kernel, dense_7/bias, dense_7/kernel, dense_8/bias, dense_8/kernel, dense_9/bias, dense_9/kernel, training/Adam/Variable, training/Adam/Variable_1, training/Adam/Variable_10, training/Adam/Variable_11, training/Adam/Variable_12, training/Adam/Variable_13, training/Adam/Variable_14, training/Adam/Variable_15, training/Adam/Variable_16, training/Adam/Variable_17, training/Adam/Variable_2, training/Adam/Variable_3, training/Adam/Variable_4, training/Adam/Variable_5, training/Adam/Variable_6, training/Adam/Variable_7, training/Adam/Variable_8, training/Adam/Variable_9, training_1/Adam/Variable, training_1/Adam/Variable_1, training_1/Adam/Variable_10, training_1/Adam/Variable_11, training_1/Adam/Variable_12, training_1/Adam/Variable_13, training_1/Adam/Variable_14, training_1/Adam/Variable_15, training_1/Adam/Variable_16, training_1/Adam/Variable_17, training_1/Adam/Variable_2, training_1/Adam/Variable_3, training_1/Adam/Variable_4, training_1/Adam/Variable_5, training_1/Adam/Variable_6, training_1/Adam/Variable_7, training_1/Adam/Variable_8, training_1/Adam/Variable_9, training_2/Adam/Variable, training_2/Adam/Variable_1, training_2/Adam/Variable_10, training_2/Adam/Variable_11, training_2/Adam/Variable_12, training_2/Adam/Variable_13, training_2/Adam/Variable_14, training_2/Adam/Variable_15, training_2/Adam/Variable_16, training_2/Adam/Variable_17, training_2/Adam/Variable_2, training_2/Adam/Variable_3, training_2/Adam/Variable_4, training_2/Adam/Variable_5, training_2/Adam/Variable_6, training_2/Adam/Variable_7, training_2/Adam/Variable_8, training_2/Adam/Variable_9, training_3/Adam/Variable, training_3/Adam/Variable_1, training_3/Adam/Variable_10, training_3/Adam/Variable_11, training_3/Adam/Variable_12, training_3/Adam/Variable_13, training_3/Adam/Variable_14, training_3/Adam/Variable_15, training_3/Adam/Variable_16, training_3/Adam/Variable_17, training_3/Adam/Variable_2, training_3/Adam/Variable_3, training_3/Adam/Variable_4, training_3/Adam/Variable_5, training_3/Adam/Variable_6, training_3/Adam/Variable_7, training_3/Adam/Variable_8, training_3/Adam/Variable_9, training_4/Adam/Variable, training_4/Adam/Variable_1, training_4/Adam/Variable_10, training_4/Adam/Variable_11, training_4/Adam/Variable_12, training_4/Adam/Variable_13, training_4/Adam/Variable_14, training_4/Adam/Variable_15, training_4/Adam/Variable_16, training_4/Adam/Variable_17, training_4/Adam/Variable_2, training_4/Adam/Variable_3, training_4/Adam/Variable_4, training_4/Adam/Variable_5, training_4/Adam/Variable_6, training_4/Adam/Variable_7, training_4/Adam/Variable_8, training_4/Adam/Variable_9)]]

During handling of the above exception, another exception occurred:
UnknownError                              Traceback (most recent call last)
C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py in <module>()
     84 
     85 if __name__ == '__main__':
---> 86     main()

C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py in main()
     81     model = build_model()
     82     train(model, X_train, y_train, X_test, y_test)
---> 83     export_model(tf.train.Saver(), model, [""Age"",""Sex"",""ChestPain"",""BloodPressure"",""Cholestrol"",""Sugar"",""ExerciseSlope"",""Electrocardiographic"",""HeartRate"",""Exercise"",""Depression"",""MajorVessels"",""DefectType"",""Heartdisease"" ], ""Heartdisease"")
     84 
     85 if __name__ == '__main__':
C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py in export_model(saver, model, input_node_names, output_node_name)
     55         MODEL_NAME + '_graph.pbtxt')
     56 
---> 57     saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')
     58 
     59     freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py in save(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)
   1701           model_checkpoint_path = sess.run(
   1702               self.saver_def.save_tensor_name,
-> 1703               {self.saver_def.filename_tensor_name: checkpoint_file})
   1704 
   1705         model_checkpoint_path = compat.as_str(model_checkpoint_path)
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    898     try:
    899       result = self._run(None, fetches, feed_dict, options_ptr,
--> 900                          run_metadata_ptr)
    901       if run_metadata:
    902         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1133     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1134       results = self._do_run(handle, final_targets, final_fetches,
-> 1135                              feed_dict_tensor, options, run_metadata)
   1136     else:
   1137       results = []
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1314     if handle is None:
   1315       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1316                            run_metadata)
   1317     else:
   1318       return self._do_call(_prun_fn, handle, feeds, fetches)
C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1333         except KeyError:
   1334           pass
-> 1335       raise type(e)(node_def, op, message)
   1336 
   1337   def _extend_graph(self):
UnknownError: Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.
; Input/output error
[[Node: save_7/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_7/Const_0_0, save_7/SaveV2/tensor_names, save_7/SaveV2/shape_and_slices, Adam/beta_1, Adam/beta_2, Adam/decay, Adam/iterations, Adam/lr, Adam_1/beta_1, Adam_1/beta_2, Adam_1/decay, Adam_1/iterations, Adam_1/lr, Adam_2/beta_1, Adam_2/beta_2, Adam_2/decay, Adam_2/iterations, Adam_2/lr, Adam_3/beta_1, Adam_3/beta_2, Adam_3/decay, Adam_3/iterations, Adam_3/lr, Adam_4/beta_1, Adam_4/beta_2, Adam_4/decay, Adam_4/iterations, Adam_4/lr, dense_1/bias, dense_1/kernel, dense_10/bias, dense_10/kernel, dense_11/bias, dense_11/kernel, dense_12/bias, dense_12/kernel, dense_13/bias, dense_13/kernel, dense_14/bias, dense_14/kernel, dense_15/bias, dense_15/kernel, dense_2/bias, dense_2/kernel, dense_3/bias, dense_3/kernel, dense_4/bias, dense_4/kernel, dense_5/bias, dense_5/kernel, dense_6/bias, dense_6/kernel, dense_7/bias, dense_7/kernel, dense_8/bias, dense_8/kernel, dense_9/bias, dense_9/kernel, training/Adam/Variable, training/Adam/Variable_1, training/Adam/Variable_10, training/Adam/Variable_11, training/Adam/Variable_12, training/Adam/Variable_13, training/Adam/Variable_14, training/Adam/Variable_15, training/Adam/Variable_16, training/Adam/Variable_17, training/Adam/Variable_2, training/Adam/Variable_3, training/Adam/Variable_4, training/Adam/Variable_5, training/Adam/Variable_6, training/Adam/Variable_7, training/Adam/Variable_8, training/Adam/Variable_9, training_1/Adam/Variable, training_1/Adam/Variable_1, training_1/Adam/Variable_10, training_1/Adam/Variable_11, training_1/Adam/Variable_12, training_1/Adam/Variable_13, training_1/Adam/Variable_14, training_1/Adam/Variable_15, training_1/Adam/Variable_16, training_1/Adam/Variable_17, training_1/Adam/Variable_2, training_1/Adam/Variable_3, training_1/Adam/Variable_4, training_1/Adam/Variable_5, training_1/Adam/Variable_6, training_1/Adam/Variable_7, training_1/Adam/Variable_8, training_1/Adam/Variable_9, training_2/Adam/Variable, training_2/Adam/Variable_1, training_2/Adam/Variable_10, training_2/Adam/Variable_11, training_2/Adam/Variable_12, training_2/Adam/Variable_13, training_2/Adam/Variable_14, training_2/Adam/Variable_15, training_2/Adam/Variable_16, training_2/Adam/Variable_17, training_2/Adam/Variable_2, training_2/Adam/Variable_3, training_2/Adam/Variable_4, training_2/Adam/Variable_5, training_2/Adam/Variable_6, training_2/Adam/Variable_7, training_2/Adam/Variable_8, training_2/Adam/Variable_9, training_3/Adam/Variable, training_3/Adam/Variable_1, training_3/Adam/Variable_10, training_3/Adam/Variable_11, training_3/Adam/Variable_12, training_3/Adam/Variable_13, training_3/Adam/Variable_14, training_3/Adam/Variable_15, training_3/Adam/Variable_16, training_3/Adam/Variable_17, training_3/Adam/Variable_2, training_3/Adam/Variable_3, training_3/Adam/Variable_4, training_3/Adam/Variable_5, training_3/Adam/Variable_6, training_3/Adam/Variable_7, training_3/Adam/Variable_8, training_3/Adam/Variable_9, training_4/Adam/Variable, training_4/Adam/Variable_1, training_4/Adam/Variable_10, training_4/Adam/Variable_11, training_4/Adam/Variable_12, training_4/Adam/Variable_13, training_4/Adam/Variable_14, training_4/Adam/Variable_15, training_4/Adam/Variable_16, training_4/Adam/Variable_17, training_4/Adam/Variable_2, training_4/Adam/Variable_3, training_4/Adam/Variable_4, training_4/Adam/Variable_5, training_4/Adam/Variable_6, training_4/Adam/Variable_7, training_4/Adam/Variable_8, training_4/Adam/Variable_9)]]

Caused by op 'save_7/SaveV2', defined at:
  File ""<string>"", line 29, in <module>
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelapp.py"", line 484, in main
    app.start()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\zmq\eventloop\ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tornado\ioloop.py"", line 831, in start
    self._run_callback(callback)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tornado\ioloop.py"", line 604, in _run_callback
    ret = callback()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tornado\stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelbase.py"", line 258, in enter_eventloop
    self.eventloop(self)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\eventloops.py"", line 176, in loop_tk
    kernel.timer.start()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\eventloops.py"", line 173, in start
    self.app.mainloop()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\tkinter\__init__.py"", line 1131, in mainloop
    self.tk.mainloop(n)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\tkinter\__init__.py"", line 1550, in __call__
    return self.func(*args)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\tkinter\__init__.py"", line 596, in callit
    func(*args)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\eventloops.py"", line 168, in on_timer
    self.func()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelbase.py"", line 291, in do_one_iteration
    stream.flush(zmq.POLLIN, 1)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\zmq\eventloop\zmqstream.py"", line 352, in flush
    self._handle_recv()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tornado\stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\ipykernel\zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-10-c5b6ae558f44>"", line 1, in <module>
    get_ipython().magic('run ""C:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\tfl.py""')
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\interactiveshell.py"", line 2158, in magic
    return self.run_line_magic(magic_name, magic_arg_s)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\interactiveshell.py"", line 2079, in run_line_magic
    result = fn(*args,**kwargs)
  File ""<decorator-gen-58>"", line 2, in run
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\magic.py"", line 188, in <lambda>
    call = lambda f, *a, **k: f(*a, **k)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\magics\execution.py"", line 742, in run
    run()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\magics\execution.py"", line 728, in run
    exit_ignore=exit_ignore)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\pylabtools.py"", line 173, in mpl_execfile
    safe_execfile(fname,*where,**kw)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\core\interactiveshell.py"", line 2481, in safe_execfile
    self.compile if kw['shell_futures'] else None)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\IPython\utils\py3compat.py"", line 186, in execfile
    exec(compiler(f.read(), fname, 'exec'), glob, loc)
  File ""C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py"", line 86, in <module>
    main()
  File ""C:\Users\DELL\Desktop\iris\final_project\Machine Learning\tfl.py"", line 83, in main
    export_model(tf.train.Saver(), model, [""Age"",""Sex"",""ChestPain"",""BloodPressure"",""Cholestrol"",""Sugar"",""ExerciseSlope"",""Electrocardiographic"",""HeartRate"",""Exercise"",""Depression"",""MajorVessels"",""DefectType"",""Heartdisease"" ], ""Heartdisease"")
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py"", line 1338, in __init__
    self.build()
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py"", line 1347, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py"", line 1384, in _build
    build_save=build_save, build_restore=build_restore)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py"", line 832, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py"", line 350, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\training\saver.py"", line 266, in save_op
    tensors)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1800, in save_v2
    shape_and_slices=shape_and_slices, tensors=tensors, name=name)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\framework\ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""C:\Users\DELL\AppData\Local\Enthought\Canopy\edm\envs\User\lib\site-packages\tensorflow\python\framework\ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnknownError (see above for traceback): Failed to rename: out/heart_disease.chkp.index.tempstate1760485026856564713 to: out/heart_disease.chkp.index : Access is denied.
; Input/output error
[[Node: save_7/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_7/Const_0_0, save_7/SaveV2/tensor_names, save_7/SaveV2/shape_and_slices, Adam/beta_1, Adam/beta_2, Adam/decay, Adam/iterations, Adam/lr, Adam_1/beta_1, Adam_1/beta_2, Adam_1/decay, Adam_1/iterations, Adam_1/lr, Adam_2/beta_1, Adam_2/beta_2, Adam_2/decay, Adam_2/iterations, Adam_2/lr, Adam_3/beta_1, Adam_3/beta_2, Adam_3/decay, Adam_3/iterations, Adam_3/lr, Adam_4/beta_1, Adam_4/beta_2, Adam_4/decay, Adam_4/iterations, Adam_4/lr, dense_1/bias, dense_1/kernel, dense_10/bias, dense_10/kernel, dense_11/bias, dense_11/kernel, dense_12/bias, dense_12/kernel, dense_13/bias, dense_13/kernel, dense_14/bias, dense_14/kernel, dense_15/bias, dense_15/kernel, dense_2/bias, dense_2/kernel, dense_3/bias, dense_3/kernel, dense_4/bias, dense_4/kernel, dense_5/bias, dense_5/kernel, dense_6/bias, dense_6/kernel, dense_7/bias, dense_7/kernel, dense_8/bias, dense_8/kernel, dense_9/bias, dense_9/kernel, training/Adam/Variable, training/Adam/Variable_1, training/Adam/Variable_10, training/Adam/Variable_11, training/Adam/Variable_12, training/Adam/Variable_13, training/Adam/Variable_14, training/Adam/Variable_15, training/Adam/Variable_16, training/Adam/Variable_17, training/Adam/Variable_2, training/Adam/Variable_3, training/Adam/Variable_4, training/Adam/Variable_5, training/Adam/Variable_6, training/Adam/Variable_7, training/Adam/Variable_8, training/Adam/Variable_9, training_1/Adam/Variable, training_1/Adam/Variable_1, training_1/Adam/Variable_10, training_1/Adam/Variable_11, training_1/Adam/Variable_12, training_1/Adam/Variable_13, training_1/Adam/Variable_14, training_1/Adam/Variable_15, training_1/Adam/Variable_16, training_1/Adam/Variable_17, training_1/Adam/Variable_2, training_1/Adam/Variable_3, training_1/Adam/Variable_4, training_1/Adam/Variable_5, training_1/Adam/Variable_6, training_1/Adam/Variable_7, training_1/Adam/Variable_8, training_1/Adam/Variable_9, training_2/Adam/Variable, training_2/Adam/Variable_1, training_2/Adam/Variable_10, training_2/Adam/Variable_11, training_2/Adam/Variable_12, training_2/Adam/Variable_13, training_2/Adam/Variable_14, training_2/Adam/Variable_15, training_2/Adam/Variable_16, training_2/Adam/Variable_17, training_2/Adam/Variable_2, training_2/Adam/Variable_3, training_2/Adam/Variable_4, training_2/Adam/Variable_5, training_2/Adam/Variable_6, training_2/Adam/Variable_7, training_2/Adam/Variable_8, training_2/Adam/Variable_9, training_3/Adam/Variable, training_3/Adam/Variable_1, training_3/Adam/Variable_10, training_3/Adam/Variable_11, training_3/Adam/Variable_12, training_3/Adam/Variable_13, training_3/Adam/Variable_14, training_3/Adam/Variable_15, training_3/Adam/Variable_16, training_3/Adam/Variable_17, training_3/Adam/Variable_2, training_3/Adam/Variable_3, training_3/Adam/Variable_4, training_3/Adam/Variable_5, training_3/Adam/Variable_6, training_3/Adam/Variable_7, training_3/Adam/Variable_8, training_3/Adam/Variable_9, training_4/Adam/Variable, training_4/Adam/Variable_1, training_4/Adam/Variable_10, training_4/Adam/Variable_11, training_4/Adam/Variable_12, training_4/Adam/Variable_13, training_4/Adam/Variable_14, training_4/Adam/Variable_15, training_4/Adam/Variable_16, training_4/Adam/Variable_17, training_4/Adam/Variable_2, training_4/Adam/Variable_3, training_4/Adam/Variable_4, training_4/Adam/Variable_5, training_4/Adam/Variable_6, training_4/Adam/Variable_7, training_4/Adam/Variable_8, training_4/Adam/Variable_9)]] 





The code is:-





# -*- coding: utf-8 -*-
""""""
Created on Tue Jun 12 17:40:11 2018

@author: DELL
""""""
import os
import os.path as path
import pandas as pd
import keras
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from tensorflow.python.tools import freeze_graph
from tensorflow.python.tools import optimize_for_inference_lib
from keras import backend as K
MODEL_NAME = ""heart_disease""

def load_data():
    data = pd.read_csv('C:\\Users\\DELL\\Desktop\\iris\\final_project\\Machine Learning\\neew.csv')
    X = data.iloc[:,:-1].values
    y = data.iloc[:,13].values
    print(X)
    print(y)
    from sklearn.model_selection import train_test_split 
    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)
    
    from sklearn.preprocessing import StandardScaler
    sc_X =StandardScaler()
    X_train = sc_X.fit_transform(X_train)
    X_test = sc_X.transform(X_test)
    return X_train, y_train, X_test, y_test

def build_model():
    model = Sequential()
    model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu',input_dim =13))
    model.add(Dense(output_dim = 7,init ='uniform',activation = 'relu'))
    model.add(Dense(output_dim = 1,init ='uniform',activation = 'sigmoid'))
    return model

def train(model, X_train, y_train, X_test, y_test):
    model.compile(loss='binary_crossentropy', \
                  optimizer='adam', \
                  metrics=['accuracy'])

    model.fit(X_train, y_train, \
              batch_size=10, \
              epochs=100, \
              verbose=1, \
              validation_data=(X_test, y_test))
    
def export_model(saver, model, input_node_names, output_node_name):
    
    tf.train.write_graph(K.get_session().graph_def, 'out', \
        MODEL_NAME + '_graph.pbtxt')

    saver.save(K.get_session(), 'out/' + MODEL_NAME + '.chkp')

    freeze_graph.freeze_graph('out/' + MODEL_NAME + '_graph.pbtxt', None, \
        False, 'out/' + MODEL_NAME + '.chkp', output_node_name, \
        ""save/restore_all"", ""save/Const:0"", \
        'out/frozen_' + MODEL_NAME + '.pb', True, """")

    input_graph_def = tf.GraphDef()
    with tf.gfile.Open('out/frozen_' + MODEL_NAME + '.pb', ""rb"") as f:
        input_graph_def.ParseFromString(f.read())

    output_graph_def = optimize_for_inference_lib.optimize_for_inference(
            input_graph_def, input_node_names, [output_node_name],
            tf.float32.as_datatype_enum)

    with tf.gfile.FastGFile('out/opt_' + MODEL_NAME + '.pb', ""wb"") as f:
        f.write(output_graph_def.SerializeToString())

    print(""graph saved!"")
def main():
    if not path.exists('out'):
        os.mkdir('out')

    X_train, y_train, X_test, y_test = load_data()
    model = build_model()
    train(model, X_train, y_train, X_test, y_test)
    export_model(tf.train.Saver(), model, [""Age"",""Sex"",""ChestPain"",""BloodPressure"",""Cholestrol"",""Sugar"",""ExerciseSlope"",""Electrocardiographic"",""HeartRate"",""Exercise"",""Depression"",""MajorVessels"",""DefectType"",""Heartdisease"" ], ""Heartdisease"")
    
if __name__ == '__main__':
    main()




"
19967,"GPU OOM with Keras and Estimator, fine with Keras alone","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tensorflowGPU_1.7
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0/cuDNN7.0
- **GPU model and memory**:NVidia Titan X (Pascal) 12GB
- **Exact command to reproduce**:python TestKerasAndEstimator.py


### Describe the problem
I have developed a Keras model and used it successfully with only Keras train and evaluate calls. Now I would like to use the same model in an Estimator context using tf.keras.estimator.model_to_estimator.

It's quite a large model (3 LSTM layers with 100 units each, input dimension 598), but I can run it in the Keras-alone context with a batch_size up to 10.  However, with an Estimator, I get an OOM on the GPU even with a batch_size of 1.  If I reduce the sequence length (SEQ_LEN) from 24000 to 5000 however, it will run with an Estimator.

Here is the output log with Keras alone (USE_ESTIMATOR=False)
```
[Console output redirected to file:C:\Users\philip.LMS\git\GIT_RD_Python\Ch2018\ch2018_train\TestEstimator_20180612_2256_log.txt]
Using TensorFlow backend.
2018-06-12 22:57:11.753350: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-06-12 22:57:12.396391: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:03:00.0
totalMemory: 12.00GiB freeMemory: 9.93GiB
2018-06-12 22:57:12.624894: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found device 1 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:a1:00.0
totalMemory: 12.00GiB freeMemory: 9.93GiB
2018-06-12 22:57:12.625753: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0, 1
2018-06-12 22:57:17.075745: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-12 22:57:17.076181: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0 1 
2018-06-12 22:57:17.076457: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N N 
2018-06-12 22:57:17.076746: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 1:   N N 
2018-06-12 22:57:17.077336: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
2018-06-12 22:57:17.079930: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9619 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:a1:00.0, compute capability: 6.1)
Creating Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (10, 24000, 100)          279600    
_________________________________________________________________
batch_normalization_1 (Batch (10, 24000, 100)          400       
_________________________________________________________________
lstm_2 (LSTM)                (10, 24000, 100)          80400     
_________________________________________________________________
batch_normalization_2 (Batch (10, 24000, 100)          400       
_________________________________________________________________
lstm_3 (LSTM)                (10, 24000, 100)          80400     
_________________________________________________________________
batch_normalization_3 (Batch (10, 24000, 100)          400       
_________________________________________________________________
dense_1 (Dense)              (10, 24000, 3)            303       
=================================================================
Total params: 441,903
Trainable params: 441,303
Non-trainable params: 600
_________________________________________________________________
None
Epoch 1/2

10/20 [==============>...............] - ETA: 6:45 - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000
20/20 [==============================] - 904s 45s/step - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000
Epoch 2/2

10/20 [==============>...............] - ETA: 8:59 - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000
20/20 [==============================] - 1059s 53s/step - loss: 0.0000e+00 - acc: 1.0000 - weighted_acc: 1.0000

10/20 [==============>...............] - ETA: 43s
20/20 [==============================] - 86s 4s/step
```

And here is the output log with Keras and Estimator (USE_ESTIMATOR=True)

```
[Console output redirected to file:C:\Users\philip.LMS\git\GIT_RD_Python\Ch2018\ch2018_train\TestEstimator_20180612_2338_log.txt]
Creating Model
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (1, 24000, 100)           279600    
_________________________________________________________________
batch_normalization_1 (Batch (1, 24000, 100)           400       
_________________________________________________________________
lstm_2 (LSTM)                (1, 24000, 100)           80400     
_________________________________________________________________
batch_normalization_2 (Batch (1, 24000, 100)           400       
_________________________________________________________________
lstm_3 (LSTM)                (1, 24000, 100)           80400     
_________________________________________________________________
batch_normalization_3 (Batch (1, 24000, 100)           400       
_________________________________________________________________
dense_1 (Dense)              (1, 24000, 3)             303       
=================================================================
Total params: 441,903
Trainable params: 441,303
Non-trainable params: 600
_________________________________________________________________
None
2018-06-12 23:39:11.126586: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-06-12 23:39:11.751372: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:03:00.0
totalMemory: 12.00GiB freeMemory: 9.93GiB
2018-06-12 23:39:11.981018: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1344] Found device 1 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:a1:00.0
totalMemory: 12.00GiB freeMemory: 9.93GiB
2018-06-12 23:39:11.981905: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0, 1
2018-06-12 23:39:17.295319: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-12 23:39:17.295766: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0 1 
2018-06-12 23:39:17.296030: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N N 
2018-06-12 23:39:17.296314: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 1:   N N 
2018-06-12 23:39:17.296888: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
2018-06-12 23:39:17.299820: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9619 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:a1:00.0, compute capability: 6.1)
2018-06-12 23:39:17.644506: I T:\src\github\tensorflow\tensorflow\core\kernels\cuda_solvers.cc:159] Creating CudaSolver handles for stream 000001E5C8B53C10
<MapDataset shapes: (<unknown>, <unknown>), types: (tf.float32, tf.float32)>
Dataset point 1:
<MapDataset shapes: ((24000, 598), (24000, 3)), types: (tf.float32, tf.float32)>
Dataset point 2:
<MapDataset shapes: ((24000, 598), (24000, 3)), types: (tf.float32, tf.float32)>
Dataset point 3:
<RepeatDataset shapes: ((24000, 598), (24000, 3)), types: (tf.float32, tf.float32)>
Batch features
Tensor(""IteratorGetNext:0"", shape=(?, 24000, 598), dtype=float32, device=/device:CPU:0)
Batch labels
Tensor(""IteratorGetNext:1"", shape=(?, 24000, 3), dtype=float32, device=/device:CPU:0)
2018-06-12 23:39:26.545626: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1423] Adding visible gpu devices: 0, 1
2018-06-12 23:39:26.546174: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-12 23:39:26.546739: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:917]      0 1 
2018-06-12 23:39:26.547090: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 0:   N N 
2018-06-12 23:39:26.547462: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:930] 1:   N N 
2018-06-12 23:39:26.548091: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9618 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)
2018-06-12 23:39:26.549907: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9619 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:a1:00.0, compute capability: 6.1)
Input File:
b'record_0'
Decoded File:
record_0
Features:
[[ 0.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]
 ..., 
 [ 0.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]
 [ 0.  0.  0. ...,  0.  0.  0.]]
Labels:
[[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]
 ..., 
 [ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0.  0.]]
2018-06-12 23:40:47.905054: E T:\src\github\tensorflow\tensorflow\stream_executor\cuda\cuda_driver.cc:967] failed to alloc 4294967296 bytes on host: CUDA_ERROR_OUT_OF_MEMORY
2018-06-12 23:40:47.905614: W T:\src\github\tensorflow\tensorflow/core/common_runtime/gpu/pool_allocator.h:195] could not allocate pinned host memory of size: 4294967296
2018-06-12 23:40:47.906068: E 
...
```

Here is the python test file TestKerasAndEstimator.py:
```
import sys

import numpy as np
import tensorflow as tf

USE_ESTIMATOR = True
#USE_ESTIMATOR = False

if USE_ESTIMATOR:
  from tensorflow.python import keras
  from tensorflow.python.keras.models import Sequential
  from tensorflow.python.keras.layers import Dense, LSTM, BatchNormalization
  from tensorflow.python.keras.optimizers import SGD, RMSprop
  N_RECORDS = 1
  BATCH_SIZE = 1
else:
  import keras
  import keras.backend.tensorflow_backend as K
  from keras.models import Sequential
  from keras.layers import Dense, LSTM, BatchNormalization
  from keras.optimizers import SGD, RMSprop
  N_RECORDS = 20
  BATCH_SIZE = 10

#SEQ_LENGTH=1000
#SEQ_LENGTH=5000
#SEQ_LENGTH=10000
SEQ_LENGTH=24000

INPUT_DIM = 598
OUTPUT_DIM = 3

NP_DTYPE = np.float32
TF_DTYPE = tf.float32
  
TRAIN_EPOCHS = 2
DEVICE_ID = '/gpu:0'

class ModelLSTM():
  def __init__(self, batch_size, max_length=None, device_id='/cpu:0', n_input_dim=1, n_output_dim=2):  
    
    self.batch_size = batch_size
    self.max_length = max_length
    self.device_id = device_id
    self.n_input_dim = n_input_dim
    self.n_output_dim = n_output_dim

    self.lstm_n_cell=[100, 100, 100] 
    self.dropout=0.1 
    self.recurrent_dropout=0.1
    
    self.create_model()
        
  def create_model(self):        
      
    with tf.device(self.device_id):
    
      print('Creating Model')
      model = Sequential()
      model.add(LSTM(self.lstm_n_cell[0],
                      return_sequences=True,
                      stateful=False,
                      kernel_initializer='he_normal',
                      activation='tanh',
                      dropout = self.dropout, 
                      recurrent_dropout = self.recurrent_dropout,
                      batch_input_shape=(self.batch_size, self.max_length, self.n_input_dim)))
      model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, 
                                   scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))
      model.add(LSTM(self.lstm_n_cell[1],
                     return_sequences=True,
                     stateful=False,
                     kernel_initializer='he_normal',
                      activation='tanh',
                      dropout = self.dropout, 
                      recurrent_dropout = self.recurrent_dropout))
      model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, 
                                   scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))
      model.add(LSTM(self.lstm_n_cell[2],
                     return_sequences=True,
                     stateful=False,
                     kernel_initializer='he_normal',
                      activation='tanh',
                      dropout = self.dropout, 
                      recurrent_dropout = self.recurrent_dropout))
      model.add(BatchNormalization(momentum=0.99, epsilon=0.001, center=True, 
                                   scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones'))
       
      model.add(Dense(self.n_output_dim, kernel_initializer='he_normal',
                                      activation='softmax')) 
      
      print (model.summary())
      
      opt = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)
  
      model.compile(loss='categorical_crossentropy',
                    optimizer=opt,
                    metrics=['accuracy'],
                    weighted_metrics=['accuracy'],
                    sample_weight_mode='temporal')
    
    self.model = model
    return self
  
  
class TestKerasAndEstimator():
  def __init__(self):
    self.device_id = DEVICE_ID
      
  def set_device(self, id):
    self.device_id = id
          
  def the_input_fn(self, filenames, perform_shuffle=False, repeat_count=1, batch_size=1):
    def _set_shapes(features, labels):
      features.set_shape([SEQ_LENGTH, 598])
      labels.set_shape([SEQ_LENGTH, 3])
      return features, labels

    def _my_parse_function(filename, label=None):
      
      print('Input File:')
      print(filename)
      
      dec_filename = filename.decode(sys.getdefaultencoding())
      print('Decoded File:')
      print(dec_filename)
      
      features = np.zeros((SEQ_LENGTH, INPUT_DIM), dtype=NP_DTYPE)
      labels = np.zeros((SEQ_LENGTH, OUTPUT_DIM), dtype=NP_DTYPE)

      print('Features:')
      print(features)
      print('Labels:')
      print(labels)
      
      return features, labels 
      
     
    labels = [0]*len(filenames)
    labels = np.array(labels)
    labels = tf.constant(labels)
    labels = tf.cast(labels, TF_DTYPE)
    
    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))  
    
    dataset = dataset.map(
      lambda filename, label: tuple(tf.py_func(
        _my_parse_function, [filename, label], [TF_DTYPE, label.dtype])))
    
    print(dataset)

    dataset = dataset.map(_set_shapes)
    
    print(""Dataset point 1:"")
    print(dataset)
    
    if perform_shuffle:
        dataset = dataset.shuffle(buffer_size=batch_size)
    print(""Dataset point 2:"")
    print(dataset)
    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times
    print(""Dataset point 3:"")
    print(dataset)
    dataset = dataset.batch(batch_size)  # Batch size to use
    the_iterator = dataset.make_one_shot_iterator()    
    batch_features, batch_labels = the_iterator.get_next()
    print('Batch features') 
    print(batch_features) 
    print('Batch labels') 
    print(batch_labels) 
    return batch_features, batch_labels
  
  def test_keras_estimator(self, n_records=1, batch_size=1):
    gpu_options = tf.GPUOptions(allow_growth=True) 
    sess_config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=False)        
    run_config = tf.estimator.RunConfig(session_config=sess_config)   
    
    train_model = ModelLSTM(batch_size=batch_size, max_length=SEQ_LENGTH, device_id=self.device_id, 
                            n_input_dim=INPUT_DIM, n_output_dim=OUTPUT_DIM)
    self.estimator = tf.keras.estimator.model_to_estimator(keras_model=train_model.model,
                                                           model_dir='.', config=run_config)
    train_records = list()
    for i in range(0, n_records):
      train_records.append('record_' + str(i))
      
    train_spec = tf.estimator.TrainSpec(input_fn=lambda: 
                                        self.the_input_fn(train_records, perform_shuffle=False, batch_size=batch_size), 
                                        max_steps=TRAIN_EPOCHS)
    eval_spec = tf.estimator.EvalSpec(input_fn=lambda: 
                                        self.the_input_fn(train_records, perform_shuffle=False, batch_size=batch_size))

    tf.estimator.train_and_evaluate(self.estimator, train_spec, eval_spec)
    
     
  def test_keras(self, n_records=1, batch_size=1):
    gpu_options = tf.GPUOptions(allow_growth=True) 
    sess_config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True, log_device_placement=False)        
    K.set_session(tf.Session(config=sess_config))
      
    train_model = ModelLSTM(batch_size=batch_size, max_length=SEQ_LENGTH, device_id=self.device_id, 
                            n_input_dim=INPUT_DIM, n_output_dim=OUTPUT_DIM)
    features = np.zeros((n_records, SEQ_LENGTH, INPUT_DIM), dtype=NP_DTYPE)
    labels = np.zeros((n_records, SEQ_LENGTH, OUTPUT_DIM), dtype=NP_DTYPE)

    train_model.model.fit(x=features, y=labels, batch_size=batch_size, epochs=TRAIN_EPOCHS, verbose=1)
    train_model.model.evaluate(x=features, y=labels, batch_size=batch_size, verbose=1)    
     
     
     
if __name__ == ""__main__"":
  mt = TestKerasAndEstimator()
  if USE_ESTIMATOR:
      mt.test_keras_estimator(n_records=N_RECORDS, batch_size=BATCH_SIZE)
  else:
      mt.test_keras(n_records=N_RECORDS, batch_size=BATCH_SIZE)

    
  
```
Thanks!"
19965,[feature request] Quasi recurrent neural networks (QRNN) in tensorflow ,"It would be cool to have native Quasi recurrent neural networks (QRNN) implementation included in the tensorflow package.

Following is the paper : Bradbury, James, et al. ""Quasi-recurrent neural networks."" arXiv preprint arXiv:1611.01576 (2016). [link](https://arxiv.org/pdf/1611.01576)
It is claimed in the paper that QRNN is 14-16x faster than cudnn_lstm while giving same accuracies.

reference : https://github.com/salesforce/pytorch-qrnn


**System information**
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.8.0
Python version: 3.6.5
Bazel version (if compiling from source): none
GCC/Compiler version (if compiling from source): none
CUDA/cuDNN version: none
GPU model and memory: none
Exact command to reproduce: none"
19962,object detection API: tf profiler incompatible shape,"I was trying to add profiler to the existing tensorflow object detection API, the following part of code is added to https://github.com/tensorflow/tensorflow/blob/dfa0f87e333c63277b7916a8ac4c56bf61daf1ac/tensorflow/contrib/slim/python/slim/learning.py#L489

```
  if run_metadata is not None:
    logging.info('Added profiling by User')
    ProfileOptionBuilder = profiler.ProfileOptionBuilder
    opts = ProfileOptionBuilder(ProfileOptionBuilder.time_and_memory()).with_step(np_global_step).with_timeline_output(train_step_kwargs['logdir']+'/profile.json').build()
    logging.info(train_step_kwargs['logdir']+'/profile.json')
    profiler.profile(
        ops.get_default_graph(),
        run_meta=run_metadata,
        cmd='graph',
        options=opts)
```
but when I was trying to run the training for resnet_101_coco with no other changes, the training progress with no error, but the profiler output incompatible shapes:
```
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 300, 453) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 300, 453) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 300, 453) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/pool1/MaxPool incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_1/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_2/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/shortcut/MaxPool incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 150, 227) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/Pad incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 152, 229) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 64) and (2, 64, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block1/unit_3/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 256) and (2, 256, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_1/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_2/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/Relu incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/Conv2D incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/add incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_3/bottleneck_v1/Relu incompatible shapes: Shapes (2, ?, ?, 512) and (2, 512, 75, 114) are not compatible.
Node clone_3/FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/Conv2D incompatible shapes: Shapes (2, ?, ?, 128) and (2, 128, 75, 114) are not compatible.
Node 
```
"
19961,compute_output_shape() Not Working For Custom Layer,"I have created a custom layer (called GraphGather) in Keras, yet the output tensor prints as :
>Tensor(""graph_gather/Tanh:0"", shape=(?, ?), dtype=float32)

For some reason the shape is being returned as (?,?), which is causing the next dense layer to raise the following error:
>ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.

The GraphGather layer code is as follows:
```python
class GraphGather(tf.keras.layers.Layer):

  def __init__(self, batch_size, num_mols_in_batch, activation_fn=None, **kwargs):
    self.batch_size = batch_size
    self.num_mols_in_batch = num_mols_in_batch
    self.activation_fn = activation_fn
    super(GraphGather, self).__init__(**kwargs)

  def build(self, input_shape):
    super(GraphGather, self).build(input_shape)

 def call(self, x, **kwargs):
    # some operations (most of def call omitted)
    out_tensor = result_of_operations() # this line is pseudo code
    if self.activation_fn is not None:
      out_tensor = self.activation_fn(out_tensor)
    out_tensor = out_tensor
    return out_tensor

  def compute_output_shape(self, input_shape):
    return (self.num_mols_in_batch, 2 * input_shape[0][-1])
```
I have also tried hardcoding compute_output_shape to be:
```python
def compute_output_shape(self, input_shape):
    return (64, 150)
```
Yet the output tensor when printed is still 
>Tensor(""graph_gather/Tanh:0"", shape=(?, ?), dtype=float32)

which causes the ValueError written above. 

------------------------

### System information
- Have written custom code
- **OS Platform and Distribution*:  Linux Ubuntu 16.04
- **TensorFlow version (use command below)**: 1.5.0
- **Python version**: 3.5.5
"
19959,"Evaluate network first, and then apply gradients","Dear TensorFlow team,

I believe I have hit a limitation of TensorFlow and was wondering if you (or the community) could assist me. I am trying to initialize a graph with a topology from the paper seen here: https://arxiv.org/abs/1708.06686. In this paper, one splits an image into tiles (which can overlap) and has some sort of network for each tile. The output of each network is then summed to obtain an output. The problem is when you split the image into many tiles, the computational graph becomes very large and one will often run out of memory. In this topology the network is shared across all tiles. For inference, one never hits a memory problem, because one can evaluate the value of each tile one by one. This is where I am having an issue. I cannot seem to define gradients properly if I first evaluate the tiles one by one. The way that TensorFlow is currently set up, I have to define the full computational graph to get the correct gradients. Is there a way I could evaluate the tiles first, and then apply gradients afterwards?

OS Platform and Distribution: MacOS
TensorFlow installed from: TensorFlow 
TensorFlow version: 1.8
Bazel version: Unknown
CUDA/cuDNN version: N/A (this experiment was ran on CPU)
GPU model and memory: N/A
Exact command to reproduce: https://anaconda.org/kryczko/untitled3/notebook"
19958,Support init_from_checkpoint and warm start with Distribution Strategy ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Reporting issues raise in this stackoverflow question:
https://stackoverflow.com/questions/50758110/warm-start-with-distribute-mirroredstrategy-and-tf-estimator:
1.  tf.train.init_from_checkpoint doesn't work well with MirroredStrategy
2. tf.estimator.WarmStartSettings with Estimator doesn't work with MirroredStrategy 


### Source code / logs
See code snippets and error messages in this stack overflow page:
https://stackoverflow.com/questions/50758110/warm-start-with-distribute-mirroredstrategy-and-tf-estimator

The root cause is that we haven't modified these 2 paths for restoring from checkpoints to work with mirrored variables. So we need to do 2 things:
1. Use the appropriate method to restore mirrored variables in these codepaths - either via distribution.update or by using Saver (see Allen's suggestion below). 
2. if the restoring is happening in tower context(for e.g. when init_from_checkpoint is called in model_fn), then we may need to first enter cross tower context before restoring. 

Suggestion for addressing #1 from @allenlavoie :
Do the same [SaveableObject extraction as Saver](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L531) in warm_start, then just call SaveableObject.restore() with the Tensor instead of using .assign. This will work for MirroredVariables and whatever else is checkpointable (and means that to work with both, new objects only need to do the checkpointable thing). Potentially we could just call [SaveableObjectsForOp](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L573) for everything including variables.

"
19957,tf.dynamic_partition cannot have dynamic num_partitions,"I am attempting to use `tf.dynamic_partition` as so:
`tf.dynamic_partition(features, membership, tf.reduce_max(membership))`
Unfortunately, however, it is throwing this error
>TypeError: Expected int for argument 'num_partitions' not <tf.Tensor 'Max:0' shape=() dtype=int32>.

Can `tf.dynamic_partition` not receive a dynamic input for num_partitions? "
19956,Problems while compiling lite on arm64,"Hello everyone! I'm encountering this error compiling tensorflow r1.9 (which can help to the official release):
```
                                                     ^
ERROR: /home/nvidia/src/tensorflow/tensorflow/contrib/lite/kernels/BUILD:128:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels:builtin_ops' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /home/nvidia/.cache/bazel/_bazel_nvidia/a3a3883903ac5bbe9db32b5447dc16d6/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64: \
    PATH=/usr/local/cuda/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TENSORRT_INSTALL_PATH=/usr/lib/aarch64-linux-gnu \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=6.2 \
    TF_CUDA_VERSION=9.0 \
    TF_CUDNN_VERSION=7 \
    TF_NCCL_VERSION=1 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL_SYCL=0 \
    TF_TENSORRT_VERSION=4.0.4 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/_objs/builtin_ops/tensorflow/contrib/lite/kernels/depthwise_conv.pic.d '-frandom-seed=bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/_objs/builtin_ops/tensorflow/contrib/lite/kernels/depthwise_conv.pic.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/arm-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/arm-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/arm-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/arm-opt/genfiles/external/local_config_sycl -iquote external/gemmlowp -iquote bazel-out/arm-opt/genfiles/external/gemmlowp -iquote external/flatbuffers -iquote bazel-out/arm-opt/genfiles/external/flatbuffers -iquote external/fft2d -iquote bazel-out/arm-opt/genfiles/external/fft2d -iquote external/arm_neon_2_x86_sse -iquote bazel-out/arm-opt/genfiles/external/arm_neon_2_x86_sse -iquote external/farmhash_archive -iquote bazel-out/arm-opt/genfiles/external/farmhash_archive -isystem external/eigen_archive -isystem bazel-out/arm-opt/genfiles/external/eigen_archive -isystem bazel-out/arm-opt/bin/external/eigen_archive -isystem tensorflow/contrib/lite/schema -isystem bazel-out/arm-opt/genfiles/tensorflow/contrib/lite/schema -isystem bazel-out/arm-opt/bin/tensorflow/contrib/lite/schema -isystem external/flatbuffers/include -isystem bazel-out/arm-opt/genfiles/external/flatbuffers/include -isystem bazel-out/arm-opt/bin/external/flatbuffers/include -isystem external/farmhash_archive/src -isystem bazel-out/arm-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/arm-opt/bin/external/farmhash_archive/src '-std=c++11' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections '-march=native' -DFARMHASH_NO_CXX_STRING '-Wno-error=reorder' -c tensorflow/contrib/lite/kernels/depthwise_conv.cc -o bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/_objs/builtin_ops/tensorflow/contrib/lite/kernels/depthwise_conv.pic.o)
In file included from ./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8.h:21:0,
                 from tensorflow/contrib/lite/kernels/depthwise_conv.cc:26:
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:80:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, input_depth) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:80:45: error: 'input_depth' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_depth) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:80:56: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_depth) ==
                                                        ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:82:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, input_row_size) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:82:45: error: 'input_row_size' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_row_size) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:82:59: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_row_size) ==
                                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:84:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_depth) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:84:45: error: 'output_depth' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_depth) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:84:57: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_depth) ==
                                                         ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:86:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_row_size) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:86:45: error: 'output_row_size' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_row_size) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:86:60: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_row_size) ==
                                                            ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:88:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, input_offset) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:88:45: error: 'input_offset' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_offset) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:88:57: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_offset) ==
                                                         ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:90:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_offset) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:90:45: error: 'output_offset' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_offset) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:90:58: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_offset) ==
                                                          ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:92:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, filter_offset) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:92:45: error: 'filter_offset' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, filter_offset) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:92:58: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, filter_offset) ==
                                                          ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:94:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_multiplier) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:94:45: error: 'output_multiplier' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_multiplier) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:94:62: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_multiplier) ==
                                                              ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:96:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_activation_min) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:96:45: error: 'output_activation_min' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_activation_min) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:96:66: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_activation_min) ==
                                                                  ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:98:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_activation_max) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:98:45: error: 'output_activation_max' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_activation_max) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:98:66: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_activation_max) ==
                                                                  ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:100:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_shift) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:100:45: error: 'output_shift' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_shift) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:100:57: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_shift) ==
                                                         ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:102:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, input_width) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:102:45: error: 'input_width' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_width) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:102:56: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_width) ==
                                                        ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:104:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, input_height) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:104:45: error: 'input_height' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_height) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:104:57: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, input_height) ==
                                                         ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:106:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_width) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:106:45: error: 'output_width' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_width) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:106:57: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_width) ==
                                                         ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:108:43: error: expected primary-expression before ',' token
 static_assert(offsetof(DepthwiseConvParams, output_height) ==
                                           ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:108:45: error: 'output_height' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_height) ==
                                             ^
./tensorflow/contrib/lite/kernels/internal/optimized/depthwiseconv_uint8_3x3_filter.h:108:58: error: 'offsetof' was not declared in this scope
 static_assert(offsetof(DepthwiseConvParams, output_height) ==
                                                          ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 5672.830s, Critical Path: 357.47s
INFO: 2837 processes, local.
FAILED: Build did NOT complete successfully
```

I had no problem compiling 1.8, it seems that something was broken in that branch. Any solution ?"
19955,(tensorboard) TypeError: __new__() got an unexpected keyword argument 'file',"# System information

    Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
    Yes
    OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
    Windows 10
    TensorFlow installed from (source or binary):
    binary
    TensorFlow version (use command below):
    1.8.0
    Python version:
    3.5
    Bazel version (if compiling from source):
    GCC/Compiler version (if compiling from source):
    CUDA/cuDNN version:
    9.0/7.2
    GPU model and memory:
    Nvidia
    Exact command to reproduce:
     tensorboard --logdir=""C:\Users\isultan\PycharmProjects\deep-shading\logs""`

# Describe the problem

Calling tensorboard with an argument for the directory of logs from Anaconda prompt causes a type error. Logs where produced in tf.keras with tensorboard callback `model_tb = TensorBoard(log_dir='./logs', write_graph=True)` passed to `model.fit_generator`. 

# Source code / logs

`(tf) C:\Users\isultan> tensorboard --logdir=""C:\Users\isultan\PycharmProjects\deep-shading\logs""`

Traceback (most recent call last):
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\isultan\AppData\Local\Continuum\miniconda3\envs\tf\Scripts\tensorboard.exe\__main__.py"", line 5, in <module>
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\site-packages\tensorboard\main.py"", line 30, in <module>
    from tensorboard import default
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\site-packages\tensorboard\default.py"", line 35, in <module>
    from tensorboard.plugins.audio import audio_plugin
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\site-packages\tensorboard\plugins\audio\audio_plugin.py"", line 30, in <module>
    from tensorboard.plugins.audio import metadata
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\site-packages\tensorboard\plugins\audio\metadata.py"", line 22, in <module>
    from tensorboard.plugins.audio import plugin_data_pb2
  File ""c:\users\isultan\appdata\local\continuum\miniconda3\envs\tf\lib\site-packages\tensorboard\plugins\audio\plugin_data_pb2.py"", line 63, in <module>
    options=None, file=DESCRIPTOR),
TypeError: __new__() got an unexpected keyword argument 'file'
``"
19954,"Support compression_type for tf.contrib.data.make_csv_dataset, CsvDataset","Currently `TFRecordDataset` and `TextLineDataset` support `compression_type` for reading compressed CSV/Tfrecords files. However the newer `make_csv_dataset` and `CsvDataset` do not support compression_type. Request tou to support the `compression_type` feature.
"
19952,tf.data.Dataset.shard_and_drop_remainder?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
      - yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
       - v.1.8.0
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I'm curious if there's anyway to accomplish a function like Dataset.shard_and_drop_remainder(num_shards, index) with the current machinery? If not, then I guess this is a feature request. The use case I have is, I'm training an RNN model with horovod and I've decided to bucket my variable length sequences, then batch them, and then shard to the number of workers, but I have no idea if there are enough batches at all my workers to perform an allreduce, which results in horovod complaining and failing in the allreduce. Ideally I would like the dataset to take ""num_shards"" and use that to check whether I have enough elements in the dataset to carry out another global step.

The solution I've come up with now is to iterate once to count the number of batches and then use Dataset.take((num_batches//num_workers)*num_workers) to ensure the number of batches is divisible by the number of workers. 
"
19951,Bazel Build transform_graph failing to find inputs/outputs ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX HS 10.13.4
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 3.65
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: Tesla V100 16g x2

### Describe The Problem
Using retrained Inception V3 model.
I have used the exact scripts from the docs to fold the graph and optimize for mobile, yet it keeps failing. I ran `./configure` and built the `transform_graph` function as specified. Running the function with:
```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=/path/frozen.pb \
--out_graph=/path/optimized.pb \
--inputs=“input” \
--outputs=“new_output_layer/probability” \
--transforms='
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms'
```
gives the error: `Input node ‘new_output_layer/probability’ not found in graph` (full trace below) even though I know I specified the tensor names correctly. For some reason it seems to be looking for an input node under my output node's name even though the output node's name is rightly under `--outputs`. Inspecting the graph with `bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=/path/frozen.pb` gives:
```
Found 1 possible inputs: (name=input, type=float(1), shape=[?,299,299,3]) 
No variables spotted.
Found 1 possible outputs: (name=new_output_layer/probability, op=Softmax) 
Found 21826166 (21.83M) const parameters, 0 (0) variable parameters, and 191 control_edges
```
confirming that my names are correct. 

### Full Logs/Code
Inspect_graph:
`$ bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=/Users/manc568/Documents/projects/tf-threeclass/pbdir/frozen.pb`
```
Found 1 possible inputs: (name=input, type=float(1), shape=[?,299,299,3]) 
No variables spotted.
Found 1 possible outputs: (name=new_output_layer/probability, op=Softmax) 
Found 21826166 (21.83M) const parameters, 0 (0) variable parameters, and 191 control_edges
Op types used: 849 Switch, 679 Const, 569 Identity, 188 FusedBatchNorm, 95 Merge, 94 Conv2D, 94 Relu, 15 ConcatV2, 10 AvgPool, 4 MaxPool, 2 Add, 2 Mul, 1 BiasAdd, 1 Placeholder, 1 MatMul, 1 RandomUniform, 1 RealDiv, 1 Floor, 1 Shape, 1 Softmax, 1 Squeeze, 1 Sub, 1 PlaceholderWithDefault
To use with tensorflow/tools/benchmark:benchmark_model try these arguments:
bazel run tensorflow/tools/benchmark:benchmark_model -- --graph=/Users/manc568/Documents/projects/tf-threeclass/pbdir/frozen.pb --show_flops --input_layer=input --input_layer_type=float --input_layer_shape=-1,299,299,3 --output_layer=new_output_layer/probability
```
Transform_graph:
```
$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=/Users/manc568/Documents/projects/tf-threeclass/pbdir/frozen.pb \
--out_graph=/Users/manc568/Documents/projects/tf-threeclass/pbdir/optimized_inception_graph.pb \
--inputs=“input” \
--outputs=“new_output_layer/probability” \
--transforms='
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights' 
```
```
2018-06-12 11:38:14.293873: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying strip_unused_nodes
2018-06-12 11:38:14.297407: E tensorflow/tools/graph_transforms/transform_graph.cc:264] Input node “new_output_layer/probability” not found in graph
```"
19949,toco error when converting tensorflow (Alexnet caffe model converted to tensorflow using MMdnn) to tflite,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS High Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.1
- **Python version**: 2.7.15
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.1.0 (clang-902.0.39.2)
- **CUDA/cuDNN version**: No
- **GPU model and memory**:No 
- **Exact command to reproduce**: toco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3

Hi,

I have a caffe model (Retrained Alexnet), converted this into tensorflow model using following commands. (https://github.com/Microsoft/MMdnn/issues/10)

```python -m mmdnn.conversion._script.convertToIR -f caffe -d kit_imagenet -n examples/caffe/models/bvlc_alexnet.prototxt -w examples/caffe/models/bvlc_alexnet.caffemodel```

```python -m mmdnn.conversion._script.IRToCode -f tensorflow --IRModelPath kit_imagenet.pb --dstModelPath kit_imagenet.py -w kit_imagenet.npy``` 

It generated python file kit_imagenet.py and numpy weights kit_imagenet.npy.
Kit_imagenet.py looks like this
```
import tensorflow as tf
__weights_dict = dict()
is_train = False

def load_weights(weight_file):
    import numpy as np
    if weight_file == None:
        return
    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()
    return weights_dict

def KitModel(weight_file = None):
    global __weights_dict
    __weights_dict = load_weights(weight_file)

    data            = tf.placeholder(tf.float32, shape = (None, 227, 227, 3), name = 'input')
    conv1_pad       = tf.pad(data, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]])
    conv1           = convolution(conv1_pad, group=1, strides=[4, 4], padding='VALID', name='conv1')
    relu1           = tf.nn.relu(conv1, name = 'relu1')
    pool1_pad       = tf.pad(relu1, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))
    pool1           = tf.nn.max_pool(pool1_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool1')
    norm1           = tf.nn.lrn(pool1, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm1')
    conv2_pad       = tf.pad(norm1, paddings = [[0L, 0L], [2L, 2L], [2L, 2L], [0L, 0L]])
    conv2           = convolution(conv2_pad, group=2, strides=[1, 1], padding='VALID', name='conv2')
    relu2           = tf.nn.relu(conv2, name = 'relu2')
    pool2_pad       = tf.pad(relu2, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))
    pool2           = tf.nn.max_pool(pool2_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool2')
    norm2           = tf.nn.lrn(pool2, 2, alpha = 1.99999994948e-05, beta = 0.75, name = 'norm2')
    conv3_pad       = tf.pad(norm2, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])
    conv3           = convolution(conv3_pad, group=1, strides=[1, 1], padding='VALID', name='conv3')
    relu3           = tf.nn.relu(conv3, name = 'relu3')
    conv4_pad       = tf.pad(relu3, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])
    conv4           = convolution(conv4_pad, group=2, strides=[1, 1], padding='VALID', name='conv4')
    relu4           = tf.nn.relu(conv4, name = 'relu4')
    conv5_pad       = tf.pad(relu4, paddings = [[0L, 0L], [1L, 1L], [1L, 1L], [0L, 0L]])
    conv5           = convolution(conv5_pad, group=2, strides=[1, 1], padding='VALID', name='conv5')
    relu5           = tf.nn.relu(conv5, name = 'relu5')
    pool5_pad       = tf.pad(relu5, paddings = [[0L, 0L], [0L, 1L], [0L, 1L], [0L, 0L]], constant_values=float('-Inf'))
    pool5           = tf.nn.max_pool(pool5_pad, [1, 3, 3, 1], [1, 2, 2, 1], padding='VALID', name='pool5')
    fc6_0           = tf.contrib.layers.flatten(pool5)
    fc6_1           = tf.layers.dense(fc6_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc6_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc6_1']['bias']), use_bias = True)
    relu6           = tf.nn.relu(fc6_1, name = 'relu6')
    fc7_0           = tf.contrib.layers.flatten(relu6)
    fc7_1           = tf.layers.dense(fc7_0, 4096, kernel_initializer = tf.constant_initializer(__weights_dict['fc7_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc7_1']['bias']), use_bias = True)
    relu7           = tf.nn.relu(fc7_1, name = 'relu7')
    fc8_indoor_outdoor_0 = tf.contrib.layers.flatten(relu7)
    fc8_indoor_outdoor_1 = tf.layers.dense(fc8_indoor_outdoor_0, 2, kernel_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['weights']), bias_initializer = tf.constant_initializer(__weights_dict['fc8-indoor-outdoor_1']['bias']), use_bias = True)
    prob            = tf.nn.softmax(fc8_indoor_outdoor_1, name = 'output')
    return data, prob

def convolution(input, name, group, **kwargs):
    w = tf.Variable(__weights_dict[name]['weights'], trainable=is_train, name=name + ""_weight"")
    if group == 1:
        layer = tf.nn.convolution(input, w, **kwargs)
    else:
        weight_groups = tf.split(w, num_or_size_splits=group, axis=-1)
        xs = tf.split(input, num_or_size_splits=group, axis=-1)
        convolved = [tf.nn.convolution(x, weight, **kwargs) for
                    (x, weight) in zip(xs, weight_groups)]
        layer = tf.concat(convolved, axis=-1)

    if 'bias' in __weights_dict[name]:
        b = tf.Variable(__weights_dict[name]['bias'], trainable=is_train, name=name + ""_bias"")
        layer = layer + b
    return layer

```


I then wrote a script which uses kit_imagenet.py and numpy weights kit_imagenet.npy to create freezed model
```
import tensorflow as tf
from freeze_graph import freeze_graph # tensorflow comes up with a tool allowing freeze graph
from kit_imagenet import KitModel
from tensorflow.python.framework import graph_util
import os

data_node, prob_node = KitModel('kit_imagenet.npy')
sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())

model_dir = './saved_model'
MODEL_NAME = ""inorout""

saver = tf.train.Saver()
saver.save(sess, os.path.join(model_dir,MODEL_NAME), global_step=0, latest_filename='chkpt_state')

graph_def = tf.get_default_graph().as_graph_def()
output_graph = graph_util.convert_variables_to_constants(sess, graph_def, ['output'])
with tf.gfile.GFile(os.path.join(model_dir, MODEL_NAME + '.pb'), 'wb') as f:
    f.write(output_graph.SerializeToString())
```

After having freezed model, I converted to optimized version of protobuf using (tensorflow.python.tools.optimize_for_inference ). now i have 'inference_inorout.pb'.

Now I am trying to converted this optimized version of protobuf to tflite model, but it shows errors!

```

toco --input_file='inferencemodel/inference_inorout.pb' --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file='tflite/model.tflite' --inference_type = FLOAT --input_data_type = FLOAT --input_array='input' --output_array='output' --input_shape=1,227,227,3
2018-06-12 10:53:52.151081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2
2018-06-12 10:53:52.153847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2
2018-06-12 10:53:52.161334: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1233] Converting unsupported operation: PadV2
2018-06-12 10:53:52.457117: F tensorflow/contrib/lite/toco/tooling_util.cc:842] Check failed: name.substr(colon_pos + 1).find_first_not_of(""0123456789"") == string::npos (1 vs. 18446744073709551615)Array name must only have digits after colon
Abort trap: 6 ```
"
19948,superfluous tf.reshape affacts output,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: Python 3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: run the following code snippet

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
The code snippet attached, when run with different values for `reshape_iter`, produces different results.

This should not happen since `reshape`-ing a tensor repeatedly to the same shape is, by definition, idempotent.  Could it be that `reshape` affects the internal state of the random number generator?

### Source code / logs
````python
import numpy as np
import tensorflow as tf
import tflearn


def network(x, reshape_iter):
    _, height, width, c_dim = x.shape
    for i in range(reshape_iter):
        x = tf.reshape(x, (-1, height * width * c_dim))
    logits = tflearn.fully_connected(x, 1)
    x = tflearn.activation(logits, 'sigmoid')
    return x, logits


np.random.seed(123456)
tf.set_random_seed(123456)

disc_input = tflearn.input_data(shape=(None, 128, 128, 3))
disc_output, logits = network(disc_input, reshape_iter=5)

sample = np.random.random((8, 128, 128, 3))
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    disc_output_val, logits_val, W_val = sess.run(
            (disc_output, logits, logits.W), feed_dict={disc_input: sample}
    )

print(disc_output_val.reshape((-1,)))
print(W_val.reshape((-1,)))
````"
19946,Extend replicate_model_fn to work with datasets with arbitrary nested structure of tensors as input_fn,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN 7.0
- **GPU model and memory**: Nvidia K80 (x4)
- **Exact command to reproduce**: python training/train.py

You can collect some of this information using our environment capture script: 

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Feature request: extend `tf.contrib.estimator.replicate_model_fn` to be usable with a dataset feeder (with arbitrary nested structure of tensors) as `input_fn`. Currently the `_split_batch` (in replicate_model_fn.py) can only split flat nested structures.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Below is traceback from dataset using dict of dict of tensors.
```
Traceback (most recent call last):
  File ""training/train.py"", line 82, in <module>
    run_experiment(args.train_files, args.eval_files, hparams)
  File ""training/train.py"", line 50, in run_experiment
    tf.estimator.train_and_evaluate(_estimator, train_spec, eval_spec)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/training.py"", line 439, in train_and_evaluate
    executor.run()
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/training.py"", line 518, in run
    self.run_local()
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/training.py"", line 650, in run_local
    hooks=train_hooks)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 843, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 856, in _train_model_default
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py"", line 831, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py"", line 226, in replicated_model_fn
    features, labels, len(devices), device=consolidation_device)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py"", line 486, in _split_batch
    feature_shards = split_dictionary(features)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py"", line 478, in split_dictionary
    ensure_divisible_by_shards(tensor)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py"", line 462, in ensure_divisible_by_shards
    batch_size = ops_lib.convert_to_tensor(sequence).get_shape()[0]
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1014, in convert_to_tensor
    as_ref=False)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1104, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 235, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 214, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/home/alex/T2/virtualenv/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 521, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'dict'> to Tensor. Contents: {'input_seq': <tf.Tensor 'IteratorGetNext:4' shape=(128, ?) dtype=int64>, 'stop_token': <tf.Tensor 'IteratorGetNext:3' shape=(128, ?) dtype=float32>, 'target_seq': <tf.Tensor 'IteratorGetNext:2' shape=(128, ?, 80) dtype=float32>}. Consider casting elements to a supported type.
```
"
19945,"The argument ""num_parallel_calls"" in tf.data.Dataset.map() doesn't work in eager execution.","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
pip
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.6.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
No
- **GPU model and memory**:
No
- **Exact command to reproduce**:
No

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I use `tf.py_func`(`tfe.py_func` has the same problem) in `tf.data.Dataset.map()` function to pre-process my training data in eager execution.

In my model, the batch size is 16, and it costs about 30ms to process a piece of data. So it takes 16*30=480ms to process a batch of training data. The network trained with a batch of data costs about 300ms.

I followed this guide (https://www.tensorflow.org/performance/datasets_performance) and try to build  an efficient input pipeline.

First, I use `prefetch(1)` after `batch(16)`, and it works(480ms per batch).
Then, I use `map(map_func, num_parallel_calls=4)` to pre-process the data in parallel. But it doesn't work. It costs 480ms per batch.
Furthermore, I try it without eager execution. And it works well(300ms per batch). 


### Source code / logs
Using Eager Execution
```python
import time
import tensorflow as tf
from tensorflow.contrib.eager.python import tfe
tf.enable_eager_execution()


def main():
    data = tf.range(0, 100, dtype=tf.float32)

    def map_fn(n):
        def fn(nn):
            time.sleep(0.03)
            return tf.constant(1.)
        return tfe.py_func(fn, [n], [tf.float32])

    dataset = tf.data.Dataset.from_tensor_slices(data)
    dataset = dataset.repeat()
    dataset = dataset.map(map_fn, num_parallel_calls=4).batch(16).prefetch(1)

    t = time.time()
    for i in dataset:
        time.sleep(0.3)
        print('time: {}'.format((time.time() - t) * 1000))
        t = time.time()


if __name__ == '__main__':
    main()
```

output:
>time: 880.5060386657715
time: 487.31040954589844
time: 487.4300956726074
time: 487.37573623657227
...



Without Eager Execution
```python
import time
import numpy as np
import tensorflow as tf


def main():
    data = tf.range(0, 100, dtype=tf.float32)

    def map_fn(n):
        def fn(nn):
            time.sleep(0.03)
            return np.array([1], dtype=np.float32)
        return tf.py_func(fn, [n], [np.float32])

    dataset = tf.data.Dataset.from_tensor_slices(data)
    dataset = dataset.repeat()
    dataset = dataset.map(map_fn, num_parallel_calls=4).batch(16).prefetch(1)

    next_data = dataset.make_one_shot_iterator().get_next()

    sess = tf.Session()
    sess.run(tf.global_variables_initializer())

    t = time.time()
    for i in range(10000):
        time.sleep(0.3)
        d = sess.run(next_data)
        print('time: {}'.format((time.time() - t) * 1000))
        t = time.time()


if __name__ == '__main__':
    main()
```

output:
> time: 435.55521965026855
time: 301.36632919311523
time: 301.2561798095703
time: 301.67603492736816
..."
19944,c++ gradient is not implemented for concat/stack,"Feature Request:
I noticed that c++ gradient for concat or stack is not implemented while i am using tensorflow sharp. I think those are quite important operations.  Could you please somehow consider implement those? Or is there any other replacement?

Thank you!

"
19943,"i get the error Could not import tensorflow. Do not import tensorflow from its source directory; change directory to outside the TensorFlow source tree, and relaunch your Python interpreter from there.","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19940,Bazel compilation issue,"I am trying to compile TF with bazel release 0.14.1 using gcc 6.4.0 (and gcc 7.2.0) with Python 3.6 from Anaconda on CentOS 7, using only Jemalloc support. 

`/usr/bin/bazel build --config=mkl  --copt=""-mfma"" --copt=""-mavx2"" --copt=""-march=broadwell"" --copt=""-O3"" -s -c opt //tensorflow/tools/pip_package:build_pip_package -j 64`

I observed the following error:

> ERROR: /home/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:339:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels/internal:audio_utils' failed (Exit 1)
> /scratch/gcc/6.4.0/libexec/gcc/x86_64-pc-linux-gnu/6.4.0/cc1plus: error while loading shared libraries: libisl.so.15: cannot open shared object file: No such file or directory

The same error is reported here:
https://stackoverflow.com/questions/50548504/unable-to-find-libisl-so-15

Using gcc 4.8.5 and TF branch r1.7, I had instead:
(following https://www.tensorflow.org/versions/master/install/install_sources)

> ERROR: /home/lmontigny/tensorflow/tensorflow/contrib/lite/BUILD:78:1: C++ compilation of rule '//tensorflow/contrib/lite:simple_memory_arena' failed (Exit 1)
> tensorflow/contrib/lite/simple_memory_arena.cc:1:0: error: bad value (broadwell) for -march= switch
> 
"
19939,Object_detection_api : Le fichier sp\udce9cifi\udce9 est introuvable.,"Thisissue appear when i want to generate TFRecord file.

models\research\object_detection\images\train\image1 : Le fichier sp\udce9cifi\udce9 est introuvable. ; No such file or directory

`def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf-8')
    image_format = b'png'
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf-8'))
        classes.append(class_text_to_int(row['class']))

    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example`
this is the stack-trace : File ""generate_tfrecord.py"", line 46, in create_tf_example encoded_jpg = fid.read()"
19936,"Min/Max value, naming scope, and tf.contrib.quantize","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Pip package
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: non-related to GPU
- **GPU model and memory**: non-related to GPU
- **Exact command to reproduce**:

### Describe the problem

I am assuming to use `create_training_graph()` to insert min/max vars into my graph, train it, and then reuse variables to re-route an inference graph with `create_eval_graph()`. By this way I could reuse the min/max information gathered in the training process.

So I wrote the following code to try them out:

```python
import tensorflow as tf

def _build():
    """"""A simple matmul() model.""""""
    # with tf.variable_scope('YEAH'): **************************
    w = tf.get_variable('W', [64, 64], tf.float32)
    b = tf.get_variable('b', [64], tf.float32)
    x = tf.placeholder(tf.float32, [1, 64], 'input')
    y = tf.matmul(x, w) + b
    o = tf.identity(y, 'output')
    return x, o

with tf.name_scope('Train'):
    _build()
    tf.contrib.quantize.create_training_graph(quant_delay=1000)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())

    # train the model...
    pass

    # inference graph
    tf.get_variable_scope().reuse_variables()
    _build()
    tf.contrib.quantize.create_eval_graph()

    # export...
    pass
```

And it raises exception:

```
ValueError: Variable act_quant_1/min does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?
```

However, if I change the `_build()` function:

```python
def _build():
    """"""A simple matmul() model.""""""
    with tf.variable_scope('YEAH'):
        w = tf.get_variable('W', [64, 64], tf.float32)
        b = tf.get_variable('b', [64], tf.float32)
        x = tf.placeholder(tf.float32, [1, 64], 'input')
        y = tf.matmul(x, w) + b
        o = tf.identity(y, 'output')
    return x, o
```

...to solely apply a variable scope for all nodes, the error disappears. And the variables seems fine.

```python
In [2]: tf.global_variables()
Out[2]: 
[<tf.Variable 'YEAH/W:0' shape=(64, 64) dtype=float32_ref>,
 <tf.Variable 'YEAH/b:0' shape=(64,) dtype=float32_ref>,
 <tf.Variable 'YEAH/weights_quant/min:0' shape=() dtype=float32_ref>,
 <tf.Variable 'YEAH/weights_quant/max:0' shape=() dtype=float32_ref>,
 <tf.Variable 'fake_quantization_step:0' shape=() dtype=int64_ref>,
 <tf.Variable 'YEAH/act_quant/min:0' shape=() dtype=float32_ref>,
 <tf.Variable 'YEAH/act_quant/max:0' shape=() dtype=float32_ref>,
 <tf.Variable 'YEAH/act_quant/YEAH/act_quant/min/biased:0' shape=() dtype=float32_ref>,
 <tf.Variable 'YEAH/act_quant/YEAH/act_quant/min/local_step:0' shape=() dtype=float32_ref>,
 <tf.Variable 'YEAH/act_quant/YEAH/act_quant/max/biased:0' shape=() dtype=float32_ref>,
 <tf.Variable 'YEAH/act_quant/YEAH/act_quant/max/local_step:0' shape=() dtype=float32_ref>]
```

What is the correct usage for `create_training_graph()` and `create_eval_graph()`? Is my expectation correct? It looks like `create_xxx_graph()` searches for vacant scope instead of accepting possible reuse.
"
19935,linalg_grad_test is failing with minor array mismatch ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
      Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source
- **TensorFlow version (use command below)**:
      TF master
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
     bazel-0.11.1
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
 `bazel test -c opt --test_output=errors //tensorflow/python/kernel_tests:linalg_grad_test`

### Describe the problem
This test is failing due to array mismatch error – a single value in an array of 100+ (or 200+) elements differing i.e.  `-0.2765212 VS  -0.09727482` (minor mismatch i.e. 0.01%), I feel this is not ""critical"".

Hence, I tried running this test by changing minor tolerance `(from atol=0.16 to 0.17)`, and test is passing -
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/linalg_grad_test.py#L133
Original : `self.assertAllClose(theoretical, numerical, atol=tol, rtol=tol) `
Update to : ` self.assertAllClose(theoretical, numerical, atol=tol+0.01, rtol=tol)`

@skye Is it OK to raise a PR with this changes ?. Please provide your comments on this.
This is similar to PR https://github.com/tensorflow/tensorflow/pull/14086 (Issue : https://github.com/tensorflow/tensorflow/issues/13992).
Thanks!

### Source code / logs
 `bazel test -c opt --test_output=errors //tensorflow/python/kernel_tests:linalg_grad_test`

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
..F.........
======================================================================
FAIL: test_MatrixSolveLsGradient_float32_10_10_1e-06 (__main__.MatrixBinaryFunctorGradientTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/8f6ddabc24aafac92d95350c806a3c5a/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/linalg_grad_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/linalg_grad_test.py"", line 133, in Test
    self.assertAllClose(theoretical, numerical, atol=tol, rtol=tol)
  File ""/root/.cache/bazel/_bazel_root/8f6ddabc24aafac92d95350c806a3c5a/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/linalg_grad_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1368, in assertAllClose
    self._assertAllCloseRecursive(a, b, rtol=rtol, atol=atol, msg=msg)
  File ""/root/.cache/bazel/_bazel_root/8f6ddabc24aafac92d95350c806a3c5a/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/linalg_grad_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1338, in _assertAllCloseRecursive
    path_str))
  File ""/root/.cache/bazel/_bazel_root/8f6ddabc24aafac92d95350c806a3c5a/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/linalg_grad_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1273, in _assertArrayLikeAllClose
    a, b, rtol=rtol, atol=atol, err_msg=msg, equal_nan=True)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/nose_tools/utils.py"", line 1396, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/nose_tools/utils.py"", line 779, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.16, atol=0.16
Mismatched value: a is different from b.
(mismatch 0.01%)
 x: array([[-0.274541,  0.232045,  0.238228, ..., -0.034111, -0.373466,
         0.033984],
       [-0.781969,  3.879241, -0.101673, ..., -2.040497, -3.555899,...
 y: array([[-0.27545 ,  0.234431,  0.2381  , ..., -0.040039, -0.382935,
         0.036284],
       [-0.782201,  3.879493, -0.102113, ..., -2.039877, -3.555702,...

----------------------------------------------------------------------
Ran 12 tests in 1.858s

FAILED (failures=1)
not close where =  (array([40]), array([33]))
not close lhs =  [-0.2765212]
not close rhs =  [-0.09727482]
not close dif =  [0.1792464]
not close tol =  [0.17556396]
dtype = float32, shape = (100, 100)
```
"
19934,init function of OpTypePattern has a confusing if condition,"**System information**
Have I written custom code: No
OS Platform and Distribution: NA
TensorFlow installed from: source code, master branch
TensorFlow version: 1.8.0
Bazel version: NA
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: NA

**Bug description**
Related file: tensorflow/tensorflow/contrib/quantize/python/graph_matcher.py
At master branch, line 62 to 64。
According to the description in ValueError, I think the condition in if should like below:
if len(inputs) >= 8 and not ordered_inputs:
    raise ValueError('xxx')

May this helps! Thanks!"
19933,Using feed_dict is more than 5x faster than using dataset API?,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.4 (on Linux Ubuntu 16.04 you get similar results)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7 cpu
- **Python version**:  3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
I created a dataset in TFRecord format for testing. Every entry contains 200 columns, named C1 - C199, each being a strings list, and a label column to denote the labels. The code to create the data can be found here: https://github.com/codescv/tf-dist/blob/8bb3c44f55939fc66b3727a730c57887113e899c/src/gen_data.py#L25

Then I used a linear model to train the data. The first approach looks like this:

```
dataset = tf.data.TFRecordDataset(data_file)
dataset = dataset.prefetch(buffer_size=batch_size*10)
dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)
dataset = dataset.repeat(num_epochs)
dataset = dataset.batch(batch_size)

features, labels = dataset.make_one_shot_iterator().get_next()    
logits = tf.feature_column.linear_model(features=features, feature_columns=columns, cols_to_vars=cols_to_vars)
train_op = ...

with tf.Session() as sess:
    sess.run(train_op)
```
The full code can be found here: https://github.com/codescv/tf-dist/blob/master/src/lr_single.py

When I run the code above, I get 0.85 steps/sec (batch size being 1024).

In the second approach, I manually get batches from Dataset into python, then feed them to a placeholder, like this:

```
example = tf.placeholder(dtype=tf.string, shape=[None])
features = tf.parse_example(example, features=tf.feature_column.make_parse_example_spec(columns+[tf.feature_column.numeric_column('label', dtype=tf.float32, default_value=0)]))
labels = features.pop('label')
train_op = ...

dataset = tf.data.TFRecordDataset(data_file).repeat().batch(batch_size)
next_batch = dataset.make_one_shot_iterator().get_next()

with tf.Session() as sess:
    data_batch = sess.run(next_batch)
    sess.run(train_op, feed_dict={example: data_batch})
```
The full code can be found here: https://github.com/codescv/tf-dist/blob/master/src/lr_single_feed.py

When I run the code above, I get 5 steps/sec. That is 5x faster than the first approach. This is what I do not understand, because theoretically the second should be slower due to the extra serialization/deserialization of data batches.

Is this possibly a bug or am I using it mistakenly ?

Thanks!

### Source code / logs
I have also included some profile traces below:

(using tf Dataset API)
![lr_single](https://user-images.githubusercontent.com/124190/41281915-3b049342-6e65-11e8-8b04-4d4611a96fa8.png)

[profile-101.json.zip](https://github.com/tensorflow/tensorflow/files/2093402/profile-101.json.zip)


(using feed_dict)
![lr_single_feed](https://user-images.githubusercontent.com/124190/41281927-4186bcae-6e65-11e8-80a6-e19dcd6b5c53.png)

[profile-101.json.zip](https://github.com/tensorflow/tensorflow/files/2093405/profile-101.json.zip)



"
19931,pd Convert tflite to error,"Download the network model

MobileNet_v1_1.0_224_quant

https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
Turn tflite error

bazel run toco -- \
  --input_file=/Users/dchealth/Desktop/mobilenet_v1_1.0_224_quant/mobilenet_v1_1.0_224_quant_frozen.pb \
  --output_file=/Users/dchealth/Desktop/mobilenet_v1_1.0_224_quant/mobilenetnew.tflite \
  --input_format=TENSORFLOW_GRAPHDEF \
  --inference_type=FLOAT \
  --output_format=TFLITE \
  --input_type=FLOAT \
  --input_shapes=1,224,224,3 \
  --input_arrays=input \
  --output_arrays=MobilenetV1/Predictions/Reshape_1

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:mac os 10.13.5
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:'1.8.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**:
Build label: 0.14.0-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 1 14:26:58 2018 (1527863218)
Build timestamp: 1527863218
Build timestamp as int: 1527863218

- **GCC/Compiler version (if compiling from source)**:no
- **CUDA/cuDNN version**:no
- **GPU model and memory**:no
- **Exact command to reproduce**:no

2018-06-12 15:29:13.254673: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 598 operators, 889 arrays (0 quantized)
2018-06-12 15:29:13.272912: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 598 operators, 889 arrays (0 quantized)
2018-06-12 15:29:13.994779: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 59 operators, 117 arrays (0 quantized)
2018-06-12 15:29:13.996069: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 59 operators, 117 arrays (0 quantized)
2018-06-12 15:29:13.997304: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:329] Total transient array allocated size: 6422528 bytes, theoretical optimal value: 6422528 bytes.
2018-06-12 15:29:13.997580: I tensorflow/contrib/lite/toco/toco_tooling.cc:373] Estimated count of arithmetic ops: 1.14264 billion (note that a multiply-add is counted as 2 ops).
2018-06-12 15:29:13.998014: E tensorflow/contrib/lite/toco/tflite/export.cc:320] FAKE_QUANT operation was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.



Xcode runs an error:
Loaded model 1resolved reporterDidn't find custom op for name 'FAKE_QUANT'

Registration failed.

Failed to construct interpreter(lldb) "
19927," return getattr(obj, method)(*args, **kwds) numpy.core._internal.AxisError: axis 1 is out of bounds for array of dimension 1","Having error in the code:


def accuracy(predictions,labels):
    return(100.0*np.sum(np.argmax(predictions) == np.argmax(labels,1))/predictions.shape[0])

with tf.Session(graph=graph) as session:
    tf.global_variables_initializer().run()
    print('Initialized')
    for step in range(num_steps):
        _, l, predictions = session.run([optimizer, loss, train_prediction])
        if (step % 100 == 0):
         
            
            print('loss at step %d: %f'%(step,1))
            print('Training accurecy:%.1f%%'% accuracy(
                predictions,train_labels[:train_subset,:]))
            print('Validation accuracy : %.1f%%' %accuracy(
                valid_prediction.eval(),valid_labels))
    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(),test_labels))
    
            "
19926,Could tensorboard add search function,"Tensorboard visualization is great, but for big graphs, it is hard to locate certain ops. There are two many components in the graph. So I want two new functions:
1. It is possible to hide some nodes, such as reshape, relu, and soon, which does not affects the graph structure.
2. Is it possible to search some ops by name keywords, such as RPNLoss? The search result could be displayed on a search board."
19924,Build from source fails due to function mismatch in MPIServer code,"### Context:
Trying to build from source, master branch as of 12/06/2018 T 06.00 UTC+2.
Configured to build with MPI support, using OpenMPI 3 (compiled from source and already tried and tested, including with older versions of TF, such as the TF master branch from a week ago).

The error occurs during compilation, preventing it to conclude successfully. Disabling MPI from configure leads to successful build.

### Error messages (relevant parts):
```
ERROR: [...]/tensorflow/tensorflow/contrib/mpi/BUILD:83:1: C++ compilation of rule '//tensorflow/contrib/mpi:mpi_server_lib' failed (Exit 1)
tensorflow/contrib/mpi/mpi_server_lib.cc: In member function 'tensorflow::Status tensorflow::MPIServer::Init(tensorflow::ServiceInitFunction, tensorflow::RendezvousMgrCreationFunction)':
tensorflow/contrib/mpi/mpi_server_lib.cc:57:64: error: no matching function for call to 'tensorflow::MPIServer::Init(tensorflow::ServiceInitFunction&, tensorflow::RendezvousMgrCreationFunction&)'
   Status s = GrpcServer::Init(service_func, rendezvous_mgr_func);
                                                                ^
```

### Debugging steps tried so far:
I am not familiar with the codebase, but it seems that the recently introduced feature *Collective Ops* (commits in *Part 8*) does add an argument place to non-empty `GrpcServer::Init` calls in `tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc`, which is then called in `tensorflow/contrib/mpi/mpi_server_lib.cc` with a number of arguments not matching any definition.

### System information (if needed, anyway)
- **Have I written custom code**: Yes, but probably unrelated ([this](https://github.com/tensorflow/tensorflow/commit/191da96863333222768f5ecc3b58de64729346cf.patch) and [this](https://github.com/tensorflow/tensorflow/commit/749c3e9bc36c37f2981b635a4022a6f0db5c30f7.patch) patches to fix a GCC 8.1-related problem with MPI's streamexecutor);
- **OS Platform and Distribution**: Manjaro Linux (ArchLinux);
- **TensorFlow installed from**: Source, master branch;
- **TensorFlow version**: 1.9-RC0
- **Python version**: 3.6.3 (IntelPython)
- **Bazel version (if compiling from source)**: 0.14.1- (@non-git)
- **GCC/Compiler version (if compiling from source)**: 8.1.1; 7.x for CUDA
- **CUDA/cuDNN version**: 9.2/7.1
- **GPU model and memory**: Quadro Mobile M1000M (compute capability: 5)
- **Exact command to reproduce**: Building from source (`/bin/bazel build --config=opt --config=cuda --config=mkl --copt=""-DEIGEN_USE_VML"" //tensorflow/tools/pip_package:build_pip_package` after having configured to use MPI)"
19922,tf.Session.run/tf.RunOptions timeout issue,"When setting a timeout for a tf.Session.run with XLA enabled it seems that the argument is not used during the XLA build process:

```
run_options = tf.RunOptions(timeout_in_ms=60000)
r = sess.run(e, options=run_options)
```

I have some code to build and evaluate different NN architectures and it can switch betteen XLA and normal execution, however XLA sometimes is extremely slow compiling and I want to know if there is a way to stop it other than killing the process.

**Have I written custom code**: No.
**OS**: Windows 10 x64 and Ubuntu 16.04.4 LTS
**Tensorflow installed from**: pip on windows, git sources r1.9 on ubuntu.
**TensorFlow version**: 1.8 on windows (python 3.5.5) , 1.9 on ubuntu (python 3.5.2, jemalloc, XLA JIT, GCC 5.4.0, CUDA, other ./configure options disabled).
**Bazel version**: 0.14.1 on ubuntu, n/a on windows.
**CUDA/cuDNN version**: 9.1/7.1 on windows, 9.2/7.1.4.18 on ubuntu
**GPU model and memory**: nvidia 1060/6GB
**Exact command to reproduce**: anything that would trigger a long XLA build within a Session.run with a timeout set.

Thanks."
19921,How could I change freeze model's input node type?,"Hi ,

I built a TensorFlow pb file and lost checkpoints file. 
It's woking fine on linux, but iOS.
On linux, I feed the batch_size layer a float image ,it will output the feature data which is float format. 
On iOS, it shows ""Running model failed: Invalid argument: Expects arg[0] to be int32 but float is provided"".
And I don't know how to solve it, I think that maybe change the input node type will solve it.(maybe I guess)

Here are some information about this pb file.
inputs->
batch_size ,int32(3
phase_train, bool(10)
outputs->
embeddings, float

Thanks,
Alyson

"
19918,"Hi, how can I fix HTTP error 403? mnist input_data","Hi!
It is my first time to use this data set!
I got HTTP error 403 when I use the following code.

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""./mnist/data/"", one_hot=True)

So.. I tried several things such as turning off firewall.
But, I can't solve it and need to fix it for homework.
Can you help me?"
19914,TensorFlow MNIST dataset is throwing 403,"[TensorFlow official MNIST model](https://github.com/tensorflow/models/blob/master/official/mnist/dataset.py) and [TFLearn Model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py) use https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz as a data store for MNIST dataset.

This URL is returning 403 errors:
```
<Error>
  <Code>UserProjectAccountProblem</Code>
  <Message>User project billing account not in good standing.</Message>
  <Details>
    The billing account for project 81,941,577,218 is disabled in state delinquent
  </Details>
</Error>
```

Any ETA for the fix?

cc @reedwm @martinwicke "
19913,ValueError: Could not interpret optimizer identifier (tf.keras),"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0/6.0
- **GPU model and memory**:
Nvidia
- **Exact command to reproduce**:
model.compile(optimizer=tf.keras.optimizers.Adadelta() ...)

### Describe the problem
Passing in keras optimizers into a tf.keras model causes a value error, unless they are passed as strings i.e. ""Adadelta"" instead of Adadelta( ). This prevents arguments from being passed to the optimizer. Please note that when the optimizer is imported from vanilla Keras i.e. `keras.optimizers.Adadelta(rho=0.9)` there is no such issue. 

### Source code / logs

``
    import tensorflow as tf
    from tensorflow.python.keras.optimizers import Adadelta, Adam

    model = deepshading.get_model()
    model.compile(optimizer=tf.keras.optimizers.Adadelta(rho=0.9),
                  loss=DSSIMObjective(k1=0.0001, k2=0.001, kernel_size=8),
                  metrics=[DSSIMObjective(k1=0.0001, k2=0.001, kernel_size=8)])
``

Returns trace-back
``
identifier=identifier.__class__.__name__))
Traceback (most recent call last):
  File ""C:/Users/isultan/PycharmProjects/deep-shading/run.py"", line 69, in <module>
    train()
  File ""C:/Users/isultan/PycharmProjects/deep-shading/run.py"", line 35, in train
    metrics=[DSSIMObjective(k1=0.0001, k2=0.001, kernel_size=8)])
  File ""C:\Users\isultan\AppData\Local\Continuum\miniconda3\envs\tf\lib\site-packages\keras\engine\training.py"", line 604, in compile
    self.optimizer = optimizers.get(optimizer)
  File ""C:\Users\isultan\AppData\Local\Continuum\miniconda3\envs\tf\lib\site-packages\keras\optimizers.py"", line 768, in get
    str(identifier))
ValueError: Could not interpret optimizer identifier: <tensorflow.python.keras._impl.keras.optimizers.Adadelta object at 0x000001E563508860>
``"
19912,tf dataset iterators producing Key error when used with tf.keras.Model fit method,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.9.0-rc0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)

### Describe the problem
 In the tf 1.9 rc0 release notes, it was mentioned that dataset iterator can work with Keras training and eval methods. However, the fit method is throwing the following error when used with an iterator.

> No data provided for ""InputLayer"". Need data for each key in: ['InputLayer']

### Source code / logs

```
X_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_0','Load_residential_multi_1'],shuffle=False)
Y_dataset = tf.contrib.data.make_csv_dataset(file_names[0],4,select_columns=['Load_residential_multi_2'],shuffle=False)
dataset = tf.data.Dataset.zip((X_dataset,Y_dataset))
dataset = dataset.batch(2)
dataset_iterator = dataset.make_one_shot_iterator()

model = Sequential() 
#Input Layer
model.add(InputLayer(input_shape=(1,),name='InputLayer'))#,input_tensor =dataset
#Layer1 
model.add(Dense(units=5,activation='relu',name='FeedForward1'))  #Add a feed forward layer
#Layer2 
model.add(Dense(units=5,activation='relu',name='FeedForward2'))  #Add a feed forward layer
#Output layer 
model.add(Dense(units=2,name='OutputLayer'))
#Specify loss function and optimizer
model.compile(loss='mse',optimizer='adam',metrics=['mae'])
#Summarize model
model.summary()
#Train model
model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)
```
The error trace is given below:

> KeyError                                  Traceback (most recent call last)
> ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
>     125           if data[x].__class__.__name__ == 'DataFrame' else data[x]
> --> 126           for x in names
>     127       ]
> 
> ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_utils.py in <listcomp>(.0)
>     125           if data[x].__class__.__name__ == 'DataFrame' else data[x]
> --> 126           for x in names
>     127       ]
> 
> KeyError: 'InputLayer'
> 
> During handling of the above exception, another exception occurred:
> 
> ValueError                                Traceback (most recent call last)
> <ipython-input-90-cd138934ce6f> in <module>()
> ----> 1 model.fit(dataset_iterator,steps_per_epoch=2,batch_size=2,epochs=2,shuffle =True,verbose=1)
> 
> ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)
>    1256         steps_name='steps_per_epoch',
>    1257         steps=steps_per_epoch,
> -> 1258         validation_split=validation_split)
>    1259 
>    1260     # Prepare validation data.
> 
> ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split)
>     867         feed_input_shapes,
>     868         check_batch_axis=False,  # Don't enforce the batch size.
> --> 869         exception_prefix='input')
>     870 
>     871     if y is not None:
> 
> ~\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
>     128     except KeyError as e:
>     129       raise ValueError('No data provided for ""' + e.args[0] + '"". Need data '
> --> 130                        'for each key in: ' + str(names))
>     131   elif isinstance(data, list):
>     132     if isinstance(data[0], list):
> 
> ValueError: No data provided for ""InputLayer"". Need data for each key in: ['InputLayer']"
19911,Adding report_tensor_allocations_upon_oom to RunOptions in Keras Ask Question,"Im trying to add the report tensor GPU allocations for keras model to debug `tensorflow.python.framework.errors_impl.ResourceExhaustedError`.

Im doing exactly like [this page](https://stackoverflow.com/questions/49665757/how-to-add-report-tensor-allocations-upon-oom-to-runoptions-in-keras?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa) suggested, but I got this error

```
ValueError: ('Some keys in session_kwargs are not supported at this time: %s', dict_keys(['options']))
```

Is there any other way for me to get the logs for memory allocation?

Im using `tensorflow-gpu==1.8.0` and `Keras==2.2.0`"
19910,glorot_uniform_initializer and glorot_normal_initializer not consistent with the rest of the initializers?,"In /ops/init_ops.py:

All the initializers inherit from class Initializer and implements:
def __call__(self, shape, dtype=None, partition_info=None)

This gives a different signature from the two glorot initializer functions (which are defs rather than classes), and the parameter 'partition_info' doesn't exist. This causes compatibility problems when passing them in as initializers."
19909,Tensorflow C++ API Batch Inference,"Hello,

My question is considering the inference in C++ API using batches. I'm trying to run SSD net based on Mobilenet. It works on a single image, but when I try to use multiple images inference, I can't understand how to get the multiple outputs. It seems like my program runs properly as a run time increased for a batch inference though.
Here is my sample code: I'm loading a batch of 32 images with OpenCV, transform them into a input tensor and run the Session. I need to understand what should I change in order to get 32 outputs. 
Thank you.

```
int main(int argc, char* argv[]) {
	//string image(argv[1]);
	int batchSize = 32;
	string pathFilenameImg1 = ""Patch6.jpg"";
	string pathFilenameImg2 = ""Patch1.jpg"";
	string pathFilenameImg3 = ""Patch2.jpg"";
	string pathFilenameImg4 = ""Patch3.jpg"";
	string pathFilenameImg5 = ""Patch0.jpg"";
	string pathFilenameImg6 = ""Patch1.jpg"";
	string pathFilenameImg7 = ""Patch2.jpg"";
	string pathFilenameImg8 = ""Patch3.jpg"";
	string graph = ""ssd_mobilenet.pb"";
	string labels = ""security_labels.txt"";
	int32 input_width = 512;
	int32 input_height = 512;
	int32 input_depth = 3;
	string input_layer = ""image_tensor"";
	vector<string> output_layer = { ""detection_boxes:0"", ""detection_scores:0"", ""detection_classes:0"", ""num_detections:0""};

	bool self_test = false;
	string root_dir = """";

	// First we load and initialize the model.
	std::unique_ptr<tensorflow::Session> session;
	string graph_path = tensorflow::io::JoinPath(root_dir, graph);
	LOG(ERROR) << ""graph_path:"" << graph_path;
	Status load_graph_status = LoadGraph(graph_path, &session);
	if (!load_graph_status.ok()) {
		LOG(ERROR) << ""LoadGraph ERROR!!!!"" << load_graph_status;
		return -1;
	}


	// Read and prepare images using OpenCV:
	std::vector<string> imgPathArray= { pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, 
										pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,
										pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1,
		pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1, pathFilenameImg1 ,pathFilenameImg2 ,pathFilenameImg3 ,pathFilenameImg1
	};
	std::vector<cv::Mat> imgArray;
	for (int i = 0; i < batchSize; i++)
		imgArray.push_back(cv::imread(imgPathArray.at(i)));


	// creating a Tensor for storing the data
	Tensor input_tensor(tensorflow::DT_UINT8, tensorflow::TensorShape({ batchSize, input_height, input_width, input_depth}));
	auto input_tensor_mapped = input_tensor.tensor<uchar, 4>();

	for (int bz = 0; bz < batchSize; ++bz) {
		uchar *source_data;
		source_data = imgArray.at(bz).data;
		for (int y = 0; y < input_height; ++y) {
			uchar* source_row = source_data + (y * input_width * input_depth);
			for (int x = 0; x < input_width; ++x) {
				uchar* source_pixel = source_row + (x * input_depth);
				uchar* source_B = source_pixel + 0;
				uchar* source_G = source_pixel + 1;
				uchar* source_R = source_pixel + 2;
				input_tensor_mapped(bz, y, x, 0) = *source_R;
				input_tensor_mapped(bz, y, x, 1) = *source_G;
				input_tensor_mapped(bz, y, x, 2) = *source_B;
			}
		}
	}


	/*// Get the image from disk as a float array of numbers, resized and normalized
	// to the specifications the main graph expects.
	std::vector<Tensor> resized_tensors;
	string image_path = tensorflow::io::JoinPath(root_dir, image);
	Status read_tensor_status = ReadTensorFromImageFile(image_path, input_height, input_width, input_mean, input_std, &resized_tensors);
	if (!read_tensor_status.ok()) {
		LOG(ERROR) << read_tensor_status;
		return -1;
	}
	const Tensor& resized_tensor = resized_tensors[0];

	LOG(ERROR) << ""image shape:"" << resized_tensor.shape().DebugString() << "",len:"" << resized_tensors.size() << "",tensor type:"" << resized_tensor.dtype();*/


	// Actually run the image through the model.
	std::vector<Tensor> outputs;

	std::chrono::steady_clock::time_point begin = std::chrono::steady_clock::now();
	Status run_status = session->Run({ { input_layer, input_tensor} }, output_layer, {}, &outputs);
	std::chrono::steady_clock::time_point end = std::chrono::steady_clock::now();	std::cout << ""Time difference (sec) = "" << (std::chrono::duration_cast<std::chrono::microseconds>(end - begin).count()) / 1000000.0 << std::endl;

	if (!run_status.ok()) {
		LOG(ERROR) << ""Running model failed: "" << run_status;
		return -1;
	}

	//int image_width = resized_tensor.dims();
	//int image_height = 0;
	//int image_height = resized_tensor.shape()[1];

	//LOG(ERROR) << ""output size:"" << outputs.size() << "",image_width:"" << image_width << "",image_height:"" << image_height << endl;

	auto boxes = outputs[0].flat_outer_dims<float, 3>();
	tensorflow::TTypes<float>::Flat scores = outputs[1].flat<float>();
	tensorflow::TTypes<float>::Flat classes = outputs[2].flat<float>();
	tensorflow::TTypes<float>::Flat num_detections = outputs[3].flat<float>();


	//LOG(ERROR) << ""num_detections:"" << num_detections(0) << "","" << outputs[0].shape().DebugString();
	int BarcodeCnt = 0;
	int GyoshCnt = 0;
	for (size_t i = 0; i < num_detections(0) && i < 20; ++i)
	{
		if (scores(i) > 0.9)
		{
			LOG(ERROR) <<""score:"" << scores(i) << "",class:"" << classes(i) << "",box:"" << "","" << boxes(0, i, 0) << "","" << boxes(0, i, 1) << "","" << boxes(0, i, 2) << "","" << boxes(0, i, 3);
			if(classes(i) == 1)
				BarcodeCnt++;
			else
				GyoshCnt ++;
		}
	}
	LOG(ERROR) << ""Total number of Security Barcodes is :"" << BarcodeCnt;
	LOG(ERROR) << ""Total number of Security Gyoshes is :"" << GyoshCnt;

	


	return 0;
}
```"
19908,how to used nccl.reduce_sum,"is there some example to use nccl.reduce_sum , as the doc say:
```
// Note: This op has no kernel implementation, but is replaced by
// _NcclReduceSend and _NcclReduceRecv during graph optimization stage.
```
so  how the nccl.reduce_sum works?"
19907,CreateSession still waiting for response from worker: /job:ps/replica:0/task:0,"OS Platform and Distribution : CentOS7.4
TensorFlow installed from : source code tensorflow-base:1.4.0
TensorFlow version: 1.4.0
CUDA/cuDNN version:1.8
GPU model and memory:nvidia_geforce_gtx_1080_ti
 NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |
| 23%   29C    P8    16W / 250W |  10623MiB / 11172MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |
| 25%   26C    P8    16W / 250W |     10MiB / 11172MiB |      0%      Default |

the pods are as below：
[root@k8s-node1 ~]# kubectl --namespace=liuning get pod -owide
NAME                          READY     STATUS    RESTARTS   AGE       IP              NODE
tensorfenbus-ps-0             1/1       Running   0          27m       10.10.36.111    k8s-node1
tensorfenbus-session-fh65h    1/1       Running   0          26m       10.10.169.152   k8s-node2
tensorfenbus-tf-board-n6d28   2/2       Running   0          26m       10.10.169.151   k8s-node2
tensorfenbus-worker-0         1/1       Running   0          27m       10.10.169.150   k8s-node2
tensorfenbus-worker-1         1/1       Running   0          27m       10.10.36.112    k8s-node1

In tensorfenbus-worker-1 i run python tf_cnn_benchmarks.py --local_parameter_device=gpu --num_gpus=1 \
--batch_size=32 --model=resnet50 \
--job_name=worker --ps_hosts=k8s-node1:2225 \
--worker_hosts=k8s-node1:2225,k8s-node2:2225 --task_index=0 

and then in tensorfenbus-ps-0 run python tf_cnn_benchmarks.py --local_parameter_device=gpu --num_gpus=1 \
--batch_size=32 --model=resnet50 \
--job_name=ps --ps_hosts=k8s-node1:2225 \
--worker_hosts=k8s-node1:2225,k8s-node2:2225 --task_index=0

but the work node log show ：
2018-06-11 11:34:29.568785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:04:00.0
totalMemory: 10.91GiB freeMemory: 398.38MiB
2018-06-11 11:34:29.568848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
E0611 11:34:29.572333602     348 ev_epoll1_linux.c:1051]     grpc epoll fd: 24
2018-06-11 11:34:29.577958: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> k8s-node1:2225}
2018-06-11 11:34:29.577990: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2225, 1 -> k8s-node2:2225}
2018-06-11 11:34:29.580147: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2225
TensorFlow:  1.4
Model:       resnet50
Mode:        training
Batch size:  32 global
             32 per device
Devices:     ['/job:worker/task:0/gpu:0']
Data format: NCHW
Optimizer:   sgd
Variables:   parameter_server
Sync:        True
==========
Generating model
WARNING:tensorflow:From tf_cnn_benchmarks.py:772: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_or_create_global_step
WARNING:tensorflow:From tf_cnn_benchmarks.py:627: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.get_global_step
2018-06-11 11:34:44.477725: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:34:44.477831: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:34:54.477958: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:34:54.478023: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:35:04.478242: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:35:04.478340: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:35:14.478475: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:35:14.478546: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:35:24.478709: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:35:24.478773: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:35:34.478927: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:35:34.478997: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:35:44.479163: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:35:44.479227: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:35:54.479470: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:35:54.479553: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:36:04.479720: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:36:04.479781: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-06-11 11:36:14.479936: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-06-11 11:36:14.479999: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1


**where's wrong**"
19906,"Build OK ,but My own C++ project has error :"" std::bad_alloc ""","**System information:**
· Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes

· OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10-x64

· TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git

· TensorFlow version (use command below): r1.8, command :
git checkout -b v1.8 -f origin/r1.8

· Python version: Anaconda3 - python3.6

· Bazel version (if compiling from source): I used CMAKE 3.11.1

· GCC/Compiler version (if compiling from source): both Visual Studio 2015 and Visual Studio 2015' MSBuild

· CUDA/cuDNN version: CUDA9.0, cudnn-9.0-win10-7.1

· GPU model and memory: GTX-860m with 2Gb Memory

Exact command to reproduce:
""
D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=**Release** -DSWIG_EXECUTABLE=D:/soft/TensorflowSoft/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/ProgramData/Anaconda3/python.exe -DPYTHON_LIBRARIES=D:/ProgramData/Anaconda3/libs/python36.lib -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""D:\soft\TensorflowSoft\cudnn"" -G ""Visual Studio 14 2015""

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> set PreferredToolArchitecture=x64

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> MSBuild /p:Configuration=**Release** ALL_BUILD.vcxproj
""

**Describe the problem :**

I build tensorflow-**GPU-Release** version sucessfully (even though GPU - Debug version had error). My project code is :

"" 
```
GraphDef CMFCtensorTest01Dlg::CreateGraphDef()
{      
     Scope root = Scope::NewRootScope();

     auto X = ops::Placeholder(root.WithOpName(""x""), DT_FLOAT, ops::Placeholder::Shape({ -1, 2 }));

     auto A = ops::Const(root, { { 3.f, 2.f },{ -1.f, 0.f } });

     auto Y = ops::MatMul(root.WithOpName(""y""), A, X,
     ops::MatMul::TransposeB(true));

     GraphDef def;
     TF_CHECK_OK(root.ToGraphDef(&def));
     return def;
}
```
""

Error running to the second line :""**auto X = ops::Placeholder(root.WithOpName(""x""), DT_FLOAT, ops::Placeholder::Shape({ -1, 2 }))**;""


The error is : ""0x00007FF95998F218 处(位于 MFCtensorTest01.exe 中)引发的异常: Microsoft C++ 异常: std::bad_alloc，位于内存位置 0x00000065700F9280 处。""

These code worked successfully on my **CPU - Debug** version build,  **GPU - Release** version had error. I think this error is about application memory.

Not long ago I tested it, if I change the **GUP - Release‘ s _pywrap_tensorflow_internal.pyd**  to **CPU - Debug ‘s _pywrap_tensorflow_internal.pyd**，code runs successfully（I build Win10 - CPU - Debug version **successfully** several days ago），I think the **GUP - Release‘ s _pywrap_tensorflow_internal.pyd** had something wrong."
19904,"Multiple Prediction With Tensorflow Model On iOS Swift, Objective-C","I am trying to do character recognition mobile app with CNN. My model predict with %99,6 accuracy on python.
Now, I am trying to implement my model on iOS. 
I used this project for sample project [Tensorflow Camera Example](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios/camera)
I created an app, it can predict right single character on screen. But I need to predict 5 character (like a code ABCDE) at same time. And when I change settings to send 5 CVPixelBuffer value to model, it predict wrong. When I send wrong predicted images to computer and try with python , it predicts true. I think there should be some special setting which I do not know, or something wrong about my function to get CVPixelBuffer value from UIImage.
I trained my model with 45x45 images. Now I crop 5 images (45x45 pixels) and send them to model.

My function to get CVPixelBuffer : 

    extension UIImage {
    /**
     Resizes the image to width x height and converts it to an BGR CVPixelBuffer.
     */
    public func pixelBuffer(width: Int, height: Int) -> CVPixelBuffer? {
        return pixelBuffer(width: width, height: height,
                           pixelFormatType: kCVPixelFormatType_32BGRA,
                           colorSpace: CGColorSpaceCreateDeviceRGB(),
                           alphaInfo: .noneSkipLast)
    }
    func pixelBuffer(width: Int, height: Int, pixelFormatType: OSType,
                     colorSpace: CGColorSpace, alphaInfo: CGImageAlphaInfo) -> CVPixelBuffer? {
        var maybePixelBuffer: CVPixelBuffer?
        let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
                     kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue]
        let status = CVPixelBufferCreate(kCFAllocatorDefault,
                                         width,
                                         height,
                                         pixelFormatType,
                                         attrs as CFDictionary,
                                         &maybePixelBuffer)
        
        guard status == kCVReturnSuccess, let pixelBuffer = maybePixelBuffer else {
            return nil
        }
        
        CVPixelBufferLockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))
        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer)
        
        guard let context = CGContext(data: pixelData,
                                      width: width,
                                      height: height,
                                      bitsPerComponent: 8,
                                      bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer),
                                      space: colorSpace,
                                      bitmapInfo: alphaInfo.rawValue)
            else {
                return nil
        }
        
        UIGraphicsPushContext(context)
        context.translateBy(x: 0, y: CGFloat(height))
        context.scaleBy(x: 1, y: -1)
        self.draw(in: CGRect(x: 0, y: 0, width: width, height: height))
        UIGraphicsPopContext()
        
        CVPixelBufferUnlockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))
        return pixelBuffer
    }

Thanks.

- Have I written custom code: Yes
- OS Platform and Distribution: Mac OS 10.13.3 High Sierra
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.1.0 on Mac (Tensorflow-Experimental on iOS)
- Python version: 3
- Bazel version: 0.13.0
- CUDA/cuDNN: N/A
- GPU model and Memory: N/A
- Exact command to reproduce: Single image prediction works well. But cannot predict multiple image.(Prediction)"
19903,Warm-starting moving averages (batch norm) as part of an estimator not possible,"I want to use a `tf.estimators.Estimator` to fine-tune a model that contains batch normalization (e.g. ResNet). To initialize the model, I use the new `WarmStartSettings` and pass it to the estimator's `warm_start_from` argument. Unfortunately, this will only warm-start trainable variables, and the `moving_mean` and `moving_variance` created by the batch normalization layer are not part of the trainable variables collection. Thus, the moving averages will not be warm-started.

Because of this problem, TensorFlow 1.9 (rc0) introduced the possibility to pass a list of variables to the `WarmStartSettings`. Unfortunately, when using estimators, this does not help because the variables are recreated all the time and not know at the position where the warm start settings have to be defined.

A possible solution might be to make it possible to pass a function to the `warm_start_from` argument of estimators that has access to the current graph and returns a `WarmStartSettings` object.

My current workaround is to specify a list of variable names rather than variables in the `WarmStartSettings`, but this is not exactly how it's supposed to be and comes with its own problems (e.g. getting the list of variable names before the model was built; I just use all the variable names that are saved in the checkpoint and exlude e.g. `global_step`, but this is problematic because it circumvents certain checks and assertions).
"
19901,[TF-serving-r1.7] How to compile Tensorflow-serving r1.7 with TensorRT,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  CentOS 7
- **TensorFlow installed from (source or binary)**: tensorflow-serving r1.7 source code
- **TensorFlow version (use command below)**: tensorflow-serving r1.7 source code
- **Python version**: Python2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: gcc5.3
- **CUDA/cuDNN version**: CUDA9.0, cuDNN7.0.5
- **GPU model and memory**: TitanXP 12GB
- **TensorRT Installed Version**: 4.0.4 (actually) 
- **Exact command to reproduce**: The way of compiling tf-serving 1.7 with TenosrRT, Please refer to my environment variables setting and compilation command as below.

****************************************
This issue is originally posted in repo tensorflow-serving (https://github.com/tensorflow/serving/issues/925). After several days of effort, I still failed to find a way to solve this problem. Hope someone can give me a clue of how to build tensorflow-serving 1.7 with tensorrt, because there are really few docs about this. (@samikama )
****************************************
I tried to compile the Tensorflow-serving r1.7 with TensorRT 4.0.4, and the compilation is successfully done.
```
At global scope:
cc1plus: warning: unrecognized command line option '-Wno-self-assign'
INFO: Elapsed time: 1452.421s, Critical Path: 479.68s
INFO: Build completed successfully, 11375 total actions
```

But when I start the service and load a TFTRT optimized model, I get error:
```
2018-06-07 17:41:40.910874: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:242] Loading SavedModel with tags: { serve }; from: /media/disk1/fordata/web_server/project/LdaBasedClassification_623_1.7/data/cate155_tftrt_frozen/1
2018-06-07 17:41:41.030117: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-06-07 17:41:41.283451: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2018-06-07 17:41:41.283514: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-06-07 17:41:41.601178: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-07 17:41:41.601253: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0 
2018-06-07 17:41:41.601273: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N 
2018-06-07 17:41:41.601561: I external/org_tensorflow/tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10970 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
2018-06-07 17:41:41.878689: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:291] SavedModel load for tags { serve }; Status: fail. Took 967809 microseconds.
2018-06-07 17:41:41.878771: E tensorflow_serving/util/retrier.cc:38] Loading servable: {name: inception_v3 version: 1} failed: Not found: Op type not registered 'TRTEngineOp' in binary running on bjpg-g180.yz02. Make sure the Op and Kernel are registered in the binary running in this process.

```

Looks like the TRTEngineOp is still not supported by this execution file. 
Though I'm not 100% sure about my way of compiling Tensorflow-serving 1.7 with TRT, but I think the compilation indeed searched and found the libnvinfer.so, etc, and also checked the TensorRT version is correct. So I don't know why the binary executive file still can't support TRTEngineOp. 

Here is my environment variables:
```
export TENSORRT_INSTALL_PATH=""/home/karafuto/TensorRT-3.0.4/lib""
export TF_TENSORRT_VERSION=4.0.4
export TENSORRT_LIB_PATH=""/home/karafuto/TensorRT-3.0.4/lib""
```
This is my compilation command:
```
sed -i.bak 's/@org_tensorflow\/\/third_party\/gpus\/crosstool/@local_config_cuda\/\/crosstool:toolchain/g' tools/bazel.rc      
bazel build  --config=cuda --action_env PYTHON_BIN_PATH=""/home/karafuto/dlpy72/dlpy/bin/python2.7"" TENSORRT_BIN_PATH=""/home/karafuto/TensorRT-3.0.4""  -c opt tensorflow_serving/...

```
I'm not sure whether my procedure is correct. Really few of docs can be found that talk about how to build the tensorflow-serving 1.7 with tensorrt. Any idea will be welcome? 

Thanks,
****************************************
PS:  The tensorrt source code is downloaded from NVIDIA official website, which tar file is named ""TensorRT-3.0.4.Ubuntu-14.04.5.x86_64.cuda-9.0.cudnn7.0.tar.gz"". The weird thing is, I unpacked the tar file and find the actually version is 4.0.4 not 3.0.4. So in the tensorflow-serving-r1.7, I need to set the variable TF_TENSORRT_VERSION=4.0.4 to avoid version check failure.

I encountered below 2 errors and solved them, so I think the bazel compilation shall indeed compiled the TensorRT. Post here as an evidence.
****************************************
This is the error when I set wrong TENSORRT_LIB_PATH, (can't find libnvinfer.so):
```
ERROR: error loading package 'tensorflow_serving/apis': Encountered error while reading extension file 'build_defs.bzl': no such package '@local_config_tensorrt//': Traceback (most recent call last):
	File ""/home/web_server/.cache/bazel/_bazel_web_server/7039d45003118564d66f2b06f1b7ea68/external/org_tensorflow/third_party/tensorrt/tensorrt_configure.bzl"", line 160
		auto_configure_fail(""TensorRT library (libnvinfer) v..."")
	File ""/home/web_server/.cache/bazel/_bazel_web_server/7039d45003118564d66f2b06f1b7ea68/external/org_tensorflow/third_party/gpus/cuda_configure.bzl"", line 210, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: TensorRT library (libnvinfer) version is not set.
```
*******************************************
This is when the TF_TENSORRT_VERSION is not the same with found libnvinfer:
```
ERROR: error loading package 'tensorflow_serving/apis': Encountered error while reading extension file 'build_defs.bzl': no such package '@local_config_tensorrt//': Traceback (most recent call last):
	File ""/home/web_server/.cache/bazel/_bazel_web_server/7039d45003118564d66f2b06f1b7ea68/external/org_tensorflow/third_party/tensorrt/tensorrt_configure.bzl"", line 167
		_trt_lib_version(repository_ctx, trt_install_path)
	File ""/home/web_server/.cache/bazel/_bazel_web_server/7039d45003118564d66f2b06f1b7ea68/external/org_tensorflow/third_party/tensorrt/tensorrt_configure.bzl"", line 87, in _trt_lib_version
		auto_configure_fail((""TensorRT library version detec...)))
	File ""/home/web_server/.cache/bazel/_bazel_web_server/7039d45003118564d66f2b06f1b7ea68/external/org_tensorflow/third_party/gpus/cuda_configure.bzl"", line 210, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: TensorRT library version detected from /media/disk1/fordata/web_server/project/xiaolun/TensorRT-3.0.4/include/NvInfer.h (4.0.4) does not match TF_TENSORRT_VERSION (3.0.4). To fix this rerun configure again.
```
"
19900,"""Address already in use"" occurs in Distributed Estimator.train_and_evaluator when loop training","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.18.0
- **Python version**:  2.7.13
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem

In Distributed ResNet, it need train the model many times, but when train in the second iteration, it fail for below:
```
{""created"":""@1528701271.960402221"",""description"":""No address added out of total 1 resolved"",""file"":""external/grpc/src/core/ext/transport/chttp2/server/chttp2_server.cc"",""file_line"":307,""referenced_errors"":[{""created"":""@1528701271.960399817"",""description"":""Failed to add any wildcard listeners"",""file"":""external/grpc/src/core/lib/iomgr/tcp_server_posix.cc"",""file_line"":345,""referenced_errors"":[{""created"":""@1528701271.960371584"",""description"":""OS Error"",""errno"":97,""file"":""external/grpc/src/core/lib/iomgr/socket_utils_common_posix.cc"",""file_line"":259,""os_error"":""Address family not supported by protocol"",""syscall"":""socket"",""target_address"":""[::]:50992""},{""created"":""@1528701271.960399232"",""description"":""Unable to configure socket"",""fd"":74,""file"":""external/grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc"",""file_line"":203,""referenced_errors"":[{""created"":""@1528701271.960393654"",""description"":""OS Error"",""errno"":98,""file"":""external/grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc"",""file_line"":176,""os_error"":""Address already in use"",""syscall"":""bind""}]}]}]}
```

It means that, the worker port 50992 not release when a new iteration start. The train iteration code show as fllow:


--------------------code begin----------------------------------------
```

train_spec=tf.estimator.TrainSpec(input_fn=input_fn_train,max_steps=1000)

eval_spec=tf.estimator.EvalSpec(input_fn=input_fn_eval,steps=1,throttle_secs=1,start_delay_secs=1)

for cycle_index in range(total_training_cycle):

    print(""start a train"")

    tf.logging.info('Starting a training cycle: %d/%d',cycle_index, total_training_cycle)

    tf.logging.info('Starting to evaluate.')

    tf.estimator.train_and_evaluate(classifier,train_spec,eval_spec)

    print(""end a train"")

```
--------------------code end----------------------------------------

"
19899,Documentation feature request: Explain Nesterov Accelerated Gradient implementation,"I haven't filled out the provided form because this is a feature request for the documentation.

The documentation for [`tf.train.MomentumOptimizer`](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer) offers a `use_nesterov` parameter on which the documentation says the following:

> `use_nesterov`: If True use Nesterov Momentum. See [Sutskever et al.,
> 2013](http://proceedings.mlr.press/v28/sutskever13.pdf). This
> implementation always computes gradients at the value of the
> variable(s) passed to the optimizer. Using Nesterov Momentum makes the
> variable(s) track the values called `theta_t + mu*v_t` in the paper.

The problem is that the linked paper outlines the normal NAG algorithm, which requires computation of a gradient at a different value to those provided (namely at the next step). This is not clarified in the documentation and led me to some confusion. I ended up [asking this question on StackOverflow](https://stackoverflow.com/questions/50774683/how-is-nesterovs-accelerated-gradient-descent-implemented-in-tensorflow) and cobbled together [an answer myself](https://stackoverflow.com/a/50774886/1613983), however I think the answer by `user1735003` is so complete that without too much wrangling it could greatly enhance the documentation:

[Answer by `user1735003`](https://stackoverflow.com/a/50778921/1613983)

Some clarification to the fact that tensorflow actually implements a modified version of the algorithm which is only correct under certain conditions would have been very helpful and would have saved me some time."
19898,"Win10 c++ Debug, LNK1189：Lib objects exceeded, pywrap_tensorflow_internal","**System information:**
· Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No

· OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10-x64

· TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git

· TensorFlow version (use command below): r1.4, r1.5, r1.6 r1.7 and r1.8, command :
v1.8's command : git checkout -b v1.8 -f origin/r1.8
v1.7's command : git checkout -b v1.7 -f origin/r1.7
v1.6's command : git checkout -b v1.6 -f origin/r1.6
and so on include v1.4 and v1.5

· Python version: Anaconda3 - python3.6

· Bazel version (if compiling from source): I used CMAKE 3.11.1

· GCC/Compiler version (if compiling from source): both Visual Studio 2015 and Visual Studio 2015' MSBuild

· CUDA/cuDNN version: CUDA9.0, cudnn-9.0-win10-7.1

· GPU model and memory: GTX-860m with 2Gb Memory

Exact command to reproduce:
""
D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=**Debug** -DSWIG_EXECUTABLE=D:/soft/TensorflowSoft/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/ProgramData/Anaconda3/python.exe -DPYTHON_LIBRARIES=D:/ProgramData/Anaconda3/libs/python36.lib -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""D:\soft\TensorflowSoft\cudnn"" -G ""Visual Studio 14 2015""

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> set PreferredToolArchitecture=x64

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> MSBuild /p:Configuration=Debug  ALL_BUILD.vcxproj
""

**Describe the problem :**
I build TensorFlow-CPU-r1.8-**Debug** successfully (win10-x64 + Anaconda3-python3.6 + VS2017(not VS2015) + tensorflow1.8 + cmake3.11.1 + SwigWin3.0.12).

But when I build tensorflow-GPU-**Debug** version(both tensorflow-r1.7 and r1.8), the only error has occurred: ""error LNK1189：library limit of 65535 objects exceeded, pywrap_tensorflow_internal"".
(If I use VS2017, it shows error: "" the compiler is not supported for CUDA 9.0"" , so I switch Visual Studio version to VS2015, and CMAKE command is work successfully.)

After that, I switched to lower versions TensorFlow-r1.6 to TensorFlow-r1.5, but Link error occurred：

“libprotobufd.lib(text_format.obj) : error LNK2019: unresolved external symbol __std_reverse_trivially_swappable_8 referenced in function ""void _
_cdecl std::_Reverse_unchecked1<class google::protobuf::Message const * *>(class google::protobuf::Message const * * const,class google::protobuf:
:Message const * * const,struct std::integral_constant<unsigned __int64,8>)"" (??$_Reverse_unchecked1@PEAPEBVMessage@protobuf@google@@@std@@yaxqeap
EBVMessage@protobuf@google@@0u?$integral_constant@_K$07@0@@z) [D:\tf\tensorflowGPU\tensorflow\contrib\cmake\build\proto_text.vcxproj]
libprotobufd.lib(wire_format.obj) : error LNK2001: unresolved external symbol __std_reverse_trivially_swappable_8 [D:\tf\tensorflowGPU\tensorflo
w\contrib\cmake\build\proto_text.vcxproj]
D:\tf\tensorflowGPU\tensorflow\contrib\cmake\build\Debug\proto_text.exe : fatal error LNK1120: 1 unresolved externals [D:\tf\tensorflowGPU\tenso
rflow\contrib\cmake\build\proto_text.vcxproj]”
"
19897,Feature Request: Propagate Gradients through map_fn,"I would like to request that `tf.map_fn` be capable of propagating gradients. @drpngx [suggested](https://github.com/tensorflow/tensorflow/issues/3972#issuecomment-396067543) opening a new issue and cc'ing @skye . My [specific use case](https://github.com/tensorflow/tensorflow/issues/19896) is applying the same convolutional layers to each step in a batched sequence of images i.e. along axis 1 for a tensor of shape `[batch_size, max_sequence_length, image_height, image_width, number_of_channels]`. However, I'm sure others would have use for this as well.

System information
OS Platform and Distribution: Ubuntu 16.04.4 LTS
TensorFlow installed from binary.
TensorFlow version: 'v1.8.0-2159-gea9fb80'
Python version: 2.7.12

Edit:
Have I written custom code: No.
Bazel version: 0.13.1
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: NA"
19896,How to Feed Batched Sequences of Images through Tensorflow conv2d,"This seems like a trivial question, but I've been unable to find the answer. Maybe I'm just bad at Googling, but I think the question is sufficiently common to justify an easily accessible answer.

I have batched sequences of images of shape:

`[batch_size, number_of_frames, frame_height, frame_width, number_of_channels]`

and I would like to pass each frame through a few convolutional and pooling layers. However, `tf.layers.conv2d` accepts 4D inputs of shape:

`[batch_size, frame_height, frame_width, number_of_channels]`

My first attempt was to use tf.map_fn over axis=1, but I discovered that [this function does not propagate gradients](https://github.com/tensorflow/tensorflow/issues/3972) - which isn't mentioned in the [documentation](https://www.tensorflow.org/api_docs/python/tf/map_fn) (but should be!).

My second attempt was to use `tf.unstack` over the first dimension and then use `tf.while_loop`. However, my batch_size and number_of_frames are dynamically determined (i.e. both are None), and `tf.unstack` raises `{ValueError} Cannot infer num from shape (?, ?, 30, 30, 3) if num is unspecified`. I tried specifying `num=tf.shape(observations)[1]`, but this raises `{TypeError} Expected int for argument 'num' not <tf.Tensor 'A2C/infer/strided_slice:0' shape=() dtype=int32>`.

What is the proper way to feed batched sequences of images through `conv2d`?

### System information
OS Platform and Distribution: Ubuntu 16.04.4 LTS
TensorFlow installed from binary.
TensorFlow version: 'v1.8.0-2159-gea9fb80'
Python version: 2.7.12
"
19895,Cmake build with GPU fails on Windows 10 with a MSB6006 error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 
- **TensorFlow installed from (source or binary)**: Source, from Git tag v1.8.0
- **TensorFlow version (use command below)**: 1.8 (Git tag v1.8.0)
- **Python version**: 3.5.5 (Anaconda Python)
- **Bazel version (if compiling from source)**: Cmake 3.11.3
- **GCC/Compiler version (if compiling from source)**: Visual Studio 2015 Update 3 (14.0.25431.01)
- **CUDA/cuDNN version**: CUDA 9.2, cuDNN 7.1
- **GPU model and memory**: Nvidia GeForce 940M
- **Exact command to reproduce**:
```
git clone https://github.com/tensorflow/tensorflow
....
git checkout v1.8.0
....
C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\vcvarsall.bat amd64

cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
 -DSWIG_EXECUTABLE=C:/Dev_Tools/TFBuild/tools/swigwin-3.0.12/swig.exe ^
 -DPYTHON_EXECUTABLE=C:/Users/UAMARTH/AppData/Local/Continuum/anaconda3/envs/tfbuild/python.exe ^
 -DPYTHON_LIBRARIES=C:/Users/UAMARTH/AppData/Local/Continuum/anaconda3/envs/tfbuild/libs/python35.lib ^
 -Dtensorflow_ENABLE_GPU=ON ^
 -Dtensorflow_CUDA_VERSION=9.2 ^
 -Dtensorflow_CUDNN_VERSION=7 ^
 -DCUDNN_HOME=""C:\Dev_Tools\TFBuild\tools\cudnn-9.2-windows10-x64-v7.1"" ^
 -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX


MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj
```

### Describe the problem
The build fails with a ""error MSB6006: ""cmd.exe"" exited with code 1"". Full error message below.
The line 259 of referred to in the error message points to a ""tensorflow\tensorflow\contrib\cmake\build\tf_python\tensorflow\tools\api\generator\api\keras\preprocessing\text\__init__.py"" file, which does not exist. The .......\preprocessing\text\ directory is empty.

### Source code / logs
```
""C:\Dev_Tools\TFBuild\tensorflow\tensorflow\contrib\cmake\build\tf_python_build_pip_package.vcxproj"" (default target) (
1) ->
""C:\Dev_Tools\TFBuild\tensorflow\tensorflow\contrib\cmake\build\tf_python_api.vcxproj"" (default target) (259) ->
(CustomBuild target) ->
  C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: ""cmd.exe"" e
xited with code 1. [C:\Dev_Tools\TFBuild\tensorflow\tensorflow\contrib\cmake\build\tf_python_api.vcxproj]

    19591 Warning(s)
    1 Error(s)

Time Elapsed 04:30:49.38
```
"
19893,“grp c++/grpc++.h”: No such file or directory ( D:\tensorflow-master\tensorflow\core\common_runtime\eager\context.cc),"
“D:\tensorflow-master\tensorflow\contrib\cmake\build\tf_tutorials_example_trainer.vcxproj”(默认目标) (1) ->
“D:\tensorflow-master\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj”(默认目标) (130) ->
(ClCompile 目标) ->
  D:\tensorflow-master\tensorflow/core/distributed_runtime/rpc/grpc_server_lib.h(21): fatal error C1083: 无法打开包括文件: “grp
c++/grpc++.h”: No such file or directory (编译源文件 D:\tensorflow-master\tensorflow\core\common_runtime\eager\context.cc) [
D:\tensorflow-master\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj]
  D:\tensorflow-master\tensorflow/core/distributed_runtime/rpc/grpc_server_lib.h(21): fatal error C1083: 无法打开包括文件: “grp
c++/grpc++.h”: No such file or directory (编译源文件 D:\tensorflow-master\tensorflow\core\common_runtime\eager\eager_operati
on.cc) [D:\tensorflow-master\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj]
  D:\tensorflow-master\tensorflow/core/distributed_runtime/rpc/grpc_server_lib.h(21): fatal error C1083: 无法打开包括文件: “grp
c++/grpc++.h”: No such file or directory (编译源文件 D:\tensorflow-master\tensorflow\core\common_runtime\eager\execute.cc) [
D:\tensorflow-master\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj]
  D:\tensorflow-master\tensorflow/core/distributed_runtime/rpc/grpc_server_lib.h(21): fatal error C1083: 无法打开包括文件: “grp
c++/grpc++.h”: No such file or directory (编译源文件 D:\tensorflow-master\tensorflow\core\common_runtime\eager\tensor_handle
.cc) [D:\tensorflow-master\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj]"
19892,distributed estrimator hang forever.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux
- **TensorFlow installed from (source or binary)**:  binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**:  2.7.13
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I ran the mnist code with estimator, It's ok when running in single process, but hang when running in 3 processes for distributed mode. The code (PS) is shown below. Notice that, worker should change the task.type in TF_CONFIG to 'worker', and chief should change to 'chief'.



### Source code / logs
import tensorflow as tf

import numpy as np

import pandas as pd

from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

import matplotlib.cm as cm

tf.logging.set_verbosity(tf.logging.INFO)

def load2():
    train = pd.read_csv('/tmp/train.csv')

    test = pd.read_csv('/tmp/test.csv')

    labels = train['label']

    images = train.iloc[:, 1:]

    image_size = 28

    train_ds, valid_ds, train_labels, valid_labels = train_test_split(images, labels, test_size=0.33, random_state=42)

    print len(train_ds)
    print len(valid_ds)
    print len(train_labels)
    print len(valid_labels)

    data = images

    train_ds, train_labels = reformat(train_ds, train_labels)
    valid_ds, valid_labels = reformat(valid_ds, valid_labels)
    test_ds, test_labels = reformat(test, train_labels[:len(test)])

    print('Training set', train_ds.shape, train_labels.shape)
    print('Validation set', valid_ds.shape, valid_labels.shape)
    print('Test set', test_ds.shape, test_labels.shape)


def reformat(dataset, labels):
    num_channels = 1
    num_labels = 10
    dataset = dataset.values.reshape(
        (-1, image_size, image_size, num_channels)).astype(np.float32)
    labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)
    return dataset, labels


def cnn_model_fn(features, labels, mode):
    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])
    conv1 = tf.layers.conv2d(
        inputs=input_layer,
        filters=32,
        kernel_size=[5, 5],
        padding=""same"",
        activation=tf.nn.relu
    )

    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)  # 14*14*32

    conv2 = tf.layers.conv2d(
        inputs=pool1,
        filters=64,
        kernel_size=[5, 5],
        padding='same',
        activation=tf.nn.relu
    )

    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)
    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])

    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)
    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)

    logits = tf.layers.dense(inputs=dropout, units=10)
    print '####', logits

    predictions = {
        'classes': tf.argmax(logits, axis=1),
        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')
    }

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)

    if mode == tf.estimator.ModeKeys.TRAIN:
        loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)
        train_op = optimizer.minimize(
            loss=loss,
            global_step=tf.train.get_global_step()
        )
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

def main(argvs):
    mnist = tf.contrib.learn.datasets.load_dataset(""mnist"")
    train_data = mnist.train.images
    print train_data.shape
    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)
    eval_data = mnist.test.images
    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)
    mnist_classifier = tf.estimator.Estimator(
        model_fn=cnn_model_fn, model_dir=""/tmp/mnist_convnet_model"")
    # Set up logging for predictions
    # Log the values in the ""Softmax"" tensor with label ""probabilities""
    tensors_to_log = {""probabilities"": ""softmax_tensor""}
    logging_hook = tf.train.LoggingTensorHook(
        tensors=tensors_to_log, every_n_iter=50)
    print 'labels: ', train_labels
    # Train the model
    train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": train_data},
        y=train_labels,
        batch_size=100,
        num_epochs=None,
        shuffle=True)
    mnist_classifier.train(
        input_fn=train_input_fn,
        steps=20000,
        hooks=[logging_hook])
    eval_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": eval_data},
        y=eval_labels,
        num_epochs=1,
        shuffle=False)


if __name__ == '__main__':
  import os,json
  os.environ['TF_CONFIG']=json.dumps({
      ""cluster"": {
        ""ps"": [
          ""127.0.0.1:34567""
        ],
        ""chief"": [
          ""127.0.0.1:34568""
        ],
        ""worker"": [
          ""127.0.0.1:34569""
        ]
      },
      ""task"": {
        ""index"": 0,
        ""type"": ""ps"" # optional: chief, ps, worker
      }
  })
  tf.app.run()`




WARNING:tensorflow:From ps_cnn_mnist.py:94: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data.
WARNING:tensorflow:From /home/yiguang.wyg/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/yiguang.wyg/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
WARNING:tensorflow:From /home/yiguang.wyg/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
WARNING:tensorflow:From /home/yiguang.wyg/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST-data/train-images-idx3-ubyte.gz
WARNING:tensorflow:From /home/yiguang.wyg/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
Extracting MNIST-data/train-labels-idx1-ubyte.gz
Extracting MNIST-data/t10k-images-idx3-ubyte.gz
Extracting MNIST-data/t10k-labels-idx1-ubyte.gz
WARNING:tensorflow:From /home/yiguang.wyg/tools/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
(55000, 784)
INFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'127.0.0.1:34567'], u'chief': [u'127.0.0.1:34568'], u'worker': [u'127.0.0.1:34569']}, u'task': {u'index': 0, u'type': u'ps'}}
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': u'ps', '_train_distribute': None, '_is_chief': False, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff7169d49d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://127.0.0.1:34567', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/mnist_convnet_model', '_global_id_in_cluster': 2, '_save_summary_steps': 100}
labels:  [7 3 4 ... 5 6 8]
INFO:tensorflow:Calling model_fn.
#### Tensor(""dense_1/BiasAdd:0"", shape=(100, 10), dtype=float32, device=/job:ps/task:0)
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized."
19890,Logits all reduced to very small value when training multi-label image classification,"```
Tensorflow version: 1.7-gpu
Operating system: ubuntu 16.04
```

I was training a multi-label image classification model (an image could have multiple labels, and the label is like `[1,0,0,0,1,0,0,1]` with variable number of 1s).

I have switched to the `sigmoid_cross_entropy_with_logits` like below:

```python
with slim.arg_scope(inception_resnet_v2_arg_scope()):
            logits, end_points = inception_resnet_v2(images, num_classes=dataset.num_classes, is_training=True)
         
        exclude = ['InceptionResnetV2/Logits', 'InceptionResnetV2/AuxLogits']
        variables_to_restore = slim.get_variables_to_restore(exclude=exclude)

        fp_labels = tf.cast(labels, tf.float32)
        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=fp_labels, logits=logits)
        
        total_loss = tf.losses.get_total_loss()  
        
        global_step = get_or_create_global_step()

        # Define your exponentially decaying learning rate
        lr = tf.train.exponential_decay(
            learning_rate=initial_learning_rate,
            global_step=global_step,
            decay_steps=decay_steps,
            decay_rate=learning_rate_decay_factor,
            staircase=True)

        # Now we can define the optimizer that takes on the learning rate
        optimizer = tf.train.AdamOptimizer(learning_rate=lr)

        # Create the train_op.
        train_op = slim.learning.create_train_op(total_loss, optimizer)
        
        def train_step(sess, train_op, global_step):
   
            # Check the time for each sess run
            start_time = time.time()
            total_loss, global_step_count, _ = sess.run([train_op, global_step, metrics_op])
            time_elapsed = time.time() - start_time

            # Run the logging to print some results
            logging.info('global step %s: loss: %.4f (%.2f sec/step)', global_step_count, total_loss, 
            time_elapsed)

            return total_loss, global_step_count

```

But when I started training the loss is decreasing very fast (from 0.5 to almost 0 in several minites), and all the logits value became almost zero for every image. 

I tried manual loss function implementation but also failed.

Any advice would be greatly appreciated! "
19889,"why tf.image.crop_to_bounding_box no accept float [0,1] input","By default TF prefer [0,1] range box coordinates, however the `tf.image.crop_to_bounding_box` only accept integer box coordinates input, while `tf.image.crop_and_resize` accept [0,1] range box coordinates, why?"
19888,tensorflow/tensorflow/core/framework directory  not found BUILD file .,why ， tensorflow/tensorflow/core/framework directory  not found BUILD file . ？ 
19887,Bug in nn.conv3d_transpose function?,"**System information:**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS Sierra 10.12.5
TensorFlow installed from (source or binary):Binary
TensorFlow version (use command below):1.8
Python version:3.6.2
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:None
GPU model and memory:CPU
Exact command to reproduce:

**Problem Description:**

When I am using nn.conv3d_transpose function, I found there is probably a bug in the code? 
In line 1461 of file nn.ops.py:

<img width=""742"" alt=""2"" src=""https://user-images.githubusercontent.com/19757981/41201350-32d1d18e-6cae-11e8-9ef9-505e071e0d28.png"">
It compares output_shape[4] with filter shape (which both should be the channel number). But if we use different data format such as NCDHW, the channel number should be represented by output_shape[1] right?  So I assume it should be output_shape[axis] here?

I also compared the 3d function with 2d function: nn.conv2d_transpose and it uses output_shape[axis] at the same place:

<img width=""740"" alt=""1"" src=""https://user-images.githubusercontent.com/19757981/41201372-90735894-6cae-11e8-8a12-a8350d2f3579.png"">


Thanks.
"
19886,saving tensorflow models in hdf5,"Hi Everyone

While using tensorflow, how to save the model in hdf5 file format (like keras does using model.save) .  

Most of the documentation I found online is for saving models in tensorflow with a checkpoint using saver.save

While trying 
tf.keras.models.save_model('model.h5',filepath='Desktop/')
in my mnist code in tensorflow, I get the following error

OSError: Unable to create file (unable to open file: name = 'Desktop/', errno = 22, error message = 'Invalid argument', flags = 13, o_flags = 302)"
19885,Tf summary merge all may cause issues,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**: N/A
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**:N/A



There are cases in which separate summaries would be good to have, e.g. for a graph that has more than one networks that are somewhat independent. 

In this case, having individual summaries so that they can be individually used is helpful. Most times , scalars + data (images or text) are needed to be logged, so calling `tf.summary.merge` and having to maintain a handle on all the summary requires a lot of code. 

calling `tf.summary.merge_all()` requires the data to be present for ALL possible summaries, which may introduce bugs and cause unnecessary computation. 

My proposal is to use a context manager and add the summaries to that context, which can be merged automatically. 

Somewhat along the lines of : 

```python
with tf.merged_summaries() as merged: 
    merged.add_summary(tf.summary.scalar('dropout_keep_probability', keep_prob)) # add scalar
    merged.add_summary(tf.summary.Image('dropout_keep_probability', some_image)) # add image
```
then after this block is done , `merged` can be used somewhat like this : 

```python
training_only_summary_op = merged.get_op()  # will call `tf.summary.merge()` internally 
```

I can make a pull request for this if this idea is worth exploring 
"
19884,Providing resource variables to feed_dict can be confusing,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:Binary
- **TensorFlow version (use command below)**:1.8
- **Python version**:3.6.2 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:None
- **GPU model and memory**:CPU
- **Exact command to reproduce**:

### Describe the problem
According to the documentation, the Tf.contrib.eager has classes that can be used both in Eager and Graph modes. However the results are not consistent when we pass feed_dict to a variable.

### Source code / logs

```
import tensorflow as tf
tfe = tf
x = tfe.Variable(4)
y = x * x
with tf.Session() as sess:
     sess.run(tf.global_variables_initializer())
     print(sess.run(y, feed_dict={x: 15}))  # Prints 225 which is correct

tfe = tf.contrib.eager
x = tfe.Variable(4)
y = x * x

with tf.Session() as sess:
     sess.run(tf.global_variables_initializer())
     print(sess.run(y, feed_dict={x: 15}))  #Prints 16, which is not consistent with 225 above

```"
19883,tf-nightly: cannot import tensorflow,"As of today (2018-06-09), the reproduction steps are:

```sh
pip install -U tf-nightly
```

```python
import tensorflow as tf
```

The error stack looks like:

> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/__init__.py in <module>()
>      20 
>      21 # pylint: disable=g-bad-import-order
> ---> 22 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
>      23 from . import app
>      24 from . import bitwise
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/__init__.py in <module>()
>      79 # Bring in subpackages.
>      80 from tensorflow.python import data
> ---> 81 from tensorflow.python import keras
>      82 from tensorflow.python.estimator import estimator_lib as estimator
>      83 from tensorflow.python.feature_column import feature_column_lib as feature_column
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/__init__.py in <module>()
>      22 from __future__ import print_function
>      23 
> ---> 24 from tensorflow.python.keras import activations
>      25 from tensorflow.python.keras import applications
>      26 from tensorflow.python.keras import backend
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/activations/__init__.py in <module>()
>      20 
>      21 # Activation functions.
> ---> 22 from tensorflow.python.keras._impl.keras.activations import elu
>      23 from tensorflow.python.keras._impl.keras.activations import hard_sigmoid
>      24 from tensorflow.python.keras._impl.keras.activations import linear
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/__init__.py in <module>()
>      19 from __future__ import print_function
>      20 
> ---> 21 from tensorflow.python.keras._impl.keras import activations
>      22 from tensorflow.python.keras._impl.keras import applications
>      23 from tensorflow.python.keras._impl.keras import backend
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/activations.py in <module>()
>      21 import six
>      22 
> ---> 23 from tensorflow.python.keras._impl.keras import backend as K
>      24 from tensorflow.python.keras._impl.keras.utils.generic_utils import deserialize_keras_object
>      25 from tensorflow.python.layers.base import Layer
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/backend.py in <module>()
>      35 from tensorflow.python.framework import ops
>      36 from tensorflow.python.framework import sparse_tensor
> ---> 37 from tensorflow.python.layers import base as tf_base_layers
>      38 from tensorflow.python.ops import array_ops
>      39 from tensorflow.python.ops import clip_ops
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/layers/base.py in <module>()
>      23 from tensorflow.python.framework import dtypes
>      24 from tensorflow.python.framework import ops
> ---> 25 from tensorflow.python.keras.engine import base_layer
>      26 from tensorflow.python.ops import variable_scope as vs
>      27 from tensorflow.python.ops import variables as tf_variables
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/engine/__init__.py in <module>()
>      19 from __future__ import print_function
>      20 
> ---> 21 from tensorflow.python.keras.engine.base_layer import InputSpec
>      22 from tensorflow.python.keras.engine.base_layer import Layer
>      23 from tensorflow.python.keras.engine.input_layer import Input
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py in <module>()
>      31 from tensorflow.python.framework import tensor_shape
>      32 from tensorflow.python.framework import tensor_util
> ---> 33 from tensorflow.python.keras import backend
>      34 from tensorflow.python.keras import constraints
>      35 from tensorflow.python.keras import initializers
> 
> ~/venv_cpu_py3/lib/python3.5/site-packages/tensorflow/python/keras/backend/__init__.py in <module>()
>      20 
>      21 # pylint: disable=redefined-builtin
> ---> 22 from tensorflow.python.keras._impl.keras.backend import abs
>      23 from tensorflow.python.keras._impl.keras.backend import all
>      24 from tensorflow.python.keras._impl.keras.backend import any
>
> ImportError: cannot import name 'abs'

Note that the same error does *not* happen in tensorflow 1.8.0 or 1.9.0rc0."
19881,Unable to install Tensorflow following documentation,"### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Unable to install Tensorflow using the official documentation.  On the documentation its says install VirtualEnv. https://www.tensorflow.org/install/install_mac.  When you folllow the first instruction:
`sudo easy_install pip` it returns the following error message: 
```Not a recognized archive type: pip```

Its not clear what the correct method to install - but it should be indicated in the documentation to not confuse new users. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19880,tf.image.resize_* gives negative results,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:  v1.8.0-7-g3b85959 1.8.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.14.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
I am trying to segment images using Pascal VOC 2012. I converted indexed pngs to grayscale, replaced pixels with value 255 with 0 and written them to tfrecord. Then when reading image with tf.data.Dataset i want to resize all images to constant scale at min dim and then randomly crop to square. Problem is that when i am resizing label tensor with tf.image.resize_bicubic some values are negative but in input tensor threre is no negative values.

**UPD**: Bicubc not only gives negative values but also changes it where it should not
Look at the right image:
![image](https://user-images.githubusercontent.com/13236173/41194731-12a93bc0-6c29-11e8-8793-2b40f7fa6e0d.png)


### Source code / logs
Here is run log:
```
uint8_label_after_decode[0]
uint8_label_after_decode[0]
uint8_label_after_decode[0]
uint8_label_after_decode[0]
uint8_label_after_resize[-2.43790507]
uint8_label_after_resize[-0.208821028]
uint8_label_after_resize[-3.43527746]
uint8_label_after_resize[-2.6129365]
2018-06-09 19:45:09.765736: W tensorflow/core/framework/op_kernel.cc:1318] OP_REQUIRES failed at sparse_xent_op.cc:90 : Invalid argument: Received a label value of -2 which is outside the valid range of [0, 21). 
```

```
def resize_image_keep_aspect_ratio(image, max_height, max_width, use_min_ratio, use_nn_interpolation=False):
    def compute_new_dims(height, width, max_height, max_width, use_min_ratio):
        # If use_min_ratio is set to true than image will be resized to max of smaller dim
        height_float = tf.cast(height, tf.float32)
        width_float = tf.cast(width, tf.float32)
        max_height_float = tf.cast(max_height, tf.float32)
        max_width_float = tf.cast(max_width, tf.float32)

        height_ratio = height_float / max_height_float
        widht_ratio = width_float / max_width_float

        if use_min_ratio:
            ratio = tf.minimum(height_ratio, widht_ratio)
        else:
            ratio = tf.maximum(height_ratio, widht_ratio)

        new_height = tf.cast(tf.floor(height_float / ratio), tf.int32)
        new_width = tf.cast(tf.floor(width_float / ratio), tf.int32)

        return (new_height, new_width)

    shape = tf.shape(image)
    height = shape[0]
    width = shape[1]

    new_height_and_width = compute_new_dims(height, width, max_height, max_width, use_min_ratio=use_min_ratio)

    image = tf.expand_dims(image, 0)
    if use_nn_interpolation:
        image = tf.image.resize_nearest_neighbor(image, tf.stack(new_height_and_width), align_corners=True)
    else:
        image = tf.image.resize_bicubic(image, tf.stack(new_height_and_width), align_corners=True)
    image = tf.squeeze(image, [0])
    return image


# Here I am decoding image in tf.data.Dataset
label = tf.image.decode_image(example_parsed['label'], channels=1)
label = tf.Print(label, [tf.reduce_min(label)], 'uint8_label_after_decode')
label = tf.cast(label, tf.float32)
label = resize_image_keep_aspect_ratio(label, image_size[0], image_size[1], use_min_ratio=True, 
  use_nn_interpolation=False)
label = tf.Print(label, [tf.reduce_min(label)], 'uint8_label_after_resize')
image_and_label = tf.concat([image, label], axis=2)
cropped_image_and_label = tf.random_crop(image_and_label, [image_size[0], image_size[1], 4])
image, label = tf.split(cropped_image_and_label, [3, 1], axis=2)
image = tf.cast(image, float_type) * (2.0 / 255.0) - 1.0
label = tf.cast(label, tf.int64)
```"
19879,tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM,"I am not sure if my GPU is insufficient or not.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
    Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
    Windows 8.1
- **TensorFlow installed from (source or binary)**:

   binary

- **TensorFlow version (use command below)**:
     b'v1.8.0-0-g93bc2e2072' 1.8.0

- **Python version**: 
Python 3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
9.0 / **cudnn-9.0-windows7-x64-v7**


- **GPU model and memory**:
NVIDIA GT 640
Standard Memory Config | 2048 MB
-- | --



- **Exact command to reproduce**:

Code I am running is exactly https://github.com/mohanr/Machine-Learning/blob/master/Generative%20Adversarial%20Networks/gan.py

But I also add

config = tf.ConfigProto()
config.gpu_options.allow_growth = True
config.gpu_options.per_process_gpu_memory_fraction = 0.4
sess = tf.Session(config=config)


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

The logs indicate that there isn't memory. But I couldn't describe it as I am not an expert.

### Source code / logs
2018-06-09 22:00:47.481495: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-06-09 22:00:47.666325: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1356] Found device 0 with properties: 
name: GeForce GT 640 major: 3 minor: 0 memoryClockRate(GHz): 0.797
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.63GiB
2018-06-09 22:00:47.666754: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1435] Adding visible gpu devices: 0
2018-06-09 22:00:47.924601: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-06-09 22:00:47.924881: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:929]      0 
2018-06-09 22:00:47.925054: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:942] 0:   N 
2018-06-09 22:00:47.925320: I T:\src\github\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1638 MB memory) -> physical GPU (device: 0, name: GeForce GT 640, pci bus id: 0000:01:00.0, compute capability: 3.0)
(?, 256, 256, 3)
2018-06-09 22:00:52.119015: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-09 22:00:52.780020: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-09 22:00:53.025879: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.32GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-09 22:01:01.698819: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 640.00MiB.  Current allocation summary follows.
2018-06-09 22:01:01.700407: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (256): 	Total Chunks: 63, Chunks in use: 63. 15.8KiB allocated for chunks. 15.8KiB in use in bin. 4.9KiB client-requested in use in bin.
2018-06-09 22:01:01.702825: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (512): 	Total Chunks: 13, Chunks in use: 13. 6.8KiB allocated for chunks. 6.8KiB in use in bin. 6.5KiB client-requested in use in bin.
2018-06-09 22:01:01.704767: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (1024): 	Total Chunks: 9, Chunks in use: 9. 9.3KiB allocated for chunks. 9.3KiB in use in bin. 9.0KiB client-requested in use in bin.
2018-06-09 22:01:01.706630: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (2048): 	Total Chunks: 4, Chunks in use: 4. 14.0KiB allocated for chunks. 14.0KiB in use in bin. 13.5KiB client-requested in use in bin.
2018-06-09 22:01:01.708750: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (4096): 	Total Chunks: 5, Chunks in use: 5. 20.0KiB allocated for chunks. 20.0KiB in use in bin. 20.0KiB client-requested in use in bin.
2018-06-09 22:01:01.710645: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.712622: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (16384): 	Total Chunks: 5, Chunks in use: 4. 120.0KiB allocated for chunks. 96.0KiB in use in bin. 96.0KiB client-requested in use in bin.
2018-06-09 22:01:01.714509: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (32768): 	Total Chunks: 1, Chunks in use: 0. 36.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.716503: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (65536): 	Total Chunks: 8, Chunks in use: 8. 552.0KiB allocated for chunks. 552.0KiB in use in bin. 544.0KiB client-requested in use in bin.
2018-06-09 22:01:01.718590: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (131072): 	Total Chunks: 11, Chunks in use: 11. 1.38MiB allocated for chunks. 1.38MiB in use in bin. 1.38MiB client-requested in use in bin.
2018-06-09 22:01:01.720586: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (262144): 	Total Chunks: 1, Chunks in use: 0. 384.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.722504: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (524288): 	Total Chunks: 4, Chunks in use: 4. 2.10MiB allocated for chunks. 2.10MiB in use in bin. 2.00MiB client-requested in use in bin.
2018-06-09 22:01:01.724539: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.726418: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (2097152): 	Total Chunks: 1, Chunks in use: 1. 2.50MiB allocated for chunks. 2.50MiB in use in bin. 2.50MiB client-requested in use in bin.
2018-06-09 22:01:01.727636: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (4194304): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.728533: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (8388608): 	Total Chunks: 3, Chunks in use: 3. 39.81MiB allocated for chunks. 39.81MiB in use in bin. 37.50MiB client-requested in use in bin.
2018-06-09 22:01:01.729490: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (16777216): 	Total Chunks: 2, Chunks in use: 1. 34.75MiB allocated for chunks. 16.00MiB in use in bin. 12.50MiB client-requested in use in bin.
2018-06-09 22:01:01.730439: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (33554432): 	Total Chunks: 1, Chunks in use: 0. 47.34MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.731351: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.732233: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (134217728): 	Total Chunks: 1, Chunks in use: 0. 128.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2018-06-09 22:01:01.733148: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:630] Bin (268435456): 	Total Chunks: 3, Chunks in use: 1. 1.25GiB allocated for chunks. 640.00MiB in use in bin. 640.00MiB client-requested in use in bin.
2018-06-09 22:01:01.734096: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:646] Bin for 640.00MiB was 256.00MiB, Chunk State: 
2018-06-09 22:01:01.734682: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:652]   Size: 256.00MiB | Requested Size: 196.89MiB | in_use: 0
2018-06-09 22:01:01.735323: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:652]   Size: 384.00MiB | Requested Size: 216.28MiB | in_use: 0, prev:   Size: 640.00MiB | Requested Size: 640.00MiB | in_use: 1
2018-06-09 22:01:01.736201: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60000 of size 1280
2018-06-09 22:01:01.736747: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60500 of size 256
2018-06-09 22:01:01.737303: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60600 of size 256
2018-06-09 22:01:01.737855: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60700 of size 256
2018-06-09 22:01:01.738393: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60800 of size 256
2018-06-09 22:01:01.738929: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60900 of size 256
2018-06-09 22:01:01.739470: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60A00 of size 256
2018-06-09 22:01:01.740032: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C60B00 of size 3584
2018-06-09 22:01:01.740592: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C61900 of size 256
2018-06-09 22:01:01.741145: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C61A00 of size 256
2018-06-09 22:01:01.741715: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C61B00 of size 256
2018-06-09 22:01:01.742269: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C61C00 of size 73728
2018-06-09 22:01:01.742820: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C73C00 of size 256
2018-06-09 22:01:01.743368: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C73D00 of size 256
2018-06-09 22:01:01.743919: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C73E00 of size 1024
2018-06-09 22:01:01.744454: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C74200 of size 65536
2018-06-09 22:01:01.745001: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84200 of size 256
2018-06-09 22:01:01.745556: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84300 of size 256
2018-06-09 22:01:01.746094: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84400 of size 256
2018-06-09 22:01:01.746639: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84500 of size 1024
2018-06-09 22:01:01.747178: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84900 of size 256
2018-06-09 22:01:01.747734: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84A00 of size 256
2018-06-09 22:01:01.748285: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500C84B00 of size 131072
2018-06-09 22:01:01.748741: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CA4B00 of size 131072
2018-06-09 22:01:01.749387: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC4B00 of size 256
2018-06-09 22:01:01.749938: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC4C00 of size 256
2018-06-09 22:01:01.750481: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC4D00 of size 256
2018-06-09 22:01:01.751026: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC4E00 of size 512
2018-06-09 22:01:01.751579: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC5000 of size 512
2018-06-09 22:01:01.752165: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC5200 of size 512
2018-06-09 22:01:01.752704: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC5400 of size 256
2018-06-09 22:01:01.753251: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC5500 of size 4096
2018-06-09 22:01:01.753790: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC6500 of size 256
2018-06-09 22:01:01.754337: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC6600 of size 256
2018-06-09 22:01:01.754882: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC6700 of size 256
2018-06-09 22:01:01.755435: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC6800 of size 512
2018-06-09 22:01:01.755981: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC6A00 of size 256
2018-06-09 22:01:01.756520: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500CC6B00 of size 627968
2018-06-09 22:01:01.756996: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000500D60000 of size 16777216
2018-06-09 22:01:01.757281: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D60000 of size 256
2018-06-09 22:01:01.757550: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D60100 of size 256
2018-06-09 22:01:01.757825: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D60200 of size 256
2018-06-09 22:01:01.758105: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D60300 of size 24576
2018-06-09 22:01:01.758347: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66300 of size 256
2018-06-09 22:01:01.758588: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66400 of size 256
2018-06-09 22:01:01.758818: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66500 of size 256
2018-06-09 22:01:01.759166: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66600 of size 256
2018-06-09 22:01:01.759406: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66700 of size 256
2018-06-09 22:01:01.759641: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66800 of size 256
2018-06-09 22:01:01.759915: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66900 of size 256
2018-06-09 22:01:01.760163: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66A00 of size 256
2018-06-09 22:01:01.760391: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D66B00 of size 3584
2018-06-09 22:01:01.760623: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D67900 of size 3584
2018-06-09 22:01:01.760884: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D68700 of size 1024
2018-06-09 22:01:01.761132: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D68B00 of size 256
2018-06-09 22:01:01.761369: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D68C00 of size 256
2018-06-09 22:01:01.761603: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D68D00 of size 256
2018-06-09 22:01:01.761841: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D68E00 of size 256
2018-06-09 22:01:01.762122: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D68F00 of size 256
2018-06-09 22:01:01.762356: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69000 of size 256
2018-06-09 22:01:01.762593: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69100 of size 256
2018-06-09 22:01:01.762829: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69200 of size 256
2018-06-09 22:01:01.763127: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69300 of size 256
2018-06-09 22:01:01.763366: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69400 of size 256
2018-06-09 22:01:01.763606: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69500 of size 256
2018-06-09 22:01:01.763859: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69600 of size 256
2018-06-09 22:01:01.764145: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69700 of size 256
2018-06-09 22:01:01.764386: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D69800 of size 73728
2018-06-09 22:01:01.764625: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D7B800 of size 73728
2018-06-09 22:01:01.764839: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D8D800 of size 73728
2018-06-09 22:01:01.765172: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D9F800 of size 1024
2018-06-09 22:01:01.765410: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501D9FC00 of size 1024
2018-06-09 22:01:01.765655: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DA0000 of size 1024
2018-06-09 22:01:01.765943: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DA0400 of size 65536
2018-06-09 22:01:01.766192: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DB0400 of size 65536
2018-06-09 22:01:01.766427: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DC0400 of size 4096
2018-06-09 22:01:01.766663: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DC1400 of size 24576
2018-06-09 22:01:01.766950: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000501DC7400 of size 36864
2018-06-09 22:01:01.767188: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD0400 of size 256
2018-06-09 22:01:01.767432: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD0500 of size 256
2018-06-09 22:01:01.767668: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD0600 of size 256
2018-06-09 22:01:01.767946: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD0700 of size 1024
2018-06-09 22:01:01.768188: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD0B00 of size 1024
2018-06-09 22:01:01.768426: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD0F00 of size 256
2018-06-09 22:01:01.768672: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD1000 of size 768
2018-06-09 22:01:01.768950: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DD1300 of size 131072
2018-06-09 22:01:01.769195: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501DF1300 of size 131072
2018-06-09 22:01:01.769432: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501E11300 of size 131072
2018-06-09 22:01:01.769674: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501E31300 of size 131072
2018-06-09 22:01:01.769978: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501E51300 of size 131072
2018-06-09 22:01:01.770220: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501E71300 of size 131072
2018-06-09 22:01:01.770463: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000501E91300 of size 15527168
2018-06-09 22:01:01.770708: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000502D60000 of size 131072
2018-06-09 22:01:01.771008: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000502D80000 of size 131072
2018-06-09 22:01:01.771255: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000502DA0000 of size 256
2018-06-09 22:01:01.771500: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000502DA0100 of size 256
2018-06-09 22:01:01.771740: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000502DA0200 of size 13107200
2018-06-09 22:01:01.772027: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20200 of size 256
2018-06-09 22:01:01.772267: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20300 of size 256
2018-06-09 22:01:01.772505: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20400 of size 256
2018-06-09 22:01:01.772744: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20500 of size 512
2018-06-09 22:01:01.773014: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20700 of size 512
2018-06-09 22:01:01.773257: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20900 of size 512
2018-06-09 22:01:01.773491: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20B00 of size 512
2018-06-09 22:01:01.773722: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20D00 of size 512
2018-06-09 22:01:01.774009: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A20F00 of size 256
2018-06-09 22:01:01.774190: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A21000 of size 256
2018-06-09 22:01:01.774394: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000503A21100 of size 524288
2018-06-09 22:01:01.774629: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000503AA1100 of size 19656448
2018-06-09 22:01:01.774861: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D60000 of size 256
2018-06-09 22:01:01.775296: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D60100 of size 4096
2018-06-09 22:01:01.775477: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D61100 of size 4096
2018-06-09 22:01:01.775656: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D62100 of size 4096
2018-06-09 22:01:01.775836: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D63100 of size 512
2018-06-09 22:01:01.776253: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D63300 of size 512
2018-06-09 22:01:01.776449: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D63500 of size 512
2018-06-09 22:01:01.776642: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504D63700 of size 524288
2018-06-09 22:01:01.776839: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504DE3700 of size 524288
2018-06-09 22:01:01.777219: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504E63700 of size 131072
2018-06-09 22:01:01.777400: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000504E83700 of size 393216
2018-06-09 22:01:01.777581: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EE3700 of size 256
2018-06-09 22:01:01.777759: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EE3800 of size 256
2018-06-09 22:01:01.777977: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EE3900 of size 256
2018-06-09 22:01:01.778177: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EE3A00 of size 24576
2018-06-09 22:01:01.778396: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EE9A00 of size 24576
2018-06-09 22:01:01.778615: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000504EEFA00 of size 24576
2018-06-09 22:01:01.778834: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EF5A00 of size 3584
2018-06-09 22:01:01.779416: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504EF6800 of size 73728
2018-06-09 22:01:01.779665: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000504F08800 of size 13107200
2018-06-09 22:01:01.779921: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000505B88800 of size 2621440
2018-06-09 22:01:01.780190: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000505E08800 of size 49641472
2018-06-09 22:01:01.780438: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000508F60000 of size 134217728
2018-06-09 22:01:01.780678: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000510F60000 of size 268435456
2018-06-09 22:01:01.780961: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Chunk at 0000000521260000 of size 671088640
2018-06-09 22:01:01.781212: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:665] Free  at 0000000549260000 of size 402653184
2018-06-09 22:01:01.781460: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:671]      Summary of in-use Chunks by size: 
2018-06-09 22:01:01.781702: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 63 Chunks of size 256 totalling 15.8KiB
2018-06-09 22:01:01.781999: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 12 Chunks of size 512 totalling 6.0KiB
2018-06-09 22:01:01.782236: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 768 totalling 768B
2018-06-09 22:01:01.782469: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 8 Chunks of size 1024 totalling 8.0KiB
2018-06-09 22:01:01.782715: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 1280 totalling 1.3KiB
2018-06-09 22:01:01.782979: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 4 Chunks of size 3584 totalling 14.0KiB
2018-06-09 22:01:01.783221: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 5 Chunks of size 4096 totalling 20.0KiB
2018-06-09 22:01:01.783468: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 4 Chunks of size 24576 totalling 96.0KiB
2018-06-09 22:01:01.783714: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 3 Chunks of size 65536 totalling 192.0KiB
2018-06-09 22:01:01.784012: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 5 Chunks of size 73728 totalling 360.0KiB
2018-06-09 22:01:01.784259: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 11 Chunks of size 131072 totalling 1.38MiB
2018-06-09 22:01:01.784509: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 3 Chunks of size 524288 totalling 1.50MiB
2018-06-09 22:01:01.784748: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 627968 totalling 613.3KiB
2018-06-09 22:01:01.785036: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 2621440 totalling 2.50MiB
2018-06-09 22:01:01.785281: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 2 Chunks of size 13107200 totalling 25.00MiB
2018-06-09 22:01:01.785523: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 15527168 totalling 14.81MiB
2018-06-09 22:01:01.785770: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 16777216 totalling 16.00MiB
2018-06-09 22:01:01.786086: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:674] 1 Chunks of size 671088640 totalling 640.00MiB
2018-06-09 22:01:01.786348: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:678] Sum Total of in-use chunks: 702.48MiB
2018-06-09 22:01:01.786587: I T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:680] Stats: 
Limit:                  1717986918
InUse:                   736602368
MaxInUse:               1369154816
NumAllocs:                     242
MaxAllocSize:            671088640

2018-06-09 22:01:01.787109: W T:\src\github\tensorflow\tensorflow\core\common_runtime\bfc_allocator.cc:279] ******___________________________*******************************************________________________
2018-06-09 22:01:01.787472: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1318] OP_REQUIRES failed at conv_grad_input_ops.cc:924 : Resource exhausted: OOM when allocating tensor with shape[40,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 1322, in _do_call
    return fn(*args)
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[40,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[Node: generator/conv2d_transpose/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](generator/conv2d_transpose/conv2d_transpose-0-VecPermuteNHWCToNCHW-LayoutOptimizer/_51, generator/conv2d_transpose/kernel/read, generator/conv2d_transpose/conv2d_transpose-2-TransposeNHWCToNCHW-LayoutOptimizer)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[Node: Mean_1/_123 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_357_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/spatial/PycharmProjects/TensorFlow/gan.py"", line 166, in <module>
    main()
  File ""C:/Users/spatial/PycharmProjects/TensorFlow/gan.py"", line 162, in main
    train()
  File ""C:/Users/spatial/PycharmProjects/TensorFlow/gan.py"", line 148, in train
    summary,_ = sess.run([merge,D_optimizer], feed_dict={Z : samplefromuniformdistribution(20,100), X: X_batch, keep_prob: keep_prob_value, is_training:True})
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 900, in run
    run_metadata_ptr)
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 1316, in _do_run
    run_metadata)
  File ""C:\Anaconda3\envs\ame\lib\site-packages\tensorflow\python\client\session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[40,64,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[Node: generator/conv2d_transpose/conv2d_transpose = Conv2DBackpropInput[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 1, 2, 2], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](generator/conv2d_transpose/conv2d_transpose-0-VecPermuteNHWCToNCHW-LayoutOptimizer/_51, generator/conv2d_transpose/kernel/read, generator/conv2d_transpose/conv2d_transpose-2-TransposeNHWCToNCHW-LayoutOptimizer)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[Node: Mean_1/_123 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_357_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.


"
19877,Incompatibility between Estimator evaluation and BestExporter in 1.9.0-rc0 (cherry-pick request),"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: `1.9.0-rc0`
- **Python version**:  2.7
- **Bazel version**: N/A
- **GCC/Compiler version**: N/A
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: GTX 1060 (6GB)
- **Exact command to reproduce**: N/A

### Describe the problem
Sorry if that is already planned, but this fix https://github.com/tensorflow/tensorflow/commit/ece5f512538f66b69db52b8a5b6f9669ae10a3d9 should be part of the 1.9 release for the `tf.estimator.BestExporter` to work. The incompatibility was introduced by https://github.com/tensorflow/tensorflow/commit/b183563d0bfed9fce2b623b3bff3fa3bdeccad54 (released in `1.9.0-rc0`) which writes the checkpoint path in the event file, a case not handled by the `BestExporter` that always fails with error below.

### Source code / logs
```text
  File ""<python>/local/lib/python2.7/site-packages/tensorflow/python/estimator/exporter.py"", line 156, in _loss_smaller
    'current_eval_result cannot be empty or no loss is found in it.')
ValueError: current_eval_result cannot be empty or no loss is found in it.
```

Thanks!"
19876,tf.feature_column.indicator_column lack of hash_bucket conflict resolver,"Here is my code:

```

import tensorflow as tf

features = {'color': [['R','A'], ['A','G'], ['A','G'], ['G','B'],['B','R']],
            'weight': [[1.0,2.0], [0.1,4.0], [5.0,1.0], [8.0,7.0],[3.0,2.0]]}

color_feature = tf.feature_column.categorical_column_with_hash_bucket(
                key = ""color"",
                hash_bucket_size = 10,
                dtype=tf.string)

column = tf.feature_column.weighted_categorical_column(color_feature, 'weight',dtype = tf.float32)

indicator = tf.feature_column.indicator_column(column)
tensor = tf.feature_column.input_layer(features, [indicator])

with tf.Session() as session:
    session.run(tf.global_variables_initializer())
    session.run(tf.tables_initializer())
    print(session.run([tensor]))

```

then, got the error as follow:



```
D:\ProgramData\Anaconda3\python.exe E:/wnd_test/test.py
D:\ProgramData\Anaconda3\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2018-06-09 20:54:36.683625: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2018-06-09 20:54:36.699225: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1318] OP_REQUIRES failed at sparse_to_dense_op.cc:126 : Invalid argument: indices[9] = [4,8] is repeated
2018-06-09 20:54:36.699225: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1318] OP_REQUIRES failed at sparse_to_dense_op.cc:126 : Invalid argument: indices[9] = [4,8] is repeated
Traceback (most recent call last):
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1322, in _do_call
    return fn(*args)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[9] = [4,8] is repeated
	 [[Node: input_layer/color_weighted_by_weight_indicator/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](input_layer/color_weighted_by_weight_indicator/SparseSlice, input_layer/color_weighted_by_weight_indicator/SparseSlice:2, input_layer/color_weighted_by_weight_indicator/SparseSlice:1, input_layer/color_weighted_by_weight_indicator/SparseToDense/default_value)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""E:/wnd_test/test.py"", line 55, in <module>
    print(session.run([tensor]))
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 900, in run
    run_metadata_ptr)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1316, in _do_run
    run_metadata)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[9] = [4,8] is repeated
	 [[Node: input_layer/color_weighted_by_weight_indicator/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](input_layer/color_weighted_by_weight_indicator/SparseSlice, input_layer/color_weighted_by_weight_indicator/SparseSlice:2, input_layer/color_weighted_by_weight_indicator/SparseSlice:1, input_layer/color_weighted_by_weight_indicator/SparseToDense/default_value)]]

Caused by op 'input_layer/color_weighted_by_weight_indicator/SparseToDense', defined at:
  File ""E:/wnd_test/test.py"", line 50, in <module>
    tensor = tf.feature_column.input_layer(features, [indicator])
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\feature_column\feature_column.py"", line 277, in input_layer
    trainable, cols_to_vars)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\feature_column\feature_column.py"", line 202, in _internal_input_layer
    trainable=trainable)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\feature_column\feature_column.py"", line 3302, in _get_dense_tensor
    return inputs.get(self)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\feature_column\feature_column.py"", line 2100, in get
    transformed = column._transform_feature(self)  # pylint: disable=protected-access
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\feature_column\feature_column.py"", line 3244, in _transform_feature
    return sparse_ops.sparse_tensor_to_dense(weighted_column)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\sparse_ops.py"", line 1011, in sparse_tensor_to_dense
    name=name)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\sparse_ops.py"", line 791, in sparse_to_dense
    name=name)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_sparse_ops.py"", line 3268, in sparse_to_dense
    name=name)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""D:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): indices[9] = [4,8] is repeated
	 [[Node: input_layer/color_weighted_by_weight_indicator/SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT64, validate_indices=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](input_layer/color_weighted_by_weight_indicator/SparseSlice, input_layer/color_weighted_by_weight_indicator/SparseSlice:2, input_layer/color_weighted_by_weight_indicator/SparseSlice:1, input_layer/color_weighted_by_weight_indicator/SparseToDense/default_value)]]


Process finished with exit code 1

```



The ```InvalidArgumentError``` is caused by the fact that feature ""B"" and feature  ""R"" are hashed into the same hash_bucket.  
It'll be great if a ```combiner``` argument (as in ```tf.feature_column.embedding_column```) can be implemented in the ```tf.feature_column.indicator_column``` funciton."
19875,stats_calculator.cc:185:13: error: no member named 'emplace' ,"### System information
Darwin newbmac753702.local 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64
Mac OS X 10.13.3

   ANDROID_BUILD_TOOLS_VERSION=27.0.3 \
    ANDROID_NDK_API_LEVEL=15 \
    ANDROID_SDK_API_LEVEL=27 \
    PYTHON_BIN_PATH=/Users/aruiz/miniconda3/bin/python \
    PYTHON_LIB_PATH=/Users/aruiz/miniconda3/lib/python3.6/site-packages \

Hi. I am trying to build an .apk following the steps in the android samples readme
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md however when running
bazel build -c opt //tensorflow/examples/android:tensorflow_demo 
the following errors are thrown.

### Source code / logs
tensorflow/core/util/stats_calculator.cc:142:24: warning: range-based for loop is a C++11 extension [-Wc++11-extensions]
  for (const auto& det : details_) {
                       ^
tensorflow/core/util/stats_calculator.cc:181:72: error: a space is required between consecutive right angle brackets (use '> >')
  std::priority_queue<std::pair<int64_t, std::pair<std::string, int64_t>>>
                                                                       ^~
                                                                       > > 
tensorflow/core/util/stats_calculator.cc:183:14: warning: 'auto' type specifier is a C++11 extension [-Wc++11-extensions]
  for (const auto& node_type : node_type_map_time) {
             ^
tensorflow/core/util/stats_calculator.cc:183:30: warning: range-based for loop is a C++11 extension [-Wc++11-extensions]
  for (const auto& node_type : node_type_map_time) {
                             ^
tensorflow/core/util/stats_calculator.cc:185:13: error: no member named 'emplace' in 'std::priority_queue<std::pair<long long, std::pair<std::basic_string<char>, long long> >, std::vector<std::pair<long long, std::pair<std::basic_string<char>, long long> >, std::allocator<std::pair<long long, std::pair<std::basic_string<char>, long long> > > >, std::less<std::pair<long long, std::pair<std::basic_string<char>, long long> > > >'
    timings.emplace(node_type.second,
    ~~~~~~~ ^
tensorflow/core/util/stats_calculator.cc:200:5: warning: 'auto' type specifier is a C++11 extension [-Wc++11-extensions]
    auto entry = timings.top();
    ^

I am able to solve the issue with the  > > spaces but not the emplace not found. Any ideas?

Thanks a lot"
19874,why set TF_BUILD_BAZEL_CLEAN=1 in ci_parameterized_build.sh,"Hi, 

I found TF_BUILD_BAZEL_CLEAN is always set to 1 in ci_parameterized_build.sh
https://github.com/tensorflow/tensorflow/blob/a6a265b61a9ad9510f45cf4c9032778bf2e042b9/tensorflow/tools/ci_build/ci_parameterized_build.sh#L99

This was introduced about 11 months ago.
The comment says this is temporary and will be removed later.

So is that still required?
Thanks.


"
19873,Tensorflow Testing Problem,"Hi,
I am working on Tensorflow with Python. I have a new idea about the pooling method. Currently there are two pooling methods  (max-pooling, avg-pooling). I want to do some experiment by some new idea about pooling method. 
But for that i need to find the current pooling functions. But unfortunately i could not find that. Can anyone please help me to do this experiment and help me to find the exact flow of pooling because i am not so much fluent to Python.

 Thanks."
19872,Strange TF runtime error,ignore this issue
19868,tflite tensorflow/contrib/lite/examples/minimal/minimal.cc compilation error  ,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: tflite example 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:MacOS High Serria (10.13.3)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:1.5.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:clang-900.0.39.2 
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:g++ --std=c++11 -Itensorflow/contrib/lite -I. tensorflow/contrib/lite/examples/minimal/minimal.cc -Lbazel-bin/tensorflow/contrib/lite -ltflite


Trying to compile minimal.cc in tflite examples, Added the following lines in tensorflow/contrib/lite/BUILD 

    cc_binary( 
       name = ""libtflite.so"",
       deps = ["":framework""],
       linkshared=1
    )
then made a shared library with ```bazel build //tensorflow/contrib/lite:framework```

and compiled tensorflow/contrib/lite/examples/minimal/minimal.cc  with the command
```g++ --std=c++11 -Itensorflow/contrib/lite -I. tensorflow/contrib/lite/examples/minimal/minimal.cc -Lbazel-bin/tensorflow/contrib/lite -ltflite```

but the compilation failed, it gives following errors.

``` In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:
In file included from ./tensorflow/contrib/lite/model.h:37:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:
In file included from tensorflow/contrib/lite/string.h:19:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1722:9: error: no
      member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?
        _VSTD::memmove(__result, __first, __n * sizeof(_Up));
        ^~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: 
      expanded from macro '_VSTD'
#define _VSTD std::_LIBCPP_NAMESPACE
              ^
/usr/include/wchar.h:153:10: note: 'wmemmove' declared here
wchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);
         ^
In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:
In file included from ./tensorflow/contrib/lite/model.h:37:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:
In file included from tensorflow/contrib/lite/string.h:19:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1760:9: error: no
      member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?
        _VSTD::memmove(__result, __first, __n * sizeof(_Up));
        ^~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: 
      expanded from macro '_VSTD'
#define _VSTD std::_LIBCPP_NAMESPACE
              ^
/usr/include/wchar.h:153:10: note: 'wmemmove' declared here
wchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);
         ^
In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:
In file included from ./tensorflow/contrib/lite/model.h:37:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:
In file included from tensorflow/contrib/lite/string.h:19:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1861:9: error: no
      member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?
        _VSTD::memmove(__result, __first, __n * sizeof(_Up));
        ^~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: 
      expanded from macro '_VSTD'
#define _VSTD std::_LIBCPP_NAMESPACE
              ^
/usr/include/wchar.h:153:10: note: 'wmemmove' declared here
wchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);
         ^
In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:
In file included from ./tensorflow/contrib/lite/model.h:37:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:
In file included from tensorflow/contrib/lite/string.h:19:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1899:9: error: no
      member named 'memmove' in namespace 'std::__1'; did you mean 'wmemmove'?
        _VSTD::memmove(__result, __first, __n * sizeof(_Up));
        ^~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: 
      expanded from macro '_VSTD'
#define _VSTD std::_LIBCPP_NAMESPACE
              ^
/usr/include/wchar.h:153:10: note: 'wmemmove' declared here
wchar_t *wmemmove(wchar_t *, const wchar_t *, size_t);
         ^
In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:
In file included from ./tensorflow/contrib/lite/model.h:37:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:
In file included from tensorflow/contrib/lite/string.h:19:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:2020:9: error: no
      member named 'memset' in namespace 'std::__1'; did you mean 'wmemset'?
        _VSTD::memset(__first, (unsigned char)__value_, (size_t)(__n));
        ^~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__config:392:15: note: 
      expanded from macro '_VSTD'
#define _VSTD std::_LIBCPP_NAMESPACE
              ^
/usr/include/wchar.h:154:10: note: 'wmemset' declared here
wchar_t *wmemset(wchar_t *, wchar_t, size_t);
         ^
In file included from tensorflow/contrib/lite/examples/minimal/minimal.cc:15:
In file included from ./tensorflow/contrib/lite/model.h:37:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/memory:640:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/cstring:61:
In file included from tensorflow/contrib/lite/string.h:19:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string:470:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/string_view:171:
In file included from /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__string:56:
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3343:9: error: 
      unknown type name '__destruct_n'
        __destruct_n __d(0);
        ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:9: error: 
      use of undeclared identifier 'unique_ptr'
        unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);
        ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:20: error: 
      unexpected type name 'value_type': expected expression
        unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);
                   ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:32: error: 
      use of undeclared identifier '__destruct_n'
        unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);
                               ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3344:45: error: 
      expected expression
        unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);
                                            ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3410:71: error: 
      no type named 'return_temporary_buffer' in namespace 'std::__1'; did you mean '__return_temporary_buffer'?
    _LIBCPP_INLINE_VISIBILITY void operator()(_Tp* __p) const {_VSTD::return_temporary_buffer(__p);}
                                                               ~~~~~~~^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3407:8: note: 
      '__return_temporary_buffer' declared here
struct __return_temporary_buffer
       ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3410:95: error: 
      redefinition of '__p'
    _LIBCPP_INLINE_VISIBILITY void operator()(_Tp* __p) const {_VSTD::return_temporary_buffer(__p);}
                                                                                              ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3410:52: note: 
      previous definition is here
    _LIBCPP_INLINE_VISIBILITY void operator()(_Tp* __p) const {_VSTD::return_temporary_buffer(__p);}
                                                   ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3434:5: error: 
      use of undeclared identifier 'unique_ptr'
    unique_ptr<value_type, __return_temporary_buffer> __h;
    ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3434:16: error: 
      unexpected type name 'value_type': expected expression
    unique_ptr<value_type, __return_temporary_buffer> __h;
               ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3437:22: error: 
      no member named 'get_temporary_buffer' in namespace 'std::__1'
        __p = _VSTD::get_temporary_buffer<value_type>(__len);
              ~~~~~~~^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3437:43: error: 
      unexpected type name 'value_type': expected expression
        __p = _VSTD::get_temporary_buffer<value_type>(__len);
                                          ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3438:9: error: 
      use of undeclared identifier '__h'; did you mean '__p'?
        __h.reset(__p.first);
        ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3433:34: note: 
      '__p' declared here
    pair<value_type*, ptrdiff_t> __p(0, 0);
                                 ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3473:9: error: 
      unknown type name '__destruct_n'
        __destruct_n __d(0);
        ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:3474:9: error: 
      use of undeclared identifier 'unique_ptr'
        unique_ptr<value_type, __destruct_n&> __h(__p.first, __d);
        ^
fatal error: too many errors emitted, stopping now [-ferror-limit=]
20 errors generated.  </details> ```
"
19864,No dtype for array of arrays into tf.keras.Input,"I would like to input an array of arrays into `tf.keras.Input()`, however that requires me to specify a dtype to ensure it doesn't default to expecting a float. However it doesn't appear as though there is a viable dtype for an array of arrays. For an array by itself, `dtype=float32_ref` appears to work, however this does not work for an array of arrays. `tf.keras.backend.dtype()` throws an error if I attempt to put in an array to see it's type as well. Does this dtype not exist?"
19863,Wrong calculation for conv2d_transpose outpu shape with stride != 1,"I work on convolutional auto encoder and recognized that the calculation of the conv2d_transpose output shape for a stride > 1 is wrong.  

Considering an input shape of [2, 74, 74, 16], a kernel of [3, 3], a stride of (2,2) and the 24 output filter the following code for a minimal AE would be this:


``conv_input = tf.placeholder(""float32"", [2, 74, 74, 16])``
``print(conv_input)``
``conv = tf.layers.conv2d(conv_input, 24, [3,3],strides=(2,2))``
``print(conv)``
``deconv = tf.layers.conv2d_transpose(conv, 16, [3, 3], strides=(2,2))``
``print(deconv)``

The output is:

![grafik](https://user-images.githubusercontent.com/17809849/41171901-62425888-6b52-11e8-8117-5ec0df63b859.png)

Should not the transpose operation restore the original shape or does this only appy on stride =1?
I also calculated the output shape by hand and get the same result. So not 100% sure if this is a bug."
19861,using tf.contrib.model_pruning. but how to save pruning model??,"I run the demo of model_pruning module. I got the following:
```
-rw-r--r--  1 Jeff  staff    81B  6  8 21:47 checkpoint
-rw-r--r--  1 Jeff   staff   1.3M  6  8 21:48 events.out.tfevents.1528465664.MacBook-Pro.local
-rw-r--r--  1 Jeff   staff   790K  6  8 21:47 graph.pbtxt
-rw-r--r--  1 Jeff   staff   4.1M  6  8 21:47 model.ckpt-100000.data-00000-of-00002
-rw-r--r--  1 Jeff   staff   8.2M  6  8 21:47 model.ckpt-100000.data-00001-of-00002
-rw-r--r--  1 Jeff   staff   1.6K  6  8 21:47 model.ckpt-100000.index
-rw-r--r--  1 Jeff   staff   365K  6  8 21:47 model.ckpt-100000.meta
```
but I did not get the pruning model?? Dose the model_pruning module work??"
19858,tf.einsum does not support spaces in equation,"In the numpy implementation, the `einsum` function supports spaces in the equations, but in TensorFlow it does not. I believe that spaces make the equations more readable.
For instance in this example, the numpy function call works well, while the TF function call throws a kind of cryptic ValueError:

```python
import numpy as np
import tensorflow as tf

X = np.random.random(size=(100,100))
X_tensor = tf.constant(X)

einsum_example_np = np.einsum(""ij, jk -> ik"", X, X)

einsum_example_tf = tf.einsum(""ij, jk -> ik"", X_tensor, X_tensor)
```

By changing the last line to `einsum_example_tf = tf.einsum(""ij,jk->ik"", X_tensor, X_tensor)` it can be made to work.
I think that this behavior can be confusing to people who are used to the handling of einsum equations in the numpy implementation. I would suggest to make the TF implementation also support spaces. This could probably be done by just stripping all spaces from the input to the equation argument."
19857,Tensorflow Backend error on Pycharm,"**Using Tensorflow backend** 
I have set anaconda environment on pycharm and also installed keras and tensorflow packages but it shows error **Using Tensorflow Backend**

"
19856,problem in tf.data.TFRecordDataset,"**Describe the problem**
I use the tf.data.TFRecordDataset API to read the tfrecord file. Everything is ok when batch_size is set to 1, but when the batch_size is greater than 1, the code is crashed. the error is below:

_Traceback (most recent call last):
  File ""F:/kaggle/JD_Fashion_AI/train.py"", line 125, in <module>
    main()
  File ""F:/kaggle/JD_Fashion_AI/train.py"", line 122, in main
    run_training()
  File ""F:/kaggle/JD_Fashion_AI/train.py"", line 98, in run_training
    sess.run(label)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""D:\python\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 200704 values, but the requested shape has 150528
	 [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32](DecodeRaw, Reshape/shape)]]
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,224,224,3], [?,?], [?]], output_types=[DT_UINT8, DT_UINT8, DT_STRING], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
_

note: i have totally 50000 images, i originally set batch_size to 16, so the num_per_epoch is 3125.

**Source code**
`def _parse_function(record):

    features = {'image': tf.FixedLenFeature([], tf.string), 'label': tf.FixedLenFeature([], tf.string),
                'id': tf.FixedLenFeature([], tf.string)}
    example = tf.parse_single_example(record, features=features)
    image = tf.decode_raw(example['image'], tf.uint8)
    image = tf.reshape(image, [224, 224, 3])
    label = tf.subtract(tf.decode_raw(example['label'], tf.uint8), 48)
    id = tf.cast(example['id'], tf.string)

    return image, label, id


def run_training():

    # learning_rate = tf.placeholder(dtype=tf.float32)
    train_filenames = ['I:/JD_fashion_AI/train_tfrecords/train.tfrecords']
    validation_filenames = ['I:/JD_fashion_AI/valid_tfrecords/valid.tfrecords']
    train_datasets = tf.data.TFRecordDataset(filenames=train_filenames)
    validation_datasets = tf.data.TFRecordDataset(filenames=validation_filenames)
    train_datasets = train_datasets.map(_parse_function).shuffle(buffer_size=1000).batch(16).repeat()
    validation_datasets = validation_datasets.map(_parse_function).batch(1).repeat(1)
    iterator = tf.data.Iterator.from_structure(train_datasets.output_types,
                                               train_datasets.output_shapes)
    image, label, id = iterator.get_next()
    training_init_op = iterator.make_initializer(train_datasets)
    validation_init_op = iterator.make_initializer(validation_datasets)

    init = tf.global_variables_initializer()

    with tf.Session() as sess:

        sess.run(init)
        step = 0
        for _ in range(18):
            sess.run(training_init_op)  # must initialize the iterator to read the data flow
            for _ in range(3125):
                
                sess.run(label)
                print(step)
`
anyone else know what happened ?"
19855,[Faster RCNN Resnet object detection] Tensorflow crash by using full of RAM memory,"### System information
- **What is the top-level directory of the model you are using**:
models/research/object_detection/
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**:
conda install
- **TensorFlow version (use command below)**:
1.7.0
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**:
CUDA® Toolkit 9.0; cuDNN v7.1
- **GPU model and memory**:
GForce GTX 1080Ti (11GB)
- **Exact command to reproduce**:
```
python train.py --logtostderr --train_dir=training_point/ --pipeline_config_path=training/faster_rcnn_inception_resnet_v2_atrous_coco.config
```
```
python eval.py --logtostderr --pipeline_config_path=training/faster_rcnn_inception_resnet_v2_atrous_coco.config --checkpoint_dir=training_point/ --eval_dir=eval/
```
```
tensorboard --logdir=training:training_point/,testing:eval/
```
### Describe the problem
I retrain faster_RCNN_resnet101_coco to detect some object. But it consumes all of my available RAM's memory.
My dataset contains 1000 images. My RAM's memory is 32GB.
Because of this issue, the OS always kill my training process after 7k iterations.
Why does tensorflow use too many RAM's memory like that? What is the solution to solve this issue?
Thanks you for your help!
"
19854,TensorFlowException: Op type not registered 'NonMaxSuppressionV3' in binary running on localhost.,"```
### System information
Linux 4.4.0-127-generic #153-Ubuntu SMP Sat May 19 10:58:46 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.4 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== compiler =====================================================
c++ (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux 4.4.0-127-generic #153-Ubuntu SMP Sat May 19 10:58:46 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy                          1.14.2                
protobuf                       3.5.2.post1           
tensorflow                     1.8.0                 
tensorflow-serving-api-python3 1.4.0                 

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.8.0
tf.GIT_VERSION = v1.8.0-0-g93bc2e2072
tf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072
Sanity check: array([1], dtype=int32)

- **Exact command to reproduce**: I run my android application on Android Studio
```

### Describe the problem
I have an android application where for instance I make an initialization of my frozen model. 
It seems that there is a problem with the ops. I get this exception:

`java.lang.RuntimeException: Unable to start activity ComponentInfo{myapp/myapp.MainActivity}: 
org.tensorflow.TensorFlowException: Op type not registered 'NonMaxSuppressionV3' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.

        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2666)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2727)
        at android.app.ActivityThread.-wrap12(ActivityThread.java)
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1478)
        at android.os.Handler.dispatchMessage(Handler.java:102)
        at android.os.Looper.loop(Looper.java:154)
        at android.app.ActivityThread.main(ActivityThread.java:6121)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:890)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:780)
     Caused by: org.tensorflow.TensorFlowException: Op type not registered 'NonMaxSuppressionV3' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.
        at org.tensorflow.Graph.importGraphDef(Native Method)
        at org.tensorflow.Graph.importGraphDef(Graph.java:130)
        at org.tensorflow.Graph.importGraphDef(Graph.java:114)
        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:559)
        at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:105)
        at myapp.ActivityInference.<init>(ActivityInference.java:22)
        at myapp.MainActivity.onCreate(MainActivity.java:21)
        at android.app.Activity.performCreate(Activity.java:6692)
        at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1118)
        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2619)
        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2727) 
        at android.app.ActivityThread.-wrap12(ActivityThread.java) 
        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1478) 
        at android.os.Handler.dispatchMessage(Handler.java:102) 
        at android.os.Looper.loop(Looper.java:154) 
        at android.app.ActivityThread.main(ActivityThread.java:6121) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:890) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:780) ` 

I have checked the BUILD file in tensorflow/core/kernels/ and there is defined the kernel library:
`tf_kernel_library(
    name = ""non_max_suppression_op"",
    prefix = ""non_max_suppression_op"",
    deps = IMAGE_DEPS,
)`
I am new to this so I really do not know how I can fix it.
I am working on a pre-trained frozen model.

### Source code / logs
Android code:


```
package myapp;
import android.content.Context;
import android.content.res.AssetManager;

import org.tensorflow.contrib.android.TensorFlowInferenceInterface;


public class ActivityInference {

    private static ActivityInference activityInferenceInstance;
    private TensorFlowInferenceInterface inferenceInterface;
    private static AssetManager assetManager;
    private static final String MODEL_FILE = ""file:///android_asset/frozen_inference_graph.pb"";
    private static final String INPUT_NODE = ""input"";

    public ActivityInference(final Context context) {
        this.assetManager = context.getAssets();
        inferenceInterface = new TensorFlowInferenceInterface(assetManager, MODEL_FILE);

    }

    public static ActivityInference getInstance(final Context context){
        if (activityInferenceInstance == null)
        {
            activityInferenceInstance = new ActivityInference(context);
        }
        return activityInferenceInstance;
    }
}
```

and my main activity:

```
package myapp;

import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;
import android.widget.TextView;


public class MainActivity extends AppCompatActivity {

    private ActivityInference activityInference;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        final TextView textView = (TextView) findViewById(R.id.textView);
        activityInference = new ActivityInference(getApplicationContext());
    }
}
```"
19853,There seems to be a wrong network implementation in tensorflow/example/speech_commands/models.py,"There may be a mistake I found in `tensorflow/tensorflow/example/speech_commands/models.py`:
The function `create_conv_model()` is to create a ""cnn-trad-fpool3"" network with 2 max pool layers, but the second max pool layer is missing now.  The code can run normally, but I'm not sure if it is  the right ""cnn-trad-fpool3"" network.  

I put part of the code of `tensorflow/tensorflow/exmaple/speech_commands/models.py` here below and added some comments  to explain my points.
```python
def create_conv_model(fingerprint_input, model_settings, is_training):
  """"""Builds a standard convolutional model.
  This is roughly the network labeled as 'cnn-trad-fpool3' in the
  'Convolutional Neural Networks for Small-footprint Keyword Spotting' paper:
  http://www.isca-speech.org/archive/interspeech_2015/papers/i15_1478.pdf
  Here's the layout of the graph:
  (fingerprint_input)
          v
      [Conv2D]<-(weights)
          v
      [BiasAdd]<-(bias)
          v
        [Relu]
          v
      [MaxPool]
          v
      [Conv2D]<-(weights)
          v
      [BiasAdd]<-(bias)
          v
        [Relu]
          v
      [MaxPool]
          v
      [MatMul]<-(weights)
          v
      [BiasAdd]<-(bias)
          v
  This produces fairly good quality results, but can involve a large number of
  weight parameters and computations. For a cheaper alternative from the same
  paper with slightly less accuracy, see 'low_latency_conv' below.
  During training, dropout nodes are introduced after each relu, controlled by a
  placeholder.
  Args:
    fingerprint_input: TensorFlow node that will output audio feature vectors.
    model_settings: Dictionary of information about the model.
    is_training: Whether the model is going to be used for training.
  Returns:
    TensorFlow node outputting logits results, and optionally a dropout
    placeholder.
  """"""
  if is_training:
    dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')
  input_frequency_size = model_settings['dct_coefficient_count']
  input_time_size = model_settings['spectrogram_length']
  fingerprint_4d = tf.reshape(fingerprint_input,
                              [-1, input_time_size, input_frequency_size, 1])
  first_filter_width = 8
  first_filter_height = 20
  first_filter_count = 64
  first_weights = tf.Variable(
      tf.truncated_normal(
          [first_filter_height, first_filter_width, 1, first_filter_count],
          stddev=0.01))
  first_bias = tf.Variable(tf.zeros([first_filter_count]))
  first_conv = tf.nn.conv2d(fingerprint_4d, first_weights, [1, 1, 1, 1],
                            'SAME') + first_bias
  first_relu = tf.nn.relu(first_conv)
  if is_training:
    first_dropout = tf.nn.dropout(first_relu, dropout_prob)
  else:
    first_dropout = first_relu
  # the first and only max pool operation in the whole network.
  max_pool = tf.nn.max_pool(first_dropout, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME') 
  second_filter_width = 4
  second_filter_height = 10
  second_filter_count = 64
  second_weights = tf.Variable(
      tf.truncated_normal(
          [
              second_filter_height, second_filter_width, first_filter_count,
              second_filter_count
          ],
          stddev=0.01))
  second_bias = tf.Variable(tf.zeros([second_filter_count]))
  second_conv = tf.nn.conv2d(max_pool, second_weights, [1, 1, 1, 1],
                             'SAME') + second_bias
  second_relu = tf.nn.relu(second_conv)
  if is_training:
    second_dropout = tf.nn.dropout(second_relu, dropout_prob)
  else:
    second_dropout = second_relu
  # there could be another one max pool operation as the comments said in the beginning:
  # another_max_pool =tf.nn.max_pool(second_dropout, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')
  # and the variable name ""second_dropout"" below should be changed to ""another_max_pool"".
  second_conv_shape = second_dropout.get_shape()
  second_conv_output_width = second_conv_shape[2]
  second_conv_output_height = second_conv_shape[1]
  second_conv_element_count = int(
      second_conv_output_width * second_conv_output_height *
      second_filter_count)
  flattened_second_conv = tf.reshape(second_dropout,
                                     [-1, second_conv_element_count])
  label_count = model_settings['label_count']
  final_fc_weights = tf.Variable(
      tf.truncated_normal(
          [second_conv_element_count, label_count], stddev=0.01))
  final_fc_bias = tf.Variable(tf.zeros([label_count]))
  final_fc = tf.matmul(flattened_second_conv, final_fc_weights) + final_fc_bias
  if is_training:
    return final_fc, dropout_prob
  else:
    return final_fc
```
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  No. I read the source code and run the it on my own computer.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  
N/A
- **TensorFlow installed from (source or binary)**:
N/A
- **TensorFlow version (use command below)**:  
v1.9.0-rc0
- **Python version**: 
N/A
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
N/A"
19852,How can I use beam search together with CustomHelper when decoding in a seq2seq model structure?,
19851,"Protobuff file in Android example - ""TF Detect"" app","**OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**
Linux Ubuntu 16.04
**TensorFlow installed from (source or binary):**
Source.
**TensorFlow version (use command below):**
1.8.0
**Python version:**
2.7.12
**Bazel version (if compiling from source):**
0.13.0
**GCC/Compiler version (if compiling from source):**
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)

Sorry if this is wrong place to ask, since my question is not related to any bug/error. 
I have already asked on StackOverflow and nobody has given me an answer, so I decided to ask it here. 

In android example https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android , there is ""ssd_mobilenet_v1_android_export.pb"" that gets stored in assets folderT once gradle is run. The model seems to be trained using COCO dataset.

I would like to know where I can find original .cfg and .weights files of the CNN in order to do my own training. I could not find anything online.

Thank you in advance."
19850,Computed output size would be negative. Qunatized graph error,"Some what similar to issue [10458](https://github.com/tensorflow/tensorflow/issues/10458).
I generated my frozen graph and quantized it for deploying it. But this is the error message I am getting when trying to deploy it as a apk.

```
Invalid argument: Computed output size would be negative: -32 [input_size: 84, effective_filter_size: 117, stride: 1]
Invalid argument: Computed output size would be negative: -32 [input_size: 85, effective_filter_size: 118, stride: 1]
Invalid argument:Computed output size would be negative: -32 [input_size: 86, effective_filter_size: 119, stride: 1]
Failed to run TensorFlow inference with inputs:[inputTensor, dropout_keep_prob], outputs:[output/softmax]
```"
19849,XLA Compile error: Operation has no attr named '_XlaCompile',"### System information
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: pip (Command: pip install tensorflow-gpu)
- **TensorFlow version**: v1.8.0-0-g93bc2e2072  1.8.0
- **Python version**: Python 3.6.4 :: Anaconda, Inc.
- **CUDA/cuDNN version**: CUDA Version 9.0.176 / cuDNN: 7.0.5.15
- **Bazel version**: N/A
- **GPU model and memory**: GeForce GTX 1080 / 8 GB
- **Exact command to reproduce**: python filename.py
- **Have I written custom code**: No

### Describe the problem
I am running the below code. I am getting the XLA Compiler error as mentioned below. I am having Tensorflow GPU version, but I did try with CPU version and I was getting the error. But when I downgraded Tensorflow (CPU) to 1.3 I was not getting any error. 
Please can somebody help me in this.

### Source code / logs
```
import tensorflow as tf
input_tensor = tf.placeholder(dtype=tf.float32, shape=[None, 16, 16, 3])
print(input_tensor.shape)

conv_filter = tf.get_variable('conv_filter', shape=[2, 2, 3, 6], dtype=tf.float32)
conv1 = tf.nn.conv2d(input_tensor, conv_filter, strides=[1, 2, 2, 1], padding='SAME')
print(conv1.shape)

deconv_filter = tf.get_variable('deconv_filter', shape=[2, 2, 6, 3], dtype=tf.float32)

deconv = tf.nn.conv2d_transpose(input_tensor, filter=deconv_filter,
    output_shape=tf.shape(input_tensor),
    strides=[1, 2, 2, 1],
    padding='SAME')
print(deconv.shape)

t = tf.reduce_mean(deconv)
g = tf.train.AdamOptimizer(0.01).minimize(t)
```

Error:
```
(?, 16, 16, 3)
(?, 8, 8, 6)
(?, 16, 16, 3)     # <<<<< This should have printed (?, ?, ?, ?)

Traceback (most recent call last):
  File ""/my/path/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2327, in get_attr
    c_api.TF_OperationGetAttrValueProto(self._c_op, name, buf)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Operation 'conv2d_transpose' has no attr named '_XlaCompile'.

Traceback (most recent call last):
  File ""/my/path/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py"", line 380, in _MaybeCompile
    xla_compile = op.get_attr(""_XlaCompile"")
  File ""/my/path/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2331, in get_attr
    raise ValueError(str(e))
ValueError: Operation 'conv2d_transpose' has no attr named '_XlaCompile'.
```

The error is coming in the line `g = tf.train.AdamOptimizer(0.01).minimize(t)`"
19848,ModuleNotFoundError: No module named 'tensorflow.python.training',"No Module Found for Tensorflow, 

I have installed tensorflow-gpu(version=1.5) in a conda virtual env and the cuda version 9.1 

The packages in the virtual environment  
......................................installed packages......................................
spyder (3.2.4)
SQLAlchemy (1.1.13)
statsmodels (0.8.0)
sympy (1.1.1)
tables (3.4.2)
tblib (1.3.2)
tensorflow-gpu (1.5.0)
tensorflow-tensorboard (1.5.1)
terminado (0.6)
testpath (0.3.1)
toolz (0.8.2)
------------------------------------------------------------------------------------------------

I run the following program,
`python train_tripletloss.py --logs_base_dir ~/logs/facenet/ --models_base_dir ~/models/facenet/ --data_dir /home/socian/Documents/facenet/data/lfw --image_size 250 --model_def src.models.inception_resnet_v1 --lfw_dir /home/socian/Documents/facenet/data/lfw_182 --optimizer RMSPROP --learning_rate 0.01 --weight_decay 1e-4 --max_nrof_epochs 500`


**but it shows the error 
Traceback (most recent call last):
  File ""train_tripletloss.py"", line 39, in <module>
    from src import facenet
  File ""/home/tareq/rabindra/facenet/src/facenet.py"", line 37, in <module>
    from tensorflow.python.training import training
ModuleNotFoundError: No module named 'tensorflow.python.training'**

Then I have checkout  the problem in python shell,

 >>> import tensorflow as tf
```
>>> from tensorflow.python.training import training
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.python.training'
>>> from tensorflow.python.data import dataset
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: cannot import name 'dataset'
>>> 
```


`




"
19847,win10 c++ LNK1189：library limit of 65535 objects exceeded	pywrap_tensorflow_internal,"**System information:**
· Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No

· OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10-x64

· TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git

· TensorFlow version (use command below): r1.4, r1.5, r1.6 r1.7 and r1.8, command :
v1.8's command : git checkout -b v1.8 -f origin/r1.8
v1.7's command : git checkout -b v1.7 -f origin/r1.7
v1.6's command : git checkout -b v1.6 -f origin/r1.6
and so on include v1.4 and v1.5

· Python version: Anaconda3 - python3.6

· Bazel version (if compiling from source): I used CMAKE 3.11.1

· GCC/Compiler version (if compiling from source): both Visual Studio 2015 and Visual Studio 2015' MSBuild

· CUDA/cuDNN version: CUDA9.0, cudnn-9.0-win10-7.1

· GPU model and memory: GTX-860m with 2Gb Memory

Exact command to reproduce:
""
D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=Debug -DSWIG_EXECUTABLE=D:/soft/TensorflowSoft/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/ProgramData/Anaconda3/python.exe -DPYTHON_LIBRARIES=D:/ProgramData/Anaconda3/libs/python36.lib -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""D:\soft\TensorflowSoft\cudnn"" -G ""Visual Studio 14 2015""

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> set PreferredToolArchitecture=x64

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> MSBuild /p:Configuration=Release ALL_BUILD.vcxproj
""

**Describe the problem :**
I build TensorFlow-CPU-r1.8 successfully (win10-x64 + Anaconda3-python3.6 + VS2017(not VS2015) + tensorflow1.8 + cmake3.11.1 + SwigWin3.0.12).

But when I build tensorflow-GPU version(both tensorflow-r1.7 and r1.8), the only error has occurred: ""error LNK1189：library limit of 65535 objects exceeded, pywrap_tensorflow_internal"".
 (If I use VS2017, it shows error: "" the compiler is not supported for CUDA 9.0"" , so I switch Visual Studio version to VS2015, and CMAKE command is work successfully.)

After that, I switched to lower versions TensorFlow-r1.6 to TensorFlow-r1.5, but Link error occurred：

“libprotobufd.lib(text_format.obj) : error LNK2019: unresolved external symbol __std_reverse_trivially_swappable_8 referenced in function ""void _
_cdecl std::_Reverse_unchecked1<class google::protobuf::Message const * *>(class google::protobuf::Message const * * const,class google::protobuf:
:Message const * * const,struct std::integral_constant<unsigned __int64,8>)"" (??$_Reverse_unchecked1@PEAPEBVMessage@protobuf@google@@@std@@yaxqeap
EBVMessage@protobuf@google@@0u?$integral_constant@_K$07@0@@z) [D:\tf\tensorflowGPU\tensorflow\contrib\cmake\build\proto_text.vcxproj]
libprotobufd.lib(wire_format.obj) : error LNK2001: unresolved external symbol __std_reverse_trivially_swappable_8 [D:\tf\tensorflowGPU\tensorflo
w\contrib\cmake\build\proto_text.vcxproj]
D:\tf\tensorflowGPU\tensorflow\contrib\cmake\build\Debug\proto_text.exe : fatal error LNK1120: 1 unresolved externals [D:\tf\tensorflowGPU\tenso
rflow\contrib\cmake\build\proto_text.vcxproj]”

I don't know how to solve those errors..."
19840,TF that is build from r1.9 - crashes with _gru_ops.so: undefined symbol: _ZN15stream_executor6Stream12ThenBlasGemmENS_4blas9TransposeES2_yyyfRKNS_12DeviceMemoryIfEEiS6_ifPS4_i ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I have used unchanged code from branch r1.9, commit e1436b2952c7600c8ac88114210381db0398be16
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:branch r1.9, commit e1436b2952c7600c8ac88114210381db0398be16
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.10.1
- **GCC/Compiler version (if compiling from source)**: 4.8
- **CUDA/cuDNN version**: 9.2/7.2
- **GPU model and memory**: V100, 16Gb
- **Exact command to reproduce**:

```bash
git clone https://github.com/tensorflow/benchmarks.git
cd benchmarks/scripts/tf_cnn_benchmarks
git checkout 551caecb936312690d6bc8c8c2e2562089e2c200
python3 tf_cnn_benchmarks.py --data_format=NCHW --batch_size=256 --num_batches=100 --model=resnet50 --optimizer=momentum --variable_update=replicated --nodistortions --hierarchical_copy=True --gradient_repacking=8 --datasets_use_prefetch=False --display_every=10 --gpu_thread_mode=gpu_shared --num_gpus=8 --use_fp16=True
```

### Results:
```
python3 tf_cnn_benchmarks.py --data_format=NCHW --batch_size=256 --num_batches=100 --model=resnet50 --optimizer=momentum --variable_update=replicated --nodistortions --hierarchical_copy=True --gradient_repacking=8 --datasets_use_prefetch=False --display_every=10 --gpu_thread_mode=gpu_shared --num_gpus=8 --use_fp16=True
/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 27, in <module>
    import benchmark_cnn
  File ""/home/vkovalevskyi/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 48, in <module>
    import data_utils
  File ""/home/vkovalevskyi/benchmarks/scripts/tf_cnn_benchmarks/data_utils.py"", line 21, in <module>
    from tensorflow.contrib.data.python.ops import batching
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/__init__.py"", line 35, in <module>
    from tensorflow.contrib import cudnn_rnn
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/__init__.py"", line 34, in <module>
    from tensorflow.contrib.cudnn_rnn.python.layers import *
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/__init__.py"", line 23, in <module>
    from tensorflow.contrib.cudnn_rnn.python.layers.cudnn_rnn import *
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py"", line 20, in <module>
    from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py"", line 22, in <module>
    from tensorflow.contrib.rnn.python.ops import lstm_ops
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/rnn/__init__.py"", line 88, in <module>
    from tensorflow.contrib.rnn.python.ops.gru_ops import *
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/gru_ops.py"", line 33, in <module>
    resource_loader.get_path_to_datafile(""_gru_ops.so""))
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/util/loader.py"", line 56, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py"", line 56, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: /home/vkovalevskyi/.local/lib/python3.6/site-packages/tensorflow/contrib/rnn/python/ops/_gru_ops.so: undefined symbol: _ZN15stream_executor6Stream12ThenBlasGemmENS_4blas9TransposeES2_yyyfRKNS_12DeviceMemoryIfEEiS6_ifPS4_i
```"
19838,optimize_for_inference_lib.optimize_for_inference produces an invalid graph,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source.
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.13.0
- **GCC/Compiler version (if compiling from source)**:
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)
- **CUDA/cuDNN version**:
9.0.176/7.0.5.15
- **GPU model and memory**:
1080 Ti
- **Exact command to reproduce**:
```
cat > test.py <<EOF && python test.py
import tensorflow as tf

from collections import namedtuple
from tensorflow.python.tools import optimize_for_inference_lib


def main():
    with tf.Graph().as_default(), tf.Session() as session:
        input = tf.placeholder(shape=[10], dtype=tf.float32)
        output = top_k(input)

        graph_def = session.graph.as_graph_def()

    input_nodes = [input]
    output_nodes = [output.values, output.indices]

    graph_def = tf.graph_util.convert_variables_to_constants(
        session, graph_def, [_get_node_name(t) for t in output_nodes]
    )

    with tf.Graph().as_default():
        tf.import_graph_def(graph_def)  # OK

    graph_def = optimize_for_inference_lib.optimize_for_inference(
        input_graph_def=graph_def,
        input_node_names=[_get_node_name(t) for t in input_nodes],
        output_node_names=[_get_node_name(t) for t in output_nodes],
        placeholder_type_enum=[node.dtype.as_datatype_enum for node in input_nodes]
    )

    with tf.Graph().as_default():
        tf.import_graph_def(graph_def)  # ERROR


TopKResult = namedtuple('TopKResult', ['values', 'indices'])


def top_k(input, k=1, sorted=True, name=None):
    """"""
    A version of tf.nn.top_k tolerant to k == 0 and k < tf.shape(input)[-1].
    """"""
    k = tf.minimum(k, tf.shape(input)[-1])

    return tf.cond(
        tf.equal(k, 0),
        lambda: TopKResult(
            values=tf.zeros(
                shape=tf.concat([tf.shape(input)[:-1], [0]], axis=0),
                dtype=input.dtype
            ),
            indices=tf.zeros(
                shape=tf.concat([tf.shape(input)[:-1], [0]], axis=0),
                dtype=tf.int32
            )
        ),
        lambda: TopKResult(**tf.nn.top_k(input, k, sorted, name)._asdict())
    )


def _get_node_name(tensor):
    assert tensor.name.endswith(':0')
    return tensor.name[:-len(':0')]


if __name__ == '__main__':
    main()
EOF
```

### Describe the problem

`optimize_for_inference_lib.optimize_for_inference` produces an invalid graph for the graph generated by the above script. The returned GraphDef cannot be imported:

```
Traceback (most recent call last):
  File ""test.py"", line 66, in <module>
    main()
  File ""test.py"", line 32, in main
    tf.import_graph_def(graph_def)  # ERROR
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 493, in import_graph_def
    raise ValueError(str(e))
ValueError: NodeDef expected inputs '' do not match 1 inputs specified; Op<name=Const; signature= -> output:dtype; attr=value:tensor; attr=dtype:type>; NodeDef: import/cond/zeros_1/Const = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>](import/cond/Switch:1)
```
"
19837,"freeze_graph for inference memory leak: frozen graph size 1.3GB, takes 15GB memory when inference","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (details below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.3 
- **TensorFlow installed from (source or binary)**:binary (via `pip install`)
- **TensorFlow version (use command below)**:1.8.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:


### Describe the problem
I want to train a graph, save it, then load it later for inference-only purpose.
The way I'm doing it now:
During training, I save the model with `tf.graph_util.convert_variables_to_constants` method and `tf.train.write_graph` which produces a `.pb` file. Its size is around 1.3 GB. 
Then I load the frozen graph and do some inference with some toy data. This causes memory issue by **a factor of 10**. (In activity monitor, Python takes ~15GB on the first inference)

I've also tried the ""saving-loading-inference"" procedure with 
 -`saver.save()` 
 -`saver.restore()` 
and it doesn't cause the memory issue.  However, for production purpose on my end, loading a frozen graph would be strongly preferred to the 

### Source code / logs

#### Saving graph  (for debugging purpose, I SKIPPED training and save the graph once variables are initialized)
```
## build the graph
x = tf.placeholder(..)
...
some tf operations to build graph
...
pred = tf.nn.xw_plus_b(last_layer, W,b, ""predictions"")

##save graph
sess = tf.Session()
sess.run(tf.global_variables_initializer()))
graph_as_constants = tf.graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(),
                                      output_node_names=[""predictions""])
tf.train.write_graph(graph_as_constants, model_path, as_text=False, name=""model_graph"")
sess.close()
```

#### Load graph
```
with gfile.FastGFile(model_path, 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')
graph = tf.get_default_graph()
```

#### Try inference on some toy data:
```
x = graph.get_tensor_by_name(""x:0"")
pred = graph.get_tensor_by_name(""predictions:0"")
with tf.Session() as sess:
    for _ in range(10):
        x_test = some np array for testing
        test_result = sess.run(pred, feed_dict={x:x_test})
        time.sleep(30)
```

Here in inference, it goes through a loop with 10 iterations. In the first iteration, the sess.run(..) causes the memory leak issue (15 GB). In following iterations, memory falls back to what I would expect with the size of the model loaded.

### Some details

- The issue persists whether I save the frozen graph on CPU machine (macOS High Sierra 10.13.3 ) or a remote GPU machine (Ubuntu 16.04.3 LTS). 
- Again the graph is frozen once it's initialized. I skipped all training/testing logic for debugging purpose.
- For freeze graph,  I also tried `freeze_graph` in `bazel-bin` in terminal. It still causes memory issue when loading and doing inference.
- I've tried `optimize_for_inference(graph_def,...)` in the graph loading section. It doesn't solve the issue.
"
19836,Inconsistency between layer names and weight names in HDF5 saved from tf.keras nested models,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Doesn't matter
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**:  Doesn't matter

Supposed you run the following code to construct a nested Sequential model with tf.keras and save it as a .h5 file.

```py
import tensorflow as tf


with tf.Graph().as_default(), tf.Session():
  inner_model = tf.keras.Sequential([
      tf.keras.layers.Dense(4, input_shape=[3], activation='relu'),
      tf.keras.layers.Dense(3, activation='tanh')])
  outer_model = tf.keras.Sequential()
  outer_model.add(inner_model)
  outer_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
  outer_model.compile(loss='binary_crossentropy', optimizer='sgd')

  outer_model.save('/tmp/tf_nested_keras.h5')
```

Inside the saved .h5 file, you can see the layers have the names:
* 'dense_1',
* 'dense_2' 
* 'dense_3'.

However, the weight names do not match up with the layer names:
* 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0',

This is causing issues for TensorFlow.js converters. Note that the same issue does not occur for non-tf keras.
"
19835,tensorflow/contrib/lite module tests are failed to build,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
From source
- **TensorFlow version (use command below)**:
TF-master
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.11.1
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**: 
NA
- **GPU model and memory**:
NA
- **Exact command to reproduce**:
`bazel test -c opt  -k --jobs 1 test_timeout 300,450,1200,3600 --build_tests_only -- //tensorflow/... -//tensorflow/compiler/...  `

### Describe the problem
The TF-master build completed successfully.However while running the tests , around 80+ tests are failed to build. All of the failed tests are belongs to `tensorflow/contrib/lite `module.
Now , I'm trying to understand the reason. But, if anyone knows these are known failures then please let me know.  
Also, I would like to understand more about `tensorflow/contrib/lite ` module  - Is it supported on our platform or do we need to skip the tests for this module ? or need special configuration to run the tests?

I'm using below configuration to build and test TF-master :
Enabled only 3 features i.e. TF_NEED_GCP=1 , TF_NEED_HDFS=1 & TF_NEED_JEMALLOC=1 , and all other are disabled. 
```
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: y
jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: y
Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: y
Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: n
Clang will not be downloaded.

Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -mcpu=native]: ""-mcpu=power8 -mtune=power8""


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
Configuration finished
```


### Source code / logs
For more details please check the logfile.txt.

[logfile.txt](https://github.com/tensorflow/tensorflow/files/2080578/logfile.txt)
"
19834,Attention Wrapper state error.,"Hello! I am implementing a seq2seq model with attention for multi-step time series forecasting. I am encountering an error with implementing attention for MultiRNN cell.

System Information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:   Yes , I have attached my code below.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)** - Linux Ubuntu 16.04

- **TensorFlow installed from (source or binary)**: - Source

- **TensorFlow version (use command below)**: -VERSION = 1.4.1

- **Python version**: 2.7.12

- **Bazel version (if compiling from source)**:  - NA

- **GCC/Compiler version (if compiling from source)**: COMPILER_VERSION = v1.4.0-19-ga52c8d9

- **CUDA/cuDNN version**: - NA

- **GPU model and memory**: - NA

- **Exact command to reproduce**:
I am implementing a seq2seq model with attention for multi-step time series forecasting.

I am facing an issue with attention wrapper state.

My code is given below.

Function for defining the decoder 


    def decoder_network(attention_mechanism,dropout=config.dropout ):
        cells = []
        for i in range(config.num_stacked_layers)
    
            lstm_cell = tf.contrib.rnn.LSTMCell(config.hidden_dim)
            decoder_cell = tf.contrib.seq2seq.AttentionWrapper(lstm_cell, attention_mechanism=attention_mechanism, attention_layer_size=config.hidden_dim)
            cells.append(decoder_cell)
    
    
        cell = tf.contrib.rnn.MultiRNNCell(cells)
        return cell,cells
		
		

Using the above function

    cell,cells = decoder_network(attention_mechanism)
    new_state = cells[0].zero_state(batch_size=batch_size, dtype=tf.float32).clone(cell_state = initial_state)

	for i, inp in enumerate(decoder_inputs):
	      output, new_state = cell(inp, state=new_state)
	


However, I am facing the following error :

    Traceback (most recent call last):
      File ""seq2seq.py"", line 351, in <module>
        train()
      File ""seq2seq.py"", line 274, in train
        rnn_model = build_train_graph(feed_previous=True)
      File ""seq2seq.py"", line 247, in build_train_graph
        dec_outputs, dec_memory = _basic_rnn_seq2seq(enc_inp, dec_inp, cell, Why , by , feed_previous=feed_previous)
      File ""seq2seq.py"", line 165, in _basic_rnn_seq2seq
        return _rnn_decoder(decoder_inputs, enc_state, attention_mechanism, Why , by ,_loop_function)
      File ""seq2seq.py"", line 147, in _rnn_decoder
        output, new_state = cell(inp, state=new_state)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 183, in __call__
        return super(RNNCell, self).__call__(inputs, state)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 575, in __call__
        outputs = self.call(inputs, *args, **kwargs)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 1066, in call
        cur_inp, new_state = cell(cur_inp, cur_state)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py"", line 183, in __call__
        return super(RNNCell, self).__call__(inputs, state)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py"", line 575, in __call__
        outputs = self.call(inputs, *args, **kwargs)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py"", line 1289, in call
        ""Received type %s instead.""  % type(state))
    TypeError: Expected state to be instance of AttentionWrapperState. Received type <class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'> instead.
    


I have tried printing the type of new state and i got the following type

`    
    ('new_state', AttentionWrapperState(cell_state=(LSTMStateTuple(c=<tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/add_9:0' shape=(?, 40) dtype=float32>, h=<tf.Tensor 'rnn/rnn/multi_rnn_cell/cell_0/cell_0/lstm_cell/mul_14:0' shape=(?, 40) dtype=float32>),), attention=<tf.Tensor 'AttentionWrapperZeroState/zeros_1:0' shape=(244, 40) dtype=float32>, time=<tf.Tensor 'AttentionWrapperZeroState/zeros:0' shape=() dtype=int32>, alignments=<tf.Tensor 'AttentionWrapperZeroState/zeros_2:0' shape=(244, 5) dtype=float32>, alignment_history=()))
    `
Even though new state is an instance of AttentionWrapperState it still gives an error.

Thanks in advance for your replies ."
19833,tensorflow version conflict,"There's a class under tensorflow namely ""prepare_attention"" which doesn't work on the latest version of tensorflow but only on tensorflow 1.0.0 which can't be installed on Python 3.6

My config:
Windows 10
Python 3.6.5

Please suggest me a way out either with the prepare_attention or how to get Tensorflow for Python 3.6

Thanks!"
19832,set_intersection doesn't work as expectation - tensorflow 1.6.0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.6.0
- **Python version**: 
3.6.5 (anaconda)
- **Bazel version (if compiling from source)**:
0.11
- **GCC/Compiler version (if compiling from source)**:
gcc-5.4.0
- **CUDA/cuDNN version**:
CUDA9.1 and cuDNN 7.1.4
- **GPU model and memory**:
GPU model and 16G memory
- **Exact command to reproduce**:

```python
import collections

a = collections.OrderedDict([
      ((0, 0), 1),
      ((0, 3), 1),
      ((1, 1), 1),
      ((1, 3), 1),
      ((2, 0), 1),
      ((2, 1), 1)
  ])
a = tf.SparseTensor(list(a.keys()), list(a.values()), dense_shape=[3, 4])

b = collections.OrderedDict([
      ((0, 0), 1),
      ((0, 3), 1),
      ((1, 1), 1),
      ((1, 2), 1),
      ((1, 3), 1),
      ((2, 0), 1),
      ((2, 1), 1)
  ])
b = tf.SparseTensor(list(b.keys()), list(b.values()), dense_shape=[3, 4])

with tf.Session() as sess:
    print(sess.run(a))
    print(sess.run(b))
    print(sess.run(tf.contrib.metrics.set_intersection(a, b)))

```

### Describe the problem
For set_intersection, for my own understanding, output should be 

```bash
SparseTensorValue(indices=array([[0, 0],
       [0, 3],
       [1, 1],
       [1, 3],
       [2, 0],
       [2, 1]]), values=array([1, 1, 1, 1, 1, 1], dtype=int32), dense_shape=array([3, 4]))
```

However, I get the result as follow:

```bash
SparseTensorValue(indices=array([[0, 0],
       [1, 0],
       [2, 0]]), values=array([1, 1, 1], dtype=int32), dense_shape=array([3, 1]))
```

I don't understand if I'm not fully understanding for the points....

Best Regards
Orlando"
19830,"After encoded to tfrecords and decoded, .jpg quality descend","I'm not sure if somebody has noticed or it's just an exception that after the procedure of encoding and decoding, the .jpg loss some information. I havn't figured it out.... So strange..........
Hope someone can find the answer...

The part to encode:
```
def encode_tfrecords(file_path, output_path):
    classes = os.listdir(file_path)

    with tf.python_io.TFRecordWriter(output_path) as writer:
        for index, name in enumerate(classes):
            class_path = file_path + name + ""/""
            for img_name in os.listdir(class_path):
                img_path = class_path + img_name

                img_raw = tf.gfile.FastGFile(img_path, 'rb').read()

                example = tf.train.Example(features=tf.train.Features(feature={
                    ""label"": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),
                    'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))
                }))
                writer.write(example.SerializeToString())  
```


The part to decode:
```
def read_and_decode(filename, output_path, iters):
    filename_queue = tf.train.string_input_producer([filename])  
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue) 
    features = tf.parse_single_example(serialized_example,
                                       features={
                                           'label': tf.FixedLenFeature([], tf.int64),
                                           'img_raw': tf.FixedLenFeature([], tf.string),
                                       }) 
    # image = tf.decode_raw(features['img_raw'], t.uint8)
    image = tf.image.decode_jpeg(features['img_raw'], channels=3)
    label  = tf.cast(features['label'], tf.int64)
    with tf.Session() as sess:  
        init_op = tf.global_variables_initializer()
        sess.run(init_op)
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
        for i in range(iters):
            example, l = sess.run([image, label]) 
            img = Image.fromarray(example, 'RGB')
            img.save(output_path + str(i) + '_''Label_' + str(l) + '.jpg')
        coord.request_stop()
        coord.join(threads)
```"
19829,large String[] create Tensor in java,"i use this way to create a tensor by a large String[] in java:    
* // Valid: Matrix of String tensors.
   * // Each element might have a different length.
   * byte[][][] matrix = new byte[2][2][];
   * matrix[0][0] = ""this"".getBytes(""UTF-8"");
   * matrix[0][1] = ""is"".getBytes(""UTF-8"");
   * matrix[1][0] = ""a"".getBytes(""UTF-8"");
   * matrix[1][1] = ""matrix"".getBytes(""UTF-8"");
   * Tensor<String> m = Tensor.create(matrix, String.class);
   * }</pre>

however,it cost too much time. my String[] length of 6000+,create the tensor will cost 20+ m. how can i deal with it? thanks."
19826,averaging pooling fail to execute in tensorflow C API for rectangle size,"while square size like 96X96 is OK the rectangle sized average pooling induces failure on GPU version C API.
checked the freeze_graph.py tool and the output dimension is right. the bug should be somewhere in the GPU version implementation.

2018-06-07 10:38:08.502720: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-07 10:38:09.262953: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-07 10:38:10.250411: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.05GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2018-06-07 10:38:10.290275: F tensorflow/stream_executor/cuda/cuda_dnn.cc:570] could not convert BatchDescriptor {count: 1 feature_map_count: 256 spatial: 0 2  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM
Aborted (core dumped)"
19825,Feature request: Concurrently serving models with optimizers,"==Problem==

I want to use TensorFlow Serving to serve an output given certain placeholder inputs with a single run. The graph looks like this:

Input vector -> embedding lookup -> iterative inference with optimizer and tf.while_loop -> matrix math using inferred vector -> top K -> output

The problem is that I can't simply use a Tensor in the loop because tf.Optimizer requires a Variable. This in turn forces me to modify global state in each prediction, effectively prohibiting concurrency.

==Feature Request==

This could be solved by implementing:
* a version of Optimizer.minimize() that returns a list of Tensors and takes Tensors instead of Variables as input and
* an optimization to make Optimizer.minimize() recycle Tensors that are loop variables re-assigned to the return of Optimizer.minimize()

==For tensorflowbutler==

Since this is a feature request, the following fields are irrelevant:
Have I written custom code: NA
OS Platform and Distribution: NA
TensorFlow installed from: NA
TensorFlow version: NA
Bazel version: NA
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: NA"
19824,[tfdbg]tensorflow debugger doesn't work," I tried to use tfdbg to debug my code. I run `>tfdbg run`  to debug while the error is : 
`Non-OK-status:env->NewWritableFile(file_path, &f) status: Not found: Failed to create a NewWriteableFile: C:\Users\64484\AppData\Local\Temp\tfdbg_6ipwfvi_/_tfdbg_device_,job_localhost,replica_0,task_0,device_GPU_0/gradients/seq2seq/encoder/bidirectional_rnn/fw/fw/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3/f_acc/max_size_0_DebugIdentity_1528265028602834 : 系统找不到指定的路径。` 

I have gone to stackoverflow for methods, while there's no answers. Is this a bug of tfdbg? Thanks for help."
19823,"Problem with MirroredStrategy, PerDeviceDataset requires batch function","When MirroredStrategy is used with tf.estimator for multi-gpu train, the dataset has to be batched. However, for detection jobs, the input image shape differs one by one, so it cannot be batched. What is the recommended way to solve this problem? I think padding is not a good way to do this although it works. "
19822,bazel error:cannot be loaded: Not found: Op type not registered 'ClipByValue' in binary running on,"when i start a tensorflow serving :bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=8000 --model_name=aS_24443.1000 --model_base_path=...
i get the error :

2018-06-07 07:49:54.236996: I tensorflow_serving/util/retrier.cc:34] Retrying of Loading servable: {name: aS_24443.1000 version: 2} retry: 5
2018-06-07 07:49:54.283112: I external/org_tensorflow/tensorflow/contrib/session_bundle/bundle_shim.cc:360] Attempting to load native SavedModelBundle in bundle-shim from: /home/work/ics-contrib/freechat-serving/serving/load/aS_24443.1000/2
2018-06-07 07:49:54.283150: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:240] Loading SavedModel with tags: { serve }; from: /home/work/ics-contrib/freechat-serving/serving/load/aS_24443.1000/2
2018-06-07 07:49:54.483091: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:289] SavedModel load for tags { serve }; Status: fail. Took 199577 microseconds.
2018-06-07 07:49:54.483500: E tensorflow_serving/util/retrier.cc:38] Loading servable: {name: aS_24443.1000 version: 2} failed: Not found: Op type not registered 'ClipByValue' in binary running on sandbox03. Make sure the Op and Kernel are registered in the binary running in this process.

centOs
tensorflow1.8
keras 2.1

but i can start the serving on another computer which has the same environment"
19821,Quantized Model is 50% slower in performance. Is this expected?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4 LTS (Xenial Xerus)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.1
- **Python version**: 3.6.5 :: Anaconda Inc
- **Bazel version (if compiling from source)**: 0.13.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: GeForce GTX 1080 Ti/PCIe/SSE2
- **Exact command to reproduce**: python tensorflow/examples/label_image/label_image.py

### Describe the problem

Quantized Inception-3 model using transform_graph.py script. Tested on 1000 Imagenet images. Un-quantized model takes 800 seconds whereas quantized model takes 1600 seconds. Is this the expected behavior? 

PS. Let me know please if I should move this to SO?

### Source code / logs

Model files:

>  model_file = \
>     ""tensorflow/examples/label_image/data/inception_v3_2016_08_28_frozen.pb""
>   label_file = ""tensorflow/examples/label_image/data/imagenet_slim_labels.txt""
> 
> 

```
$ bazel build tensorflow/tools/graph_transforms:transform_graph

$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=./tensorflow/examples/label_image/data/inception_v3_2016_08_28_frozen.pb --out_graph=./tensorflow/examples/label_image/data/eight_bits.pb --inputs=Mul:0 --outputs=final_result:0 --transforms='fold_constants(ignore_errors=true)  fold_batch_norms fold_old_batch_norms quantize_weights'
```

-----------After quantization, I used label_image.py script to test images in a loop as below.

```
  ts = time.time()

  for file in os.listdir('~/test_images'):
      file_name = 'tensorflow/test_images_imagenet/' + file
      print (file_name)
      t = read_tensor_from_image_file(
          file_name,
          input_height=input_height,
          input_width=input_width,
          input_mean=input_mean,
          input_std=input_std)

      with tf.Session(graph=graph) as sess:
          results = sess.run(output_operation.outputs[0], {
          input_operation.outputs[0]: t
      })
      results = np.squeeze(results)

  tf = time.time()
  diff = tf - ts
  print(diff)

```

"
19814,How to make statistics script using summary?,"Hi, all

I want parameter distribution analysis script for pretrained models.
I do not want special script for each model, just want single program to do it.

Some person advised me to use the summary graph.
tensorflow/tensorflow/tools/graph_transforms/summarize_graph_main.cc

I check the code and fell that the code does not support extracting parameters from pb file.

I wrote a draft code to analyze;
https://github.com/ElectronNest/dist_nn/blob/master/testloads_nn.py

Any suggestion is welcome, and I am beginner, please explain softly.

Best,
Syouyu
"
19813,Documentation code for ScipyOptimizerInterface crashes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I have copied code from the documentation.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux zenon 4.15.0-22-generic #24-Ubuntu SMP Wed May 16 12:15:17 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""18.04 LTS (Bionic Beaver)""
VERSION_ID=""18.04""
VERSION_CODENAME=bionic

- **TensorFlow installed from (source or binary)**:
binary using pip
- **TensorFlow version (use command below)**:
tf.VERSION = 1.8.0
tf.GIT_VERSION = v1.8.0-0-g93bc2e2072
tf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072
Sanity check: array([1], dtype=int32)

- **Python version**: 
3.6

- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
9.0 / 7.1
- **GPU model and memory**:
```
    +-----------------------------------------------------------------------------+
    | NVIDIA-SMI 390.59                 Driver Version: 390.59                    |
    |-------------------------------+----------------------+----------------------+
    | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
    |===============================+======================+======================|
    |   0  GeForce GTX 965M    Off  | 00000000:01:00.0  On |                  N/A |
    | N/A   43C    P5     8W /  N/A |    379MiB /  2002MiB |      0%      Default |
    +-------------------------------+----------------------+----------------------+
```
- **Exact command to reproduce**:
N/A

### Describe the problem
Example code from the documentation of `tf.contrib.opt.ScipyOptimizerInterface` does not work. Was tried with tensorflow 1.8.0 and 1.7.1 on CPU and GPU.

The code crashed with an exception.

### Source code / logs

The code is mainly copied from [the documentation of ScipyOptimizerInterface](https://www.tensorflow.org/api_docs/python/tf/contrib/opt/ScipyOptimizerInterface), pasted into a file with additionnal imports.

test.py file:
```python
import tensorflow as tf
from tensorflow.contrib.opt import ScipyOptimizerInterface

vector = tf.Variable([7., 7.], 'vector')

# Make vector norm as small as possible.
loss = tf.reduce_sum(tf.square(vector))

optimizer = ScipyOptimizerInterface(loss, options={'maxiter': 100})

with tf.Session() as session:
  optimizer.minimize(session)
```
executed by:

```bash
$ python test.py
```

With the following output:

```
2018-06-06 17:34:36.869162: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
Traceback (most recent call last):
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1322, in _do_call
    return fn(*args)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1307, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1409, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Variable)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./test.py"", line 12, in <module>
    optimizer.minimize(session)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/external_optimizer.py"", line 195, in minimize
    initial_packed_var_val = session.run(self._packed_var)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Variable)]]

Caused by op 'Variable/read', defined at:
  File ""./test.py"", line 4, in <module>
    vector = tf.Variable([7., 7.], 'vector')
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 235, in __init__
    constraint=constraint)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py"", line 397, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name=""read"")
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 142, in identity
    return gen_array_ops.identity(input, name=name)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3187, in identity
    ""Identity"", input=input, name=name)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/mnt/data/amignon/Projets/mypython3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

FailedPreconditionError (see above for traceback): Attempting to use uninitialized value Variable
	 [[Node: Variable/read = Identity[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Variable)]]
```
"
19812,[feature request] Improve multinomial sampling efficiency,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: b'v1.8.0-0-g93bc2e2072'
- **Python version**:  3.5.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**:  Quadro M1200
- **Exact command to reproduce**: 

### Describe the problem
I need to perform several samplings from a multinomial distribution. The problem is that it is very slow. After debugging, using a **Profiler**, I've realized that it comes from this piece of code:

`math_ops.reduce_sum(array_ops.one_hot(x, depth=k), axis=-2)` (line 257 at this moment)

from [this python file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/distributions/multinomial.py)

Indeed, the code actually allocate a matrix for each row we want to sample. So it allocate too much memory for no actual reason! Here is my [stackoverflow post](https://stackoverflow.com/questions/50704004/tensorflow-efficient-multinomial-sampling-theano-x50-faster/50723793#50723793) for more detail about the problem

### Source code / logs
Actually Theano's implementation run x25 faster as described in my stackoverflow post. Also my (not so generic and not so fast solution) runs x3 times faster than the native TensorFlow sample function. Here is a snippet for comparison:

Using native implementation:
```python
import tensorflow as tf
import numpy as np
import tensorflow.contrib.distributions as ds
import time

tf.reset_default_graph()

nb_distribution = 100 # number of probabilities distribution

u = np.random.randint(2000, 3500, size=nb_distribution) # define number of counts (vector of size 100 with int in 2000, 3500)

# probsn is a matrix of probability:
# each row of probsn contains a vector of size 30 that sums to 1
probsn = np.random.uniform(size=(nb_distribution, 30))
probsn /= np.sum(probsn, axis=1)[:, None]

counts = tf.Variable(u, dtype=tf.float32)
probs = tf.Variable(tf.convert_to_tensor(probsn.astype(np.float32)))

# sample from the multinomial
dist = ds.Multinomial(total_count=counts, probs=probs)
out = dist.sample()


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    res = sess.run(out) # if remove this line the code is slower...
    start = time.time()
    res = sess.run(out)
    print(time.time() - start)
    print(np.all(u == np.sum(res, axis=1)))
```

On my computer it runs in **0.05** seconds

And here is my own (not generic) implementation of multinomial sampling that uses
`tf.scatter_nd()` function:


Using my own multinomial sampling:
```python
def vmultinomial_sampling(counts, pvals, seed=None):
    k = tf.shape(pvals)[1]
    logits = tf.expand_dims(tf.log(pvals), 1)

    def sample_single(args):
        logits_, n_draw_ = args[0], args[1]
        x = tf.multinomial(logits_, n_draw_, seed)
        indices = tf.cast(tf.reshape(x, [-1,1]), tf.int32)
        updates = tf.ones(n_draw_) # tf.shape(indices)[0]
        return tf.scatter_nd(indices, updates, [k])

    x = tf.map_fn(sample_single, [logits, counts], dtype=tf.float32)

    return x

xx = vmultinomial_sampling(u, probsn)
# check = tf.expand_dims(counts, 1) * probs

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    res = sess.run(xx) # if remove this line the code is slower...
    start_t = time.time()
    res = sess.run(xx)
    print(time.time() -start_t)
    #print(np.sum(res, axis=1))
    print(np.all(u == np.sum(res, axis=1)))
```

On my computer the code took **0.016** seconds to execute.

For comparison Theano's implementation takes **0.0025** seconds...


Indeed, my implementation doesn't take advantage of parallelization (changing the `parallel_iterations` in `map_fn` doesn't change anything. I'm using my GPU) while it totally makes sense that using parallel computations will improve the code because sampling from a specific row is independent from sampling from any other rows...


Do you think you can improve the code in order to avoid useless memory usage and allow parallel samplings?

Thank you."
19811,Change Number of Classes in MNIST Tutorial,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64-bit
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0-rc1
- **Python version**: 3.5.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

Hello, I'm trying to use the code in the [MNIST tutorial](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/examples/tutorials/layers/cnn_mnist.py) with my own dataset. The only thing I modified from the code was the data fed into the Estimator. The code runs well, but the issue is when I try to change the number of classes. The MNIST has 10 classes in total, while my dataset only has 3. For that, I change this specific line:

`logits = tf.layers.dense(inputs=dropout, units=10)`

to this:

`logits = tf.layers.dense(inputs=dropout, units=3`

Then it gives me the error:

> InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [1024,3] rhs shape= [1024,10]
	 [[Node: save/Assign_7 = Assign[T=DT_FLOAT, _class=[""loc:@dense_1/kernel""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](dense_1/kernel, save/RestoreV2_7)]]

I cannot, for the life of me, figure out which tensor creates the shape [1024, 10], other than that line I specified.

I tried searching in the Issues section for similar case, but couldn't find any. Forgive me if there is in fact the same issue posted here."
19810,[Request] Implement Stochastic Quasi-Newton optimizer(s),"Would be nice to have optimizers based on stochastic quasi-Newton methods. In particular, the SQN algorithm described in _Byrd, Richard H., et al. ""A stochastic quasi-Newton method for large-scale optimization."" SIAM Journal on Optimization 26.2 (2016): 1008-1031._ seems very promising.

Here is a reference repository with MATLAB implementations of such algorithms:
https://github.com/keskarnitish/minSQN

And this is the paper describing this particular method:
https://arxiv.org/pdf/1401.7020

Have I written custom code: N/A
OS Platform and Distribution: N/A
TensorFlow installed from: N/A
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A"
19809,Illegal Instruction Error when Importing TensorFlow Module,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary (native pip and Anaconda), also attempted compiling source and received same error
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: Tried 2.7 and 3.6.5
- **Bazel version (if compiling from source)**: 0.14.0
- **GCC/Compiler version (if compiling from source)**: 7.3.0
- **GPU model and memory**: CPU install only with 4GB memory
- **Exact command to reproduce**:

```python
import tensorflow as tf
```

### Describe the problem

When attempting to import the TensorFlow module into python the error `illegal instruction (core dumped)` is thrown.

I am installing TensorFlow as part of university research on a home lab rack server (HP Proliant DL380 G7 with Intel Xeon 5675 processors) with a Ubuntu 18.04 VM on a Hyper V host. When I complete the installation instructions and attempt to validate the instruction, I receive the above error message.

I've attempted in a local workstation virtual environment with VMware, and it worked fine (albeit with instruction warnings that did not impede expected results).

### Troubleshooting steps taken

* Reviewed StackOverflow community, wasn't able to find a resolution
  * We are required to use r1.8 so we're not able to downgrade to r1.5 at this time.
* Attempted both binary and compiled installation.
* Attempted installation via Anaconda and native pip for Python 2.7.n and Pyhon 3.6.5
* Tried a separate VM (using a local workstation)."
19807,tf.as_string: not support tf.string,"In tf.as_string, integers or boolean are mostly supported (int8, int32, int64,bool) but not tf.string. Why? Will it be added in the feature?"
19806,<fcntl.h>,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:


**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:


### Describe the problem
tensorflow/contrib/lite/allocation.cc:16:19: fatal error: fcntl.h: No such file or directory
 #include <fcntl.h>
                   ^
compilation terminated.
In file included from tensorflow/contrib/lite/arena_planner.cc:15:0:
./tensorflow/contrib/lite/arena_planner.h:18:18: fatal error: memory: No such file or directory
 #include <memory>
                  ^
compilation terminated.
In file included from ./tensorflow/contrib/lite/context.h:33:0,
                 from tensorflow/contrib/lite/context.c:16:
/Users/chenjiao04/Documents/android-ndk-r14b/toolchains/arm-linux-androideabi-4.9/prebuilt/darwin-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/include/stdint.h:9:26: fatal error: stdint.h: No such file or directory
 # include_next <stdint.h>
                          ^
compilation terminated.

"
19802,TensorFlow lite .pb turn .tflite An error,"Error message  
  

``     F tensorflow/contrib/lite/toco/toco.cc:76] Check failed: has_input_file != has_savedmodel_dir (0 vs. 0)Specify either input_file or savedmodel_directory flag.`
`
frozen_graph
https://storage.googleapis.com/download.tensorflow.org/models/mobilenet_v1_1.0_224_frozen.tgz

Convert command

```
    bazel run toco  \
      input_file=/Users/dchealth/Desktop/mobilenet/frozen_graph.pb \
      output_file=/Users/dchealth/Desktop/mobilenet/frozen_graphnew.tflite \
      output_format=TFLITE \
      input_format=TENSORFLOW_GRAPHDEF \
      inference_type=FLOAT \
      input_type=FLOAT \
      input_shapes=1,128,128,3 \
      input_arrays=input \
      output_arrays=MobilenetV1/Predictions/Reshape_1

```


- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:mac os
 Could you update them if they are relevant in your case, or leave them as N/A? Thanks.
Have I written custom code：NO
TensorFlow installed from:Install directly with the PIP command
TensorFlow version：1.8.0
Bazel version:
Build label: 0.14.0-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 1 14:26:58 2018 (1527863218)
Build timestamp: 1527863218
Build timestamp as int: 1527863218

CUDA/cuDNN version：no
GPU model and memory:no
Exact command to reproduce：no"
19801,"""TypeError: Cannot interpret feed_dict key as Tensor: The name 'tf_new_X:0' refers to a Tensor which does not exist. The operation, 'tf_new_X', does not exist in the graph.""This error I get while I was deploying my model on the server. Can anyone please help ?","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19800,Tensorflow 1.8 build failed while enabling MPI,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux release 7.5.1804 and RHEL 7.3 (both) 

- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.8.0-2735-g5d44932', '1.8.0')
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.14
- **GCC/Compiler version (if compiling from source)**:  4.8.5 20150623
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: build from source instructions

### Describe the problem

Tensorflow -1.8 build failed while enabling MPI in the configuration. Tensorflow is build using the normal build from source instructions.It was possible to enable MPI in building TF 1.7.

### Source code / logs

C++ compilation of rule '//tensorflow/contrib/mpi_collectives:python/ops/_mpi_ops.so' failed (Exit 1)
tensorflow/contrib/mpi_collectives/kernels/mpi_ops.cc:76:18: error: expected type-specifier before 'se'
 using StatusOr = se::port::StatusOr<T>;


"
19799,Problems in switching to different datasets with iterator after restoring a pre-trained model for fine-tuning,"Have I written custom code Yes
OS Platform and Distribution ubuntu 16.04 LTS
TensorFlow installed from pip3 install tensorflow-gpu
TensorFlow version the latest version
Bazel version NA
CUDA/cuDNN version CUDA Toolkit 9.0
GPU model and memory GeForce GTX 1080
Exact command to reproduce NA

I write a separate script to load the pre-trained model for fine-tuning with different datasets, then how do I get reference to the iterator and initialize it with fine_tune_dataset?

The following is a part of code in the script for training:

```
train_dataset = dataset_input_fn([‘/path/to/training_dataset’])
 validate_dataset = dataset_input_fn([‘/path/to/validation_dataset’])
 
 # create general iterator by the from_structure() method which needs the information of output data size/shape
 iterator = tf.data.Iterator.from_structure(train_dataset.output_types)
 data_batch, label_batch = iterator.get_next()

# make datasets that we can initialize seperately. 
 train_init_op = iterator.make_initializer(train_dataset)
 validate_init_op = iterator.make_initializer(validate_dataset)

accuracy, loss, train_op = model_function(data_batch, label_batch)

The following is the part of code in a separate script for restoring pre-trained model and fine_tune:

fine_tune_dataset = dataset_input_fn(['/path/to/fine_tune_model'])
validate_dataset = dataset_input_fn(['/path/to/validate_model'])
# make datasets that we can initialize seperately.
iterator = tf.data.Iterator.from_structure(fine_tune_dataset.output_types)
fine_tune_init_op = iterator.make_initializer(fine_tune_dataset)
validate_init_op = iterator.make_initializer(validate_dataset)
```
However, when I ran the script for fine-tuning, an error was given:

FailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.

I did call sess.run(fine_tune_init_op) in the fine-tuning part which did not show in the above. Could you please help me with how to switch to fine_tune_dataset after restoring pre-trained model in a different script? Thanks for your time in advance.

"
19798,tflite toco build failed in version of 3daa07aa2dde379388beb2a557a78bc5dd1b86ba,"### System information
- Have I written custom code : No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: tensorflow 1.8
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: 6.4
- **CUDA/cuDNN version**: None
- **GPU model and memory**: GeForce GTX 750
- **Exact command to reproduce**: tensorflow code :
 commit 3daa07aa2dde379388beb2a557a78bc5dd1b86ba
Author: Courtial Florian <floriancourtial@gmail.com>
Date:   Wed Jun 6 01:02:07 2018 +0200
    Add C++ no gradient for Floor operation. (#19662)

### Describe the problem
Use cmd below: 
bazel build --config android_arm --cxxopt=-std=c++11  //tensorflow/contrib/lite/toco:toco   --config monolithic

My WORKSPACE as below:
WORKSPACE

android_sdk_repository(
    name = ""androidsdk"",
    api_level = 22,
    # Ensure that you have the build_tools_version below installed in the
    # SDK manager as it updates periodically.
    build_tools_version = ""27.0.3"",
    # Replace with path to Android SDK on your system
    path = ""/home/hwh/Android/Sdk"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/home/hwh/Android/Ndk/android-ndk-r14b"",
    # This needs to be 14 or higher to compile TensorFlow.
    # Please specify API level >= 21 to build for 64-bit architecture
    # otherwise the Android NDK will automatically select the latest
    # API level it does support without notice.
    # Note that the NDK version is not the API level.
    api_level=14)

build failed as below:
INFO: Found 1 target...
ERROR: /home/hwh/.cache/bazel/_bazel_hwh/a5d93fc2a8e4cfbb4b042a3b705d2c38/external/gif_archive/BUILD.bazel:8:1: C++ compilation of rule '@gif_archive//:gif' failed (Exit 1)
external/gif_archive/lib/openbsd-reallocarray.c:33:19: error: use of undeclared identifier 'SIZE_MAX'
            nmemb > 0 && SIZE_MAX / nmemb < size) {
                         ^
1 error generated.
Target //tensorflow/contrib/lite/toco:toco failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 167.962s, Critical Path: 29.34s
INFO: 374 processes, local.
FAILED: Build did NOT complete successfully





"
19795,Tensorflow logs everything twice while training,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS Sierra version 10.12.6
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.6.5
- **Bazel version (if compiling from source)**:
0.13.0
- **GCC/Compiler version (if compiling from source)**:
GCC 4.2.1

### Describe the problem
I'm training an object detection model using the new `ssdlite_mobilenet_v2_coco_2018_05_09` and it's configuration file `ssdlite_mobilenet_v2_coco.config` and tensorflow installed from source. When I launch the training tensorflow starts printing the same info twice. 

This problem didn't happen while training the same network I'm trying to get, with a different model (checkpoint)  `ssd_mobilenet_v1_coco_2017_11_17` and the configuration file `ssd_mobilenet_v1_pets.config` and with tensorflow installed from pip (I tested with version 1.6.0 and 1.8.0) 

NOTE : I didn't change the code in both cases and I wonder what's the cause of this.

### Source code / logs

```
INFO:tensorflow:global step 3292: loss = 3.2832 (2.960 sec/step)
INFO:tensorflow:global step 3292: loss = 3.2832 (2.960 sec/step)
INFO:tensorflow:global step 3293: loss = 3.5285 (3.675 sec/step)
INFO:tensorflow:global step 3293: loss = 3.5285 (3.675 sec/step)
INFO:tensorflow:global step 3294: loss = 2.3972 (3.564 sec/step)
INFO:tensorflow:global step 3294: loss = 2.3972 (3.564 sec/step)
INFO:tensorflow:Recording summary at step 3294.
INFO:tensorflow:Recording summary at step 3294.
INFO:tensorflow:global_step/sec: 0.294019
INFO:tensorflow:global_step/sec: 0.294019
```
"
19791,r,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19778,tensorflow.contrib.model_pruning: using illegal summary names,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

Calling [`add_pruning_summaries()`](https://github.com/tensorflow/tensorflow/blob/83543deedb68fef61ea7e709de3f462a1edd13ce/tensorflow/contrib/model_pruning/python/pruning.py#L509) leads to illegal summary names for the masks that contain colons, due to `tf.Variable.name` being used instead of `tf.Variable.op.name` (as is done for the [thresholds](https://github.com/tensorflow/tensorflow/blob/83543deedb68fef61ea7e709de3f462a1edd13ce/tensorflow/contrib/model_pruning/python/pruning.py#L524)). This leads to TensorFlow printing the following info:

> INFO:tensorflow:Summary name model/Conv/mask:0/sparsity is illegal; using model/Conv/mask_0/sparsity instead.

Which I think is unnecessary. I will create a PR to let the summary name for masks make use of `tf.Variable.op.name` as well.
"
19777,how to use map_fn to output different shaped tensors,"The result of my processed unpacked tensors may have different shape, but map_fn can only output consisstent shaped tensors, how to achieve that so the output can list of different sized tensors?"
19776,einsum contraction order (is undocumented),"### Describe the problem
The documentation for `tf.einsum` does not specify the order of the contraction. However, for contractions with three and more tensors, the contraction order is crucial as it determines the runtime complexity. The only thing one finds in the documentation is the following:

> This function behaves like `numpy.einsum` [...]

The `numpy.einsum` function has an additional parameter `optimize` and is able to peform a greedy optimisation for the contraction order. As far as I understood the tensorflow code, `tf.einsum` simply contracts tensors from left to right.
Would it be possible to adopt the optimisation code from numpy for tensorflow? If not, at least the documentation should indicate the contraction order. Thank you!"
19775,Tensorflow python version incompatibility,"Hey,

I use `inceptionv3` to classify various images. I experienced that images are classified with a different probabillity on different versions of python. I set up three environments:
1. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.6.2 with anaconda (no gpu support) (Windows 10)
2. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 2.7.12 installed via plain pip. (no GPU) (Ubuntu 16.04)
3. Tensorflow (b'v1.8.0-0-g93bc2e2072' 1.8.0) with python 3.5.2 installed via plain pip. (no GPU) (Ubuntu 16.04)

Environment 1 and 3 give the same results. Using python2 gives the lower probabilities on the correct class than given by the other two setups.

Heres a little example I just created to outline the error and show how the classification performed:
```python
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import json, os

import tensorflow as tf
import tensorflow.contrib.slim as slim
from tensorflow.contrib.slim.nets import inception

FLAGS = tf.flags.FLAGS
tf.flags.DEFINE_string('image_name', 'cropped_panda.jpg', 'Image name with file ending.')
tf.flags.DEFINE_integer('top_k', 5, 'Top k predictions to print out.')
tf.flags.DEFINE_integer('image_height', 299, 'The image height for inception_v3 model.')
tf.flags.DEFINE_integer('image_width', 299, 'The image width for inception_v3 model.')
tf.flags.DEFINE_integer('image_channels', 3, 'The number of channels of for inception_v3 model.')
tf.flags.DEFINE_integer('image_N_classes', 1000, 'The number of classes in the inception_v3 model.')
tf.flags.DEFINE_float('weight_decay', 0.0, 'The weight decay applied to each edge/weight at each update step.')


def load_images(batch_shape, pathPrefix='../../images/'):
    num_images = batch_shape[0]
    image_path = os.path.join(pathPrefix, FLAGS.image_name)
    image = Image.open(image_path)

    # crop
    wide = image.width > image.height
    new_w = FLAGS.image_width if not wide else int(image.width * FLAGS.image_width / image.height)
    new_h = FLAGS.image_height if wide else int(image.height * FLAGS.image_height / image.width)

    images = np.zeros(batch_shape)
    for idx in range(num_images):
        image = image.resize((new_w, new_h)).crop((0, 0, FLAGS.image_width, FLAGS.image_height))
        image = (np.asarray(image) / 255.0).astype(np.float32)
        images[idx, :, :, :] = image
    return images


def get_logits(image_placeholder):
    preprocessed = tf.multiply(tf.subtract(image_placeholder, 0.5), 2.0)
    arg_scope = inception.inception_v3_arg_scope(weight_decay=FLAGS.weight_decay)
    with slim.arg_scope(arg_scope):
        logits, _ = inception.inception_v3(
            preprocessed, FLAGS.image_N_classes + 1, is_training=False, reuse=False)
        logits = logits[:, 1:]
        probs = tf.nn.softmax(logits)
    return logits, probs


def get_inception_session(sess=None, pathToInception='../../'):
    saver = tf.train.Saver()
    saver.restore(sess, os.path.join(pathToInception, 'inception_v3.ckpt'))
    return sess


def main(argsunused):
    images = load_images((1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))
    image_placeholder = tf.placeholder(tf.float32, (1, FLAGS.image_height, FLAGS.image_width, FLAGS.image_channels))
    logits, preds = get_logits(image_placeholder)

    with tf.Session() as sess:
        sess = get_inception_session(sess)
        top_k = tf.nn.top_k(preds, k=FLAGS.top_k)
        values, indices = sess.run([top_k.values, top_k.indices], feed_dict={image_placeholder: images})
        for (index, value) in zip(indices[0], values[0]):
            print(""Class %d with prob: %f"" % (index, value))


if __name__ == '__main__':
    tf.app.run()
```
If I misssused something here, please be so kind and explain my mistake:)

Regards

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes. Uses the elements shown in the example.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: See above (windows and ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: b'v1.8.0-0-g93bc2e2072' 1.8.0
- **Python version**: 2.7.12, 3.5.2, 3.6.2
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: -"
19774,metagraph loading fails with 'No op named ImageProjectiveTransform' message,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary, installed with pip3
- **TensorFlow version (use command below)**:
v1.8.0-0-g93bc2e2072
- **Python version**: 
3.5

### Describe the problem
I'm trying to load a metagraph file saved with tf-v1.4.0-rc1-11-g130a514. Loading fails with the following error: 

```
  File ""/home/vyal/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py"", line 1955, in import_meta_graph
    **kwargs)
  File ""/home/vyal/.local/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py"", line 743, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/home/vyal/.local/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/vyal/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 460, in import_graph_def
    _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
  File ""/home/vyal/.local/lib/python3.5/site-packages/tensorflow/python/framework/importer.py"", line 227, in _RemoveDefaultAttrs
    op_def = op_dict[node.op]
KeyError: 'ImageProjectiveTransform'
```

I thought it's the result of some backward incompability so I retested on python2.7 and tf-v1.4.0-rc1-11-g130a514. Getting very similar message:

```
In [3]: tf.train.import_meta_graph('00000000000001107000.meta')
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-3-6d533993d6fe> in <module>()
----> 1 tf.train.import_meta_graph('00000000000001107000.meta')

/home/marin/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1808                                       clear_devices=clear_devices,
   1809                                       import_scope=import_scope,
-> 1810                                       **kwargs)
   1811   if meta_graph_def.HasField(""saver_def""):
   1812     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)

/home/marin/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)
    658     importer.import_graph_def(
    659         input_graph_def, name=(import_scope or """"), input_map=input_map,
--> 660         producer_op_list=producer_op_list)
    661 
    662     scope_to_prepend_to_names = ""/"".join(

/home/marin/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)
    283       # Set any default attr values that aren't present.
    284       if node.op not in op_dict:
--> 285         raise ValueError('No op named %s in defined operations.' % node.op)
    286       op_def = op_dict[node.op]
    287       for attr_def in op_def.attr:

ValueError: No op named ImageProjectiveTransform in defined operations.
```

"
19773,I have a problem with a script python that launch a choregraphe behavior,"
I have this script write in python 2.7:
from naoqi import ALProxy

tts = ALProxy(""ALBehaviorManager"", ""127.0.0.1"" , 9559)
tts.runBehavior(""<NomeBehavior>"");

when launch this script, however, i have this result:
Traceback (most recent call last):
  File ""C:\Users\franc\eclipse-workspace\Connection\src\connection.py"", line 7, in <module>
    from naoqi import ALProxy
  File ""C:\Program Files (x86)\Aldebaran\Choregraphe 1.14.5.1\lib\naoqi.py"", line 14, in <module>
    import _inaoqi_d as _inaoqi
ImportError: DLL load failed: Impossibile trovare il modulo specificato.
Could not find _inaoqi, trying with _inaoqi_d


someone knows how to solve it? 
"
19772,I have a problem with a python script that launch a choregraphe behavior,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19771,tensordot/conj interplay,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux 7, Kernel 3.10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: Python 3.6.2 :: Continuum Analytics, Inc.
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 9.0.176 (but not in use)
- **GPU model and memory**: GeForce GTX 1080 (but not in use)
- **Exact command to reproduce**: execute python script below

### Describe the problem
I am using the code below to contract four tensors `A[l,m,n] B[q,l,i] C[j,p,m,q] conj(D[p,n,k])` using a series of tensordot operations. To verify the result, I compare tensorflow with pure numpy. It seems like the `tf.conj` node is ignored (or an additional conjugation is executed) when executing tensorflow's `tensordot`s, as the first `print` gives me `False` and the second one `True`, although it should be the other way round. Just as a remark: The third part of my code uses `einsum` instead and works as intended (output of the third `print` should be `True` and is indeed `True`). Thank you for your help!

### Source code / logs
```python
import numpy as np
import tensorflow as tf

n = 100
m = 4
dtype = np.complex128

### generate random tensors ###

def rand(*shape):
    return np.asarray(
        np.random.random(shape) + 1j*np.random.random(shape),
        dtype
    )

A = rand(n, m, n)
B = rand(m, n, n)
C = rand(m, m, m, m)
D = rand(m, n, n)

### perform numpy computation ###

X_np = np.tensordot(A, B, (0,1))
Y_np = np.tensordot(X_np, C, ((0,2),(2,3)))
Z_np = np.tensordot(Y_np, D.conj(), ((3,0),(0,1)))

### build tensorflow computation graph ###

A_node = tf.placeholder(dtype, (n, m, n))
B_node = tf.placeholder(dtype, (m, n, n))
C_node = tf.placeholder(dtype, (m, m, m, m))
D_node = tf.placeholder(dtype, (m, n, n))

X_node = tf.tensordot(A_node, B_node, (0,1))
Y_node = tf.tensordot(X_node, C_node, ((0,2),(2,3)))
Z_node = tf.tensordot(Y_node, tf.conj(D_node), ((3,0),(0,1)))

### run tensorflow computation ###

session = tf.Session()
Z_tf = session.run(
    Z_node, feed_dict={A_node: A, B_node: B, C_node: C, D_node: D}
)
session.close()

### compare results ###

print(np.allclose(Z_np, Z_tf))

### run tensorflow computation again with numpy conj ###

session = tf.Session()
Z_tf = session.run(
    Z_node, feed_dict={A_node: A, B_node: B, C_node: C, D_node: D.conj()}
)
session.close()

### compare results ###

print(np.allclose(Z_np, Z_tf))

### build tensorflow computation graph using einsum ###

W_node = tf.einsum(
    ""lmn,qli,jpmq,pnk->ijk"", A_node, B_node, C_node, tf.conj(D_node)
)

session = tf.Session()
W_tf = session.run(
    W_node, feed_dict={A_node: A, B_node: B, C_node: C, D_node: D}
)
session.close()

print(np.allclose(Z_np, W_tf))
```
### Output
```
False
True
True
```
"
19770,"Tensorflow 1.8.0 Java tests fail with error ""Building Java resource jar failed (Segmentation fault): singlejar failed""","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 s390x
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.8.0
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**: 0.12.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **JDK Version**:
```
test@f6c9f944adde:~/tensorflow$ java -version
openjdk version ""1.8.0_171""
OpenJDK Runtime Environment (build 1.8.0_171-8u171-b11-0ubuntu0.16.04.1-b11)
OpenJDK 64-Bit Zero VM (build 25.171-b11, interpreted mode)
```
- **Exact command to reproduce**:
```
test@f6c9f944adde:~/tensorflow$ ./configure  
  Extracting Bazel installation...
  You have bazel 0.12.0- (@non-git) installed.
  Please specify the location of python. [Default is /usr/bin/python]:


  Found possible Python library paths:
    /usr/local/lib/python2.7/dist-packages
    /usr/lib/python2.7/dist-packages
  Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

  Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y
  jemalloc as malloc support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: N
  No Google Cloud Platform support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: N
  No Hadoop File System support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: N
  No Amazon S3 File System support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: N
  No Apache Kafka Platform support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with XLA JIT support? [y/N]: N
  No XLA JIT support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with GDR support? [y/N]: N
  No GDR support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with VERBS support? [y/N]: N
  No VERBS support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: N
  No OpenCL SYCL support will be enabled for TensorFlow.

  Do you wish to build TensorFlow with CUDA support? [y/N]: N
  No CUDA support will be enabled for TensorFlow.

  Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
  Clang will not be downloaded.

  Do you wish to build TensorFlow with MPI support? [y/N]: N
  No MPI support will be enabled for TensorFlow.

  Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]:


  Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
  Not configuring the WORKSPACE for Android builds.

  Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
  Configuration finished
```

Build tensorflow using 
```
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
```

Execute the tests 
```
test@f6c9f944adde:~/tensorflow$ bazel --host_jvm_args=""-Xms512m"" --host_jvm_args=""-Xmx1024m"" test --test_timeout 300,450,1200,3600 --build_tests_only -- //tensorflow/java/...
WARNING: /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
INFO: Analysed 13 targets (3 packages loaded).
INFO: Found 13 test targets...
Slow read: a 17792073-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/lib/ct.sym took 279596ms.
Slow read: a 660545-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/jsse.jar took 8904ms.
Slow read: a 65000897-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/rt.jar took 1050262ms.
Slow read: a 407746-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/lib/jconsole.jar took 7045ms.
Slow read: a 2033434-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/ext/nashorn.jar took 36359ms.
Slow read: a 3861228-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/ext/cldrdata.jar took 69984ms.
Slow read: a 7615736-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/s390x/server/libjvm.so took 139747ms.
Slow read: a 923944-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/s390x/libmlib_image.so took 18312ms.
Slow read: a 1178929-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/ext/localedata.jar took 20124ms.
Slow read: a 3135616-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/charsets.jar took 54969ms.
Slow read: a 3509496-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/resources.jar took 52916ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sstring_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 295367ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Suser_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 295164ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sno_Uop_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 219115ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sarray_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 210040ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sstate_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 228118ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Smath_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 211957ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Scandidate_Usampling_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 209071ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Snn_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 220945ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Scontrol_Uflow_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 204621ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Slogging_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 215215ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Straining_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 202976ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sio_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 197636ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Srandom_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 157546ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Ssparse_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 185855ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sdata_Uflow_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 194397ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Sparsing_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 194407ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Slinalg_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 192693ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/bin/_solib_piii/_U_S_Stensorflow_Sjava_Cops_Simage_Uops_Ugen_Utool___Utensorflow/libtensorflow_framework.so took 171085ms.
Slow read: a 807616-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/jre/lib/s390x/libawt.so took 10783ms.
Slow read: a 18318086-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/local_jdk/lib/tools.jar took 189336ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/s390x-opt/bin/_solib_piii/_U_S_Stensorflow_Sjava_Clibtensorflow_Ujni.so___Utensorflow/libtensorflow_framework.so took 150482ms.
Slow read: a 6885456-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/bazel_tools/third_party/java/jdk/langtools/javac-9+181-r4173-1.jar took 52658ms.
Slow read: a 9200450-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/bazel_tools/tools/jdk/turbine_deploy.jar took 71876ms.
Slow read: a 37198458-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath-impl.jar took 426726ms.
Slow read: a 16268324-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/host/genfiles/external/bazel_tools/tools/jdk/platformclasspath.jar took 190506ms.
Slow read: a 11497298-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/external/bazel_tools/tools/jdk/JavaBuilder_deploy.jar took 141703ms.
ERROR: /home/test/tensorflow/tensorflow/java/BUILD:54:1: Building Java resource jar failed (Segmentation fault): singlejar failed: error executing command external/bazel_tools/tools/jdk/singlejar/singlejar --normalize --dont_change_compression --exclude_build_data --output bazel-out/host/bin/tensorflow/java/libprocessor_library.jar --sources ... (remaining 3 argument(s) skipped)
Slow read: a 49095408-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/s390x-opt/bin/tensorflow/java/libtensorflow_jni.so took 521931ms.
Slow read: a 17320112-byte read from /home/test/.cache/bazel/_bazel_test/24685d064c07f7346b48c2d13ec3ad69/execroot/org_tensorflow/bazel-out/s390x-opt/bin/_solib_piii/_U_S_Stensorflow_Sjava_Csource_Uwriter_Utest___Utensorflow/libtensorflow_framework.so took 230369ms.
INFO: Elapsed time: 7966.630s, Critical Path: 2784.06s
FAILED: Build did NOT complete successfully
//tensorflow/java:ConstantTest                                        NO STATUS
//tensorflow/java:OperandsTest                                        NO STATUS
//tensorflow/java:OperationBuilderTest                                NO STATUS
//tensorflow/java:OperationTest                                       NO STATUS
//tensorflow/java:PrimitiveOpTest                                     NO STATUS
//tensorflow/java:SavedModelBundleTest                                NO STATUS
//tensorflow/java:ScopeTest                                           NO STATUS
//tensorflow/java:SessionTest                                         NO STATUS
//tensorflow/java:ShapeTest                                           NO STATUS
//tensorflow/java:TensorFlowTest                                      NO STATUS
//tensorflow/java:TensorTest                                          NO STATUS
//tensorflow/java:source_writer_test                                  NO STATUS

Executed 0 out of 13 tests: 1 fails to build and 12 were skipped.
```

### Describe the problem
I have successfully compiled tensorflow from source using same configure procedure as above and built it with the following command:
```
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
```

After that I tried executing the tests which failed with the error as stated above. I tried running just a single test from the Java module which produced the same error as above with the following error:
```
ERROR: /home/test/tensorflow/tensorflow/java/BUILD:54:1: Building Java resource jar failed (Segmentation fault): singlejar failed: error executing command external/bazel_tools/tools/jdk/singlejar/singlejar --normalize --dont_change_compression --exclude_build_data --output bazel-out/host/bin/tensorflow/java/libprocessor_library.jar --sources ... (remaining 3 argument(s) skipped)
```"
19768,Unity Tensorflow crash,"Have I written custom code: NO
OS Platform and Distribution: MacOS
TensorFlow installed from: source
TensorFlow version: 1.8
Bazel version: Build label: 0.13.1-homebrew
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: NA

I am using the example for Android. I try to build it to `.aar` file. I put the aar file to `Plugins/Android`. And put the .so file to `Assets/Plugins/Android/libs` When I start the apps, I got the crash. 

> 06-05 16:50:17.865 26605 26639 E AndroidRuntime: Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'All' with these attrs.  Registered devices: [CPU], Registered kernels:
06-05 16:50:17.865 26605 26639 E AndroidRuntime:   <no registered kernels>
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	 [[Node: assert_equal/All = All[Tidx=DT_INT32, keep_dims=false](assert_equal/Equal, assert_equal/Const)]]
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.Session.run(Native Method)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.Session.access$100(Session.java:48)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.Session$Runner.runHelper(Session.java:285)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.Session$Runner.run(Session.java:235)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:142)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:289)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at android.os.Handler.handleCallback(Handler.java:751)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at android.os.Handler.dispatchMessage(Handler.java:95)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at android.os.Looper.loop(Looper.java:154)
06-05 16:50:17.865 26605 26639 E AndroidRuntime: 	at android.os.HandlerThread.run(HandlerThread.java:61)"
19766,Illegal instruction (core dumped) When importing tensorflow,"### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: source
- **TensorFlow version**: 1.8
- **Python version**: 2.7.12
- **Bazel version**: 0.14.0
- **GCC/Compiler version**: 5.4.0
- **CUDA/cuDNN version**: 9.2/7.1.4
- **GPU model and memory**: GeForce GT 740 4GB
- **Exact command to reproduce**: `import tensorflow`

### Describe the problem
`Illegal instruction (core dumped)` upon importing tensorflow.

### Source code / logs (gdb output)
```
#0  0x00007fffd4c3891f in std::_Hashtable<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> >, std::__detail::_Select1st, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_Hashtable<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> const*>(std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> const*, std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> const*, unsigned long, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::__detail::_Mod_range_hashing const&, std::__detail::_Default_ranged_hash const&, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > const&, std::__detail::_Select1st const&, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, tensorflow::Node::NodeClass> > const&) () from /home/avidbeam/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#1  0x00007fffd4b75acc in __static_initialization_and_destruction_0(int, int) [clone .constprop.386] ()
   from /home/avidbeam/.local/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#2  0x00007ffff7de76ba in call_init (l=<optimized out>, argc=argc@entry=1, argv=argv@entry=0x7fffffffdcb8, 
    env=env@entry=0xacaf00) at dl-init.c:72
#3  0x00007ffff7de77cb in call_init (env=0xacaf00, argv=0x7fffffffdcb8, argc=1, l=<optimized out>) at dl-init.c:30
#4  _dl_init (main_map=main_map@entry=0xe25890, argc=1, argv=0x7fffffffdcb8, env=0xacaf00) at dl-init.c:120
#5  0x00007ffff7dec8e2 in dl_open_worker (a=a@entry=0x7fffffffbcb0) at dl-open.c:575
#6  0x00007ffff7de7564 in _dl_catch_error (objname=objname@entry=0x7fffffffbca0, 
    errstring=errstring@entry=0x7fffffffbca8, mallocedp=mallocedp@entry=0x7fffffffbc9f, 
    operate=operate@entry=0x7ffff7dec4d0 <dl_open_worker>, args=args@entry=0x7fffffffbcb0) at dl-error.c:187
#7  0x00007ffff7debda9 in _dl_open (
    file=0x7fffdfd37384 ""/home/avidbeam/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so"", mode=-2147483646, caller_dlopen=0x51ad19 <_PyImport_GetDynLoadFunc+233>, nsid=-2, argc=<optimized out>, 
    argv=<optimized out>, env=0xacaf00) at dl-open.c:660
#8  0x00007ffff75ecf09 in dlopen_doit (a=a@entry=0x7fffffffbee0) at dlopen.c:66
#9  0x00007ffff7de7564 in _dl_catch_error (objname=0x9b91d0, errstring=0x9b91d8, mallocedp=0x9b91c8, 
    operate=0x7ffff75eceb0 <dlopen_doit>, args=0x7fffffffbee0) at dl-error.c:187
#10 0x00007ffff75ed571 in _dlerror_run (operate=operate@entry=0x7ffff75eceb0 <dlopen_doit>, 
    args=args@entry=0x7fffffffbee0) at dlerror.c:163
#11 0x00007ffff75ecfa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87
#12 0x000000000051ad19 in _PyImport_GetDynLoadFunc ()
#13 0x000000000051a8e4 in _PyImport_LoadDynamicModule ()
#14 0x00000000005b7b1b in ?? ()
#15 0x00000000004bc3fa in PyEval_EvalFrameEx ()
#16 0x00000000004c136f in PyEval_EvalFrameEx ()
#17 0x00000000004b9ab6 in PyEval_EvalCodeEx ()
#18 0x00000000004b97a6 in PyEval_EvalCode ()
#19 0x00000000004b96df in PyImport_ExecCodeModuleEx ()
#20 0x00000000004b2b06 in ?? ()
#21 0x00000000004a4ae1 in ?? ()
#22 0x00000000004a4513 in PyImport_ImportModuleLevel ()
```
"
19765, from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin ImportError: No module named 'tensorflow.tools.api',"I came across this issue when I import tensorflow on a server:
the configurations are as follows:
Ubuntu 16.04.4 LTS
Kernel: 4.13.0-1011
Tensorflow 0.18

>>> import tensorflow
/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/__init__.py"", line 26, in <module>
    from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin
ImportError: No module named 'tensorflow.tools.api'

Any idea how to solve this problem?  
Thanks!
"
19764, auto load_file_system_library,"From https://www.tensorflow.org/extend/add_filesys we can build a custom filesystem plugin, and explictily load it like this :

```
from tensorflow.python.framework import load_library
load_library.load_file_system_library(""xxxx.so"")
```
But this is hard to use, and user who want to use xxxx.so `must change his code`.
Is there a way to call `load_library.load_file_system_library` automatically when a environment variable such as `FILE_SYSTEM_LIBRARY` is set.

To sum up with a user story:
1. user set environment variable  FILE_SYSTEM_LIBRARY=xxxx.so
2. user use xxxx.so related method in his script directly without explictily loading  xxxx.so."
19763, Key linear_model/two_linear_1/batch_normalization21/gamma/Adam_1 not found in checkpoint,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19762,TF dataset padded_batch: support for batching non-padable component,"Current` tf.data.dataset `class only support `padded_batch` method which would pad every component into same shape, but there are cases that some component may not be padable, e.g., in object detection input pipeline, the ground truth calsses and bounding boxes are different for different image, so they can not be padded to the same shape as images, so how to batch these data in this case?"
19761,"[bug]Function ""NumHyperthreadsPerCore"" may be forgotten to add into windows/port.cc","### System information
- **I did not alter any code**:
- **Windows 10 1803 (Ver. 17134.81)**:
- **TensorFlow installed from source**:
- **TensorFlow version: 1.8.0**:
- **Python version: 3.6.4**: 
- **No Bazel**:
- **Microsoft Visual Studio 2015**:
- **CUDA 9.2.88 / cuDNN 7.1.4**:
- **NVIDIA GTX 1070 8GB**:
- **Build project ""tf_python_build_pip_package"" in Release configuration**:

### Describe the problem
The project ""pywrap_tensorflow_internal"" failed to build, and error was:

> threadpool_device.obj : error LNK2019: unresolved external symbol ""int __cdecl tensorflow::port::NumHyperthreadsPerCore(void)"" (?NumHyperthreadsPerCore@port@tensorflow@@YAHXZ) in function ""public: __cdecl tensorflow::ThreadPoolDevice::ThreadPoolDevice(struct tensorflow::SessionOptions const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class tensorflow::gtl::IntType<struct tensorflow::Bytes_tag_,__int64>,class tensorflow::DeviceLocality const &,class tensorflow::Allocator *)"" (??0ThreadPoolDevice@tensorflow@@QEAA@AEBUSessionOptions@1@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@V?$IntType@UBytes_tag_@tensorflow@@_J@gtl@1@AEBVDeviceLocality@1@PEAVAllocator@1@@Z)

Finally I found that function `NumHyperthreadsPerCore` was not implemented in _**tensorflow/core/platform/windows/port.cc**_, while it was implemented in _**tensorflow/core/platform/posix/port.cc**_. Then I copy this function from **_posix/port.cc_** to **_windows/port.cc_**, it worked.

### Source code
**_tensorflow/core/platform/posix/port.cc_** line 77-80:
```
int NumHyperthreadsPerCore() {
    static const int ht_per_core = tensorflow::port::CPUIDNumSMT();
    return (ht_per_core > 0) ? ht_per_core : 1;
}
```
"
19760,tflitecamerademo error,"hi,
    I test tflitecamerademo in tensorflow\contrib\lite\java\demo

Prompt me to download the file every day, and then compile it after downloading. Do these library files need to be updated every day? :
Error:A problem occurred configuring project ':app'.
> Could not resolve all dependencies for configuration ':app:_debugApkCopy'.
   > Could not resolve org.tensorflow:tensorflow-lite:+.
     Required by:
         project :app
      > Could not resolve org.tensorflow:tensorflow-lite:+.
         > Failed to list versions for org.tensorflow:tensorflow-lite.
            > Unable to load Maven meta-data from https://jcenter.bintray.com/org/tensorflow/tensorflow-lite/maven-metadata.xml.
               > Could not GET 'https://jcenter.bintray.com/org/tensorflow/tensorflow-lite/maven-metadata.xml'.
                  > jcenter.bintray.com
      > Could not resolve org.tensorflow:tensorflow-lite:+.
         > Failed to list versions for org.tensorflow:tensorflow-lite.
            > Unable to load Maven meta-data from https://google.bintray.com/tensorflow/org/tensorflow/tensorflow-lite/maven-metadata.xml.
               > Could not GET 'https://google.bintray.com/tensorflow/org/tensorflow/tensorflow-lite/maven-metadata.xml'.
                  > google.bintray.com

------------------------------------------------------------------------------------------------------
Another question, how to compile tflite.so by yourself instead of using downloaded tflite.so

thanks."
19758,CUDA,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19756,Android demo bug ,"Have I written custom code: no
OS Platform and Distribution: MacOs, Android 8.0
TensorFlow installed from: pip
TensorFlow version: 1.8.0
Bazel version: None
CUDA/cuDNN version: None, cpu version
GPU model and memory: None
Exact command to reproduce: None

I have installed the android demo on my device but i thinks there might be a bug on object detection.
When an object is detected the rectangle around the object, the label and the precision appear on the screen; but if I frame something that doesn't present anything to be detected after a detection then the rectangle and everything still remain on the screen.

Does anyone know how to fix it?
Thanks."
19755,error in rnn with multiple inputs and one output?,
19751,No module named '_pywrap_tensorflow_internal' on Linux,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution**:  Linux Ubuntu 16.04
- **TensorFlow installed from **: a Rasa dependencies
- **TensorFlow version (use command below)**:
- **Python version**: Python 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

Both the script and the command provided for system information resulted in this error: `no module named '_pywrap_tensorflow_internal'`

### Describe the problem

Trying to develop a chatbot, anytime I call to tensorflow with a virtual environment I get this error: 

```
Traceback (most recent call last):
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""/usr/lib/python3.5/imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'
```

I have read [this closed topic](https://github.com/tensorflow/tensorflow/issues/11571) but it was about Windows and without a working solution.

The full error was:

```
(myFlaskAppenv) mike@mike-thinks:~/Programing/Rasa/myflaskapp$ python train_online.py 
INFO:rasa_nlu.components:Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.
/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/rasa_nlu/extractors/entity_synonyms.py:85: UserWarning: Failed to load synonyms file from './models/nlu/default/moodnlu/entity_synonyms.json'
  """".format(entity_synonyms_file))
/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Traceback (most recent call last):
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""/usr/lib/python3.5/imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train_online.py"", line 38, in <module>
    run_weather_online(ConsoleInputChannel(), nlu_interpreter)
  File ""train_online.py"", line 22, in run_weather_online
    policies=[MemoizationPolicy(), KerasPolicy()],
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/rasa_core/policies/keras_policy.py"", line 28, in __init__
    import keras
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/keras/__init__.py"", line 3, in <module>
    from . import utils
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/keras/utils/__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/keras/utils/conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/keras/backend/__init__.py"", line 84, in <module>
    from .tensorflow_backend import *
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""/usr/lib/python3.5/imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/mike/Programing/Rasa/myflaskapp/myFlaskAppenv/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems
```



### Source code / logs
You may be able to reproduce this error by calling for `python train_online.py` from [this repository](https://github.com/antoinecomp/myflaskapp/tree/master/myFlaskAppenv).
"
19750,Numerical errors in symmetric tensors lead to eventual instability,"I use `B = tf.matmul(A, A, transpose_b=True)` throughout my model, but I keep getting output tensors that are not symmetric. At first this is and unnoticeable amount, but after sufficient optimization steps calculations like `tf.linalg.logdet` and `tf.linalg.inv` blow up - not invertable or no cholesky decomposition.

After many steps of testing, I noticed that this happened because the input tensors were not symmetric, when they should be.

To test this out, I tried `tf.reduce_sum(tf.cast(B != tf.transpose(B), tf.int16))` to check at what point the data stops being symmetric, and this happens right at the first step.

Is this a known issue? Any recommendations?"
19749,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,"ImportError: Traceback (most recent call last):
  File ""/home/amartya/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/amartya/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/amartya/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory
"
19748,DirectSession::Run with Saver restore operation crashes during nsync wait,"### System information
Have I written custom code: Yes
OS Platform and Distribution: Tizen
TensorFlow installed from: Source
TensorFlow version: 1.4
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

### Problem
I am using Tensorflow 1.4 C++ API to read graph from meta file and load weights from checkpoint file.

```
#include <tensorflow/cc/ops/standard_ops.h>
#include <tensorflow/core/framework/tensor.h>
#include <tensorflow/core/public/session.h>
#include <tensorflow/core/protobuf/meta_graph.pb.h>

#define GRAPH_PATH ""path-to-graph.meta""
#define CHECKPOINT_PATH ""path-to-checkpoint.data-00000-of-00001""

MetaGraphDef graph_def;
Tensor checkpoint_path_tensor(DT_STRING, TensorShape());
auto session = NewSession(SessionOptions());
status = ReadBinaryProto(Env::Default(), GRAPH_PATH, &graph_def);
status = session->Create(graph_def.graph_def());
checkpoint_path_tensor.scalar<string>()() = CHECKPOINT_PATH;
status = session->Run(
        {{ graph_def.saver_def().filename_tensor_name(), checkpoint_path_tensor },},
        {},
        {graph_def.saver_def().restore_op_name()},
        nullptr);
```

While loading weights into graph from checkpoint, the program crashes during session->Run() with following trace:
```
#0  0xf1268e14 in std::condition_variable::condition_variable() () from /lib/libstdc++.so.6
#1  0xf555701c in nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*) () from /lib/libpywrap_tensorflow_internal.so
#2  0xf5557ae4 in nsync::nsync_waiter_new_() () from /lib/libpywrap_tensorflow_internal.so
#3  0xf55558fc in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) () from /lib/libpywrap_tensorflow_internal.so
#4  0xf5556004 in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) () from /lib/libpywrap_tensorflow_internal.so
#5  0xf5556040 in nsync::nsync_cv_wait(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*) () from /lib/libpywrap_tensorflow_internal.so
#6  0xf2d6ba30 in tensorflow::condition_variable::wait(tensorflow::mutex_lock&) () from /lib/libpywrap_tensorflow_internal.so
#7  0xf2d6c0d4 in tensorflow::Notification::WaitForNotification() () from /lib/libpywrap_tensorflow_internal.so
#8  0xf34f2078 in tensorflow::DirectSession::WaitForNotification(tensorflow::Notification*, long long) () from /lib/libpywrap_tensorflow_internal.so
#9  0xf34f1f14 in tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, tensorflow::CancellationManager*, long long) () from /lib/libpywrap_tensorflow_internal.so
#10 0xf34ebfc4 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /lib/libpywrap_tensorflow_internal.so
#11 0xf34eadfc in tensorflow::DirectSession::Run(std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::Tensor> > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) () from /lib/libpywrap_tensorflow_internal.so
```
"
19747,MyDatasetReaderOp crashes on assertion in tensorflow::core::RefCounted::~RefCounted(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: Not relevant
- **GCC/Compiler version (if compiling from source)**:g++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 9.0/7.0.5
- **GPU model and memory**:GTX 1080Ti
- **Exact command to reproduce**:

```bash
/usr/bin/c++   -Dexample_EXPORTS  -I/opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/include -I/opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/include/external/nsync/public -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC   -std=gnu++11 -o CMakeFiles/example.dir/my-reader-dataset-op.cc.o -c /opt/ssd/ilya/temp/my-reader-dataset-op.cc
/usr/bin/c++  -fPIC -I/opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/include -I/opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/include/external/nsync/public -D_GLIBCXX_USE_CXX11_ABI=0  -shared -Wl,-soname,libexample.so -o libexample.so CMakeFiles/example.dir/my-reader-dataset-op.cc.o -L/opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow -ltensorflow_framework 
```

`my-reader-dataset-op.cc` and `my.py` are copied from https://www.tensorflow.org/extend/new_data_formats#writing_a_dataset_for_a_file_format with two small changes in the Python code:
1) The dataset is wrapped into `batch` Dataset (any other wrapper that calls `Unref` in its destructor would work too, e.g. `cache`).
2) The iterator is initialized twice. The crash happens on the re-initialization attempt.

```python3
if __name__ == ""__main__"":
  # Create a MyReaderDataset and print its elements.
  with tf.Session() as sess:
    dataset = MyReaderDataset()
    dataset = dataset.batch(1)
    iterator = dataset.make_initializable_iterator()
    sess.run([iterator.initializer])
    print(""First init OK"")
    sess.run([iterator.initializer])
    print(""Reinit OK"")
    next_element = iterator.get_next()
    try:
      while True:
        print(sess.run(next_element))  # Prints ""MyReader!"" ten times.
    except tf.errors.OutOfRangeError:
      pass
```

```gdb
First init OK
2018-06-04 14:52:16.062227: F /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/include/tensorflow/core/lib/core/refcount.h:79] Check failed: ref_.load() == 0 (1 vs. 0)

Thread 59 ""python3"" received signal SIGABRT, Aborted.
[Switching to Thread 0x7ff95bfff700 (LWP 24856)]
0x00007ffff7825428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
54	../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) bt
#0  0x00007ffff7825428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54
#1  0x00007ffff782702a in __GI_abort () at abort.c:89
#2  0x00007fffa62a1174 in tensorflow::internal::LogMessageFatal::~LogMessageFatal() ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
#3  0x00007fffe6cf34e4 in tensorflow::core::RefCounted::~RefCounted() () from ./libexample.so
#4  0x00007fffe6cf4670 in tensorflow::DatasetBase::~DatasetBase() () from ./libexample.so
#5  0x00007fffe6cf4a7c in tensorflow::GraphDatasetBase::~GraphDatasetBase() () from ./libexample.so
#6  0x00007fffe6cf25fc in tensorflow::(anonymous namespace)::MyReaderDatasetOp::Dataset::~Dataset() ()
   from ./libexample.so
#7  0x00007fffe6cf262c in tensorflow::(anonymous namespace)::MyReaderDatasetOp::Dataset::~Dataset() ()
   from ./libexample.so
#8  0x00007fffa941529f in tensorflow::(anonymous namespace)::BatchDatasetOp::Dataset::~Dataset() ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007fffa9414f3b in tensorflow::(anonymous namespace)::BatchDatasetOp::Dataset::Iterator::~Iterator() ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007fffa84387b9 in std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::_M_release() ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007fffa945e6b6 in tensorflow::(anonymous namespace)::MakeIteratorOp::Compute(tensorflow::OpKernelContext*) ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007fffa664150c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
#13 0x00007fffa660724d in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
#14 0x00007fffa65f5fd0 in std::_Function_handler<void (), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> (tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> >::_M_invoke(std::_Any_data const&) ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
#15 0x00007fffa626d6aa in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
#16 0x00007fffa626c752 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /opt/ssd/ilya/temp-environment-for-bugreport/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so
#17 0x00007fff9d36fc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#18 0x00007ffff7bc16ba in start_thread (arg=0x7ff95bfff700) at pthread_create.c:333
#19 0x00007ffff78f741d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109
(gdb) 
```

It looks like `Unref` in https://github.com/tensorflow/tensorflow/blob/v1.8.0/tensorflow/core/kernels/data/batch_dataset_op.cc#L62 observes ref-count `1` and causes the destructor `MyReaderDatasetOp::Dataset::~Dataset()` to be called via `delete this`: https://github.com/tensorflow/tensorflow/blob/v1.8.0/tensorflow/core/lib/core/refcount.h#L93. However, later in destructor unfolding non-zero count is observed for the same object, which causes assertion failure.

The error doesn't reproduce with built-in datasets, e.g. TextLineReader or RangeDataset. However, if I copy RangeDataset code and rebuild it as MyRangeDataset, it reproduces with exactly the same symptoms."
19746,FLOP calculation by tf.profiler might be wrong,"Have I written custom code: Yes
OS Platform and Distribution: macOS 10.11.13
TensorFlow installed from: pip 
TensorFlow version: 1.6.0
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: see code below

```
import tensorflow as tf
g = tf.Graph()
with g.as_default():
    m, p, q = 25, 16, 9
    A = tf.Variable(tf.zeros([m, p]))
    B = tf.Variable(tf.zeros([p, q]))
    C = tf.matmul(A,B)

    flops = tf.profiler.profile(g, options = tf.profiler.ProfileOptionBuilder.float_operation())
    if flops is not None:
        print('FLOP should be', m * q * (2 * p - 1))
        print('Calculated FLOP', flops.total_float_ops)
```


Given two matrices `A` of shape `(m, p)` and `B` of shape `(p, q)`, the number of floating point operations (FLOP) should be `mq(2p-1)`.

Calculating the number of FLOP using tensorflow's profiler gives `2mqp` instead of `mq(2p-1)`."
19745,Jupyter Example: ImportError: Could not find 'cudart64_90.dll',"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pip install --upgrade tensorflow-gpu
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: Python 3.5.5 
- **Bazel version (if compiling from source)**: no
- **GCC/Compiler version (if compiling from source)**: wasn't used
- **CUDA/cuDNN version**: CUDA 9.0, cuDNN v7.0.5 (Dec 5, 2017), for CUDA 9.0, Library for Windows 10
- **GPU model and memory**: GeForce 940MX 2GB
- **Exact command to reproduce**:

```
import numpy as np
import os
import six.moves.urllib as urllib
import sys
import tarfile
import tensorflow as tf
import zipfile

from collections import defaultdict
from io import StringIO
from matplotlib import pyplot as plt
from PIL import Image

# This is needed since the notebook is stored in the object_detection folder.
sys.path.append("".."")
from object_detection.utils import ops as utils_ops

if tf.__version__ < '1.4.0':
  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')

```

```
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
d:\programfiles\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\platform\self_check.py in preload_check()
     74         try:
---> 75           ctypes.WinDLL(build_info.cudart_dll_name)
     76         except OSError:

d:\programfiles\anaconda3\envs\tensorflow1\lib\ctypes\__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error)
    350         if handle is None:
--> 351             self._handle = _dlopen(self._name, mode)
    352         else:

OSError: [WinError 126] The specified module could not be found

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-4a3efc4cbb3c> in <module>()
      4 import sys
      5 import tarfile
----> 6 import tensorflow as tf
      7 import zipfile
      8 

d:\programfiles\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\__init__.py in <module>()
     22 
     23 # pylint: disable=g-bad-import-order
---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
     25 # pylint: disable=wildcard-import
     26 from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin

d:\programfiles\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\__init__.py in <module>()
     47 import numpy as np
     48 
---> 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

d:\programfiles\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>()
     28 # Perform pre-load sanity checks in order to produce a more actionable error
     29 # than we get from an error during SWIG import.
---> 30 self_check.preload_check()
     31 
     32 # pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

d:\programfiles\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\platform\self_check.py in preload_check()
     80               ""environment variable. Download and install CUDA %s from ""
     81               ""this URL: https://developer.nvidia.com/cuda-toolkit""
---> 82               % (build_info.cudart_dll_name, build_info.cuda_version_number))
     83 
     84       if hasattr(build_info, ""cudnn_dll_name"") and hasattr(

ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit

```

I installed **CUDA 9.0** and extracted **cudnn-9.0-windows10-x64-v7.zip** to `C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0`

![screenshot_10](https://user-images.githubusercontent.com/8851301/40907717-5a3e947a-67ed-11e8-9fea-44b2d4f856cf.png)

I have next environment variables:

![screenshot_11](https://user-images.githubusercontent.com/8851301/40907722-5e4bc4e8-67ed-11e8-86b3-8df26821ab7e.png)

![screenshot_12](https://user-images.githubusercontent.com/8851301/40907724-5f8c666e-67ed-11e8-92d6-8d735abb6dc8.png)

So I don't understand what the problem is
I have this file, I have needed variables (paths) but it still isn't working

![screenshot_13](https://user-images.githubusercontent.com/8851301/40907826-ab3372a6-67ed-11e8-8a2e-c745bbd130e0.png)

![screenshot_14](https://user-images.githubusercontent.com/8851301/40907959-0db26fb8-67ee-11e8-93fd-3316bc60819c.png)"
19744,Warm start with distribute.MirroredStrategy not working,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.11
- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0
- **CUDA/cuDNN version**: 9.0 - 7.1
- **GPU model and memory**: Titan X
- **Exact command to reproduce**: N/A

We are trying to use distribute.MirroredStrategy to train a model on multiple GPUs on a single machine. We have a working implementation without warm start (training from scratch) and now want to initialise to model using checkpoint from imagenet before the training. 
Our first attempt is to add `init_from_checkpoint` in our model function:

```
def model_fn(features, labels, mode, params):

    .....

   tf.train.init_from_checkpoint(params['resnet_checkpoint'], {'/': 'resnet50/'})

   ....
```

But, this gives us the following error

```
.../tensorflow/contrib/distribute/python/values.py"", line 285, in _get_update_device
    ""Use DistributionStrategy.update() to modify a MirroredVariable."")
```

Is there an example of how to warm start a training with an existing checkpoint ?"
19743,"error：Library objects cannot exceed 65,536，win10 + TensorFlowGPU ","**System information:**
· Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  No

· OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Win10-x64

· TensorFlow installed from (source or binary): git clone https://github.com/tensorflow/tensorflow.git

· TensorFlow version (use command below):  r1.4, r1.5, r1.6  r1.7 and r1.8,  command : 
v1.8's command : git checkout -b v1.8 -f origin/r1.8
v1.7's command : git checkout -b v1.7 -f origin/r1.7
v1.6's command : git checkout -b v1.6 -f origin/r1.6
and so on include v1.4 and v1.5

· Python version:  Anaconda3 - python3.6

· Bazel version (if compiling from source):  I used CMAKE 3.11.1

· GCC/Compiler version (if compiling from source):  Visual Studio 2015( VS15' MSBuild)

· CUDA/cuDNN version:  CUDA9.0,   cudnn-9.0-win10-7.1

· GPU model and memory: GTX-860m with 2Gb Memory



Exact command to reproduce: 
""
D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> cmake .. -A x64 -DCMAKE_BUILD_TYPE=Debug -DSWIG_EXECUTABLE=D:/soft/TensorflowSoft/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/ProgramData/Anaconda3/python.exe -DPYTHON_LIBRARIES=D:/ProgramData/Anaconda3/libs/python36.lib -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""D:\soft\TensorflowSoft\cudnn"" -G ""Visual Studio 14 2015""

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> set PreferredToolArchitecture=x64 

D:\ProgramData\tensorflow\tensorflow\contrib\cmake\build> MSBuild /p:Configuration=Release ALL_BUILD.vcxproj
""

**Describe the problem** : 
I build TensorFlow-CPU-r1.8 successfully (win10-x64 + Anaconda3-python3.6 + **VS2017**(not VS2015) +  tensorflow1.8 + cmake3.11.1 + SwigWin3.0.12).
 
But when I build tensorflow-**GPU** version(both tensorflow-r1.7 and r1.8), the only error has occurred: The library objects cannot exceed 65,536. (If I use VS2017, it shows error: "" the compiler is not supported for CUDA 9.0"" , so I switch Visual Studio version to VS2015, and CMAKE command is work successfully.)

After that, I switched to lower versions TensorFlow-r1.6 to TensorFlow-r1.5, but Link error occurred：

“libprotobufd.lib(text_format.obj) : error LNK2019: unresolved external symbol __std_reverse_trivially_swappable_8 referenced in function ""void _
_cdecl std::_Reverse_unchecked1<class google::protobuf::Message const * *>(class google::protobuf::Message const * * const,class google::protobuf:
:Message const * * const,struct std::integral_constant<unsigned __int64,8>)"" (??$_Reverse_unchecked1@PEAPEBVMessage@protobuf@google@@@std@@YAXQEAP
EBVMessage@protobuf@google@@0U?$integral_constant@_K$07@0@@Z) [D:\tf\tensorflowGPU\tensorflow\contrib\cmake\build\proto_text.vcxproj]
  libprotobufd.lib(wire_format.obj) : error LNK2001: unresolved external symbol __std_reverse_trivially_swappable_8 [D:\tf\tensorflowGPU\tensorflo
w\contrib\cmake\build\proto_text.vcxproj]
  D:\tf\tensorflowGPU\tensorflow\contrib\cmake\build\Debug\proto_text.exe : fatal error LNK1120: 1 unresolved externals [D:\tf\tensorflowGPU\tenso
rflow\contrib\cmake\build\proto_text.vcxproj]”

I don't know how to solve those errors..."
19742,Attr 'Tshape' not found in Python2 but found in Python3,"
### System information
- Working off extension to mnist demo [here](https://github.com/uTensor/utensor-mnist-demo):
- **macOS High Sierra 10.13.4**:
- **TensorFlow installed from pip**:
- **v1.8.0-0-g93bc2e2072 1.8.0**:
- **Python 3.6.4, Python 2.7.14**: 
- **Exact command to reproduce**:

### Describe the problem
While trying to quantize a frozen TF graph I get the following error in Python2, *but not in Python3*.

```
File ""/Users/micbar02/anaconda2/lib/python2.7/site-packages/utensor_cgen/code_generator.py"", line 114, in _transform_graph
    transforms=[""quantize_weights"", ""quantize_nodes""])
  File ""/Users/micbar02/anaconda2/lib/python2.7/site-packages/tensorflow/tools/graph_transforms/__init__.py"", line 51, in TransformGraph
    transforms_string, status)
  File ""/Users/micbar02/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 519, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: No attr named 'Tshape' in NodeDef:
	 [[Node: MatMul_eightbit/x/reshape = Reshape[T=DT_FLOAT](x, MatMul_eightbit/x/reshape_dims)]]
```

FYI, we have a Cloud9 setup as well but we don't experience this issue there. It seems to be Mac only

### Source code / logs
Here is an example to recreate the issue using a model generated by this script https://github.com/uTensor/utensor-mnist-demo/blob/master/tensorflow-models/deep_mlp.ipynb:

```
def _transform_graph(self, pb_file):
  with tf.gfile.FastGFile(pb_file, 'rb') as fid:
    graph_def = GraphDef()
    graph_def.ParseFromString(fid.read())
    # Fails on the following line
    quant_graph_def = TransformGraph(input_graph_def=graph_def,
                                     inputs=[],
                                     outputs=self.output_nodes,
                                     transforms=[""quantize_weights"", ""quantize_nodes""])
    temp_file.write(quant_graph_def.SerializeToString())
```
"
19741,Issue on using custom Op with TensorRT,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
I am using tensor2tensor library.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Tensorflow docker image with ""1.7.1-devel-gpu"" tag
- **TensorFlow installed from (source or binary)**:
Source(From the docker image, nothing changed), with TensorRT enabled
- **TensorFlow version (use command below)**:
1.7.1
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.11.0
- **GCC/Compiler version (if compiling from source)**:
5.4.0 20160609
- **CUDA/cuDNN version**:
CUDA 9.0
- **GPU model and memory**:
GTX 1080 Ti 11 G
- **Exact command to reproduce**:
See problem description.

### Describe the problem
I am trying to use TensorRT feature to optimize the inference performance of Tensor2Tensor.  But got Op type not registered issue. 

### Source code / logs
```python
graph = tf.get_default_graph().as_graph_def()
frozen_graph = tf.graph_util.remove_training_nodes(graph)
trt_graph = trt.create_inference_graph(
    input_graph_def = frozen_graph, 
    outputs=[model_output],
    max_batch_size=10)
```
below error shows when create_inference_graph is called. 

>tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'convert_gradient_to_tensor_cc661786' in binary running on cffae59e0618. Makre sure the Op and Kernal are registered in the binary running in this process. 

convert_gradient_to_tensor is defined in tensor2tensor in below way. 

```python
@function.Defun(
    python_grad_func=lambda x, dy: tf.convert_to_tensor(dy),
    shape_func=lambda op: [op.inputs[0].get_shape()])
def convert_gradient_to_tensor(x):
    ...
```
"
19740,tflitecamerademo numThreads,"hi,
    I run tflitecamerademo on my device.
    I change some parameter:
    1.  tflite = new Interpreter(loadModelFile(activity),1);    ----> model inference: 250 ms
    2.  tflite = new Interpreter(loadModelFile(activity),4);    ----> model inference: 510 ms
    What is the role of this parameter(numThreads)：
    Interpreter(@NonNull MappedByteBuffer mappedByteBuffer, int numThreads)
Why 4 threads are slower than 1 thread，Only set to 1 thread, model prediction is fastest
No matter how you set it, the CPU usage has not improved (checked with the top command)

thanks.
"
19739,Run label_image.py for all images in a folder,"I tried to run label_image.py for all images in a folder as below but it seems that I cannot pass variable to the --image parameter of the label_image.py in the codelab https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#5

How can I run label_image.py through all images?

os.chdir(""D:/Tensorflow/tf_files/classroom_pixel_test/Empty"")
for filename in os.listdir(os.getcwd()):
    if filename.endswith("".jpg""): 
        display(Image(filename))
        imagefile1=os.getcwd()+""\\""+filename
        imagefile2=""D:/Tensorflow/tf_files/classroom_pixel_test/Empty/""+filename
        imagefile3=""D:/Tensorflow/tf_files/classroom_pixel_test/Empty/29.jpg""
        print(imagefile1)
        print(imagefile2)
        print(os.getcwd())
        print(filename)
        #%run D:/Tensorflow/label_image --graph=D:/Tensorflow/tf_files/retrained_graph_classroom_pixel_LR_0.5.pb --labels=D:/Tensorflow/tf_files/retrained_labels_classroom_pixel_LR_0.5.txt --image=ph_classroom_pixel_LR_0.5.pb --labels=D:/Tensorflow/tf_files/retrained_labels_classroom_pixel_LR_0.5.txt --image=ph_classroom_pixel_LR_0.5.pb --labels=D:/Tensorflow/tf_files/retrained_labels_classroom_pixel_LR_0.5.txt --image=D:/Tensorflow/tf_files/classroom_pixel_test/Empty/29.jpg --output_layer=final_result --input_layer=Placeholder
        %run D:/Tensorflow/label_image --graph=D:/Tensorflow/tf_files/retrained_graph_classroom_pixel_LR_0.5.pb --labels=D:/Tensorflow/tf_files/retrained_labels_classroom_pixel_LR_0.5.txt --image=ph_classroom_pixel_LR_0.5.pb --labels=D:/Tensorflow/tf_files/retrained_labels_classroom_pixel_LR_0.5.txt --image=ph_classroom_pixel_LR_0.5.pb --labels=D:/Tensorflow/tf_files/retrained_labels_classroom_pixel_LR_0.5.txt --image=imagefile3 --output_layer=final_result --input_layer=Placeholder
        continue                        
    else:
        continue"
19738,Android Picture improves image clarity and cannot be used,"![image](https://user-images.githubusercontent.com/19525589/40902335-464f0a12-6806-11e8-933c-bb668e56affa.png)

I got a picture of the current TF input and saw that the resolution is not high. I tried to change to an HD picture, but

![image](https://user-images.githubusercontent.com/19525589/40902543-e17d1b28-6806-11e8-8d3c-4b84a09d0f7d.png)
After the modification, I could not identify it. I would like to ask about the definition of the image at the time of design. Can't modify and use the high-resolution graphics?"
19735,How to quantize MobileNetV2 for deeplabV3+ ?,"**System information**
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:Source
- **TensorFlow version (use command below)**:1.8.0rc0
- **Python version**:2.7.12
- **Bazel version (if compiling from source)**:0.12.0
- **GCC/Compiler version (if compiling from source)**:5.4.0
- **CUDA/cuDNN version**:cuda-9.0/7.0
- **GPU model and memory**:GeForce GTX 1080/8105MiB
- **Phone**:xiaomi5 (Snapdragon 820)
- **Exact command to reproduce**:
bazel run --config=opt //tensorflow/contrib/lite/toco:toco --
--input_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb
--output_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/kanul.tflite
--inference_type=QUANTIZED_UINT8
--input_shape=1,513,513,3
--input_array=sub_7
--output_array=logits/semantic/BiasAdd

**Describe the problem**
I have tried to quantize MobileNetV2 for deeplabV3+ with TFlite. But I fail to convert the model.
From the following issue, I saw that the operations were not supported for the option of quantization.

https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md
Checkpoint name: mobilenetv2_coco_voc_trainaug

Who can explain and support to resolve the issue?

**Source code / logs**
bazel run --config=opt //tensorflow/contrib/lite/toco:toco -- 
 --input_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb 
 --output_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/kanul.tflite 
 --inference_type=QUANTIZED_UINT8 
 --input_shape=1,513,513,3 
 --input_array=sub_7 
 --output_array=logits/semantic/BiasAdd

Unimplemented: this graph contains an operator of type SpaceToBatchND for which the quantized form is not yet implemented. Sorry, and patches welcome (that's a relatively fun patch to write, mostly providing the actual quantized arithmetic code for this op).
"
19734,[bug] Regularizers do not allow integer scales.,"Location:

https://github.com/tensorflow/tensorflow/blob/c9de294d0a0980b1636f76757c175afbf4f58ea8/tensorflow/contrib/layers/python/layers/regularizers.py#L92

Expected behavior: I was expecting layers to work with integer scale regularizers.

Actual behavior: program throws error and quits on me when I set scale=10 but not when I set scale=10.0

This seems to be vestigial of a misunderstanding: earlier commits limit regularizer scale to a floating point number between 0.0 and 1.0, disallowing integers. While the upperbound of 1.0 has been removed, the no-integers limitation is left over."
19733,TensorArray performance on GPU is poor.,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.8.0-7-g3b85959' 1.8.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.13.1
- **GCC/Compiler version (if compiling from source)**: 4.9.3
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**: TITAN X (Pascal) 12GB
- **Exact command to reproduce**:

### Describe the problem
Hi, I've found `TensorArrayScatterV3` op to be the bottleneck of my model, and it seems like TensorArray.scatter is really slow on GPU.
I compared 'tf.TensorArray.scatter' with `tf.scatter_update` on CPU/GPU, with the following code:
```
import time
import tensorflow as tf

with tf.device('/gpu:0'):
    t = tf.Variable(tf.random_normal([100000, 100]))
    ta = tf.TensorArray(tf.float32, size=100000, element_shape=[100])
    perm = tf.random_shuffle(tf.range(100000, dtype=tf.int32))
    for i in range(1000):
        idx = perm[i*100: (i+1)*100]
        v = tf.random_normal([100, 100])
        t = tf.scatter_update(t, idx, v)
        ta = ta.scatter(idx, v)
    o1 = tf.gather(t, idx[:10])
    o2 = ta.gather(idx[:10])

sess_config = tf.ConfigProto()
sess_config.allow_soft_placement = True
sess = tf.Session(config=sess_config)
sess.run([tf.global_variables_initializer()])

total_time_tensor_scatter = 0.
total_time_tensorarray_scatter = 0.
for i in range(100):
    start_time = time.time()
    sess.run([o1])
    total_time_tensor_scatter += time.time() - start_time
    start_time = time.time()
    sess.run([o2])
    total_time_tensorarray_scatter += time.time() - start_time
print('total_time_tensor_scatter', total_time_tensor_scatter)
print('total_time_tensorarray_scatter', total_time_tensorarray_scatter)
```
The results are like:
On CPU:
```
total_time_tensor_scatter 8.333731889724731
total_time_tensorarray_scatter 19.28065252304077
```
On GPU:
```
total_time_tensor_scatter 8.216091632843018
total_time_tensorarray_scatter 82.21394562721252
```
It seems like TensorArray scatter is slower than tensor scatter on CPU, and it is much slower on GPU.

By the way, the timeline on GPU is like:
![image](https://user-images.githubusercontent.com/7380587/40897557-4f5f2e2e-67ee-11e8-82ba-298c6c74241d.png)

Is it intrinsic for TensorArray or not?
Can it be optimized further?"
19732,mobilenetv2," i just need a  Mobilenet V2 model for android test that is quantized, but there is only  un-quantized version here (https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet)  ,who can offer me a quantized version?


"
19731,How to release GPU memory after sess.close()?,"hi, all:
     I'm training models iteratively. After each model trained, I run sess.close() and recreate a new session to run a new training process. But it seems that the GPU memory was not relseased and it's increasing constantly. 
I tried tf.reset_default_graph() before run session also typed gc.collect() after sess.close(), but takes no effect. 
     How could I release GPU memory timely to avoid OOM error please? 
     Thanks!"
19729,Getting empty tensorflow installation,"### System information


== cat /etc/issue ===============================================
Linux analyst-PC 4.4.0-124-generic #148~14.04.1-Ubuntu SMP Thu May 3 07:26:53 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""14.04.5 LTS, Trusty Tahr""
VERSION_ID=""14.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux analyst-PC 4.4.0-124-generic #148~14.04.1-Ubuntu SMP Thu May 3 07:26:53 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy                              1.14.3            
numpydoc                           0.7.0             
protobuf                           3.5.2.post1       
tensorflow-gpu                     1.5.1             
tensorflow-tensorboard             1.5.1             

== check for virtualenv =========================================
False

== tensorflow import ============================================

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sun Jun  3 23:29:37 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.48                 Driver Version: 390.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 660     Off  | 00000000:01:00.0 N/A |                  N/A |
| 30%   35C    P8    N/A /  N/A |    266MiB /  1998MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0                    Not Supported                                       |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart.so.9.0.176
/usr/local/cuda-9.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
 
You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
#running from console says about unsupported operation.
#in jupyter notebook:
AttributeError: module 'tensorflow' has no attribute 'GIT_VERSION'


### Describe the problem
Then tried to import tensorflow, I get no error However tf.set_random_seed(random_state) - returns AttributeError: module 'tensorflow' has no attribute 'set_random_seed'

Then in the jupyter notebook with shit-tab get library help:
Type:        module
String form: <module 'tensorflow' (namespace)>
Docstring:   <no docstring>


Seems to isnt righ. However :

 ~ $ pip show tensorflow-gpu
Name: tensorflow-gpu
Version: 1.5.1
Summary: TensorFlow helps the tensors flow
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /home/analyst/anaconda3/lib/python3.6/site-packages
Requires: absl-py, wheel, six, tensorflow-tensorboard, numpy, protobuf
Required-by: 

$ pip show tensorflow  #Returns nothing
What might be wrong?


I have 2 active namaspaces: how to fix that:

    > tf.__path__
    
    _NamespacePath(['/home/aa/tensorflow', '/home/aa/anaconda3/lib/python3.6/site-packages/tensorflow'])"
19725,I cannot code to use  individual elements of a tensor outside a session ,"I am writing a model in Keras, where the output of one of the layers gives me the coordinates of a mask that I want to apply on the image input. The problem is that I could not find any way to do this, methods such as tf.slice() do not work if you are not inside a session. 
I want to do equivalent to this:
x=dense(2)(x)
A=np.zeros((224,224, 3)) or K.zeros((224,224,3))
x=int(x)
A[x[0],x[1],:]=1
where x comes from previous layers and is reassigned in the layer shown (dense layer from keras), the output is two numbers representing the position in the picture, then I create A which is a mask to be multiplied with the input (input not shown), and I need both, make the output of the layer an integer, and then use it to add ones to the mask A at position (x[0],x[1]) (and other ones too, but just having one is enough to know the method. "
19723,ERROR while training ( tensorflow.python.framework.errors_impl.NotFoundError),"hello . first I'm sorry for my weak english lang.
Would you please help me to fix this problem?
![11](https://user-images.githubusercontent.com/24391257/40887860-748c26e4-673e-11e8-83f2-2b170205b4a5.png)

I have object-detection.pbtxt and I gave different models path in command but I got same error again 

I follow this youtube  video https://www.youtube.com/watch?v=JR8CmWyh2E8

"
19722,Faild clone libFuzzer when compiling tensorflow on win10,"When compiling tensorflow on windows 10 with vs2017, follow error occor:

  Cloning into 'third_party/libFuzzer'...
  fatal: unable to access 'https://chromium.googlesource.com/chromium/llvm-project/llvm/lib/Fuzzer/': Failed to connect to chromium.googlesource.com port 443: Timed out
  fatal: clone of 'https://chromium.googlesource.com/chromium/llvm-project/llvm/lib/Fuzzer' into submodule path 'third_party/libFuzzer' failed
  Failed to recurse into submodule path 'third_party/bloaty'
  CMake Error at D:/program/tfMake/tensorflow-master/tensorflow/contrib/cmake/build/grpc/tmp/grpc-gitclone.cmake:93 (message):
    Failed to update submodules in:
    'D:/program/tfMake/tensorflow-master/tensorflow/contrib/cmake/build/grpc/src/grpc'

However, open https://chromium.googlesource.com/chromium/llvm-project/llvm/lib/Fuzzer/  I see:
024d10d [libFuzzer] Delete llvm/lib/Fuzzer by vitalybuka · 8 months ago master 

The libFuzzer is already deleted. I think this is a bug need to fix.

Have I written custom code: No
OS Platform and Distribution: Windows 10
TensorFlow installed from: git clone
TensorFlow version: latest
Bazel version: 
CUDA/cuDNN version: CUDA9.0, cuDNN 7.0 for win10
GPU model and memory: GPU GTX970M, 3G
Exact command to reproduce:

code for CMake:
cmake .. -DCMAKE_C_COMPILER=""C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe"" -DCMAKE_CXX_COMPILER=""C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe"" -T v140 -A x64 -DCMAKE_BUILD_TYPE=Release -DPYTHON_EXECUTABLE=C:/Users/hasee/Anaconda3/python.exe -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0"" -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_ENABLE_GRPC_SUPPORT=ON -DCUDA_HOST_COMPILER=""C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/cl.exe"" -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX -Dtensorflow_BUILD_CC_EXAMPLE=OFF -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF

code for MSBuild:
& ""C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\MSBuild\15.0\Bin\MSBuild.exe"" ALL_BUILD.vcxproj /m:1 /p:CL_MPCount=1 /p:Configuration=Release /p:Platform=x64 /p:PreferredToolArchitecture=x64 /filelogger"
19721,UnicodeDecodeError while loading trained model through import_meta_graph function.,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

Yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Windows 10 Home, but using online Jupyter Notebook environment for coding purposes

- **TensorFlow version (use command below)**:

Version : 1.8.0
- **Python version**: 

3.6.3
- **Bazel version (if compiling from source)**:

N/A
- **GCC/Compiler version (if compiling from source)**:

N/A
- **CUDA/cuDNN version**:

N/A
- **GPU model and memory**:

Tesla K80, 11.5 GB RAM
- **Exact command to reproduce**:

new_saver = tf.train.import_meta_graph('model-21-epochs.meta')


### Describe the problem

I trained a text classification model on an online Jupyter Notebook, and saved models at each epoch to evaluate the best performing one. On the notebook itself, after the training session is over, running the tf.train.import_meta_graph() function seemed to work fine. 

**I then downloaded all 3 files : the .meta file, the .data-00000-of-00001 file and the .index file** and on running it locally on my machine, I get a UnicodeDecodeError like this : 

```
2018-06-03 17:46:04.730649: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
Traceback (most recent call last):
  File ""code.py"", line 14, in <module>
    new_saver = tf.train.import_meta_graph('model-31.meta')
  File ""C:\Users\sekha\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1947, in import_meta_graph
    meta_graph_def = meta_graph.read_meta_graph_file(meta_graph_or_file)
  File ""C:\Users\sekha\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\meta_graph.py"", line 643, in read_meta_graph_file
    text_format.Merge(file_content.decode(""utf-8""), meta_graph_def)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 1: invalid continuation byte
```
The online notebook only stores files on it for a certain amount of time, and after that they are deleted. So I uploaded the meta file on the notebook again, to see if the problem persisted on a new session ( session on the notebook, not used in the tensorflow 'session' lingo ) in the notebook. And it gave me the same error then too. 

An issue almost identical to this one has been raised fairly recently in #19573 but there hasn't been an update at all. And this was asked on StackOverflow too, to which the response was that it might be a bug  and github was the place for it, as can be seen in #19573. 

For reference, this is the entire inference portion of the code:

  ```
graph = tf.Graph()
  with tf.Session(graph = graph) as sess: 
      
        new_saver = tf.train.import_meta_graph('/content/runs/1527946417/checkpoints/model-31.meta') 
        new_saver.restore(sess, ('/content/runs/1527946417/checkpoints/model-31'))
        sess.run(tf.tables_initializer())
        e = (graph.get_operations())
   
        arr_placeholder = graph.get_operation_by_name('arr_placeholder/inp_array').outputs[0]
        str_placeholder = graph.get_tensor_by_name('str_placeholder/inp_string:0')
        dropout_keep_prob = graph.get_operation_by_name('dropout_keep_prob/keep_prob').outputs[0]
        
        logis = (graph.get_operation_by_name('logits/scores')).outputs[0]

        a =  (sess.run(logis, feed_dict = {arr_placeholder : x_dev, dropout_keep_prob : 1.0, str_placeholder : ls[4731:]}))
```

So is it the case that saved models and meta graphs only be restored from the directory it was saved to during the training phase? Is it impossible to run inference on a pre-trained model downloaded from an online source?"
19720,Library not loaded: @rpath/libcublas.8.0.dylib when running TF GPU on MacOS ,"
### System information

- **System: Mac OS 10.13.4**:
- **Xcode:9.2 .  Apple LLVM version 9.0.0 (clang-900.0.39.2)**:
- **Cuda:**:
- **nvcc: NVIDIA (R) Cuda compiler driver**:
- **Copyright (c) 2005-2018 NVIDIA Corporation**:
- **Built on Sun_Mar_18_21:08:25_CDT_2018**:
- **Cuda compilation tools, release 9.2, V9.2.64**:
- **cudnn:7.1.4**:
- **gcc g++ : 4.2.1**:


- **Question:**:
When i use anaconda install tensorflow-gpu,the terminal say i was successful! Such as:
Installing collected packages: numpy, six, werkzeug, protobuf, tensorflow-gpu
Successfully installed numpy-1.14.3 protobuf-3.5.2.post1 six-1.11.0 tensorflow-gpu-1.1.0 werkzeug-0.14.1

But when is write ""import tensorflow as tf"",some erroes is show.

> (tensorflowGPU) jhmdeMacBook-Air:Sources jhm$ python
Python 3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37) 
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: dlopen(/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib
  Referenced from: /Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
  Reason: image not found

During handling of the above exception, another exception occurred:

>Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: dlopen(/Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib
  Referenced from: /Users/jhm/anaconda3/envs/tensorflowGPU/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
  Reason: image not found


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.



BugLog/tensorflowGPU-01.log

I don't konw what to do!"
19718,the gradient function returned by tfe.implicit_value_and_gradients() doesn't support keyword argument,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
v1.8.0
- **Python version**: 
Python 3.6.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
No
- **GPU model and memory**:
No
- **Exact command to reproduce**:


### Describe the problem
When using eager mode, I found that the gradient function returned by `tfe.implicit_value_and_gradients()` doesn't support keyword argument.


### Source code / logs
My code like this
```python
grad_fn = tfe.implicit_gradients(MLP)
grads_and_vars = grad_fn(data, label, is_training=True)
```

And I got the error
>Traceback (most recent call last):
  File ""xxx.py"", line 91, in <module>
    grads_and_vars = grad_fn(data, label, is_training=True)
  File ""xxx\anaconda3\lib\site-packages\tensorflow\python\eager\backprop.py"", line 289, in grad_fn
    return implicit_val_and_grad(f)(*args, **kwds)[1]
TypeError: grad_fn() got an unexpected keyword argument 'is_training'

When I remove the keyword ""is_training"", like this
```
grads_and_vars = grad_fn(data, label, True)
```
Then the code has no problem. 

The bug can be fixed by modifying ’xxx\Lib\site-packages\tensorflow\python\eager\backprop.py‘ and adding `**kwds` in function `implicit_val_and_grad(f)`
the modified code like this
```python
  def grad_fn(*args, **kwds):
    """"""Computes the gradient of the wrapped function.""""""
    this_tape = tape.push_new_tape()
    try:
      end_node = f(*args, **kwds)
  ...
```


"
19717,`ScipyOptimizerInterface` fails with `scatter_add` and `scatter_update`,"If I try to build some loss function which in its calculations includes an `scatter_add` or `scatter_update` and optimize it using `ScipyOptimizerInterface`, TensorFlow will fail in calculating the gradient.

Here's an example with a variant of low-rank matrix factorization in which I add an extra variable, which adds to some of the rows of one of the matrices in the low-rank factorization:

```python
import numpy as np, tensorflow as tf

nrow = 20
ncol = 30
k = 15
nrow_add = 10
ncol_mult_add = 5
regularization = 1e-6

np.random.seed(1)
X = np.random.normal(size = (nrow, ncol)).astype('float32')
X2 = np.random.normal(size = (nrow_add, ncol_mult_add)).astype('float32')
ix_row_add = np.random.choice(np.arange(nrow), replace=False, size=nrow_add).astype('int32')

A = tf.Variable(tf.random_normal([nrow, k]))
B = tf.Variable(tf.random_normal([ncol, k]))
A2 = tf.Variable(tf.random_normal([ncol_mult_add, k]))

Xtf = tf.placeholder(tf.float32)
X2tf = tf.placeholder(tf.float32)

A_added = tf.scatter_add(A, ix_row_add, tf.matmul(X2, A2))
pred_x = tf.matmul(A_added, B, transpose_b=True)
loss = tf.losses.mean_squared_error(Xtf, pred_x)
loss += regularization * (tf.nn.l2_loss(A) + tf.nn.l2_loss(A2) + tf.nn.l2_loss(B))

optimizer = tf.contrib.opt.ScipyOptimizerInterface(loss, method='L-BFGS-B')
model = tf.global_variables_initializer()
sess=tf.Session()
sess.run(model)
with sess:
    sess.run(model)
    optimizer.minimize(sess, feed_dict={Xtf:X, X2tf:X2})
    Aopt = A.eval(session=sess)
    A2opt = A2.eval(session=sess)
    Bopt = B.eval(session=sess)
``` 

Throws:
```
InvalidArgumentError: Input 0 of node ScatterAdd was passed float from _arg_Variable_0_2:0 incompatible with expected float_ref.
```

Information about my system:
* Have I written custom code: No
* OS Platform and Distribution: Debian buster/sid 64-bit
* TensorFlow installed from: binary (PyPI)
* TensorFlow version: 1.7.0
* Python version: 3.6.3
* Bazel version: N/A
* GCC/Compiler version: N/A
* CUDA/cuDNN version: N/A
* GPU model and memory: N/A
* Exact command to reproduce: N/A"
19716,TF Lite wants help on Andorid Between ImageClassifier and ObjectDetection,"Dear Sir/Madam:
       (1)I run tf-lite to recognize things ok according to 
 `https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0`
     (2)But When I want to detect Objects on camera,Only `https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android`
     the first one use  `private Interpreter tflite` to run .lite for result,while the second one use `TensorFlowInferenceInterface` to build graph and feed inputs,this need to using bazel compile the whole project,a lot time need to spend
   So my Question is: Can Examples like the first one for Object Detection using lighweight interpreter?
    Plus tensorflow-lite is valued very import in many areas,Hope for talents helping,Thank you.
Plus 
OS Platform and Distribution:Ubuntu16.04LTS
TensorFlow installed from:PIP install
TensorFlow version:tensorflow-gpu:1.6
Bazel version:0.11.1
CUDA/cuDNN version
GPU model and memory:nvidia 1080TI 12G
Exact command to reproduce:N/A"
19710,TF dataset: support for aspect ratio group batching,"Current TF dataset class only support fixed size padding for batching different sized input elements, however there are cases like in object detection, we may need to batch images according to their aspect ratios, i.e., push images with similar aspect ratio into one batch and pad them with minimal extra paddings, is there any existing approach that does not use feed_dict approach but directly utilize TF operators and read TF record files for accomplish this ? Thanks!"
19709,build tensorflow-lite example label_image to .so ,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.8.0 gpu
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:0.12.0
- **GCC/Compiler version (if compiling from source)**: c++11  
- **CUDA/cuDNN version**:7.5.18
- **GPU model and memory**:TITAN,12GB
- **Exact command to reproduce**:N/A


### Describe the problem
I want to use bazel to build label_image to .so file. I modified the BUILD in /tensorflow/contrib/lite/examples/label_image/BUILD like below:



```
package(default_visibility = [""//visibility:public""])

licenses([""notice""])  # Apache 2.0

load(""//tensorflow:tensorflow.bzl"", ""tf_cc_binary"", ""tf_copts"", ""if_android"")
load(""//tensorflow/contrib/lite:build_def.bzl"", ""tflite_linkopts"")

exports_files([
    ""version_script.lds"",
])

filegroup(
    name = ""label_image_src"",
    srcs = glob([
        ""label_image.cc"",
        ""bitmap_helpers.cc"",
        ""label_image.h"",
        ""bitmap_helpers.h"",
    ]),
    visibility = [""//visibility:public""],
)

LINKER_SCRIPT = ""//tensorflow/contrib/lite/examples/label_image:version_script.lds""

cc_binary(
    name = ""libtflite_label_image.so"",
    srcs = [],
    copts = tf_copts() + [
        ""-ffunction-sections"",
        ""-fdata-sections"",
    ],
    linkopts = if_android([
        ""-landroid"",
        ""-latomic"",
        ""-ldl"",
        ""-llog"",
        ""-lm"",
        ""-z defs"",
        ""-s"",
        ""-Wl,--gc-sections"",
        ""-Wl,--version-script"",  # This line must be directly followed by LINKER_SCRIPT.
        LINKER_SCRIPT,
    ]),
    linkshared = 1,
    linkstatic = 1,
    tags = [
        ""manual"",
        ""notap"",
    ],
    deps = [
        "":label_image"",
        ""//tensorflow/contrib/lite:framework"",
        ""//tensorflow/contrib/lite:string_util"",
        ""//tensorflow/contrib/lite/kernels:builtin_ops"",
        ""//tensorflow/core:android_tensorflow_lib"",
        LINKER_SCRIPT,
    ],
)
cc_library(
    name = ""label_image"",
    srcs = if_android(["":label_image_src""]),
    copts = tf_copts(),
    visibility = [""//visibility:public""],
    deps = [
        ""//tensorflow/contrib/lite:framework"",
        ""//tensorflow/contrib/lite:string_util"",
        ""//tensorflow/contrib/lite/kernels:builtin_ops"",
        ""//tensorflow/core:android_tensorflow_lib_lite"",
    ],
    alwayslink = 1,
)
```

I can generated libtflite_label_image.so successfully by using  command
`""bazel build --config monolithic --cxxopt=-std=c++11   --crosstool_top=//external:android/crosstool   --host_crosstool_top=@bazel_tools//tools/cpp:toolchain   --cpu=arm64-v8a   //tensorflow/contrib/lite/examples/label_image:libtflite_label_image.so --verbose_failures""`
but when I test the libtflite_label_image.so by using Cmake file, I got the error ` undefined reference to `tflite::label_image::label_image`
I think maybe the .so file is generated uncorrectly, some one can help me?
Thank you!

"
19706,Add eager with estimator," By adding 
```
import tensorflow.contrib.eager as tfe
tf.enable_eager_execution()
```
at the beginning of the [python code](https://raw.githubusercontent.com/aymericdamien/TensorFlow-Examples/90bb4de75322f8c01048dd98c7f194442051d257/examples/3_NeuralNetworks/neural_network.py), I got the following RuntimeError: Estimators are not supported when eager execution is enabled.. 

```
File ""neural_network.py"", line 88, in <module>
    model = tf.estimator.Estimator(model_fn)
  File ""/.../anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 171, in __init__
    'Estimators are not supported when eager execution is enabled.')

```"
19700,ppc64le: //tensorflow/python:nn_test test fails,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/python:nn_test

### Describe the problem
```
======================================================================
FAIL: testNaNs (__main__.ReluTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/nn_test.runfiles/org_tensorflow/tensorflow/python/ops/nn_test.py"", line 934, in testNaNs
    self.assertTrue(np.isnan(z).all())
AssertionError: False is not true

----------------------------------------------------------------------
Ran 79 tests in 12.600s

FAILED (failures=1)
0.0208333333333
0.00566666666667
0.0075
0.0208333333333
0.00566666666667
0.0075
0.0208333333333
0.00566666666667
0.0075
0.0208333333333
0.00566666666667
0.0075
L2Loss gradient err = 9.6958e-12
L2Normalize gradient err = 4.2424e-08
L2Normalize gradient err = 5.45829e-07
L2Normalize gradient err = 7.61142e-05
================================================================================
```

### Source code / logs
[nn_test.log](https://github.com/tensorflow/tensorflow/files/2063777/nn_test.log)
"
19698,ppc64le: //tensorflow/python/kernel_tests:self_adjoint_eig_op_test test fails,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/python/kernel_tests:self_adjoint_eig_op_test

### Describe the problem
```
======================================================================
FAIL: testMatrixThatFailsWhenFlushingDenormsToZero (__main__.SelfAdjointEigTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.py"", line 87, in testMatrixThatFailsWhenFlushingDenormsToZero
    np.matmul(v, v.transpose()), np.eye(32, dtype=np.float32), atol=2e-3)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1368, in assertAllClose
    self._assertAllCloseRecursive(a, b, rtol=rtol, atol=atol, msg=msg)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1338, in _assertAllCloseRecursive
    path_str))
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/self_adjoint_eig_op_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1273, in _assertArrayLikeAllClose
    a, b, rtol=rtol, atol=atol, err_msg=msg, equal_nan=True)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 1411, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 754, in assert_array_compare
    chk_same_position(x_isnan, y_isnan, hasval='nan')
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 735, in chk_same_position
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=1e-06, atol=0.002
Mismatched value: a is different from b.
x and y nan location mismatch:
 x: array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],
       [ nan,  nan,  nan, ...,  nan,  nan,  nan],
       [ nan,  nan,  nan, ...,  nan,  nan,  nan],...
 y: array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  1.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  1., ...,  0.,  0.,  0.],...

----------------------------------------------------------------------
Ran 9 tests in 1.543s

FAILED (failures=1)
not close where =  (array([ 0,  0,  0, ..., 31, 31, 31]), array([ 0,  1,  2, ..., 28, 29, 30]))
not close lhs =  [ nan  nan  nan ...,  nan  nan  nan]
not close rhs =  [ 1.  0.  0. ...,  0.  0.  0.]
not close dif =  [ nan  nan  nan ...,  nan  nan  nan]
not close tol =  [ 0.002001  0.002     0.002    ...,  0.002     0.002     0.002   ]
dtype = float32, shape = (32, 32)
================================================================================

```
### Source code / logs
[self_adjoint_eig_op_test.log](https://github.com/tensorflow/tensorflow/files/2063585/self_adjoint_eig_op_test.log)
"
19697,ppc64le: ///tensorflow/python/kernel_tests:matrix_solve_ls_op_test and svd_op_test core dump,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/python/kernel_tests:svd_op_test
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/python/kernel_tests:matrix_solve_ls_op_test



### Describe the problem
```
*** Received signal 11 ***
*** BEGIN MANGLED STACK TRACE ***
/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/svd_op_test.runfiles/org_tensorflow/tensorflow/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so(+0x73cb0c)[0x3ffefda9cb0c]
[0x3fffa9fe04d8]
/usr/lib/libopenblas.so.0(dlasd2_+0xb20)[0x3fffa9372820]
[0x0]
/usr/lib/libopenblas.so.0(dlasd1_+0x3bc)[0x3fffa9371bac]
/usr/lib/libopenblas.so.0(dlasd0_+0xb98)[0x3fffa9371618]
/usr/lib/libopenblas.so.0(dbdsdc_+0xda8)[0x3fffa92be6a8]
/usr/lib/libopenblas.so.0(zgesdd_+0x5878)[0x3fffa95cf368]
/usr/local/lib/python2.7/dist-packages/numpy/linalg/_umath_linalg.so(+0x119cc)[0x3fff0ace19cc]
/usr/local/lib/python2.7/dist-packages/numpy/core/umath.so(+0xe9340)[0x3fff75389340]
/usr/local/lib/python2.7/dist-packages/numpy/core/umath.so(+0xe9c38)[0x3fff75389c38]
/usr/local/lib/python2.7/dist-packages/numpy/core/umath.so(+0xeb1dc)[0x3fff7538b1dc]
/usr/bin/python(PyEval_EvalFrameEx+0x65b0)[0x1009fb80]
/usr/bin/python(PyEval_EvalCodeEx+0x498)[0x10095768]
/usr/bin/python(PyEval_EvalFrameEx+0x6768)[0x1009fd38]
/usr/bin/python(PyEval_EvalCodeEx+0x498)[0x10095768]
/usr/bin/python(PyEval_EvalFrameEx+0x6f74)[0x100a0544]
/usr/bin/python(PyEval_EvalCodeEx+0x498)[0x10095768]
/usr/bin/python[0x100c01d4]
.
.
.
/usr/bin/python(PyRun_FileExFlags+0xc4)[0x100d7934]
/usr/bin/python(PyRun_SimpleFileExFlags+0x1d8)[0x100d58d8]
/usr/bin/python(Py_Main+0x780)[0x10051c60]
/lib/powerpc64le-linux-gnu/libc.so.6(+0x2309c)[0x3fffa9de309c]
/lib/powerpc64le-linux-gnu/libc.so.6(__libc_start_main+0xb8)[0x3fffa9de3298]
*** END MANGLED STACK TRACE ***

*** Begin stack trace ***
        tensorflow::CurrentStackTrace[abi:cxx11]()

        __kernel_sigtramp_rt64
        dlasd2_

        dlasd1_
        dlasd0_
        dbdsdc_
        zgesdd_




        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx

        PyObject_Call
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx


        PyObject_Call

        PyEval_EvalFrameEx
        PyEval_EvalCodeEx

        PyObject_Call
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx


        PyObject_Call

        PyEval_EvalFrameEx
        PyEval_EvalCodeEx

        PyObject_Call
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx


        PyObject_Call

        PyEval_EvalFrameEx
        PyEval_EvalFrameEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx




        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyEval_EvalFrameEx
        PyEval_EvalCodeEx
        PyRun_FileExFlags
        PyRun_SimpleFileExFlags
        Py_Main

        __libc_start_main
*** End stack trace ***
/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/svd_op_test.runfiles/org_tensorflow/tensorflow/tools/ci_build/gpu_build/parallel_gpu_execute: line 40: 72935 Aborted                 (core dumped) $@
================================================================================
```

### Source code / logs
[svd_op_test.log](https://github.com/tensorflow/tensorflow/files/2063542/svd_op_test.log)
[matrix_solve_ls_op_test.log](https://github.com/tensorflow/tensorflow/files/2063544/matrix_solve_ls_op_test.log)
"
19696,Save training using Tensorflow C++ with VS2015,"------------------------
------------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: Visual Studio 2015
- **CUDA/cuDNN version**: Yes
- **GPU model and memory**:  NVIDIA Quadro P5000 16GB
- **Exact command to reproduce**: N/A
------------------------
------------------------

### Description of the problem: Save Training Results using Tensorflow C++ VS2015
I have successfully compiled tensorflow to be able to use the C++ with VS2015, and I have successfully run some examples.

I want to save my training results and restore them to be able to continue training or simply to use the network to perform e.g. classification.

I was unable until now to perform that, and the C++ interface didn't have many examples or tutorials available.

Can someone provide me some instructions to perform that?

------------------------
------------------------"
19695,ppc64le: //tensorflow/contrib/image:image_ops_test test fails,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/contrib/image:image_ops_test



### Describe the problem
```
======================================================================
FAIL: test_rotate_even (__main__.ImageOpsTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/image/image_ops_test.runfiles/org_tensorflow/tensorflow/contrib/image/python/kernel_tests/image_ops_test.py"", line 68, in test_rotate_even
    [1, 7, 13, 19, 25, 31], [0, 6, 12, 18, 24, 30]]])
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/image/image_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1466, in assertAllEqual
    np.testing.assert_array_equal(a, b, err_msg=msg)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 871, in assert_array_equal
    verbose=verbose, header='Arrays are not equal')
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 796, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Arrays are not equal

(mismatch 1.85185185185%)
 x: array([[[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17],...
 y: array([[[ 0,  1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10, 11],
        [12, 13, 14, 15, 16, 17],...

----------------------------------------------------------------------
Ran 11 tests in 14.343s

FAILED (failures=1)
not equal where =  (array([1, 1]), array([3, 4]), array([3, 4]))
not equal lhs =  [20 32]
not equal rhs =  [21 33]
================================================================================
```

### Source code / logs
[image_ops_test.log](https://github.com/tensorflow/tensorflow/files/2063329/image_ops_test.log)
"
19694,ppc64le: //tensorflow/contrib/distributions:sinh_arcsinh_bijector_test test fails,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/contrib/distributions:sinh_arcsinh_bijector_test



### Describe the problem
```
======================================================================
FAIL: testBijectorOverRange (__main__.SinhArcsinhBijectorTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/sinh_arcsinh_bijector_test.runfiles/org_tensorflow/tensorflow/contrib/distributions/python/kernel_tests/bijectors/sinh_arcsinh_bijector_test.py"", line 163, in testBijectorOverRange
    atol=0.)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/sinh_arcsinh_bijector_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1368, in assertAllClose
    self._assertAllCloseRecursive(a, b, rtol=rtol, atol=atol, msg=msg)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/sinh_arcsinh_bijector_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1338, in _assertAllCloseRecursive
    path_str))
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/distributions/sinh_arcsinh_bijector_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1273, in _assertArrayLikeAllClose
    a, b, rtol=rtol, atol=atol, err_msg=msg, equal_nan=True)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 1411, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 762, in assert_array_compare
    chk_same_position(x == -inf, y == -inf, hasval='-inf')
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 735, in chk_same_position
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=0.0001, atol=0
Mismatched value: a is different from b.
x and y -inf location mismatch:
 x: array([[-2.66556, -52.9496],
       [-2.76943, -53.0418],
       [-2.91071, -53.1402],...
 y: array([[  -2.665562,  -52.949618],
       [  -2.769431,  -53.041801],
       [  -2.910706,  -53.140182],...

----------------------------------------------------------------------
Ran 12 tests in 1.492s

FAILED (failures=1)
not close where =  (array([473, 474, 475, ..., 998, 999, 999]), array([1, 1, 1, ..., 1, 0, 1]))
not close lhs =  [-inf -inf -inf ..., -inf -inf -inf]
not close rhs =  [-327.55577066 -328.16256741 -328.76936416 ..., -646.12406241 -357.13107722
 -646.73085916]
not close dif =  [ inf  inf  inf ...,  inf  inf  inf]
not close tol =  [ 0.03275558  0.03281626  0.03287694 ...,  0.06461241  0.03571311
  0.06467309]
dtype = float128, shape = (1000, 2)
================================================================================

```


### Source code / logs
[distributions_sinh_arcsinh_bijector_test.log](https://github.com/tensorflow/tensorflow/files/2063320/distributions_sinh_arcsinh_bijector_test.log)
"
19693,ppc64le: //tensorflow/python/kernel_tests:conv_ops_test test fails,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/python/kernel_tests:conv_ops_test



### Describe the problem
```
======================================================================
FAIL: testInceptionFwd_46 (__main__.Conv2DTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/conv_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 717, in decorated
    f(self, **kwargs)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/conv_ops_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/conv_ops_test.py"", line 1842, in Test
    self._CompareFwdValues(input_size, filter_size, [stride, stride], padding)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/conv_ops_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/conv_ops_test.py"", line 252, in _CompareFwdValues
    self.assertAllClose(values[0], values[i], rtol=1e-5, atol=1e-5)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/conv_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1368, in assertAllClose
    self._assertAllCloseRecursive(a, b, rtol=rtol, atol=atol, msg=msg)
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/conv_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1338, in _assertAllCloseRecursive
    path_str))
  File ""/root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/kernel_tests/conv_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py"", line 1273, in _assertArrayLikeAllClose
    a, b, rtol=rtol, atol=atol, err_msg=msg, equal_nan=True)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 1411, in assert_allclose
    verbose=verbose, header=header, equal_nan=equal_nan)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/testing/utils.py"", line 796, in assert_array_compare
    raise AssertionError(msg)
AssertionError:
Not equal to tolerance rtol=1e-05, atol=1e-05
Mismatched value: a is different from b.
(mismatch 26.2006802721%)
 x: array([[[[  9.935687,   9.715093,   9.417497,  10.535542,   9.895369,
            8.248978],
         [ 12.098586,  12.769324,  11.302494,  11.481708,  13.940086,...
 y: array([[[[  9.933954,   9.714816,   9.417538,  10.534116,   9.897067,
            8.247837],
         [ 12.099165,  12.76971 ,  11.302752,  11.482008,  13.93998 ,...

----------------------------------------------------------------------
Ran 72 tests in 22.143s

FAILED (failures=1)

```

### Source code / logs
[conv_ops_test.log](https://github.com/tensorflow/tensorflow/files/2063282/conv_ops_test.log)"
19692,ppc64le: //tensorflow/python/kernel_tests:atrous_conv2d_test test fails,"Please assign this issue to me and add the tag: stat:community support

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, Have written a Dockerfile.gpu.ppc64le file and modified ci_parameterized_build.sh to allow for build/test runs on ppc64le. (Will submit as a PR)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master from may 30th
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 9.2.88, 7
- **GPU model and memory**: 2 P100 GPUs with 16 GB of memory each

- **Exact command to reproduce**:
bazel test --config=cuda -c opt --local_test_jobs=2 --cache_test_results=no --run_under=//tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/python/kernel_tests:atrous_conv2d_test



### Describe the problem
```
----------------------------------------------------------------------
Ran 4 tests in 14.613s

FAILED (failures=1)
atrous_conv2d gradient err = 0.000759065
atrous_conv2d gradient err = 0.000683963
atrous_conv2d gradient err = 0.000596046
not close where =  (array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]), array([0, 1, 1, 2, 2, 3, 4, 5, 7, 8, 9, 9, 0, 0, 0, 1, 0, 1]), array([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]))
not close lhs =  [   3.    3.   13.   10.   30.   30.  113.  113.  221.  275.  310.  410.
   19.   93.  163.  165.  181.  183.]
not close rhs =  [   2.38105154    2.80899453   12.87652969   10.06372643   29.96479416
   30.14238167  113.12899017  113.32045746  221.52029419  274.54296875
  310.39041138  410.5213623    19.19488144   93.29485321  161.81001282
  164.79013062  181.79176331  183.26371765]
not close dif =  [ 0.61894846  0.19100547  0.12347031  0.06372643  0.03520584  0.14238167
  0.12899017  0.32045746  0.52029419  0.45703125  0.39041138  0.5213623
  0.19488144  0.29485321  1.18998718  0.20986938  0.79176331  0.26371765]
not close tol =  [ 0.00338105  0.00380899  0.01387653  0.01106373  0.0309648   0.03114238
  0.114129    0.11432046  0.22252031  0.27554297  0.3113904   0.41152138
  0.02019488  0.09429486  0.16281003  0.16579014  0.18279177  0.18426372]
dtype = float32, shape = (2, 13, 13, 2)
================================================================================
Target //tensorflow/python/kernel_tests:atrous_conv2d_test up-to-date:
  bazel-bin/tensorflow/python/kernel_tests/atrous_conv2d_test
INFO: Elapsed time: 67.037s, Critical Path: 46.28s
INFO: Build completed, 1 test FAILED, 3 total actions
//tensorflow/python/kernel_tests:atrous_conv2d_test                      FAILED in 1 out of 2 in 16.1s
  Stats over 2 runs: max = 16.1s, min = 4.3s, avg = 10.2s, dev = 5.9s
  WARNING: //tensorflow/python/kernel_tests:atrous_conv2d_test: Test execution time (4.3s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=""short"" or size=""small"".
  /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/testlogs/tensorflow/python/kernel_tests/atrous_conv2d_test/shard_1_of_2/test.log

Executed 1 out of 1 test: 1 fails locally.
```


### Source code / logs

[atrous_conv2d_test.log](https://github.com/tensorflow/tensorflow/files/2063256/atrous_conv2d_test.log)

"
19691,"tf.image.convert_image_dtype(image, tf.float32) does not normalize output properly","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary via pip
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
In docs: `This op converts between data types, scaling the values appropriately before casting.`
Yes, we can not scale uint8 and then cast, we will loose all the information
But this function is counterintuitive in a way that we can convert from float to uint and get ready-to-display result (e.g. in Tensorboard) but we can't do same to covert when reading images as input to our model
Is that a correct behaviour?

### Source code / logs
```
image_gt = tf.image.decode_image(image_parsed[""image""], channels=3)
image_gt = tf.image.convert_image_dtype(image_gt, tf.float32, saturate=False)
image_gt = tf.Print(image_gt, [tf.reduce_max(image_gt)], ""image_gt_cast"")
```

Result of execution:
```
image_gt_cast[250.892319]
image_gt_cast[244.243454]
image_gt_cast[245.468872]
image_gt_cast[258.527466]
image_gt_cast[270.992615]
image_gt_cast[227.410767]
```
"
19690,The tensorflow become dead when I use nccl.all_sum,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:ubuntu14.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.3.1
- **Python version**: python3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

I try to use nccl to transfer data between gpus, but I can not run the programme although my 'print' tell
me 'Tensor(""NcclAllReduce_1:0"", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)
'
### Source code / logs
this is my code:
```
import tensorflow as tf
import numpy as np

def network(x):
    with tf.device('/gpu:1'):
        x1 = tf.zeros(shape=[32, 35, 35, 192])
    with tf.device('/gpu:0'):
        x0= tf.reshape(x, [-1, 35, 35, 192])
        #x1 = tf.contrib.nccl.broadcast(x0, ['/gpu:1'])
        #print(type(x1[1][0]))
        #return x1
        #return x1
        (x_temp, x_temp1) = tf.contrib.nccl.all_sum([x0,x1])
        print(x_temp1)
        result = tf.identity(x_temp1)
        return result

def main(_):
    x = np.random.ranf(size=[32, 35, 35, 192])
    x = x.astype('float32')
    y_pre = network(x)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(y_pre)

if __name__ == '__main__':
    tf.app.run(main=main)
```
this is my log:
Tensor(""NcclAllReduce_1:0"", shape=(32, 35, 35, 192), dtype=float32, device=/device:GPU:1)
2018-06-01 21:16:36.078103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-06-01 21:16:36.197439: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x4741160 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-06-01 21:16:36.198248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:02:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-06-01 21:16:36.323103: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47455a0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-06-01 21:16:36.323733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 2 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:03:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-06-01 21:16:36.456854: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x47499e0 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-06-01 21:16:36.457447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 3 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:04:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2018-06-01 21:16:36.461138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 2 3
2018-06-01 21:16:36.461152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y Y Y
2018-06-01 21:16:36.461171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y Y Y
2018-06-01 21:16:36.461177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 2:   Y Y Y Y
2018-06-01 21:16:36.461181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 3:   Y Y Y Y
2018-06-01 21:16:36.461189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
2018-06-01 21:16:36.461195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:02:00.0)
2018-06-01 21:16:36.461201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:03:00.0)
2018-06-01 21:16:36.461205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:04:00.0)
"
19688,"why new defined op always runs on PS host, not in worker host?","i have refactored word2vec code（from models/tutorials/embedding/）, my problem is new defined OP ""train_op = word2vec.neg_train_word2vec ""  runs on PS,  I don't know where I went wrong.  my code :           
with tf.device(tf.train.replica_device_setter(worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
                                                      cluster=cluster, ps_strategy=ps_strategy, merge_devices=False)):

            # Declare all variables we need.
            embedding = tf.get_variable(name=""word_embedding"", shape = [71291,FLAGS.embedding_size],
                        initializer = tf.random_uniform_initializer(-0.5 / FLAGS.embedding_size, 0.5 / FLAGS.embedding_size))

            weights =   tf.get_variable(name=""word_weights"",shape = [71291, FLAGS.embedding_size],
                        initializer = tf.random_normal_initializer() )


            global_step = tf.Variable(0, name=""global_step"", trainable=False)

            # The training data
            ( words,
              counts,
              words_per_epoch,
              current_epoch,
              total_words_processed,examples,
              labels) = word2vec.skipgram_word2vec(filename=FLAGS.train_data,
                                           batch_size=FLAGS.batch_size,
                                           window_size=FLAGS.window_size,
                                           min_count=FLAGS.min_count,
                                           subsample=FLAGS.subsample)

            # Linear learning rate decay.
            words_to_train = tf.cast(words_per_epoch * FLAGS.epochs_to_train, tf.float32)
            lr = FLAGS.learning_rate * tf.maximum(
                        0.0001,
                        1.0 - tf.cast(total_words_processed, tf.float32) / words_to_train)

            train_op = word2vec.neg_train_word2vec(embedding,
                                          weights,
                                          examples,
                                          labels,
                                          lr,
                                          #vocab_count=counts.tolist(),
                                           num_negative_samples=FLAGS.num_neg_samples)"
19687,incompatible with eager and graph when output of tf.keras.Model is a dictionary,"env: ubuntu18.04 python2.7 tensorflow1.8
```   
 import tensorflow as tf
 tf.enable_eager_execution()
 class Model(tf.keras.Model):
        def __init__(self):
            super(Model, self).__init__()

        def call(self, inputs):
            return {""inputs"": inputs}
 m = Model()
 m(tf.random_uniform((2, 2)))
```
the code runs smoothly, but when I comment ` tf.enable_eager_execution()`, it raises error,  the compatibility between eager and graph is quite important, please have a see and fix it"
19686,"feature request: tf.string_split cannot split more than twice, when the maxlengths are not same","------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:1.7
- **Python version**: 3.6.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CUDA 9.0 / cuDNN7
- **GPU model and memory**:  NVIDIA Quadro K620
- **Exact command to reproduce**:


### Describe the problem
I used Dataset API to process NLP task.
In input function, I have a string col, which contains three kinds of  delimiter '\1', '\2', ' '.
For example, the string is a ducument, the '\1' is used to split passages and '\2' is used to split sentecnes and ' ' is used to split tokens(words).
I want to split it into a 3-D tensor, whose shape may be [None,None,None], and before the data is truly read, these three numbers cannot be determined.

Firstly, I try the following code to directly call tf.string_split three times:
```python 
#parsed_line[4] is the string col, Tensor(""DecodeCSV:5"", shape=(), dtype=string)
parsed_line[4]=tf.string_split([parsed_line[4]],delimiter='\2').values
parsed_line[4]=tf.string_split(parsed_line[4],delimiter='\1').values
parsed_line[4]=tf.string_split(parsed_line[4],delimiter=' ')
parsed_line[4]=tf.sparse_tensor_to_dense(parsed_line[4], default_value = """")
#after processing, parsed_line[4] is Tensor(""SparseToDense_2:0"", shape=(?, ?), dtype=string)
```
However, I want to get [None,None,None], but not [None,None], because it loss the information which passage the sencences are belong to.

Secondly, I try tf.map_fn as follows:
```python
parsed_line[4]=tf.string_split([parsed_line[4]],delimiter='\2').values
parsed_line[4]=tf.string_split(parsed_line[4],delimiter='\1')
parsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)
parsed_line[4]=tf.sparse_tensor_to_dense(parsed_line[4], default_value = """")
```
Then it will throw out the following errors:
```
Traceback (most recent call last):
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 179, in <module>
    first_batch = sess.run(binput.input_fn(r'D:\Datadump\LSAT\debug_data\test_tsv.tsv','train'))
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 109, in train_input
    .map(lambda x: decode_tsv_indexing(x)))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 838, in map
    return MapDataset(self, map_func)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1826, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\function.py"", line 488, in add_to_graph
    self._create_definition_if_needed()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\function.py"", line 321, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\function.py"", line 338, in _create_definition_if_needed_impl
    outputs = self._func(*inputs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1791, in tf_map_func
    ret = map_func(nested_args)
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 109, in <lambda>
    .map(lambda x: decode_tsv_indexing(x)))
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 54, in decode_tsv_indexing
    parsed_line[4]=tf.SparseTensor(parsed_line[4].indices,tf.map_fn(tf.string_split,[parsed_line[4].values]),parsed_line[4].dense_shape)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\functional_ops.py"", line 413, in map_fn
    swap_memory=swap_memory)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\control_flow_ops.py"", line 3202, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\control_flow_ops.py"", line 2940, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\control_flow_ops.py"", line 2877, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\functional_ops.py"", line 404, in compute
    nest.assert_same_structure(dtype or elems, packed_fn_values)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\nest.py"", line 267, in assert_same_structure
    _recursive_assert_same_structure(nest1, nest2, check_types)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\util\nest.py"", line 193, in _recursive_assert_same_structure
    ""First structure: %s\n\nSecond structure: %s."" % (nest1, nest2))
ValueError: The two structures don't have the same nested structure.

First structure: [tf.string]

Second structure: SparseTensor(indices=Tensor(""map/while/StringSplit:0"", shape=(?, 2), dtype=int64), values=Tensor(""map/while/StringSplit:1"", shape=(?,), dtype=string), dense_shape=Tensor(""map/while/StringSplit:2"", shape=(2,), dtype=int64)).

Process finished with exit code 1
```
I think it is caused by the lengths (the last dimensionality) of each sentence are different.

To valid my guess, I split this col to 5 cols in the input file, and I run tf.string_split on each of them to get [None,None] tensor, and finally, I try to stack them int one tensor [None,None,None]
```python
for i in range(4,9):
    parsed_line[i] = tf.string_split([parsed_line[i]], delimiter='\1').values
    parsed_line[i] = tf.string_split(parsed_line[i])
    parsed_line[i] = tf.sparse_tensor_to_dense(parsed_line[i], default_value="""")
parsed_line[4]=tf.stack(parsed_line[4:9])
```
Yes, it throws an error:
```
2018-06-01 17:41:31.412421: W T:\src\github\tensorflow\tensorflow\core\framework\op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:891 : Invalid argument: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]
	 [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1327, in _do_call
    return fn(*args)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1312, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1420, in _call_tf_sessionrun
    status, run_metadata)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 516, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [2,31] != values[1].shape = [2,35]
	 [[Node: stack = Pack[N=5, T=DT_STRING, axis=0](SparseToDense_2, SparseToDense_3, SparseToDense_4, SparseToDense_5, SparseToDense_6)]]
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,?], [?,5,?,?], [?,?], [?,?,?], [?,?], [?]], output_types=[DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_STRING, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]

```
When truly read the input data, two sentences has 31 tokens and 35 tokens, respectively.
Finally, I try to pad them dynamically as follows:
```python
for i in range(4,9):
    parsed_line[i] = tf.string_split([parsed_line[i]], delimiter='\1').values
    parsed_line[i] = tf.string_split(parsed_line[i])
    parsed_line[i] = tf.sparse_tensor_to_dense(parsed_line[i], default_value="""")

shape_list=[]
for i in range(4, 9):
    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)
    shape_list.append(tmp)
shape_stack=tf.stack(shape_list)
maxs=tf.reduce_max(shape_stack,0)
for i in range(4,9):
    paddings=tf.stack([tf.constant([0,0],dtype='int32'),maxs-parsed_line[i].shape])
    parsed_line[i]=tf.pad(parsed_line[i],paddings,""CONSTANT"")
parsed_line[4]=tf.stack(parsed_line[4:9])
```
This code throws the following erros:
```
Traceback (most recent call last):
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 175, in <module>
    first_batch = sess.run(binput.input_fn(r'D:\Datadump\LSAT\debug_data\test_tsv.tsv','train'))
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 105, in train_input
    .map(lambda x: decode_tsv_indexing(x)))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 838, in map
    return MapDataset(self, map_func)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1826, in __init__
    self._map_func.add_to_graph(ops.get_default_graph())
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\function.py"", line 488, in add_to_graph
    self._create_definition_if_needed()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\function.py"", line 321, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\function.py"", line 338, in _create_definition_if_needed_impl
    outputs = self._func(*inputs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 1791, in tf_map_func
    ret = map_func(nested_args)
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 105, in <lambda>
    .map(lambda x: decode_tsv_indexing(x)))
  File ""D:/PythonProjects/PhillyNNFramework/p_data_func/LSATInput.py"", line 71, in decode_tsv_indexing
    tmp=tf.convert_to_tensor(parsed_line[i].shape,dtype=None)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 950, in convert_to_tensor
    as_ref=False)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1040, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 256, in _tensor_shape_tensor_conversion_function
    ""Cannot convert a partially known TensorShape to a Tensor: %s"" % s)
ValueError: Cannot convert a partially known TensorShape to a Tensor: (?, ?)
```
""Cannot convert a partially known TensorShape to a Tensor: (?, ?)""
Thus, I don't know whether there is other methods to solve my problems.

Thanks."
19685,bazel build libtensorflow_inference.so failed,"I try to put this `TensorFlow` to Unity for Android. I built the aar file in Android Studio. But I got below error.<br>

> 06-01 16:38:34.341  4137  4154 E AndroidRuntime: Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'All' with these attrs.  Registered devices: [CPU], Registered kernels:
06-01 16:38:34.341  4137  4154 E AndroidRuntime:   <no registered kernels>
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	 [[Node: assert_equal/All = All[Tidx=DT_INT32, keep_dims=false](assert_equal/Equal, assert_equal/Const)]]
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.Session.run(Native Method)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.Session.access$100(Session.java:48)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.Session$Runner.runHelper(Session.java:285)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.Session$Runner.run(Session.java:235)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:142)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.demo.TensorFlowObjectDetectionAPIModel.recognizeImage(TensorFlowObjectDetectionAPIModel.java:158)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:289)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at android.os.Handler.handleCallback(Handler.java:751)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at android.os.Handler.dispatchMessage(Handler.java:95)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at android.os.Looper.loop(Looper.java:154)
06-01 16:38:34.341  4137  4154 E AndroidRuntime: 	at android.os.HandlerThread.run(HandlerThread.java:61)

Do anyone know how to resolve it?"
19684,how can i import tensorflow lite into eclipse java project?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19683,Transform_Graph feed value for  bool placeholder,"### System Information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow):** No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** MacOS 10.13.3
- **TensorFlow installed from (source or binary):** source
- **TensorFlow version (use command below):** r1.8
- **Python version:** 2.7
- **Bazel version (if compiling from source):** 0.13
- **GCC/Compiler version (if compiling from source):** Apple LLVM version 9.1.0 (clang-902.0.39.1)
- **CUDA/cuDNN version:** version 8.0
- **GPU model and memory:** No
- **Exact command to reproduce:** `bazel build tensorflow/tools/graph_transforms:transform_graph`


### Describe the problem
Fold the batchnorm of [Facenet](https://github.com/davidsandberg/facenet#Pre-trained).

### Source Code/ Logs
```bash
bazel-bin/tensorflow/tools/graph_transforms/transform_graph 
--in_graph=""/Users/kit/Downloads/20180408-1029002/20180408-102900.pb""
 --out_graph=""../optimize_graph.pb"" 
--inputs=""input"" 
--outputs=""InceptionResnetV1/Logits/Flatten/flatten/Reshape""
 --transforms='
  strip_unused_nodes(type=float, shape=""1,299,299,3"")
  remove_nodes(op=Identity, op=CheckNumerics)
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms'
```
### Error:
```bash
2018-06-01 12:51:11.118630: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying strip_unused_nodes
2018-06-01 12:51:11.344986: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying remove_nodes
2018-06-01 12:52:04.712395: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying fold_constants
2018-06-01 12:52:05.068919: E tensorflow/tools/graph_transforms/transform_graph.cc:279] fold_constants: Ignoring error You must feed a value for placeholder tensor 'phase_train' with dtype bool
	 [[Node: phase_train = Placeholder[dtype=DT_BOOL, shape=<unknown>]()]]
2018-06-01 12:52:05.201658: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying fold_batch_norms
2018-06-01 12:52:05.509836: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying fold_old_batch_norms
```
I use the tensorboard to see the graph and I `phase_train` is the input to every `slim.batchnorm`.
![image](https://user-images.githubusercontent.com/20907377/40823628-9adb611c-65a3-11e8-8b0a-1f6414718460.png)

My Question is how can I feed the value for this bool placeholder in bazel."
19681,Dockerfiles need to be updated,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- OS: Ubuntu16.04 in Nvidia-Docker container with image `tensorflow/tensorflow:latest-gpu-py3`

### Describe the problem
The Nvidia has upgraded their apt-repo sources lists files to `https` but the source-list files depended in tensorflow are still old one(with http). So, when we rebuild the image, the issue occurs like this:
```shell
Err:7 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  Release.gpg
  The following signatures were invalid: NODATA 1  NODATA 2
Get:10 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [637 kB]
Get:12 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]
Get:13 http://archive.ubuntu.com/ubuntu xenial/universe Sources [9802 kB]
Get:11 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release.gpg [691 B]
Err:11 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release.gpg
  The following signatures were invalid: NODATA 1  NODATA 2
```
Following the lists file in the up-to-date `nvidia/cuda:9.0-base-ubuntu16.04` image, I tried to update the sources lists files in `/etc/apt/sources.list.d/` and it was solved:  
In `cuda.list`:  
```
deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64 /
```
In `nvidia-ml.list`:
```
deb https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64 /
```
 Probably you need to rebuild and update your docker images.
"
19679,Build fails if Nvidia nccl doc files (NCCL-SLA.txt) are relocated,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Slackware 14.2+ (-current)
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:

- **Python version**: 
2.7.15
- **Bazel version (if compiling from source)**:
0.13.1- (@non-git)
- **GCC/Compiler version (if compiling from source)**:
gcc (GCC) 7.3.0
- **CUDA/cuDNN version**:
CUDA 9.2/cuDNN 7.1
- **GPU model and memory**:
Titan X Pascal 16 GB
- **Exact command to reproduce**:
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Tensorflow build process with nccl enabled is too ""picky"" about location of Nvidia NCLL doc file(s) - for ex. NCCL-SLA.txt.
It expects to find the text file(s) in the root of the nccl install dir (in my case `/opt/nvidia/nccl`) and the build fails if I relocate the txt file(s) (to for ex. a `doc` dir in the nccl install dir (for ex. `/opt/nvidia/nccl/doc`)

Would be great if the build process would also look for the file(s) in subdirs of the `nccl` install directory. This would also make it possible to install nccl in a prefix such as `/usr/` and put the docs in `/usr/doc`. Not a big deal though, considering there are always more important issues to worry about.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
ERROR: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt'
ERROR: /usr/local/src/tensorflow/tensorflow-git/tensorflow/tools/pip_package/BUILD:167:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@local_config_nccl//:nccl/NCCL-SLA.txt'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```
"
19677,Inconsistent calculation of complex derivatives,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.4 LTS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0 and 1.8.0
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  the problem is in both cpu and gpu tensorflow
- **GPU model and memory**: nvidia 1080 ti
- **Exact command to reproduce**: see the code below

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I run a simple code in tensorflow 1.7.0 and then in 1.8.0, which calculates gradients of a function of complex variables and I got a very strange behaviour especially in tensorflow 1.8.0. See the code and the output. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
from __future__ import print_function
import numpy as np
import tensorflow as tf

x1 = tf.placeholder(shape=(), dtype=tf.complex64, name='x1')
x2 = tf.placeholder(shape=(), dtype=tf.complex64, name='x2')

x1_value = np.complex(1.0, 2.0)
x2_value = np.complex(4.0, 1.0)

sess = tf.Session()

init_op = tf.global_variables_initializer()

sess.run(init_op)

x1c = tf.conj(x1)
x2c = tf.conj(x2)

y1 = 2*x1*tf.log(x2c) 
y2 = 2*x1c*tf.log(x2)
y = y1 + y2

# Print the partial derivative of y evaluated at x1_value and x2_value
print('tf one sess.run', sess.run(tf.conj(tf.gradients(y, x1, tf.constant(1, dtype=tf.complex64))), feed_dict={x1:x1_value, x2:x2_value}))

# Print the partial derivative of y1 evaluated at x1_value and x2_value + the partial derivative of y2 evaluated at x1_value and x2_value
print('tf, two sess.run', sess.run(tf.conj(tf.gradients(y1, x1, tf.constant(1, dtype=tf.complex64))), feed_dict={x1:x1_value, x2:x2_value}) + sess.run(tf.conj(tf.gradients(y2, x1, tf.constant(1, dtype=tf.complex64))), feed_dict={x1:x1_value, x2:x2_value}))

print('np, hand computed partial derivative', 2*np.log(np.conj(x2_value))  + 2*np.log(x2_value))

# Output
Tensorflow 1.7.0
tf one sess.run [5.6664267-0.97991467j]
tf, two sess.run [5.6664267-0.97991467j]
np, hand computed partial derivative (5.66642668811+0j)

Tensorflow 1.8.0
tf one sess.run [5.6664267-0.97991467j]
tf, two sess.run [5.6664267+0.j]
np, hand computed partial derivative (5.66642668811+0j)
```"
19676,"Error trying to build for macOS with GPU support: ""no toolchain corresponding to 'local_darwin' found for cpu 'darwin' ""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 'High Sierra' Version 10.13.4 (17E202)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: N/A, attempting to compile at e365deab1333005c8aa186632f160c1bfd4485f8 with minimal local changes (see below)
- **Python version**: 2.7.15
- **Bazel version (if compiling from source)**: 0.13.1-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 8.1.0 (clang-802.0.42)
- **CUDA/cuDNN version**: cuda_9.2.64_mac with cuda_9.2.64.1_mac, cudnn-9.2-osx-x64-v7.1
- **GPU model and memory**: NVIDIA GeForce GT 750M with 2 GB device memory, CUDA Compute Capability 3.0
- **Exact command to reproduce**:

```
./configure
bazel build --config=opt --config=cuda --save_temps --explain=explain.txt --verbose_explanations --verbose_failures --linkopt=-Wl,-rpath,/usr/local/cuda/lib //tensorflow/tools/pip_package:build_pip_package
```

### Describe the problem
This is a re-occurrence of #9072, except that the solutions mentioned there (not using clang as the CUDA compiler, using CommandLineTools) do not resolve the problem.

To configure, I selected the following:
```
You have bazel 0.13.1-homebrew installed.
Please specify the location of python. [Default is /usr/local/opt/python@2/bin/python2.7]: 


Found possible Python library paths:
  /usr/local/Cellar/python@2/2.7.15/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/Cellar/python@2/2.7.15/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages]

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]:  
Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: 
Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: 
Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: 
Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: 
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: 
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: 
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: 9.2


Please specify the location where CUDA 9.2 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7.1.4


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:


Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]3.0


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: 
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
Configuration finished
```

To build, I try:

```
bazel build --config=opt --config=cuda --save_temps --explain=explain.txt --verbose_explanations --verbose_failures --linkopt=-Wl,-rpath,/usr/local/cuda/lib //tensorflow/tools/pip_package:build_pip_package
```

However, this results in the error:

```
Starting local Bazel server and connecting to it...
............
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: Inconsistent crosstool configuration; no toolchain corresponding to 'local_darwin' found for cpu 'darwin'
INFO: Elapsed time: 0.903s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (2 packages loaded)
```

The output of `xcode-select -p` is:

```
/Library/Developer/CommandLineTools
```

The output of `/usr/bin/gcc --version` is:

```
Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 8.1.0 (clang-802.0.42)
Target: x86_64-apple-darwin17.5.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin
```

I am able to build & run the 'deviceQuery' CUDA SDK sample without issue.

### Source code / logs
The only local changes from e365deab1333005c8aa186632f160c1bfd4485f8 I have are:

```diff
diff --git a/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc b/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
index a561d918bd..46c91b4511 100644
--- a/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
+++ b/tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc
@@ -69,7 +69,7 @@ __global__ void concat_variable_kernel(
   IntType num_inputs = input_ptr_data.size;
 
   // verbose declaration needed due to template
-  extern __shared__ __align__(sizeof(T)) unsigned char smem[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char smem[];
   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);
 
   if (useSmem) {
diff --git a/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc b/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc
index 5390222b3a..fcbd733614 100644
--- a/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc
+++ b/tensorflow/core/kernels/depthwise_conv_op_gpu.cu.cc
@@ -172,7 +172,7 @@ __global__ __launch_bounds__(1024, 2) void DepthwiseConv2dGPUKernelNHWCSmall(
     const DepthwiseArgs args, const T* input, const T* filter, T* output) {
   assert(CanLaunchDepthwiseConv2dGPUSmall(args));
   // Holds block plus halo and filter data for blockDim.x depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast<T*>(shared_memory);
 
   const int num_batches = args.batch;
@@ -452,7 +452,7 @@ __global__ __launch_bounds__(1024, 2) void DepthwiseConv2dGPUKernelNCHWSmall(
     const DepthwiseArgs args, const T* input, const T* filter, T* output) {
   assert(CanLaunchDepthwiseConv2dGPUSmall(args));
   // Holds block plus halo and filter data for blockDim.z depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast<T*>(shared_memory);
 
   const int num_batches = args.batch;
@@ -1118,7 +1118,7 @@ __launch_bounds__(1024, 2) void DepthwiseConv2dBackpropFilterGPUKernelNHWCSmall(
     const DepthwiseArgs args, const T* output, const T* input, T* filter) {
   assert(CanLaunchDepthwiseConv2dBackpropFilterGPUSmall(args, blockDim.z));
   // Holds block plus halo and filter data for blockDim.x depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast<T*>(shared_memory);
 
   const int num_batches = args.batch;
@@ -1388,7 +1388,7 @@ __launch_bounds__(1024, 2) void DepthwiseConv2dBackpropFilterGPUKernelNCHWSmall(
     const DepthwiseArgs args, const T* output, const T* input, T* filter) {
   assert(CanLaunchDepthwiseConv2dBackpropFilterGPUSmall(args, blockDim.x));
   // Holds block plus halo and filter data for blockDim.z depths.
-  extern __shared__ __align__(sizeof(T)) unsigned char shared_memory[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char shared_memory[];
   T* const shared_data = reinterpret_cast<T*>(shared_memory);
 
   const int num_batches = args.batch;
diff --git a/tensorflow/core/kernels/split_lib_gpu.cu.cc b/tensorflow/core/kernels/split_lib_gpu.cu.cc
index 393818730b..58a1294005 100644
--- a/tensorflow/core/kernels/split_lib_gpu.cu.cc
+++ b/tensorflow/core/kernels/split_lib_gpu.cu.cc
@@ -121,7 +121,7 @@ __global__ void split_v_kernel(const T* input_ptr,
   int num_outputs = output_ptr_data.size;
 
   // verbose declaration needed due to template
-  extern __shared__ __align__(sizeof(T)) unsigned char smem[];
+  extern __shared__ __align__(sizeof(T) > 16 ? sizeof(T) : 16) unsigned char smem[];
   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);
 
   if (useSmem) {
diff --git a/third_party/gpus/cuda/BUILD.tpl b/third_party/gpus/cuda/BUILD.tpl
index 2a37c65bc7..43446dd99b 100644
--- a/third_party/gpus/cuda/BUILD.tpl
+++ b/third_party/gpus/cuda/BUILD.tpl
@@ -110,7 +110,7 @@ cc_library(
         ""."",
         ""cuda/include"",
     ],
-    linkopts = [""-lgomp""],
+    #linkopts = [""-lgomp""],
     linkstatic = 1,
     visibility = [""//visibility:public""],
 )
diff --git a/third_party/toolchains/gpus/cuda/BUILD b/third_party/toolchains/gpus/cuda/BUILD
index 4cb8380938..d025c4f3aa 100644
--- a/third_party/toolchains/gpus/cuda/BUILD
+++ b/third_party/toolchains/gpus/cuda/BUILD
@@ -115,7 +115,7 @@ cc_library(
         ""."",
         ""cuda/include"",
     ],
-    linkopts = [""-lgomp""],
+    #linkopts = [""-lgomp""],
     linkstatic = 1,
     visibility = [""//visibility:public""],
 )
```"
19673,ImportError: cannot import name 'cache',"when I try to run the inception code for deep learning (pre-learned) on Anaconda3 which have this command line:
from cache import cache

I get this error and I don't know how to solve it.
ImportError: cannot import name 'cache'"
19672,how to train models on different GPUs in parallel?,"hi, all:
    How to train different models on different GPUs in parallel? For example, gpu_0 is responsible for model_0 and gpu_1 is for model_1
    I tried this way:
    with tf.device('/gpu:0'):
         op_0
    with tf.device('/gpu:1'):
         op_1
    but it seems that the models are trained in sequential order, because each time only one GPU-Util info is printed.
    Any advice please?
    Thanks :)"
19671,Variables may live longer than they suppose to on Eager Execution,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 3.6


### Describe the problem

Using tensorflow EagerExecution. According to the documentation :

> During eager execution the lifetime of state objects is determined by the lifetime of their corresponding Python object.

I have some trouble with how tensorflow handle memory. I would like to remove tensors from my memory after each iteration on this toy example. The results are shown in the chart.

I have tried with Variables and with simple tensors. tf.assign doesn't do the job. More and more memory is used. It might be normal in order to be able to compute the gradient. But, if I apply some dummy optimizer at the end of each iteration, the memory isn't not released (more precisely, it happens sometimes but the global trend is that the memory use is growing).

I haven't found any API to deal with that yet.


![stackoverflow](https://user-images.githubusercontent.com/38664274/40790405-c17a6b2c-64ec-11e8-8a35-361885acd44a.PNG)


### Source code / logs

```
import tensorflow as tf
import tensorflow.contrib.eager as tfe
import numpy as np
import time as ti


tf.enable_eager_execution()

for i in range(150):
    all_subject=tfe.Variable(np.random.rand(200, 500), dtype=tf.float32)
    tf.assign(all_subject, np.random.rand(200,500) )
    ti.sleep(1.0)
    del all_subject
    ti.sleep(0.5)
```"
19670,adjust_hsv_in_yiq_op_gpu.cu.pic.o was not created,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8
- **Python version**:  3.6.5
- **Bazel version (if compiling from source)**:  0.13.0
- **GCC/Compiler version (if compiling from source)**:  7.3.1
- **CUDA/cuDNN version**: 9.1.85/7.1.3
- **GPU model and memory**: GTX 745, 4GB
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures


### Describe the problem
I'm new in programming. I have searched on google but there is no result relating to this.
Thanks in advanced

### Source code / logs
/usr/lib/gcc/x86_64-redhat-linux/7/../../../../include/c++/7/type_traits:1544:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'
     struct is_convertible
        ^~~~~~~~~~~~~~
/usr/lib/gcc/x86_64-redhat-linux/7/../../../../include/c++/7/tuple:504:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
ERROR: /home/khanh/tensorflow/tensorflow/contrib/image/BUILD:115:1: output 'tensorflow/contrib/image/_objs/python/ops/_distort_image_ops_gpu/tensorflow/contrib/image/kernels/adjust_hsv_in_yiq_op_gpu.cu.pic.o' was not created
ERROR: /home/khanh/tensorflow/tensorflow/contrib/image/BUILD:115:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 589.364s, Critical Path: 50.07s
INFO: 2171 processes, local.
FAILED: Build did NOT complete successfully

More info:
I have compiled Tensorflow 1.6.1 successfully. The difference between 2 versions is Tensorflow 1.7 forwards need Nvidia NCCL that I haven't installed on my PC."
19669,No module named 'sparse_dot_topn,"Hello all, trying to install the ""sparse_dot_topn"" package in python using pip install sparse_dot_topn in my mac terminal but failing.How else can i go about this?"
19668,tf.layers.conv2d_transpose does not accept output_shape,I believe there is no reason why using layer interface user should not be able to specify this. Output shape is not obvious for some cases (as stated here: https://github.com/tensorflow/tensorflow/issues/2118) and without accepting output_shape argument one cannot match desired output. Potential use case is trying to build autoencoder for 2d images in form of (conv1->conv2->conv3->deconv1->deconv2->deconv3). With stride >1 there is no way for doing this with layers interface right now.
19667,Messed up dimentions expanding within transform calling,"https://github.com/tensorflow/tensorflow/blob/25b2f01d5fc9ae500bc5969291ba90e48b25cceb/tensorflow/contrib/image/python/ops/image_ops.py#L252

If image has no channels, we have to add one in the last dim
So the code have to be:
images = image_or_images[ :, :, :, None]"
19664,Speech command pretrained model in tensorflow lite is slow,"
System information
Have I written custom code: Yes
OS Platform and Distribution: Linux Ubuntu 16.04
TensorFlow installed from (source): tensorflow v1.8.0
Python version: 2.7
Bazel version (if compiling from source): 0.11.1
GCC/Compiler version (if compiling from source): 5.4
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: see code below



I am trying to use pretrained model (conv_actions_frozen.tflite from ""https://storage.googleapis.com/download.tensorflow.org/models/tflite/conv_actions_tflite.zip"") 
to inference on my ubuntu desktop , it took around 100ms for invoking. 
But in tensorflow, using the same pretrained model(conv_action_frozen.pb) label_wav.py to inference just around 80ms. 
I would expect the inference time on tflite should be faster than tensorflow and i found it spend most time on Depthwise_conv2 operator. 
Is there any reason or clue can check this?
Thanks.



"
19659,aceholders,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19658,feature request:TFLite seem don't support conv3d yet?,"### System information
irrelevant

### Describe the problem
I try to convert a model that contains conv3d op into tflite model using TOCO.But it seems that TFLite limits input shape dim to less than 4.That is to say,it can only support at most conv2d?I hope that TFLite should support conv3d someday~

### Source code / logs
F tensorflow/contrib/lite/toco/import_tensorflow.cc:182] Check failed: input_shape.dim_size() <= 4 (5 vs. 4)

"
19657,"Crash when saving model: ""tensorflow.GraphDef was modified concurrently during serialization""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.4 (also Linux Ubuntu)
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A 
- **GPU model and memory**: N/A (problem on CPU and GPU)
- **Exact command to reproduce**: saver.save(sess,fname)

### Describe the problem
TF consistently crashes when saving a model after loading datasets of a certain size into memory and creating iterators for them.  This occurs both on macOS and on Linux.

Some additional information:
- If I make the iterators initializable instead of one-shot, there is no crash.
- If I only make one iterator (not two), there is no crash
- If I reduce the size of the dataset, there is no crash

### Source code / logs
The most minimal example I could come up with:
```
import numpy as np
import tensorflow as tf

### The following two lines are necsesary to cause the crash
### Also, reduce the size to eliminate the crash
data1 = tf.data.Dataset.from_tensor_slices(np.ones([20000000,2,2]))
iter1 = data1.make_one_shot_iterator()

data2 = tf.data.Dataset.from_tensor_slices(np.ones([20000000,2,2]))
iter2 = data2.make_one_shot_iterator()
feat2 = iter2.get_next()
out = tf.layers.dense(inputs=feat2, units=10)

saver = tf.train.Saver()
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    # Crash here
    saver.save(sess=sess,save_path='/tmp/crash-example')
```

This causes the following crash:
```
[libprotobuf FATAL external/protobuf_archive/src/google/protobuf/message_lite.cc:68] CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): tensorflow.GraphDef was modified concurrently during serialization.
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: (byte_size_before_serialization) == (byte_size_after_serialization): tensorflow.GraphDef was modified concurrently during serialization.
Aborted (core dumped)
```"
19648,kernel_constraint=maxnorm(3) raises error with eager execution,"I posted this already on Stackoverflow and it was suggested this is indeed a bug:
https://stackoverflow.com/questions/50594025/how-to-include-kernel-constraints-in-tensorflow-eager-conv2d

I'm having trouble using `kernel_constraint=maxnorm(3)` within keras when using Tensorflow eager execution. This works fine when not using the standard `Sequential` method outside of eager execution, but seems to fail with an error here (it seems to be because of a multiplication step `*=` which I don't know if there is a substitute for in this context). 

**Question:** Is there a workaround to incorporate the maximum $L^2$ norm functionality within the Eager Tensorflow execution framework? Below are more details.

Here is how I activate `tensorflow` eager. 



    from __future__ import absolute_import, division, print_function
    import tensorflow as tf
    import tensorflow.contrib.eager as tfe
    from keras.datasets import cifar10
    tf.enable_eager_execution()



The following code works fine


**Works:**


    class ObjectDet(tf.keras.Model):
        def __init__(self):
            super(ObjectDet,self).__init__()
            self.layer1= tf.keras.layers.Conv2D(32, (3, 3), input_shape=(32,32,3), padding='same', activation='relu')
            self.layer2=tf.keras.layers.Dropout(0.2)
            self.layer3=tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')
            self.layer4=tf.keras.layers.MaxPooling2D(pool_size=(2,2))
            self.layer5=tf.keras.layers.Flatten()
            self.layer6=tf.keras.layers.Dense(512, activation='relu')
            self.layer7=tf.keras.layers.Dropout(0.1)
            self.layer8=tf.keras.layers.Dense(10, activation='softmax')

        def call(self, input):
            """"""Run the model.""""""
            result = self.layer1(input)
            result = self.layer2(result)
            result = self.layer3(result)
            result = self.layer4(result)
            result = self.layer5(result)
            result = self.layer6(result)
            result = self.layer7(result)
            result = self.layer8(result)
        
            return result



    def loss(model, x, y):
      prediction = model(x)
      return cross_entropy(prediction,y)
    
    def grad(model, inputs, targets):
      with tf.GradientTape() as tape:
        loss_value = loss(model, inputs, targets)
      return tape.gradient(loss_value, model.variables)
    
    
    x, y = iter(train_ds).next()
    print(""Initial loss: {:.3f}"".format(loss(model, x, y)))
    
    # Training loop
    for (i, (x, y)) in enumerate(train_ds):
      # Calculate derivatives of the input function with respect to its parameters.
      grads = grad(model, x, y)
      # Apply the gradient to the model
      
      optimizer.apply_gradients(zip(grads, model.variables),
                                global_step=tf.train.get_or_create_global_step())
      if i % 200 == 0:
        pass
        print(""Loss at step {:04d}: {:.3f}"".format(i, loss(model, x, y)))



**Does not work:**

If I replace 

    self.layer1= tf.keras.layers.Conv2D(32, (3, 3), input_shape=(32,32,3), padding='same', activation='relu')

with

    self.layer1= tf.keras.layers.Conv2D(32, (3, 3), input_shape=(32,32,3), padding='same', activation='relu',kernel_constraint=maxnorm(3))

I obtain the error:


    RuntimeErrorTraceback (most recent call last)
    <ipython-input-74-629273c4a534> in <module>()
         19 
         20   optimizer.apply_gradients(zip(grads, model.variables),
    ---> 21                             global_step=tf.train.get_or_create_global_step())
         22   if i % 200 == 0:
         23     pass
    
    /home/dgoldma1/.local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc in apply_gradients(self, grads_and_vars, global_step, name)
        615           scope_name = var.op.name
        616         with ops.name_scope(""update_"" + scope_name), ops.colocate_with(var):
    --> 617           update_ops.append(processor.update_op(self, grad))
        618       if global_step is None:
        619         apply_updates = self._finish(update_ops, name)
    
    /home/dgoldma1/.local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.pyc in update_op(self, optimizer, g)
        166     if self._v.constraint is not None:
        167       with ops.control_dependencies([update_op]):
    --> 168         return self._v.assign(self._v.constraint(self._v))
        169     else:
        170       return update_op
    
    /home/dgoldma1/.local/lib/python2.7/site-packages/keras/constraints.pyc in __call__(self, w)
         51         norms = K.sqrt(K.sum(K.square(w), axis=self.axis, keepdims=True))
         52         desired = K.clip(norms, 0, self.max_value)
    ---> 53         w *= (desired / (K.epsilon() + norms))
         54         return w
         55 
    
    /home/dgoldma1/.local/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.pyc in __imul__(self, unused_other)
        931 
        932   def __imul__(self, unused_other):
    --> 933     raise RuntimeError(""Variable *= value not supported. Use ""
        934                        ""variable.assign_mul(value) to modify the variable ""
        935                        ""value and variable = variable * value to get a new ""
    
    RuntimeError: Variable *= value not supported. Use variable.assign_mul(value) to modify the variable value and variable = variable * value to get a new Tensor object.


Thanks!

"
19647,"TensorFlowInferenceInterface( )  in TensorFlowInferenceInterface cannot be applied to (android.content.res.AssetManager, java","package com.technicalshow.siraj.models;


//Provides access to an application's raw asset files;
import android.content.res.AssetManager;
//Reads text from a character-input stream, buffering characters so as to provide for the efficient reading of characters, arrays, and lines.
import java.io.BufferedReader;
//for erros
import java.io.IOException;
//An InputStreamReader is a bridge from byte streams to character streams:
// //It reads bytes and decodes them into characters using a specified charset.
// //The charset that it uses may be specified by name or may be given explicitly, or the platform's default charset may be accepted.
import java.io.InputStreamReader;
import java.util.ArrayList;
import java.util.List;
import java.lang.String;
//made by google, used as the window between android and tensorflow native C++
import org.tensorflow.contrib.android.TensorFlowInferenceInterface;

/**
 * Changed from https://github.com/MindorksOpenSource/AndroidTensorFlowMNISTExample/blob/master
 * /app/src/main/java/com/mindorks/tensorflowexample/TensorFlowImageClassifier.java
 * Created by marianne-linhares on 20/04/17.
 */

//lets create this classifer
public class TensorFlowClassifier implements Classifier {

    // Only returns if at least this confidence
    //must be a classification percetnage greater than this
    private static final float THRESHOLD = 0.1f;

    private TensorFlowInferenceInterface tfHelper;

    private String name;
    private String inputName;
    private String outputName;
    private int inputSize;
    private boolean feedKeepProb;

    private List<String> labels;
    private float[] output;
    private String[] outputNames;

    //given a saved drawn model, lets read all the classification labels that are
    //stored and write them to our in memory labels list
    private static List<String> readLabels(AssetManager am, String fileName) throws IOException {
        BufferedReader br = new BufferedReader(new InputStreamReader(am.open(fileName)));

        String line;
        List<String> labels = new ArrayList<>();
        while ((line = br.readLine()) != null) {
            labels.add(line);
        }

        br.close();
        return labels;
    }

   //given a model, its label file, and its metadata
    //fill out a classifier object with all the necessary
    //metadata including output prediction
    public static TensorFlowClassifier create(AssetManager assetManager, String name,
            String modelPath, String labelFile, int inputSize, String inputName, String outputName,
            boolean feedKeepProb) throws IOException {
        //intialize a classifier
        TensorFlowClassifier c = new TensorFlowClassifier();

        //store its name, input and output labels
        c.name = name;

        c.inputName = inputName;
        c.outputName = outputName;

        //read labels for label file
        c.labels = readLabels(assetManager, labelFile);

        //set its model path and where the raw asset files are
        c.tfHelper = new TensorFlowInferenceInterface( assetManager, modelPath);
        int numClasses = 10;

        //how big is the input?
        c.inputSize = inputSize;

        // Pre-allocate buffer.
        c.outputNames = new String[] { outputName };

        c.outputName = outputName;
        c.output = new float[numClasses];

        c.feedKeepProb = feedKeepProb;

        return c;
    }

    @Override
    public String name() {
        return name;
    }

    @Override
    public Classification recognize(final float[] pixels) {

        //using the interface
        //give it the input name, raw pixels from the drawing,
        //input size
        tfHelper.addFeed(inputName, pixels, 1, inputSize, inputSize, 1);

        //probabilities
        if (feedKeepProb) {
            tfHelper.addFeed(""keep_prob"", new float[] { 1 });
        }
        //get the possible outputs
        tfHelper.run(outputNames);

        //get the output
        tfHelper.fetch(outputName, output);

        // Find the best classification
        //for each output prediction
        //if its above the threshold for accuracy we predefined
        //write it out to the view
        Classification ans = new Classification();
        for (int i = 0; i < output.length; ++i) {
            System.out.println(output[i]);
            System.out.println(labels.get(i));
            if (output[i] > THRESHOLD && output[i] > ans.getConf()) {
                ans.update(output[i], labels.get(i));
            }
        }

        return ans;
    }
}
"
19646,macOS build fail on __shared__ variable,"- **Code changes**:
Fixes from https://github.com/tensorflow/tensorflow/issues/17067#issuecomment-366544970 .
Fix from https://github.com/tensorflow/tensorflow/issues/18564#issue-314731167
Fix from https://github.com/tensorflow/tensorflow/issues/14174#issuecomment-342163130

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS High Sierra 10.13.4 (17E202)
XCode 7.2.1, XCode 8.2

- **TensorFlow installed from (source or binary)**:
During compilation from sources

- **TensorFlow version (use command below)**:
1.6.0, 1.7.1

- **Python version**: 
3.6.5

- **Bazel version (if compiling from source)**:
Build label: 0.13.1-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed May 23 16:57:59 2018 (1527094679)
Build timestamp: 1527094679
Build timestamp as int: 1527094679

- **GCC/Compiler version (if compiling from source)**:
XCode 7.2.1
Apple LLVM version 7.0.2 (clang-700.1.81)
Target: x86_64-apple-darwin17.5.0
Thread model: posix

- **CUDA/cuDNN version**:
CUDA 9.2
cudNN 7.1.4

- **GPU model and memory**:
GeForce 1080Ti 11Gb

- **Exact command to reproduce**:
`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem
During compilation from sources, an errorr occurs about __shared__ variable expression used. 

### Source code / logs
`INFO: From Compiling tensorflow/core/kernels/reduction_ops_gpu_complex64.cu.cc:
./tensorflow/core/lib/core/status.h(32): warning: attribute ""warn_unused_result"" does not apply here

external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Meta.h(187): warning: missing return statement at end of non-void function ""Eigen::internal::device::numeric_limits<T>::quiet_NaN [with T=std::__1::complex<float>]""
          detected during:
            instantiation of ""T Eigen::internal::device::numeric_limits<T>::quiet_NaN() [with T=std::__1::complex<float>]"" 
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/NumTraits.h(180): here
            instantiation of ""T Eigen::GenericNumTraits<T>::quiet_NaN() [with T=std::__1::complex<float>]"" 
./tensorflow/core/kernels/reduction_ops.h(59): here

external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/NumTraits.h(180): warning: calling a __host__ function from a __host__ __device__ function is not allowed
          detected during instantiation of ""T Eigen::GenericNumTraits<T>::quiet_NaN() [with T=std::__1::complex<float>]"" 
./tensorflow/core/kernels/reduction_ops.h(59): here

external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/Meta.h(187): warning: missing return statement at end of non-void function ""Eigen::internal::device::numeric_limits<T>::quiet_NaN [with T=std::__1::complex<double>]""
          detected during:
            instantiation of ""T Eigen::internal::device::numeric_limits<T>::quiet_NaN() [with T=std::__1::complex<double>]"" 
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/NumTraits.h(180): here
            instantiation of ""T Eigen::GenericNumTraits<T>::quiet_NaN() [with T=std::__1::complex<double>]"" 
./tensorflow/core/kernels/reduction_ops.h(60): here

external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/NumTraits.h(180): warning: calling a __host__ function from a __host__ __device__ function is not allowed
          detected during instantiation of ""T Eigen::GenericNumTraits<T>::quiet_NaN() [with T=std::__1::complex<double>]"" 
./tensorflow/core/kernels/reduction_ops.h(60): here

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(271): error: initializer not allowed for __shared__ variable 

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(319): error: initializer not allowed for __shared__ variable 

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(271): error: initializer not allowed for __shared__ variable 

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(319): error: initializer not allowed for __shared__ variable 

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(271): error: initializer not allowed for __shared__ variable 

./tensorflow/core/kernels/reduction_gpu_kernels.cu.h(319): error: initializer not allowed for __shared__ variable 

external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/NumTraits.h(180): warning: calling a __host__ function(""Eigen::internal::device::numeric_limits< ::std::__1::complex<float> > ::quiet_NaN"") from a __host__ __device__ function(""Eigen::GenericNumTraits< ::std::__1::complex<float> > ::quiet_NaN"") is not allowed

6 errors detected in the compilation of ""/var/folders/by/bnpbnnbj2m180m_vjq9l97n40000gn/T//tmpxft_00009e05_00000000-6_reduction_ops_gpu_complex64.cu.cpp1.ii"".
ERROR: tensorflow/tensorflow/core/kernels/BUILD:2796:1: output 'tensorflow/core/kernels/_objs/reduction_ops_gpu/tensorflow/core/kernels/reduction_ops_gpu_complex64.cu.pic.o' was not created
ERROR: tensorflow/tensorflow/core/kernels/BUILD:2796:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 486.544s, Critical Path: 212.55s
INFO: 595 processes, local.
FAILED: Build did NOT complete successfully`
"
19645,Feature: Exiting current variable_scope (parent scope),"Is it possible to exit a current variable_scope?

I know it is possible to get to the root `name_scope` with something like `tf.name_scope(None)` but I don't seem to find a way to do that for `tf.variable_scope`.
This feature is interesting to me because I would like to share certain variables across parts of my model without passing around the `variable_scope` object. I would like to just configure a name for my shared `variable_scope` and then wherever I need to use that shared scope call
`with tf.variable_scope(shared, reuse=tf.AUTO_REUSE)` without having to care which scope I am currently in.

I look through all the issues and stackoverflow but I have not found anything in that direction."
19644,Feature Request: 1 bit quantization in FakeQuantWithMinMaxVars ,"Feature Request: 1 bit quantization in FakeQuantWithMinMaxVars 

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8
- **Python version**:  3.6
- **Bazel version (if compiling from source)**: Does not apply
- **GCC/Compiler version (if compiling from source)**: Does not apply
- **CUDA/cuDNN version**: Does not apply
- **GPU model and memory**: Does not apply
- **Exact command to reproduce**: Does not apply

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Binary NN are raising the attention of researchers/developers.
Right now `fake_quant `operations do support quantization in the range 2-16 bits. It would be really usefull extending this (relying on FakeQuantWithMinMaxVars) to 1b quantization.
If so, `Quantize` methods (such as  `tf.contrib.quantize.create_eval_graph`) should be updated to include this new quantization limit (now  `tf.contrib.quantize.experimental_create_eval_graph` supports bit selection for quantization).

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19643,keras.layers.BatchNormalization update_ops not added,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.8.0-1660-ga543d94
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: 4.9.3
- **CUDA/cuDNN version**: 9.1 / 7.1
- **GPU model and memory**: GeForce GTX 1070 , 8119MiB
- **Exact command to reproduce**: See source code below

### Describe the problem
`tf.keras.layers.BatchNormalization()` does not add any operations to `UPDATE_OPS` under certain version constraints.

### Source code / logs
```python
#!/usr/bin/python
import tensorflow as tf

graph = tf.get_default_graph()
tf.keras.backend.set_learning_phase(True)
features = tf.zeros(shape=(3, 10), dtype=tf.float32)
normed = tf.keras.layers.BatchNormalization()(features)

update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
print('n_ops:        %d' % len(graph.get_operations()))
print('n_update_ops: %d' % len(update_ops))
```
Output using v1.8.0-1660-ga543d94, cuda 9.1, cudnn 7.1, installed from source (other details as above):
```
n_ops:        51
n_update_ops: 0
```
Output using v1.8.0-0-g93bc2e2072, cuda 9.0, cudnn 7.0, pip installed
```
n_ops:        41
n_update_ops: 2
```"
19642,Linking issues with tensorflow-lite.a with android-studio and CMake.,"### System information
- **Have I written custom code:**
- **OS Platform and Distribution ( )**:
Linux Ubuntu 16.04 / Android
- **TensorFlow installed from:**
 source

- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.13
- **GCC/Compiler version (if compiling from source)**:
NDK16b 

### Describe the problem
I am having problems linking libtensorflow-lite.a with CMake and Android Studio. 
It seems that the tf-lite library is not compatible with my architecture, but I do not know why this is happening. 
I have succesfully compiled the libtensorflow-lite.a library, following these steps: 

```
export NDK_ROOT=<your_ndk>
tensorflow/contrib/lite/download_dependencies.sh
make -f tensorflow/contrib/lite/Makefile TARGET=ANDROID ANDROID_ARCH=armeabi-v7a
```
The problem comes when I try to link the library with CMake. it seems that even I compiled the armeabi-v7a the linker, I have these errors: 

>  incompatible target

>  the vtable symbol may be undefined because the class is missing its key function

### Source code / logs
This my error log: 
```
Build command failed.
Error while executing process /home/VICOMTECH/uelordi/Android/Sdk/cmake/3.6.4111459/bin/cmake with arguments {--build /home/VICOMTECH/uelordi/projects/SwitchTrackingEngine/kanvas_tracker/kt/tools/Deep-learning-tools/android/tfliteTest/app/.externalNativeBuild/cmake/debug/armeabi-v7a --target native-lib}
[1/1] Linking CXX shared library ../../../../build/intermediates/cmake/debug/obj/armeabi-v7a/libnative-lib.so
FAILED: : && /home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++  --target=armv7-none-linux-androideabi --gcc-toolchain=/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 --sysroot=/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/sysroot -fPIC -isystem /home/VICOMTECH/uelordi/SDK/android-ndk-r16b/sysroot/usr/include/arm-linux-androideabi -D__ANDROID_API__=21 -g -DANDROID -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -march=armv7-a -mfloat-abi=softfp -mfpu=vfpv3-d16 -fno-integrated-as -mthumb -Wa,--noexecstack -Wformat -Werror=format-security  -std=c++11 -O0 -fno-limit-debug-info  -Wl,--exclude-libs,libgcc.a -Wl,--exclude-libs,libatomic.a --sysroot /home/VICOMTECH/uelordi/SDK/android-ndk-r16b/platforms/android-21/arch-arm -Wl,--build-id -Wl,--warn-shared-textrel -Wl,--fatal-warnings -Wl,--fix-cortex-a8 -Wl,--no-undefined -Wl,-z,noexecstack -Qunused-arguments -Wl,-z,relro -Wl,-z,now -shared -Wl,-soname,libnative-lib.so -o ../../../../build/intermediates/cmake/debug/obj/armeabi-v7a/libnative-lib.so CMakeFiles/native-lib.dir/src/main/cpp/native-lib.cpp.o  /home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a /home/VICOMTECH/uelordi/SDK/android-ndk-r16b/platforms/android-21/arch-arm/usr/lib/liblog.so -latomic -lm ""/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/libgnustl_static.a"" && :
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: /home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a(error_reporter.o): incompatible target
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: /home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a(interpreter.o): incompatible target
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: /home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a(register.o): incompatible target
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: /home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a(model.o): incompatible target
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: /home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/gen/lib/libtensorflow-lite.a(op_resolver.o): incompatible target
/home/VICOMTECH/uelordi/projects/SwitchTrackingEngine/kanvas_tracker/kt/tools/Deep-learning-tools/android/tfliteTest/app/src/main/cpp/native-lib.cpp:23: error: undefined reference to 'tflite::DefaultErrorReporter()'
/home/VICOMTECH/uelordi/projects/SwitchTrackingEngine/kanvas_tracker/kt/tools/Deep-learning-tools/android/tfliteTest/app/src/main/cpp/native-lib.cpp:23: error: undefined reference to 'tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'
/home/VICOMTECH/uelordi/projects/SwitchTrackingEngine/kanvas_tracker/kt/tools/Deep-learning-tools/android/tfliteTest/app/src/main/cpp/native-lib.cpp:27: error: undefined reference to 'tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'
/home/VICOMTECH/uelordi/projects/SwitchTrackingEngine/kanvas_tracker/kt/tools/Deep-learning-tools/android/tfliteTest/app/src/main/cpp/native-lib.cpp:28: error: undefined reference to 'tflite::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)'
/home/VICOMTECH/uelordi/projects/SwitchTrackingEngine/kanvas_tracker/kt/tools/Deep-learning-tools/android/tfliteTest/app/src/main/cpp/native-lib.cpp:30: error: undefined reference to 'tflite::InterpreterBuilder::operator()(std::unique_ptr<tflite::Interpreter, std::default_delete<tflite::Interpreter> >*)'
/home/VICOMTECH/uelordi/SDK/tensorflow/tensorflow/contrib/lite/op_resolver.h:70: error: undefined reference to 'vtable for tflite::MutableOpResolver'
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64/lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: the vtable symbol may be undefined because the class is missing its key function
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/sources/cxx-stl/gnu-libstdc++/4.9/include/bits/unique_ptr.h:76: error: undefined reference to 'tflite::FlatBufferModel::~FlatBufferModel()'
/home/VICOMTECH/uelordi/SDK/android-ndk-r16b/sources/cxx-stl/gnu-libstdc++/4.9/include/bits/unique_ptr.h:76: error: undefined reference to 'tflite::Interpreter::~Interpreter()'
clang++: error: linker command failed with exit code 1 (use -v to see invocation)
ninja: build stopped: subcommand failed.
```


My CmakeScript: 
```
# For more information about using CMake with Android Studio, read the
# documentation: https://d.android.com/studio/projects/add-native-code.html

# Sets the minimum version of CMake required to build the native library.
`
SET(PROJECT_NAME  native-lib)
cmake_minimum_required(VERSION 3.4.1)
set(PREBUILT_DIR ${TENSORFLOW_ROOT_DIR}/tensorflow/contrib/lite)

add_library(lib_tflite STATIC IMPORTED )
set_target_properties(lib_tflite PROPERTIES IMPORTED_LOCATION
${PREBUILT_DIR}/gen/lib/libtensorflow-lite.a)

INCLUDE_DIRECTORIES(${TENSORFLOW_ROOT_DIR}
    ${PREBUILT_DIR}/downloads/flatbuffers/include)

add_library( # Sets the name of the library.
            ${PROJECT_NAME}
             SHARED
             src/main/cpp/native-lib.cpp )

find_library( log-lib
              log )


target_link_libraries( # Specifies the target library.
                       ${PROJECT_NAME}
                       lib_tflite
                       ${log-lib} )
```



My build_gradle (I have only copy the relevant part)
```
android {
    compileSdkVersion 27
    defaultConfig {
        applicationId ""com.androidapp.kt.kanvas.tflitetest""
        minSdkVersion 21
        targetSdkVersion 27
        versionCode 1
        versionName ""1.0""
        testInstrumentationRunner ""android.support.test.runner.AndroidJUnitRunner""
        externalNativeBuild {
            cmake {
                cppFlags ""-std=c++11""
                arguments ""-DTENSORFLOW_ROOT_DIR="" + getTensorflowDir().toString()
                abiFilters  'armeabi-v7a' 
            }
        }
    }
```

"
19641,tflite::Interpreter::Invoke() changes input data if call multiple times,"OS Platform and Distribution: Android Native C, Android API 26
TensorFlow installed from: Compiled from the official github master branch
TensorFlow version: Master
Bazel versio: 0.13.0-homebrew
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A
Code below:

```
int input = interpreter->inputs()[0];
float* input_to_model = interpreter->typed_tensor<float>(input);
//put data into input_to_model here

for (int i = 0; i < loop_count; i++) {
        if (interpreter->Invoke() != kTfLiteOk) {
            __android_log_print(ANDROID_LOG_INFO, ""Invoke"", ""ailed to invoke tflite!"");
        }
}
```
input_to_model content will be changed when Invoke() is called. Thus only the first time the output is correct, the second to tenth times results are wrong.
"
19640,Tensorflow Serving not using multi GPU/CUDA cores ,"I'm using an AWS g3.8xlarge instance which has 2 GPUs.

TF serving is able to detect both GPUs and initialise them but while running the model it only uses 1 GPU to the maximum.

We are on version 1.7, even though the client sends upto 32 requests in parallel, the model server only uses the first GPU 
![40657873-faca0f68-6366-11e8-963c-3d5ba1db4e2c](https://user-images.githubusercontent.com/6717323/40708575-66e52d36-6411-11e8-9e01-d95a0861827d.jpg)

06_09_21"
19639,Core ML in android,is there any way to use Ios coreML file in android for object detaction?
19632,Disable tensors with unknown rank,"I am a Tensorflow novice. I found that a lot of headache was caused by tensors of unknown rank. This sometimes caused runtime errors and sometimes errors at graph building time. I now understand why all of this happened but at the time it caused a lot of grief. I have seen the Tensorflow developers speak about tensors of unknown rank as something to be avoided.

I propose adding a feature to Tensorflow to disable tensors with unknown rank. Often, when that happens it signals a coding error. That way I would immediately notice when this happens with some intermediate computation.

This feature could be either to immediately throw when this happens or it could be a linter that can be run on a graph to warn about suspicious patterns.

------------------------

### System information
- **Experiences from custom code**
- **Windows TF 1.8**
- **Python 3.5**
"
19631,Just another missing module error,"After seeing some YT videos about AI programming in Python using TensorFlow, I thought that this shouldn't be too hard. Although I got an error. I don't really understand it.
There's told everywhere that I should install some Nvidia-related DLLs, but I neither have Nvidia GPU nor tensorflow-gpu.
The error is listed [here](https://pastebin.com/Ft1qDyHD).
Please, explain me the error and preferably give the step by step solution for this issue.
Thanks for any help given.
EDIT
Also, here's more info:
Have I written custom code: No
OS Platform and Distribution: Windows 10 Home
TensorFlow installed from: tensorflow.org
TensorFlow version: I don't know
Bazel version: I don't know
CUDA/cuDNN version: I don't know, probably don't have it
GPU model and memory: AMD Mobility Radeon 5000 Series, 1 GB VRAM, 4 GB RAM
Exact command to reproduce: import tensorflow as tf

Also, after PC restart it even can't find module named ""tensorflow"". What's going on? Help please"
19630,"Possible Error in ""TensorFlow For Poets"" Guide","Small, possible error found in https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#4:
""The first figure shows accuracy (x-axis) as a function of training progress (y-axis):""

Should be corrected to:
""The first figure shows accuracy (y-axis) as a function of training progress (x-axis):""

Or you can change the ""accuracy_1"" graph below it."
19629,"Error in ""TensorFlow for Poets","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19628,Feature Request: Add normalizer_fn to sequence_numeric_column.,"### System information
- **Have I written custom code**: no
- **OS Platform and Distribution**: macOS Sierra 10.12.6
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version**: N/A
- **GCC/Compiler version**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
Currently, `sequence_numeric_column` does not support a `normalizer_fn`, wondering if this could be added in like in `numeric_column`."
19627,tf.image.resize_bilinear vs cv2.resize,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

Not to compare with opencv, but ... when the scale factor is larger, the unchanged part at right-bottom is larger. I found this a little bothersome. Set `align_corners=True` is not always reasonable because the four corners are not always supposed to be fixed in the corner.

So is there anyway to make it a little more ""symmetry""?

Code to reproduce:
```
import tensorflow as tf
import numpy as np
import cv2
np.set_printoptions(precision=3)
resize_shape = (10, 10)

a = np.ones((1, 2, 2, 1), dtype=np.float32)
a[0, 0, 0, 0] = 5.0
a[0, 1, 1, 0] = 5.0

b = tf.constant(a, dtype=tf.float32)
c = tf.image.resize_bilinear(b, resize_shape)

with tf.Session() as sess:
    np_c = sess.run(c)
    print np_c[0, :, :, 0]

print cv2.resize(a[0], resize_shape, interpolation=cv2.INTER_LINEAR)
```
Obtained results:
```
# tf.image.resize_bilinear
[[ 5.    4.2   3.4   2.6   1.8   1.    1.    1.    1.    1.  ]
 [ 4.2   3.72  3.24  2.76  2.28  1.8   1.8   1.8   1.8   1.8 ]
 [ 3.4   3.24  3.08  2.92  2.76  2.6   2.6   2.6   2.6   2.6 ]
 [ 2.6   2.76  2.92  3.08  3.24  3.4   3.4   3.4   3.4   3.4 ]
 [ 1.8   2.28  2.76  3.24  3.72  4.2   4.2   4.2   4.2   4.2 ]
 [ 1.    1.8   2.6   3.4   4.2   5.    5.    5.    5.    5.  ]
 [ 1.    1.8   2.6   3.4   4.2   5.    5.    5.    5.    5.  ]
 [ 1.    1.8   2.6   3.4   4.2   5.    5.    5.    5.    5.  ]
 [ 1.    1.8   2.6   3.4   4.2   5.    5.    5.    5.    5.  ]
 [ 1.    1.8   2.6   3.4   4.2   5.    5.    5.    5.    5.  ]]
# cv2.resize
[[ 5.    5.    5.    4.2   3.4   2.6   1.8   1.    1.    1.  ]
 [ 5.    5.    5.    4.2   3.4   2.6   1.8   1.    1.    1.  ]
 [ 5.    5.    5.    4.2   3.4   2.6   1.8   1.    1.    1.  ]
 [ 4.2   4.2   4.2   3.72  3.24  2.76  2.28  1.8   1.8   1.8 ]
 [ 3.4   3.4   3.4   3.24  3.08  2.92  2.76  2.6   2.6   2.6 ]
 [ 2.6   2.6   2.6   2.76  2.92  3.08  3.24  3.4   3.4   3.4 ]
 [ 1.8   1.8   1.8   2.28  2.76  3.24  3.72  4.2   4.2   4.2 ]
 [ 1.    1.    1.    1.8   2.6   3.4   4.2   5.    5.    5.  ]
 [ 1.    1.    1.    1.8   2.6   3.4   4.2   5.    5.    5.  ]
 [ 1.    1.    1.    1.8   2.6   3.4   4.2   5.    5.    5.  ]]
```


"
19626,FailedPreconditionError: Table already initialized when use Feature Column in Eager mode,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Latest Mac OS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see below

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

```python
---------------------------------------------------------------------------
FailedPreconditionError                   Traceback (most recent call last)
<ipython-input-2-443ffe416ebf> in <module>()
      7 
      8 features = df.to_dict('series')
----> 9 input_layer = tf.feature_column.input_layer(features, columns)

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in input_layer(features, feature_columns, weight_collections, trainable, cols_to_vars)
    275   """"""
    276   return _internal_input_layer(features, feature_columns, weight_collections,
--> 277                                trainable, cols_to_vars)
    278 
    279 

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in _internal_input_layer(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)
    200             builder,
    201             weight_collections=weight_collections,
--> 202             trainable=trainable)
    203         num_elements = column._variable_shape.num_elements()  # pylint: disable=protected-access
    204         batch_size = array_ops.shape(tensor)[0]

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in _get_dense_tensor(***failed resolving arguments***)
   3300     # Feature has been already transformed. Return the intermediate
   3301     # representation created by _transform_feature.
-> 3302     return inputs.get(self)
   3303 
   3304   def _get_sequence_dense_tensor(

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in get(self, key)
   2098     column = key
   2099     logging.debug('Transforming feature_column %s.', column)
-> 2100     transformed = column._transform_feature(self)  # pylint: disable=protected-access
   2101     if transformed is None:
   2102       raise ValueError('Column {} is not supported.'.format(column.name))

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in _transform_feature(self, inputs)
   3229       ValueError: if input rank is not known at graph building time.
   3230     """"""
-> 3231     id_weight_pair = self.categorical_column._get_sparse_tensors(inputs)  # pylint: disable=protected-access
   3232     id_tensor = id_weight_pair.id_tensor
   3233     weight_tensor = id_weight_pair.weight_tensor

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in _get_sparse_tensors(self, inputs, weight_collections, trainable)
   2872   def _get_sparse_tensors(
   2873       self, inputs, weight_collections=None, trainable=None):
-> 2874     return _CategoricalColumn.IdWeightPair(inputs.get(self), None)
   2875 
   2876 

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in get(self, key)
   2098     column = key
   2099     logging.debug('Transforming feature_column %s.', column)
-> 2100     transformed = column._transform_feature(self)  # pylint: disable=protected-access
   2101     if transformed is None:
   2102       raise ValueError('Column {} is not supported.'.format(column.name))

/usr/local/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column.py in _transform_feature(self, inputs)
   2863         num_oov_buckets=self.num_oov_buckets,
   2864         dtype=key_dtype,
-> 2865         name='{}_lookup'.format(self.key)).lookup(input_tensor)
   2866 
   2867   @property

/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py in index_table_from_tensor(vocabulary_list, num_oov_buckets, default_value, hasher_spec, dtype, name)
   1097           name=""table_init"")
   1098       table = HashTable(
-> 1099           init, default_value, shared_name=shared_name, name=hash_table_scope)
   1100     if num_oov_buckets:
   1101       table = IdTableWithHashBuckets(

/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py in __init__(self, initializer, default_value, shared_name, name)
    277           name=scope)
    278 
--> 279       super(HashTable, self).__init__(table_ref, default_value, initializer)
    280 
    281 

/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py in __init__(self, table_ref, default_value, initializer)
    169         default_value, dtype=self._value_dtype)
    170     self._default_value.get_shape().merge_with(tensor_shape.scalar())
--> 171     self._init = initializer.initialize(self)
    172 
    173   @property

/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py in initialize(self, table)
    348                             self._values)) as scope:
    349       init_op = gen_lookup_ops.initialize_table_v2(
--> 350           table.table_ref, self._keys, self._values, name=scope)
    351     ops.add_to_collection(ops.GraphKeys.TABLE_INITIALIZERS, init_op)
    352     return init_op

/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_lookup_ops.py in initialize_table_v2(table_handle, keys, values, name)
    404       else:
    405         message = e.message
--> 406       _six.raise_from(_core._status_to_exception(e.code, message), None)
    407 
    408 

/usr/local/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

FailedPreconditionError: Table already initialized. [Op:InitializeTableV2] name: input_layer/Col2_indicator/Col2_lookup/hash_table/table_init/
```

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python

import pandas as pd
import tensorflow as tf

tf.enable_eager_execution()
df = pd.DataFrame([['A1', 'A2'], ['B1', 'B2'], ['C1', 'C2']], columns=['Col1', 'Col2'])

columns = [
    tf.feature_column.indicator_column(
        tf.feature_column.categorical_column_with_vocabulary_list(col, df[col].unique())) for col in df.columns
]

features = df.to_dict('list')
input_layer = tf.feature_column.input_layer(features, columns)
```"
19625,Raw pointer member variables of tflite::Interpreter are not initialized or released properly.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.13.1
- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)
- **CUDA/cuDNN version**: 9/7
- **GPU model and memory**: K80
- **Exact command to reproduce**:

```
bazel build -c opt --copt=""-D TFLITE_PROFILING_ENABLED"" tensorflow/contrib/lite/tools:benchmark_model
./bazel-bin/tensorflow/contrib/lite/tools/benchmark_model --graph=model.tflite
```
output:
```
Graph: [model.tflite]
Num runs: [50]
Inter-run delay (seconds): [-1.0]
Num threads: [1]
Warmup runs: [1]
Use nnapi : [0]
Initialized session in 0.002312s
Running benchmark for 1 ddditerations: 
Segmentation fault (core dumped)
```

There are two raw pointer member variables within tflite::Interpreter.
- [`profiling::Profiler* profiler_`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/interpreter.h#L576) is not initialized. 
[It may cause segmentation fault](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/profiling/profiler.h#L134) if `profiler_` is initialized with a nonzero value and users don't set it by `tflite::Interpreter::SetProfiler`.

- [`ErrorReporter* error_reporter_`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/interpreter.h#L545)
The default error reporter pointed by `error_reporter_` will not be released.
"
19624,Build issue Linking of rule '//tensorflow/cc:ops/nn_ops_gen_cc' failed (Exit 1),"Hi, 

I've encountered an issue occurred during build tf v1.6.0, the error message is like follows:

    /path/to/tensorflow/tensorflow/cc/BUILD:422:1: Linking of rule '//tensorflow/cc:ops/nn_ops_gen_cc' failed (Exit 1)

Any suggestion would be appreciated! Many thanks! 

### System information
- **OS Platform**: Linux Ubuntu 16.04
- **TensorFlow installed from source**: yes
- **TensorFlow version**: v1.6.0
- **Python version**: 2.7.5
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 7.0.5
- **GPU model and memory**: P100
- **Exact command to reproduce**: `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --action_env=""LD_LIBRARY_PATH=${LD_LIBRARY_PATH}""`"
19623,No module named '_pywrap_tensorflow_internal,">>>import keras
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Download\python3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 985, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 968, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 957, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 938, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Download\python3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""<input>"", line 1, in <module>
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\keras\backend\__init__.py"", line 84, in <module>
    from .tensorflow_backend import *
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\keras\backend\tensorflow_backend.py"", line 6, in <module>
    from tensorflow.python.training import moving_averages
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""D:\Download\python3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 985, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 968, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 957, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 938, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\Program Files\JetBrains\PyCharm 2017.3.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 20, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Snow\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""D:\Download\python3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'
Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/install_sources#common_installation_problems
for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
19622,SIGFPE in Conv2d when kernel size is 0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: via pip
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:N/A

### Describe the problem
When tf.nn.conv2d recives kernel with spatial dims 0, 0 or tf.layers.conv2d kernel_size is 0 tensorflow will silently crash leaving only `Process finished with exit code 136 (interrupted by signal 8: SIGFPE)`
That is super frustrating and prevents searching for errors in model construction code."
19621,[Bug] AdamOptimizer: No Exception on invalid input,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: 4G/Quadro M1000M
- **Exact command to reproduce**: -


### Describe the problem
The graph can be executed with AdamOptimizer, thus the graph input is invalid. In the example an out-of-bound embedding  index is passed. Other tested optimizer (RMSP,Ada) yield: InvalidArgumentError: indices[0,0] = 10 is not in [0, 10)

### Source code / logs
```python
import tensorflow as tf
import numpy as np

def embed_helper(inputs, size, dim, name=None):
    std = np.square(2. / dim)
    test_emb = tf.Variable(tf.random_uniform([size, dim], -std, std), name=name)
    return tf.nn.embedding_lookup(test_emb, inputs)

num_factors = 16
num_embed = 10

graph = tf.Graph()
with graph.as_default():
    x = tf.placeholder(tf.int32, shape=(None, 1))
    x_emb = embed_helper(x, num_embed, num_factors, name=None)
    very_complicated_net = tf.square(tf.subtract(x_emb, tf.constant(3.)))

    # RMSP and the other tested optimizer yield InvalidArgumentError - AdamOptimizer does not
    # -> InvalidArgumentError (see above for traceback): indices[0,0] = 10 is not in [0, 10)
    #opt = tf.train.RMSPropOptimizer(learning_rate=0.01)
    opt = tf.train.AdamOptimizer(learning_rate=0.01)

    graph_step = opt.minimize(very_complicated_net)
    init = tf.global_variables_initializer()

session = tf.Session(config=None, graph=graph)
session.run(init)

# 10 is not in [0,1,..,9]
index_batch_out_of_bound = np.array([10]).reshape(-1, 1)

x_feed_dict = {
    x: index_batch_out_of_bound
}

session.run(graph_step, x_feed_dict)
```
"
19620,Tensorflow Lite NNAPI doesn't work,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Android armeabi-v7a
- **TensorFlow installed from (source or binary)**: no
- **TensorFlow version (use command below)**: no
- **Python version**:  no
- **Bazel version (if compiling from source)**: no
- **GCC/Compiler version (if compiling from source)**: no
- **CUDA/cuDNN version**: no
- **GPU model and memory**: no
- **Exact command to reproduce**: no

### Describe the problem
I build a graph with simple matmul and reshap ops, and compile android apk with nigthly-build `org.tensorflow:tensorflow-lite:0.1.7'`. Then run the app in Android 8.1 devices.
If I `setUseNNAPI(false)`, its' result is rigth. However, when I `setUseNNAPI(true)`, it excute very fast and its result is wrong (it outputs whatever I feed inputs).

Can anyone help me ?"
19619,TensorRT: Large memory consumption on SSD-like graphs [Feature Request/Discussion],"Hi,

`tf.contrib.tensorrt` currently automatically segments a given graph into subgraphs which can be fused into TensorRT nodes. This approach works well with networks having linear topology, e.g., CNN classifiers like VGG or ResNet-N: a single node is created, taking an image batch as input and producing a single tensor with predictions.

The situation with SSD-like networks is less favorable. Such a network has a topology of the form a->b->c->d->e->f, a->a_1, a->a_2, b->b_1, b->b_2, ..., f->f_1, f->f2, where a->b->c->d->e->f is a feature extractor and a_1, a_2, b_1, b_2, ..., f_1, f_2 are branches stemming from the feature extractor and predicting, e.g., classes and exact locations of the objects in the predefined anchor boxes. The `tf.contrib.tensorrt`'s segmentation algorithm on such a graph selects a subgraph consisting of all the feature extractor's nodes, plus maybe parts of the branches (e.g., convolutions computing the logits, but not the argmaxes computing the class ids; TensorRT as of version 3 does not support argmax). As a result, we get a huge operation with lots of outputs (e.g., all logits and all raw location amendments, before argmaxes, reshapes, or NCHW->NHWC transpositions), which all must simultaneously fit in GPU memory at the moment of TensorRT's op's completion.

When the same graph is computed on TensorFlow, this high peak in memory usage can be (and seems to be) avoided: TensorFlow can compute the feature extractor up to a next level, compute the branches, copy the results computed in the branches into host RAM, go to the next level, and so on.

This means, `tf.contrib.tensorrt`-optimized graph can use (and seems to actually use in my experiments) significantly more GPU memory than the original graph, which can lead (and seems to lead in my experiments) to out-of-memory errors.

One workaround that I tried was to add to `tf.contrib.tensorrt.create_inference_graph` a parameter for specifying a list of subgraphs which should be independently segmented into subsubgraphs for fusion into TensorRT nodes. I passed individual levels of the feature extractor plus the branches at this level as such subgraphs. This reduced the memory use by TensorRT by a factor of around two and fixed the out-of-memory errors in my case.

Should such a parameter then maybe added to the mainline `tf.contrib.tensorrt`?
Maybe you have a better idea of avoiding a high GPU memory consumption in SSD-like graphs?
Comments, ideas are welcome.

I guess, I should invite @drpngx, @samikama, @jjsjann123 to the discussion.

In case it matters, my experience comes from the experiments with TensorFlow 1.8, TensorRT-3.0.4 running on Ubuntu 16.04 (AMD64) with GTX 1080 Ti.

Thanks!"
19618,Tensorflow custom Ops on AWS P3 instances exit with CUDA_ERROR_ILLEGAL_ADDRESS,"I am trying to build my own Tensorflow Op on a AWS P3 instance (using NVIDIA's GPU Cloud and nvidia-docker) and I get the following error message:

```
2018-05-29 10:47:38.377439: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
2018-05-29 10:47:38.377513: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1
```

To build the Op, I had to create a coda_config.h, under /usr/local/cuda/, with the following content
```
#ifndef CUDA_CUDA_CONFIG_H_
#define CUDA_CUDA_CONFIG_H_

#define TF_CUDA_CAPABILITIES CudaVersion(""3.0"")

#define TF_CUDA_VERSION ""9.0""
#define TF_CUDNN_VERSION ""7.0.5""

#define TF_CUDA_TOOLKIT_PATH ""/usr/local/cuda-9.0""

#endif  // CUDA_CUDA_CONFIG_H_
```
I also had to make these changes to /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/platform/default/mutex.h

```
#include ""/usr/local/lib/python2.7/dist-packages/tensorflow/include/external/nsync/public/nsync_cv.h"" // <- ""nsync_cv.h""
#include ""/usr/local/lib/python2.7/dist-packages/tensorflow/include/external/nsync/public/nsync_mu.h"" // <- ""nsync_mu.h""
```
I compile my source code files as follows
```
nvcc -std=c++11 -c -o my_op_gpu.cu.o my_op_gpu.cu.cc -I $TF_INC -I /usr/local/ -I /usr/local/lib/python2.7/dist-packages/tensorflow/include/external/nsync/public -I /usr/local/cuda/include/ -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC --expt-relaxed-constexpr

g++ -std=c++11 -shared -D_GLIBCXX_USE_CXX_ABI=0 -o my_op.so my_op.cc my_op_gpu.cu.o -I $TF_INC -I /usr/local/lib/python2.7/dist-packages/tensorflow/include/external/nsync/public -D GOOGLE_CUDA=1 -L$TF_LIB -ltensorflow_framework -fPIC
```

where
```
TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')
TF_LIB=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')
```

Please help."
19617,Model_Average_optimizer Use Problems in got multiple values for keyword argument 'dtype',"I used `Model_Average_optimizer` and some problems occured:<br>
the code is used more likely as `model_average_optimizer_test.py`.<br>
I find this error is occured in `init ModelAverageOptimizer` to create local_step. And this problem is more likely some problems with device_setter.<br>
But I don't know why. Could someone help me?<br>

Have I written custom code: Yes
OS Platform and Distribution: Linux n10-044-067 4.4.0-33.bm.1-amd64 #1 SMP Thu, 22 Jun 2017 11:19:55 +0800 x86_64 GNU/Linux
TensorFlow installed from: Anaconda2.5, pip install tensorflow_gpu
TensorFlow version: 1.8.0
Bazel version: N/A
CUDA/cuDNN version: CUDA-9.0, cuDNN-7.1.2(installed in anaconda2.5 also)
GPU model and memory: GeForce GTX 1080
Exact command to reproduce:

    ~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=0
    ~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=worker --task_id=1
    ~/anaconda2/bin/python test.py --server_hosts=localhost:12222 --worker_hosts=localhost:12223,localhost:12224 --job_name=server --task_id=0

You may notice the errors below is occured when one worker init class `ModelAverageOptimizer`

Traceback (most recent call last):

    File ""/data00/home/wupeihao/ma_test/src/rnnlm.py"", line 112, in tf.app.run()
    File ""/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
    File ""/data00/home/wupeihao/ma_test/src/rnnlm.py"", line 109, in main
    test()
    File ""/data00/home/wupeihao/ma_test/src/rnnlm.py"", line 84, in test
    interval_steps=3)
    File ""/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py"", line 139, in init name=""local_step"")
    File ""/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1317, in get_variable
    constraint=constraint)
    File ""/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1079, in get_variable
    constraint=constraint)
    File ""/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 417, in get_variable
    return custom_getter(**custom_getter_kwargs)
    File ""/data00/home/wupeihao/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/opt/python/training/model_average_optimizer.py"", line 92, in call
    return getter(name, trainable, collections, *args, **kwargs)
    TypeError: _true_getter() got multiple values for keyword argument 'dtype'

The code is below:
    
    import os
    import time
    import json
    import copy
    import numpy as np
    import tensorflow as tf
    from tensorflow.python.framework import ops
    from tensorflow.python.framework import constant_op
    from tensorflow.contrib.opt.python.training import model_average_optimizer
     
    flags = tf.flags
    flags.DEFINE_string(""server_hosts"", """", ""Comma-separated list of hostname:port pairs"")
    flags.DEFINE_string(""worker_hosts"", """", ""Comma-separated list of hostname:port pairs"")
    flags.DEFINE_string(""job_name"", """", ""Either 'server' of 'worker'"")
    flags.DEFINE_integer(""task_id"", 0, ""Task Id for Each workers"")
     
    FLAGS = flags.FLAGS
    tf.logging.set_verbosity(tf.logging.INFO)
     
    def workers_ps_creator(args):
        ps_hosts = args.server_hosts.split("","")
        worker_hosts = args.worker_hosts.split("","")
        num_workers = len(worker_hosts)
     
        cluster = tf.train.ClusterSpec({""ps"": ps_hosts,""worker"": worker_hosts})
        gpu_options = tf.GPUOptions(allocator_type='BFC', allow_growth=True)
        if args.job_name == ""server"":
            server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),
                job_name='ps',
                task_index=args.task_id,
                default_session_config=tf.ConfigProto(gpu_options=gpu_options, device_count={""GPU"":0}),
                protocol=""grpc"")
        elif args.job_name == ""worker"":
            server_def = tf.train.ServerDef(cluster=cluster.as_cluster_def(),
                    job_name=""worker"",
                    task_index=args.task_id,
                    default_session_config = tf.ConfigProto(gpu_options=gpu_options),
                    protocol=""grpc"")
        server = tf.train.Server(server_def)
        return server, cluster, num_workers, gpu_options
     
    def Model(opt):
        if FLAGS.task_id == 0:
            var_0 = tf.get_variable(initializer = 0.0, name = 'v0')
            var_1 = tf.get_variable(initializer = 1.0, name = 'v1')
            grads_0 = constant_op.constant(-1.0)
            grads_1 = constant_op.constant(-1.0)
        else:
            var_0 = tf.get_variable(initializer = 7.0, name = 'v0')
            var_1 = tf.get_variable(initializer = 8.0, name = 'v1')
            grads_0 = constant_op.constant(-2.0)
            grads_1 = constant_op.constant(-2.0)
        train_op = opt.apply_gradients([[grads_0, var_0], [grads_1, var_1]],
                global_step = tf.train.get_or_create_global_step())
        return train_op
     
    def test():
        server, cluster, num_workers, gpu_options = workers_ps_creator(FLAGS)
        if FLAGS.job_name == ""server"":
            server.join()
        elif FLAGS.job_name == ""worker"":
            is_chief = (FLAGS.task_id == 0)
            #Between-graph replication
            worker_device = ""/job:worker/task:%d"" % (FLAGS.task_id)
            ma_custom = model_average_optimizer.ModelAverageCustomGetter(worker_device=worker_device)
            from tensorflow.python.training import device_setter
            with tf.device(
                device_setter.replica_device_setter(
                    cluster=cluster,
                    worker_device=worker_device,
                    ps_device=""/job:ps"")), \
                tf.variable_scope("""", custom_getter=ma_custom):
                #create model
                lr = tf.Variable(1, trainable=False)
                opt = tf.train.GradientDescentOptimizer(lr)
                sync_opt = model_average_optimizer.ModelAverageOptimizer(
                            opt=opt,
                            num_worker=num_workers,
                            ma_custom_getter=ma_custom,
                            is_chief=is_chief,
                            interval_steps=3)
                tf.logging.info('model start')
                train_model = Model(sync_opt)
                tf.logging.info('model end')
                ma_hook = sync_opt.make_session_run_hook()
            sess_config = tf.ConfigProto(gpu_options=gpu_options)
            sess_config.log_device_placement = False
            sess_config.allow_soft_placement = True
      
            all_hooks = [ma_hook]
     
            tf.logging.info('Start Sess')
            with tf.train.MonitoredTrainingSession(master=server.target,
                    is_chief=is_chief,
                    hooks=all_hooks) as sess:
                tf.logging.info(""is chief: %s, len: %s"", is_chief, num_workers)
                for i in range(4):
                    sess.run(train_op)
                    pp1 = sess.run(tf.get_default_graph().get_tensor_by_name('v0:0'))
                    pp2 = sess.run(tf.get_default_graph().get_tensor_by_name('v1:0'))
                    tf.logging.info(""%d %.2f %.2f"" % (FLAGS.task_id, pp1, pp2))
            sv.stop()
            tf.logging.info(""done"")"
19616,[Feature Request] print_tensors_in_checkpoint_file should accept Google Cloud Bucket addresses of the form 'gs://...',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS High Sierra
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
v1.8.0-1660-ga543d94710;  1.9.0-dev20180510
- **Python version**:
3.6.4 
Bazel version:
N/A
CUDA/cuDNN version:
N/A
GPU model and memory:
N/A
Exact command to reproduce:
```python
from tensorflow.python.tools import inspect_checkpoint as chkp
chkp.print_tensors_in_checkpoint_file(""gs://..."",all_tensors=True)
```

### Describe the problem
The function `print_tensors_in_checkpoint_file` does not seem to handle Google Cloud Bucket addresses of the form 'gs://...', but rather gives a ""not found"" error. This does not match the behavior of tf.train.Saver.save() and .restore() 

### Source code / logs
N/A
"
19613,Cannot create initializer for non-floating point type,"I m using tensorflow.contrib.slim for creating my model and google Colaboratory for running my code.
My code was working like a charm with tensorflow 1.7 but when the new version 1.8 was installed in the cloud, I got the following error:

`TypeError                                 Traceback (most recent call last)
/content/drive/Colab/baby_training_model_estimators/train_model.py in <module>()
    100     import logging
    101     logging.getLogger('tensorflow').propagate = False
--> 102     run_train()

/content/drive/Colab/baby_training_model_estimators/train_model.py in run_train(args)
     94                                       run_config=run_config,
     95                                       schedule=""train_and_evaluate"",
---> 96                                       hparams=params)
     97 
     98 if __name__ == '__main__':

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    248               'in a future version' if date is None else ('after %s' % date),
    249               instructions)
--> 250       return func(*args, **kwargs)
    251     return tf_decorator.make_decorator(
    252         func, new_func, 'deprecated',

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in run(experiment_fn, output_dir, schedule, run_config, hparams)
    223   schedule = schedule or _get_default_schedule(run_config)
    224 
--> 225   return _execute_schedule(experiment, schedule)
    226 
    227 

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/learn_runner.py in _execute_schedule(experiment, schedule)
     50     logging.error('Allowed values for this experiment are: %s', valid_tasks)
     51     raise TypeError('Schedule references non-callable member %s' % schedule)
---> 52   return task()
     53 
     54 

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train_and_evaluate(self)
    664                   hooks=self._eval_hooks)
    665           ]
--> 666       self.train(delay_secs=0)
    667 
    668     # If the checkpoint_and_export flag and appropriate estimator configuration

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in train(self, delay_secs)
    387         max_steps=self._train_steps,
    388         hooks=self._train_monitors + extra_hooks,
--> 389         saving_listeners=self._saving_listeners)
    390 
    391   def evaluate(self, delay_secs=None, name=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/experiment.py in _call_train(self, _sentinel, input_fn, steps, hooks, max_steps, saving_listeners)
    874           max_steps=max_steps,
    875           hooks=hooks,
--> 876           saving_listeners=saving_listeners)
    877     else:
    878       return self._estimator.fit(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    361 
    362     saving_listeners = _check_listeners_type(saving_listeners)
--> 363     loss = self._train_model(input_fn, hooks, saving_listeners)
    364     logging.info('Loss for final step: %s.', loss)
    365     return self

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
    841       return self._train_model_distributed(input_fn, hooks, saving_listeners)
    842     else:
--> 843       return self._train_model_default(input_fn, hooks, saving_listeners)
    844 
    845   def _train_model_default(self, input_fn, hooks, saving_listeners):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
    854       worker_hooks.extend(input_hooks)
    855       estimator_spec = self._call_model_fn(
--> 856           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
    857       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
    858                                              hooks, global_step_tensor,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
    829 
    830     logging.info('Calling model_fn.')
--> 831     model_fn_results = self._model_fn(features=features, **kwargs)
    832     logging.info('Done calling model_fn.')
    833 

/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/estimator.py in _model_fn(features, labels, mode)
     92                                                  dropout=dropout,
     93                                                  weight_decay=weight_decay,
---> 94                                                  mode=mode)
     95             return _create_estimator_spec_from_logits(labels=labels,
     96                                                       logits=logits,

/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fully_connected_autoencoder(network_type, model_id, sparse_coding, inputs, hidden_units, activation_fn, dropout, weight_decay, mode)
     90         with tf.variable_scope(scope, 'FCAutoencoder', [inputs]):
     91                 with slim.arg_scope(autoencoder_arg_scope(activation_fn, dropout, weight_decay, None, mode)):
---> 92                         net = fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)
     93                         n_features = inputs.shape[1].value
     94                         decoder_units = hidden_units[:-1][::-1] + [n_features]

/content/drive/Colab/baby_training_model_estimators/tf_autoencoder/layers.py in fc_encoder(inputs, hidden_units, network_type, model_id, dropout, sparse_coding)
     15                         with tf.variable_scope('layer_{}'.format(layer_id), values=(net,)) as layer_scope:
     16                                 print(num_hidden_units)
---> 17                                 net = slim.fully_connected(net, num_outputs= num_hidden_units, scope=layer_scope)
     18                                 if sparse_coding is not None:
     19                                         tf.losses.mean_squared_error(net, tf.zeros_like(net), weights=sparse_coding, scope=layer_scope)

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    181       current_args = current_scope[key_func].copy()
    182       current_args.update(kwargs)
--> 183     return func(*args, **current_args)
    184 
    185   _add_op(func)

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in fully_connected(inputs, num_outputs, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)
   1714         _scope=sc,
   1715         _reuse=reuse)
-> 1716     outputs = layer.apply(inputs)
   1717 
   1718     # Add variables to collections.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    826       Output tensor(s).
    827     """"""
--> 828     return self.__call__(inputs, *args, **kwargs)
    829 
    830   def _add_inbound_node(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    697           if all(hasattr(x, 'get_shape') for x in input_list):
    698             input_shapes = nest.map_structure(lambda x: x.get_shape(), inputs)
--> 699           self.build(input_shapes)
    700         try:
    701           # Note: not all sub-classes of Layer call Layer.__init__ (especially

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/core.py in build(self, input_shape)
    136                                     constraint=self.kernel_constraint,
    137                                     dtype=self.dtype,
--> 138                                     trainable=True)
    139     if self.use_bias:
    140       self.bias = self.add_variable('bias',

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in add_variable(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)
    544             constraint=constraint,
    545             trainable=trainable and self.trainable,
--> 546             partitioner=partitioner)
    547 
    548         if init_graph is not None:  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpointable.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)
    434     new_variable = getter(
    435         name=name, shape=shape, dtype=dtype, initializer=initializer,
--> 436         **kwargs_for_getter)
    437 
    438     # If we set an initializer and the variable processed it, tracking will not

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
   1315       partitioner=partitioner, validate_shape=validate_shape,
   1316       use_resource=use_resource, custom_getter=custom_getter,
-> 1317       constraint=constraint)
   1318 get_variable_or_local_docstring = (
   1319     """"""%s

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
   1077           partitioner=partitioner, validate_shape=validate_shape,
   1078           use_resource=use_resource, custom_getter=custom_getter,
-> 1079           constraint=constraint)
   1080 
   1081   def _get_partitioned_variable(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
    415       if ""constraint"" in estimator_util.fn_args(custom_getter):
    416         custom_getter_kwargs[""constraint""] = constraint
--> 417       return custom_getter(**custom_getter_kwargs)
    418     else:
    419       return _true_getter(

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in layer_variable_getter(getter, *args, **kwargs)
   1609   def layer_variable_getter(getter, *args, **kwargs):
   1610     kwargs['rename'] = rename
-> 1611     return _model_variable_getter(getter, *args, **kwargs)
   1612 
   1613   return layer_variable_getter

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in _model_variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **_)
   1600       partitioner=partitioner,
   1601       custom_getter=getter,
-> 1602       use_resource=use_resource)
   1603 
   1604 

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    181       current_args = current_scope[key_func].copy()
    182       current_args.update(kwargs)
--> 183     return func(*args, **current_args)
    184 
    185   _add_op(func)

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in model_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)
    289                  caching_device=caching_device, device=device,
    290                  partitioner=partitioner, custom_getter=custom_getter,
--> 291                  use_resource=use_resource)
    292   return var
    293 

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    181       current_args = current_scope[key_func].copy()
    182       current_args.update(kwargs)
--> 183     return func(*args, **current_args)
    184 
    185   _add_op(func)

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)
    244                   caching_device=caching_device,
    245                   partitioner=partitioner,
--> 246                   use_resource=use_resource)
    247 
    248 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)
    392           trainable=trainable, collections=collections,
    393           caching_device=caching_device, validate_shape=validate_shape,
--> 394           use_resource=use_resource, constraint=constraint)
    395 
    396     if custom_getter is not None:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)
    784         validate_shape=validate_shape,
    785         constraint=constraint,
--> 786         use_resource=use_resource)
    787     if not context.executing_eagerly() or self._store_eager_variables:
    788       # In eager mode we do not want to keep default references to Variable

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in variable(initial_value, trainable, collections, validate_shape, caching_device, name, dtype, constraint, use_resource)
   2218                          name=name, dtype=dtype,
   2219                          constraint=constraint,
-> 2220                          use_resource=use_resource)
   2221 
   2222 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>(**kwargs)
   2208              constraint=None,
   2209              use_resource=None):
-> 2210   previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
   2211   for getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
   2212     previous_getter = _make_getter(getter, previous_getter)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)
   2191         collections=collections, validate_shape=validate_shape,
   2192         caching_device=caching_device, name=name, dtype=dtype,
-> 2193         constraint=constraint)
   2194 
   2195 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)
    233           dtype=dtype,
    234           expected_shape=expected_shape,
--> 235           constraint=constraint)
    236 
    237   def __repr__(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)
    341             with ops.name_scope(""Initializer""), ops.device(None):
    342               self._initial_value = ops.convert_to_tensor(
--> 343                   initial_value(), name=""initial_value"", dtype=dtype)
    344               shape = (self._initial_value.get_shape()
    345                        if validate_shape else tensor_shape.unknown_shape())

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>()
    768           initializer = initializer(dtype=dtype)
    769         init_val = lambda: initializer(  # pylint: disable=g-long-lambda
--> 770             shape.as_list(), dtype=dtype, partition_info=partition_info)
    771         variable_dtype = dtype.base_dtype
    772 

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/initializers.py in _initializer(shape, dtype, partition_info)
    118     """"""Initializer function.""""""
    119     if not dtype.is_floating:
--> 120       raise TypeError('Cannot create initializer for non-floating point type.')
    121     # Estimating fan_in and fan_out is not possible to do perfectly, but we try.
    122     # This is the right thing for matrix multiply and convolutions.

TypeError: Cannot create initializer for non-floating point type.

`

I think it is related to a previous bug: [#6342](https://github.com/tensorflow/tensorflow/issues/6342)
"
19612,import _pywrap_tensorflow ModuleNotFoundError: No module named '_pywrap_tensorflow',"Hello,  I know already a few had a similar problem. But I just don't get it fixed.

This is my error:

Import tensorflow

`Traceback (most recent call last):
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\danyb\AppData\Local\Programs\Python\Python36-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.`

"
19611,performance bug in Conv3d_transpose causes it to be a factor >100 slower than equivalent computations,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: This only concerns a nativ tensorflow function
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Tested on Arch Linux, OS X and Windows 8
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5, 1.7 & 1.8 (cpu)
- **Python version**: 2.7.14 and 3.6.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CPU-only issue
- **GPU model and memory**: CPU-only issue
- **Exact command to reproduce**: tf.conv3d_transpose

### Describe the problem
tf.conv3d_transpose is a factor >100 slower than other operations doing the same or an equivalent computation when working with tensorflow on cpu. This was previously reported in Issue #10535 and #7610 , but none have provided a minimal example and both were closed due to inactivity.

### Source code / logs
Minimal example that shows how much slower conv3d_transposed is compared to einsum doing the same computation and to the conv3d forward computation:
```
import tensorflow as tf
import time

batch_size = 200
inp = tf.ones((batch_size,28,28,1,1))
filter_conv = tf.ones((28,28,1,1,50))
filter_fc = tf.ones((28,28,1,1,50))
lat = tf.ones((batch_size,1,1,1,50))

sess = tf.InteractiveSession()
t0 = time.time()
# takes 47sec on my machine
sess.run(tf.nn.conv3d_transpose(lat, filter_conv, inp.shape,[1,1,1,1,1],padding='VALID'))
delta_t = time.time() - t0
print(""time it takes for conv3d_transpose:"", delta_t)
t0 = time.time()
# takes .04sec on my machine
sess.run(tf.einsum(""ijclm,abclm->iabcj"",lat,filter_fc)) 
delta_t = time.time() - t0
print(""time it takes with einsum to do the same computation:"", delta_t)
t0 = time.time()
# takes .01sec on my machine
sess.run(tf.nn.conv3d(inp, filter_conv, [1,1,1,1,1],padding='VALID'))
delta_t = time.time() - t0
print(""time it takes to apply conv3d:"", delta_t)
```
"
19610,tflite AllocateTensors error after ResizeInputTensor,"OS Platform and Distribution: Android Native C, Android API 26
TensorFlow installed from: Compiled from the official github master branch
TensorFlow version: Master
Bazel versio: 0.13.0-homebrew
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A
Code below: 
```
int input = interpreter->inputs()[0];
//  TfLiteStatus status = interpreter->ResizeInputTensor(0, sizes);
  TfLiteStatus status = interpreter->ResizeInputTensor(input, sizes);

  if (interpreter->ResizeInputTensor(input, sizes) != kTfLiteOk) {
        exit(-1);
   }

  if (interpreter->AllocateTensors() != kTfLiteOk) {
      exit(-1);
  }
```
AllocateTensors errors after resize the InputTensor, any suggestions? I am using mobilenet_ssd.tflite model."
19608,Value error in variable scope,"
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 653, in _get_single_variable
    name, """".join(traceback.format_list(tb))))

ValueError: Variable proj_w already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:

  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\ops.py"", line 1228, in __init__
    self._traceback = _extract_stack()
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\ops.py"", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""D:\Anaconda\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 768, in apply_op
    op_def=op_def)


This is the error i am getting with the sequence to sequence model i am using to build a chatbot using the cornell movie conversation dataset. the console throws a error that variable proj_w already exists, disallowed. Did you mean to set reuse=True in VarScope? How to rectify this problem?"
19607,Android tensorflow lite kernel_util.cc:34 input_product_scale < output_scale,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:1.8
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
1.I retrained and quantized the openpose model(add tf.contrib.quantize.create_training_graph() in my code）

2.Generate .pb (add tf.contrib.quantize.create_eval_graph() in my code) 

3.Then, I converted my own pb model to lite.
It was succeed,the command:

./bazel-bin/tensorflow/contrib/lite/toco/toco \
  --input_file=models/freeze/frozen_q_256.pb \
  --output_file=tf_files/lite/frozen_q_256.lite \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --input_array=image \
  --input_shape=1,256,256,3\
  --output_array=Openpose/concat_stage7 \
  --std_value=127.5 \
  --mean_value=127.5 \

4.But when I put it on android, I got an error.

### Source code / logs
ava.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/kernel_util.cc:34 input_product_scale < output_scale was not true.
                                                                                  at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
                                                                                  at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:95)
                                                                                  at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
                                                                                  at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
                                                                                  at com.asus.android.poseestimator.ImageClassifier.classifyFrame(ImageClassifier.java:167)
                                                                                  at com.asus.android.poseestimator.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:740)
                                                                                  at com.asus.android.poseestimator.Camera2BasicFragment.access$1000(Camera2BasicFragment.java:74)
                                                                                  at com.asus.android.poseestimator.Camera2BasicFragment$5.run(Camera2BasicFragment.java:621)
                                                                                  at android.os.Handler.handleCallback(Handler.java:836)
                                                                                  at android.os.Handler.dispatchMessage(Handler.java:103)
                                                                                  at android.os.Looper.loop(Looper.java:208)
                                                                                  at android.os.HandlerThread.run(HandlerThread.java:61)

my tensorflow lite version is 0.1.1. Does this version support qauntized lite??
How can I solve this problem?

"
19606,Android tensorflow lite kernel_util.cc:34 input_product_scale < output_scale,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19605,"how to distribute train using tf estimator, is there an example?","Is distributed training using tf estimator still under development?
Are there any examples show how to train distributedly using tf estimator(using the develop version)?
Following the https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig, I could not work it out, could you provide some examples?"
19603,"terminate called after throwing an instance of 'std::bad_alloc', over 20Gb memory free","Training a small model in Keras, getting this error after about 20 epochs (of 10000 samples).  While training is running, the system is chugging along happily with about 43Gb of memory free.  At about epoch 20, suddenly everything stops and free memory drops to about 20Gb before throwing the error.

Seems to be the same issue as #9487
```
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
```


tf_env data:

> == cat /etc/issue ===============================================
> Linux 7ff559301433 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
> VERSION=""16.04.2 LTS (Xenial Xerus)""
> VERSION_ID=""16.04""
> VERSION_CODENAME=xenial
> 
> == are we in docker =============================================
> Yes
> 
> == compiler =====================================================
> c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
> Copyright (C) 2015 Free Software Foundation, Inc.
> This is free software; see the source for copying conditions.  There is NO
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
> 
> 
> == uname -a =====================================================
> Linux 7ff559301433 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
> 
> == check pips ===================================================
> numpy (1.14.3)
> protobuf (3.4.0)
> tensorflow-gpu (1.3.0)
> tensorflow-tensorboard (0.1.8)
> 
> == check for virtualenv =========================================
> False
> 
> == tensorflow import ============================================
> tf.VERSION = 1.3.0
> tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
> tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
> Sanity check: array([1], dtype=int32)
> 
> == env ==========================================================
> LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64
> DYLD_LIBRARY_PATH is unset
> 
> == nvidia-smi ===================================================
> Mon May 28 18:57:01 2018       
> +-----------------------------------------------------------------------------+
> | NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
> |-------------------------------+----------------------+----------------------+
> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
> |===============================+======================+======================|
> |   0  GeForce GTX 750 Ti  Off  | 00000000:0B:00.0 Off |                  N/A |
> | 33%   30C    P0     1W /  38W |     11MiB /  2000MiB |      0%      Default |
> +-------------------------------+----------------------+----------------------+
> |   1  GeForce GTX 660     Off  | 00000000:14:00.0 N/A |                  N/A |
> | 30%   34C    P0    N/A /  N/A |     11MiB /  1999MiB |     N/A      Default |
> +-------------------------------+----------------------+----------------------+
>                                                                                
> +-----------------------------------------------------------------------------+
> | Processes:                                                       GPU Memory |
> |  GPU       PID   Type   Process name                             Usage      |
> |=============================================================================|
> |    1                    Not Supported                                       |
> +-----------------------------------------------------------------------------+
> 
> == cuda libs  ===================================================
> /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
> /usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
> 

The data loading code isn't important, just opening files and getting 64x64 pixel chunks of each.  I'm attaching the actual NN code though.

```
import tensorflow as tf

import keras
from keras.models import Sequential
from keras.utils import multi_gpu_model
from keras.layers import Convolution2D, MaxPooling2D, Conv2DTranspose

from keras import backend as K
K.clear_session()

import numpy as np

import dataPool2 as dp

def psnr(img1, img2):
    #print(img1.shape, img2.shape)
    #assert img1.shape == img2.shape

    mse = tf.losses.mean_squared_error(img1, img2)

    score = 3 * tf.log((255 ** 2) / mse)
    
    return 1 / score

def srcnnModel():
	model = Sequential()
	model.add(Convolution2D(64, (9, 9), activation='relu', padding='same', input_shape=(64,64,1)))
	model.add(Convolution2D(32, (1, 1), activation='relu', padding='same'))
	model.add(Convolution2D(1, (5, 5), padding='same'))
	
	model.compile(loss='mse',
              optimizer='adam',
              metrics=['accuracy'])

	return model

with tf.device('/cpu:0'):
    model = srcnnModel()

print(model.summary())
	
parallel_model = multi_gpu_model(model, gpus=2)
parallel_model.compile(loss=psnr,
                       optimizer='adam')
				   
# Generate Data
xYchan, xCrCb, yYchan, origY = dp.createDataset(""test_images/"", 10000)

parallel_model.fit(np.array(xYchan), np.array(yYchan), epochs=200, batch_size=128, callbacks=[
                keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0001, patience=3, verbose=0, mode='auto')],) 
```"
19602,[Feature Request] Named Dimensions,"Having named dimensions would be a nice improvement to dynamic shapes.
I'm thinking about a similar system like [xarray's](http://xarray.pydata.org/en/stable/data-structures.html#dataset).

Example of current code:
```
images = tf.placeholder(tf.float32, shape=(None, None, None, 3))
images_shape = tf.shape(images)
ones = tf.ones(images_shape, dtype=images.dtype)
images_plus1 = images + ones 
print(images_plus1)
```
> <tf.Tensor 'add:0' shape=(?, ?, ?, 3) dtype=float32>

Due to the ""None"" - Dimensions it's hard to distinguish them, especially when using reshaping ops.
In my opinion some type of ""tf.Dimension"" would be better:
```
image_dim_0 = tf.Dimension(size=None, name=""image_dim_0"")
image_dim_1 = tf.Dimension(size=None, name=""image_dim_1"")
image_dim_2 = tf.Dimension(size=None, name=""image_dim_2"")

images = tf.placeholder(tf.float32, shape=(image_dim_0, image_dim_1, image_dim_2, 3))
images_shape = tf.shape(images)
ones = tf.ones(images_shape, dtype=images.dtype)
images_plus1 = images + ones 
print(images_plus1)
```
> <tf.Tensor 'add:0' shape=(**image_dim_0:** ?, **image_dim_1:** ?, **image_dim_2:** ?, 3) dtype=float32>

Also, this maybe helps to do some shape inference?

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: none
- **GCC/Compiler version (if compiling from source)**: none
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**: none
"
19596,Undefined symbol _rdft and _cblas_sgemm in libtensorflow-lite.a,"Hi,

I am working on creating this SDK which is working fine if installed TensorflowLite via **_pod install_**
But, when creating this same SDK by steps mentioned in the following link (https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/lite/g3doc/ios.md) it gives the issue mentioned below:

> Undefined symbols for architecture arm64:
>   ""_rdft"", referenced from:
>       tflite::internal::Spectrogram::ProcessCoreFFT() in libtensorflow-lite.a(spectrogram.o)
>   ""_cblas_sgemm"", referenced from:
>       tflite::cblas_ops::Conv(float const*, tflite::Dims<4> const&, float const*, tflite::Dims<4> const&, float const*, tflite::Dims<4> const&, int, int, int, int, float, float, float*, tflite::Dims<4> const&, float*, tflite::Dims<4> const&) in libtensorflow-lite.a(conv.o)
> ld: symbol(s) not found for architecture arm64

thats when using TensorFlow version - r1.8

Also libtensorflow-lite.a is not created when using TensorFlow version - r1.7

> 1 error generated.
> make: *** [/Users/quantiphi/TFLite/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/kernels/internal/spectrogram.o] Error 1


Have I written custom code - No
OS Platform and Distribution - MacOS
TensorFlow - N/A
TensorFlow version - r1.8
Bazel version - 0.11.0
CUDA/cuDNN version - N/A
GPU model and memory - N/A
Exact command to reproduce - N/A
"
19595,"hardening-check return ""Fortify Source functions: no, only unprotected functions found!"" for some ""so""s, for example - tensorflow/contrib/image/python/ops/_distort_image_ops.so ","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.12.0
- **GCC/Compiler version (if compiling from source)**: (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609

- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: 12G, K80
- **Exact command to reproduce**:  hardening-check ./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/k8-py3-opt/bin/tensorflow/contrib/rnn/python/ops/_lstm_ops.so



### Describe the problem
run hardening-check on Ubuntu16.04 against all the ""so""es built from TensorFlow source code, in the result, some of "" Fortify Source functions"" return ""yes (some protected functions found)"", some return ""no, only unprotected functions found!"". 

I assume those ""so""es who return ""no, only unprotected functions found!"" are not fortified, could anybody help confirm? If yes, it that a bug?

here are the result example s for a few ""so""es: 

> ./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/image/python/ops/_distort_image_ops.so:
 Position Independent Executable: no, regular shared library (ignored)
 Stack protected: yes
 **Fortify Source functions: no, only unprotected functions found!**
 Read-only relocations: yes
 Immediate binding: yes
./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/image/python/ops/_single_image_random_dot_stereograms.so
./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/image/python/ops/_single_image_random_dot_stereograms.so:
 Position Independent Executable: no, regular shared library (ignored)
 Stack protected: yes
 **Fortify Source functions: yes (some protected functions found)**
 Read-only relocations: yes
 Immediate binding: yes
./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/libsvm/python/ops/_libsvm_ops.so
./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/libsvm/python/ops/_libsvm_ops.so:
 Position Independent Executable: no, regular shared library (ignored)
 Stack protected: yes
 **Fortify Source functions: no, only unprotected functions found!**
 Read-only relocations: yes
 Immediate binding: yes
./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/ffmpeg/ffmpeg.so
./.cache/bazel/_bazel_pengwa/85985b4501e3e12ee6a73770d2b8b659/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/contrib/ffmpeg/ffmpeg.so:
 Position Independent Executable: no, regular shared library (ignored)
 Stack protected: yes
 **Fortify Source functions: yes (some protected functions found)**
 Read-only relocations: yes
 Immediate binding: yes
"
19594,Using 1.7's TF_C_API_GRAPH_CONSTRUCTION=0 in 1.8.,"After your 1.8 change I am unable to programatically obtain architecture of loaded neural network (neural network saved by SavedModel functionality, custom tf.Estimator [or any tf.Estimator for that matter]). 

In 1.7 I could get all of the operations by ```graph.get_operations()```. Those were ordered (exactly the same as network layout, e.g. input operations first, followed by dense/convolutional/other layers up to network/graph output). Furthermore I could infer architecture by their names like conv2d etc. Right now (version 1.8) operations are **unordered** and their placement does not make much sense.

My question is: Is it possible to do now? Should I use some script from your repository to get those names in order (other than environment variable provided right now)?"
19593,Does AWS (4.4.0-1060-aws) with g2.2X large support TensorFlow - GPU ?,"Installed CUDA 9.0 and CuDNN on Ubuntu 16.04 (4.4.0-1060-aws; g2.2X large).

I got an error as - The GPU Driver (GPU Name: Persistence-M; NVIDIA-SMI 396.26) is not TensorFlow compatible. Below is my Linux screenshot).
2018-05-24 22:08:28.707495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Ignoring visible gpu device (device: 0, name: GRID K520, pci bus id: 0000:00:03.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.

Does AWS (4.4.0-1060-aws) with g2.2X large support TensorFlow - GPU ?

Thanks."
19589,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,"Hi

I installed CUDA Toolkit 9.2 and CuDNN on Ubuntu 16.04 (4.4.0-1060-aws; g2.2X large) with strictly followed the installation instructions from these two urls -""https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions"" and ""https://docs.nvidia.com/deeplearning/sdk/cudnn-install/"". My CUDA and CuDNN installation were successful. I verified the CuDNN installation as mentioned at the installation guide.
But, after installing ""tensorflow-gpu"", it throws the above error. I installed Anaconda and then ""tensorflow-gpu"" with pip command as: $pip install -U tensorflow-gpu
The ""tensorflow-gpu"" installation became fully successful.

These are some more details of my configurations:
 NVIDIA-SMI 396.26

$cat /usr/local/cuda/version.txt
CUDA Version 9.2.88
CUDA Patch Version 9.2.88.1

$which nvcc
/usr/local/cuda-9.2/bin/nvcc

$nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Wed_Apr_11_23:16:29_CDT_2018
Cuda compilation tools, release 9.2, V9.2.88

Please suggest me. Thanks.
"
19588,"Using Dataset api with Estimator in MirroredStrategy,  Non-DMA-safe string tensor error","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: centos
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**:1.8.0 
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:4.8.5
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**:GeForce GTX 1080Ti * 4
- **Exact command to reproduce**:


### Describe the problem
Using mutilple gpu by MirroredStrategy, Get ' Non-DMA-safe string tensor may not be copied from/to a GPU.' error

### Source code / logs

![image](https://user-images.githubusercontent.com/12636388/40601170-a716ad26-6286-11e8-9fb1-7b5d1b6c6545.png)
![image](https://user-images.githubusercontent.com/12636388/40601198-c0ad1f36-6286-11e8-956c-3023fcc86292.png)
![image](https://user-images.githubusercontent.com/12636388/40601204-c6ecdaf8-6286-11e8-96cd-588ef276f5b4.png)
![image](https://user-images.githubusercontent.com/12636388/40601209-cbc60c16-6286-11e8-8dd0-6b54df3ab8fe.png)

"
19587,how to use tflite with arm compute library？,as the title says
19586,"[TFlite]Not supported (ELU, ResizeNearestNeighbor ExpandDims)","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**:1.7.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:no
- **GCC/Compiler version (if compiling from source)**:no
- **CUDA/cuDNN version**:no
- **GPU model and memory**:no
- **Exact command to reproduce**:yes

### Describe the problem
I tried to convert some TF model to "".tflite"" format. But I was encountered with ""No supporting operation"". 


### Source code / logs

tensorflow/contrib/lite/toco/tflite/export.cc:304] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you hava a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: Elu, ExpandDims, ResizeNearestNeighbor.

"
19585,coco error ,"
NotFoundError: ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb; No such file or directory"
19584,Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.,"As announced in release notes, TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets. This means on any CPU that do not have these instruction sets either CPU or GPU version of TF will fail to load with any of the following errors:

- `ImportError: DLL load failed:`
-  A crash with return code 132

Our recommendation is to build TF from sources on these systems.


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu/windows/macos
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6 and up
- **Python version**:  2.7, 3.3, 3.4, 3.5, 3.6 and any newer
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: any
- **GPU model and memory**: any
- **Exact command to reproduce**: python -c ""import tensorflow as tf"""
19583,[Documentation] No documentation for building TensorFlow with Windows through Bazel,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: dcb10b1
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.13.1
- **GCC/Compiler version (if compiling from source)**: Visual Studio C++ 2017
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `bazel build -s --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_package`

### Describe the problem

Based on https://github.com/tensorflow/tensorflow/issues/18296#issuecomment-386685428, it looks like TensorFlow already supports Windows build with Bazel. However, there is no documentation about Windows + Bazel support, and my attempts have failed (see steps below).

It would be good to add documentation for building TensorFlow with Windows + Bazel. That will help greatly.


### Source code / logs

As I don't have a Windows machine, I tried to build TensorFlow with the Virtual Machine of Window 10, provided by Microsoft https://developer.microsoft.com/en-us/windows/downloads/virtual-machines

The VM is **Windows 10 Enterprise (Evaluation - Build 201805)**. It  (Expire on 7/30/2018)**, and **Visual Studio 2017** has been pre-installed.

The VM image is deployed on macOS with VMware Fusion, and allocated `4 CPU + 8GB Memory`.

Here are the steps I tried until I encountered the failure:
1. Install msys2 (`msys2-x86_64-20161025.exe`) to `C:\msys64`.
2. Downlaod Bazel (`bazel-0.13.1-windows-x86_64.exe`) and place it to `C:\Users\user\bazel.exe`. Add `C:\Users\user` to `PATH`.
3. Set `BAZEL_VC` with `SET BAZEL_VC=C:\Program Files (x86)\Microsoft Visual Studio\2017\Community\VC`
4. Verified `bazel build //examples/cpp:hello-world` works
5. ~~Install python 3.6.5 (`python-3.6.5-amd64.exe`) to `C:\Users\Python36`~~
   **Install Anaconda (Anaconda3-5.1.0-Windows-x86_64.exe) to C:\Users\Anaconda** (update)
6. `git clone tensorflow`
7.  `python configure.py` and always use the default value (return).
8. `bazel build -s --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_package`

*Update: Python 3.6 install could be replaced by Anaconda for numpy*

Below is the output:
```
C:\Users\user\tensorflow>python configure.py
You have bazel 0.13.1 installed.
Please specify the location of python. [Default is C:\Users\Python36\python.exe]:


Found possible Python library paths:
  C:\Users\Python36\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\Python36\lib\site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]:
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]:
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]:
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]:
No CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with MPI support? [y/N]:
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See tools/bazel.rc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.

C:\Users\user\tensorflow>
C:\Users\user\tensorflow>
C:\Users\user\tensorflow>bazel build -s --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_package
Starting local Bazel server and connecting to it...
..................
WARNING: C:/users/user/_bazel_user/4opxzgxi/external/protobuf_archive/WORKSPACE:1: Workspace name in C:/users/user/_bazel_user/4opxzgxi/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: C:/users/user/_bazel_user/4opxzgxi/external/absl_py/WORKSPACE:1: Workspace name in C:/users/user/_bazel_user/4opxzgxi/external/absl_py/WORKSPACE (@io_abseil_py) does not match the name given in the repository's definition (@absl_py); this will cause a build error in future versions
ERROR: C:/users/user/tensorflow/util/python/BUILD:5:1: no such package '@local_config_python//': Traceback (most recent call last):
        File ""C:/users/user/tensorflow/third_party/py/python_configure.bzl"", line 291
                _create_local_python_repository(repository_ctx)
        File ""C:/users/user/tensorflow/third_party/py/python_configure.bzl"", line 251, in _create_local_python_repository
                _check_python_bin(repository_ctx, python_bin)
        File ""C:/users/user/tensorflow/third_party/py/python_configure.bzl"", line 204, in _check_python_bin
                _fail((""--define %s='%s' is not execut...)))
        File ""C:/users/user/tensorflow/third_party/py/python_configure.bzl"", line 27, in _fail
                fail((""%sPython Configuration Error:%...)))
Python Configuration Error: --define PYTHON_BIN_PATH='C:/Users/Python36/python.exe' is not executable. Is it the python binary?
 and referenced by '//util/python:python_headers'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed
INFO: Elapsed time: 17.944s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (126 packages loaded)

C:\Users\user\tensorflow>
```"
19582,Can any one help me in resolving this issue?? I'm using keras and tensorflow,"Using TensorFlow backend.
Traceback (most recent call last):
  File ""app.py"", line 32, in <module>
    model, graph = init()
  File ""/home/jitendra/cnn-hand-written-digit-master/model/load.py"", line 12, in init
    loaded_model = model_from_json(loaded_model_json)
  File ""build/bdist.linux-x86_64/egg/keras/engine/saving.py"", line 369, in model_from_json
  File ""build/bdist.linux-x86_64/egg/keras/layers/__init__.py"", line 55, in deserialize
  File ""build/bdist.linux-x86_64/egg/keras/utils/generic_utils.py"", line 145, in deserialize_keras_object
  File ""build/bdist.linux-x86_64/egg/keras/engine/sequential.py"", line 293, in from_config
  File ""build/bdist.linux-x86_64/egg/keras/engine/sequential.py"", line 166, in add
  File ""build/bdist.linux-x86_64/egg/keras/engine/base_layer.py"", line 414, in __call__
  File ""build/bdist.linux-x86_64/egg/keras/engine/base_layer.py"", line 279, in assert_input_compatibility
  File ""build/bdist.linux-x86_64/egg/keras/backend/tensorflow_backend.py"", line 469, in is_keras_tensor
  File ""build/bdist.linux-x86_64/egg/keras/backend/tensorflow_backend.py"", line 477, in is_tensor
AttributeError: 'module' object has no attribute '_TensorLike'
"
19581,Can any one help me in resolving this issue?? I'm using keras and tensorflow,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19579,Turn some sessionmanager/dataset info messages to debug.,"Since TF1.7, many logging seems to have been added and set to info, e.g.:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/session_manager.py
```py
logging.info(""Running local_init_op."")
sess.run(self._local_init_op)
logging.info(""Done running local_init_op."")
```

And 
https://github.com/tensorflow/tensorflow/blob/b12c3bb1157245adf6230a2e045831348f679b5b/tensorflow/python/training/monitored_session.py
```py
logging.info('Graph was finalized.')
```

Same for dataset shuffle buffer:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/data/shuffle_dataset_op.cc
```cpp
LOG(INFO) << ""Filling up shuffle buffer (this may take a while): ""
  << num_elements_ << "" of "" << dataset()->buffer_size_;
```

This leads to a lot of clutter. Should this be cleaned up? The shuffle buffer f.e. might be a nice message, but ""graph was finalized"" and ""running init op"" and ""done running init op"" seem to be should be debug.
"
19578,Latest NonMaxSuppression breaks backward compatiblity,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**:  N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

The latest changes https://github.com/tensorflow/tensorflow/commit/1a300437cecfae36f7584694dac523851f1cd931 to the NonMaxSuppression op have two issues:

1. It breaks backward compatibility. It removes all boxes whose scores are below a threshold, and the threshold is default to 0. However, the old API does not require that the scores have to be >= 0. Boxes with negative scores will be removed by default after this change.
On [my implementation of Mask RCNN](https://github.com/ppwwyyxx/tensorpack/tree/master/examples/FasterRCNN) this decreases mAP by 0.2.

2. It has a potential bug. This loop:
https://github.com/tensorflow/tensorflow/blob/1a300437cecfae36f7584694dac523851f1cd931/tensorflow/core/kernels/non_max_suppression_op.cc#L137-L142

triggers an integer underflow when `selected` is empty, because `size()` is unsigned. It happens to cause no bugs in this case, but should better be fixed. If the loop order is reversed like `for (int j = 0; j <= selected.size() - 1; ++j)`, this would become a bug immediately.

EDIT: From https://en.cppreference.com/w/cpp/language/implicit_conversion:

> If the destination type is signed, the value does not change if the source integer can be represented in the destination type. Otherwise the result is implementation-defined. (Note that this is different from signed integer arithmetic overflow, which is undefined).

So the above code relies on implementation-defined behavior."
19575,[BUG] Failed to build from source because of missing #include directive,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.8.0, tf.GIT_VERSION is 'unknown' (I compiled from commit dcb10b1d557168646204239bea6ca5bf1abc40a3)
- **Python version**: Python 3.6.5
- **Bazel version (if compiling from source)**: 0.13.1
- **GCC/Compiler version (if compiling from source)**: 7.3.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
When compiling tensorflow from source following the instructions here (https://www.tensorflow.org/install/install_sources#build_the_pip_package), I encountered the following C++ error:
```
ERROR: /path/to/tensorflow/tensorflow/python/BUILD:310:1: C++ compilation of rule '//tensorflow/python:cpp_python_util' failed (Exit 1)
tensorflow/python/util/util.cc:276:16: error: 'function' in namespace 'std' does not name a template type
     const std::function<int(PyObject*)>& is_sequence_helper,
                ^~~~~~~~
tensorflow/python/util/util.cc:276:24: error: expected ',' or '...' before '<' token
     const std::function<int(PyObject*)>& is_sequence_helper,
                        ^
tensorflow/python/util/util.cc: In function 'bool tensorflow::swig::{anonymous}::FlattenHelper(PyObject*, PyObject*, int)':
tensorflow/python/util/util.cc:280:16: error: 'is_sequence_helper' was not declared in this scope
   int is_seq = is_sequence_helper(nested);
                ^~~~~~~~~~~~~~~~~~
tensorflow/python/util/util.cc:280:16: note: suggested alternative: 'IsSequenceHelper'
   int is_seq = is_sequence_helper(nested);
                ^~~~~~~~~~~~~~~~~~
                IsSequenceHelper
[... other C++ mumbling ...]
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
```

### Source code / logs
Adding ``#include <functional>`` to the file solves the issue.
"
19573,UnicodeDecodeError from tf.train.import_meta_graph,"I serialized a Tensorflow model with the following code ...

    save_path = self.saver.save(self.session, os.path.join(self.logdir, ""model.ckpt""), global_step)
    logging.info(""Model saved in file: %s"" % save_path)

... and I'm now trying to restore it from scratch in a separate file using the following code:

    saver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')
    session = tf.Session()
    saver.restore(session, PROJ_DIR + '/logs/default/model.ckpt-54')
    print('Model restored')

When `tf.train.import_meta_graph` is called, the following exception is thrown:

    [libprotobuf ERROR google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
    Traceback (most recent call last):
      File ""/home/reid/projects/research/ccg/taggerflow_modified/test/tf_restore.py"", line 4, in <module>
    saver = tf.train.import_meta_graph(PROJ_DIR + '/logs/default/model.ckpt-54.meta')
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1711, in import_meta_graph
    read_meta_graph_file(meta_graph_or_file), clear_devices)
      File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1563, in read_meta_graph_file
    text_format.Merge(file_content.decode(""utf-8""), meta_graph_def)
      File ""/usr/lib/python2.7/encodings/utf_8.py"", line 16, in decode
    return codecs.utf_8_decode(input, errors, True)
    UnicodeDecodeError: 'utf8' codec can't decode byte 0xa7 in position 1: invalid start byte

For reference, here's the first few lines of `<PROJ_DIR>/logs/default/model.ckpt-54.meta`:

    <A7>:^R<A4>:
    9
    ^CAdd^R^F
    ^Ax""^AT^R^F
    ^Ay""^AT^Z^F
    ^Az""^AT""^Z
    ^AT^R^Dtype:^O
    ^M2^K^S^A^B^D^F^E^C    ^R^G

I think that Tensorflow is using a different encoding when serializing vs when deserializing. How do we specify the encoding that Tensorflow uses when serializing/deserializing? Or is the solution something different?

This was originally a Stack Overflow question. Someone asked me to make it a GitHub issue. I'm using version r0.11."
19572,[Feature] tf.reduce_dims() to reduce dimension as opposite to tf.expand_dims(),"### Describe the problem
It seems that there is no `tf.reduce_dims()` (the opposite of `tf.expand_dims()`). This functionality will be useful in the following scenario:

```python
# I want to reduce the last dimension 
[[1,2,3], [4,5,6], [7,8,9]]
# such that it becomes
[1,2,3,4,5,6,7,8,9]
```

I know this can be done with `tf.reshape()` but
 1. that requires extra `tf.shape()` for dynamic dimensions
 2. `tf.expand_dims()` can also be implemented with `tf.reshape()` but we have `tf.expand_dims()`

Would it be a bad idea to implement `tf.reduce_dims()`?
"
19571,Allow full deallocation of GPU memory - like in Catboost,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no (slightly modified)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
tensorflow-gpu 1.8.0 <pip>
- **Python version**: 
Python version: 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19) 
[GCC 7.2.0]
- **Bazel version (if compiling from source)**:
N/A
- **GCC/Compiler version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
9.0.176 / 7.1.2
- **GPU model and memory**:
GPU[0] GeForce GTX 1080 Ti
- **Exact command to reproduce**:
```
import tensorflow as tf
import numpy
import matplotlib.pyplot as plt
import sklearn.datasets.samples_generator as sample_gen
rng = numpy.random

# Parameters
learning_rate = 0.01
training_epochs = 500
display_step = 50

# Training set
n_features=1
n_samples=100

# Training Data
# train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,
#                          7.042,10.791,5.313,7.997,5.654,9.27,3.1])
# train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,
#                          2.827,3.465,1.65,2.904,2.42,2.94,1.3])
train_X, train_Y = sample_gen.make_regression(n_samples=n_samples, n_features=n_features, random_state=0)
# n_samples = train_X.shape[0]

# tf Graph Input
X = tf.placeholder(""float"")
Y = tf.placeholder(""float"")

# Set model weights
W = tf.Variable(rng.randn(), name=""weight"")
b = tf.Variable(rng.randn(), name=""bias"")

# Construct a linear model
pred = tf.add(tf.multiply(X, W), b)

# Mean squared error
cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)
# Gradient descent
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

# Initialize the variables (i.e. assign their default value)
init = tf.global_variables_initializer()

# Start training
with tf.Session() as sess:
    sess.run(init)

    # Fit all training data
    for epoch in range(training_epochs):
        for (x, y) in zip(train_X, train_Y):
            sess.run(optimizer, feed_dict={X: x, Y: y})

        #Display logs per epoch step
        if (epoch+1) % display_step == 0:
            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})
            print(""Epoch:"", '%04d' % (epoch+1), ""cost="", ""{:.9f}"".format(c), 
                ""W="", sess.run(W), ""b="", sess.run(b))

    print(""Optimization Finished!"")
    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})
    print(""Training cost="", training_cost, ""W="", sess.run(W), ""b="", sess.run(b), '\n')
    
    #Graphic display
    plt.plot(train_X, train_Y, 'ro', label='Original data')
    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')
    plt.legend()
    plt.show()
    plt.show()
```
### Describe the problem
Same issue as #15880 here, with a fully reproducible example using latest TF 1.8 with CUDA 9.0 and cuDNN 7.1 on Ubuntu 16.04. So same old story, but this time I'm giving you a model solution to GPU memory management -  the [Catboost library](https://github.com/catboost/catboost) by Yandex.

I confirm that Tensorflow does not release GPU memory after preallocating most of the available VRAM 
(leaving only a few percent free). This memory should be freed by TF immediately after use for other modeling frameworks to use, so it is a bug that needs to be repaired. To see how it is done, refer to how Catboost manages GPU resources.

If you are using Jupyter Notebook, restarting python kernel is relatively easy and it ""solves"" the problem, but of course at the cost of losing all your data loaded to CPU memory.

"
19570,[Bug] Very slow operation of Cumsum in tensorflow 1.6,"It seems in tensorflow the tf.cumsum operation is extremely slow on GPU, and takes a huge amount of time (~99% of the total time).

In Pytorch, as expected, the sort operation is the one that takes the most time, cumsum is virtually instant on GPU.

I give an issues on other‘s’ gitHub, we get conclusion that is cumsum is very slow aginst pytorch.
 
we issue is https://github.com/bermanmaxim/LovaszSoftmax/issues/6

code is https://github.com/bermanmaxim/LovaszSoftmax/tree/master/tensorflow

```
def lovasz_grad(gt_sorted):
    """"""
    Computes gradient of the Lovasz extension w.r.t sorted errors
    See Alg. 1 in paper
    """"""
    gts = tf.reduce_sum(gt_sorted)
    **intersection = gts - tf.cumsum(gt_sorted)
    union = gts + tf.cumsum(1. - gt_sorted)**
    jaccard = 1. - intersection / union
    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)
    return jaccard
```"
19569,I am not able to install tensorflow through anaconda it is showing the following error.....,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
![tff](https://user-images.githubusercontent.com/32293756/40574201-1316f586-60ec-11e8-8349-113b722f788a.png)
![Uploading tff1.png…]()
"
19568,sess.run([train_step]) freezes when using batch_normalization and Collection Update,"Hi,

I have faced a strange situation with Tensorflow. I explored a lot about this problem but just found one other thread (unsolved) on StackOverflow. (here: https://stackoverflow.com/questions/47047124/tf-layers-batch-normalization-freezes-during-sess-run-1-5-0-dev20171031). So, I decided to ask it here.

Basically, when I call sess.run(), it freezes. By freeze, I mean, the GPU utilization is zero, I get no errors and the process is on GPU (GPU memory is allocated).  I have the following code segment:
```
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
  with tf.control_dependencies(update_ops):
        train_step1 = optimizer1.minimize(loss = loss_fill +lossL2+ loss_detection,var_list=vars)
```

When I change this part to:
```
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
     with tf.control_dependencies(update_ops):
             pass
train_step1 = optimizer1.minimize(loss = loss_fill +lossL2+ loss_detection,var_list=vars)
```

which basically ignores some necessary moving average updates, it doesn't freeze anymore. I have a lot of tf.layers.batch_normalization() instances in my code and this is the first time I am facing this issue.

Thanks

"
19567,[BUG] max_pooling1d can not run in GPU ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.6.0
- **Python version**: 2.71.0
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  9.0/7102
- **GPU model and memory**: 3x GeForce GTX 1080 at 8G
- **Exact command to reproduce**: 

### Describe the problem

I have a rank-2 tensor, say a 1024*512 tensor, and I want to apply 1D max pooling. If I run in CPU, codes work great. However, If I run in GPU, codes will throw exceptions like the following.

```
2018-05-25 18:28:34.272767: E tensorflow/stream_executor/cuda/cuda_dnn.cc:396] Loaded runtime CuDNN library: 7102 (compatibility version 7100) but source was compiled with 7005 (compatibility version 7000).  If using a binary install, upgrade your CuDNN library to match.  If building from sources, make sure the library loaded at runtime matches a compatible version specified during compile configuration.
2018-05-25 18:28:34.273613: W ./tensorflow/stream_executor/stream.h:2018] attempting to perform DNN operation using StreamExecutor without DNN support
Traceback (most recent call last):
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 903, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 546, in run
    run_metadata=run_metadata)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1022, in run
    run_metadata=run_metadata)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1113, in run
    raise six.reraise(*original_exc_info)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1098, in run
    return self._sess.run(*args, **kwargs)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 1170, in run
    run_metadata=run_metadata)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 950, in run
    return self._sess.run(*args, **kwargs)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 905, in run
    run_metadata_ptr)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1140, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    run_metadata)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: cudnn PoolForward launch failed
	 [[Node: dnn/input_from_feature_columns_2/max_pooling1d/MaxPool = MaxPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 1, 3], padding=""SAME"", strides=[1, 1, 1, 3], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](dnn/input_from_feature_columns_2/max_pooling1d/MaxPool-0-TransposeNHWCToNCHW-LayoutOptimizer)]]
	 [[Node: dnn/gradients/dnn/input_from_feature_columns_2/input_layer/b_media_appbundle_format_embedding/b_media_appbundle_format_embedding_weights_grad/Select_1/_313 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1344_...d/Select_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op u'dnn/input_from_feature_columns_2/max_pooling1d/MaxPool', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/data2/jenkins/src/marvel2/python/moloco/deploy/models/tf_dnn/training/main/task.py"", line 66, in <module>
    tf.app.run()
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""/data2/jenkins/src/marvel2/python/moloco/deploy/models/tf_dnn/training/main/task.py"", line 61, in main
    t.train_eval()
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/training/trainer.py"", line 127, in train_eval
    self.model.train_eval(config, model_dir, train_data, eval_data)
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/models/tf_deep.py"", line 170, in train_eval
    training.train_and_evaluate(m, train_spec, eval_spec)
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/training.py"", line 401, in train_and_evaluate
    executor.run_local()
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/training.py"", line 572, in run_local
    self._estimator.train(input_fn=self._train_spec.input_fn, max_steps=max_steps, hooks=train_hooks)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 824, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 805, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/dnn.py"", line 466, in _model_fn
    config=config)
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/dnn.py"", line 224, in _dnn_model_fn
    last_layer_feats=ll_feats.values())
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/logit_ops.py"", line 301, in build_dnn_logits
    last_layer_feats=last_layer_feats)
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/logit_ops.py"", line 206, in build_hidden_layers
    net = apply_pooling(net, pooling, pooling_size, pooling_stride)
  File ""/data2/jenkins/src/marvel2/python/moloco/learn/estimators/logit_ops.py"", line 343, in apply_pooling
    o = tf.layers.max_pooling1d(o, pooling_size, strides=pooling_stride, padding=""same"")
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/layers/pooling.py"", line 231, in max_pooling1d
    return layer.apply(inputs)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 825, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 714, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/layers/pooling.py"", line 86, in call
    data_format=data_format)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 2144, in max_pool
    name=name)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 4587, in max_pool
    data_format=data_format, name=name)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3290, in create_op
    op_def=op_def)
  File ""/var/lib/jenkins/venvs/gpumoloco/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1654, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InternalError (see above for traceback): cudnn PoolForward launch failed
	 [[Node: dnn/input_from_feature_columns_2/max_pooling1d/MaxPool = MaxPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 1, 3], padding=""SAME"", strides=[1, 1, 1, 3], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](dnn/input_from_feature_columns_2/max_pooling1d/MaxPool-0-TransposeNHWCToNCHW-LayoutOptimizer)]]
	 [[Node: dnn/gradients/dnn/input_from_feature_columns_2/input_layer/b_media_appbundle_format_embedding/b_media_appbundle_format_embedding_weights_grad/Select_1/_313 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1344_...d/Select_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

INFO:root:RETURN CODES: 1
```


### Source code / logs

Here are my codes:

```python
def apply_pooling(inputs, pooling, pooling_size, pooling_stride):
  """"""Apply pooling operations on inputs tensor.

  Args:
    inputs: A tensor with at least 3 rank.
    pooling: When not `None`, `max` means max pooling, and `average` means average pooling.
    pooling_size: The pooling size in all spatial dimensions.
    pooling_stride: The stride operation size in all spatial dimensions.

  Returns:
    A tensors after applying for pooling strategy.
  """"""
  if pooling is None or pooling == Pooling.NONE:
    return inputs

  # Expand dimension if inputs has not enough rank
  ndims = len(inputs.get_shape().as_list())
  if ndims == 1:
    raise ValueError(""inputs must be at least rank 2. Given it's {}"".format(ndims))
  o = inputs
  if ndims == 2:
    o = tf.expand_dims(o, -1)
  # TODO: fix the issue of not being able to run pooling in GPU
  if pooling == Pooling.MAX:
    o = tf.layers.max_pooling1d(o, pooling_size, strides=pooling_stride, padding=""same"")
  elif pooling == Pooling.AVERAGE:
    o = tf.layers.average_pooling1d(o, pooling_size, strides=pooling_stride, padding=""same"")
  else:
    raise ValueError(""Unsupported pooling strategy: {}"".format(pooling))
  # Squeeze dimenion if necessary
  if ndims == 2:
    o = tf.squeeze(o, -1)
  return o
```"
19566,'infiniband/verbs.h' file not found,"**ERROR**: /Users/abc/tensorflow/tensorflow/contrib/verbs/BUILD:90:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_rendezvous_mgr' failed (Exit 1)
In file included from tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:18:
In file included from ./tensorflow/contrib/verbs/rdma_rendezvous_mgr.h:21:
In file included from ./tensorflow/contrib/verbs/rdma_mgr.h:24:
**./tensorflow/contrib/verbs/rdma.h:21:10: fatal error: 'infiniband/verbs.h' file not found**
#include <infiniband/verbs.h>"
19565,Getting wrong values from slice of a variable array,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.4 LTS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.7.0-3-g024aecf414 1.7.0
- **Python version**: 3.6.5
- **CUDA/cuDNN version**: CUDA Driver Version / Runtime Version:  9.1 / 9.0;  cuDNN: 7.1.3.16-1+cuda9.0
- **GPU model and memory**: GeForce 940MX 
- **Have I written custom code**: N/A
- **Bazel version**: N/A
- **Exact command to reproduce**: N/A


### Describe the problem
Bug: I am getting wrong values when I try to run/evaluate slice of a variable array with rank 3. 
Wrong values are all zeros, no matter how I initialize the array. Problem occurs for some dimension values (see screenshots below).

### Source code / logs
Trying to run this code with different k and d values. For instance there is no problem for k=3 and d=4, but k=3 and d=4 replicates the problem.

```
import tensorflow as tf
import numpy as np


k = 4
d = 3
sigma_init = np.repeat([np.eye(d, dtype=np.float32)], k, axis=0)

sigma = tf.get_variable(""sigma"",
                      shape=(k,d,d),
                      dtype=tf.float32,
                      initializer=tf.constant_initializer(sigma_init),
                      trainable=False)


sess = tf.Session()

sess.run([sigma.initializer])
#sess.run(tf.global_variables_initializer())
print(""whole:"")
print(sigma.eval(session=sess))


print(""slices:"")
print(sigma[0].eval(session=sess))

with sess.as_default():
    print(sigma[0].eval())
    
print(sess.run(sigma[0]))
```

![kd34](https://user-images.githubusercontent.com/9108649/40570982-228658b4-6091-11e8-83d6-aa59d15900e0.png)

![kd43](https://user-images.githubusercontent.com/9108649/40570984-264f6d00-6091-11e8-8b19-224ef3d5045d.png)

Some additional info about system:
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/2041188/tf_env.txt)
"
19564,Building TF from the source: compilation error with enabling AVX512 (Eigen/src/Core/arch/AVX512/PacketMath.h),"### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No.

-**OS Platform and Distribution 
Linux Ubuntu 16.04:

-**CPU info
Intel(R) Xeon(R) Gold 5118 CPU

-**TensorFlow master branch commit-id:
commit 38926b8a0fa89bef74085be0e321c13e739795d4
Merge: 00aa1d3 2457cae

- **Python version**: 
python2.7

- **Bazel version (if compiling from source)**:
Build label: 0.12.0

- **GCC/Compiler version (if compiling from source)**:
gcc version 6.4.0 20180424 (Ubuntu 6.4.0-17ubuntu1~16.04)

- **CUDA/cuDNN version**:
CUDA 9. 2 / cuDNN 7.1

- **GPU model and memory**:
NVIDIA Quadro P2000, 5G DDR Mem.

- **Exact command to reproduce**:

bazel build --jobs 48 --config=mkl -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mavx512f --copt=-mavx512pf --copt=-mavx512cd --copt=-mavx512er --copt=""-DEIGEN_USE_VML"" --copt ""-DEIGEN_ENABLE_AVX512"" --copt ""-DEIGEN_ENABLE_AVX2"" //tensorflow/tools/pip_package:build_pip_package



ERROR: tensorflow/tensorflow/core/kernels/BUILD:3446:1: C++ compilation of rule '//tensorflow/core/kernels:bincount_op' failed (Exit 1)
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:400:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/kernels/bincount_op.h:19,
                 from tensorflow/core/kernels/bincount_op.cc:20:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h: In function 'typename Eigen::internal::unpacket_traits<T>::type Eigen::internal::predux(const Packet&) [with Packet = __vector(16) float]':
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:866:1: error: unrecognizable insn:
 }
 ^
(insn 12 11 13 2 (set (mem/c:V4SF (plus:DI (reg/f:DI 82 virtual-stack-vars)
                (const_int -320 [0xfffffffffffffec0])) [5 lane0+0 S16 A128])
        (vec_merge:V4SF (vec_select:V4SF (reg:V16SF 87 [ _4 ])
                (parallel [
                        (const_int 0 [0])
                        (const_int 1 [0x1])
                        (const_int 2 [0x2])
                        (const_int 3 [0x3])
                    ]))
            (reg:V4SF 102 [ D.798038 ])
            (reg:QI 105))) external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:857 -1
     (nil))
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX512/PacketMath.h:866:1: internal compiler error: in extract_insn, at recog.c:2287
Please submit a full bug report,
"
19561,AddSymbolicGradients cannot compute the partial derivative for merged node,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.5.0
- **Bazel version (if compiling from source)**:
0.13.0
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
No CUDA
- **GPU model and memory**:
No GPU
- **Exact command to reproduce**:

### Describe the problem
Create a graph in C++ as following

      input
       /    \
      |      |
      x     y
       \    / 
         + (or concat)
         |
     output 

getting following error:

Non-OK-status: AddSymbolicGradients(root, {loss}, vars, &grads) status: Invalid argument: Cannot compute the partial derivative for node 'Variable_1' as it's unreachable from the output node(s).

The 'Variable_1' is the weight of x op. It should be reachable from output, but it looks the C++ library is not able to handle branch merge or adding.
"
19559,TF1.8 is 10% slower than TF1.4 on most cases,"I have tested on quantities of tensorflow-based applications, including tf_cnn_benchmark and keras typically applications and even for multi-GPU applications. All performance benchmarks are 10% dropped when TF1.4 is upgraded to TF1.8. However, once I revert the upgrade to use TF1.4 again, the 10% performance loss will be back."
19557,OpenCL GPU support issue,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 18.04 LTS (Bionic Beaver)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.8.0-2217-g7ad3964dcb 1.8.0
- **Python version**: Python 3.6.5
- **Bazel version (if compiling from source)**: Build label: 0.13.1
- **GCC/Compiler version (if compiling from source)**: g++ (Ubuntu 7.3.0-16ubuntu3) 7.3.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: AMD Radeon R9290
- **Exact command to reproduce**: bazel test -c opt --config=sycl --test_output=all //tensorflow/python/kernel_tests:basic_gpu_test

### Describe the problem
I built TF 1.8 from source with 'y' for OpenCL SYCL and ComputeCPP support in build configuration ('n' for other options). Build was complete successfully, but GPU device seems unavailable in TF, only CPU:0 is listed by
`tensorflow.python.client.device_lib.device_lib.list_local_devices()`
and
`tensorflow.contrib.eager.list_devices()`
Also, `tensorflow.matmul(a, b)` is placed on CPU:0, log_device_placement says: ""Device mapping: no known devices.""

`bazel test -c opt --config=sycl --test_output=all //tensorflow/python/kernel_tests:basic_gpu_test`
fails with errors from SYCL.

Bazel test, clinfo and computecpp_info logs are listed below.

Requirements for OpenCL GPU support seem to be met, but it doesn't work. Am I missing something?

### Source code / logs
clinfo

> Number of platforms                               1
  Platform Name                                   AMD Accelerated Parallel Processing
  Platform Vendor                                 Advanced Micro Devices, Inc.
  Platform Version                                OpenCL 2.1 AMD-APP (2633.3)
  Platform Profile                                FULL_PROFILE
  Platform Extensions                             cl_khr_icd cl_amd_event_callback cl_amd_offline_devices 
  Platform Host timer resolution                  1ns
  Platform Extensions function suffix             AMD
  Platform Name                                   AMD Accelerated Parallel Processing
Number of devices                                 1
  Device Name                                     Hawaii
  Device Vendor                                   Advanced Micro Devices, Inc.
  Device Vendor ID                                0x1002
  Device Version                                  OpenCL 1.2 AMD-APP (2633.3)
  Driver Version                                  2633.3
  Device OpenCL C Version                         OpenCL C 1.2 
  Device Type                                     GPU
  Device Board Name (AMD)                         AMD Radeon R9 200 Series
  Device Topology (AMD)                           PCI-E, 01:00.0
  Device Profile                                  FULL_PROFILE
  Device Available                                Yes
  Compiler Available                              Yes
  Linker Available                                Yes
  Max compute units                               40
  SIMD per compute unit (AMD)                     4
  SIMD width (AMD)                                16
  SIMD instruction width (AMD)                    1
  Max clock frequency                             947MHz
  Graphics IP (AMD)                               7.2
  Device Partition                                (core)
    Max number of sub-devices                     40
    Supported partition types                     none specified
  Max work item dimensions                        3
  Max work item sizes                             1024x1024x1024
  Max work group size                             256
  Preferred work group size (AMD)                 256
  Max work group size (AMD)                       1024
  Preferred work group size multiple              64
  Wavefront width (AMD)                           64
  Preferred / native vector sizes                 
    char                                                 4 / 4       
    short                                                2 / 2       
    int                                                  1 / 1       
    long                                                 1 / 1       
    half                                                 1 / 1        (n/a)
    float                                                1 / 1       
    double                                               1 / 1        (cl_khr_fp64)
  Half-precision Floating-point support           (n/a)
  Single-precision Floating-point support         (core)
    Denormals                                     No
    Infinity and NANs                             Yes
    Round to nearest                              Yes
    Round to zero                                 Yes
    Round to infinity                             Yes
    IEEE754-2008 fused multiply-add               Yes
    Support is emulated in software               No
    Correctly-rounded divide and sqrt operations  Yes
  Double-precision Floating-point support         (cl_khr_fp64)
    Denormals                                     Yes
    Infinity and NANs                             Yes
    Round to nearest                              Yes
    Round to zero                                 Yes
    Round to infinity                             Yes
    IEEE754-2008 fused multiply-add               Yes
    Support is emulated in software               No
  Address bits                                    64, Little-Endian
  Global memory size                              2471116800 (2.301GiB)
  Global free memory (AMD)                        2398160 (2.287GiB)
  Global memory channels (AMD)                    16
  Global memory banks per channel (AMD)           16
  Global memory bank width (AMD)                  256 bytes
  Error Correction support                        No
  Max memory allocation                           2082456371 (1.939GiB)
  Unified memory for Host and Device              No
  Minimum alignment for any data type             128 bytes
  Alignment of base address                       2048 bits (256 bytes)
  Global Memory cache type                        Read/Write
  Global Memory cache size                        16384 (16KiB)
  Global Memory cache line size                   64 bytes
  Image support                                   Yes
    Max number of samplers per kernel             16
    Max size for 1D images from buffer            134217728 pixels
    Max 1D or 2D image array size                 2048 images
    Base address alignment for 2D image buffers   256 bytes
    Pitch alignment for 2D image buffers          256 pixels
    Max 2D image size                             16384x16384 pixels
    Max 3D image size                             2048x2048x2048 pixels
    Max number of read image args                 128
    Max number of write image args                8
  Local memory type                               Local
  Local memory size                               32768 (32KiB)
  Local memory syze per CU (AMD)                  65536 (64KiB)
  Local memory banks (AMD)                        32
  Max number of constant args                     8
  Max constant buffer size                        2082456371 (1.939GiB)
  Preferred constant buffer size (AMD)            16384 (16KiB)
  Max size of kernel argument                     1024
  Queue properties                                
    Out-of-order execution                        No
    Profiling                                     Yes
  Prefer user sync for interop                    Yes
  Profiling timer resolution                      1ns
  Profiling timer offset since Epoch (AMD)        1527256350447623220ns (Fri May 25 10:52:30 2018)
  Execution capabilities                          
    Run OpenCL kernels                            Yes
    Run native kernels                            No
    Thread trace supported (AMD)                  Yes
    Number of async queues (AMD)                  2
    Max real-time compute queues (AMD)            0
    Max real-time compute units (AMD)             0
    SPIR versions                                 1.2
  printf() buffer size                            4194304 (4MiB)
  Built-in kernels                                
  Device Extensions                               cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_image2d_from_buffer cl_khr_spir cl_khr_gl_event 
NULL platform behavior
  clGetPlatformInfo(NULL, CL_PLATFORM_NAME, ...)  No platform
  clGetDeviceIDs(NULL, CL_DEVICE_TYPE_ALL, ...)   No platform
  clCreateContext(NULL, ...) [default]            No platform
  clCreateContext(NULL, ...) [other]              Success [AMD]
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_DEFAULT)  Success (1)
    Platform Name                                 AMD Accelerated Parallel Processing
    Device Name                                   Hawaii
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CPU)  No devices found in platform
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU)  Success (1)
    Platform Name                                 AMD Accelerated Parallel Processing
    Device Name                                   Hawaii
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ACCELERATOR)  No devices found in platform
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CUSTOM)  No devices found in platform
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ALL)  Success (1)
    Platform Name                                 AMD Accelerated Parallel Processing
    Device Name                                   Hawaii

/usr/local/computecpp/bin/computecpp_info

>ComputeCpp Info (CE 0.8.0)
Toolchain information:
GLIBC version: 2.27
GLIBCXX: 20160609
This version of libstdc++ is supported.
Device Info:
Discovered 1 devices matching:
  platform    : <any>
  device type : <any>
Device 0:
  Device is supported                     : UNTESTED - Untested OS
  CL_DEVICE_NAME                          : Hawaii
  CL_DEVICE_VENDOR                        : Advanced Micro Devices, Inc.
  CL_DRIVER_VERSION                       : 2633.3
  CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_GPU 

bazel test -c opt --config=sycl --test_output=all //tensorflow/python/kernel_tests:basic_gpu_test

> INFO: Analysed target //tensorflow/python/kernel_tests:basic_gpu_test (0 packages loaded).
INFO: Found 1 test target...
ERROR: /home/dmitry/Soft/dev/source/TensorFlow/tensorflow/tensorflow/core/BUILD:715:1: C++ compilation of rule '//tensorflow/core:ctc_ops_op_lib' failed (Exit 1)
In file included from tensorflow/core/ops/ctc_ops.cc:17:
In file included from ./tensorflow/core/framework/shape_inference.h:20:
In file included from ./tensorflow/core/framework/node_def_util.h:23:
In file included from ./tensorflow/core/framework/attr_value_util.h:23:
In file included from ./tensorflow/core/framework/partial_tensor_shape.h:20:
In file included from ./tensorflow/core/framework/tensor_shape.h:21:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:163:19: error: no matching member function for call to 'get_access'
    auto ptr =buf.get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::host_buffer>().get_pointer();
              ~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:593:3: note: candidate template ignored: invalid explicitly-specified argument for template parameter 'accessMode'
  get_access() {
  ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:611:53: note: candidate function template not viable: requires single argument 'cgh', but no arguments were provided
  accessor<T, dimensions, accessMode, accessTarget> get_access(
                                                    ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:633:53: note: candidate function template not viable: requires 3 arguments, but 0 were provided
  accessor<T, dimensions, accessMode, accessTarget> get_access(
                                                    ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:653:53: note: candidate function template not viable: requires at least 2 arguments, but 0 were provided
  accessor<T, dimensions, accessMode, accessTarget> get_access(
                                                    ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:670:68: note: candidate function template not viable: requires 2 arguments, but 0 were provided
  accessor<T, dimensions, accessMode, access::target::host_buffer> get_access(
                                                                   ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:684:68: note: candidate function template not viable: requires at least argument 'range', but no arguments were provided
  accessor<T, dimensions, accessMode, access::target::host_buffer> get_access(
                                                                   ^
In file included from tensorflow/core/ops/ctc_ops.cc:17:
In file included from ./tensorflow/core/framework/shape_inference.h:20:
In file included from ./tensorflow/core/framework/node_def_util.h:23:
In file included from ./tensorflow/core/framework/attr_value_util.h:23:
In file included from ./tensorflow/core/framework/partial_tensor_shape.h:20:
In file included from ./tensorflow/core/framework/tensor_shape.h:21:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:61: error: no member named 'map_allocator' in namespace 'cl::sycl'
      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));
                                                  ~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:75: error: unexpected type name 'uint8_t': expected expression
      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));
                                                                          ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:86: warning: expression result unused [-Wunused-value]
      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));
                                                                                     ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:31: error: expected unqualified-id
        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);
                              ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:107: error: nested name specifier 'cl::sycl::access::target::' for declaration does not refer into a class, class template or class template partial specialization
        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);
                                                                                ~~~~~~~~~~~~~~~~~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:120: error: expected ';' at end of declaration
        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);
                                                                                                                       ^
                                                                                                                       ;
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:62: error: no member named 'map_allocator' in namespace 'cl::sycl'
      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));
                                                   ~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:76: error: unexpected type name 'uint8_t': expected expression
      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));
                                                                           ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:87: warning: expression result unused [-Wunused-value]
      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));
                                                                                      ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:32: error: expected unqualified-id
        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);
                               ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:117: error: nested name specifier 'cl::sycl::access::target::' for declaration does not refer into a class, class template or class template partial specialization
        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);
                                                                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:130: error: expected ';' at end of declaration
        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);
                                                                                                                                 ^
                                                                                                                                 ;
2 warnings and 11 errors generated.
Target //tensorflow/python/kernel_tests:basic_gpu_test failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 10.427s, Critical Path: 9.81s
INFO: 4 processes, local.
FAILED: Build did NOT complete successfully
Executed 0 out of 1 test: 1 fails to build"
19556,[Feature request] Backpropagation through Dataset API,"It would be cool if the Dataset API would support backpropagation.

Currenty I'm working on a statistical model with per-sample weights. 
Therefore, I have to pass sample indices through the Dataset API and index the weights manually.

[See my question (especially Allen Lavoie's comment) on stackoverflow.](https://stackoverflow.com/questions/50155021/tensorflow-dataset-api-gradient-is-none?noredirect=1#comment87464556_50155021)


------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: none
- **GCC/Compiler version (if compiling from source)**: none
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**: none
"
19554,TF for mobile,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19551,Cannot use AdagradOptimizer with MirroredStrategy,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072 1.8.0
- **Python version**: 3.6.3 64-bit
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0 / 6.0
- **GPU model and memory**: Nvidia GTX 1080 8 GB 
- **Exact command to reproduce**: `python train_model.py`

### Describe the problem
It took me a while to work out what was going on, but it seems that  tf.train.AdagradOptimizer has some specific implementation detail that causes an error when used with MirroredStrategy. I did a spot check with GradientDescentOptimizer and RMSPropOptimizer and they both appear to work in my environment. I'm happy to use a different optimizer as a workaround but I thought at the very least this might save others some time hunting down the cause of the error!

### Source code / logs
This is almost exactly copied from the example at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distribute (except for the choice of optimizer)

    import tensorflow as tf

    def model_fn(features, labels, mode):
        layer = tf.layers.Dense(1)
        logits = layer(features)

        if mode == tf.estimator.ModeKeys.PREDICT:
            predictions = {""logits"": logits}
            return tf.estimator.EstimatorSpec(mode, predictions=predictions)

        loss = tf.losses.mean_squared_error(
                labels=labels, predictions=tf.reshape(logits, []))

        if mode == tf.estimator.ModeKeys.EVAL:
            return tf.estimator.EstimatorSpec(mode, loss=loss)

        if mode == tf.estimator.ModeKeys.TRAIN:
            train_op = tf.train.AdagradOptimizer(0.2).minimize(loss)
            return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)

    def input_fn():
        features = tf.data.Dataset.from_tensors([[1.]]).repeat(100)
        labels = tf.data.Dataset.from_tensors(1.).repeat(100)
        return tf.data.Dataset.zip((features, labels))

    distribution = tf.contrib.distribute.MirroredStrategy()
    config = tf.estimator.RunConfig(train_distribute=distribution)
    classifier = tf.estimator.Estimator(model_fn=model_fn, config=config)
    classifier.train(input_fn=input_fn)

Log output:

    2018-05-25 15:30:12.300908: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
    2018-05-25 15:30:14.231174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
    name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898
    pciBusID: 0000:03:00.0
    totalMemory: 7.93GiB freeMemory: 7.81GiB
    2018-05-25 15:30:14.557081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties: 
    name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.898
    pciBusID: 0000:81:00.0
    totalMemory: 7.93GiB freeMemory: 7.81GiB
    2018-05-25 15:30:14.557174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
    2018-05-25 15:30:15.198082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
    2018-05-25 15:30:15.198134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
    2018-05-25 15:30:15.198142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N 
    2018-05-25 15:30:15.198145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N 
    2018-05-25 15:30:15.198488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7542 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
    2018-05-25 15:30:15.324510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7543 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)
    WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpqglycjzk
    2018-05-25 15:30:15.455314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1
    2018-05-25 15:30:15.455414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
    2018-05-25 15:30:15.455423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 
    2018-05-25 15:30:15.455427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N N 
    2018-05-25 15:30:15.455431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   N N 
    2018-05-25 15:30:15.455615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 7542 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
    2018-05-25 15:30:15.455720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 7543 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080, pci bus id: 0000:81:00.0, compute capability: 6.1)
    Traceback (most recent call last):
      File ""train_model.py"", line 62, in <module>
        classifier.train(input_fn=input_fn)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 363, in train
        loss = self._train_model(input_fn, hooks, saving_listeners)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 841, in _train_model
        return self._train_model_distributed(input_fn, hooks, saving_listeners)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py"", line 884, in _train_model_distributed
        self.config)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/distribute.py"", line 756, in call_for_each_tower
        return self._call_for_each_tower(fn, *args, **kwargs)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 254, in _call_for_each_tower
        coord.join(threads)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
        six.reraise(*self._exc_info_to_raise)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/six.py"", line 693, in reraise
        raise value
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 297, in stop_on_exception
        yield
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py"", line 248, in _call_for_each_tower
        self, *merge_args, **merge_kwargs)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 671, in _distributed_apply
        self._create_slots(var_list)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/training/adagrad.py"", line 66, in _create_slots
        with ops.colocate_with(v):
      File ""/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py"", line 81, in __enter__
        return next(self.gen)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 4186, in _colocate_with_for_gradient
        with self.colocate_with(op, ignore_existing):
      File ""/home/aeiq/.pyenv/versions/3.6.3/lib/python3.6/contextlib.py"", line 81, in __enter__
        return next(self.gen)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 4239, in colocate_with
        op = internal_convert_to_tensor_or_indexed_slices(op, as_ref=True).op
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1262, in internal_convert_to_tensor_or_indexed_slices
        value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1104, in internal_convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/home/aeiq/.local/share/virtualenvs/echoiq-308-HW9bcZ4A/lib/python3.6/site-packages/tensorflow/contrib/distribute/python/values.py"", line 243, in _tensor_conversion
        assert not as_ref
    AssertionError

"
19550,"Output of Two .pb files why the outputs are different , How to make them same.",">>> gf.ParseFromString(open('OptimizedGraph.pb','rb').read())5713824
>>> [n.name + '=>' +  n.op for n in gf.node if n.op in ( 'Softmax','Placeholder')]
[u'inputTensor=>Placeholder', u'dropout_keep_prob=>Placeholder']
>>> gf.ParseFromString(open('test.pb','rb').read())4543637
>>> [n.name + '=>' +  n.op for n in gf.node if n.op in ( 'Softmax','Placeholder')]
[u'inputTensor=>Placeholder', u'dropout_keep_prob=>Placeholder', u'output/softmax=>Softmax']
"
19549,Export GRPC symbols along with the C API,"Hi,

Given the recent changes to the eager API, that requires GRPC, the eager API cannot be used by external libraries, because it cannot link to the GRPC symbols in TensorFlow. A possible solution is to add `*grpc*` to the C API version script. @asimshankar @alextp is it ok if I make a PR to add that?

Thanks,
Anthony"
19548,Inference accuracy depends on batch size,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: r1.8
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 4.9
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: 16GB
- **Exact command to reproduce**: pip3 install tensorflow_gpu-1.8.0-cp35-cp35m-manylinux1_x86_64.whl

### Describe the problem
The inference accuracy of a trained model for image recognition, e.g. ResNet-18, Incpetion_v3, depends on the batch size. For example, if the batch size of the input is set to one, the accuracy is around 0.2. However, if feed 32 images at ones, the accuracy becomes over 0.82... If feed even more images at ones, the accuracy can even increase... This is really strange.

### Source code / logs
The model will classify 16 categories.  Images for training and validating are subsets of imagenet. (Over 223,918 training images and 22, 016 validating images)

1. The input size for training is set as:
```
tf.placeholder(tf.float32, [None im_height, im_width, n_channel], name = ""input_x"")
```

2. data is feeded by dataset  from tfrecord. 
```
dataset = tf.data.TFRecordDataset(filename)
dataset = dataset.map(tfrecord_parser).prefetch(buffer_size = 4 * batch_size).batch(batch_size)
```

3. model loading from pb file
```
def load_pb_graph(frozen_graph_file):
    with tf.gfile.GFile(frozen_graph_file, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        
    with tf.Graph().as_default() as graph:
        tf.import_graph_def(graph_def, name="""")
    
    return graph, graph_def
```

4. Computation of accuracy
```
with g2.as_default():        
    in_logits = tf.placeholder(tf.float32, [None, FLAGS.n_class])
    in_labels = tf.placeholder(tf.float32, [None, FLAGS.n_class])
    accuracy = tf.metrics.accuracy(tf.argmax(in_logits, 1), tf.argmax(in_labels, 1))[1]
        
    sess2 = tf.Session(graph = g2, config = config)
    sess2.run(tf.global_variables_initializer())
    sess2.run( tf.local_variables_initializer())
....
_logits = sess.run(logits, feed_dict = val_feed_dict) 
_accuacy = sess2.run(accuracy, {in_logits: _logits, in_labels: val_batch_y})
```

Feeding one image for inference:
> 2018-05-24 21:14:36 Step 22016 : Validation Accuracy:0.21825 

Feeding 16 images for inference：
> 2018-05-24 21:16:22 Step 22016 : Validation Accuracy:0.80069

Feeding 32 images for inference :
> 2018-05-24 21:18:14 Step 22016 : Validation Accuracy:0.81486

Feeding 128 images for inference:
> 2018-05-24 21:22:42 Step 22016 : Validation Accuracy:0.82744

"
19547,TFServing returns inconsistent predict result under stress load,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**: latest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 
- **CUDA/cuDNN version**:
- **GPU model and memory**:CPU only
- **Exact command to reproduce**:

### Describe the problem
We trained a model and use TFServing to Predict API to return the matched result. When we run our test scripts in single threaded, we can get the same result every time. But when we run the scripts in 2 threads, or run them in multiple machines, sometimes we the returned result is slightly (10%) different from the original one. The more threads we use, the more frequent the result become inconsistent. After we added a lock/unlock when calling ""TF_RETURN_IF_ERROR(bundle->session->Run(run_options, input_tensors, output_tensor_names, {}, &outputs, &run_metadata));"" in SaveModelPredict() in tensorflow_serving/servables/tensorflow/predict_impl.cc, the issue got suppressed.

"
19546,Estimator API for DQN?,"Hello,
This is my first time using Estimator API. I'm trying to use Estimator to train a DQN on multiple GPUs. Here is my code:
```python
import tensorflow as tf
import numpy as np
from constants import *

class Net:
    def __init__(self, n_state, n_action, dueling=False, grad_clip=10, double_q=True):
        self.n_state = n_state
        self.n_action = n_action
        self.dueling = dueling
        self.grad_clip = grad_clip
        self.double_q = double_q

        params ={'lr':LR_NN,
                 'eps':1e-3,
                 'gamma':DISCOUNT_FACTOR,
                 'double_q':double_q,
                 'grad_clip':grad_clip,
                 'n_action':n_action}

        self.model = tf.estimator.Estimator(model_fn=tf.contrib.estimator.replicate_model_fn(self._model_fn), params=params)

    def _inference(self, state_in, scope_name, reuse=None):
        with tf.variable_scope(scope_name, reuse=reuse):
            h1 = tf.layers.conv2d(state_in, CONV1_SIZE, CONV1_KERNEL, CONV1_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))
            h2 = tf.layers.conv2d(h1, CONV2_SIZE, CONV2_KERNEL, CONV2_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))
            h3 = tf.layers.conv2d(h2, CONV3_SIZE, CONV3_KERNEL, CONV3_STRIDE, padding='same', activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))
            h4 = tf.layers.dense(tf.layers.flatten(h3), 256, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.variance_scaling_initializer(2.0))
            if self.dueling:
                V = tf.layers.dense(h4, 1)
                A = tf.layers.dense(h4, self.n_action)
                Q = A + V - tf.reduce_mean(A, 1, keepdims=True)
            else:
                Q = tf.layers.dense(h4, self.n_action)
        return Q

    def _model_fn(inp, mode, params):
        s = inp['s']
        a = inp['a']
        r = inp['r']
        ns = inp['ns']
        d = inp['d']

        online_Q = self._inference(s, 'online')
        target_Q = self._inference(ns, 'target')
        next_online_Q = self._inference(ns, 'online', reuse=True)

        if params['double_q']:
            best = tf.reduce_sum(target_Q*tf.one_hot(tf.argmax(next_online_Q, axis=1), params['n_action']), axis=1, keepdims=True)
        else:
            best = tf.reduce_max(target_Q, axis=1, keepdims=True)
        target = r + (1.0 - d)*params['gamma']*tf.stop_gradient(best)
        pred = tf.reduce_sum(online_Q*tf.one_hot(a, params['n_action']), axis=1, keepdims=True)

        loss = tf.losses.huber_loss(target, pred, reduction=tf.losses.Reduction.MEAN)

        optimizer = tf.train.AdamOptimizer(params['lr'], epsilon=params['eps'])
        optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)

        if mode == tf.estimator.ModeKeys.TRAIN:
            if params['grad_clip'] is not None:
                grads = optimizer.compute_gradients(loss)
                for i, (grad, var) in enumerate(grads):
                    if grad is not None:
                        grads[i] = (tf.clip_by_norm(grad, params['grad_clip']), var)
                optimizer_op = optimizer.apply_gradients(grads)
            else:
                optimizer_op = optimizer.minimize(loss)

            return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=optimizer_op)
        elif mode == tf.estimator.ModeKeys.PREDICT:
            pred_action = tf.argmax(online_Q)
            return tf.estimator.EstimatorSpec(mode=mode, predictions=pred_action)

if __name__ == '__main__':
    sess = tf.InteractiveSession()
    nn = Net(n_state=(84,84,4), n_action=4)
    sess.run(tf.global_variables_initializer())
    s = np.random.rand(32, 84, 84, 4)
    ns = np.random.rand(32, 84, 84, 4)
    a = np.random.randint(4, size=32)
    r = np.random.randint(30, size=32).reshape(-1,1)
    d = np.random.randint(2, size=32).reshape(-1,1)
    inp = {}
    inp['s'] = np.array(s)
    inp['a'] = np.array(a)
    inp['r'] = np.array(r)
    inp['ns'] = np.array(ns)
    inp['d'] = np.array(d)

    input_f = tf.estimator.inputs.numpy_input_fn(x=inp, batch_size=32, shuffle=False)
    nn.model.train(input_fn=input_f, steps=1)
```

The output/error when running the last (final) line:
```python
INFO:tensorflow:Calling model_fn.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-7-1a67111ae305> in <module>()
----> 1 nn.model.train(input_fn=input_f, steps=1)

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    361 
    362       saving_listeners = _check_listeners_type(saving_listeners)
--> 363       loss = self._train_model(input_fn, hooks, saving_listeners)
    364       logging.info('Loss for final step: %s.', loss)
    365       return self

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1053       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1054     else:
-> 1055       return self._train_model_default(input_fn, hooks, saving_listeners)
   1056 
   1057   def _train_model_default(self, input_fn, hooks, saving_listeners):

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1066       worker_hooks.extend(input_hooks)
   1067       estimator_spec = self._call_model_fn(
-> 1068           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
   1069       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
   1070                                              hooks, global_step_tensor,

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)
   1041 
   1042     logging.info('Calling model_fn.')
-> 1043     model_fn_results = self._model_fn(features=features, **kwargs)
   1044     logging.info('Done calling model_fn.')
   1045 

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py in replicated_model_fn(features, labels, mode, params, config)
    238         config=config,
    239         devices=devices,
--> 240         local_ps_devices=ps_devices)
    241 
    242     if mode == model_fn_lib.ModeKeys.TRAIN:

~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/estimator/python/estimator/replicate_model_fn.py in _get_loss_towers(model_fn, mode, features, labels, params, config, devices, local_ps_devices, loss_reduction, name_scope_pattern)
    522   tower_specs = []
    523 
--> 524   model_fn_args = util.fn_args(model_fn)
    525   optional_params = {}
    526   if 'params' in model_fn_args:

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/util.py in fn_args(fn)
     60     args = tf_inspect.getfullargspec(fn).args
     61     if _is_bounded_method(fn):
---> 62       args.remove('self')
     63   return tuple(args)
     64 

ValueError: list.remove(x): x not in list
```

Any idea where the error happens?"
19543,TPUEstimator.evaluate() docstring incorrect for steps param,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: TPUv2-8
- **TensorFlow installed from (source or binary)**: VM disk image as configured by ctpu
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: my_tpu_estimator.evaluate(my_input_fn, steps=None)

### Describe the problem
The docstring for https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimator#evaluate incorrectly states that ```steps``` can be None, but when called in this way it causes a ```ValueError: Evaluate `steps` must be set on TPU. Cannot be `None`.```
"
19541,End of Sequence Error when using tf.estimator with tf.data,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS v7
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0 / 7
- **GPU model and memory**: Titan Xp, 12GB 
- **Exact command to reproduce**: 

### Describe the problem
I am using tf.estimator.train_and_evaluate and tf.data.Dataset to feed data to the estimator:

Input Data function:

```
    def data_fn(data_dict, batch_size, mode, num_epochs=10):
        dataset = {}
        if mode == tf.estimator.ModeKeys.TRAIN:
            dataset = tf.data.Dataset.from_tensor_slices(data_dict['train_data'].astype(np.float32))
            dataset = dataset.cache()
            dataset = dataset.shuffle(buffer_size= batch_size * 10).repeat(num_epochs).batch(batch_size)
        else:
            dataset = tf.data.Dataset.from_tensor_slices(data_dict['valid_data'].astype(np.float32))
            dataset = dataset.cache()
            dataset = dataset.batch(batch_size)

        iterator = dataset.make_one_shot_iterator()
        next_element = iterator.get_next()

    return next_element
```

Train Function:
```
def train_model(data):
    tf.logging.set_verbosity(tf.logging.INFO)
    config = tf.ConfigProto(allow_soft_placement=True,
                            log_device_placement=False)
    config.gpu_options.allow_growth = True
    run_config = tf.contrib.learn.RunConfig(
        save_checkpoints_steps=10,
        keep_checkpoint_max=10,
        session_config=config
    )

    train_input = lambda: data_fn(data, 100, tf.estimator.ModeKeys.TRAIN, num_epochs=1)
    eval_input = lambda: data_fn(data, 1000, tf.estimator.ModeKeys.EVAL)
    estimator = tf.estimator.Estimator(model_fn=model_fn, params=hps, config=run_config)
    train_spec = tf.estimator.TrainSpec(train_input, max_steps=100)
    eval_spec = tf.estimator.EvalSpec(eval_input,
                                      steps=None,
                                      throttle_secs = 30)

    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)
```

The training goes fine, but when it comes to evaluation I get this error:
`OutOfRangeError (see above for traceback): End of sequence `

If I don't use Dataset.batch on evaluation dataset (by omitting the line dataset[name] = dataset[name].batch(batch_size) in data_fn) I get the same error but after a much longer time.

I can only avoid this error if I don't batch the data and use steps=1 for evaluation (does that perform the evaluation on the whole dataset?)

I don't understand what causes this error as the documentation suggests I should be able to evaluate on batches too.

Note: I get the same error when using tf.estimator.evaluate on data batches.

### Source code / logs

```
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 439, in train_and_evaluate
    executor.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 518, in run
    self.run_local()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 657, in run_local
    eval_result = evaluator.evaluate_and_export()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/training.py"", line 847, in evaluate_and_export
    hooks=self._eval_spec.hooks)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 425, in evaluate
    name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 1085, in _evaluate_model
    input_fn, model_fn_lib.ModeKeys.EVAL))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 691, in _get_features_and_labels_from_input_fn
    result = self._call_input_fn(input_fn, mode)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py"", line 798, in _call_input_fn
    return input_fn(**kwargs)
  File ""/snel/home/mreza/projects/PBT_HP_opt/lfadslite/lfadslite.py"", line 748, in <lambda>
    eval_input = lambda: self.data_fn(hps, tf.estimator.ModeKeys.EVAL)
  File ""/snel/home/mreza/projects/PBT_HP_opt/lfadslite/lfadslite.py"", line 112, in data_fn
    next_element = iterator.get_next()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 370, in get_next
    name=name)), self._output_types,
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 1466, in iterator_get_next
    output_shapes=output_shapes, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

OutOfRangeError (see above for traceback): End of sequence
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,200,29]], output_types=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](OneShotIterator)]]

```"
19536,How to link tensorflow contrib module in C API,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: Binary wheel (tensorflow-gpu)
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: Python 3.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: 1080 GTX / 8GB
- **Exact command to reproduce**: -

----------------

Using python, I have built a graph that relies on tensorflow.contrib.resampler and exported it to a .pb file. I am able to correctly import and execute that graph in python, by adding the following lines to my script:
    import tensorflow as tf
    tf.contrib.resampler

However, when I try to import and execute that graph in plain C (c_api.h), I get the following error:
    Failed to process frame with No OpKernel was registered to support Op 'Resampler' with these attrs.
    Registered devices: [CPU,GPU], Registered kernels: <no registered kernels>

What is the correct way to register this op and use it in the C API? I have not been able to find any relevant documentation on the matter.

    "
19535,TensorRT: Invalid graph after calibration -> inference graph transformation,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source.
- **TensorFlow version (use command below)**:
1.8
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.13.0
- **GCC/Compiler version (if compiling from source)**:
gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.9)
- **CUDA/cuDNN version**:
9.0.176/7.0.5.15
- **GPU model and memory**:
1080 Ti
- **Exact command to reproduce**:

### Describe the problem

It seems that `tf.contrib.tensorrt` may incorrectly redirect edges when transforming an INT8 calibration node into an engine node. The current implementation, for each output node, searches the first edge from this output node [1] and redirects only this edge to point from the newly created engine node [2]. If the output node has multiple outgoing edges, then only the first one is redirected, and the remaining edges still use the output node as the source. As a result, after the output node is deleted, the graph becomes invalid and the graphdef generated by `tf.contrib.tensorrt.calib_graph_to_infer_graph` cannot be loaded (e.g., using `TF_GraphImportGraphDef`) due to errors like this: `Node 'Shape_4': Unknown input node 'group1/block1/Relu'`. (In this case, `group1/block1/Relu` had two edges in the original graph: to some convolution node and to `Shape_4`; the first edge was updated, the second one was not and caused the error.)

[1] https://github.com/tensorflow/tensorflow/blob/717aa746e7e915cba9ce36df424d05642fbe8cd7/tensorflow/contrib/tensorrt/convert/convert_nodes.cc#L2191
[2] https://github.com/tensorflow/tensorflow/blob/717aa746e7e915cba9ce36df424d05642fbe8cd7/tensorflow/contrib/tensorrt/convert/convert_nodes.cc#L2258"
19530,"transforms_graph error when ""remove_nodes(op=Identity, op=CheckNumerics)"" and ""fold_old_batch_norms"" are used together","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.8
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.0
- **GCC/Compiler version (if compiling from source)**: 4.9
- **CUDA/cuDNN version**: No
- **GPU model and memory**: No
- **Exact command to reproduce**: ` bazel build tensorflow/tools/graph_transforms:transform_graph`

### Describe the problem
I followed the proposed commands for optimizing the model. However, ""remove_node(op=Identity, op=CheckNumerics)"" and ""fold_old_batch_norms"" cannot be used together.

### Source code / logs
```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=resnet-18_train.pb \
--out_graph=opt_resnet-18_train.pb \
--inputs='input_x' \
--outputs='output/BiasAdd' \
--transforms='
strip_unused_nodes(type=float, shape=""1,224,224,3"")
remove_nodes(op=Identity, op=CheckNumerics)
fold_old_batch_norms
fold_batch_norms'
```
Error:
> 2018-05-24 20:53:06.184534: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying strip_unused_nodes
2018-05-24 20:53:06.259019: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying remove_nodes
2018-05-24 20:53:06.486037: I tensorflow/tools/graph_transforms/transform_graph.cc:264] Applying fold_old_batch_norms
2018-05-24 20:53:06.513047: E tensorflow/tools/graph_transforms/transform_graph.cc:210] Beta input to batch norm has bad shape: [64]

However, if ""remove_node(op=Identity, op=CheckNumerics)"" is removed
```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=resnet-18_train.pb \
--out_graph=opt_resnet-18_train.pb \
--inputs='input_x' \
--outputs='output/BiasAdd' \
--transforms='
strip_unused_nodes(type=float, shape=""1,224,224,3"")
fold_old_batch_norms
fold_batch_norms'
```
It then works...

"
19529,how to save intermediate checkpoints when using slim.learning.train ,"I have trained classification model using inception_resnet_v2, and I set max_train_steps equals 15w steps. However, according to loss graph on tensorboard, I found the minimum loss at  2w steps. I also set `save_interval_secs=600`, I need this model at 2w steps rather than 15w steps, but tensorflow only save the last model. so, how can i get the intermediate checkpoints?"
19528,Restore problem when work with multiple tf.contrib.lookup.MutableHashTable,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 3.10.0-693.2.2.el7.x86_64
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: Python 2.7.14 :: Anaconda
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: See below

### Describe the problem
We try to use multiple tf.contrib.lookup.MutableHashTable objects in the script. But after do checkpoint with Saver.save(), we find that it can not restore table contents successfully. 

The problem disappears if we explicitly specify name field for tables. It seems that the MutableHashTable save contents with spec key ""xxxx-keys"" and ""xxxx-values"", where ""xxxx"" is the object's name field defaults to ""MutableHashTable"".

https://github.com/tensorflow/tensorflow/blob/93bc2e2072e0daccbcff7a90d397b704a9e8f778/tensorflow/contrib/lookup/lookup_ops.py#L463-L467

Maybe it is better to associate unique name for each table object if not explicitly specified?

### Source code / logs
Create and insert tables, and save
```python
keys = tf.placeholder(dtype=tf.string, shape=[None])
values = tf.placeholder(dtype=tf.int64, shape=[None])
table1 = tf.contrib.lookup.MutableHashTable(tf.string, tf.int64, -1)
table2 = tf.contrib.lookup.MutableHashTable(tf.string, tf.int64, -1)
insert_table1 = table1.insert(keys, values)
insert_table2 = table2.insert(keys, values)
saver = tf.train.Saver()
with tf.Session() as sess:
    sess.run(insert_table1, feed_dict={keys: [""a""], values: [1]})
    sess.run(insert_table2, feed_dict={keys: [""b""], values: [2]})
    print ""table1:"", sess.run(table1.export())
    print ""table2:"", sess.run(table2.export())
    saver.save(sess, ""checkpoint/test"")
```
table1: (array(['a'], dtype=object), array([1]))
table2: (array(['b'], dtype=object), array([2]))

Try restore contents
```python
table1 = tf.contrib.lookup.MutableHashTable(tf.string, tf.int64, -1)
table2 = tf.contrib.lookup.MutableHashTable(tf.string, tf.int64, -1)
saver = tf.train.Saver()
with tf.Session() as sess:
    saver.restore(sess, ""checkpoint/test"")
    print ""table1:"", sess.run(table1.export())
    print ""table2:"", sess.run(table2.export())
```
table1: (array([], dtype=object), array([], dtype=int64))
table2: (array(['b'], dtype=object), array([2]))"
19527,SIGSEGV at TensorFlowInferenceInterface.run,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution** : Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary, pip
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7
- **GPU model and memory**:
- **Exact command to reproduce**:

I'm running Inference on an small Style Transfer Model on Android using TF Mobile.
My App crashes on Motorola Nexus 6 with the following Error after i call:

`inferenceInterface.run(new String[]{OUTPUT_NODE});`

 **Fatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 24385**
[log.txt](https://github.com/tensorflow/tensorflow/files/2034709/log.txt)

I'm using Andoird Studio and integrated TFMobile on Android using the AAR:
```
allprojects {
    repositories {
        jcenter()
    }
}

dependencies {
    implementation 'org.tensorflow:tensorflow-android:+'
}
```
I'm using a model similar to the popular feed forward model described by Johnson and optimized using graph transform tool:

```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=wave.pb \
--out_graph=wave_optimized.pb \
--inputs='input_image' \
--outputs='output_image' \
--transforms='
  add_default_attributes
  strip_unused_nodes
  remove_nodes(op=Identity, op=CheckNumerics)
  fuse_resize_and_conv
  fuse_resize_pad_and_conv
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  quantize_weights
  strip_unused_nodes
  sort_by_execution_order'
```

- It only happens if the input image size gets to large, e.g. 600x600. So it could be simply a memory / CPU problem.
- **But** it seems to be phone specific: I can scale up the images up to 1200x1200 on other phones and the app doesn't crash (it only takes for about 10 seconds)
- I'm not doing Real-Time-Style-Transfer as in the TF Stylize App, i simply run inference on selected images and i'm testing with different input sizes

I know the error may be hard to reproduce and the main focus is now on TFLite (but TFLite doesn't support Style Transfer yet, as far as i know).
I could also life with the fact that i have to further downscale the images to avoid the crash but maybe someone has an idea about: 

- what is going wrong
- why it only crashes on certain phones
- how i can get more specific information why it crashes

Thanks for any tips

 


"
19526,Node 'output/softmax' does not exist in model 'file:///android_asset/OptimizedGraph.pb',"I trained my model then frozen the graph using the .ckpt file and .pbtxt file  
**Code to freeze:**
 

    freeze_graph.freeze_graph('./tensorflowModel.pbtxt', """",False,'./tfmodel.ckpt', ""output/predictions"", ""save/restore_all"",  ""save/Const:0"",'frozen.pb', True,"""")

Then to **optimize for inference** followed the  below code:

    inputGraph = tf.GraphDef()
    with tf.gfile.Open(""frozen.pb"", ""rb"") as f:
        data2read = f.read()
        inputGraph.ParseFromString(data2read)
    
    outputGraph = optimize_for_inference_lib.optimize_for_inference(
                    inputGraph,
                    [""inputTensor""], # an array of the input node(s)
                    [""output/predictions""], # an array of output nodes
                    tf.int32.as_datatype_enum)
    
            # Save the optimized graph
    
    f = tf.gfile.FastGFile(""OptimizedGraph.pb"", ""w"")
    f.write(outputGraph.SerializeToString())  

 

The output file **""OptimizedGraph.pb"",** When I try to use it in the android studio it produces the error:

     Node 'output/softmax' does not exist in model 'file:///android_asset/OptimizedGraph.pb'


I checked my .pbtxt file which I used to freeze my graph and there was no node **output/softmax**!

What should I do?
"
19525,How to use grap_transfroms tools?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes and No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: Source 
- **TensorFlow version (use command below)**: 1.7
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 9 / 7
- **GPU model and memory**: 4GB GTX 1050
- **Exact command to reproduce**:

I want to use the graph_transforms tools but i dont know how to use them correctly:

As far as i know you have to run the commands like
```
bazel build tensorflow/tools/graph_transforms:summarize_graph
bazel-bin/tensorflow/tools/graph_transforms/summarize_graph --in_graph=tensorflow_inception_graph.pb
```
from inside the cloned tensorflow repo from which you successfull build tf from source.

But then i see errors like:
```
ERROR: /home/gustav/.cache/bazel/_bazel_gustav/0efb90387e9af20adf0714a85702521f/external/jpeg/BUILD:126:12: Illegal ambiguous match on configurable attribute ""deps"" in @jpeg//:jpeg:
@jpeg//:k8
@jpeg//:armeabi-v7a
Multiple matches are not allowed unless one is unambiguously more specialized.
Unhandled exception thrown during build; message: Unrecoverable error while evaluating node 'PACKAGE:tensorflow/core/kernels' (requested by nodes '//tensorflow:libtensorflow_framework.so com.google.devtools.build.lib.skyframe.BuildConfigurationValue$Key@fedf386b false (700629378)', '//tensorflow/core:framework_internal_headers_lib_gather com.google.devtools.build.lib.skyframe.BuildConfigurationValue$Key@fedf386b false (744921750)')

```
and
```
FAILED: Build did NOT complete successfully (33 packages loaded)
    currently loading: tensorflow/core/kernels ... (3 packages)
java.lang.RuntimeException: Unrecoverable error while evaluating node 'PACKAGE:tensorflow/core/kernels' (requested by nodes '//tensorflow:libtensorflow_framework.so com.google.devtools.build.lib.skyframe.BuildConfigurationValue$Key@fedf386b false (700629378)', '//tensorflow/core:framework_internal_headers_lib_gather com.google.devtools.build.lib.skyframe.BuildConfigurationValue$Key@fedf386b false (744921750)')

```
"
19524,Compiling C++ inference with -O1 produces wrong results,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Not in the tensorflow, but I have a code that utilizes C++ API

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux VirtualBox 4.13.0-41-generic #46~16.04.1-Ubuntu SMP Thu May 3 10:06:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux - running in VirtualBox on a Windows Host

- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
tf.VERSION = 1.8.0-rc1
tf.GIT_VERSION = v1.8.0-rc1-1239-gd0f5bc1
tf.COMPILER_VERSION = v1.8.0-rc1-1239-gd0f5bc1
Sanity check: array([1], dtype=int32)
- **Python version**: 
Python 2.7.12

- **Bazel version (if compiling from source)**:
Build label: 0.13.0
Build target: bazel-out/k8-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Oct 18 21:33:40 +50297 (1525078013620)
Build timestamp: 1525078013620
Build timestamp as int: 1525078013620

- **GCC/Compiler version (if compiling from source)**:
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609

- **CUDA/cuDNN version**:
No

- **GPU model and memory**:
No

- **Exact command to reproduce**:
Please see below
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I'm using a model I built in Python to run inference in C++ and compare the results to the ones I got when running it in Python. I save the exact batches I fed in Python and feed them in C++. When I use the default build settings I get very close results. However, I've found that matrix calclulations I performs with the results are incredibly slow (3 minutes for matrix division of 2 1000 by 5 matrices - I will submit a separate issue for that). So I tried to compile with -O1. 
The result returned by running the inference very different now from the expected one.
Please clarify what is going on here.

So without optimization I get:
LoadModel passed!
Iteration 1
outputs[0]: Tensor<type: float shape: [1,5] values: [0.928591609 0.129222199 1.01102]...> <== Inferred by C++
output_tensor Tensor<type: float shape: [1,1,5] values: [[0.928591728 0.129222214 1.01102006]]...> <== Inferred by Python

With -O1:
LoadModel passed!
Iteration 1
outputs[0]: Tensor<type: float shape: [1,5] values: [0.907290399 0.124970555 1]...> <== Inferred by C++

output_tensor Tensor<type: float shape: [1,1,5] values: [[0.928591728 0.129222214 1.01102006]]...><== Inferred by Python

diff is bigger than expected: 0.0445271
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
[optimization_problem_tensorflow.zip](https://github.com/tensorflow/tensorflow/files/2034485/optimization_problem_tensorflow.zip)

"
19523,[tensorflow/tools/graph_transforms] No scripts / files in the installed tensorflow directory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes and No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: Source 
- **TensorFlow version (use command below)**: 1.7
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 9 / 7
- **GPU model and memory**: 4GB GTX 1050
- **Exact command to reproduce**:

I try to use the `summarize_graph` and `transform_graph` tools but inside my `/usr/local/lib/python2.7/dist-packages/tensorflow/tools/graph_transforms` directory there is nothing besides the __init__.py and __pyc files.

Why do i lack these tools / scripts and how do I get them?

I always see errors like this:
```
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
..............................
ERROR: Skipping 'tensorflow/tools/graph_transforms:summarize_graph': no such package 'tensorflow/tools/graph_transforms': BUILD file not found on package path
WARNING: Target pattern parsing failed.
ERROR: no such package 'tensorflow/tools/graph_transforms': BUILD file not found on package path
INFO: Elapsed time: 3.386s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```
"
19522,how to alter predefined network architecture and reuse the pretrained model please?,"hi，all , I'm faced with a problem.
I predefined a neural network architecture, simply, conv->pooling->conv->pooling->FC->softmax, then I trained the network with tensorflow also obtained checkpoint and models in directory: /mnist_convnet_model
Next, I want to reload the model. This time I need to alter the network's architecture, but still, weights pretrained needed to be reloaded.  The pretrained weights and the new nerual architecture do not match exactly but part of previous trained info is needed.
What should I do? Is there any API available please ?
Thx!"
19521,[TFlite] unable to bazel build tensorflow/contrib/lite/toco:toco,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes and No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04)
- **TensorFlow installed from (source or binary)**: Source 
- **TensorFlow version (use command below)**: 1.7
- **Python version**:  2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: 9 / 7
- **GPU model and memory**: 4GB GTX 1050
- **Exact command to reproduce**:

i trained a mask r-cnn model with mobilenet as backbone and i try to quantize it according to this guide: https://www.tensorflow.org/performance/quantization 

My code looks like this:
```
MODEL_NAME=""mask_rcnn_mobilenet_v1_400_coco_117k""

INPUT_FILE=""models/${MODEL_NAME}/frozen_inference_graph.pb""
OUTPUT_FILE=""models/${MODEL_NAME}/frozen_inference_graph.tflite""
INPUT_SHAPE=""1,400,400,3""
INPUT_ARRAY=['image_tensor']
OUTPUT_ARRAY=['num_detections','detection_boxes','detection_scores','detection_classes','detection_masks']
STD_VALUE=127.5
MEAN_VALUE=127.5


bazel build tensorflow/contrib/lite/toco:toco && \
  ./bazel-bin/third_party/tensorflow/contrib/lite/toco/toco \
  --input_file=${INPUT_FILE} \
  --output_file=${OUTPU_FILE} \
  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --input_shape=${INPUT_SHAPE} \
  --input_array=${INPUT_ARRAY} \
  --output_array=${OUTPUT_ARRAY} \
  --std_value=${STD_VALUE} --mean_value=${MEAN_VALUE}
```
and this error i get:
```
ERROR: Skipping 'tensorflow/contrib/lite/toco:toco': no such package 'tensorflow/contrib/lite/toco': BUILD file not found on package path
WARNING: Target pattern parsing failed.
ERROR: no such package 'tensorflow/contrib/lite/toco': BUILD file not found on package path
INFO: Elapsed time: 1.132s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```


Another thing i don't understand is that when i try to run this code in my custom model folder i see this error:
`ERROR: The 'build' command is only supported from within a workspace.`

What is this supposed to mean?

So i tried it in the tensorflow/models"
19520,Why there is no C  GPU based tensorflow for windows?,"I have seen that there are only Linux and MacOS based installations for the C language.
Kindly let me know if there is any tensorflow for the Windows in C langauage."
19518,Hello every one. I tried to export the models to a compact format. I used the following command ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19517,Support on TPU for tf.contrib.framework.sort,"We tried to train with TPU on our model which needs to sort a tensor along an axis. Using  tf.contrib.framework.sort results in the following error:
```
NotFoundError (see above for traceback): No registered 'TopKV2' OpKernel for XLA_TPU_JIT devices compatible with node TPUReplicate/loop/resnet/unit_2_4/sub1/conv1/sort/TopKV2 = TopKV2[T=DT_FLOAT, sorted=true, _device=""/device:TPU_REPLICATED_CORE""](TPUReplicate/loop/resnet/unit_2_4/sub1/conv1/sort/transpose, TPUReplicate/loop/resnet/unit_2_4/sub1/conv1/sort/strided_slice)
```

Are there any alternatives? 

Have I written custom code: N/A
OS Platform and Distribution: ubuntu
TensorFlow installed from: official
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: TPU on gcloud
Exact command to reproduce: any training script using tf.contrib.framework.sort"
19516,Windows can't build toco library by bazel (bazel build //tensorflow/contrib/lite/toco:toco),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: I user command (pip install tensorflow)
- **TensorFlow version (use command below)**: Version: 1.7.1
- **Python version**:  Python 3.6.4 :: Anaconda
- **Bazel version (if compiling from source)**:  Build label: 0.13.0
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:  bazel build //tensorflow/contrib/lite/toco:toco

### Describe the problem
I am trying to run the command ""toco --help"" for tensorflow lite. 
but I get the error ModuleNotFoundError: No module named 'tensorflow.contrib.lite.toco.python'.
so I'm going to build the toco library , when I run the command ""bazel build tensorflow/contrib/lite/toco:toco"" I get the error ""**ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package** "".

### Source code / logs
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading 
[https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz,
https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to C:/users/XXXX/_bazel_XXXX/pqfcltl7/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: []
INFO: Elapsed time: 57.492s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
"
19515,"KeyError: ""The following input nodes were not found: set(['Mul'])\n""","I have a model named rounded_graph.pb that's been produced from the TensorFlow for Poets codelab. Then I should strip the DecodeJpeg Op from model by the following command :

python strip_unused.py --input_graph=rounded_graph.pb --output_graph=output.pb --input_node_names=""Mul"" --output_node_names=""final_result"" --input_binary=true  

But I got the following error :

  File ""strip_unused.py"", line 107, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/eli/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""strip_unused.py"", line 61, in main
    FLAGS.placeholder_type_enum)
  File ""/home/eli/.local/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py"", line 114, in strip_unused_from_files
    placeholder_type_enum)
  File ""/home/eli/.local/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py"", line 83, in strip_unused
    raise KeyError(""The following input nodes were not found: %s\n"" % not_found)
KeyError: ""The following input nodes were not found: set(['Mul'])\n""
eli@eli-virtual-machine:~/Documents/tensorflow-master/tensorflow/python/tools$ python strip_unused.py --input_graph=optimized_graph.pb --output_graph=output.pb --input_node_names=""Mul"" --output_node_names=""final_result"" --input_binary=true 
Traceback (most recent call last):
  File ""strip_unused.py"", line 107, in <module>
    app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/eli/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 126, in run
    _sys.exit(main(argv))
  File ""strip_unused.py"", line 61, in main
    FLAGS.placeholder_type_enum)
  File ""/home/eli/.local/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py"", line 114, in strip_unused_from_files
    placeholder_type_enum)
  File ""/home/eli/.local/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py"", line 83, in strip_unused
    raise KeyError(""The following input nodes were not found: %s\n"" % not_found)
KeyError: ""The following input nodes were not found: set(['Mul'])\n""

If I don't do this before moving the model to APP, ""Error initializing TensorFlow"" will happen when APP run.

What should I do? Please help me, thanks!"
19514,Bug: About tf.Variable and tf.get_variable,"Hi,
    I have a question about tf.Variable and tf.get_variable, it seems that the tf.get_variable cannot share the variables defined by tf.Variable.
    My test code is like this:

```
#! /usr/bin/python
import tensorflow as tf
def main():
	with tf.variable_scope(""scope_1""):
		v1 = tf.Variable([1], name=""v1"", dtype=tf.float32)
	print v1
	with tf.variable_scope(""scope_1"", reuse=True):
		v2 = tf.get_variable(""v1"", [1])
        print v2
if __name__ == ""__main__"":
	main()
```

    The output:

![2018-05-24 10 18 55](https://user-images.githubusercontent.com/18585014/40461001-e46e7094-5f3b-11e8-952b-1656c40ddf03.png)
    Um..., from the first terminal output line, we can see that there exists a variable named ""scope_1/v1:0"", but tf.get_variable still can't find the variable? So, I'm confused about this.
    Can you help me?
    Thank you very much.
    GeWei

"
19513,Cannot use lookup table in dataset when using  Distribute MirroredStrategy,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

tensorflow-gpu 1.8.0

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

![image](https://user-images.githubusercontent.com/12636388/40460717-b398fd3c-5f3a-11e8-946c-85f8c2516951.png)
![image](https://user-images.githubusercontent.com/12636388/40460728-becca0fa-5f3a-11e8-932f-b0cb5b3ed8dd.png)

I use a lookup table in dataset map function, for mapping string labels to digits.
When I use this dataset feed to estimator using MirroredStrategy,
it gives this error.

If using eager mode, it may support this feature,  but estimator is not supported in eager mode

So how can I still keeping lookup table while using MirroredStrategy?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


"
19511,Error in tensorflow in python2.7 ubuntu,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.8
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

(tens) sagar@sagar-HP-Pavilion-Notebook:~/Desktop/neural-vqa-tensorflow/tens$ python
Python 2.7.12 (default, Dec  4 2017, 14:50:18) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
/home/sagar/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/sagar/Desktop/neural-vqa-tensorflow/tens/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/home/sagar/Desktop/neural-vqa-tensorflow/tens/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 82, in <module>
    from tensorflow.python.estimator import estimator_lib as estimator
  File ""/home/sagar/Desktop/neural-vqa-tensorflow/tens/lib/python2.7/site-packages/tensorflow/python/estimator/estimator_lib.py"", line 41, in <module>
    from tensorflow.python.estimator.inputs import inputs
  File ""/home/sagar/Desktop/neural-vqa-tensorflow/tens/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/inputs.py"", line 22, in <module>
    from tensorflow.python.estimator.inputs.numpy_io import numpy_input_fn
  File ""/home/sagar/Desktop/neural-vqa-tensorflow/tens/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/numpy_io.py"", line 26, in <module>
    from tensorflow.python.estimator.inputs.queues import feeding_functions
  File ""/home/sagar/Desktop/neural-vqa-tensorflow/tens/lib/python2.7/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py"", line 40, in <module>
    import pandas as pd
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/pandas/__init__.py"", line 23, in <module>
    from pandas.compat.numpy import *
  File ""/home/sagar/miniconda2/lib/python2.7/site-packages/pandas/compat/__init__.py"", line 420, in <module>
    if LooseVersion(dateutil.__version__) < LooseVersion('2.5'):
AttributeError: 'module' object has no attribute '__version__'
>>> 

"
19510,The name 'softmax:0' refers to a tensor which does not exist.,"Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary (pip)
TensorFlow version (use command below): v1.8.0-0-g93bc2e2072 1.8.0
Python version: 3.5.2
CUDA/cuDNN version: N/A
GPU model and memory: N/A

I have this error: 
`
KeyError: ""The name 'softmax:0' refers to a Tensor which does not exist. The operation, 'softmax', does not exist in the graph.""
`

Here's a part of my code:
```Python
global num_top_predictions
  if not tf.gfile.Exists(image):
    tf.logging.fatal('File does not exist %s', image)
  image_data = tf.gfile.FastGFile(image, 'rb').read()
  with tf.Session() as sess:
    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')
    predictions = sess.run(softmax_tensor,
                           {'DecodeJpeg/contents:0': image_data})
    predictions = np.squeeze(predictions)
    node_lookup = NodeLookup()
    top_k = predictions.argsort()[-num_top_predictions:][::-1]
    results = []
    for node_id in top_k:
      human_string = node_lookup.id_to_string(node_id)
      score = predictions[node_id]
      results.append((human_string, score))
    return results
```
I've made some research and found out that this can be a tensorflow version problem. But I installed a latest version using pip.
Thank you for your help"
19507,Eager metrics not saving as summaries,"I am writing a piece of tf.eager code on the Iris dataset and I'm facing issues when trying to save `Mean` and `Accuracy` as summaries. Here is the piece of code I am using:
```
def evaluate(model, iterator, logdir=None):
    avg_loss = tfe.metrics.Mean('loss')
    accuracy = tfe.metrics.Accuracy('accuracy')

    for inputs, labels in iterator:
        avg_loss(sce(model, inputs, labels))
        accuracy(tf.argmax(model(inputs), axis=1, output_type=tf.int64),
                 tf.argmax(labels, axis=1))
    print(f""Dev set: Average loss: {avg_loss.result()},\
    Accuracy: {100 * accuracy.result()}\n"")
    with tf.contrib.summary.always_record_summaries():
        tf.contrib.summary.scalar('loss', avg_loss.result())
        tf.contrib.summary.scalar('accuracy', accuracy.result())
```

This is almost a copy from the MNIST Eager tutorial (line 82).
The print statement is working great but when it gets into the `with` block I get:
```
File ""./iris.py"", line 131, in train_iris_model
    logdir=logdir, summary_freq=summary_freq)
  File ""./iris.py"", line 98, in fit
    evaluate(model, dev_iterator, logdir=logdir)
  File ""./iris.py"", line 61, in evaluate
    Accuracy: {100 * accuracy.result()}\n"")
  File ""/Users/thms/.virtualenvs/unbabel3/lib/python3.6/site-packages/tensorflow/contrib/eager/python/metrics_impl.py"", line 341, in result
    t = self.numer / self.denom
AttributeError: 'Mean' object has no attribute 'numer'
```

If I understand correctly it means that is is trying to call `.result()` on an unitialized `Mean` object but I don't get why. Is this normal behaviour?

Full code can be found [here](https://github.com/Threynaud/tf-deep-learning/blob/master/tensorflow/tf-eager/iris/iris.py) and run with `./iris.py`

------------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS High Sierra
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 3.6.5"
19505,Tensorflow Lite Python Interpreter Crashes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: b'v1.8.0-2191-gc36266e' 1.8.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.13
- **GCC/Compiler version (if compiling from source)**: c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
mkvirtualenv tf -p /usr/bin/python3
git clone https://github.com/tensorflow/tensorflow
cd tensorflow
git checkout 4dbaa65
./configure
bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
cd ~
pip install /tmp/tensorflow_pkg/tensorflow-1.8.0-cp35-cp35m-linux_x86_64.whl
wget http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz
tar -zxf mobilenet_v1_1.0_224.tgz
python
> import tensorflow as tf
> a = tf.contrib.lite.Interpreter('mobilenet_v1_1.0_224.tflite')
> a.allocate_tensors()
> a.get_input_details()
Segmentation fault (core dumped)

### Describe the problem
Segmentation fault when running the tflite python interpreter.  The Interpreter initializes and allocate_tensors() runs, but other commands result in segfault.

Is the python tflite interface only intended for ARM systems, or should it run on x64 as well?  (I'm running on x64).

### Source code / logs

"
19504,Tensorflow build on Bazel takes longer than 24Hrs,"Hello Guys, I got a question.. I want to get Tensorflow on my Rasberypi 3b+ and found here the Tutorial to build Tensorflow on Bazel.. After several attempts i got it.. to the point wherenitiate TensorFlow  the build with: bazel build -c opt --copt=""-mfpu=neon-vfpv4"" --copt=""-ftree-vectorize"" --copt=""-fomit-frame-pointer"" --local_resources 1024,1.0,1.0 --verbose_failures tensorflow/tools/pip_package:build_pip_package

![img_6831](https://user-images.githubusercontent.com/39053923/40437580-feae0630-5eb5-11e8-86db-e0bed0d5f56b.JPG)

now it stuck since 20 Hours maybe here .. 
it is normal? or im just should still waiting"
19503,"TOCO Quantized InceptionV3 Error: ""tensorflow/contrib/lite/kernels/pooling.cc:116 input->params.scale != output->params.scale""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Minor custom code for quantization but using provided InceptionV3 checkpoints and models/research/slim scripts.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: ('v1.8.0-2169-gb84878e63e', '1.8.0')
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.12.0
- **GCC/Compiler version (if compiling from source)**: gcc version 7.2.0
- **CUDA/cuDNN version**: 9.1/7.1.3
- **GPU model and memory**: NVIDIA P40 (24 GB)
- **Exact command to reproduce**: I link to my script on GitHub below.

### Describe the problem
I've been trying to produce a quantized InceptionV3 model since one is not provided (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md) but it currently fails in the `label_image` demo application due to a MaxPool that has different input/output quantization ranges.

In this TensorFlow Lite announcement video, quantized InceptionV3 is shown to be ~3x faster than floating point (https://youtu.be/FAMfy7izB6A?t=8m40s), so I thought it might work ""out of the box"".
Additionally, in this Google quantization paper the accuracy is shown to be fairly high (https://arxiv.org/abs/1712.05877), which is pretty motivating. 

### Source code / logs
I have a branch of `tensorflow/models` with very minor changes to support quantization: https://github.com/parvizp/models/tree/quantize
You can run the whole script to see the training, TOCO call and call to `label_image`: https://github.com/parvizp/models/blob/279e458ac99da67e405ac74bc5e4583d5111c1bb/research/slim/scripts/quantize_inception_v3_on_imagenet.sh
```
INFO: Running command line: bazel-bin/tensorflow/contrib/lite/examples/label_image/label_image '--tflite_model=/tmp/imagenet-models/inception_v3/inception_v3.quantized.tflite' '--image=/tmp/tensorflow/tensorflow/contrib/lite/examples/label_image/testdata/grace_hopper.bmp' '--labels=/tmp/imagenet/labels.txt'
nnapi error: unable to open library libneuralnetworks.so
Loaded model /tmp/imagenet-models/inception_v3/inception_v3.quantized.tflite
resolved reporter
tensorflow/contrib/lite/kernels/pooling.cc:116 input->params.scale != output->params.scale (-1454358704 != 734155808)
Failed to allocate tensors!
```
The error seems to stem from this MaxPool in the center of:
<img width=""850"" alt=""inception_v3 quantized maxpool-issue"" src=""https://user-images.githubusercontent.com/926261/40436998-d7f6ff38-5e79-11e8-9b1e-6e65f2f20ec9.png"">
To reach the accuracy reported in (https://arxiv.org/abs/1712.05877) should we:
- Add support for TF-Lite MaxPool kernel so it can perform requantization as needed (i.e. for this case)?
- Make TOCO nudge the ranges so all things forking from the cancat and joining have the same range? Could also make the graph re-writer emulate this with shared ranges? 

Seems to preserve more precision and easier to do the first option. I'm happy to provide a patch if you can provide some insight into which direction to pursue."
19501,Tensorflow Estimator API doesn't work in distributed mode,"here is my test code 

```
from tensorflow.python.keras.layers import Conv1D, MaxPooling1D
from tensorflow.python.keras.models import Model
import logging
level = logging.getLevelName('INFO')
logging.getLogger().setLevel(level)
model = tf.keras.Sequential()
output = Dense(2, activation=""softmax"")
model.add(Dense(64, activation=""relu"", input_shape=(10,)))
model.add(output)
model.compile('rmsprop', 'categorical_crossentropy')
est_model = tf.keras.estimator.model_to_estimator(keras_model=model)
train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""dense_2_input"": np.random.randint(10, size=(320, 10))},
        y=np.random.rand(320, 2),
        num_epochs=10000,
        shuffle=False)
est_model.train(train_input_fn)
```

My TF_CONFIG is like is
```
TF_CONFIG={
""cluster"": {""chief"": [""localhost:2223""], 
""worker"": [""localhost:2221""], 
""ps"": [""lcoalhost:2222""]}, 
""task"": {""index"": ""0"", ""type"": ""chief""}
}
```

The chief is stuck on logging 
`INFO:tensorflow:Restoring parameters from /tmp/tmpe_c82nqn/keras_model.ckpt` 
and no ports is listening.
Maybe I can't simulate cluster in local? 

When I using strace to found out why? I saw a lots 
`[pid 16719] futex(0x7f4c39cab604, FUTEX_WAIT_BITSET_PRIVATE, 850, {4401792, 658466075}, ffffffff) = -1 ETIMEDOUT (Connection timed out)`

Without TF_CONFIG set, the code is working fine.

Any suggestion? "
19500,"i took the mine and rock problem based ANN program from edureka and edited it to suit my need which is tripping the transformer for fault current. for training purpose i used a csv input in which i passed 6 featured input values, while passing one desirable output. Now the problem is i want the trained model to work for live values for which i don't have desired output ... i only want to predict the output with the help of trained model ... but it keeps giving an error at the Y input ... How can i make the program run without passing a desired output?","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19499,tf.data.Dataset iterators are not cleaned when the loop ends with a break,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:CentOS7
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.8.0
- **Python version**: 2.7.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
tf.data.Dataset iterators are not cleaned when the loop ends with a `break`.

The code below opens one file per epoch. This eventually hits a system limit (maximum number of open files).

Replacing the `break` by a `continue` works better since the files are closed. However, this is inefficient if we only need to iterate over a small fraction of the data

### Source code / logs
```
dataset = tf.data.TextLineDataset(fp)
...
for epoch in xrange(epochs):
    ...
    batches = 0
    for (x, y) in dataset:
        batches += 1
        if batches > MAX_BATCHES:
            break
        ...
```"
19498,tf.reduce_sum not consistent with documentation when axis==[ ],"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  9.0.176 / 7.0.5
- **GPU model and memory**: GeForce GTX 1050 Ti/PCIe/SSE2 4GB
- **Exact command to reproduce**: custom script

### Describe the problem
documentation says:
If axis has no entries, all dimensions are reduced, and a tensor with a single element is returned.

In practice:
If axis == []: nothing is reduced (the output is the input itself)

### Source code / logs
import tensorflow as tf

constant = tf.constant([[1., 2.], [3., 4.]])
reduce = tf.reduce_sum(constant, axis=[])

with tf.Session() as sess:
    print(sess.run(reduce))"
19497,NHWC convolution sometimes incorrectly considered NCHW,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0
- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  9.0.176 / 7.0.5
- **GPU model and memory**: GeForce GTX 1050 Ti/PCIe/SSE2 4GB
- **Exact command to reproduce**: custom script

### Describe the problem
When using dilated conv2d and bias_add, the conv2d is incorrectly considered NCHW, so the normal dilation format is not accepted. Strangely when there is no bias_add, the problem does not happen.

### Source code / logs
This gives ERROR:
```
import tensorflow as tf 
import numpy as np

def test_add_conv_transform1():
    input_ = tf.placeholder(tf.float32, shape=[1, 64, 64, 3], name=""input"")
    filter_ = tf.get_variable(dtype=tf.float32, shape=[4, 4, 3, 16], name=""filter"")
    
    conv = tf.nn.conv2d(input_, filter_, strides=[1, 1, 1, 1], padding='VALID', dilations=[1, 4, 4, 1])

    bias1 = tf.get_variable(name='bias', shape=[16], dtype=tf.float32)
    return tf.nn.bias_add(conv, bias1)
        
o = test_add_conv_transform1()
with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run(init)
    sess.run(o, {""input:0"": np.random.random([1, 64, 64, 3])})
```

tensorflow.python.framework.errors_impl.InvalidArgumentError: Current implementation does not yet support dilations in the batch and depth dimensions.
         [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NCHW"", dilations=[1, 4, 4, 1], padding=""VALID"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Conv2D-0-TransposeNHWCToNCHW-LayoutOptimizer, filter/read)]]

Interestingly this works as intended:
```
import tensorflow as tf 
import numpy as np

def test_add_conv_transform1():
    input_ = tf.placeholder(tf.float32, shape=[1, 64, 64, 3], name=""input"")
    filter_ = tf.get_variable(dtype=tf.float32, shape=[4, 4, 3, 16], name=""filter"")

    return tf.nn.conv2d(input_, filter_, strides=[1, 1, 1, 1], padding='VALID', dilations=[1, 4, 4, 1])
        
o = test_add_conv_transform1()
with tf.Session() as sess:
    init = tf.global_variables_initializer()
    sess.run(init)
    sess.run(o, {""input:0"": np.random.random([1, 64, 64, 3])})
```
"
19496,Segfault with rpc ops in eager mode,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary, pip
- **TensorFlow version (use command below)**: 1.8
- **Python version**:  3.6
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: see below

### Describe the problem

Rpc ops (`rpc`, `try_rpc`)  are not working in eager mode. See minimal examples below.

### Source code / logs

Non-eager version works

```python
import tensorflow as tf
from tensorflow.contrib.rpc.python.ops.gen_rpc_op import try_rpc

with tf.Graph().as_default():
    response = try_rpc('localhost:80', '/Test', 'some simple message', protocol='grpc')
    session = tf.InteractiveSession()
    print( session.run([response], feed_dict={}) )
```
Eager version does not (results in segfault):
```python
import tensorflow as tf
from tensorflow.contrib.rpc.python.ops.gen_rpc_op import try_rpc
tf.enable_eager_execution()
response = try_rpc('localhost:80', '/Test', 'some simple message', protocol='grpc')
```

"
19495,"How to optimize for inference , from frozen graph?","```
import tensorflow as tf
from tensorflow.python.tools import freeze_graph
from tensorflow.python.tools import optimize_for_inference_lib

inputGraph = tf.GraphDef()
with tf.gfile.Open(""frozen.pb"", ""rb"") as f:
    data2read = f.read()
    inputGraph.ParseFromString(data2read)

outputGraph = optimize_for_inference_lib.optimize_for_inference(
                inputGraph,
                [""inputTensor""], # an array of the input node(s)
                [""output/output""], # an array of output nodes
                tf.int32.as_datatype_enum)

        # Save the optimized graph

f = tf.gfile.FastGFile(""outputOptimizedGraph.pb"", ""w"")
f.write(outputGraph.SerializeToString())    

```
Output : /home/bibhu/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Traceback (most recent call last):
  File ""convert_frozen.py"", line 14, in <module>
    tf.int32.as_datatype_enum)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py"", line 111, in optimize_for_inference
    placeholder_type_enum)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/tools/strip_unused_lib.py"", line 86, in strip_unused
    output_node_names)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/graph_util_impl.py"", line 174, in extract_sub_graph
    _assert_nodes_are_present(name_to_node, dest_nodes)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-**packages/tensorflow/python/framework/graph_util_impl.py"", line 133, in _assert_nodes_are_present
    assert d in name_to_node, ""%s is not in graph"" % d
AssertionError: output/output is not in grap**"
19493,How to get the output of a layer when making predictions?,"My code is something like this:
```
        from tensorflow.contrib.layers import fully_connected

        hidden1 = fully_connected(train_inputs, hidden[0], scope=""hidden1"") 
        hidden2 = fully_connected(hidden1, hidden[1], scope=""hidden2"")
        u = fully_connected(hidden2, hidden[2], scope=""u"")

        loss = tf.reduce_mean(
            tf.nn.sampled_softmax_loss(
                weights=nce_weights,
                biases=nce_biases,
                labels=train_labels,
                inputs=u,
                num_sampled=sample_num,
                num_classes=class_num,
                remove_accidental_hits=True),
            name='loss')
```

After training, i loaded the model and make predictions for my data. I want to get the 'u' scope layer output in the net as output. How can i achieve that?
Notice that 'u' is a scope define, so i can not just use sess.run(['u:0'])

I load the model as follows:
```
    sess = tf.Session()
    saver = tf.train.import_meta_graph(meta_path)
    saver.restore(sess, model_path)
```
"
19492,How to freeze the graph ? ,"```
sess = tf.Session()
sess.run(tf.global_variables_initializer())

tf.train.write_graph(sess.graph.as_graph_def(),'.','tensorflowModel.pbtxt', as_text=True)

saver.save(sess, './my_test_model.ckpt')

freeze_graph.freeze_graph('./tensorflowModel.pbtxt', """",False,'./my_test_model.ckpt', ""output/predictions"", ""save/restore_all"",  ""save/Const:0"",'frozen.pb', True,"""")

```

Error:
freeze_graph.freeze_graph('./tensorflowModel.pbtxt', """",False,'./my_test_model.ckpt', ""output/predictions"", ""save/restore_all"",  ""save/Const:0"",'frozen.pb', True,"""")
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py"", line 254, in freeze_graph
    checkpoint_version=checkpoint_version)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/tools/freeze_graph.py"", line 153, in freeze_graph_with_def_protos
    variable_names_blacklist=variable_names_blacklist)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/graph_util_impl.py"", line 232, in convert_variables_to_constants
    inference_graph = extract_sub_graph(input_graph_def, output_node_names)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/graph_util_impl.py"", line 174, in extract_sub_graph
    _assert_nodes_are_present(name_to_node, dest_nodes)
  File ""/home/bibhu/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/graph_util_impl.py"", line 133, in _assert_nodes_are_present
    **assert d in name_to_node, ""%s is not in graph"" % d
AssertionError: output/predictions is not in graph**
 
"
19491,Performance problem with TensorFlow training,"Hello,
    We are running a not-very-complex 3D convolution problem had we have extremely poor performance. Here is the summary of our problem

Now the technical part.

I am running on an Haswell CPU in a Mac OS running High Sierra. 

Model Name:	MacBook Pro
Model Identifier:	MacBookPro11,5
Processor Name:	Intel Core i7
Processor Speed:	2.5 GHz
Number of Processors:	1
Total Number of Cores:	4
L2 Cache (per Core):	256 KB
L3 Cache:	6 MB
Memory:	16 GB


Tensorflow performance
---------------------------------

1.) Memory allocation

Memory allocation seems highly unoptimized. I see an allocation of ~80GB (78M allocations) out of which we are left with 37GB persistent (corresponding to 575k permanent allocations). The memory churn is enormous and this may affect very seriously performance. Most of those are very small allocation / deallocation which happen here

Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::Schedule(std::__1::function<void ()>)

I have tried to run with tcmalloc from google hoping to improve memory allocation and handling. tcmalloc complains that there are the following “large allocation” from TF even before starting the epochs: (23+23+2+18+4+9+2) = 81GB of allocation even before starting the epoch’s. After that my disk is full of swap files and my machine dies.

Then I went back running with the Mac allocator, which surprisingly seems to be more robust. 

2.) Code performance

A careful VTune analysis performed by Sofia has identified Eigen as the major source of CPU consumption.  All the time is wasted simply in repacking (gemm_pack_rhs).

To look at the code I attempted to compile with -g, however the default compilation is with -g0 and I could not find yet a way to replace this default on bazel. I added -g3 that, according to the manual (and to a small test I have made) should override -g0. However the Mac Instrument (a poor relation of VTune on Mac) could not find out the source. The library should be _pywrap_tensorflow_internal.so. Then I went looking for the source and I found that gemm_pack_rhs::operator() is defined in the following files

./bazel-tensorflow/external/eigen_archive/Eigen/src/Core/products/GeneralBlockPanelKernel.h
./bazel-tensorflow/third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h
./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/MatMatProductAVX2.h

The last two are identical. Putting good old printf’s I discovered we are calling the GeneralBlockPanelKernel.h version. The operator works with packets of size 8, which is fine for AVX2 (256) and float32 as we are using. However I am not sure that the compiler manages to vectorize this procedure. Indeed, most of the time is spent in line 559 of eigen_volume_patch.h. 

   for (int i = 0; i < PacketSize; ++i) {
      values[i] = coeff(index + i);
    }

The packet structure of the code is meant to have each packet treated as a unit. This for loop simply destroys all possibility of optimisation. There is a lot of room for optimisation in tensorflow before we get really serious about performance with a problem like ours. But who is going to pick up the tab? 

3.) MKL or not MKL. 

When bringing up this problem, I have been answered that tensorflow in Mac does not support the usage of MKL, and therefore, till then, my findings were not entirely relevant. MKL for Mac exists, however clang does not support OMP (or rather the default version of clang distributed with Mac does not have OMP support enabled). So the only way to compile tensorflow on the Mac with MKL was to change compiler. 

Unfortunately changing compiler with bazel on the Mac seems a very ambitious proposition. After posting to and perusing stackoverflow, bazel forum and tensorflow forum, I came to the following recipe

export BAZEL_USE_CPP_ONLY_TOOLCHAIN=1 
export CC=/path/to/compiler
bazel build […]

does indeed force Bazel to use a new compiler, however controlling the compiler switches is much more complicated. The two compiler flags -Wthread-safety and -Wself-assign, as well as the linker flag “-no-as-needed” and “-z” are incompatible with g++ linker. The CROSSTOOL.tpl are automatically generated during configuration. The only occurrences of (for instance) -Wself-assign in the TF code are in 

third_party/gpus/crosstool/CROSSTOOL_nvcc.tpl
third_party/toolchains/clang6/CROSSTOOL.tpl
third_party/toolchains/cpus/arm/CROSSTOOL.tpl

but even if I comment the lines:

-  compiler_flag: ""-Wthread-safety""
-  compiler_flag: ""-Wself-assign""
+#  compiler_flag: ""-Wthread-safety""
+#  compiler_flag: ""-Wself-assign”

in all three of them “something” creates a CROSSTOOL.tpl with these flags in. The hack I am trying now is to configure and then edit the file

./bazel-tensorflow/external/local_config_cc/cc_wrapper.sh

adding the following line

/sw/bin/gcc-fsf-7 `echo ""$@"" | sed -e 's/-Wself-assign//' | sed -e 's/-Wthread-safety//' | sed -e 's/-Wl,-no-as-needed//' | sed -e 's/-Wl,-z,relro,-z,now//‘`

which is a very poor hack. 

With this I could build a version of tensorflow using the Mac MKL, but to no avail. Performance is still abysmal with the same bottleneck. 

Thanks for reading up to here..."
19490,tensorflow cpu module's speed lower on windows than linux,"System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows7 64bit and ubuntu 16.04 64bit
- TensorFlow installed from (source or binary):build tensorflow source to shared lib
- TensorFlow version (use command below):tensorflow v1.3.0
- Python version: 3.5
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A
- Exact command to reproduce:N/A

Describe the problem
Training tensorflow module and detect faces both on windows7 and ubuntu 16.04, but it costs about twice time on windows7 than ubuntu16.04. So we want to know this issue is normal or not? And if it is normal, what's the reason?
windows7 PC environment:
CPU: Intel Core i3 2120
time: 80~160 ms

ubuntu16.04 PC environment:
CPU: Intel(R) Core(TM) i3-3220 CPU@3.30GHz
time: 40~100 ms
"
19489,TF eager backdrop does not co-locate gradient computation correctly.  Results in Placement warning.  ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.08
- **Python version**: 2.7
- **CUDA/cuDNN version**:
- **GPU model and memory**:  Tesla V100-SXM2-16GB
- **Exact command to reproduce**: - 

### Describe the problem
While moving a model to eager execution, I encountered an error using gradient_tape for back propagation.  While as far as I can tell all operations are taking place on the GPU, during back prop I get the following error:

```
>   File ""tf_registration_continuous.py"", line 128, in single_registration_step
>     elastic_grads = tape.gradient(loss_value, elastic_variable_list)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 767, in gradient
>     output_gradients=output_gradients)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/eager/imperative_grad.py"", line 63, in imperative_grad
>     tape._tape, vspace, target, sources, output_gradients)  # pylint: disable=protected-access
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 147, in grad_fn
>     op_inputs, op_outputs, orig_outputs)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/eager/backprop.py"", line 115, in _magic_gradient_function
>     return grad_fn(mock_op, *out_grads)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py"", line 427, in _GatherV2Grad
>     params_shape = math_ops.to_int32(params_shape)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 875, in to_int32
>     return cast(x, dtypes.int32, name=name)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 787, in cast
>     x = gen_math_ops.cast(x, base_type, name=name)
>   File ""/share/software/user/open/py-tensorflow/1.8.0_py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1548, in cast
>     _six.raise_from(_core._status_to_exception(e.code, message), None)
>   File ""/share/software/user/open/py-scipystack/1.0_py27/lib/python2.7/site-packages/six.py"", line 718, in raise_from
>     raise value
> tensorflow.python.framework.errors_impl.InvalidArgumentError: Tensors on conflicting devices: cannot compute Cast as input #0 was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0) Tensors can be copied explicitly using .gpu() or .cpu() methods, or transparently copied by using tf.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT). Copying tensors between devices may slow down your model [Op:Cast] name: ToInt32/
```

I might also put in a feature request to make backdrop error messages more verbose -- since I can not tell what operation in the model is actually causing this error.  "
19488,tensorflow 'killed' issue on Jetson TX1 ,"i use tensorflow v1.3.0 on Jetson TX1.
when i use tensorflow to train model repeatedly, occur 'killd' message or 'system stop' after one normal training. this error occurs during the model builing phase.
i reboot TX1 then i can train model without any problem.
all the time, i need to reboot TX1 every model training.

 in other words, i can train model with tensorflow only once without any error. after training, if i want to train again, i need to reboot TX1.

i think that memory can't be released after processs died or closed.
so, i force to refresh cache memory and swap memory directly. but it still doesn't work normally.
in other deivce such as JTX2, desktop PC, i can train model with tensorflow without any error.
also, i reinstalled tensorflow after format, but i still this issue.
help me, please.
"
19487,"platform.syscofig.has no get_compile_flags()and get_link_flags() function after v1.*,why？ is it  implemented in other places？","platform.syscofig.has no get_compile_flags()and get_link_flags() function after v1.*,why？ is it  implemented in other places？ Thanks!"
19486,Python Dropout op will not return directly when keep_prob =1,"Python Dropout op uses the following code to check keep_prob value:
`if tensor_util.constant_value(keep_prob) == 1:
  return x`
If keep_prob is placeholder,  tensor_util.constant_value(keep_prob) will return None,  if statement will always be false.

In python/ops/nn_test.py
When test keep_prob value (testDropoutPlaceholderKeepProb), it only test keep_prob in [0.1, 0.5, 0.8],
We should add the case of keep_prob = 1.0 test. 

 

"
19484,Question about using of TFRecordDataset,"Hi every body:
   I am new to tensorflow, I am now try to read tfrecords file by TFRecordDataset,  I use the code like follows:
      traindataset = tf.data.TFRecordDataset(train_file) 
      traindataset = traindataset.map(dataset._parse_record)
    
        
    iterator = traindataset.make_one_shot_iterator()
    images, labels, comment = iterator.get_next()

   raw_images, raw_labels, comments = sess.run([images, labels, comments])
   for img, lex, comment in zip(raw_images, raw_labels, comments):
          ......
      
   And I am not sure that img got like above are regular images or the serialized version of images? And should I use the following statement to convert them like:
          img_decoded = tf.image.decode_image(img) 
        
          
    "
19482,CUDA cannot create more than one session,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Xenial
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**: 
1.8
- **Python version**:
2.7 
- **Bazel version (if compiling from source)**:
0.13
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
9.0/7.0
- **GPU model and memory**:
Tegra x2
- **Exact command to reproduce**:
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4 # I have also tried with allow memory growth
sess1 = tf.Session(config=config)
sess2=tf.Session(config=config) # Cannot create the session
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I have a Jetson TX2 with updated drivers and the last jetpack provided by Nvidia, I have built tensorflow (r.1.5 and r.18) and I'm not able to create more than one session, I can execute operations and everything with only one session, but once I create a new session, I encounter that tensorflow cannot create a new session, which I suspect is Nvidia fault, but the error is not that informative:

```
  File ""object_detection.py"", line 183, in detection
    with tf.Session(graph=detection_graph,config=config) as sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1509, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 628, in __init__
    self._session = tf_session.TF_NewDeprecatedSession(opts, status)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Failed to create session.
```
Is there any way I can get more information about the cuda error or status? So I can complement my bug report?

Thanks

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19481,PowerSignOptimizer not available on TPUv2,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: TPUv2-8
- **TensorFlow installed from (source or binary)**: VM disk image as configured by ctpu
- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Attempt to execute ```tf.contrib.opt.PowerSignOptimizer()``` on a TPUv2

### Describe the problem
The Powersign optimizer ```tf.contrib.opt.PowerSignOptimizer()``` does not have a OpKernel for the XLA_TPU_JIT device.

### Source code / logs
```
NotFoundError (see above for traceback): No registered 'ResourceApplyPowerSign' OpKernel for XLA_TPU_JIT devices compatible with node PowerSignOptimizer/update_dense/bias/ResourceApplyPowerSign = ResourceApplyPowerSign[T=DT_FLOAT, _class=[""loc:@PowerSignOptimizer/update_dense/bias/Read/ReadVariableOp""], use_locking=false, _device=""/device:TPU_REPLICATED_CORE""](_arg106, _arg10, PowerSignOptimizer/learning_rate, PowerSignOptimizer/logbase, PowerSignOptimizer/sign_decay, PowerSignOptimizer/beta, CrossReplicaSum_95)
        .  Registered:  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_HALF]
```
"
19480,Manually placing operations in eager execution raises FailedPreconditionError.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: tensorflow 1.6
- **Python version**: python3.6
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: V9.0.176
- **GPU model and memory**:  NVIDIA Corporation GV100GL [Tesla V100 SXM2 16GB] (rev a1)
- **Exact command to reproduce**: 



### Describe the problem
I have a model that I believe was not automatically being placed onto an available GPU.  

I then placed this part of the computation inside a with_device() block.  This schematically looks like:

 ```
# define some variables
with tf.device(""/device:GPU:0""):
     with tfe.GradientTape(persistent=True) as tape:
        # calculate loss based on variables

```

The error is thrown during the loss calculation step.  

### Source code / logs


2018-05-22 13:57:11.963021: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-05-22 13:57:12.324280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
totalMemory: 15.78GiB freeMemory: 15.36GiB
2018-05-22 13:57:12.324584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0
2018-05-22 13:57:12.623548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14878 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
Traceback (most recent call last):
  File ""tf_registration_continuous.py"", line 619, in <module>
    cProfile.run('main()', file)
  File ""/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py"", line 16, in run
    return _pyprofile._Utils(Profile).run(statement, filename, sort)
  File ""/share/software/user/open/python/3.6.1/lib/python3.6/profile.py"", line 55, in run
    prof.run(statement)
  File ""/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py"", line 95, in run
    return self.runctx(cmd, dict, dict)
  File ""/share/software/user/open/python/3.6.1/lib/python3.6/cProfile.py"", line 100, in runctx
    exec(cmd, globals, locals)
  File ""<string>"", line 1, in <module>
  File ""tf_registration_continuous.py"", line 615, in main
    accuracy ,runtime, final_loss = run_registration(directory='output/' + hparams_run.name, hparams=hparams_run, dataset_path = dataset_path, save_figs=False)
  File ""tf_registration_continuous.py"", line 525, in run_registration
    rm.register(save_summaries = save_figs, make_animation=save_figs)
  File ""tf_registration_continuous.py"", line 190, in register
    num_images_to_optimize_params= self.hparams.num_images_to_optimize_params
  File ""tf_registration_continuous.py"", line 105, in single_registration_step
    _ = self.eif.warp(scale, num_images_for_loss_calculation)
  File ""/home/groups/bmacint/Ultrasound/timing/elastic_image_field.py"", line 118, in warp
    field_image.initialize_translation()
  File ""/home/groups/bmacint/Ultrasound/timing/field_image.py"", line 87, in initialize_translation
    self.translation_warp_points = tf.tile(self.translation[tf.newaxis, tf.newaxis, :],
  File ""/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py"", line 828, in _SliceHelperVar
    return _slice_helper(var._AsTensor(), slice_spec, var)
  File ""/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 741, in _AsTensor
    return self.value()
  File ""/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 572, in value
    return self._read_variable_op()
  File ""/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 655, in _read_variable_op
    self._dtype)
  File ""/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py"", line 304, in read_variable_op
    attrs=_attrs, ctx=_ctx, name=name)
  File ""/share/software/user/open/py-tensorflow/1.6.0_py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 66, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 2, in raise_from
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable 152 from Container: eager-execution-0/. This could mean that the variable was uninitialized. Invalid argument: Trying to access resource located in device /job:localhost/replica:0/task:0/device:CPU:0 from device /job:localhost/replica:0/task:0/device:GPU:0 [Op:ReadVariableOp]

"
19478,Does eager execution allow dynamic batching like Tensorflow fold?,"Tensorflow fold has no updates since months and as far as I know it only works with Tensorflow v1.0.
Does anybody know if eager execution in newer Tensorflow versions supports dynamic batching like Tensorflow fold? If not, is it likely that future versions would support it?
Thanks for any answer!
 
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: from 1.4 to the latest
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A
"
19477,tf.contrib.tensorrt.create_inference_graph fails for ssd_mobilenet_v2_coco network with error,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0 / 7.1.3
- **GPU model and memory**: GeForce 940MX / 2GB 
- **TensorRT version**: 3.0.4
- **Exact command to reproduce**:


```
import tensorflow as tf
import tensorflow.contrib.tensorrt as trt
from tensorflow.python.platform import gfile


def get_graph_def_from_pb(file):
    with gfile.FastGFile(file, 'rb') as f:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(f.read())
        return graph_def


trt_graph = trt.create_inference_graph(
                input_graph_def=get_graph_def_from_pb(""~/Downloads/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb""), # from http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz
                outputs=[""detection_boxes""],
                max_batch_size=1,
                max_workspace_size_bytes=500000000,
                precision_mode=""FP32"")


with gfile.FastGFile(""trt_frozen_graph.pb"", 'wb') as f:
    f.write(trt_graph.SerializeToString())
```

### Describe the problem
When I try to convert ssd_mobilenet_v2_coco for the use with TensorRT in tensorflow, the convert step fails with below's Traceback. This seems to be a problem within tf.contrib.tensorrt.create_inference_graph [Line 115](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/tensorrt/python/trt_convert.py#L115) which itself is an exception risen if the c++ binary [trt_convert](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/tensorrt/python/trt_convert.py#L102) returns an error. Unfortunately here my bread-crumbs end, as I've not found the line in [convert_graph.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/tensorrt/convert/convert_graph.cc), which might be responsible for this behaviour.

Using a much simpler network (just a few CNN layers and FCN layers) works - so it does not seem to be my TensorRT installation.




### Source code / logs
```
Traceback (most recent call last):
  File ""/home/q0we9saweq/projects/tf_helpers/tensorrt_prep.py"", line 20, in <module>
    precision_mode=""FP32"")
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tensorrt/python/trt_convert.py"", line 115, in create_inference_graph
    int(msg[0]))
tensorflow.python.framework.errors_impl.NotFoundError: No attr named 'index_type' in NodeDef:
	 [[Node: MultipleGridAnchorGenerator/Meshgrid/ExpandedShape/ones = Fill[T=DT_INT32](MultipleGridAnchorGenerator/Meshgrid/ExpandedShape/Reshape, MultipleGridAnchorGenerator/Meshgrid/ExpandedShape/ones/Const)]]
	 [[Node: MultipleGridAnchorGenerator/Meshgrid/ExpandedShape/ones = Fill[T=DT_INT32](MultipleGridAnchorGenerator/Meshgrid/ExpandedShape/Reshape, MultipleGridAnchorGenerator/Meshgrid/ExpandedShape/ones/Const)]]
```
"
19476,Error while importing tensorflow (DLL Load Failed+No module named '_pywrap_tensorflow_internal'),"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------
Hello, this is my first time on github so forgive me if I do something wrong.
I've been interested in machine learning and i've tried to install tensorflow (to use keras).
When I finally thought everything was installed and ready, I got this issue when importing tensorflow on python. Can someone help me?
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: nope
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows10 64 bits
- **TensorFlow installed from (source or binary)**: pip3 install --upgrade tensorflow
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: don't know what that is
- **GCC/Compiler version (if compiling from source)**: neither that
- **CUDA/cuDNN version**: neither that
- **GPU model and memory**: i have an intel CPU
- **Exact command to reproduce**: import tensorflow

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Traceback (most recent call last):
  File ""<console>"", line 1, in <module>
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: Une routine d’initialisation d’une bibliothèque de liens dynamiques (DLL) a échoué.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""c:\users\antoine rollet\appdata\local\programs\python\python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
19475,transform_graph obfuscate_names error in Windows 10,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: source 
- **TensorFlow version (use command below)**: v1.7.1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: Not used
- **GCC/Compiler version (if compiling from source)**: Visual Studio 2015 (MSBuild.exe)
- **CUDA/cuDNN version**: CUDA 9.1, cuDNN 7.0.5
- **GPU model and memory**: NVIDIA GeForce GTX 1070
- **Exact command to reproduce**:
1. Open cmd
2. Go to the directory where a saved model is stored.
2. Run the following command
PATH\TO\tensorflow-1.7.1\tensorflow\contrib\cmake\build_cuda_v9.1\Release\transform_graph --in_graph=saved_model.pb --out_graph=saved_model_2.pb --inputs=""image:0"" --outputs=""probability:0"" --transforms=""obfuscate_names""

### Describe the problem
I had the following error after running the command.

[libprotobuf ERROR D:\workspace_tensorflow_source\tensorflow-1.7.1\tensorflow\contrib\cmake\build_cuda_v9.1\protobuf\src\protobuf\src\google\protobuf\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:1: Invalid control characters encountered in text.
[libprotobuf ERROR D:\workspace_tensorflow_source\tensorflow-1.7.1\tensorflow\contrib\cmake\build_cuda_v9.1\protobuf\src\protobuf\src\google\protobuf\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Interpreting non ascii codepoint 192.
[libprotobuf ERROR D:\workspace_tensorflow_source\tensorflow-1.7.1\tensorflow\contrib\cmake\build_cuda_v9.1\protobuf\src\protobuf\src\google\protobuf\text_format.cc:288] Error parsing text-format tensorflow.GraphDef: 1:4: Expected identifier, got: └
2018-05-22 13:39:08.760764: E D:\workspace_tensorflow_source\tensorflow-1.7.1\tensorflow\tools\graph_transforms\transform_graph.cc:200] Loading graph 'saved_model.pb' failed with Can't parse saved_model.pb as binary proto
         (both text and binary parsing failed for file saved_model.pb)
2018-05-22 13:39:08.767541: E D:\workspace_tensorflow_source\tensorflow-1.7.1\tensorflow\tools\graph_transforms\transform_graph.cc:202] usage: D:\workspace_tensorflow_source\tensorflow-1.7.1\tensorflow\contrib\cmake\build_cuda_v9.1\Release\transform_graph
Flags:
        --in_graph=""""                           string  input graph file name
        --out_graph=""""                          string  output graph file name
        --inputs=""""                             string  inputs
        --outputs=""""                            string  outputs
        --transforms=""""                         string  list of transforms
        --output_as_text=false                  bool    whether to write the graph in text protobuf format

Transforms are:
add_default_attributes
backport_concatv2
backport_tensor_array_v3
flatten_atrous_conv
fold_batch_norms
fold_constants
fold_old_batch_norms
freeze_requantization_ranges
fuse_pad_and_conv
fuse_resize_and_conv
fuse_resize_pad_and_conv
insert_logging
merge_duplicate_nodes
obfuscate_names
quantize_nodes
quantize_weights
remove_attribute
remove_control_dependencies
remove_device
remove_nodes
rename_attribute
rename_op
round_weights
set_device
sort_by_execution_order
sparsify_gather
strip_unused_nodes

### Source code / logs
I created a saved model using Estimator. The following shows how I create a saved model.

            # Get warm start settings
            wss = self._get_warm_start_settings()

            # Create a estimator w/ or w/o warm start
            estimator = tf.estimator.Estimator(
                model_fn=NetTrainer.model_fn,
                model_dir=self.model_path,
                params={
                    'net_id': str(self.net_id)
                },
                config=tf.estimator.RunConfig(
                    save_checkpoints_steps=training_config.CHECKPOINTS_STEPS,
                    save_summary_steps=training_config.SUMMARY_STEPS,
                    keep_checkpoint_max=training_config.KEEP_CHENCKPOINT_MAX
                ),
                warm_start_from=wss)
 
            for lp in list(range(0, training_config.NUM_TRAINING_EVALUATION_CYCLES)):
                                  
                # Train the model
                estimator.train(
                    input_fn=lambda:self.train_input_fn(training_db_reader_state),
                    steps=training_config.TRAINING_STEPS,
                    max_steps=None)
  
                # Evaluate the model
                eval_result = estimator.evaluate(
                    input_fn=lambda:self.eval_input_fn(evaluation_db_reader_state))
                  
                tf.logging.info('training-evaluation cycle: {:d}'.format(lp))
                tf.logging.info('global_step: {global_step:d}'.format(**eval_result))
                tf.logging.info('Test set accuracy: {accuracy:0.3f}'.format(**eval_result))
                
            # Export the model
            image_shape = self._get_image_shape(include_batch=True, batch_size=1);
            feature_spec = {config.IMAGE_KEY: tf.placeholder(tf.float32, shape=image_shape, name=config.IMAGE_KEY)}
            serving_input_receiver_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(feature_spec, default_batch_size=1)

            estimator.export_savedmodel(
                export_dir_base=self.saved_model_path,
                serving_input_receiver_fn=serving_input_receiver_fn,
                strip_default_attrs=True)


"
19473,Random initialization of a GPU variable with more than INT32_MAX elements crashes with CUDA_ERROR_ILLEGAL_ADDRESS,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: 9.0
- **GPU model and memory**: V100
- **Bazel version**: N/A
- **Exact command to reproduce**: see below

### Describe the problem
Random initialization of a GPU variable with more than INT32_MAX elements crashes with CUDA_ERROR_ILLEGAL_ADDRESS.

### Source code / logs
The following code runs with no problem (ran into this with large embedding tables):
```python
import tensorflow as tf
n = 13417676
h = 160
x = tf.get_variable('x', [n, h])
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
```
The following code crashes with CUDA_ERROR_ILLEGAL_ACCESS:
```python
import tensorflow as tf
n = 13417677 # increased by 1
h = 160
x = tf.get_variable('x', [n, h])
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
```

Running with `cuda-memcheck` reports the following:
```
========= Invalid __global__ write of size 16
=========     at 0x00000850 in void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>(tensorflow::random::PhiloxRandom, tensorflow::random::PhiloxRandomResultElementType*, __int64, tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::UniformDistribution<tensorflow::random::PhiloxRandom, float>>)
=========     by thread (1023,0,0) in block (127,0,0)
=========     Address 0x7f7e3c6806f0 is out of bounds
```

Checking the source code, the following looks suspicious to me: https://github.com/tensorflow/tensorflow/blob/982549ea3423df4270ff154e5c764beb43d472da/tensorflow/core/kernels/random_op_gpu.cu.cc#L136

The `int32 offset` variable is later used to index into the output array -- and I believe it can overflow and generate an illegal negative index."
19471,T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19469,"C:\Users\Lenovo\AppData\Local\Programs\Python\Python36\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19468,"  The scripts freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, toco.exe and toco_from_protos.exe are installed in 'c:\users\lenovo\appdata\local\programs\python\python36\Scripts' which is not on PATH.   Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19467,get_variables constraint doesn't work,"```
import tensorflow as tf
a = tf.get_variable('a', shape=[], constraint=lambda t: tf.clip_by_value(t, -2, 2))
sess = tf.Session()
sess.run(a.assign(3.))
sess.run(a)
```

I tried on `tf 1.8.0` and `tf 1.5.0`, both outputs `3`"
19466,libpng compiled without VSX option (for IBM Power8),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL75
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.7.1
- **Python version**:  Python 3.5.4+ (default, Jan  9 2018, 16:01:00)
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: GCC 6.4.1
- **CUDA/cuDNN version**: 9.2/7.1.3
- **GPU model and memory**: P100 Nvidia
- **Exact command to reproduce**: import tensorflow

### Describe the problem
Compiling from source TF on IBM Power8 (ppc64le) leads to a problem with libpng. 
By default, TF download and get it's own libpng. This however lacks VSX symbols inside. To add those symbols libpng should be compiled with the following flags:

```
./configure --enable-powerpc-vsx --enable-hardware-optimizations
```

otherwise it leads to the following error when importing tensorflow:

```ImportError: /hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: png_init_filter_functions_vsx```

I think the `third_party/png.BUILD` file needs to be updated accordingly, but I do not have experience with bazel to do that myself.

Could you please solve this?

### Source code / logs
```> python3
Python 3.5.4+ (default, Jan  9 2018, 16:01:00)
[GCC 6.4.1 20170720 (Advance-Toolchain-at10.0) IBM AT 10 branch, based on subve on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/opt/at10.0/lib64/python3.5/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/opt/at10.0/lib64/python3.5/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: /hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: png_init_filter_functions_vsx

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *  # pylint: disable=redefined-builtin
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/opt/at10.0/lib64/python3.5/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/opt/at10.0/lib64/python3.5/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: /hpc_modules/at10.0-based/deeplearning/tensorflow/tensorflow-v1.7.1_openmpi-3.0.1/lib64/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: png_init_filter_functions_vsx


Failed to load the native TensorFlow runtime.```"
19465,Mixing Keras layers and tf.layers  in Estimator  ( or otherwise),"I am trying to figure out a way to mix Kears   and tf layers. Would be great  to be able to do something like the following. 

  x = tf.keras.layers.Dense(64, activation='relu', name ='d1')(inputs)
  x = tf.keras.layers.Dense(64, activation='relu', name ='d2')(x)
  predictions = tf.layers.Dense (units=10, activation=tf.nn.softmax, name='d3')(x)

Have I written custom code : NO
OS Platform and Distribution: N/A
TensorFlow installed from : N/A
TensorFlow version: 1.8
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A"
19464,TF failing to build on Bazel CI,"See logs at https://buildkite.com/bazel/bazel-with-downstream-projects-bazel/builds/246#a2654e2b-dbaf-4c4b-909f-1dfd16b7fe7a

The underlying error is:
```
ERROR: /usr/local/google/home/jcater/.cache/bazel/_bazel_jcater/30de07a0c21303385c48fed63725bc15/external/grpc/BUILD:1300:1: C++ compilation of rule '@grpc//:grpc_resolver_dns_ares' failed (Exit 1)
external/grpc/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc:30:10: fatal error: ares.h: No such file or directory
 #include <ares.h>
          ^~~~~~~~
compilation terminated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

I can't determine why ares.h cannot be found. The generated .tf_configure.bazelrc contains the line:
```
build --define grpc_no_ares=true
```
"
19463,AttributeError: 'NoneType' object has no attribute 'rfind'," **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-**TensorFlow installed from (source)**:
**tensorflow v1.6.0-0-gd2e24b6039 1.6.0**:
**Python 3.5**: 

**Reproduce**
git clone tensorflow 
python3 tensorflow/examples/speech_commands/train.py
python3 tensorflow/examples/speech_commands/freeze.py \
--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000 \
--output_file=/tmp/my_frozen_graph.pb

**Error appears:**
/home/lukas/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
2018-05-22 21:59:00.562103: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
Converted 6 variables to const ops.
Traceback (most recent call last):
  File ""/home/lukas/Desktop/tensorflow-master/tensorflow/examples/speech_commands/freeze.py"", line 180, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/lukas/.local/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/lukas/Desktop/tensorflow-master/tensorflow/examples/speech_commands/freeze.py"", line 124, in main
    os.path.dirname(FLAGS.output_file),
  File ""/usr/lib/python3.5/posixpath.py"", line 148, in dirname
    i = p.rfind(sep) + 1
AttributeError: 'NoneType' object has no attribute 'rfind'

**Thanks** "
19460,Mistake in tensorflow API doc,"As you can see in the [documentation](https://www.tensorflow.org/api_docs/python/tf/nn/softmax), the 'axis' attribute is not mandatory.
But, its default value is ""None"" in the function call example, but is '-1' in the description of the 'axis' attribute.


"
19458,"I am trying to deploy my tensorflow model(CNN) to android, when I am trying to use my .pb file( generated after training the model )in android studio it shows! ","05-22 16:23:02.608 27021-27021/com.example.bibhu.smscnn E/AndroidRuntime: FATAL EXCEPTION: main
Process: com.example.bibhu.smscnn, PID: 27021
java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.bibhu.smscnn/com.example.bibhu.smscnn.MainActivity}: java.lang.RuntimeException: Failed to load model from 'file:///android_asset/graph11.pb'
at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2820)
at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2895)
at android.app.ActivityThread.-wrap11(Unknown Source:0)
at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1596)
at android.os.Handler.dispatchMessage(Handler.java:105)
at android.os.Looper.loop(Looper.java:164)
at android.app.ActivityThread.main(ActivityThread.java:6565)
at java.lang.reflect.Method.invoke(Native Method)
at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240)
at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767)
Caused by: java.lang.RuntimeException: Failed to load model from 'file:///android_asset/graph11.pb'
at org.tensorflow.contrib.android.TensorFlowInferenceInterface.(TensorFlowInferenceInterface.java:113)
at com.example.bibhu.smscnn.TensorFlowClassifier.create(TensorFlowClassifier.java:70)
at com.example.bibhu.smscnn.TensorflowIntegrationExample.loadModel(TensorflowIntegrationExample.java:35)
at com.example.bibhu.smscnn.TensorflowIntegrationExample.(TensorflowIntegrationExample.java:27)
at com.example.bibhu.smscnn.MainActivity.onCreate(MainActivity.java:21)
at android.app.Activity.performCreate(Activity.java:6975)
at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1214)
at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2773)
at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2895) 
at android.app.ActivityThread.-wrap11(Unknown Source:0) 
at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1596) 
at android.os.Handler.dispatchMessage(Handler.java:105) 
at android.os.Looper.loop(Looper.java:164) 
at android.app.ActivityThread.main(ActivityThread.java:6565) 
at java.lang.reflect.Method.invoke(Native Method) 
at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240) 
at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767) 
Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Input 1 of node embedding/embedding_lookup was passed float from inputTensor:0 incompatible with expected int32.
at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:561)
at org.tensorflow.contrib.android.TensorFlowInferenceInterface.(TensorFlowInferenceInterface.java:105)
at com.example.bibhu.smscnn.TensorFlowClassifier.create(TensorFlowClassifier.java:70) 
at com.example.bibhu.smscnn.TensorflowIntegrationExample.loadModel(TensorflowIntegrationExample.java:35) 
at com.example.bibhu.smscnn.TensorflowIntegrationExample.(TensorflowIntegrationExample.java:27) 
at com.example.bibhu.smscnn.MainActivity.onCreate(MainActivity.java:21) 
at android.app.Activity.performCreate(Activity.java:6975) 
at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1214) 
at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2773) 
at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2895) 
at android.app.ActivityThread.-wrap11(Unknown Source:0) 
at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1596) 
at android.os.Handler.dispatchMessage(Handler.java:105) 
at android.os.Looper.loop(Looper.java:164) 
at android.app.ActivityThread.main(ActivityThread.java:6565) 
at java.lang.reflect.Method.invoke(Native Method) 
at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:240) 
at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:767) "
19457,Slot variables used in an optimizer must have the same shape with the variable to be optimized?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu, MacOS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  2.7.5
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 4.8.5
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: CPU
- **Exact command to reproduce**: When a optimizer is created.

### Describe the problem

I write a new optimizer to try some strategies for gradients apply. Some slots are used in the implementation. But I find that slots must have the same shape with the variables to be optimized. Otherwise, an error will be thrown out with message ""shape not match"" when I try to save model.

The problem happens in version 1.4. I try the same code in version 1.2, it works correctly.

So I want to figure out the reason.

### Source code / logs
 
```python
 1 def _create_slots(self, var_list):
 2   for v in var_list:
 3     with ops.colocate_with(v):
 4       dtype = v.dtype.base_dtype
 5       v_shape = v.get_shape()
 6       if v_shape.is_fully_defined():
 7         init = init_ops.constant_initializer(self._initial_accumulator_value, dtype=dtype)
 8       else:                                  
 9         init_constant = gen_array_ops.fill(array_ops.shape(v), self._initial_accumulator_value)
10         init = math_ops.cast(init_constant, dtype)
11 
12     self._get_or_make_slot_with_initializer(
13        v, init, v_shape, dtype, ""accumulator"", self._name)
14     self._get_or_make_slot_with_initializer(
15        v, init_ops.zeros_initializer(self._global_step.dtype),-
16        v_shape, self._global_step.dtype, ""accumulator_decay_power"", self._name)
```

In line 16, if I change 'v_shape' with other value, an error will be got. For example, v_shape=[512, 256], but only [512] is needed to create this slot. 
"
19455,CuDNN error while fitting CNN ,"OS: Windows 10 64bit
TensorFlow GPU: 1.5.0 (installed with pip)
Python Version: 3.6.4
IDE : Spyder 3.2.6
CUDA: v9.0
CuDNN: v7.0.5 for CUDA 9.0
GPU: GeForce GTX 960M 4GB
NVIDIA drivers: 397.64


So, I was trying to run some CNN (and also CapsNet where the first layer is just a convolution layer). And it keeps crushing with the error below. From what I found on the internet I decided to reinstall cuda and cudnn. And the code with CNN worked. Though capsnet still didn't. I googled more and found out that cuda reset your drivers after installation, so, I needed to update my drivers. I had something like 380 or 384. Don't remember exactly. I installed 397. And now they both don't work again. I'm desperate. I don't know what to do anymore.
The CNN code works fine on CPU though.

Error given by CNN code:

` 2018󈚩󈚺 15:50:40.136802: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018󈚩󈚺 15:50:40.925004: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.176
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.34GiB
2018󈚩󈚺 15:50:40.930269: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) ‑> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2018󈚩󈚺 15:50:47.834229: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:50:47.866263: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:50:47.905931: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:50:47.907669: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:50:47.909351: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:50:47.911059: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:50:48.585303: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2018󈚩󈚺 15:50:48.586924: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2018󈚩󈚺 15:50:48.588290: F C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\kernels\conv_ops.cc:717] Check failed: stream‑>parent()‑>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) 
2018󈚩󈚺 15:53:45.749902: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018󈚩󈚺 15:53:46.246273: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.176
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.34GiB
2018󈚩󈚺 15:53:46.248497: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) ‑> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2018󈚩󈚺 15:53:49.372376: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:53:49.373772: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:53:49.377767: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:53:49.379147: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:53:49.380568: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:53:49.382145: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_blas.cc:444] failed to create cublas handle: CUBLAS_STATUS_ALLOC_FAILED
2018󈚩󈚺 15:53:49.646183: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2018󈚩󈚺 15:53:49.647436: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2018󈚩󈚺 15:53:49.648615: F C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\kernels\conv_ops.cc:717] Check failed: stream‑>parent()‑>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) `


Part of the error given by capsnet:

` 2018󈚩󈚺 15:49:02.623151: W C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:277] *****************************************___________________________________________________________
2018󈚩󈚺 15:49:02.624700: W C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Resource exhausted: OOM when allocating tensor with shape[24,6,6,3,3,32,32,4,4,4] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2018󈚩󈚺 16:22:12.617066: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018󈚩󈚺 16:22:13.091828: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1105] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.176
pciBusID: 0000:01:00.0
totalMemory: 4.00GiB freeMemory: 3.34GiB
2018󈚩󈚺 16:22:13.094135: I C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) ‑> (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2018󈚩󈚺 16:23:36.501624: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2018󈚩󈚺 16:23:36.504510: E C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\stream_executor\cuda\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
2018󈚩󈚺 16:23:36.507233: F C:\tf_jenkins\workspace\rel‑win\M\windows‑gpu\PY\36\tensorflow\core\kernels\conv_ops.cc:717] Check failed: stream‑>parent()‑>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) `



"
19452,tensorflow-lite batch_to_space_nd when will support crops attribute?,"commit id : 52e2698 

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0 gpu
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:0.12.0
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**: 7.5.18
- **GPU model and memory**:TITAN,12GB
- **Exact command to reproduce**: N/A

### Describe the problem
I saw the ""tf.batch_to_space_nd - as long as the input tensor is 4D (1 batch + 2 spatial + 1 other) and the crops attribute is not used"" in TensorFlow Lite & TensorFlow Compatibility Guide page.
I want to convert customed model to tensorflow-lite format which has crops attribute in batch_to_space_nd op. I wandor when will batch_to_space_nd support crops attribute?
Thank you very much.



"
19451,Feature Request: evaluate both train_data and test_data using tf.contrib.learn.Experiment?,"### Describe the problem
feature request：
i'm using the api ""tf.contrib.learn.Experiment"" for distributed training, but i don't know the method for evaluating the train_data and test_data at the same step, i want to check the model is overfit or not, so i want to print both train_auc and test_auc after saving model each time.

now, i can only see the performance on the test data for every saved model. is there any methods to print both train and test evaluation? Thanks a lot!

### Source code / logs
here is  code:
`def train(self):
        if self.job_name == ""worker"":
            # get data
            self.init_worker_input_split()
            self.init_worker_test_input_split()

        # data input function
        train_input = lambda: dataset_v1.create_input_fun(self.file_names,
                                                          FLAGS.batch_size,
                                                          repeat_count=FLAGS.train_epochs)
        test_input = lambda: dataset_v1.create_input_fun(self.test_file_names,
                                                         FLAGS.batch_size,
                                                         perform_shuffle=False)
        # estimator define
        model = self.build_estimator(FLAGS.log_dir, FLAGS.model_type)

        distribute_exp = tf.contrib.learn.Experiment(estimator=model,
                                                     train_input_fn=train_input,
                                                     eval_input_fn=test_input,
                                                     min_eval_frequency=100
                                                     )

        if self.job_name == ""ps"":
            # Starts a TensorFlow server and joins the serving thread
            distribute_exp.run_std_server()
        elif self.job_name == ""worker"":
            distribute_exp.train_and_evaluate()

        if self.is_chief:
            # Evaluate on the evaluation data.
            distribute_exp.evaluate(name='test_performance')

        tf.logging.info(""Optimization Finished!"")`

here is the logs:
INFO:tensorflow:Validation (step 7014908): loss = 15.8598, accuracy_baseline = 0.925938, global_step = 7014348, auc = 0.683994, prediction/mean = 0.0714387, label/mean = 0.0740625, average_loss = 0.24781, auc_precision_recall = 0.167725, accuracy = 0.927031
INFO:tensorflow:global_step/sec: 98.1175
INFO:tensorflow:global_step/sec: 124.708
INFO:tensorflow:global_step/sec: 121.122
INFO:tensorflow:loss = 11.3313, step = 7016362 (21.941 sec)
INFO:tensorflow:global_step/sec: 122.56
INFO:tensorflow:global_step/sec: 114.473
INFO:tensorflow:global_step/sec: 122.207
INFO:tensorflow:global_step/sec: 123.767
INFO:tensorflow:global_step/sec: 125.336
INFO:tensorflow:loss = 14.5477, step = 7016886 (4.307 sec)
INFO:tensorflow:global_step/sec: 120.105
INFO:tensorflow:global_step/sec: 110.698
INFO:tensorflow:global_step/sec: 124.799
INFO:tensorflow:global_step/sec: 121.776
INFO:tensorflow:global_step/sec: 114.484
INFO:tensorflow:loss = 16.5542, step = 7017438 (4.837 sec)
INFO:tensorflow:global_step/sec: 125.595
INFO:tensorflow:global_step/sec: 122.375
INFO:tensorflow:global_step/sec: 122.392
INFO:tensorflow:global_step/sec: 124.201
INFO:tensorflow:global_step/sec: 122.038
INFO:tensorflow:loss = 17.7121, step = 7017930 (3.817 sec)
INFO:tensorflow:global_step/sec: 102.7
INFO:tensorflow:global_step/sec: 121.585
INFO:tensorflow:global_step/sec: 119.404
INFO:tensorflow:global_step/sec: 121.501
INFO:tensorflow:global_step/sec: 119.815
INFO:tensorflow:loss = 16.0022, step = 7018577 (5.630 sec)
INFO:tensorflow:global_step/sec: 118.615
INFO:tensorflow:global_step/sec: 122.272
INFO:tensorflow:global_step/sec: 121.206
INFO:tensorflow:global_step/sec: 123.087
INFO:tensorflow:global_step/sec: 120.079
INFO:tensorflow:loss = 20.2255, step = 7019070 (4.049 sec)
INFO:tensorflow:global_step/sec: 118.552
INFO:tensorflow:global_step/sec: 121.404
INFO:tensorflow:Saving checkpoints for 7019347 into viewfs://hadoop-meituan/user/hadoop-generalshop/caiqi.sun/spark/dl/demo/output/wide_deep_all_82/model.ckpt.
INFO:tensorflow:global_step/sec: 102.859
INFO:tensorflow:Starting evaluation at 2018-05-22-03:56:24
INFO:tensorflow:Restoring parameters from viewfs://hadoop-meituan/user/hadoop-generalshop/caiqi.sun/spark/dl/demo/output/wide_deep_all_82/model.ckpt-7019347
INFO:tensorflow:Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2018-05-22-03:56:31
INFO:tensorflow:Saving dict for global step 7019354: accuracy = 0.927031, accuracy_baseline = 0.925938, auc = 0.683203, auc_precision_recall = 0.170481, average_loss = 0.247913, global_step = 7019354, label/mean = 0.0740625, loss = 15.8664, prediction/mean = 0.0705214
INFO:tensorflow:Validation (step 7019922): loss = 15.8664, accuracy_baseline = 0.925938, global_step = 7019354, auc = 0.683203, prediction/mean = 0.0705214, label/mean = 0.0740625, average_loss = 0.247913, auc_precision_recall = 0.170481, accuracy = 0.927031

"
19449,"All mirrors are down: [Unknown host: github.com, Unknown host: mirror.bazel.build]:when I used bazel build .","My mechine cannot connect to the internet,I set proxy,but I can't bulid it.
WARNING: ignoring http_proxy in environment.
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz, https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to /root/.cache/bazel/_bazel_root/9227cb95690bff1538ed0807e5bae959/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: [Unknown host: github.com, Unknown host: mirror.bazel.build]
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz, https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to /root/.cache/bazel/_bazel_root/9227cb95690bff1538ed0807e5bae959/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: [Unknown host: github.com, Unknown host: mirror.bazel.build]
INFO: Elapsed time: 2.090s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
"
19448,"In TF Stylize demo,I replace the camera captured bitmap with a predefined one,but not work","I replace the camera captured bitmap with a predefined one,but not work.
The code changes as follows:
`@TargetApi(Build.VERSION_CODES.LOLLIPOP)
public class StylizeActivity  extends Activity  {

  private static final Logger LOGGER = new Logger();

  private static final String MODEL_FILE = ""file:///android_asset/stylize_quantized.pb"";
  private static final String INPUT_NODE = ""input"";
  private static final String STYLE_NODE = ""style_num"";
  private static final String OUTPUT_NODE = ""transformer/expand/conv3/conv/Sigmoid"";
  private static final int NUM_STYLES = 26;

  private static final boolean SAVE_PREVIEW_BITMAP = false;
  private static final boolean NORMALIZE_SLIDERS = true;

  private static final float TEXT_SIZE_DIP = 12;

  private static final boolean DEBUG_MODEL = false;
  private Handler handler;
  private HandlerThread handlerThread;
  private int desiredSize = 256;
  private long lastProcessingTimeMs;
  private final float[] styleVals = new float[NUM_STYLES];
  private int[] intValues;
  private float[] floatValues;

  private int frameNum = 0;
  private ImageView imageView;

  private Bitmap textureCopyBitmap;
  private Bitmap bitmap;
  private Bitmap newbm;
  private Bitmap test;

  private TensorFlowInferenceInterface inferenceInterface;

  private int lastOtherStyle = 1;

  private boolean allZero = false;

  private ImageGridAdapter adapter;
  private GridView grid;
  private int[] rgbBytes = null;
  private Runnable imageConverter;
  // which image
  int position_now;
  // image url
  String url = null;
  private Boolean debug=false;




  private final OnTouchListener gridTouchAdapter =
          new OnTouchListener() {
            ImageSlider slider = null;

            @Override
            public boolean onTouch(final View v, final MotionEvent event) {
              switch (event.getActionMasked()) {
                case MotionEvent.ACTION_DOWN:
                  for (int i = 0; i < NUM_STYLES; ++i) {
                    final ImageSlider child = adapter.items[i];
                    final Rect rect = new Rect();
                    child.getHitRect(rect);
                    if (rect.contains((int) event.getX(), (int) event.getY())) {
                      slider = child;
                      slider.setHilighted(true);
                    }
                  }
                  **chuli();**
                  break;

                case MotionEvent.ACTION_MOVE:
                  if (slider != null) {
                    final Rect rect = new Rect();
                    slider.getHitRect(rect);

                    final float newSliderVal =
                            (float)
                                    Math.min(
                                            1.0,
                                            Math.max(
                                                    0.0, 1.0 - (event.getY() - slider.getTop()) / slider.getHeight()));

                    setStyle(slider, newSliderVal);
                  }
                  **chuli();**
                  break;

                case MotionEvent.ACTION_UP:
                  if (slider != null) {
                    slider.setHilighted(false);
                    slider = null;
                  }
                  **chuli();**
                  break;

                default: // fall out

              }
              return true;
            }
          };
  private int previewWidth;
  private int previewHeight;

  @Override
  protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.camera_connection_fragment_stylize);
    // get intent information
    getMessage();
    initView();


  }

private void initView(){
  adapter = new ImageGridAdapter();
  grid = (GridView) findViewById(R.id.grid_layout);
  grid.setAdapter(adapter);
  grid.setOnTouchListener(gridTouchAdapter);
  imageView=(ImageView)findViewById(R.id.ivs);
  inferenceInterface = new TensorFlowInferenceInterface(getAssets(), MODEL_FILE);

  intValues = new int[desiredSize * desiredSize];
  floatValues = new float[desiredSize * desiredSize * 3];
  BitmapFactory.Options options = new BitmapFactory.Options();
  options.inPreferredConfig = Config.ARGB_8888;
  bitmap = BitmapFactory.decodeFile(url, options);
  previewWidth=bitmap.getWidth();
  previewHeight=bitmap.getHeight();

  **newbm=Bitmap.createScaledBitmap(bitmap,desiredSize,desiredSize,true);**
  **imageView.setImageBitmap(bitmap);

  if(textureCopyBitmap!=null){
    test=big(textureCopyBitmap);
    imageView.setImageBitmap(test);
  }**

}
  private  Bitmap big(Bitmap bitmap) {
    Matrix matrix = new Matrix();
    matrix.postScale(2.f,2.f); //长和宽放大缩小的比例
    Bitmap resizeBmp = Bitmap.createBitmap(bitmap,0,0,bitmap.getWidth(),bitmap.getHeight(),matrix,true);
    return resizeBmp;
  }
private void chuli(){
  runInBackground(
          new Runnable() {
            @Override
            public void run() {
              final long startTime = SystemClock.uptimeMillis();
              stylizeImage(newbm);
              lastProcessingTimeMs = SystemClock.uptimeMillis() - startTime;
              textureCopyBitmap = Bitmap.createBitmap(newbm);
              requestRender();
          
            }
          });
}
  protected void getMessage() {
    Intent intent = getIntent();
    try {
      position_now = intent.getIntExtra(""position"", -1);
      url  = intent.getStringExtra(""url"");
    } catch (Exception e) {
      Log.d(""ERROR: "", """" + e);
    }
    Log.d(""Info: "", """" + position_now + "" "" + url);
  }



  private static Bitmap getBitmapFromAsset(final Context context, final String filePath) {
    final AssetManager assetManager = context.getAssets();

    Bitmap bitmap = null;
    try {
      final InputStream inputStream = assetManager.open(filePath);
      bitmap = BitmapFactory.decodeStream(inputStream);
    } catch (final IOException e) {
      LOGGER.e(""Error opening bitmap!"", e);
    }

    return bitmap;
  }


  @Override
  public synchronized void onStart() {
    LOGGER.d(""onStart "" + this);
    super.onStart();
  }

  @Override
  public synchronized void onResume() {
    LOGGER.d(""onResume "" + this);
    super.onResume();

    handlerThread = new HandlerThread(""inference"");
    handlerThread.start();
    handler = new Handler(handlerThread.getLooper());
  }

  @Override
  public synchronized void onPause() {
    LOGGER.d(""onPause "" + this);

    if (!isFinishing()) {
      LOGGER.d(""Requesting finish"");
      finish();
    }

    handlerThread.quitSafely();
    try {
      handlerThread.join();
      handlerThread = null;
      handler = null;
    } catch (final InterruptedException e) {
      LOGGER.e(e, ""Exception!"");
    }

    super.onPause();
  }

  @Override
  public synchronized void onStop() {
    LOGGER.d(""onStop "" + this);
    super.onStop();
  }

  @Override
  public synchronized void onDestroy() {
    LOGGER.d(""onDestroy "" + this);
    super.onDestroy();
  }

  protected synchronized void runInBackground(final Runnable r) {
    if (handler != null) {
      handler.post(r);
    }
  }

//gridview imagestyle
  private class ImageSlider extends android.support.v7.widget.AppCompatImageView {
    private float value = 0.0f;
    private boolean hilighted = false;

    private final Paint boxPaint;
    private final Paint linePaint;

    public ImageSlider(final Context context) {
      super(context);
      value = 0.0f;

      boxPaint = new Paint();
      boxPaint.setColor(Color.BLACK);
      boxPaint.setAlpha(128);

      linePaint = new Paint();
      linePaint.setColor(Color.WHITE);
      linePaint.setStrokeWidth(10.0f);
      linePaint.setStyle(Style.STROKE);
    }

    @Override
    public void onDraw(final Canvas canvas) {
      super.onDraw(canvas);
      final float y = (1.0f - value) * canvas.getHeight();

      // If all sliders are zero, don't bother shading anything.
      if (!allZero) {
        canvas.drawRect(0, 0, canvas.getWidth(), y, boxPaint);
      }

      if (value > 0.0f) {
        canvas.drawLine(0, y, canvas.getWidth(), y, linePaint);
      }

      if (hilighted) {
        canvas.drawRect(0, 0, getWidth(), getHeight(), linePaint);
      }
    }

    @Override
    protected void onMeasure(final int widthMeasureSpec, final int heightMeasureSpec) {
      super.onMeasure(widthMeasureSpec, heightMeasureSpec);
      setMeasuredDimension(getMeasuredWidth(), getMeasuredWidth());
    }

    public void setValue(final float value) {
      this.value = value;
      postInvalidate();
    }

    public void setHilighted(final boolean highlighted) {
      this.hilighted = highlighted;
      this.postInvalidate();
    }
  }

  public void requestRender() {
    final OverlayView overlay = (OverlayView) findViewById(R.id.debug_overlay);
    if (overlay != null) {
      overlay.postInvalidate();
    }
  }

  public void addCallback(final OverlayView.DrawCallback callback) {
    final OverlayView overlay = (OverlayView) findViewById(R.id.debug_overlay);
    if (overlay != null) {
      overlay.addCallback(callback);
    }
  }
  
  private class ImageGridAdapter extends BaseAdapter {
    final ImageSlider[] items = new ImageSlider[NUM_STYLES];
    final ArrayList<Button> buttons = new ArrayList<>();

    {
      final Button saveButton =
          new android.support.v7.widget.AppCompatButton(StylizeActivity.this) {
            @Override
            protected void onMeasure(final int widthMeasureSpec, final int heightMeasureSpec) {
              super.onMeasure(widthMeasureSpec, heightMeasureSpec);
              setMeasuredDimension(getMeasuredWidth(), getMeasuredWidth());
            }
          };
      saveButton.setText(""save"");
      saveButton.setTextSize(12);

      saveButton.setOnClickListener(
          new OnClickListener() {
            @Override
            public void onClick(final View v) {
              if ( test != null) {
                // TODO(andrewharp): Save as jpeg with guaranteed unique filename.
                ImageUtils.saveBitmap(test, ""stylized"" + url + "".png"");
                Toast.makeText(
                        StylizeActivity.this,
                        ""Saved image to: /sdcard/tensorflow/"" + ""stylized"" + url + "".png"",
                        Toast.LENGTH_LONG)
                    .show();
              }
            }
          });


      buttons.add(saveButton);

      for (int i = 0; i < NUM_STYLES; ++i) {
        LOGGER.v(""Creating item %d"", i);

        if (items[i] == null) {
          final ImageSlider slider = new ImageSlider(StylizeActivity.this);
          final Bitmap bm =
              getBitmapFromAsset(StylizeActivity.this, ""thumbnails/style"" + i + "".jpg"");
          slider.setImageBitmap(bm);

          items[i] = slider;
        }
      }
    }

    @Override
    public int getCount() {
      return buttons.size() + NUM_STYLES;
    }

    @Override
    public Object getItem(final int position) {
      if (position < buttons.size()) {
        return buttons.get(position);
      } else {
        return items[position - buttons.size()];
      }
    }

    @Override
    public long getItemId(final int position) {
      return getItem(position).hashCode();
    }

    @Override
    public View getView(final int position, final View convertView, final ViewGroup parent) {
      if (convertView != null) {
        return convertView;
      }
      return (View) getItem(position);
    }
  }


  private void setStyle(final ImageSlider slider, final float value) {
    slider.setValue(value);

    if (NORMALIZE_SLIDERS) {
      // Slider vals correspond directly to the input tensor vals, and normalization is visually
      // maintained by remanipulating non-selected sliders.
      float otherSum = 0.0f;

      for (int i = 0; i < NUM_STYLES; ++i) {
        if (adapter.items[i] != slider) {
          otherSum += adapter.items[i].value;
        }
      }

      if (otherSum > 0.0) {
        float highestOtherVal = 0;
        final float factor = otherSum > 0.0f ? (1.0f - value) / otherSum : 0.0f;
        for (int i = 0; i < NUM_STYLES; ++i) {
          final ImageSlider child = adapter.items[i];
          if (child == slider) {
            continue;
          }
          final float newVal = child.value * factor;
          child.setValue(newVal > 0.01f ? newVal : 0.0f);

          if (child.value > highestOtherVal) {
            lastOtherStyle = i;
            highestOtherVal = child.value;
          }
        }
      } else {
        // Everything else is 0, so just pick a suitable slider to push up when the
        // selected one goes down.
        if (adapter.items[lastOtherStyle] == slider) {
          lastOtherStyle = (lastOtherStyle + 1) % NUM_STYLES;
        }
        adapter.items[lastOtherStyle].setValue(1.0f - value);
      }
    }

    final boolean lastAllZero = allZero;
    float sum = 0.0f;
    for (int i = 0; i < NUM_STYLES; ++i) {
      sum += adapter.items[i].value;
    }
    allZero = sum == 0.0f;

    // Now update the values used for the input tensor. If nothing is set, mix in everything
    // equally. Otherwise everything is normalized to sum to 1.0.
    for (int i = 0; i < NUM_STYLES; ++i) {
      styleVals[i] = allZero ? 1.0f / NUM_STYLES : adapter.items[i].value / sum;

      if (lastAllZero != allZero) {
        adapter.items[i].postInvalidate();
      }
    }
  }

public boolean isDebug() {
  return debug;
}

  private void stylizeImage(final Bitmap bitmap) {
    ++frameNum;
    bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());

    if (DEBUG_MODEL) {
      // Create a white square that steps through a black background 1 pixel per frame.
      final int centerX = (frameNum + bitmap.getWidth() / 2) % bitmap.getWidth();
      final int centerY = bitmap.getHeight() / 2;
      final int squareSize = 10;
      for (int i = 0; i < intValues.length; ++i) {
        final int x = i % bitmap.getWidth();
        final int y = i / bitmap.getHeight();
        final float val =
            Math.abs(x - centerX) < squareSize && Math.abs(y - centerY) < squareSize ? 1.0f : 0.0f;
        floatValues[i * 3] = val;
        floatValues[i * 3 + 1] = val;
        floatValues[i * 3 + 2] = val;
      }
    } else {
      for (int i = 0; i < intValues.length; ++i) {
        final int val = intValues[i];
        floatValues[i * 3] = ((val >> 16) & 0xFF) / 255.0f;
        floatValues[i * 3 + 1] = ((val >> 8) & 0xFF) / 255.0f;
        floatValues[i * 3 + 2] = (val & 0xFF) / 255.0f;
      }
    }

    // Copy the input data into TensorFlow.
    LOGGER.i(""Width: %s , Height: %s"", bitmap.getWidth(), bitmap.getHeight());
    inferenceInterface.feed(
        INPUT_NODE, floatValues, 1, bitmap.getWidth(), bitmap.getHeight(), 3);
    inferenceInterface.feed(STYLE_NODE, styleVals, NUM_STYLES);
    inferenceInterface.run(new String[] {OUTPUT_NODE}, isDebug());
    inferenceInterface.fetch(OUTPUT_NODE, floatValues);
    for (int i = 0; i < intValues.length; ++i) {
      intValues[i] =
          0xFF000000
              | (((int) (floatValues[i * 3] * 255)) << 16)
              | (((int) (floatValues[i * 3 + 1] * 255)) << 8)
              | ((int) (floatValues[i * 3 + 2] * 255));
    }

    bitmap.setPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
  }

public void onSetDebug(final boolean debug) {}
  @Override
  public boolean onKeyDown(int keyCode, KeyEvent event) {
    int moveOffset = 0;
    switch (keyCode) {
      case KeyEvent.KEYCODE_DPAD_LEFT:
        moveOffset = -1;
        break;
      case KeyEvent.KEYCODE_DPAD_RIGHT:
        moveOffset = 1;
        break;
      case KeyEvent.KEYCODE_DPAD_UP:
        moveOffset = -1 * grid.getNumColumns();
        break;
      case KeyEvent.KEYCODE_DPAD_DOWN:
        moveOffset = grid.getNumColumns();
        break;
      default:
        **if (keyCode == KeyEvent.KEYCODE_VOLUME_DOWN || keyCode == KeyEvent.KEYCODE_VOLUME_UP
                || keyCode == KeyEvent.KEYCODE_BUTTON_L1 || keyCode == KeyEvent.KEYCODE_DPAD_CENTER) {
          debug = !debug;
          requestRender();
          onSetDebug(debug);
          return true;
        }**
        return super.onKeyDown(keyCode, event);
    }

    // get the highest selected style
    int currentSelect = 0;
    float highestValue = 0;
    for (int i = 0; i < adapter.getCount(); i++) {
      if (adapter.items[i].value > highestValue) {
        currentSelect = i;
        highestValue = adapter.items[i].value;
      }
    }
    setStyle(adapter.items[(currentSelect + moveOffset + adapter.getCount()) % adapter.getCount()], 1);

    return true;
  }

}
`
I preprocessed the bitmap and resized it to(256,256).But when I touch the grideview ,nothing happend. So I want to know how should I modify it so that it can achieve stylize??
"
19447,whether one tensor  can be distributed to different gpu cards?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem

I have six gpu cards ,  i have a problem that my data have 90000 attribute, whether i can be distributed one `weight`  tensor to different cards?  where i can found a example?

"
19444,Cannot use per process memory fraction in tensorflow distributed,"**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- OS Platform and Distribution :  Linux Ubuntu 16.04 (Deep Learning AMI (Ubuntu) Version 8.0 (ami-dff741a0) on AWS)
- TensorFlow installed from binary:
- TensorFlow version : v1.7.0-13-g99322a92bf 1.7.0
- Python version : Python 3.6.4 :: Anaconda, Inc. 
- CUDA/cuDNN version : 9.0, V9.0.176
- GPU model and memory : Tesla K80, 12gb
- Bazel version : N/A
- **Exact command to reproduce**:

```
  train_dataset = tf.data.TFRecordDataset([train_file])
  train_dataset = train_dataset.map(lambda x : _parse_function(x), num_parallel_calls = 4)
  train_dataset = train_dataset.batch(train_batch_size)
  #train_dataset = train_dataset.prefetch(buffer_size = 1000)
  train_dataset = train_dataset.repeat()
  train_iterator = train_dataset.make_initializable_iterator()
  next_train_element = train_iterator.get_next()
![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332854-82ac9076-5d0a-11e8-8c81-8ef0f982f41f.png)
![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332868-9198bd8a-5d0a-11e8-9f3c-f40b93687371.png)

cluster = tf.train.ClusterSpec({
            ""ps"": FLAGS.ps_hosts.split("",""),
            ""worker"": FLAGS.worker_hosts.split("","")})

  server = tf.train.Server(cluster, 
                           job_name = FLAGS.job_name,
                           task_index = FLAGS.task_index)

if FLAGS.job_name == ""ps"":
    server.join()
  elif FLAGS.job_name == ""worker"":
    with tf.device(tf.train.replica_device_setter(
                       worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
                       cluster=cluster)):

      users_input = tf.placeholder(tf.float32, shape = [None, items_size], name = 'User_input')
      items_input = tf.placeholder(tf.float32, shape = [None, users_size], name = 'Item_input')
      ratings_input = tf.placeholder(tf.float32, shape = [None, 1], name = 'Rating_input')
```

... model defn

```
init_op = tf.initialize_all_variables()
hooks=[tf.train.StopAtStepHook(last_step=10000)]
sess_config = tf.ConfigProto(allow_soft_placement = True, log_device_placement = True)
sess_config.gpu_options.allow_growth = True
sess_config.gpu_options.per_process_gpu_memory_fraction = 0.33

with tf.train.MonitoredTrainingSession(master=server.target,
                                           is_chief=(FLAGS.task_index == 0),
                                           checkpoint_dir=FLAGS.log_dir,
                                           hooks=hooks,
                                           save_summaries_steps = 10,
                                           config = sess_config) as sess:
```
... model training 



....

Processes completely utilize the available gpu memory. I further reduced the batch size to 20, input is sensor input values, not images.


![screen shot 2018-05-21 at 2 37 10 pm](https://user-images.githubusercontent.com/13630072/40332635-8fa94fd6-5d09-11e8-9bcc-9b0f70946387.png)

![screen shot 2018-05-21 at 3 19 59 pm](https://user-images.githubusercontent.com/13630072/40332884-9fa526f2-5d0a-11e8-8a19-12870cd01d2d.png)


"
19442,Feature Request: Checkpointable slot_variables for AdamOptimizer,"When using `tf.train.Checkpoint()` in combination with the `AdamOptimizer` the following error is thrown.

```
load_status.initialize_or_restore(self.session)
  File ""/home/lib/python3.5/site-packages/tensorflow/python/training/checkpointable_utils.py"", line 677, in initialize_or_restore
    checkpointable_objects = list_objects(self._root_checkpointable)
  File ""/home/lib/python3.5/site-packages/tensorflow/python/training/checkpointable_utils.py"", line 472, in list_objects
    object_names=object_names)
  File ""/home/lib/python3.5/site-packages/tensorflow/python/training/checkpointable_utils.py"", line 291, in _serialize_slot_variables
    ""A slot variable was re-used as a dependency of a ""
NotImplementedError: A slot variable was re-used as a dependency of a Checkpointable object. This is not currently allowed. File a feature request if this limitation bothers you
```

See also: https://github.com/tensorflow/tensorflow/issues/19208"
19441,Feature request: Generate java classes from .protos for java library,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Yes
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 5.3.1
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
It would be nice to be able to handle protobufs within java as java classes, rather than byte arrays, as is currently done. Concretely, this would be useful because we could extract the input and output variable names from, e.g.: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/protobuf/meta_graph.proto, instead of having to hard-code them in our java code, hoping that they python code which produced the MetaGraphDef hasn't changed the input or output names. I am sure there are other helpful things one could do with programmatic access to their protobufs.

I don't see a better way to do this than to modify tensorflow's BUILD files to call the rule `java_proto_library` in [tf_proto_library](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/default/build_config.bzl). Since .proto files are not exported in the python wheel, or the java jar, end-users do not currently have the ability to generate their own files from the .proto files.

I would be happy to do this if the maintainers think it is a reasonable request and don't consider it to be a burdensome thing to maintain.

### Source code / logs
N/A
"
19440,Race codition during updating of checkpoint file on samba file share,"Have I written custom code: No. Any code generating checkpoints on Azure File Share seems to be affected.
OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from: NA (doesn't matter)
TensorFlow version: 1.6 (but seems to be the case for other versions as well)
Bazel version: NA
CUDA/cuDNN version: 9.0 (doesn't matter)
GPU model and memory: K80
Exact command to reproduce: launch long running training job which generates checkpoints on Azure File Share or just simulate race conditions in atomic_write_string_to_file when the target file is opened by other thread or process (see Describe the problem below).

### Describe the problem
I am observing a race condition while writing checkpoint file into Azure File Share directory - atomic_write_string_to_file sometimes (after multiple hours of training) crashes with ""Permission denied"" error. This race condition seems to be the same as being fixed by 3758878728710801f681afba39e145df4ddb8bf1. Unfortunately, this fix doesn't work on Azure file share (and, probably, on cifs in general) because of a fancy samba behavior - rename of a file fails if the target file is currently opened. Here is a simple repro for this behavior:

    import os
    f = open('target.txt', 'r')
    os.rename('source.txt', 'target.txt')

    Traceback (most recent call last):
    PermissionError: [Errno 13] Permission denied: 'source.txt' -> 'target.txt'

"
19439,Manjaro/Arch Linux: build from sources fails,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Manjaro (Arch Linux; Kernel 4.16.8)
- **TensorFlow installed from (source or binary)**: sources
- **TensorFlow version (use command below)**: 1.7.1
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.13
- **GCC/Compiler version (if compiling from source)**: 4.9.3, 5.4.1, 6.4.1, 8.1
- **CUDA/cuDNN version**: 9.0.176 / 7.0.5
- **GPU model and memory**: GTX 1080 8GB


### Describe the problem
Build from sources **fails** with CUDA support.
Build for CPU-only works properly.
``pip install tensorflow-gpu==1.7.1`` works properly, I'd just prefer a custom build with --march native stuff.

Any suggestions? Should I try to build older versions of TensorFlow?


### Source code / logs
**gcc-4.9** build fails very early on complaining about missing files:
``libmpfr.so.4: cannot open shared object file: No such file or directory``

The same goes for **gcc-5.4**, although it builds for a few seconds longer and fails with other missing files.

**gcc-6.4** compiles for 1-2 minutes, then fails with:
```
/usr/include/bits/floatn.h(74): error: invalid argument to attribute ""__mode__""

/usr/include/bits/floatn.h(86): error: identifier ""__float128"" is undefined

2 errors detected in the compilation of ""/tmp/tmpxft_00003957_00000000-6_libwrap.cu.cpp1.ii"".
ERROR: (...) output 'external/nccl_archive/_objs/nccl/external/nccl_archive/src/libwrap.cu.pic.o' was not created
ERROR: (...) not all outputs were created or valid
```

**gcc-8.1** builds for 20+ seconds and then fails with ``undeclared inclusion(s) in rule '@nccl_archive``. Sometimes with another rule (maybe it depends which rule is violated first? I am building with 16 threads).


"
19438,Unable to import tensorflow error,"I am getting below while importing tensorflow
My OS is windows 10
cuda -9.2
cudnn -7
tensorflow - 1.8.0

tensorflow installed from pip3

Traceback (most recent call last):
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\platform\self_check.py"", line 75, in preload_check
    ctypes.WinDLL(build_info.cudart_dll_name)
  File ""C:\Program Files\Python36\lib\ctypes\__init__.py"", line 348, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""C:\Program Files\Python36\lib\site-packages\tensorflow\python\platform\self_check.py"", line 82, in preload_check
    % (build_info.cudart_dll_name, build_info.cuda_version_number))
ImportError: Could not find 'cudart64_90.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 9.0 from this URL: https://developer.nvidia.com/cuda-toolkit"
19437,My tensorflow model doesn't work on c++ iOS,"I am trying to do character recognition mobile app with CNN. My model predict with %99,6 accuracy on python. But when I m trying to use same model with c++ in iOS app it can't predict any value. 

I am getting pixelBuffer values from images for my cnn model with this:

        pixelBuffer(width: width, height: height,
                           pixelFormatType: kCVPixelFormatType_32BGRA,
                           colorSpace: CGColorSpaceCreateDeviceRGB(),
                           alphaInfo: .noneSkipFirst)

    func pixelBuffer(width: Int, height: Int, pixelFormatType: OSType,
                     colorSpace: CGColorSpace, alphaInfo: CGImageAlphaInfo) -> CVPixelBuffer? {
        var maybePixelBuffer: CVPixelBuffer?
        let attrs = [kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
                     kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue]
        let status = CVPixelBufferCreate(kCFAllocatorDefault,
                                         width,
                                         height,
                                         pixelFormatType,
                                         attrs as CFDictionary,
                                         &maybePixelBuffer)
        
        guard status == kCVReturnSuccess, let pixelBuffer = maybePixelBuffer else {
            return nil
        }
        
        CVPixelBufferLockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))
        let pixelData = CVPixelBufferGetBaseAddress(pixelBuffer)
        
        guard let context = CGContext(data: pixelData,
                                      width: width,
                                      height: height,
                                      bitsPerComponent: 8,
                                      bytesPerRow: CVPixelBufferGetBytesPerRow(pixelBuffer),
                                      space: colorSpace,
                                      bitmapInfo: alphaInfo.rawValue)
            else {
                return nil
        }
        
        UIGraphicsPushContext(context)
        context.translateBy(x: 0, y: CGFloat(height))
        context.scaleBy(x: 1, y: -1)
        self.draw(in: CGRect(x: 0, y: 0, width: width, height: height))
        UIGraphicsPopContext()
        
        CVPixelBufferUnlockBaseAddress(pixelBuffer, CVPixelBufferLockFlags(rawValue: 0))
        return pixelBuffer}

and then I m creating my model with this settings:

        static NSString* model_file_name = @""inference_1_1_0"";
        static NSString* model_file_type = @""pb"";
        static NSString* labels_file_name = @""labels"";
        static NSString* labels_file_type = @""txt"";
        std::unique_ptr<tensorflow::Session> tf_session;
        std::vector<std::string> labels;

        const int wanted_input_width = 38;
        const int wanted_input_height = 45;
        const int wanted_input_channels = 3;
        const float input_mean = 117.0f;
        const float input_std = 1.0f;
        const std::string input_layer_name = ""input_input"";
        const std::string output_layer_name = ""output_node0"";

but I have no idea what should I use for `input_mean` and `input_std` . Maybe they can be problem. 
I got runCNN method default from [Tensorflow Example](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/ios/camera/CameraExampleViewController.mm)

I really have no idea my image is wrong or should I change any default settings from tensorflow

Thanks.

- Have I written custom code: Yes
- OS Platform and Distribution: Mac OS 10.13.3 High Sierra
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.1.0 on Mac (Tensorflow-Experimental on iOS)
- Python version: 3
- Bazel version: 0.13.0
- CUDA/cuDNN: N/A
- GPU model and Memory: N/A
- Exact command to reproduce: When I am trying to predict with my model it's always predict wrong.(Prediction)"
19436,CANNOT IMPORT TENSORFLOW 1.8.0 (PYTHON 3) ON COLAB: AttributeError: module 'tensorflow.python.training.checkpointable' has no attribute 'CheckpointableBase',"### System information
- **The only code is importing `tensorflow` as `tf`**
- **OS Platform and Distribution: [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb), Python 3, non-GPU Runtime**
- **TensorFlow installed from `pip`**
- **TensorFlow version 1.8.0 (the `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` command does not work, and only returns the error below)**
- **Python version: Python 3** 
- **CUDA/cuDNN version: Unknown, `!nvcc --version` returns `/bin/sh: 1: nvcc: not found`**
- **GPU model and memory: Non GPU Runtime, ~13.34 GB of Memory**
- **Exact command to reproduce: (See Below)**


### Describe the problem
Simply put, importing tensorflow in python 3 within Google Colab results in the following error. There is no other code that has been run, other than `!pip install --upgrade tensorflow`. No information has come up in a Google Search, let alone StackOverflow. The usual advice of uninstalling tensorlfow, uninstalling protobuf, and then reinstalling tensorflow (which should contain the appropriate protobuf version), does not fix this issue.

### Source code / logs
#### Source Code:
```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
import seaborn as sns

import tensorflow as tf                            # importing Tensorflow
import tensorflow_probability as tfp               # and Tensorflow probability
from tensorflow_probability import edward2 as ed   # Edwardlib extension

tfd = tfp.distributions             # Basic probability distribution toolkit
tfb = tfp.distributions.bijectors   # and their modifiers

# Eager Execution
# tfe = tf.contrib.eager
# tfe.enable_eager_execution()

%matplotlib inline
plt.style.use(""fivethirtyeight"")        # Styling plots like FiveThirtyEight

import warnings
warnings.filterwarnings('ignore')
%config InlineBackend.figure_format=""retina"" # improves resolution of plots
```

#### Logs:
```python
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-20-649f48dbabd7> in <module>()
      8 import seaborn as sns
      9 
---> 10 import tensorflow as tf                            # importing Tensorflow
     11 import tensorflow_probability as tfp               # and Tensorflow probability
     12 from tensorflow_probability import edward2 as ed   # Edwardlib extension

/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=g-bad-import-order
---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
     25 # pylint: disable=wildcard-import
     26 from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin

/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py in <module>()
     79 # Bring in subpackages.
     80 from tensorflow.python import data
---> 81 from tensorflow.python import keras
     82 from tensorflow.python.estimator import estimator_lib as estimator
     83 from tensorflow.python.feature_column import feature_column_lib as feature_column

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/__init__.py in <module>()
     24 
     25 # pylint: disable=wildcard-import
---> 26 from tensorflow.python.keras import activations
     27 from tensorflow.python.keras import applications
     28 from tensorflow.python.keras import backend

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/activations/__init__.py in <module>()
     20 
     21 # Activation functions.
---> 22 from tensorflow.python.keras._impl.keras.activations import elu
     23 from tensorflow.python.keras._impl.keras.activations import hard_sigmoid
     24 from tensorflow.python.keras._impl.keras.activations import linear

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/__init__.py in <module>()
     19 from __future__ import print_function
     20 
---> 21 from tensorflow.python.keras._impl.keras import activations
     22 from tensorflow.python.keras._impl.keras import applications
     23 from tensorflow.python.keras._impl.keras import backend

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/activations.py in <module>()
     21 import six
     22 
---> 23 from tensorflow.python.keras._impl.keras import backend as K
     24 from tensorflow.python.keras._impl.keras.utils.generic_utils import deserialize_keras_object
     25 from tensorflow.python.layers.base import Layer

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/_impl/keras/backend.py in <module>()
     36 from tensorflow.python.framework import sparse_tensor
     37 from tensorflow.python.framework import tensor_util
---> 38 from tensorflow.python.layers import base as tf_base_layers
     39 from tensorflow.python.ops import array_ops
     40 from tensorflow.python.ops import clip_ops

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in <module>()
     43 
     44 @tf_export('layers.Layer')
---> 45 class Layer(checkpointable.CheckpointableBase):
     46   """"""Base layer class.
     47 

AttributeError: module 'tensorflow.python.training.checkpointable' has no attribute 'CheckpointableBase'
```
"
19435,CANNOT IMPORT TENSORFLOW 1.8.0 (PYTHON 2) ON COLAB: ImportError: cannot import name abs,"### System information
- **The only code is importing `tensorflow` as `tf`**
- **OS Platform and Distribution: [Google Colab](https://colab.research.google.com/notebooks/welcome.ipynb), Python 2, non-GPU Runtime**
- **TensorFlow installed from `pip`**
- **TensorFlow version 1.8.0 (the `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` command does not work, and only returns the error below)**
- **Python version: Python 2** 
- **CUDA/cuDNN version: Unknown, `!nvcc --version` returns `/bin/sh: 1: nvcc: not found`**
- **GPU model and memory: Non GPU Runtime, ~13.34 GB of Memory**
- **Exact command to reproduce: (See Below)**


### Describe the problem
Simply put, importing tensorflow in python 2 within Google Colab results in the following error. There is no other code that has been run, other than `!pip install --upgrade tensorflow`. No information has come up in a Google Search, let alone StackOverflow.

### Source code / logs
#### Source Code:
```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
import seaborn as sns

import tensorflow as tf                            # importing Tensorflow
import tensorflow_probability as tfp               # and Tensorflow probability
from tensorflow_probability import edward2 as ed   # Edwardlib extension

tfd = tfp.distributions             # Basic probability distribution toolkit
tfb = tfp.distributions.bijectors   # and their modifiers

# Eager Execution
# tfe = tf.contrib.eager
# tfe.enable_eager_execution()

%matplotlib inline
plt.style.use(""fivethirtyeight"")        # Styling plots like FiveThirtyEight

import warnings
warnings.filterwarnings('ignore')
%config InlineBackend.figure_format=""retina"" # improves resolution of plots
```

#### Logs:
```python
ImportErrorTraceback (most recent call last)
<ipython-input-3-42b866c8ed86> in <module>()
      8 import seaborn as sns
      9 
---> 10 import tensorflow as tf                            # importing Tensorflow
     11 import tensorflow_probability as tfp               # and Tensorflow probability
     12 from tensorflow_probability import edward2 as ed   # Edwardlib extension

/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=g-bad-import-order
---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
     25 # pylint: disable=wildcard-import
     26 from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin

/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py in <module>()
     79 # Bring in subpackages.
     80 from tensorflow.python import data
---> 81 from tensorflow.python import keras
     82 from tensorflow.python.estimator import estimator_lib as estimator
     83 from tensorflow.python.feature_column import feature_column_lib as feature_column

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/__init__.py in <module>()
     22 from __future__ import print_function
     23 
---> 24 from tensorflow.python.keras import activations
     25 from tensorflow.python.keras import applications
     26 from tensorflow.python.keras import backend

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/activations/__init__.py in <module>()
     20 
     21 # Activation functions.
---> 22 from tensorflow.python.keras._impl.keras.activations import elu
     23 from tensorflow.python.keras._impl.keras.activations import hard_sigmoid
     24 from tensorflow.python.keras._impl.keras.activations import linear

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/__init__.py in <module>()
     19 from __future__ import print_function
     20 
---> 21 from tensorflow.python.keras._impl.keras import activations
     22 from tensorflow.python.keras._impl.keras import applications
     23 from tensorflow.python.keras._impl.keras import backend

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/activations.py in <module>()
     21 import six
     22 
---> 23 from tensorflow.python.keras._impl.keras import backend as K
     24 from tensorflow.python.keras._impl.keras.utils.generic_utils import deserialize_keras_object
     25 from tensorflow.python.layers.base import Layer

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/_impl/keras/backend.py in <module>()
     36 from tensorflow.python.framework import sparse_tensor
     37 from tensorflow.python.framework import tensor_util
---> 38 from tensorflow.python.layers import base as tf_base_layers
     39 from tensorflow.python.ops import array_ops
     40 from tensorflow.python.ops import clip_ops

/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.py in <module>()
     23 from tensorflow.python.framework import dtypes
     24 from tensorflow.python.framework import ops
---> 25 from tensorflow.python.keras.engine import base_layer
     26 from tensorflow.python.ops import variable_scope as vs
     27 from tensorflow.python.ops import variables as tf_variables

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/__init__.py in <module>()
     19 from __future__ import print_function
     20 
---> 21 from tensorflow.python.keras.engine.base_layer import InputSpec
     22 from tensorflow.python.keras.engine.base_layer import Layer
     23 from tensorflow.python.keras.engine.input_layer import Input

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/base_layer.py in <module>()
     30 from tensorflow.python.framework import tensor_shape
     31 from tensorflow.python.framework import tensor_util
---> 32 from tensorflow.python.keras import backend
     33 from tensorflow.python.keras import constraints
     34 from tensorflow.python.keras import initializers

/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/backend/__init__.py in <module>()
     20 
     21 # pylint: disable=redefined-builtin
---> 22 from tensorflow.python.keras._impl.keras.backend import abs
     23 from tensorflow.python.keras._impl.keras.backend import all
     24 from tensorflow.python.keras._impl.keras.backend import any

ImportError: cannot import name abs

---------------------------------------------------------------------------
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
""Open Examples"" button below.
---------------------------------------------------------------------------
```
"
19434,"Compiling libtensorflow_inference.so generates error: ""error: undefined reference to 'dl_iterate_phdr'""","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.8.0-2153-ge844159e63', '1.8.0')
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: 4.9
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: bazel build //tensorflow/contrib/android:libtensorflow_inference.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=x86

I believe this is a bug

When I run the above command, at some point the compiler / linker stops with the following error message:

ERROR: /home/karsten/.cache/bazel/_bazel_karsten/c3148022e5394457e9b87b7ac08211f4/external/protobuf_archive/BUILD:259:1: Linking of rule '@protobuf_archive//:js_embed' failed (Exit 1)
/usr/local/google/buildbot/src/android/gcc/toolchain/build/../gcc/gcc-4.9/libgcc/unwind-dw2-fde-dip.c:461: error: undefined reference to 'dl_iterate_phdr'
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build
Use --verbose_failures to see the command lines of failed build steps.

I have not injected any custom code. "
19433,Tensorflow on iMX6 with Vivante GPU - OpenCL support enabled,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **Target OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.9 Yocto
- **TensorFlow installed from (source or binary)**: Source (Cross Compiling for arm)
- **TensorFlow version (use command below)**: 1.5
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.10.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0 
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: Vivante GPU - GC2000, OpenCL 1.1
- **Exact commands to reproduce**:
$ ./configure
You have bazel 0.10.1 installed.
Please specify the location of python. [Default is /usr/bin/python]: 

Found possible Python library paths:
  /opt/ros/indigo/lib/python2.7/dist-packages
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/opt/ros/indigo/lib/python2.7/dist-packages]
/usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: y
jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: y
OpenCL SYCL support will be enabled for TensorFlow.

Please specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]: 

Please specify which C compiler should be used as the hostC compiler. [Default is /usr/bin/gcc]: 

Do you wish to build TensorFlow with ComputeCPP support? [Y/n]: y
ComputeCPP support will be enabled for TensorFlow.

Please specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]: <Relative Location>/ComputeCpp-CE-0.7.0-Ubuntu-14.04-ARM_32

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: -march=armv7-a

Add ""--config=mkl"" to your bazel command to build with MKL support.
Please note that MKL on MacOS or windows is still not supported.
If you would like to use a local MKL instead of downloading, please set the environment variable ""TF_MKL_ROOT"" every time before build.

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Configuration finished


$ bazel build --crosstool_top=//arm-compiler:toolchain --config=sycl --cpu=armeabi-v7a --config=opt -s tensorflow/examples/label_image/...  --cxxopt=""-std=c++11"" --copt=""-mfpu=neon""


I am currently trying to run a deep learning **inference CNN network on embedded platforms in real-time using GPU** with improved performance. Instead of creating my own inference engine, I thought of using existing frameworks in GPU mode itself to leverage the performance. 

After various study, I found that in the list of frameworks (Caffe, Tensorflow, MxNet, Torch) there are no resource on how to cross compile a particular framework for my arm architecture except few resources for Tensorflow. Though many frameworks suggest to use native compilation for building from source, I have not provided with the resources to build natively for my iMX6 quad [CPU : 4x Arm® Cortex®-A9 up to 1.2 GHz per core , GPU : Vivante GC2000] (yocto build) leaving cross compilation as the only option.

I referred this link - [Cross compiling TF for Jetson TK1][1] and got successful in cross compiling Tensorflow cpu version. To benchmark, I tried to run Inception network and found CPU utilization is nearly 80% and the inference time is around 3.5 seconds. I need to make use of the **vivante GPU (Embedded Profile : OpenCL 1.1)** available in the board to reduce this utilization percentage and the inference time. 

**Since to use GPU,** 

(A) CUDA option is ruled out taking into the consideration I have no nvidia GPU's.

(B) I tried to make use of the OpenCL capability [OpenCL support][2]. Using the similar way (like the CPU build) I tried to cross compile with OpenCL flags support this time, but failing miserably during the build. 

**Forum responses :** 

1. They claim cross compiling TF with computecpp(codeplay sycl) is not possible. [Codeplay forum][3]

2. Another implementation method with TriSycl claims the codes only use CPU, the option of using GPU is under research. [TriSycl forum][4]

**Questions :** 

There is an another SYCL implementation available open source [Sycl ProGTX][5].
-> Whether Tensorflow  has an idea to integrate this implementation? 
-> Also is there any pre-requisite, my device driver version is only OpenCL 1.1? Is that enough to run the tensorflow code?

Anyone attempted this and got success. Kindly guide me on how to proceed further to achieve my goal.

  [1]: http://www.morethantechnical.com/2018/03/08/cross-compile-latest-tensorflow-1-5-for-the-nvidia-jetson-tk1/
  [2]: https://github.com/tensorflow/tensorflow/issues/22
  [3]: https://github.com/codeplaysoftware/computecpp-sdk/issues/68#issuecomment-348952794
  [4]: http://%20https://github.com/triSYCL/triSYCL/pull/45
  [5]: https://github.com/ProGTX/sycl-gtx
"
19431,TFLite toco failed to conver quantized model ( mobilenet_v1_1.0_224 ) to tflite format,"### Describe the Problem

Firstly, I download the mobilenet_v1_1.0_224 model from ( http://download.tensorflow.org/models/mobilenet_v1_2018_02_22/mobilenet_v1_1.0_224.tgz ) ;

Then, i used Command  belown to get a quantized model ( mobilenet_v1_1.0_224_frozen_quantized_graph.pb  ) successfully.

```
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=/tmp /mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen.pb \
--inputs=""input"" \
--outputs=""MobilenetV1/Predictions/Reshape_1"" \
--out_graph=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \
--transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,224,224,3"") 
remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true) 
fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes 
strip_unused_nodes sort_by_execution_order'
```
However , when I used TFLite toco Command to convert .pb to .lite format but ERROR was output

#### TFLite toco Build Command:

```
bazel run --config=opt \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.pb \
  --output_file=/tmp/mobilenet_v1_1.0_224/mobilenet_v1_1.0_224_frozen_quantized_graph.lite \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --input_shapes=1,224,224,3 \
  --mean_values=128 \
  --std_values=128 \
  --input_arrays=""input"" \
  --output_arrays=""MobilenetV1/Predictions/Reshape_1"" \
  --inference_type=QUANTIZED_UINT8 \
  --default_ranges_min=0 \
  --default_ranges_max=6 

```
#### ERROR OUTPUT:
```
2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.
```

#### ERROR LOG:

```
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedConv2D
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: RequantizationRange
……
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizeV2
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: QuantizedReshape
: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1326] Converting unsupported operation: Dequantize
2018-05-21 17:32:50.581333: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 352 operators, 853 arrays (0 quantized)
2018-05-21 17:32:50.601042: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 352 operators, 853 arrays (0 quantized)
2018-05-21 17:32:50.603908: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:42] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.

```

"
19430,tensorflow Win10+python3.5+Cpu(or Gpu) with Link Error 2019,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Win10
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**: git clone https://github.com/tensorflow/tensorflow.git
- **Python version**: both 3.5.2 and 3.6
- **Bazel version (if compiling from source)**: I used both CMAKE 3.6.3 and 3.11.1
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: used CPU and CUDA9.0
- **GPU model and memory**: GTX-860m with 2Gb Memory
- **Exact command to reproduce**: set PreferredToolArchitecture=x64 & MSBuild /p:Configuration=Release ALL_BUILD.vcxproj


### Describe the problem
When .../build dir‘s size is 3.6Gb,  the MSBuild Command Prompt has the following LINK errors：
```
""
“D:\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj”(默认目标) (1) ->
“D:\tensorflow\tensorflow\contrib\cmake\build\benchmark_model.vcxproj”(默认目标) (254) ->
(Link 目标) ->
  eager_operation.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int
)"" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function ""public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow
::TensorHandle *)"" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\benchmark_model.vcxpro
j]
  execute.obj : error LNK2019: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef c
onst * *)"" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecut
e(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVS
tatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\benchmark_m
odel.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basi
c_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basi
c_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensor
flow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa
gerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\benchmark_model.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)""
 (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class ten
sorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEA
VEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\benchmark_model.vcxpro
j]
  D:\tensorflow\tensorflow\contrib\cmake\build\Release\benchmark_model.exe : fatal error LNK1120: 4 unresolved externals [D:\tensorflow\tensorflow\contri
b\cmake\build\benchmark_model.vcxproj]


“D:\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj”(默认目标) (1) ->
“D:\tensorflow\tensorflow\contrib\cmake\build\compare_graphs.vcxproj”(默认目标) (255) ->
  eager_operation.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int
)"" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function ""public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow
::TensorHandle *)"" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\compare_graphs.vcxproj
]
  execute.obj : error LNK2019: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef c
onst * *)"" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecut
e(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVS
tatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\compare_gra
phs.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basi
c_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basi
c_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensor
flow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa
gerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\compare_graphs.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)""
 (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class ten
sorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEA
VEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\compare_graphs.vcxproj
]
  D:\tensorflow\tensorflow\contrib\cmake\build\Release\compare_graphs.exe : fatal error LNK1120: 4 unresolved externals [D:\tensorflow\tensorflow\contrib
\cmake\build\compare_graphs.vcxproj]
“D:\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj”(默认目标) (1) ->
“D:\tensorflow\tensorflow\contrib\cmake\build\summarize_graph.vcxproj”(默认目标) (257) ->
  eager_operation.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int
)"" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function ""public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow
::TensorHandle *)"" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\summarize_graph.vcxpro
j]
  execute.obj : error LNK2019: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef c
onst * *)"" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecut
e(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVS
tatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\summarize_g
raph.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basi
c_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basi
c_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensor
flow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa
gerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\summarize_graph.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)""
 (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class ten
sorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEA
VEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\summarize_graph.vcxpro
j]
  D:\tensorflow\tensorflow\contrib\cmake\build\Release\summarize_graph.exe : fatal error LNK1120: 4 unresolved externals [D:\tensorflow\tensorflow\contri
b\cmake\build\summarize_graph.vcxproj]


“D:\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj”(默认目标) (1) ->
“D:\tensorflow\tensorflow\contrib\cmake\build\tf_label_image_example.vcxproj”(默认目标) (260) ->
  eager_operation.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int
)"" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function ""public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow
::TensorHandle *)"" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_label_image_example
.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef c
onst * *)"" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecut
e(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVS
tatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_label_im
age_example.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basi
c_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basi
c_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensor
flow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa
gerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_label_image_example.vc
xproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)""
 (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class ten
sorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEA
VEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_label_image_example
.vcxproj]
  D:\tensorflow\tensorflow\contrib\cmake\build\Release\tf_label_image_example.exe : fatal error LNK1120: 4 unresolved externals [D:\tensorflow\tensorflow
\contrib\cmake\build\tf_label_image_example.vcxproj]


“D:\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj”(默认目标) (1) ->
“D:\tensorflow\tensorflow\contrib\cmake\build\tf_tutorials_example_trainer.vcxproj”(默认目标) (261) ->
  eager_operation.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int
)"" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function ""public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow
::TensorHandle *)"" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_tutorials_example_t
rainer.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef c
onst * *)"" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecut
e(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVS
tatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_tutorial
s_example_trainer.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basi
c_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basi
c_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensor
flow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa
gerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_tutorials_example_trai
ner.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)""
 (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class ten
sorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEA
VEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\tf_tutorials_example_t
rainer.vcxproj]
  D:\tensorflow\tensorflow\contrib\cmake\build\Release\tf_tutorials_example_trainer.exe : fatal error LNK1120: 4 unresolved externals [D:\tensorflow\tens
orflow\contrib\cmake\build\tf_tutorials_example_trainer.vcxproj]


“D:\tensorflow\tensorflow\contrib\cmake\build\ALL_BUILD.vcxproj”(默认目标) (1) ->
“D:\tensorflow\tensorflow\contrib\cmake\build\transform_graph.vcxproj”(默认目标) (262) ->
  eager_operation.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::AttrBuilder & __cdecl tensorflow::AttrBuilder::NumInputs(int
)"" (?NumInputs@AttrBuilder@tensorflow@@QEAAAEAV12@H@Z) referenced in function ""public: void __cdecl tensorflow::EagerOperation::AddInput(class tensorflow
::TensorHandle *)"" (?AddInput@EagerOperation@tensorflow@@QEAAXPEAVTensorHandle@2@@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\transform_graph.vcxpro
j]
  execute.obj : error LNK2019: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::OpDefForOp(char const *,class tensorflow::OpDef c
onst * *)"" (?OpDefForOp@tensorflow@@YA?AVStatus@1@PEBDPEAPEBVOpDef@1@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecut
e(class tensorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVS
tatus@1@PEAVEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\transform_g
raph.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: struct tensorflow::Fprint128 __cdecl tensorflow::AttrBuilder::CacheKey(class std::basi
c_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?CacheKey@AttrBuilder@tensorflow@@QEBA?AUFprint128@2@AEBV?$basi
c_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class tensor
flow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEAVEa
gerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\transform_graph.vcxproj]
  execute.obj : error LNK2019: unresolved external symbol ""public: class tensorflow::NodeDef const & __cdecl tensorflow::AttrBuilder::BuildNodeDef(void)""
 (?BuildNodeDef@AttrBuilder@tensorflow@@QEAAAEBVNodeDef@2@XZ) referenced in function ""class tensorflow::Status __cdecl tensorflow::EagerExecute(class ten
sorflow::EagerOperation *,class tensorflow::gtl::InlinedVector<class tensorflow::TensorHandle *,2> *,int *)"" (?EagerExecute@tensorflow@@YA?AVStatus@1@PEA
VEagerOperation@1@PEAV?$InlinedVector@PEAVTensorHandle@tensorflow@@$01@gtl@1@PEAH@Z) [D:\tensorflow\tensorflow\contrib\cmake\build\transform_graph.vcxpro
j]
  D:\tensorflow\tensorflow\contrib\cmake\build\Release\transform_graph.exe : fatal error LNK1120: 4 unresolved externals [D:\tensorflow\tensorflow\contri
b\cmake\build\transform_graph.vcxproj]

    342 个警告（Warning）
    30 个错误 (Error)
""
```
I tried a lot of configurations and all of the above errors occurred and the errors were the same.

### Source code / logs

"
19428,Tensor hub link not working https://www.tensorflow.org/installation,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19427,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,"Please note that I have cuda-9.2 ...there are no cuda 9.0 files anywhere in my system or references . Yet tensorflow still wants  libcublas.so.9.0.  I tried uninstalling both cuda and tensorflow but still error is show. Has anyone seen this and what can be done? Thank you.
```
sudo find . / -name libcublas.so.9.*

./cuda-9.2/targets/x86_64-linux/lib/libcublas.so.9.2
./cuda-9.2/targets/x86_64-linux/lib/libcublas.so.9.2.113
./cuda-9.2/targets/x86_64-linux/lib/libcublas.so.9.2.88
/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcublas.so.9.2
/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcublas.so.9.2.113
/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcublas.so.9.2.88
```




```
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

```"
19426,"Unknown TF crash on OSX in C++ Application, works fine on another machine, other operating systems","
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes there is a bunch of private OpenFX plugin and C++ hosting of the network involved.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS 10.12
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
r1.6
- **Python version**: 
na
- **Bazel version (if compiling from source)**:
0.6
- **GCC/Compiler version (if compiling from source)**:
clang 8
- **CUDA/cuDNN version**:
NA
- **GPU model and memory**:
NVIDIA GTX 780M
- **Exact command to reproduce**:
Download alpha trial of software, install according to instructions.

Launch Nuke as follows:
ROTOBOT_MODEL_DIR=$PWD OFX_PLUGIN_PATH=$OFX_PLUGIN_PATH:$PWD /Applications/Nuke10.5v7/Nuke10.5v7.app/Contents/MacOS/Nuke10.5v7 

Create read node, create Rotobot-MaskRCNN node, connect source to read node

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Same neural network work fine on hardware without GPU installed

Works OK under Linux 64, macOS

I am unsure of what is causing this crash.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


```
Thread 36 Crashed:
0   libtensorflow_cc.so           	0x000000013c6ce622 Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::DefaultDevice, true>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, long>, 16, Eigen::MakePointer> const> const> const&, Eigen::DefaultDevice const&) + 1682
1   libtensorflow_cc.so           	0x000000013ca4eb15 tensorflow::functor::Split<Eigen::ThreadPoolDevice, float>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 3, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, long>, 16, Eigen::MakePointer>, Eigen::DSizes<long, 3> const&, Eigen::DSizes<long, 3> const&) + 101
2   libtensorflow_cc.so           	0x000000013c6cde31 tensorflow::SplitOpCPU<float>::Compute(tensorflow::OpKernelContext*)::'lambda'(long long, long long)::operator()(long long, long long) const + 481
3   libtensorflow_cc.so           	0x000000013c6cd7db tensorflow::SplitOpCPU<float>::Compute(tensorflow::OpKernelContext*) + 1099
4   libtensorflow_cc.so           	0x000000013e3f7442 tensorflow::grappler::ConstantFolding::EvaluateNode(tensorflow::NodeDef const&, tensorflow::gtl::InlinedVector<tensorflow::TensorValue, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorValue, 4>*) const + 562
5   libtensorflow_cc.so           	0x000000013e3f78bc tensorflow::grappler::ConstantFolding::EvaluateOneFoldable(tensorflow::NodeDef const&, std::__1::vector<tensorflow::NodeDef, std::__1::allocator<tensorflow::NodeDef> >*) + 604
6   libtensorflow_cc.so           	0x000000013e3f82d2 tensorflow::grappler::ConstantFolding::FoldNode(tensorflow::NodeDef*, tensorflow::GraphDef*) + 402
7   libtensorflow_cc.so           	0x000000013e3fa54d tensorflow::grappler::ConstantFolding::FoldGraph(tensorflow::GraphDef*) + 973
8   libtensorflow_cc.so           	0x000000013e400f83 tensorflow::grappler::ConstantFolding::RunOptimizationPass(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) + 1523
9   libtensorflow_cc.so           	0x000000013e401925 tensorflow::grappler::ConstantFolding::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) + 1829
10  libtensorflow_cc.so           	0x000000013e3db066 tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) + 2822
11  libtensorflow_cc.so           	0x000000013e3dc2dd tensorflow::grappler::RunMetaOptimizer(tensorflow::grappler::GrapplerItem const&, tensorflow::RewriterConfig const&, tensorflow::DeviceBase*, tensorflow::grappler::Cluster*, tensorflow::GraphDef*) + 109
12  libtensorflow_cc.so           	0x000000013e3d6dac tensorflow::GraphExecutionState::OptimizeGraph(tensorflow::BuildGraphOptions const&, std::__1::unique_ptr<tensorflow::Graph, std::__1::default_delete<tensorflow::Graph> >*) + 3564
13  libtensorflow_cc.so           	0x000000013e3d4686 tensorflow::GraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::__1::unique_ptr<tensorflow::ClientGraph, std::__1::default_delete<tensorflow::ClientGraph> >*) + 166
14  libtensorflow_cc.so           	0x000000013e3c0d37 tensorflow::DirectSession::CreateGraphs(tensorflow::BuildGraphOptions const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::unique_ptr<tensorflow::Graph, std::__1::default_delete<tensorflow::Graph> >, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::unique_ptr<tensorflow::Graph, std::__1::default_delete<tensorflow::Graph> > > > >*, std::__1::unique_ptr<tensorflow::FunctionLibraryDefinition, std::__1::default_delete<tensorflow::FunctionLibraryDefinition> >*, tensorflow::DirectSession::RunStateArgs*, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*) + 375
15  libtensorflow_cc.so           	0x000000013e3bb469 tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::gtl::ArraySlice<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, tensorflow::gtl::ArraySlice<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, tensorflow::gtl::ArraySlice<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) + 4585
16  libtensorflow_cc.so           	0x000000013e3b893c tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) + 908
17  libtensorflow_cc.so           	0x000000013e3b8437 tensorflow::DirectSession::Run(std::__1::vector<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor>, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::Tensor> > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > > const&, std::__1::vector<tensorflow::Tensor, std::__1::allocator<tensorflow::Tensor> >*) + 103
18  rotobotmaskrcnn.ofx           	0x000000013b805f21 drawMasks(OpenImageIO::v1_6::ImageBuf&, std::__1::unique_ptr<tensorflow::Session, std::__1::default_delete<tensorflow::Session> >&, OpenImageIO::v1_6::ImageBuf&, bool) + 6737
19  rotobotmaskrcnn.ofx           	0x000000013b8038af RotobotMaskRCNNPlugin::computeMask(OFX::Image*) + 3823
20  rotobotmaskrcnn.ofx           	0x000000013b80234c RotobotMaskRCNNPlugin::setupAndProcess(ImageScalerBase&, OFX::RenderArguments const&) + 1628
21  rotobotmaskrcnn.ofx           	0x000000013b808df9 RotobotMaskRCNNPlugin::render(OFX::RenderArguments const&) + 409
22  rotobotmaskrcnn.ofx           	0x000000013b84b2a6 OFX::Private::renderAction(OfxImageEffectStruct*, OFX::PropertySet) + 86
23  rotobotmaskrcnn.ofx           	0x000000013b84750b OFX::Private::mainEntryStr(char const*, void const*, OfxPropertySetStruct*, OfxPropertySetStruct*, char const*) + 9115
24  rotobotmaskrcnn.ofx           	0x000000013b81b970 OFX::FactoryMainEntryHelper<RotobotMaskRCNNPluginFactory>::mainEntry(char const*, void const*, OfxPropertySetStruct*, OfxPropertySetStruct*) + 320
25  libnuke-10.5.7.dylib          	0x000000010702e9ac OFX::Host::ImageEffect::Instance::mainEntry(char const*, void const*, OFX::Host::Property::Set*, OFX::Host::Property::Set*) + 284
26  libnuke-10.5.7.dylib          	0x000000010703072d OFX::Host::ImageEffect::Instance::renderAction(double, std::string const&, OfxRectI const&, OfxPointD) + 973
27  libnuke-10.5.7.dylib          	0x0000000106b25e21 Nofx::NofxIop::renderBlock(unsigned long, DD::Image::ChannelSet const&) + 1393
28  libnuke-10.5.7.dylib          	0x0000000106b21df1 Nofx::NofxIop::engine(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 657
29  libDDImage.dylib              	0x000000010850873c DD::Image::Cache::fill_line(int, DD::Image::Row&, DD::Image::ChannelSet const&, DD::Image::ChannelSet&, DD::Image::ChannelSet&) + 556
30  libDDImage.dylib              	0x0000000108508d78 DD::Image::Cache::load_line_incr(int, DD::Image::Row&, DD::Image::ChannelSet const&, DD::Image::ChannelSet&, DD::Image::ChannelSet&) + 488
31  libDDImage.dylib              	0x00000001085a5fef DD::Image::Iop::get(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 1519
32  libDDImage.dylib              	0x0000000108631757 DD::Image::PixelIop::engine(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 183
33  libDDImage.dylib              	0x000000010850b079 DD::Image::Cache::run_engine(DD::Image::Iop*, int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 137
34  libDDImage.dylib              	0x00000001085a6225 DD::Image::Iop::get(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 2085
35  libDDImage.dylib              	0x0000000108631757 DD::Image::PixelIop::engine(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 183
36  libDDImage.dylib              	0x000000010850b079 DD::Image::Cache::run_engine(DD::Image::Iop*, int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 137
37  libDDImage.dylib              	0x00000001085a6225 DD::Image::Iop::get(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 2085
38  libDDImage.dylib              	0x0000000108631757 DD::Image::PixelIop::engine(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 183
39  libDDImage.dylib              	0x000000010850b079 DD::Image::Cache::run_engine(DD::Image::Iop*, int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 137
40  libDDImage.dylib              	0x00000001085a6225 DD::Image::Iop::get(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 2085
41  libDDImage.dylib              	0x0000000108631757 DD::Image::PixelIop::engine(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 183
42  libDDImage.dylib              	0x000000010850b079 DD::Image::Cache::run_engine(DD::Image::Iop*, int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 137
43  libDDImage.dylib              	0x00000001085a6225 DD::Image::Iop::get(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 2085
44  libDDImage.dylib              	0x0000000108631757 DD::Image::PixelIop::engine(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 183
45  libDDImage.dylib              	0x000000010850b079 DD::Image::Cache::run_engine(DD::Image::Iop*, int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 137
46  libDDImage.dylib              	0x00000001085a6225 DD::Image::Iop::get(int, int, int, DD::Image::ChannelSet const&, DD::Image::Row&) + 2085
47  libnuke-10.5.7.dylib          	0x0000000106f954bd Viewer_Image::thread_proc() + 813
48  libnuke-10.5.7.dylib          	0x0000000106f95186 Viewer_Image::_thread_proc(void*) + 6
49  libnuke-10.5.7.dylib          	0x000000010668cc0e thread_func(unsigned int, unsigned int, void*) + 14
50  libDDImage.dylib              	0x0000000108690ad8 DD::Image::thread_proc(void*) + 120
51  libsystem_pthread.dylib       	0x00007fffc282093b _pthread_body + 180
52  libsystem_pthread.dylib       	0x00007fffc2820887 _pthread_start + 286
53  libsystem_pthread.dylib       	0x00007fffc282008d thread_start + 13
```

To see the expected result please visit:

https://www.linkedin.com/feed/update/urn:li:activity:6403107128722190336"
19424,tf.fill fails when dims has type tf.int64,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8.0 (CPU version)
- **Python version**: 3.6.5

### Describe the problem

`tf.fill([n], 42.0)` fails when `n` is of type `tf.int64`, according to [the docs](https://www.tensorflow.org/api_docs/python/tf/fill):

>  dims: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D. Represents the shape of the output tensor.

### Source code / logs

The following code describes the problem:

```python
import tensorflow as tf

n1 = tf.constant(3, tf.int32)
n2 = tf.constant(3, tf.int64)

x1 = tf.fill([n1], 42.0)  # OK
x2 = tf.fill([n2], 42.0)  # not OK
```

output:

```python
>>> import tensorflow as tf
>>> n1 = tf.constant(3, tf.int32)
>>> n2 = tf.constant(3, tf.int64)
>>> x1 = tf.fill([n1], 42.0)  # OK
>>> x2 = tf.fill([n2], 42.0)  # not OK
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 2717, in fill
    ""Fill"", dims=dims, value=value, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 513, in _apply_op_helper
    raise err
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 510, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1104, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 235, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py"", line 214, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 432, in make_tensor_proto
    _AssertCompatible(values, dtype)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py"", line 340, in _AssertCompatible
    raise TypeError(""List of Tensors when single Tensor expected"")
TypeError: List of Tensors when single Tensor expected
```

Thanks!"
19422,ERROR build: output 'tensorflow/core/kernels/_objs/crop_and_resize_op_gpu/tensorflow/core/kernels/crop_and_resize_op_gpu.cu.o' was not created,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: source (build error)
- **TensorFlow version (use command below)**: 1.8.0
- **Python version**:  3.6.5
- **Bazel version (if compiling from source)**: 0.13.0
- **GCC/Compiler version (if compiling from source)**: 6.4.0-17ubuntu1
- **CUDA/cuDNN version**: 9.1.85-3ubuntu1 / 7.0.5
- **GPU model and memory**: GeForce 1080ti 11GB
- **Exact command to reproduce**:

### Describe the problem

Building with bazel fails with the error below, using the following build command:

```
bazel build --jobs=12 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures 
````

### Source code / logs

Here's the error log from re-running the build with `--verbose_failures` https://gist.github.com/darthdeus/1596b20a326f4ca6d41cae4b09aaf87e

"
19421,Feature Request:  128-bit floats,"I have posted a question and answer on [SO](https://stackoverflow.com/questions/50438071/cost-function-convergence-in-tensorflow-using-softmax-cross-entropy-with-logits/50438072#50438072) showing why this is needed.  Admittedly it is probably not a common case, but I do research and the problems I deal with usually require creative solutions and so I'm generally pushing the boundaries of packages like Tensorflow (which is a wonderful package!).  I ran into this with soft-target classification.  

> with soft targets, especially ones that aren't close to 1 or zero, cross entropy loss doesn't change significantly as the algorithm improves. Let's say the targets are [0.39019628, 0.44301641, 0.16678731]. Well, using the formula for cross entropy

`cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))`

> but then using the targets ""y_"" in place of the predicted probabilities ""y"" we arrive at the true entropy value of 1.0266190072458234. If you're predictions are just slightly off of target....lets say they are [0.39511779, 0.44509024, 0.15979198], then the cross entropy is 1.026805558049737.

Basically even with 64-bit floats, the loss function shows evidence that it would continue to train if further significant digits were available.  This is just to support the cost function during the training process since the final trained values would not need such precision, but to get to an optimal convergence I need it.


"
19420,tf.keras.layers.Dropout has no 'is_training' argument,"Dropout layer is (usually) only used while training. Keras automatically enable dropout layers while training and disable them while predicting.

Thus, tf.keras.layers.Dropout has no 'is_training' argument (but it exists in tf.layers.dropout). That can mislead Keras and tf users when trying to mix Keras with TF layers. Indeed, predicting new data with dropout layers doesn't produce any error but reduces the accuracy ! Maybe a warning note in 'tf.keras.layers.Dropout' documentation can be useful. 

With tf.layers
```
dropout = tf.layers.dropout(inputs=dense, rate=0.2, training=is_training, name=""dropout-1"")
```

With tf.Keras.layers
```
dense = ...
if(is_training):
      dropout = tf.keras.layers.Dropout(0.2, noise_shape=None, seed=None)(dense)
  else :
      dropout = dense
```"
19417,Assertion error while using triplet_semihard_loss function,"Though my label dimensions are of the form (?,1) and embeddings dimensions (?, 128)
the loss function throwing out assertion error.

[  lshape = array_ops.shape(labels)](https://github.com/tensorflow/tensorflow/blob/4bd6243e45f7e4c9757e32e499495ac1ec28f95f/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops.py#L178)
"
19416,ImportError : no module named 'pywrap_tensorflow_internal',"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
windows 7 ultimate 64 bit.
- **TensorFlow installed from (source or binary)**:
conda
- **TensorFlow version (use command below)**:
1.8.0
- **Python version**: 
3.6.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
1 . conda create -n tensorflow pip python=3.5
2 . activate tensorflow
3 . pip install --ignore-installed --upgrade tensorflow
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh


Log from tf_env_collect.sh

Collecting system information...
cat: /proc/1/cgroup: No such file or directory
Traceback (most recent call last):
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/SRIDHA~1/AppData/Local/Temp/check_tf.py"", line 1, in <module>
    import tensorflow as tf;
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\SridharKannan\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt


### Describe the problem
 I tried to install tensorflow in my laptop.The installation went smoothly , but I'm getting error while importing tensorflow . 

### Source code / logs
>>> import tensorflow
Traceback (most recent call last):
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 985, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 968, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 957, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 938, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 14, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 985, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 968, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 957, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 938, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed with error code -1073741795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 17, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 16, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\SridharKannan\Miniconda3\envs\tensorflow\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
19414,Feature Request: Add support in TFAndroid to toggle camera for DetectorActivity in TF Detect,"Add Toggle camera button widget in TF Detect App for detecting objects using front camera of the phone.
Thanks!"
19412,[Batch Normal] Would you have plan to sync batch normalization?,"For semantic segmentation, it is very import to syncbn. would you tell us how to do it?"
19407,Using estimators created by `tf.keras.estimator.model_to_estimator` in `tf.estimator.train_and_evaluate` causes a memory leak of sorts,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see provided gist
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian Jessie
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: ('v1.8.0-0-g93bc2e2072', '1.8.0')
- **Python version**: 2.7.9
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**: Run provided gist


### Describe the problem
When using keras models with `train_and_evaluate`, you need to convert them into estimators first. The best way to do this is `tf.keras.estimator.model_to_estimator`. However, when `train_and_evaluate` is called with those estimators, the default graphs that are created end up referenced in `_GRAPH_LEARNING_PHASES` and never deallocated (so sort of a memory leak). This is due to a call to `keras.backend.set_learning_phase` that's done as part of the created `model_fn`, which uses the default graph as a key into `_GRAPH_LEARNING_PHASES`. Since that graph changes every so often in `train_and_evaluate`, that key changes so there's a new key inserted without the old ones being removed.

Or at leas, I'm 80% certain that's what's going on. You can see in the provided code a very simple Keras model turned into an estimator and then run with a hook that prints out memory usage and the size of `_GRAPH_LEARNING_PHASES`. It increases over time!

While the leak is small in the provided example, it has caused me great strife in real usage.
### Source code / logs

The source code and a sample run are provided in [this gist](https://gist.github.com/zmjjmz/392ead713f19db025390f6d8de17bde2). It should be easy to run the python script yourself however you'll need to have `numpy` and `psutil` installed."
19406,runtime error in monitored_session.py,"The complete code I am running is very short: its in a github project RL-Implementation-IMPALA where I uncommented the with GPU in the learner. The code runs fine if you do not use the GPU.  I have installed tensorflow-gpu 1.4 under ubuntu16.04.   I can run  nvidia-settings  and it shows the GPU gtx1060 


```
File ""/home/rjn/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 368, in MonitoredTrainingSession

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'save/StringJoin': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:explorer/replica:0/task:0/device:CPU:0, /job:learner/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.
	 [[Node: save/StringJoin = StringJoin[N=2, separator="""", _device=""/device:GPU:0""](save/Const, save/StringJoin/inputs_1)]]

```"
19397,[Bug] tf.shape does not return correct value when using tf.cond and tf.reshape,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.8.0-0-g93bc2e2072', '1.8.0')
- **Python version**: 2.7.15
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 9.0/7.0
- **GPU model and memory**: GeForce GTX 1060 6GB
- **Exact command to reproduce**:

### Describe the problem

When  all of below conditions is true, tf.shape return NOT correct value.
* use `tf.reshape` in and out of `tf.cond` and 
* `tf.reshape` inside of `tf.cond` has unknown shape (-1)
* `tf.reshape` inside of `tf.cond` reduces or increases rank of tensor



I have checked that same code doesn't cause error  in TensorFlow 1.7. But TensorFlow 1.8 cause this error.

I guess this phenomena caused by a failure of branch prediction or error of graph-optimization.

### Source code / logs

#### Source code
```python
import tensorflow as tf


def init(height):
    orig = tf.zeros(shape=[height])
    reshaped = tf.reshape(orig, shape=[-1])

    # tf.shape(reshaped) must return [1, 2]. But this actually return [2, 2]. It's WRONG!!
    reshaped = tf.Print(reshaped, [tf.shape(reshaped)], message=""tf.shape(reshaped) before tf.cond: "")

    def true_fn(t):
        t = tf.Print(t, [], message=""pass in true_fn"")
        return tf.reshape(t, (2, 1))

    def false_fn(t):
        t = tf.Print(t, [], message=""pass in false_fn"")
        return tf.reshape(t, (-1, 1))

    reshaped = tf.cond(
        tf.equal(tf.shape(reshaped)[0], 2), lambda: true_fn(reshaped), lambda: false_fn(reshaped), strict=True)

    reshaped = tf.Print(reshaped, [tf.shape(reshaped)], message=""tf.shape(reshaped) after tf.cond: "")

    return reshaped


def main():

    height = tf.placeholder(dtype=tf.int32, shape=())
    reshaped = init(height)

    with tf.Session() as sess:
        sess.run(reshaped, feed_dict={height: 1})


if __name__ == '__main__':
    main()
```

#### Log
```
2018-05-19 04:54:10.722065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning
 NUMA node zero
2018-05-19 04:54:10.722448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7845
pciBusID: 0000:01:00.0
totalMemory: 5.94GiB freeMemory: 4.86GiB
2018-05-19 04:54:10.722467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-05-19 04:54:10.911223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-19 04:54:10.911263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0
2018-05-19 04:54:10.911271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N
2018-05-19 04:54:10.911466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4623 MB memory) -> physical GPU (device: 0
, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
tf.shape(reshaped) before tf.cond: [2]
pass in true_fn
Traceback (most recent call last):
  File ""./main.py"", line 40, in <module>
    main()
  File ""./main.py"", line 36, in main
    sess.run(reshaped, feed_dict={height: 1})
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 900, in run
    run_metadata_ptr)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1316, in _do_run
    run_metadata)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 1 values, but the requested shape has 2
         [[Node: cond/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](cond/Print/_19, cond/Reshape/shape)]]
         [[Node: Shape_2/_25 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_26_Shape_2"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op u'cond/Reshape', defined at:
  File ""./main.py"", line 40, in <module>
    main()
  File ""./main.py"", line 33, in main
    reshaped = init(height)
  File ""./main.py"", line 23, in init
    tf.equal(tf.shape(reshaped)[0], 2), lambda: true_fn(reshaped), lambda: false_fn(reshaped), strict=True)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 432, in new_func
    return func(*args, **kwargs)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 2063, in cond
    orig_res_t, res_t = context_t.BuildCondBranch(true_fn)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1913, in BuildCondBranch
    original_result = fn()
  File ""./main.py"", line 23, in <lambda>
    tf.equal(tf.shape(reshaped)[0], 2), lambda: true_fn(reshaped), lambda: false_fn(reshaped), strict=True)
  File ""./main.py"", line 16, in true_fn
    return tf.reshape(t, (2, 1))
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 6113, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3392, in create_op
    op_def=op_def)
  File ""/home/n/anaconda2/envs/tf18/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1718, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1 values, but the requested shape has 2
         [[Node: cond/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](cond/Print/_19, cond/Reshape/shape)]]
         [[Node: Shape_2/_25 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_26_Shape_2"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
```

"
19395,Gridrnn (Grid2LSTM) tied behaviour is inverted,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.8
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
When trying to create a unrolled sequence for a `Grid2LSTMCell`, weights are shared among two states (the two dimensions) for a given step, when the property `tied` is set to *False* and they are not shared when `tied` is set to *True*. If this is indeed the behaviour that was desired, then it deviates from the original paper based on which it is implemented, otherwise it seems to be a bug in variable reuse.

**Expected Behaviour**: Share weights when `tied` is True and do not share when `tied` is False

### Source code / logs
```python
import tensorflow as tf
from tensorflow.contrib.rnn.python.ops import rnn_cell
from tensorflow.contrib import grid_rnn
from tensorflow.python.ops import variable_scope

batch_size = 32
seq_len = 10
# inp => sequence_length x batch_size x embedding_size
inp_grid = tf.placeholder(tf.float32, shape=(seq_len, batch_size, 2048)) 
rnnargs = {
            'use_peepholes': True, 'forget_bias': 1.0,
            'state_is_tuple': False, 'output_is_tuple': False,
            'output_is_tuple': True, 'state_is_tuple': True,
            'tied': False
            }
glstm = grid_rnn.Grid2LSTMCell(1024, **rnnargs)
state = glstm.zero_state(batch_size, tf.float32)
for i in range(seq_len):
    if i>0:
        variable_scope.get_variable_scope().reuse_variables()
    state_left, state_top = state[0], state[1] # since two dimensions
    out, state = glstm(inp_grid[i], (state_left, state_top))
    # If you observe the actual tensor (name) of the two states, 
    # they will be same when tied is False 
    # and different when tied is true
    print(state[0],""\t"",state[1],""\n"")
```

I think this is a bug related to variable reuse instead of how cells are defined in `grid_rnn` constructor. I would like to work on this issue if this indeed is an issue, or else a explanation of why this is the correct behaviour will do."
19393,Build Tensorflow-master with sycl support - error computecpp,"
- Ubuntu 18.04
- TensorFlow installed from source 1.80
- Python version 2.7
- Bazel version 0.13.0
- GCC/Compiler 7.3
- OpenCL 1.2 AMD-APP 
- AMD Vega FE
- bazel build --config=sycl --verbose_failures --test_timeout 1600 //tensorflow/tools/pip_package:build_pip_package

I am trying to compile Tensorflow for my amd GPU, when i set it to --config=sycl it fails with the error :

`
INFO: Found 1 target...
ERROR: /home/frankie/Downloads/TENSORFLOW_BUILDs/tensorflow/tensorflow/contrib/tensor_forest/hybrid/BUILD:72:1: C++ compilation of rule '//tensorflow/contrib/tensor_forest/hybrid:utils' failed (Exit 1): computecpp failed: error executing command
  (cd /home/frankie/.cache/bazel/_bazel_frankie/d74dd7347ab17909423a2342e3b420ce/execroot/org_tensorflow && \
  exec env - \
    COMPUTECPP_TOOLKIT_PATH=/usr/local/computecpp \
    HOST_CXX_COMPILER=/usr/bin/g++ \
    HOST_C_COMPILER=/usr/bin/gcc \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_DOWNLOAD_CLANG=0 \
    TF_NEED_COMPUTECPP=1 \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=1 \
  external/local_config_sycl/crosstool/computecpp -fPIE -fno-omit-frame-pointer -Wall -msse3 -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/k8-opt/bin/tensorflow/contrib/tensor_forest/hybrid/_objs/utils/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/contrib/tensor_forest/hybrid/_objs/utils/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.pic.o' -fPIC -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/k8-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/k8-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/genfiles/external/local_config_sycl -iquote external/protobuf_archive -iquote bazel-out/k8-opt/genfiles/external/protobuf_archive -isystem external/eigen_archive -isystem bazel-out/k8-opt/genfiles/external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/local_config_sycl/sycl -isystem bazel-out/k8-opt/genfiles/external/local_config_sycl/sycl -isystem bazel-out/k8-opt/bin/external/local_config_sycl/sycl -isystem external/local_config_sycl/sycl/include -isystem bazel-out/k8-opt/genfiles/external/local_config_sycl/sycl/include -isystem bazel-out/k8-opt/bin/external/local_config_sycl/sycl/include -isystem external/protobuf_archive/src -isystem bazel-out/k8-opt/genfiles/external/protobuf_archive/src -isystem bazel-out/k8-opt/bin/external/protobuf_archive/src -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc -o bazel-out/k8-opt/bin/tensorflow/contrib/tensor_forest/hybrid/_objs/utils/tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.pic.o)
In file included from tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc:15:
In file included from ./tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.h:20:
In file included from ./tensorflow/core/framework/tensor.h:19:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:163:19: error: no matching member function for call to 'get_access'
    auto ptr =buf.get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::host_buffer>().get_pointer();
              ~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:593:3: note: candidate template ignored: invalid explicitly-specified argument for template parameter 'accessMode'
  get_access() {
  ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:611:53: note: candidate function template not viable: requires single argument 'cgh', but no arguments were provided
  accessor<T, dimensions, accessMode, accessTarget> get_access(
                                                    ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:633:53: note: candidate function template not viable: requires 3 arguments, but 0 were provided
  accessor<T, dimensions, accessMode, accessTarget> get_access(
                                                    ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:653:53: note: candidate function template not viable: requires at least 2 arguments, but 0 were provided
  accessor<T, dimensions, accessMode, accessTarget> get_access(
                                                    ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:670:68: note: candidate function template not viable: requires 2 arguments, but 0 were provided
  accessor<T, dimensions, accessMode, access::target::host_buffer> get_access(
                                                                   ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/buffer.h:684:68: note: candidate function template not viable: requires at least argument 'range', but no arguments were provided
  accessor<T, dimensions, accessMode, access::target::host_buffer> get_access(
                                                                   ^
In file included from tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.cc:15:
In file included from ./tensorflow/contrib/tensor_forest/hybrid/core/ops/utils.h:20:
In file included from ./tensorflow/core/framework/tensor.h:19:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:99:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:61: error: no member named 'map_allocator' in namespace 'cl::sycl'
      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));
                                                  ~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:75: error: unexpected type name 'uint8_t': expected expression
      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));
                                                                          ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:195:86: warning: expression result unused [-Wunused-value]
      auto src_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(static_cast<void*>(const_cast<Index*>(src))), cl::sycl::range<1>(n));
                                                                                     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:31: error: expected unqualified-id
        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);
                              ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:107: error: nested name specifier 'cl::sycl::access::target::' for declaration does not refer into a class, class templat
e or class template partial specialization
        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);
                                                                                ~~~~~~~~~~~~~~~~~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:198:120: error: expected ';' at end of declaration
        auto src_acc =src_buf.template get_access<cl::sycl::access::mode::read, cl::sycl::access::target::global_buffer>(cgh);
                                                                                                                       ^
                                                                                                                       ;
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:62: error: no member named 'map_allocator' in namespace 'cl::sycl'
      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));
                                                   ~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:76: error: unexpected type name 'uint8_t': expected expression
      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));
                                                                           ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:217:87: warning: expression result unused [-Wunused-value]
      auto dest_buf = cl::sycl::buffer<uint8_t, 1, cl::sycl::map_allocator<uint8_t> >(static_cast<uint8_t*>(dst), cl::sycl::range<1>(n));
                                                                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:32: error: expected unqualified-id
        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);
                               ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:117: error: nested name specifier 'cl::sycl::access::target::' for declaration does not refer into a class, class templat
e or class template partial specialization
        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);
                                                                                          ~~~~~~~~~~~~~~~~~~~~~~~~~~^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceSycl.h:220:130: error: expected ';' at end of declaration
        auto dst_acc =dest_buf.template get_access<cl::sycl::access::mode::discard_write, cl::sycl::access::target::global_buffer>(cgh);
                                                                                                                                 ^
                                                                                                                                 ;
2 warnings and 11 errors generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 8.290s, Critical Path: 7.83s
INFO: 2 processes, local.
FAILED: Build did NOT complete successfully
`

It compile well without sycl.

I have installed computecpp downloading the files from the official website (ComputeCpp-CE-0.8.0-Ubuntu.16.04-64bit.tar.gz) and coping them to /usr/local/computecpp, adding the variable with 

`export COMPUTECPP_PACKAGE_ROOT_DIR=/usr/local/computecpp/`

am i missing something ?
thanks !"
19391,Feature Request: Use hwloc to query CPU topologies and support thread/memory binding for improved performance,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
Feature request to add hwloc (https://www.open-mpi.org/projects/hwloc/) to TensorFlow's third-party dependencies, use hwloc APIs to query CPU topologies in a portable manner and bind threads/memory for improved performance

This is following up on some of the discussion here: https://github.com/tensorflow/tensorflow/pull/19136"
19390,depthwise_conv2d_native too slow,"***edit***: Simplified the example, added system info

According to this [thread](https://github.com/tensorflow/tensorflow/pull/17961) Tensorflow now uses the CuDNN accelerations of group convolutions for depthwise_conv2d_native. Thank you for working on this! However, I am having a hard time reproducing any gains from the accelerated version. Both the native and accelerated versions of depthwise_conv2d_native is about 3-4 times slower than doing a full (dense) convolution.

In the example below, a dense 3x3 convolution with 64-in and 64-out channels should do about 16 times more multiplications compared to a group convolution with the same dimensions and 16 groups (64x3x3x64 vs 16x4x3x3x4). The latter can be implemented with depthwise_conv2d_native with channel_multiplier of 4 followed by a sum. So I expect a fully amortized depthwise_conv2d_native to be 16 times faster than a dense convolution, and yet, it is about 4 times slower. It is also substantially slower than naive slice/convolve/concat implementation of group convolution


### System information
- **Have I written custom code**: no
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from (source)**: from May 15, 2018 commit 1521eeb676383417b33ad55ad73b152bd5b046ca
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4
- **CUDA/cuDNN version**: 9.1, 7.1.3
- **GPU model and memory**: GeForce GTX 1080ti (tf compiled for compute capability 6.1) and Volta (V100, tf compiled for compute capability 7.0)
- **Exact command to reproduce**: see code below


Here are my results on GTX 1080ti:
```
           depthwise : 2.72s
     depthwise_cudnn : 2.59s
   manual_group_conv : 0.84s
          dense_conv : 0.72s
```
Here is the code I used to test performance:
```
import numpy as np, time, os
import tensorflow as tf
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

def conv3x3(bottom, filters):
    return tf.layers.conv2d(bottom, filters, kernel_size = 3, padding='same', use_bias = False, data_format = 'channels_first')

# this is not even group convolution, just the depthwise part without the sum
def depthwise(bottom, num_groups):
    input_chans = bottom.shape[1]
    group_size = input_chans / num_groups
    w0 = tf.get_variable(name='var', shape=[3, 3, input_chans, group_size])
    return tf.nn.depthwise_conv2d_native(bottom, w0, strides = [1,1,1,1], padding = 'SAME', data_format = 'NCHW')

def depthwise_cudnn(bottom, num_groups):
    with tf.get_default_graph()._kernel_label_map({""DepthwiseConv2dNative"": ""cudnn_grouped_convolution""}):
        return depthwise(bottom, num_groups)

def manual_group_conv(bottom, num_groups):
    input_chans = bottom.shape[1]
    group_size = input_chans / num_groups
    slices = [bottom[:,i:(i+group_size)] for i in range(0, input_chans, group_size)]
    convs = [conv3x3(sl, group_size) for sl in slices]
    return tf.concat(convs, axis = 1)

def dense_conv(bottom, num_groups):
    return conv3x3(bottom, bottom.shape[1])

input_shape = [16, 64, 128, 128]
groups = 16
dtype = tf.float32

for cnv_type in [depthwise, depthwise_cudnn, manual_group_conv, dense_conv]:
    tf.reset_default_graph()

    cnv = cnv_type(tf.constant(np.zeros(input_shape), dtype), groups)

    N = 100
    with tf.Session('') as sess:
        sess.run(tf.global_variables_initializer())

        sess.run(cnv) # initialization run

        start = time.time()
        for i in range(N):
            sess.run(cnv)

        print ""%20s : %4.2fs"" % (cnv_type.func_name, time.time() - start)

```

I also tested with NHWC with similar results. Let me know if I am doing something wrong or whether you can replicate my perf results. Thanks!
"
19389,when i compile tf,"
1.  the info list :
dega@degawong:~/Downloads/degawong/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
WARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions
WARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/absl_py/WORKSPACE:1: Workspace name in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/absl_py/WORKSPACE (@io_abseil_py) does not match the name given in the repository's definition (@absl_py); this will cause a build error in future versions
WARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/WORKSPACE:1: Workspace name in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions
WARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/BUILD:1960:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /home/dega/.cache/bazel/_bazel_dega/9ba28720ba7acd5a42576ba91fba1ed4/external/grpc/bazel/grpc_build_system.bzl:172:12
WARNING: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded).
INFO: Found 1 target...
ERROR: /home/dega/Downloads/degawong/tensorflow/tensorflow/contrib/seq2seq/BUILD:89:1: undeclared inclusion(s) in rule '//tensorflow/contrib/seq2seq:beam_search_ops_op_lib':
this rule is missing dependency declarations for the following files included by 'tensorflow/contrib/seq2seq/ops/beam_search_ops.cc':
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/stddef.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/stdarg.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/stdint.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include-fixed/limits.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include-fixed/syslimits.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/mmintrin.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/emmintrin.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/xmmintrin.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/mm_malloc.h'
  '/usr/lib/gcc/x86_64-linux-gnu/6/include/pmmintrin.h'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2.301s, Critical Path: 1.90s
INFO: 0 processes.
FAILED: Build did NOT complete successfully

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:17.10
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:latest
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:latest
- **GCC/Compiler version (if compiling from source)**:6
- **CUDA/cuDNN version**:9.0/7.0.5
- **GPU model and memory**:1050 ti
- **Exact command to reproduce**:

### Describe the problem
when i install tensorflow , there seems always something wrong......

### Source code / logs

"
19387,why ...the tfmobile has stopped ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
19385,Memory leak in Eager execution,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Xubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.8.0-1451-g6ba9573' 1.8.0
- **Python version**: 3.6.5
- **Bazel version (if compiling from source)**: 0.11.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0 20160609
- **CUDA/cuDNN version**: 9.1 / 7.1
- **GPU model and memory**: GeForce GTX 960M - 2GB
- **Exact command to reproduce**: Just run the following code:

```python
import tensorflow as tf

tf.enable_eager_execution()

class Net(tf.keras.Model):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = tf.keras.layers.Conv2D(32, 3)

    def call(self, x):
        y = self.conv1(x)
        return y

inputs = tf.zeros([1, 10, 10, 3], tf.float32)
net = Net()
for _ in range(1000000):
    net(inputs)
```

### Describe the problem
I am observing a memory leak when I run the code above at my machine. The RAM usage increase indefinitely over time (but GPU memory remains constant). Profiling the code with memory_profiler produces the following plot:
![memory_plot_conv2d](https://user-images.githubusercontent.com/24420973/40237678-828c29ec-5a87-11e8-9a96-a15d7b1b3ca6.png)

### Source code / logs

This problem might be related to the usage of tensors of rank higher than two. For example, if I use a rank 2 tensor as input to a dense layer, then there is no leak:
```python
import tensorflow as tf

tf.enable_eager_execution()

class Net(tf.keras.Model):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = tf.keras.layers.Dense(32)

    def call(self, x):
        y = self.fc1(x)
        return y

inputs = tf.zeros([1, 100], tf.float32)
net = Net()
for _ in range(1000000):
    net(inputs)
```
![memory_plot_fc](https://user-images.githubusercontent.com/24420973/40238436-951a3570-5a89-11e8-8d80-b75a423e2f3f.png)

However, if I input a rank 3 tensor to the same net, there is a leak again:
```python
import tensorflow as tf

tf.enable_eager_execution()

class Net(tf.keras.Model):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = tf.keras.layers.Dense(32)

    def call(self, x):
        y = self.fc1(x)
        return y

inputs = tf.zeros([1, 10, 10], tf.float32)
net = Net()
for _ in range(1000000):
    net(inputs)
```
![memory_plot_fc_rank3](https://user-images.githubusercontent.com/24420973/40238473-a8f22ea4-5a89-11e8-9ab7-0b9fc6eab18b.png)

Please let me know if there is anything else I can do to help."
19384,App crashes when building with gradle,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
macOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**:
source


- **Python version**: 
python 3.6
- **Bazel version (if compiling from source)**:
bazel 0.13.0
- **GCC/Compiler version (if compiling from source)**:
GCC 4.2.1

I managed to implement the object detection api in my app with my trained model. Despite that the app works fine I always get an error the the tensorflow_demo.so was not find so the tracking is unavailable which affected the bounding boxes in comparison with the tensorflow object detection demo (when you build it with bazel)

I downloaded the missing .so file and add it to my project by adding this to my gradle :
 
     lintOptions {
        abortOnError false
    }

    sourceSets.main {
        jniLibs.srcDirs =  ['libs']
    }

and then dropping the files into the created directory (JniLibs)

when I unpack my .apk file I can see clearly that the .so are packed in the .apk : 

     20336344  Defl:N  5832450  71% 00-00-1980 00:00 33cca329  lib/arm64-       v8a/libtensorflow_inference.so
      412440  Defl:N   210820  49% 00-00-1980 00:00 f305dd00  lib/armeabi- v7a/libtensorflow_demo.so
      1.3987972  Defl:N  4856867  65% 00-00-1980 00:00 be7adc48  lib/armeabi-v7a/libtensorflow_inference.so
       21178780  Defl:N  6353576  70% 00-00-1980 00:00 addfcb9d  lib/x86/libtensorflow_inference.so
       21811248  Defl:N  6681692  69% 00-00-1980 00:00 4cac1c73  lib/x86_64/libtensorflow_inference.so

the problem now is when I launch the app it crashes with the following error : 

         No implementation found for void package_name_tracking.ObjectTracker.initNative(int, int, boolean) (tried Java_package_name_tracking_ObjectTracker_initNative and Java_package_name_tracking_ObjectTracker_initNative__IIZ)

I want to avoid the use of bazel or cmake, is it possible or there is a solution for the error I'm getting !!

Any information would be helpful
"
19383,Speech demo crash [Bug],"I installed the demo APK on my android phone to test it out. during my playthrough of the speech app, the APP crashed but I had the phone connected to my PC so I found in the logs the following error(couldn't reproduce crash).

`org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: Thread-6
    Process: org.tensorflow.demo, PID: 29587
    java.lang.RuntimeException: You must feed results in increasing time order, but received a timestamp of 1526649298145 that was earlier than the previous one of 1526649298240
        at org.tensorflow.demo.RecognizeCommands.processLatestResults(RecognizeCommands.java:114)
        at org.tensorflow.demo.SpeechActivity.recognize(SpeechActivity.java:319)
        at org.tensorflow.demo.SpeechActivity.access$100(SpeechActivity.java:61)
        at org.tensorflow.demo.SpeechActivity$3.run(SpeechActivity.java:265)
        at java.lang.Thread.run(Thread.java:762)`

### FORM

APK link: https://ci.tensorflow.org/view/Nightly/job/nightly-android/lastSuccessfulBuild/artifact/out/tensorflow_demo.apk

Have I written custom code: No Used the already build Demo APK
OS Platform and Distribution: Android API 24 - Samsung
TensorFlow installed from N/A
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: Mali-T830 (Single core GPU)
Exact command to reproduce: Opened Voice Apk then said the second word(Couldn't reproduce)"
