Issue Number,Issue Title,Issue Body
15795,configure.py environment variables,"Have I written custom code: No
OS Platform and Distribution: Linux (Any?)
TensorFlow installed from: Source
TensorFlow version: 1.4 (Master Branch)
Bazel version: 0.6
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A


### System information
- Building from source
- Branch Master (currently d87a9fbbc5f49ec5ae8eb52c62628f0b1a0bf67f)



### Describe the problem
Line 1353 of configure.py needs to have int( ) wrapped around the function get_var, otherwise the string that is returned always flags positive and setting TF_SET_ANDROID_WORKSPACE=0 environment variable to avoid user interaction in building from source will never work.

  "
15793,Feature Request: tf.train.MonitoredTrainingSession implementation for slim.learning.train,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**:  N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

This is a feature request:
Issue #6263 states that tf.train.Supervisor is to be deprecated. Since the slim.learning.train uses Supervisor internally, is it still advisable to use it?
Or are there any chances to implement the slim.learning.train to use tf.train.MonitoredSession instead of Supervisor?

@sguada 

Thanks!
  "
15792,Portability of TensorFlow Meta graph file,"OS Platform and Distribution : CentOS
TensorFlow installed from : Sources
TensorFlow version : 1.4
Bazel version : N/A
CUDA/cuDNN version 8.0 (CUDA) and 6.0 (CuDNN)
GPU model and memory : N/A
Exact command to reproduce : N/A

The `.meta` file from TensorFlow contains device information. Although I can use `clear_devices=False` to prevent device information getting logged, I beg to ask the relevance of the `.meta` file with respect to portability.

 1. If I have the code for the generation of the TensorFlow graph, then I do not need the `.meta` file as per [this answer][1]. 

 2. What is the applicability of transferring only the `.meta` file to someone ? 

 3. Assuming that I train the graph with 4 GPUs, and then provide `.meta` file to someone with 8 or possibly only 1 GPU. For someone with 8 GPUs, would this not prevent him/her from actually running the graph for training/inference over 8 GPUs ? In the case of someone with only 1 GPU, what would happen to entities with device numbers 1-3 ?

 4. And finally, what are the implications of point 3, when `clear_devices=True` ? 

  [1]: https://stackoverflow.com/a/36203288/8530591
  "
15791,weighted_cross_entropy_with_logits produces wrong result,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.6
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: Geforce GTX 1080 Ti / 12G

### Describe the problem
I am trying to use tf.nn.weighted_cross_entropy_with_logits API, but I found I just can not get the right result when the weight is not 1.0 (1.0 means no weight).


### Source code / logs
```
import tensorflow as tf
import numpy as np

def my_binary_crossentropy_np(labels, output, weight=10.0):
  """"""
  Weighted binary crossentropy between an output tensor 
  and a target tensor.
  """"""
  # transform back to logits
  epsilon = 1e-08
  np.clip(output, epsilon, 1.0 - epsilon, out=output)
  output = np.log(output / (1.0 - output))

  # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits 
  # l = 1 + (q - 1) * z
  # (1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0))
  l = 1.0 + (weight - 1.0) * labels
  loss1 = np.multiply(1.0 - labels, output)
  loss2 = np.multiply(l, np.log(1.0 + np.exp(-abs(output))))
  loss3 = np.maximum(-output, 0)
  loss = loss1 + loss2 + loss3
  
  return np.mean(loss)


def my_binary_crossentropy_tf(labels, output, weight=1.0):
  """"""
  Weighted binary crossentropy between an output tensor 
  and a target tensor.
  """"""
  epsilon = 1e-08
  output = tf.clip_by_value(output, epsilon, 1.0 - epsilon)
  output = tf.log(output / (1.0 - output))

  # compute weighted loss
  #loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=output)
  loss = tf.nn.weighted_cross_entropy_with_logits(targets=labels, logits=output, pos_weight=weight)
  return tf.reduce_mean(loss)


# generate random test data and random label
predict = np.random.rand(10, 8)

label = np.random.rand(10, 8)
label[label >= 0.5] = 1
label[label < 0.5] = 0


loss1 = my_binary_crossentropy_np(label, predict, 1.0)
print('loss1 = ', loss1)

loss1 = my_binary_crossentropy_np(label, predict, 10.0)
print('loss1 = ', loss1)


predict_tf = tf.convert_to_tensor(predict)
loss2 = my_binary_crossentropy_tf(label, predict_tf, 1.0)
loss2 = tf.Session().run(loss2)
print('loss2 = ', loss2)

loss2 = my_binary_crossentropy_tf(label, predict_tf, 10.0)
loss2 = tf.Session().run(loss2)
print('loss2 = ', loss2)
```

running result: 
loss1 =  1.02193164517
loss1 =  1.96332399324

loss2 =  1.02193164517
loss2 =  4.80529539791
"
15788,MultiRNNCell and reuse_variables(),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 4.8.4
- **CUDA/cuDNN version**: 8.0/6.0
- **GPU model and memory**: Geforce GTX TITAN X/12G

### Describe the problem

`tf.nn.dynamic_rnn()` and `tf.nn.rnn_cell.MultiRNNCell()` breaks down when add **`tf.get_variable_scope().reuse_variables()`** before defining a rnn architecture.

#### Correct Situation

- When there is no `tf.get_variable_scope().reuse_variables()`

```python
import tensorflow as tf
x = tf.random_normal([6, 5, 100])

def build_lstm(num_units, num_layers, batch_size):
    def build_cell(num_units):
        return tf.contrib.rnn.LSTMCell(num_units)
    
    with tf.name_scope('multi_cells'):
        cell = tf.nn.rnn_cell.MultiRNNCell([build_cell(num_units) for _ in range(num_layers)])
    init_state = cell.zero_state(batch_size, tf.float32)
    
    return cell, init_state

lstm_cell, lstm_init_state = build_lstm(200, 2, 5)
lstm, final_state =  tf.nn.dynamic_rnn(lstm_cell, x, initial_state=lstm_init_state, time_major=True)
```
It works fine!

#### Wrong Situation

- When there is `tf.get_variable_scope().reuse_variables()`

```python
import tensorflow as tf
x = tf.random_normal([6, 5, 100])

# add a magic sentence here
tf.get_variable_scope().reuse_variables()

def build_lstm(num_units, num_layers, batch_size):
    def build_cell(num_units):
        return tf.contrib.rnn.LSTMCell(num_units)
    
    with tf.name_scope('multi_cells'):
        cell = tf.nn.rnn_cell.MultiRNNCell([build_cell(num_units) for _ in range(num_layers)])
    init_state = cell.zero_state(batch_size, tf.float32)
    
    return cell, init_state

lstm_cell, lstm_init_state = build_lstm(200, 2, 5)
lstm, final_state =  tf.nn.dynamic_rnn(lstm_cell, x, initial_state=lstm_init_state, time_major=True)
```
it returns:

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-7-d333e19dbfd0> in <module>()
----> 1 lstm, final_state =  tf.nn.dynamic_rnn(lstm_cell, x, initial_state=lstm_init_state, time_major=True)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.pyc in dynamic_rnn(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)
    612         swap_memory=swap_memory,
    613         sequence_length=sequence_length,
--> 614         dtype=dtype)
    615 
    616     # Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.pyc in _dynamic_rnn_loop(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)
    775       loop_vars=(time, output_ta, state),
    776       parallel_iterations=parallel_iterations,
--> 777       swap_memory=swap_memory)
    778 
    779   # Unpack final output if not using output tuples.

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.pyc in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)
   2814     loop_context = WhileContext(parallel_iterations, back_prop, swap_memory)  # pylint: disable=redefined-outer-name
   2815     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)
-> 2816     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
   2817     return result
   2818 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.pyc in BuildLoop(self, pred, body, loop_vars, shape_invariants)
   2638       self.Enter()
   2639       original_body_result, exit_vars = self._BuildLoop(
-> 2640           pred, body, original_loop_vars, loop_vars, shape_invariants)
   2641     finally:
   2642       self.Exit()

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.pyc in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)
   2588         structure=original_loop_vars,
   2589         flat_sequence=vars_for_body_with_tensor_arrays)
-> 2590     body_result = body(*packed_vars_for_body)
   2591     if not nest.is_sequence(body_result):
   2592       body_result = [body_result]

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.pyc in _time_step(time, output_ta_t, state)
    760           skip_conditionals=True)
    761     else:
--> 762       (output, new_state) = call_cell()
    763 
    764     # Pack state if using state tuples

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.pyc in <lambda>()
    746 
    747     input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)
--> 748     call_cell = lambda: cell(input_t, state)
    749 
    750     if sequence_length is not None:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in __call__(self, inputs, state, scope)
    181       with vs.variable_scope(vs.get_variable_scope(),
    182                              custom_getter=self._rnn_get_variable):
--> 183         return super(RNNCell, self).__call__(inputs, state)
    184 
    185   def _rnn_get_variable(self, getter, *args, **kwargs):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.pyc in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in call(self, inputs, state)
   1064                                       [-1, cell.state_size])
   1065           cur_state_pos += cell.state_size
-> 1066         cur_inp, new_state = cell(cur_inp, cur_state)
   1067         new_states.append(new_state)
   1068 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in __call__(self, inputs, state, scope)
    181       with vs.variable_scope(vs.get_variable_scope(),
    182                              custom_getter=self._rnn_get_variable):
--> 183         return super(RNNCell, self).__call__(inputs, state)
    184 
    185   def _rnn_get_variable(self, getter, *args, **kwargs):

/usr/local/lib/python2.7/dist-packages/tensorflow/python/layers/base.pyc in __call__(self, inputs, *args, **kwargs)
    573         if in_graph_mode:
    574           self._assert_input_compatibility(inputs)
--> 575         outputs = self.call(inputs, *args, **kwargs)
    576 
    577         if outputs is None:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in call(self, inputs, state)
    606               partitioned_variables.fixed_size_partitioner(
    607                   self._num_unit_shards))
--> 608         self._linear1 = _Linear([inputs, m_prev], 4 * self._num_units, True)
    609 
    610     # i = input_gate, j = new_input, f = forget_gate, o = output_gate

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in __init__(self, args, output_size, build_bias, bias_initializer, kernel_initializer)
   1169           _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],
   1170           dtype=dtype,
-> 1171           initializer=kernel_initializer)
   1172       if build_bias:
   1173         with vs.variable_scope(outer_scope) as inner_scope:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
   1201       partitioner=partitioner, validate_shape=validate_shape,
   1202       use_resource=use_resource, custom_getter=custom_getter,
-> 1203       constraint=constraint)
   1204 get_variable_or_local_docstring = (
   1205     """"""%s

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
   1090           partitioner=partitioner, validate_shape=validate_shape,
   1091           use_resource=use_resource, custom_getter=custom_getter,
-> 1092           constraint=constraint)
   1093 
   1094   def _get_partitioned_variable(self,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)
    415       if ""constraint"" in estimator_util.fn_args(custom_getter):
    416         custom_getter_kwargs[""constraint""] = constraint
--> 417       return custom_getter(**custom_getter_kwargs)
    418     else:
    419       return _true_getter(

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc in wrapped_custom_getter(getter, *args, **kwargs)
   1581     return custom_getter(
   1582         functools.partial(old_getter, getter),
-> 1583         *args, **kwargs)
   1584   return wrapped_custom_getter
   1585 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in _rnn_get_variable(self, getter, *args, **kwargs)
    184 
    185   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 186     variable = getter(*args, **kwargs)
    187     if context.in_graph_mode():
    188       trainable = (variable in tf_variables.trainable_variables() or

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.pyc in _rnn_get_variable(self, getter, *args, **kwargs)
    184 
    185   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 186     variable = getter(*args, **kwargs)
    187     if context.in_graph_mode():
    188       trainable = (variable in tf_variables.trainable_variables() or

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)
    392           trainable=trainable, collections=collections,
    393           caching_device=caching_device, validate_shape=validate_shape,
--> 394           use_resource=use_resource, constraint=constraint)
    395 
    396     if custom_getter is not None:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)
    758       raise ValueError(""Variable %s does not exist, or was not created with ""
    759                        ""tf.get_variable(). Did you mean to set ""
--> 760                        ""reuse=tf.AUTO_REUSE in VarScope?"" % name)
    761     if not shape.is_fully_defined() and not initializing_from_value:
    762       raise ValueError(""Shape of a new variable (%s) must be fully defined, ""

ValueError: Variable rnn/multi_rnn_cell/cell_0/lstm_cell/kernel does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?
```

### Conclusion
It seems that `tf.get_variable_scope().reuse_variables()` and `tf.nn.rnn_cell.MultiRNNCell()` are not compatiable"
15785,Unable to find source java class: '/Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/java/src/main/java/org/tensorflow/op/core/Constant.java',"I follow the instructions on the tensorflow official website on how to import android samples. I did exactly as they said but when I try to run the app it shows the following error.

Error:Execution failed for task ':compileDebugJavaWithJavac'.
> Unable to find source java class: '/Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/java/src/main/java/org/tensorflow/op/core/Constant.java' because it does not belong to any of the source dirs: '[/Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/src/main/java, /Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/src, /Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/build-types/debug/java, /Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/gradleBuild/generated/source/r/debug, /Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/gradleBuild/generated/source/buildConfig/debug, /Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/gradleBuild/generated/source/aidl/debug, /Users/vinay.garg/AndroidStudioProjects/tensorflow/tensorflow/examples/android/gradleBuild/generated/source/rs/debug]'


The problem is, Constants.java file is in the parent directory and not in the sample project directory. I tried to find the usage of the Constants.java file but can't find its use anywhere in the sample project. What am I missing here?"
15784,[FeatureRequest] Support PathLike objects for directory arguments,"With python 3.6, [PEP 519](https://www.python.org/dev/peps/pep-0519/) and the [pathlib](https://docs.python.org/3/library/pathlib.html) module, it would be great if TensorFlow directory parameters accepted PathLike objects.

From the [Backwards Compatibility](https://www.python.org/dev/peps/pep-0519/#backwards-compatibility) part of the documentation, a suggested implementation is:
```python
path.__fspath__() if hasattr(path, ""__fspath__"") else path
```

With such an implementation, it seems `path` in the code above can be any file system representation of `str`, `bytes` or `pathlib.Path`. For my case, I was using/looking at the [`tf.estimator.model_dir`](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/estimator/estimator.py#L122-L126) parameter, but for consistency I assume it would also need applying in all cases where a path is accepted such as `tf.gfile`

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: v1.4.0-8-gbca50da6eb 1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem
Problem is the `pathlib` module represents filesystem paths although is not accepted in parameters that refer to a directory or file in the TensorFlow API. The proposed feature would enable accepting these objects while still maintaining compatibility with existing `str` type paths.
"
15783,CUDA crashes during Cholesky_grad procedure,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes (see command below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: 'unknown' 1.4.0
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: Cuda: 8.0.61.2; cuDNN: 6.1
- **GPU model and memory**: GeForce GTX 770M (3GB); NVIDIA driver 388.71
- **Bazel version**: N/A
- **Exact command to reproduce**:
```
import tensorflow as tf
import numpy as np

with tf.Session() as sess:
    x = tf.placeholder(tf.float64, [None, None])
    f = tf.reduce_sum(tf.cholesky(x))
    sess.run(tf.global_variables_initializer())
    print(sess.run(tf.gradients(f, x), {x:np.array(1.).reshape(1, 1)}))
```

### Describe the problem
Python crashes when running the code above. It was initially encountered when trying to perform a Cholesky decomposition during sparse Gaussian process regression (see https://github.com/GPflow/GPflow/issues/602). I am out of my depth here, but the following error messages seemed interesting:
* Address 0x00000000 is out of bounds
* Blas GEMV launch failed
* failed to run cuBLAS routine cublasDgemv_v2: CUBLAS_STATUS_EXECUTION_FAILED

I have run various CUDA profiling tests and have had no issues. The cholesky decomposition example that comes with CUDA could also execute just fine. I have tried both reducing the amount of GPU memory available to tensorflow _and_ setting it grow-able, to no effect.

### Source code / logs
See above for source code.

stdout/stderr:
```
2018-01-02 18:14:34.305556: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-01-02 18:14:35.110794: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 770M major: 3 minor: 0 memoryClockRate(GHz): 0.797
pciBusID: 0000:01:00.0
totalMemory: 3.00GiB freeMemory: 2.50GiB
2018-01-02 18:14:35.110932: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 770M, pci bus id: 0000:01:00.0, compute capability: 3.0)
2018-01-02 18:14:35.290410: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\kernels\cuda_solvers.cc:159] Creating CudaSolver handles for stream 00000189FC81C670
2018-01-02 18:14:35.615695: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
2018-01-02 18:14:35.615847: F C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:203] Unexpected Event status: 1
2018-01-02 18:14:35.615695: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\stream_executor\cuda\cuda_driver.cc:1110] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS :: No stack trace available
```

cuda-memcheck:
```
========= CUDA-MEMCHECK
2018-01-02 18:15:26.061068: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-01-02 18:15:26.872851: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 770M major: 3 minor: 0 memoryClockRate(GHz): 0.797
pciBusID: 0000:01:00.0
totalMemory: 3.00GiB freeMemory: 2.52GiB
2018-01-02 18:15:26.873028: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 770M, pci bus id: 0000:01:00.0, compute capability: 3.0)
2018-01-02 18:15:27.425673: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\core\kernels\cuda_solvers.cc:159] Creating CudaSolver handles for stream 00000162C1EBD150
2018-01-02 18:15:30.721433: E C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\35\tensorflow\stream_executor\cuda\cuda_blas.cc:551] failed to run cuBLAS routine cublasDgemv_v2: CUBLAS_STATUS_EXECUTION_FAILED
Traceback (most recent call last):
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1323, in _do_call
    return fn(*args)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InternalError: Blas GEMV launch failed:  m=1, n=1
         [[Node: gradients/Cholesky_grad/MatMul_1 = MatMul[T=DT_DOUBLE, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Cholesky_grad/MatrixTriangularSolve, gradients/Cholesky_grad/MatrixBandPart)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test2.py"", line 11, in <module>
    print(sess.run(tf.gradients(f, x), {x:np.array(1.).reshape(1, 1)}))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InternalError: Blas GEMV launch failed:  m=1, n=1
         [[Node: gradients/Cholesky_grad/MatMul_1 = MatMul[T=DT_DOUBLE, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Cholesky_grad/MatrixTriangularSolve, gradients/Cholesky_grad/MatrixBandPart)]]

Caused by op 'gradients/Cholesky_grad/MatMul_1', defined at:
  File ""test2.py"", line 11, in <module>
    print(sess.run(tf.gradients(f, x), {x:np.array(1.).reshape(1, 1)}))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 581, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 353, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 581, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\linalg_grad.py"", line 77, in _CholeskyGrad
    math_ops.matmul(l_inverse, middle, adjoint_a=True), l_inverse)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 1891, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 2436, in _mat_mul
    name=name)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

...which was originally created as op 'Cholesky', defined at:
  File ""test2.py"", line 9, in <module>
    f = tf.reduce_sum(tf.cholesky(x))
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_linalg_ops.py"", line 419, in cholesky
    ""Cholesky"", input=input, name=name)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InternalError (see above for traceback): Blas GEMV launch failed:  m=1, n=1
         [[Node: gradients/Cholesky_grad/MatMul_1 = MatMul[T=DT_DOUBLE, transpose_a=true, transpose_b=false, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients/Cholesky_grad/MatrixTriangularSolve, gradients/Cholesky_grad/MatrixBandPart)]]

========= Invalid __global__ read of size 1
=========     at 0x00000398 in void Eigen::internal::FullReductionKernel<int=256, int=128, Eigen::TensorEvaluator<Eigen::TensorReductionOp<Eigen::internal::SumReducer<double>, Eigen::DimensionList<__int64, unsigned __int64=2> const , Eigen::TensorGeneratorOp<tensorflow::generator::OverwriteDiagGenerator<double>, Eigen::TensorMap<Eigen::Tensor<double const , int=2, int=1, __int64>, int=16, Eigen::MakePointer> const > const , Eigen::MakePointer> const , Eigen::GpuDevice>, Eigen::internal::SumReducer<double>, __int64>(Eigen::internal::SumReducer<double>, double, __int64, Eigen::internal::SumReducer<double>::CoeffReturnType*, unsigned int*)
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x00000000 is out of bounds
=========     Saved host backtrace up to driver entry point at kernel launch time
=========     Host Frame:C:\WINDOWS\SYSTEM32\nvcuda.dll (cuTexRefSetAddress + 0x1aaaf3) [0x1b8145]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd [0x35d2]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd [0x2365]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (perftools::gputools::cuda::CUDATimer::Stop + 0x1cf760) [0x2202ba0]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (perftools::gputools::cuda::CUDATimer::Stop + 0x1d18f2) [0x2204d32]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (perftools::gputools::cuda::CUDATimer::Stop + 0x1ce985) [0x2201dc5]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::MatrixSetDiagOp<Eigen::GpuDevice,double>::Compute + 0x407) [0x13180d7]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::BaseGPUDevice::ComputeHelper + 0x4f4) [0x3aab84]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::BaseGPUDevice::Compute + 0x18a) [0x3aa3aa]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::NewLocalExecutor + 0xfdb) [0x2aefdb]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (?_Copy@?$_Func_impl@V?$_Binder@U_Unforced@std@@P8ExecutorState@?A0x4546b700@tensorflow@@EAAXUTaggedNode@345@_J@ZQEAV345@AEBU6345@AEA_J@std@@V?$allocator@H@2@X$$V@std@@EEBAPEAV?$_Func_base@X$$V@2@PEAX@Z + 0x78) [0x2b2548]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop + 0x3d9) [0x247839]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop + 0x560) [0x2479c0]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::WindowsFileSystem::Utf8ToWideChar + 0x175) [0x276795]
=========     Host Frame:C:\Users\tomah\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\_pywrap_tensorflow_internal.pyd (tensorflow::WindowsFileSystem::Utf8ToWideChar + 0xc9) [0x2766e9]
=========     Host Frame:C:\WINDOWS\System32\ucrtbase.dll (iswascii + 0xa5) [0x1d885]
=========     Host Frame:C:\WINDOWS\System32\KERNEL32.DLL (BaseThreadInitThunk + 0x14) [0x11fe4]
=========     Host Frame:C:\WINDOWS\SYSTEM32\ntdll.dll (RtlUserThreadStart + 0x21) [0x6ef91]
=========
========= ERROR SUMMARY: 1 error
```

  "
15782,"[BUG REPORT] how to set TF_CONFIG,  bug ? ","------------------------

### System information
python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.4.0-19-ga52c8d9', '1.4.1')


### Describe the problem

[NORMAL CODE]
```
  chief_host = ['localhost:20000']
  worker_hosts = ['localhost:20002']
  ps_hosts = ['localhost:20001']

  cluster = {'chief': chief_host,
             'worker': worker_hosts,
             'ps': ps_hosts}
  task_type = 'chief'
  task_index = 0
  os.environ['TF_CONFIG'] = json.dumps(
      {'cluster': cluster,
       'task': {'type': task_type, 'index': task_index}})
```

[ NORMAL OUTPUT]
```
INFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20001'], u'chief': [u'localhost:20000'], u'worker': [u'localhost:20002']}, u'task': {u'index': 0, u'type': u'chief'}}
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {
  key: ""GPU""
}
, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x5e30bd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhost:20000', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}
INFO:tensorflow:Start Tensorflow server.
2018-01-02 16:31:58.374169: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
E0102 16:31:58.378815122   44355 ev_epoll1_linux.c:1051]     grpc epoll fd: 3
2018-01-02 16:31:58.384682: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -> {0 -> localhost:20000}
2018-01-02 16:31:58.384723: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:20001}
2018-01-02 16:31:58.384736: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20002}
2018-01-02 16:31:58.391874: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20000
Parsing data/adult.data
INFO:tensorflow:Create CheckpointSaverHook.
2018-01-02 16:32:10.407610: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-01-02 16:32:10.407652: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
2018-01-02 16:32:20.407746: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-01-02 16:32:20.407766: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
2018-01-02 16:32:30.407834: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:ps/replica:0/task:0
2018-01-02 16:32:30.407850: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:0
```

============

[BUG CODE]
```
  print(type(chief_host), type(worker_hosts), type(ps_hosts))
  print('chief=',chief_host, 'worker=',worker_hosts, 'ps=',ps_hosts)

  chief_host = chief_host
  worker_hosts = worker_hosts
  ps_hosts = ps_hosts

  cluster = {'chief': chief_host,
             'worker': worker_hosts,
             'ps': ps_hosts}
  task_type = 'chief' 
  task_index = 0 
  os.environ['TF_CONFIG'] = json.dumps(
      {'cluster': cluster,
       'task': {'type': task_type, 'index': task_index}})
```

[BUG OUTPUT]
```
<type 'list'> <type 'list'> <type 'list'>
chief= ['localhosts:20001'] worker= ['localhost:20003'] ps= ['localhost:20000']

INFO:tensorflow:TF_CONFIG environment variable: {u'cluster': {u'ps': [u'localhost:20000'], u'chief': [u'localhosts:20001'], u'worker': [u'localhost:20003']}, u'task': {u'index': 0, u'type': u'chief'}}
INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': device_count {
  key: ""GPU""
}
, '_keep_checkpoint_max': 5, '_task_type': u'chief', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x6264e10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 1, '_tf_random_seed': None, '_master': u'grpc://localhosts:20001', '_num_worker_replicas': 2, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/census_model', '_save_summary_steps': 100}
INFO:tensorflow:Start Tensorflow server.
2018-01-02 16:34:09.909573: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
E0102 16:34:09.914156177   44635 ev_epoll1_linux.c:1051]     grpc epoll fd: 3
2018-01-02 16:34:09.920491: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job chief -> {0 -> localhost:20001}
2018-01-02 16:34:09.920540: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:20000}
2018-01-02 16:34:09.920558: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20003}
2018-01-02 16:34:09.927272: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:20001
Parsing data/adult.data
INFO:tensorflow:Create CheckpointSaverHook.
```

Note: [ BUG OUTPUT ] don't print "" CreateSession still waiting for response from worker "" ,  i have wait long enough !!!

===========
my train and eval code
```
  train_spec = tf.estimator.TrainSpec(input_fn=lambda: input_fn(FLAGS.train_data,
      None, True, FLAGS.batch_size), max_steps=30000)
  eval_spec = tf.estimator.EvalSpec(input_fn=lambda: input_fn(FLAGS.test_data, 1, False,
      FLAGS.batch_size), steps=5)
  tf.estimator.train_and_evaluate(model, train_spec, eval_spec)
```
i can run my code on non-distribution and distribution as follows style:
```
TF_CONFIG='{
    ""cluster"": {
        ""chief"": [""localhost:20000""],
        ""worker"": [""localhost:20002""],
        ""ps"": [""localhost:20001""]
    },
    ""task"": {""type"": ""worker"", ""index"": 0}
}'
TF_CONFIG=$TF_CONFIG python wide_deep_d.py 

......
```
but can't set TF_CONFIG by os.environ with json.dumps correctly

Need your help, Thanks , "
15781,build&link tensorflow lite c++ library,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: g++ 5.4.0
- **CUDA/cuDNN version**: none
- **GPU model and memory**: none
- **Exact command to reproduce**: g++ -std=c++11 -I...tensorflow -L. -lframework demo.cpp

### Describe the problem
I run 'bazel build //tensorflow/contrib/lite:framework' and get libframework.so. Then I use libframework.so in my own code, but get undefined reference error when compile with g++:
/temp/ccYTZw2h.o: In function 'main':
demo.cpp:(.text+0x46): undefined reference to 'tflite::DefaultErrorReporter()'
demo.cpp:(.text+0x6a): undefined reference ro 'tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'
......

I get following lines by 'nm libframework.so | grep 'DefaultErrorReporter'':
000000000001b1b0 b _ZGVZN6tflite20DefaultErrorReporterEvE14error_reporter
0000000000007990 T _ZN6tflite20DefaultErrorReporterEv
000000000001b1a8 b _ZZN6tflite20DefaultErrorReporterEvE14error_reporter

I'm not familiar with how to use tensorflow lite. Where is the problem could be?

### Source code / logs
"
15779,"I have simple question on tensorflow , Does tensorflow support for IONIC (Hybrid-Applications), I mean the models that we genarate through tensorflow that will support for Ionic application.","  I have simple question on tensorflow , Does tensorflow support for IONIC (Hybrid-Applications), I mean the models that we genarate through tensorflow that will support for Ionic application"
15777,libstdc++.so.6: version `CXXABI_1.3.8' not found,"All of my `tf-nightly` Travis CI pipelines started failing today with following error

``` ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /home/travis/virtualenv/python3.5.4/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)```

Example:
https://travis-ci.org/yaroslavvb/chain_constant_memory/builds/323851093

Any ideas how to fix?
"
15776,Compiler Errors Installing Tensorflow from Source,"### System information

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 SP1
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.5
- **Python version**: 3.6.4
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 6.4.0
- **CUDA/cuDNN version**: 7.0
- **GPU model and memory**: NVIDIA Quadro K4000

- **Exact command to reproduce**:

bazel build -c opt %BUILD_OPTS% //tensorflow/tools/pip_package:build_pip_package

### Describe the problem

I have tried compiling with MSYS2 and VS2015. I am trying to get VS2015 to work.

###Using VS2015 and `--cpu=x64_windows_msvc --host_cpu=x64_windows_msvc` (among other options), I get the following error:

```
c:\Users\adam.hendry\Downloads\tensorflow>bazel build -c opt %BUILD_OPTS% //tens
orflow/tools/pip_package:build_pip_package
.......................
Loading:
Loading: 0 packages loaded
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (48 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (81 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (93 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (94 packages
loaded)
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/core/BUILD:1807:1:
 in includes attribute of cc_library rule //tensorflow/core:framework_headers_li
b: '../../external/nsync/public' resolves to 'external/nsync/public' not below t
he relative path of its package 'tensorflow/core'. This will be an error in the
future. Since this rule was created by the macro 'cc_header_only_library', the e
rror might have been caused by the macro implementation in C:/users/adam.hendry/
downloads/tensorflow/tensorflow/tensorflow.bzl:1138:30
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (116 packages
 loaded)
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (127 pack
ages loaded).
INFO: Found 1 target...
Building: no action
[0 / 7] [-----] BazelWorkspaceStatusAction stable-status.txt
INFO: From Compiling external/zlib_archive/uncompr.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzlib.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/adler32.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzclose.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/compress.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
[134 / 1,014] Compiling external/zlib_archive/deflate.c [for host]; 1s local ...
 (16 actions, 14 running)
INFO: From Compiling external/zlib_archive/infback.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling tensorflow/core/lib/hash/crc32c_accelerate.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/highwayhash/highwayhash/arch_specific.cc [for host
]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/crc32.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inflate.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inftrees.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzread.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzwrite.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/zutil.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inffast.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/trees.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/deflate.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/fft2d/fft/fftsg.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/farmhash_archive/src/farmhash.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling tensorflow/compiler/xla/executable_run_options.cc:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
[349 / 1,966] Compiling external/protobuf_archive/src/google/protobuf/compiler/j
s/embed.cc [for host]; 1s local ... (5 actions, 3 running)
INFO: From Compiling external/farmhash_archive/src/farmhash.cc:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/protobuf_archive/src/google/protobuf/compiler/js/e
mbed.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling tensorflow/core/grappler/costs/robust_stats.cc:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/lmdb/midl.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
[643 / 3,343] Compiling external/lmdb/mdb.c; 0s local ... (23 actions, 22 runnin
g)
INFO: From Compiling external/zlib_archive/gzread.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/trees.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzclose.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzwrite.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/crc32.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inffast.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inftrees.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/compress.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/uncompr.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/zutil.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/gzlib.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/infback.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/deflate.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/inflate.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/zlib_archive/adler32.c:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/png_archive/pngtrans.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/highwayhash/highwayhash/sip_hash.cc [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/png_archive/pngget.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
INFO: From Compiling external/png_archive/pngread.c [for host]:
cl : Command line warning D9002 : ignoring unknown option '-march=native'
ERROR: C:/users/adam.hendry/downloads/tensorflow/tensorflow/compiler/xla/service
/cpu/BUILD:772:1: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu
:custom_call_target_registry' failed (Exit 1): cl.exe failed: error executing co
mmand
  cd C:/users/adam.hendry/appdata/local/temp/_bazel_adam.hendry/qoyar4dt/execroo
t/org_tensorflow
  SET CUDA_COMPUTE_CAPABILITIE=None
    SET CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1
    SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.
1
    SET CUDNN_INSTALL_PATH=C:/cuda
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C
:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program
Files (x86)\Windows Kits\10\include\10.0.16299.0\ucrt;C:\Program Files (x86)\Win
dows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\10\inclu
de\10.0.16299.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.16299
.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.16299.0\winrt;
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\LIB\amd64;C:\
Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\LIB\amd64;C:\Program
Files (x86)\Windows Kits\10\lib\10.0.16299.0\ucrt\x64;C:\Program Files (x86)\Win
dows Kits\NETFXSDK\4.6.1\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\1
0.0.16299.0\um\x64;
    SET NO_WHOLE_ARCHIVE_OPTION=1
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE\Com
monExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studi
o 14.0\VC\BIN\amd64;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program F
iles (x86)\Microsoft Visual Studio 14.0\VC\VCPackages;C:\Program Files (x86)\Mic
rosoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual St
udio 14.0\Common7\Tools;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team
 Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio 14.0
\Team Tools\Performance Tools;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\
Program Files (x86)\Windows Kits\10\bin\x86;C:\Program Files (x86)\Microsoft SDK
s\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;;C:\Windows\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Python/Python36/lib/site-packages
    SET TEMP=C:\Users\ADAM~1.HEN\AppData\Local\Temp
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0
    SET TF_CUDA_VERSION=9.1
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
    SET TMP=C:\Users\ADAM~1.HEN\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /c ten
sorflow/compiler/xla/service/cpu/custom_call_target_registry.cc /Fobazel-out/x64
_windows_msvc-py3-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/custom_call_
target_registry/tensorflow/compiler/xla/service/cpu/custom_call_target_registry.
o /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPR
ECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /big
obj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 -DGEMMLOWP_ALLOW_SLO
W_SCALAR_FALLBACK -w -march=native -D_GLIBCXX_USE_CXX11_ABI=0 /I. /Ibazel-out/x6
4_windows_msvc-py3-opt/genfiles /Iexternal/bazel_tools /Ibazel-out/x64_windows_m
svc-py3-opt/genfiles/external/bazel_tools /Iexternal/bazel_tools/tools/cpp/gcc3
/showIncludes /MD /O2 /DNDEBUG
C:\users\adam.hendry\appdata\local\temp\_bazel_adam.hendry\qoyar4dt\execroot\org
_tensorflow\tensorflow\compiler\xla\service\cpu\custom_call_target_registry.cc :
 fatal error C1083: Cannot open compiler generated file: '': Invalid argument
cl : Command line warning D9002 : ignoring unknown option '-march=native'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 25.271s, Critical Path: 3.48s
FAILED: Build did NOT complete successfully
```

###Using VS2015 and `--cpu=x64_windows_msys --host_cpu=x64_windows_msys` (among other options), I get this error:

```
c:\Users\adam.hendry\Downloads\tensorflow>bazel build -c opt %BUILD_OPTS% //tens
orflow/tools/pip_package:build_pip_package
.......................
Loading:
Loading: 0 packages loaded
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (1 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (6 packages l
oaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (73 packages
loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (131 packages
 loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (141 packages
 loaded)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (142 packages
 loaded)
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/core/BUILD:1807:1:
 in includes attribute of cc_library rule //tensorflow/core:framework_headers_li
b: '../../external/nsync/public' resolves to 'external/nsync/public' not below t
he relative path of its package 'tensorflow/core'. This will be an error in the
future. Since this rule was created by the macro 'cc_header_only_library', the e
rror might have been caused by the macro implementation in C:/users/adam.hendry/
downloads/tensorflow/tensorflow/tensorflow.bzl:1138:30
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (157 packages
 loaded)
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/contrib/learn/BUIL
D:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflo
w/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/sessio
n_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: C:/users/adam.hendry/downloads/tensorflow/tensorflow/contrib/learn/BUIL
D:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflo
w/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/sessio
n_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (254 pack
ages loaded).
INFO: Found 1 target...
Building: no action
[0 / 17] [-----] BazelWorkspaceStatusAction stable-status.txt
[105 / 747] Executing genrule @local_config_cuda//cuda:cuda-lib; 2s local ... (2
4 actions running)
[106 / 747] Executing genrule @local_config_cuda//cuda:cuda-lib; 5s local ... (2
3 actions running)
[111 / 747] Executing genrule @local_config_cuda//cuda:cuda-lib; 10s local ... (
24 actions running)
[113 / 747] Executing genrule //tensorflow/core:version_info_gen [for host]; 13s
 local ... (23 actions running)
[129 / 968] Executing genrule //tensorflow/core:version_info_gen [for host]; 20s
 local ... (24 actions running)
[148 / 1,274] Executing genrule //tensorflow/core:version_info_gen [for host]; 3
1s local ... (24 actions running)
[149 / 1,275] Executing genrule //tensorflow/core:version_info_gen [for host]; 3
7s local ... (24 actions running)
[149 / 1,275] Executing genrule //tensorflow/core:version_info_gen [for host]; 4
6s local ... (24 actions running)
[155 / 1,279] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 57s local ... (23 actions running)
[228 / 1,543] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 68s local ... (24 actions, 23 running)
[417 / 2,009] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 83s local ... (24 actions, 23 running)
[437 / 2,009] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 98s local ... (23 actions running)
[458 / 2,009] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 115s local ... (24 actions, 23 running)
[523 / 2,096] Executing genrule @local_config_cuda//cuda:cuda-include [for host]
; 135s local ... (24 actions, 23 running)
ERROR: C:/users/adam.hendry/appdata/local/temp/_bazel_adam.hendry/qoyar4dt/exter
nal/com_google_absl/absl/base/BUILD.bazel:30:1: C++ compilation of rule '@com_go
ogle_absl//absl/base:spinlock_wait' failed (Exit 1): gcc failed: error executing
 command
  cd C:/users/adam.hendry/appdata/local/temp/_bazel_adam.hendry/qoyar4dt/execroo
t/org_tensorflow
  SET CUDA_COMPUTE_CAPABILITIE=None
    SET CUDA_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.1
    SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.
1
    SET CUDNN_INSTALL_PATH=C:/cuda
    SET NO_WHOLE_ARCHIVE_OPTION=1
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Program Files (x86)\Microsoft Vi
sual Studio 14.0\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Fi
les (x86)\MSBuild\14.0\bin;C:\Program Files (x86)\Microsoft Visual Studio 14.0\C
ommon7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN;C:\Progra
m Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Windows\Microsoft.NE
T\Framework\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\VC
Packages;C:\Program Files (x86)\HTML Help Workshop;C:\Program Files (x86)\Micros
oft Visual Studio 14.0\Team Tools\Performance Tools;C:\Program Files (x86)\Windo
ws Kits\10\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETF
X 4.6.1 Tools\;C:\Program Files (x86)\Microsoft Visual Studio 14.0\;C:\Program F
iles (x86)\Microsoft Visual Studio 14.0\VC\;C:\Program Files (x86)\Microsoft Vis
ual Studio 14.0\VC\bin\;C:\Program Files (x86)\Windows Kits\10\;C:\Python\Python
36\;C:\Python\Python36\Scripts\;C:\ProgramData\chocolatey\bin;C:\Program Files\G
it LFS;C:\Program Files\CMake\bin;C:\Program Files\Java\jdk1.8.0_152\;C:\Program
Data\Oracle\Java\javapath;C:\Windows;C:\Windows\System32;C:\Windows\System32Wbem
;C:\Windows\System32WindowsPowerShell\v1.0\;C:\bazel\output;C:\apache-maven-3.3.
9\;C:\apache-maven-3.3.9\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\
v9.1\;%CUDNN_PATH%;C:\Program Files\ImageMagick-7.0.5-Q16\;C:\Program Files (x86
)\QuickTime\QTSystem\;C:\Program Files (x86)\gs\gs9.21\bin\;C:\cppan\cppan.exe;C
:\Program Files (x86)\Tesseract-OCR\;C:\Program Files\MiKTeX 2.9\miktex\bin\x64\
;C:\ffmpeg\bin;C:\Users\adam.hendry\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm
\;C:\Program Files\HDF_Group\HDF5\1.10.1\bin\;C:\Program Files (x86)\GtkSharp\2.
12\bin;C:\Program Files (x86)\gettext-iconv\lib\gettext;C:\Program Files (x86)\C
ommon Files\Intel\Shared Libraries\redist\ia32\mpirt;C:\Program Files (x86)\Comm
on Files\Intel\Shared Libraries\redist\ia32\compiler;C:\Program Files\Common Fil
es\Microsoft Shared\Windows Live;C:\Program Files (x86)\Common Files\Microsoft S
hared\Windows Live;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Pro
gram Files (x86)\Intel\iCLS Client\;C:\Program Files\Intel\iCLS Client\;C:\Progr
am Files (x86)\Windows Live\Shared;C:\Program Files\Microsoft SQL Server\130\Too
ls\Binn\;C:\Intel\OpenCL\sdk\bin\x64;C:\Intel\OpenCL\sdk\bin\x86\;C:\Intel\OpenC
L\sdk\bin\Pin;C:\Intel\OpenCL\sdk\bin\GTPin;C:\Program Files\Git\cmd;
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Python/Python36/python.exe
    SET PYTHON_LIB_PATH=C:/Python/Python36/lib/site-packages
    SET TF_CUDA_CLANG=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0
    SET TF_CUDA_VERSION=9.1
    SET TF_CUDNN_VERSION=7
    SET TF_NEED_CUDA=1
    SET TF_NEED_OPENCL_SYCL=0
  C:/msys64/usr/bin/gcc -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -w -march=native -
std=gnu++0x -D_GLIBCXX_USE_CXX11_ABI=0 -MD -MF bazel-out/x64_windows_msys-py3-op
t/bin/external/com_google_absl/absl/base/_objs/spinlock_wait/external/com_google
_absl/absl/base/internal/spinlock_wait.d -frandom-seed=bazel-out/x64_windows_msy
s-py3-opt/bin/external/com_google_absl/absl/base/_objs/spinlock_wait/external/co
m_google_absl/absl/base/internal/spinlock_wait.o -D__CLANG_SUPPORT_DYN_ANNOTATIO
N__ -iquote external/com_google_absl -iquote bazel-out/x64_windows_msys-py3-opt/
genfiles/external/com_google_absl -iquote external/bazel_tools -iquote bazel-out
/x64_windows_msys-py3-opt/genfiles/external/bazel_tools -isystem external/bazel_
tools/tools/cpp/gcc3 -Wall -Wextra -Wcast-qual -Wconversion-null -Wmissing-decla
rations -Woverlength-strings -Wpointer-arith -Wunused-local-typedefs -Wunused-re
sult -Wvarargs -Wvla -Wwrite-strings -c external/com_google_absl/absl/base/inter
nal/spinlock_wait.cc -o bazel-out/x64_windows_msys-py3-opt/bin/external/com_goog
le_absl/absl/base/_objs/spinlock_wait/external/com_google_absl/absl/base/interna
l/spinlock_wait.o
In file included from external/com_google_absl/absl/base/config.h:66:0,
                 from external/com_google_absl/absl/base/port.h:23,
                 from external/com_google_absl/absl/base/internal/spinlock_posix
.inc:23,
                 from external/com_google_absl/absl/base/internal/spinlock_wait.
cc:27:
external/com_google_absl/absl/base/policy_checks.h:40:2: error: #error ""Cygwin i
s not supported.""
 #error ""Cygwin is not supported.""
  ^~~~~
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 172.251s, Critical Path: 153.84s
FAILED: Build did NOT complete successfully
```

###Any help would be appreciated. I can give you more details as well.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15773,How to define multiple loss function and train_op  in tf.estimator.EstimatorSpec,"

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: 1080 Ti + 1080

### Describe the problem
I'm currently implementing a pose estimation system and I defined my network with 3 loss and train_op in each of degree, yaw, pitch and roll. And I'm current using your tf.estimator API which I think is pretty convenient to monitor the system, however I found that I may only be able to define one loss and train_op using this set of API. I would like to know if there is any solution to train and monitor the system with multiple loss and train_op at the same time. Thanks.

### Source code / logs
```
    return tf.estimator.EstimatorSpec(
        mode=mode,
        predictions=predictions,
        loss=[yaw_total_loss, pitch_total_loss, roll_total_loss],  # error
        train_op=[yaw_train_op, pitch_train_op, roll_train_op],  # error
        eval_metric_ops=None)
```
"
15771,Flexible input shape for map method in class RandomFourierFeatureMapper,"This is a feature request. In tensorflow r1.4, Class RandomFourierFeatureMapper, map method,
The shape of the input must be, [batch_size, self._output_dim].   

There can be scenarios where in each batch there are multiple training point, essentially i'm proposing a scenario where the input shape  must be  [batch_size, x ,self._output_dim].   

Which is not possible in current API.        
In the matmul we can see that it is mentioned, ""The inputs must, following any transpositions, be tensors of rank >= 2 where the inner 2 dimensions specify valid matrix multiplication arguments, and any further outer dimensions match."" which is in-fact very flexible.     

"
15769,Out of range: End of sequence,"
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**:   python3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:   Cuda 8.0  cudnn6_6.0.
- **GPU model and memory**:  Titax 12G
- **Exact command to reproduce**:

python -m nmt.nmt \
    --src=vi --tgt=en \
    --vocab_prefix=/tmp/nmt_data/vocab  \
    --train_prefix=/tmp/nmt_data/train \
    --dev_prefix=/tmp/nmt_data/tst2012  \
    --test_prefix=/tmp/nmt_data/tst2013 \
    --out_dir=/tmp/nmt_model \
    --num_train_steps=12000 \
    --steps_per_stats=100 \
    --num_layers=2 \
    --num_units=128 \
    --dropout=0.2 \
    --metrics=bleu

2018-01-01 21:14:49.071267: W tensorflow/core/kernels/lookup_util.cc:362] Table trying to initialize from file /tmp/nmt_data/vocab.vi is already initialized.
2018-01-01 21:14:49.071378: W tensorflow/core/kernels/lookup_util.cc:362] Table trying to initialize from file /tmp/nmt_data/vocab.en is already initialized.
2018-01-01 21:14:49.071554: W tensorflow/core/kernels/lookup_util.cc:362] Table trying to initialize from file /tmp/nmt_data/vocab.en is already initialized.
  loaded infer model parameters from /tmp/nmt_model/translate.ckpt-9000, time 0.08s

  decoding to output /tmp/nmt_model/output_dev.
2018-01-01 21:14:58.585992: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: End of sequence
         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?], [?]], output_types=[DT_INT32, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
2018-01-01 21:14:58.586255: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: End of sequence
         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?], [?]], output_types=[DT_INT32, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
  done, num sentences 1553, num translations per input 1, time 9s, Mon Jan  1 21:14:58 2018.
  bleu dev: 5.2
  saving hparams to /tmp/nmt_model/hparams

  decoding to output /tmp/nmt_model/output_test.
2018-01-01 21:15:08.289098: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: End of sequence
         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?], [?]], output_types=[DT_INT32, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
2018-01-01 21:15:08.289145: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: End of sequence
         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?], [?]], output_types=[DT_INT32, DT_INT32], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]
  done, num sentences 1268, num translations per input 1, time 9s, Mon Jan  1 21:15:08 2018.
  bleu test: 4.4

"
15768,Training broke with ResourceExausted error,"------------------------

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5
- **CUDA/cuDNN version**: 8
- **GPU model and memory**: TITAN X, 12207MiB

----------------------

Most Probably everyone will be asking about this is a question for StackOverflow. Here is the link to the StackOverflow question,  But please take a look at the problem. There could be some bug in tensorflow as the error occurs after 32 epoch.
https://stackoverflow.com/questions/48007984/training-broke-with-resourceexausted-error

Here is the code of the model, https://paste.ubuntu.com/26298336/
A short description of the model would be,

- Character level Embedding Vector -> Embedding lookup -> LSTM1
- Word level Embedding Vector->Embedding lookup -> LSTM2
- [LSTM1+LSTM2] -> single layer MLP-> softmax layer/CRF layer
- [LSTM1+LSTM2] -> Single layer MLP-> WGAN discriminator

While running the code it produces the following error output at the epoch 32,

`ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[24760,100] [[Node: chars/bidirectional_rnn/bw/bw/while/bw/lstm_cell/split = Split[T=DT_FLOAT, num_split=4, _device=""/job:localhost/replica:0/task:0/device:GPU:0""](gradients_2/Add_3/y, chars/bidirectional_rnn/bw/bw/while/bw/lstm_cell/BiasAdd)]] [[Node: bi-lstm/bidirectional_rnn/bw/bw/stack/_167 = _Recvclient_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_636_bi-lstm/bidirectional_rnn/bw/bw/stack"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]]`

My question is if there is any error then it should occur in the first epoch why at 32 epoch?

I am using embedding_lookup in following way,

```
_word_embeddings = tf.Variable(
                        embeddings,
                        name=""_word_embeddings"",
                        dtype=tf.float32,
                        trainable=False)
            word_embeddings = tf.nn.embedding_lookup(_word_embeddings, self.word_ids, name=""word_embeddings"")

```

Where `embeddings` is a `(61698, 100)` sized vector. which is only 24 MB. However in the error message, it showed the error with, `(24760, 100)` sized vector which is only 10MB. It also produces warning while declaring optimizers for the model. it was suggested as below,

> gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.

"
15767,Decode_raw_op_test failure on s390x,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: s390x Ubuntu 16.04 
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.1
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: bazel test -c opt //tensorflow/python/kernel_tests:decode_raw_op_test

### Describe the problem
Observing a failure in [testToFloat16](https://github.com/tensorflow/tensorflow/blob/v1.4.1/tensorflow/python/kernel_tests/decode_raw_op_test.py#L77) sub test, while running `decode_raw_op_test`. It seems that the [byte-reversal logic](https://github.com/tensorflow/tensorflow/blob/v1.4.1/tensorflow/core/kernels/decode_raw_op.cc#L80) for big endian is not needed for **float16 input**(and float16 output). While the other sub tests like int16/uint16 which have byte array input need byte-swapping for consistent results. What would be the best way to correct this?
@rmlarsen, @jiefangxuanyan , Could you please share your thoughts on this?
 
### Source code / logs
```
FAIL: testToFloat16 (__main__.DecodeRawOpTest)
----------------------------------------------------------------------
.
AssertionError:
Arrays are not equal
(mismatch 100.0%)
 x: [repr failed for <matrix>: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()]
 y: array([[  3.576279e-06,   1.144409e-05,   1.156330e-05,   4.053116e-06]], dtype=float16)
----------------------------------------------------------------------
Ran 7 tests in 0.089s

FAILED (failures=1)
not equal where =  (array([0, 0, 0, 0]), array([0, 1, 2, 3]))
not equal lhs =  [[ 1. -2. -3.  4.]]
not equal rhs =  [  3.57627869e-06   1.14440918e-05   1.15633011e-05   4.05311584e-06]
```
"
15766,tf.assert_equal raises incorrect traceback in Eager mode,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04.1 LTS
- **TensorFlow installed from (source or binary)**: pip binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171227
- **Python version**: 3.5.0
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: python main.py


### Describe the problem

In eager mode, tf.assert_equal only shows `[]` in traceback message when two inputs are different. However, in graph mode, it does show different values in the message. 

### Source code / logs

```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()

x = tf.constant([1,2,3])
y = tf.constant([3,2,1])

with tf.control_dependencies([tf.assert_equal(x, y)]):
    output = tf.reduce_sum(x)

```


Eager Mode Traceback:

```
Traceback (most recent call last):
  File ""/Users/matt/PycharmProjects/scratch/main.py"", line 9, in <module>
    with tf.control_dependencies([tf.assert_equal(x, y)]):
  File ""/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py"", line 376, in assert_equal
    summary_msg)))
tensorflow.python.framework.errors_impl.InvalidArgumentError: 
Condition x == y did not hold.
Indices of first 0 different values:
[]
Corresponding x values:
[]
Corresponding y values:
[]
```


Graph Mode Traceback:
```
Traceback (most recent call last):
  File ""/Users/matt/PycharmProjects/scratch/main.py"", line 9, in <module>
    with tf.control_dependencies([tf.assert_equal(x, y)]):
  File ""/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py"", line 391, in assert_equal
    _assert_static(condition_static, data)
  File ""/usr/local/var/pyenv/versions/anaconda3-4.1.1/lib/python3.6/site-packages/tensorflow/python/ops/check_ops.py"", line 104, in _assert_static
    message='\n'.join(data_static))
tensorflow.python.framework.errors_impl.InvalidArgumentError: 
Condition x == y did not hold element-wise:
x (Const:0) = 
[1 2 3]
y (Const_1:0) = 
[3 2 1]
```
"
15760,Custom gradient aggregation methods,"I would like a way to apply some custom gradient aggregation ops. Probably the simplest thing to do is just allow `tf.gradients` (and `Optimizer.compute_gradients`) to return un-aggregated gradients so I could work with those?
Anyway, seems like an easy fix? I will do this myself in a month or so (cant now as on holiday), but if someone else wants to do it/has some thoughts, I am interested.
"
15758,Getting rid of all_opensource_files,"This ticket is for tracking the progress of removing the `all_opensource_files` bazel target.
See the discussion in #15368.

- [x] Turn `check_futures_test` into a sanity check #15671
- [x] De-Bazel `check_load_py_test` sanity check #15677
- [x] De-Bazel `pip_smoke_test` sanity check #15678
- [x] Rewrite `//tensorflow/contrib/makefile:build_all_linux`
- [x] Remove `all_opensource_files` bb582f1b6fad474bc446c78a6683247a8eb6048e"
15755,Tensorflow Dataset.from_generator blocks input?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: both win7 and CentOS 7.2.1511
- **TensorFlow installed from (source or binary)**: pip3
- **TensorFlow version (use command below)**: 'v1.4.0-rc1-11-g130a514 1.4.0' and '1.5.0-dev20180102'
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: NA

### Describe the problem

I submitted a problem on stackoverflow but nobody solved it. So I open it here. Does anybody can help to solve it?

Here is the problem:
[https://stackoverflow.com/questions/47917288/tensorflow-dataset-from-generator-blocks-input](https://stackoverflow.com/questions/47917288/tensorflow-dataset-from-generator-blocks-input)

I installed tensorflow 1.4.0 via pip, without gpu support. My python version is 3.5.3
  "
15754,Protobuf Compilation /object_detection/protos/anchor_generator_pb2.py: Permission denied issue,"I need to implement object detection using Tensorflow but.
Im getting ,
**Protobuf Compilation /object_detection/protos/anchor_generator_pb2.py: Permission denied issue** when executing 
`protoc object_detection/protos/*.proto --python_out=.`  in Protobuf Compilation

this is the issue i already having.

![error](https://user-images.githubusercontent.com/34977438/34461460-ae4e5120-ee50-11e7-8d43-1ba5ecab2bc3.jpg)

Here is my link for Tensorflow model [https://github.com/tensorflow/models](url)
and i used **Protocol Buffers v3.4.0**
 So, can anyone knows how to solve and execute that command?﻿"
15753, ImportError: cannot import name 'checkpoint_ops',"keras version =2.0.8
tensorflow version =1.2.1
anconda and windows 10
install a binary 
python version is 3.5 64bit

> `from tensorflow.contrib.framework.python.ops.checkpoint_ops import *
  File ""C:\Users\hp\Anaconda3\lib\site-packages\tensorflow\contrib\framework\python\ops\checkpoint_ops.py"", line 22, in <module>
    from tensorflow.python.training import checkpoint_ops
ImportError: cannot import name 'checkpoint_ops'`
  
"
15752,Eager: Incompatible rnn model shapes inferred when using more than one CudnnGRU/LSTM,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.5.0dev20171230
- **Python version**: 3.6

### Describe the problem
When I use more than one CudnnGRU in eager, I got an error:
```Python
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-1-f618cd483215> in <module>()
     26 with tf.device(device):
     27     images = tf.constant(toy_data)
---> 28     logits = net(images)

~\Anaconda3\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    651 
    652         if not in_deferred_mode:
--> 653           outputs = self.call(inputs, *args, **kwargs)
    654           if outputs is None:
    655             raise ValueError('A layer\'s `call` method should return a Tensor '

<ipython-input-1-f618cd483215> in call(self, x)
     17         x = tf.transpose(x, [1, 0, 2])
     18         x, s = self.gru1(x)
---> 19         x, s = self.gru2(x)
     20         x = tf.transpose(x, [1, 0, 2])
     21         x = self.fc(x)

~\Anaconda3\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    651 
    652         if not in_deferred_mode:
--> 653           outputs = self.call(inputs, *args, **kwargs)
    654           if outputs is None:
    655             raise ValueError('A layer\'s `call` method should return a Tensor '

~\Anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\layers\cudnn_rnn.py in call(self, inputs, initial_state, training)
    400       c = array_ops.constant([], dtype=dtype)
    401     outputs, (output_h, output_c) = self._forward(inputs, h, c, self.kernel,
--> 402                                                   training)
    403     if self._rnn_mode == CUDNN_LSTM:
    404       return outputs, (output_h, output_c)

~\Anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\layers\cudnn_rnn.py in _forward(self, inputs, h, c, opaque_params, training)
    475         direction=self._direction,
    476         dropout=self._dropout,
--> 477         seed=self._seed)
    478     return output, (output_h, output_c)
    479 

~\Anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\python\ops\cudnn_rnn_ops.py in _cudnn_rnn(inputs, input_h, input_c, params, is_training, rnn_mode, input_mode, direction, dropout, seed, name)
    858       seed=seed,
    859       seed2=seed2,
--> 860       name=name)
    861   return (outputs, output_h, output_c)
    862 

~\Anaconda3\lib\site-packages\tensorflow\contrib\cudnn_rnn\ops\gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)
    120               ""seed2"", seed2, ""is_training"", is_training)
    121     _result = _execute.execute(b""CudnnRNN"", 4, inputs=_inputs_flat,
--> 122                                attrs=_attrs, ctx=_ctx, name=name)
    123   _execute.record_gradient(
    124       ""CudnnRNN"", _inputs_flat, _attrs, _result, name)

~\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     64     else:
     65       message = e.message
---> 66     six.raise_from(core._status_to_exception(e.code, message), None)
     67   # pylint: enable=protected-access
     68   return tensors

~\Anaconda3\lib\site-packages\six.py in raise_from(value, from_value)

InvalidArgumentError: Incompatible rnn model shapes inferred: expecting [num_layers, input_size, num_units, dir_count]: [1, 28, 100, 1], getting [num_layers, input_size, num_units, dir_count]: [1, 100, 100, 1]. [Op:CudnnRNN]
```
If I use same network in graph mode, there is no problem.
reproduce error code:
```Python
import tensorflow as tf
import tensorflow.contrib.eager as tfe
import numpy as np
config = tf.ConfigProto()
config.gpu_options.allow_growth=True
tfe.enable_eager_execution(config=config)
class CudnnCrashNet(tfe.Network):
    def __init__(self, name):
        super(CudnnCrashNet, self).__init__(name)
        self.gru1 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)
        self.track_layer(self.gru1)
        self.gru2 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)
        self.track_layer(self.gru2)
        self.fc = self.track_layer(tf.layers.Dense(10))
    def call(self, x):
        x = tf.reshape(x, [-1, 28, 28])
        x = tf.transpose(x, [1, 0, 2])
        x, s = self.gru1(x)
        x, s = self.gru2(x)
        x = tf.transpose(x, [1, 0, 2])
        x = self.fc(x)
        return x
toy_data = np.ones((100, 784)).astype(np.float32)
device = ""gpu:0"" if tfe.num_gpus() else ""cpu:0""
net = CudnnCrashNet('net')
with tf.device(device):
    images = tf.constant(toy_data)
    logits = net(images)
```
normal graph-mode code:
```Python
import tensorflow as tf
import numpy as np
class CudnnNormalNet(tf.layers.Layer):
    def __init__(self, name):
        super(CudnnNormalNet, self).__init__(name)
        self.gru1 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)
        self.gru2 = tf.contrib.cudnn_rnn.CudnnGRU(1, 100)
        self.fc = tf.layers.Dense(10)
    def call(self, x):
        x = tf.reshape(x, [-1, 28, 28])
        x = tf.transpose(x, [1, 0, 2])
        x, s = self.gru1(x)
        x, s = self.gru2(x)
        x = tf.transpose(x, [1, 0, 2])
        x = self.fc(x)
        return x
config = tf.ConfigProto()
config.gpu_options.allow_growth=True
toy_data = np.ones((100, 784)).astype(np.float32)
with tf.Graph().as_default():
    net = CudnnNormalNet('net')
    x_p = tf.placeholder(tf.float32, [None, 784])
    logits = net(x_p)
    with tf.Session(config=config) as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(logits, feed_dict={x_p: toy_data})
```"
15751,Uninitialised Classifier or invalid context,"I was able to run the tensorflowlite demo app with no error. But it is not detecting the objects as it is supposed to. I have followed the instructions to be followed  in android studio in readme.
![Uploading Screenshot_20171231-151052.png…]()
"
15747,An easy problem about tensorflow GPU unilization,"Today , I run an easy RNN model to deal with a  NLP task, which the traindata is just about 4000 short sentences and the iteration is 30. However, the time cost about 1 hour to finish the procedure. my computer GPU is nvidia 1080Ti and CPU is i7 8700K. 

In the console, the information is: 
Total memory: 10.91GiB
Free memory: 10.30GiB

but in the terminal, i use the command： nvidia-smi -l
it return another information:
10713MiB / 11171MiB 

my question are : 1. Does the GPU really work ??? 
                             2. if work, why the time cost still large???

Thx！"
15746,CIFAR10 slows down every 100th step,"### System information
- **Have I written custom code**: No
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: Have tried both binary and source
- **TensorFlow version**: 1.4.0-19-ga52c8d9, 1.4.1
- **Python version**: 2.7.12
- **CUDA/cuDNN version**: 8.0.61
- **Hardware**: GPU: NVIDIA GeForce GTX 1080 Ti (11GB), RAM: 64GB, CPU: Intel i7-6850K
- **Exact command to reproduce**: python cifar10_train.py

### Describe the problem
The [CIFAR10 Tensorflow tutorial](https://www.tensorflow.org/tutorials/deep_cnn) seems to have a few odd patterns when it comes to the number of examples per second it can compute:
 - Step 0 is extremely slow 
 - Every 100th step is significantly slow 
 - The step after a really slow step is either a little slow or average
 - The next 10-30 steps after that are slightly boosted (faster than average)
 - The rest of the steps are average speed

I'm hoping for (in order of importance):
 - An explanation and fix for every 100th step being so slow
 - An explanation and instructions showing me how to make every step run at the boosted speed (the speed shortly after a slow step)
 - An explanation and fix for the slow 0th and 1st step

I can't find any additional logging or processing that happens on every 100th step. Could it be `tf.train.MonitoredSession`?

### Reproducible:
- when training on CPU rather than GPU
- independent of batch size
- on MacBook Pro (Retina, 13-inch, Mid 2014)

### Hardware utilization: 
1. Average:
- CPU: 82-84%
- GPU: 70-85%
- RAM: 3.7GB

2. Every 100th step:
- CPU: 9%
- GPU: 0%
- RAM: 3.7GB

3. Boosted after slow step: 
- GPU: 92%
- CPU: 82-84%
- RAM: 3.7GB

4. Idle:
- CPU: 1%
- GPU: 0%
- RAM: 1.6GB

*Overall CPU and RAM usage (clearly showing CPU trough every 100 steps)*:
![Overall CPU and RAM usage](https://user-images.githubusercontent.com/7654904/34998310-6b153646-fae7-11e7-8e0c-00ccf01349bf.png)

### Logs excerpt [(full logs)](https://github.com/tensorflow/tensorflow/files/1635342/terminalOutput.txt):

> step 0: (587.3 examples/sec; 6.974 sec/batch)
> step 1: (22630.6 examples/sec; 0.181 sec/batch)
> step 2: (36253.6 examples/sec; 0.113 sec/batch)
> step 3: (37966.0 examples/sec; 0.108 sec/batch)
> step 4: (38511.4 examples/sec; 0.106 sec/batch)
> step 5: (38554.6 examples/sec; 0.106 sec/batch)
> step 6: (32112.4 examples/sec; 0.128 sec/batch)
> step 7: (38912.4 examples/sec; 0.105 sec/batch)
> step 8: (39377.0 examples/sec; 0.104 sec/batch)
> step 9: (38206.2 examples/sec; 0.107 sec/batch)
> step 10: (38222.1 examples/sec; 0.107 sec/batch)
> step 11: (38757.5 examples/sec; 0.106 sec/batch)
> step 12: (38833.1 examples/sec; 0.105 sec/batch)
> step 13: (39774.8 examples/sec; 0.103 sec/batch)
> step 14: (39795.9 examples/sec; 0.103 sec/batch)
> step 15: (37850.5 examples/sec; 0.108 sec/batch)
> step 16: (38443.5 examples/sec; 0.107 sec/batch)
> step 17: (39194.6 examples/sec; 0.105 sec/batch)
> step 18: (39164.0 examples/sec; 0.105 sec/batch)
> step 19: (39057.5 examples/sec; 0.105 sec/batch)
> step 20: (33268.7 examples/sec; 0.123 sec/batch)
> step 21: (39459.7 examples/sec; 0.104 sec/batch)
> step 22: (39336.2 examples/sec; 0.104 sec/batch)
> step 23: (39207.1 examples/sec; 0.104 sec/batch)
> step 24: (39330.5 examples/sec; 0.104 sec/batch)
> step 25: (38783.9 examples/sec; 0.106 sec/batch)
> step 26: (39038.9 examples/sec; 0.105 sec/batch)
> step 27: (39214.2 examples/sec; 0.104 sec/batch)
> step 28: (39525.9 examples/sec; 0.104 sec/batch)
> step 29: (37209.0 examples/sec; 0.110 sec/batch)
> step 30: (38356.7 examples/sec; 0.107 sec/batch)
> step 31: (36077.0 examples/sec; 0.114 sec/batch)
> step 32: (37143.8 examples/sec; 0.110 sec/batch)
> step 33: (35961.1 examples/sec; 0.114 sec/batch)
> step 34: (33378.4 examples/sec; 0.123 sec/batch)
> step 35: (37830.3 examples/sec; 0.108 sec/batch)
> step 36: (36789.5 examples/sec; 0.111 sec/batch)
> step 37: (36638.2 examples/sec; 0.112 sec/batch)
> step 38: (36848.1 examples/sec; 0.111 sec/batch)
> step 39: (36041.4 examples/sec; 0.114 sec/batch)
> step 40: (36612.0 examples/sec; 0.112 sec/batch)
> step 41: (35623.9 examples/sec; 0.115 sec/batch)
> step 42: (37589.3 examples/sec; 0.109 sec/batch)
> step 43: (37462.9 examples/sec; 0.109 sec/batch)
> step 44: (35823.6 examples/sec; 0.114 sec/batch)
> step 45: (35911.8 examples/sec; 0.114 sec/batch)
> step 46: (36073.8 examples/sec; 0.114 sec/batch)
> step 47: (36930.2 examples/sec; 0.111 sec/batch)
> step 48: (36142.9 examples/sec; 0.113 sec/batch)
> ...
> step 99: (36434.8 examples/sec; 0.112 sec/batch)
> step 100: (1215.0 examples/sec; 3.371 sec/batch)
> step 101: (35952.9 examples/sec; 0.114 sec/batch)
> step 102: (38422.5 examples/sec; 0.107 sec/batch)
> step 103: (39315.8 examples/sec; 0.104 sec/batch)
> step 104: (38989.1 examples/sec; 0.105 sec/batch)
> step 105: (39091.4 examples/sec; 0.105 sec/batch)
> step 106: (39247.6 examples/sec; 0.104 sec/batch)
> step 107: (38009.7 examples/sec; 0.108 sec/batch)
> step 108: (38746.7 examples/sec; 0.106 sec/batch)
> step 109: (39505.4 examples/sec; 0.104 sec/batch)
> step 110: (39340.0 examples/sec; 0.104 sec/batch)
> step 111: (39065.0 examples/sec; 0.105 sec/batch)
> step 112: (38561.1 examples/sec; 0.106 sec/batch)
> step 113: (39109.0 examples/sec; 0.105 sec/batch)
> step 114: (39203.7 examples/sec; 0.104 sec/batch)
> step 115: (39144.4 examples/sec; 0.105 sec/batch)
> step 116: (38317.6 examples/sec; 0.107 sec/batch)
> step 117: (33757.5 examples/sec; 0.121 sec/batch)
> step 118: (34115.4 examples/sec; 0.120 sec/batch)
> step 119: (35671.4 examples/sec; 0.115 sec/batch)
> step 120: (35297.2 examples/sec; 0.116 sec/batch)
> step 121: (36152.8 examples/sec; 0.113 sec/batch)
> step 122: (35780.1 examples/sec; 0.114 sec/batch)
> step 123: (35847.1 examples/sec; 0.114 sec/batch)
> step 124: (36888.9 examples/sec; 0.111 sec/batch)
> step 125: (36946.2 examples/sec; 0.111 sec/batch)
> ..."
15745,Eager: variable created in @tfe.defun is invalid and raise error when print,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.5.0dev20171230
- **Python version**: 3.6

### Describe the problem
I want to use defun to speed up static rnn compute in eager:
```Python
def _eager_dynamic_rnn(cell,
                       inputs,
                       sequence_length=None,
                       initial_state=None,
                       dtype=tf.float32,
                       parallel_iterations=None,
                       swap_memory=False,
                       time_major=False,
                       scope=None):
    time_axis = 0 if time_major else 1
    input_shape = inputs.shape.as_list()
    seq_len = input_shape[time_axis]
    if time_major:
        batch_size = input_shape[1]
    else:
        batch_size = input_shape[0]
    if initial_state is None:
        initial_state = cell.zero_state(batch_size, dtype)
    inputs = tf.unstack(inputs, num=seq_len, axis=time_axis)
    outputs = []
    for inp in inputs:
        output, initial_state = cell(inp, initial_state)
        outputs.append(output)
    outputs = tf.stack(outputs, axis=time_axis)
    return outputs, initial_state


@tfe.defun
def _eager_compiled_dynamic_rnn(cell,
                                inputs,
                                sequence_length=None,
                                initial_state=None,
                                dtype=tf.float32,
                                parallel_iterations=None,
                                swap_memory=False,
                                time_major=False,
                                scope=None):
    return _eager_dynamic_rnn(cell, inputs, sequence_length, initial_state,
                              dtype, None, False, time_major, scope)
```
If I directly use `_eager_compiled_dynamic_rnn` in forward, because of `tf.layers.Layer` create variables in its first __call__, then variables created in `_eager_compiled_dynamic_rnn` is invalid, if print it, get a error:
```Python
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-308544234cc4> in <module>()
      1 for var in net.variables:
----> 2     print(var)

~\Anaconda3\lib\site-packages\tensorflow\python\ops\variables.py in __repr__(self)
    233       return ""<tf.Variable '%s' shape=%s dtype=%s, numpy=%s>"" % (
    234           self.name, self.get_shape(), self.dtype.name,
--> 235           ops.numpy_text(self.read_value(), is_repr=True))
    236     else:
    237       return ""<tf.Variable '%s' shape=%s dtype=%s>"" % (

~\Anaconda3\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py in read_value(self)
    679       # Ensure we read the variable in the same device as the handle.
    680       with ops.device(self._handle_device):
--> 681         value = self._read_variable_op()
    682     # Return an identity so it can get placed on whatever device the context
    683     # specifies instead of the device where the variable is.

~\Anaconda3\lib\site-packages\tensorflow\python\ops\resource_variable_ops.py in _read_variable_op(self)
    657       tape.watch_variable(self)
    658     return gen_resource_variable_ops.read_variable_op(self._handle,
--> 659                                                       self._dtype)
    660 
    661   def read_value(self):

~\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_resource_variable_ops.py in read_variable_op(resource, dtype, name)
    209     _attrs = (""dtype"", dtype)
    210     _result = _execute.execute(b""ReadVariableOp"", 1, inputs=_inputs_flat,
--> 211                                attrs=_attrs, ctx=_ctx, name=name)
    212   _execute.record_gradient(
    213       ""ReadVariableOp"", _inputs_flat, _attrs, _result, name)

~\Anaconda3\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,
     59                                                op_name, inputs, attrs,
---> 60                                                num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

TypeError: provided list of inputs contains objects other than 'EagerTensor'
```
To solve this problem, I must call function which isn't decorated by tfe.defun in first forward, then switch to `_eager_compiled_dynamic_rnn`:
```Python
if self._cell.built is True:
    func = _eager_compiled_dynamic_rnn
else:
    func = _eager_dynamic_rnn
outputs, state = func(
    self._cell,
    inputs,
    seq_len,
    state,
    dtype=self._rnn_dtype,
    time_major=self._time_major, )
```
locate this error cost me much time. please consider to fix it."
15744,Summary op crashes when run multiple times,"### System information
- **Windows 10 16299**:
- **pip install tensorflow-gpu**:
- **b'unknown' 1.4.0**:
- **3.5**: 
- **CUDA: V9.1.85, cuDNN version: 6**:
- **Geforce 930 MX, 2GB**:

### Describe the problem
Opening a session for the second time and trying to run a summary op causes crash for some reason. The error message is misleading as a placeholder is provided.

### Source code / logs
```
import tensorflow as tf

class MyModel:
    def __init__(self, sess, i):
        self.x = tf.placeholder(tf.float32, [2, 2])
        self.W = tf.Variable(tf.truncated_normal([2, 2]))
        self.y = tf.matmul(self.W, self.x)

        tf.summary.scalar('y',tf.reduce_sum(self.y))

        sess.run(tf.global_variables_initializer())

        self.summary = tf.summary.merge_all()
        self.writer = tf.summary.FileWriter('./logs/test' + str(i),sess.graph)

    def run(self, sess):        
        feed_dict = {self.x:[[0,0],[0,0]]}
        sess.run(self.y,feed_dict)
        print('inside1')
        s = sess.run(self.summary,feed_dict)
        print('inside2')
        self.writer.add_summary(s,0)

    def close(self):
        self.writer.close()        

# Swapping order of line 1 and 2 still causes crash
for i in range(3): # line 1
    with tf.Session() as sess: # line 2
        print('outside')
        M = MyModel(sess, i)
        M.run(sess)
        M.close()
    #sess.close() # No luck
```

OUTPUT:
```
outside
inside1
inside2
outside
inside1

Traceback (most recent call last):
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1323, in _do_call
    return fn(*args)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [2,2]
	 [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[2,2], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Sum_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_7_Sum_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:\TensorFlow\tensorflow-experiments\ravens-matrix-autoencoder\minimum.py"", line 31, in <module>
    M.run(sess)
  File ""D:\TensorFlow\tensorflow-experiments\ravens-matrix-autoencoder\minimum.py"", line 20, in run
    s = sess.run(self.summary,feed_dict)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [2,2]
	 [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[2,2], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Sum_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_7_Sum_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]

Caused by op 'Placeholder', defined at:
  File ""<string>"", line 1, in <module>
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\idlelib\run.py"", line 124, in main
    ret = method(*args, **kwargs)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\idlelib\run.py"", line 351, in runcode
    exec(code, self.locals)
  File ""D:\TensorFlow\tensorflow-experiments\ravens-matrix-autoencoder\minimum.py"", line 30, in <module>
    M = MyModel(sess, i)
  File ""D:\TensorFlow\tensorflow-experiments\ravens-matrix-autoencoder\minimum.py"", line 5, in __init__
    self.x = tf.placeholder(tf.float32, [2, 2])
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1599, in placeholder
    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 3090, in _placeholder
    ""Placeholder"", dtype=dtype, shape=shape, name=name)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\windows\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [2,2]
	 [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[2,2], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Sum_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_7_Sum_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
```
"
15741,Python tensorflow module cannot be reloaded (bug),"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:  no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  confirmed on both Ubuntu 16.04 LTS in VirtualBox and OS X 10.12.6
- **TensorFlow installed from (source or binary)**:  installed via pip
- **TensorFlow version (use command below)**:  ('v1.4.0-19-ga52c8d9b01', '1.4.1')
- **Python version**: Python 2.7.13
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

> import tensorflow as tf
> reload(tf)

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Simple bug:

Trying to reload the module causes a failure.  Not a major problem, in general, but troublesome for the task, which is automated testing of the tensorflow Python API using TSTL (https://github.com/agroce/tstl).

The exact sequence is trivial:

>>> import tensorflow as tf
>>> reload(tf)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/__init__.py"", line 40, in <module>
    del python
NameError: name 'python' is not defined

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15738,"wrong output(extra symbol ""b"")","**System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows  Home
TensorFlow installed from (source or binary): binary (pip)
TensorFlow version (use command below): 1.4.0 (GPU)
Python version: 3.6**
GPU: GTX1050 Ti M (disabled Intel visualization)

Basically any output I try to write in console is with extra symbol : ""b""
for example:
with cmmand:
```
C: python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
b'unknown' 1.4.0 //OUTPUT
```
I downloaded GPU verison form guide from official webiste(with:Anaconda):
[https://www.tensorflow.org/install/install_windows#installing_with_anaconda](url)

i have tried the validation example and same problem (extra symbol : ""b"")
"
15737,"AttentionWrapper zero_state(batch_size, tf.float32).clone(cell_state=encoder_state) fails when batch size is 1","Hello!
I believe to have found a small bug when using the `zero_state(batch_size, tf.float32).clone(cell_state=encoder_state)` command. When batch size is 1, the error `ValueError: The shape for decoder/while/Merge_5:0 is not an invariant for the loop. It enters the loop with shape (1, 512), but has shape (?, 512) after one iteration. Provide shape invariants using either the shape_invariants argument of tf.while_loop or set_shape() on the loop variables.` is thrown. This error does not occur when batch size is 2 or larger. The error also doesn't occur if I remove the .clone command. 
I tried investigating where the error is, but couldn't find the cause. I'm using this in context of trying to build a neural transducer, but also get the same error for basic seq2seq:
(Based on the NMT tutorial)

```python
# .... Encoder, constants etc...
# Decoder
helper = tf.contrib.seq2seq.TrainingHelper(
    decoder_inputs_embedded, decoder_full_length, time_major=True) 

attention_states = tf.transpose(encoder_outputs, [1, 0, 2])  # attention_states: [batch_size, max_time, num_units]
attention_mechanism = tf.contrib.seq2seq.LuongAttention(
    encoder_hidden_units, attention_states,
    memory_sequence_length=encoder_inputs_length)
decoder_cell = tf.contrib.seq2seq.AttentionWrapper(
    tf.contrib.rnn.LSTMCell(decoder_hidden_units),
    attention_mechanism,
    attention_layer_size=decoder_hidden_units)

projection_layer = layers_core.Dense(
    vocab_size, use_bias=False)


decoder = tf.contrib.seq2seq.BasicDecoder(
    decoder_cell, helper, decoder_cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state),
    output_layer=projection_layer)

# ---- Training ----
outputs, last_state, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True)
logits = outputs.rnn_output
decoder_prediction = outputs.sample_id
```


TF Version: ('v1.4.0-19-ga52c8d9', '1.4.1')
System details:
```
== cat /etc/issue ===============================================
Linux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""17.10 (Artful Aardvark)""
VERSION_ID=""17.10""
VERSION_CODENAME=artful

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 7.2.0-8ubuntu3) 7.2.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux nikita-coolboi 4.13.0-21-generic #24-Ubuntu SMP Mon Dec 18 17:29:16 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.5.1)
tensorflow (1.4.1)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.1
tf.GIT_VERSION = v1.4.0-19-ga52c8d9
tf.COMPILER_VERSION = v1.4.0-19-ga52c8d9
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
```
I believe this is an important issue, as often times when experimenting with new seq2seq models I start off with trying to get it to work for a batch size of 1.

Thanks!
Nikita"
15736,Importing submodules from tensorflow.keras fails with No module named 'tensorflow.keras',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: 3.6
- **Exact command to reproduce**:
from tensorflow.keras import datasets # fails but should work
import tensorflow as tf #succeeds
tf.keras.datasets #succeeds
from tensorflow.python.keras import datasetst # succeeds

### Describe the problem
Importing submodules from tensorflow.keras fails with error: `ModuleNotFoundError: No module named 'tensorflow.keras'`. but `import tensorflow as tf` and then doing `tf.keras.datasets` works. This is a big inconsistency, also it means that every time an element from within the `tensforlow.keras` module you need to write the complete path (which is very annoying) this removes the simplicity and readability of the `keras` API. A work around is to import submodules from `tensorflow.python.keras`, which again is inconsistent. 

In my opinion, since the documentation states that `keras` is availabe at `tf.keras` that should be the access path to the submodules and not `tensorflow.python.keras`. I'll try to  make a pull request for this.

### Source code / logs

```python
# fails but should work
from tensorflow.keras import datasets
```
```python
# succeeds
import tensorflow as tf
tf.keras.datasets
```
```python
# succeeds
from tensorflow.python.keras import datasetst
```"
15735,Segmentation fault when using cuDNN LSTMs + orthogonal initializer,"On TF 1.4.0 with CUDA 8.0 and cuDNN 7, I get a segmentation fault if I use an orthogonal initializer for the `kernel_initializer` argument of `cudnn_rnn.CudnnLSTM` (the layers version not the op). I'm aware of #14306 but since I'm running into this problem with the cuDNN LSTMs and not the native TF ones I suspect the underlying cause is different."
15733,"""Failed to load the native TensorFlow runtime."" error on Raspbian stretch","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Raspbian Strecth
- **TensorFlow installed from (source or binary)**: Source (Compiled from git on raspberry pi 3)
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: gcc version 4.8.5 (Raspbian 4.8.5-4) 
- **CUDA/cuDNN version**: No (nonconfigured)
- **GPU model and memory**:No (nonconfigured)
- **Exact command to reproduce**: python3 "">>> import tensorflow""
Hi,
I have compiled tensorflow's 1.4.1 source code from git source. There was no error while compiling from source but after installition by pip3, I can't import tensorflow library in python3
When I gave ""import tensorflow"" command in the python 3 shell it gives this error:

 "">>> import tensorflow
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws11Environment6GetEnvEPKc

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN3Aws11Environment6GetEnvEPKc


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems""

"
15732,Missing OpKernel when using selective registration header,"I use the `bazel-bin/tensorflow/python/tools/print_selective_registration_header` to find out all necessary ops and kernels for my `test.pb`, and then compile them into a android executable

`bazel build test/test:test_run --copt=-DSELECTIVE_REGISTRATION  --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a`

The `ops_to_register.h` is as follows

```
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER
constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || (strcmp(op, ""Add"") == 0)
     || (strcmp(op, ""AddN"") == 0)
     || (strcmp(op, ""ApplyGradientDescent"") == 0)
     || (strcmp(op, ""Assign"") == 0)
     || (strcmp(op, ""AssignAdd"") == 0)
     || (strcmp(op, ""BiasAdd"") == 0)
     || (strcmp(op, ""BiasAddGrad"") == 0)
     || (strcmp(op, ""BroadcastGradientArgs"") == 0)
     || (strcmp(op, ""ConcatOffset"") == 0)
     || (strcmp(op, ""ConcatV2"") == 0)
     || (strcmp(op, ""Const"") == 0)
     || (strcmp(op, ""ExpandDims"") == 0)
     || (strcmp(op, ""Fill"") == 0)
     || (strcmp(op, ""Floor"") == 0)
     || (strcmp(op, ""FloorMod"") == 0)
     || (strcmp(op, ""Gather"") == 0)
     || (strcmp(op, ""Identity"") == 0)
     || (strcmp(op, ""L2Loss"") == 0)
     || (strcmp(op, ""MatMul"") == 0)
     || (strcmp(op, ""Minimum"") == 0)
     || (strcmp(op, ""Mul"") == 0)
     || (strcmp(op, ""Neg"") == 0)
     || (strcmp(op, ""NoOp"") == 0)
     || (strcmp(op, ""Pack"") == 0)
     || (strcmp(op, ""Placeholder"") == 0)
     || (strcmp(op, ""PlaceholderWithDefault"") == 0)
     || (strcmp(op, ""PreventGradient"") == 0)
     || (strcmp(op, ""RandomUniform"") == 0)
     || (strcmp(op, ""RealDiv"") == 0)
     || (strcmp(op, ""Reshape"") == 0)
     || (strcmp(op, ""ScatterSub"") == 0)
     || (strcmp(op, ""Shape"") == 0)
     || (strcmp(op, ""Sigmoid"") == 0)
     || (strcmp(op, ""SigmoidGrad"") == 0)
     || (strcmp(op, ""Size"") == 0)
     || (strcmp(op, ""Slice"") == 0)
     || (strcmp(op, ""Softmax"") == 0)
     || (strcmp(op, ""SparseSoftmaxCrossEntropyWithLogits"") == 0)
     || (strcmp(op, ""Split"") == 0)
     || (strcmp(op, ""SplitV"") == 0)
     || (strcmp(op, ""Sqrt"") == 0)
     || (strcmp(op, ""Squeeze"") == 0)
     || (strcmp(op, ""StridedSlice"") == 0)
     || (strcmp(op, ""Sub"") == 0)
     || (strcmp(op, ""Sum"") == 0)
     || (strcmp(op, ""Tanh"") == 0)
     || (strcmp(op, ""TanhGrad"") == 0)
     || (strcmp(op, ""Tile"") == 0)
     || (strcmp(op, ""TopKV2"") == 0)
     || (strcmp(op, ""Unpack"") == 0)
     || (strcmp(op, ""VariableV2"") == 0)
     || (strcmp(op, ""ZerosLike"") == 0)
     || (strcmp(op, ""_Recv"") == 0)
     || (strcmp(op, ""_Send"") == 0)
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)


    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
""BinaryOp< CPUDevice, functor::add<float>>"",
""AddNOp< CPUDevice, float>"",
""ApplyGradientDescentOp<CPUDevice, float>"",
""AssignOpT<CPUDevice, ::tensorflow::int64>"",
""AssignOpT<CPUDevice, float>"",
""DenseUpdateOp<CPUDevice, ::tensorflow::int64, DenseUpdateType::ADD>"",
""BiasOp<CPUDevice, float>"",
""BiasGradOp<CPUDevice, float>"",
""BCastGradArgsOp"",
""ConcatOffsetOp"",
""ConcatV2Op<CPUDevice, ::tensorflow::int32>"",
""ConcatV2Op<CPUDevice, float>"",
""ConstantOp"",
""ExpandDimsOp"",
""FillOp<CPUDevice, float>"",
""UnaryOp< CPUDevice, functor::floor<float>>"",
""BinaryOp< CPUDevice, functor::safe_floor_mod<int32>>"",
""GatherOp<CPUDevice, float, int32>"",
""IdentityOp"",
""L2LossOp<CPUDevice, float>"",
""MatMulOp<CPUDevice, float, false >"",
""BinaryOp< CPUDevice, functor::minimum<float>>"",
""BinaryOp< CPUDevice, functor::mul<float>>"",
""UnaryOp< CPUDevice, functor::neg<float>>"",
""NoOp"",
""PackOp<CPUDevice, ::tensorflow::int32>"",
""PackOp<CPUDevice, float>"",
""PlaceholderOp"",
""IdentityOp"",
""IdentityOp"",
""PhiloxRandomOp<CPUDevice, random::UniformDistribution< random::PhiloxRandom, float> >"",
""BinaryOp< CPUDevice, functor::div<float>>"",
""ReshapeOp"",
""ScatterUpdateOp< CPUDevice, float, int32, scatter_op::UpdateOp::SUB>"",
""ShapeOp<int32>"",
""UnaryOp< CPUDevice, functor::sigmoid<float>>"",
""SimpleBinaryOp< CPUDevice, functor::sigmoid_grad<float>>"",
""SizeOp<int32>"",
""SliceOp<CPUDevice, ::tensorflow::int32>"",
""SliceOp<CPUDevice, float>"",
""SoftmaxOp<CPUDevice, float>"",
""SparseSoftmaxXentWithLogitsOp<CPUDevice, float, int32>"",
""SplitOpCPU<float>"",
""SplitVOpCPU<float, int32>"",
""UnaryOp< CPUDevice, functor::sqrt<float>>"",
""SqueezeOp"",
""StridedSliceOp<CPUDevice, ::tensorflow::int32>"",
""StridedSliceOp<CPUDevice, float>"",
""BinaryOp< CPUDevice, functor::sub<float>>"",
""ReductionOp<CPUDevice, float, Eigen::internal::SumReducer<float>>"",
""UnaryOp< CPUDevice, functor::tanh<float>>"",
""SimpleBinaryOp< CPUDevice, functor::tanh_grad<float>>"",
""TileOp<CPUDevice>"",
""TopK<float>"",
""UnpackOp<CPUDevice, float>"",
""VariableOp"",
""ZerosLikeOp< CPUDevice, float>"",
""RecvOp"",
""SendOp"",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

#define SHOULD_REGISTER_OP_GRADIENT false
#endif
```

However, when I try to run the executable on my Android device, it says some kernels are missed.

```
Error creating graph: Invalid argument: No OpKernel was registered to support Op 'Placeholder' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: OnlineTraining/Model/Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[2000,400]]()]]
```

How can I generate a complete file for this? If necessary I can also upload the `test.pb` file for testing."
15731,Error while building from source on Ubuntu ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  3.6.3
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0 20160609
- **CUDA/cuDNN version**: 9.1
- **GPU model and memory**: GTX 950 , 2GB
- **Exact command to reproduce**:  `bazel build --config=opt --config=cuda --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package`


### Describe the problem
The following error occurring while building tensorflow from source. I'm not able to understand what the error is.

### Source code / logs
```
ERROR: /home/rakshith/Downloads/Tensorflow/tensorflow/tensorflow/contrib/boosted_trees/BUILD:419:1: Linking of rule '//tensorflow/contrib/boosted_trees:gen_gen_training_ops_py_py_wrappers_cc' failed (Exit 1)
/usr/bin/ld: warning: libcublas.so.9.1, needed by bazel-out/host/bin/_solib_local/_U_S_Stensorflow_Scontrib_Sboosted_Utrees_Cgen_Ugen_Utraining_Uops_Upy_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
```
"
15730,Tensorflow Python3,"i recently installed tensorflow in my linux machine with pip.

when i try to import tensorflow it show me this 
```
Python 3.6.4 (default, Dec 19 2017, 14:09:48) 
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
```

i installed tensorflow cpu version with this command `pip install tensorflow`

this warning don't affect the script but its annoying

can anyone explain to me what is this
**OS: Linux ubuntu**
**Python Version: 3.6.4**"
15729,Feature Request: 'msg' parameter for test cases.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Not relevant
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: Master rev. 3629fc4e98254c37e614ac3f77fa250b75c70f8d
- **Python version**: 2/3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  Not relevant
- **GPU model and memory**: Not relevant
- **Exact command to reproduce**: Not relevant

### Describe the problem
Python's unittest module as well as numpy's testing tools allow to optionally pass a message to various assertion functions. I'd love to have this for all functions in tf.TestCase as well (quite a few already have this paramter). It allows for more descriptive error messages where many permutations of ops/dtype/cpu/gpu configurations are tested (e.g. [here](https://github.com/tensorflow/tensorflow/blob/3629fc4e98254c37e614ac3f77fa250b75c70f8d/tensorflow/python/kernel_tests/segment_reduction_ops_test.py#L109))

As many of the underlying testing functions already have a msg parameter this could easily be implemented, e.g.
```
  def assertAllClose(self, a, b, rtol=1e-6, atol=1e-6, msg=None):
    ...
      self.assertItemsEqual(
          a.keys(), b.keys(),
          msg=""mismatched keys, expected %s, got %s\n%s"" % (a.keys(), b.keys(), msg if msg else """"))
      for k in a:
        self._assertArrayLikeAllClose(
            a[k], b[k], rtol=rtol, atol=atol,
            msg=""%s: expected %s, got %s.\n%s"" % (k, a, b, msg if msg else """"))
    else:
      self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol, msg=msg)
```

Relevant functions:
- `assertAllClose`
- `assertAllCloseAccordingToType`
- `assertAllEqual`
- `assertAlmostEqual`
- `assertAlmostEquals`
- `assertArrayNear`
- `assertDeviceEqual`
- `assertNDArrayNear`
- `assertProtoEquals`
- `assertProtoEqualsVersion`
- (`assertRaises...`) adding a msg parameter to these test functions would probably break lot's of test cases, so I'd omit it
- `assertShapeEqual`
- `checkedThread`


If you agree, I'll submit a quick pull request.
"
15727,using tf.layers.batch_normalization() gives erratic validation loss though implementation seems correct.,"I am trying to use Batch Normalization using [tf.layers.batch_normalization()][1] and I have followed the documentation closely. My code looks like this:

<!-- language: python -->

    def create_conv_exp_model(fingerprint_input, model_settings, is_training):
      

      # Dropout placeholder
      if is_training:
        dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')

      # Mode placeholder
      mode_placeholder = tf.placeholder(tf.bool, name=""mode_placeholder"")

      he_init = tf.contrib.layers.variance_scaling_initializer(mode=""FAN_AVG"")

      # Input Layer
      input_frequency_size = model_settings['bins']
      input_time_size = model_settings['spectrogram_length']
      net = tf.reshape(fingerprint_input,
                       [-1, input_time_size, input_frequency_size, 1],
                       name=""reshape"")
      net = tf.layers.batch_normalization(net, 
                                          training=mode_placeholder,
                                          name='bn_0')

      for i in range(1, 6):
        net = tf.layers.conv2d(inputs=net,
                               filters=8*(2**i),
                               kernel_size=[5, 5],
                               padding='same',
                               kernel_initializer=he_init,
                               name=""conv_%d""%i)
        net = tf.layers.batch_normalization(net,
                                            training=mode_placeholder,
                                            name='bn_%d'%i)
        with tf.name_scope(""relu_%d""%i):
          net = tf.nn.relu(net)
        net = tf.layers.max_pooling2d(net, [2, 2], [2, 2], 'SAME', 
                                      name=""maxpool_%d""%i)

      net_shape = net.get_shape().as_list()
      net_height = net_shape[1]
      net_width = net_shape[2]
      net = tf.layers.conv2d( inputs=net,
                              filters=1024,
                              kernel_size=[net_height, net_width],
                              strides=(net_height, net_width),
                              padding='same',
                              kernel_initializer=he_init,
                              name=""conv_f"")
      net = tf.layers.batch_normalization( net, 
                                            training=mode_placeholder,
                                            name='bn_f')
      with tf.name_scope(""relu_f""):
        net = tf.nn.relu(net)

      net = tf.layers.conv2d( inputs=net,
                              filters=model_settings['label_count'],
                              kernel_size=[1, 1],
                              padding='same',
                              kernel_initializer=he_init,
                              name=""conv_l"")

      ### Squeeze
      squeezed = tf.squeeze(net, axis=[1, 2], name=""squeezed"")

      if is_training:
        return squeezed, dropout_prob, mode_placeholder
      else:
        return squeezed, mode_placeholder

And my train step looks like this:

<!-- language: python -->

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
      optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_input)
      gvs = optimizer.compute_gradients(cross_entropy_mean)
      capped_gvs = [(tf.clip_by_value(grad, -2., 2.), var) for grad, var in gvs]
      train_step = optimizer.apply_gradients(gvs))

During training, I am feeding the graph with:

<!-- language: python -->

    train_summary, train_accuracy, cross_entropy_value, _, _ = sess.run(
        [
            merged_summaries, evaluation_step, cross_entropy_mean, train_step,
            increment_global_step
        ],
        feed_dict={
            fingerprint_input: train_fingerprints,
            ground_truth_input: train_ground_truth,
            learning_rate_input: learning_rate_value,
            dropout_prob: 0.5,
            mode_placeholder: True
        })

During validation, 

<!-- language: python -->

    validation_summary, validation_accuracy, conf_matrix = sess.run(
                    [merged_summaries, evaluation_step, confusion_matrix],
                    feed_dict={
                        fingerprint_input: validation_fingerprints,
                        ground_truth_input: validation_ground_truth,
                        dropout_prob: 1.0,
                        mode_placeholder: False
                    })

My loss and accuracy curves (orange is training, blue is validation):
[Plot of loss vs number of iterations][2],
[Plot of accuracy vs number of iterations][3]

The validation loss (and accuracy) seem very erratic. Is my implementation of Batch Normalization wrong? Or is this normal with Batch Normalization and I should wait for more iterations? Or maybe, moving statistics are not being saved and hence poor performance. I tried StackOverflow and found many people have the same problem and there is no definitive guide on how to resolve this.

  [1]: https://www.tensorflow.org/api_docs/python/tf/layers/batch_normalization
  [2]: https://i.stack.imgur.com/ZAqDw.png
  [3]: https://i.stack.imgur.com/CYKJX.png"
15725,Source Built r1.4 on GPUs with CPU optimized is always slower than 'no cpu optimization',"### System information
- **Have I written custom code**: Yes, the model named PSIque [arXiv:1711.10644](https://arxiv.org/abs/1711.10644)
- **OS Platform and Distribution**: CentOS 7.1/CentOS 7.3
- **TensorFlow installed from**: source build w/ Bazel
- **TensorFlow version**: 1.4
- **Python version**: Anaconda 3.6.2
- **Bazel version**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: gcc version 4.8.3 20140911 (Red Hat4.8.3-9) (GCC)
- **CUDA/cuDNN version**: CUDA 8.0/r375.26/cuDNN 6.0.0 & CUDA 9.0/r384.81/cuDNN 7.0.5 
- **GPU model and memory**: E5-2660v3*2 Socket, K40m 12GB, P100-PCIE-16GB
- **Exact command to reproduce**: python model.py

### Describe the problem
* I built tensorflow from source for boosting operation performance.

* 6 different distributions were built;
  * CPU only & No CPU optimization (NO EXTRA flags)
  * CPU only & CPU optimization (--config=opt)
  * GPU support & CUDA 8/9 & No CPU optimization (--config=cuda)
  * GPU support & CUDA 8/9 & CPU optimization (--config=opt --config=cuda)

* Experiments were basically done by 5 phases; experiments on CPU only are still going on,
so please focus on GPU version results.

* Results are quite frustrating me, because 'most of CPU optimized versions' gave me slow results.
![results](https://user-images.githubusercontent.com/20734988/34451067-1d8c1cf0-ed5e-11e7-9a4f-3ff21a5c9aea.png)

* Test were made on multiple machine with random order.
  * P100: 2 nodes
  * K40m: 7 nodes
  * CPU only: 8 nodes

* I am curious why CPU optimized version is slow
  * on every experiment combinations
  * even different GPU environments
  * even Dual CPU socket (E5-2660v3)

* (Extra) I believe my current model does not require high throughputs

### tf_env_collect.sh
== cat /etc/issue ===============================================
Linux <hostname> 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux vis5 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = b'unknown'
tf.COMPILER_VERSION = b'unknown'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sat Dec 30 12:39:08 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |
| N/A   28C    P0    35W / 250W |      0MiB / 16276MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |
| N/A   35C    P0    38W / 250W |  15661MiB / 16276MiB |     19%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1     68169      C   python                                     15643MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176
/usr/local/cuda-9.0/lib64/libcudart_static.a
"
15724,How to register all kernels to Android lib,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.0.1
- **Python version**: 3.4
- **Bazel version (if compiling from source)**: 0.4

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I am trying to compile a Android lib which can load a MetaGraph into a session as [this link](https://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c/43639305#43639305) specifies. I first extracts a GraphDef from this MetaGraph and uses this GraphDef to generate `ops_to_register.h`. Then I compile the lib as 

`bazel build my_model/test:test_lib --copt=-DSELECTIVE_REGISTRATION  --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a`

However when I trying to run the test_lib, it complains some kernels are not registered. Then I brutally adds all kernels to be registered as

`#define SHOULD_REGISTER_OP_KERNEL(clz) true`

However, it still complains

```
Error creating graph: Invalid argument: No OpKernel was registered to support Op 'Const' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: save/RestoreV2_8/shape_and_slices = Const[_output_shapes=[[1]], dtype=DT_STRING, value=Tensor<type: string shape: [1] values: >]()]]
```

How can I solve this by adding this Const kernel or simply registering all kernels?"
15722,Image Adjustments API doesn't clearly specify input range,"### Describe the problem

There is a documentation issue with a possible corresponding tf.keras bug.
The [tf image adjustments guide](https://www.tensorflow.org/api_guides/python/image#Image_Adjustments) doesn't document the inputs. It appears they can be in a `[0, 1]` range or `[0, MAX]` based on comments in tf.slim where the relevant APIs are used. 

This may have led to preprocessing bugs in other utilities such as keras and tf.keras, which believe tf expects the range `[-1, 1]` see https://github.com/keras-team/keras/issues/8916, the following includes additional details from that issue:

It appears Keras' imagenet image preprocessing may be inconsistent with how it is done in tf, in particular keras sets values to `[-1, 1]` while in tf the expected range is `[0, 1]`.

- [slim/preprocessing/inception_preprocessing.py](https://github.com/tensorflow/models/blob/master/research/slim/preprocessing/inception_preprocessing.py#L284) 
    - notes `If dtype is tf.float32 then the range should be [0, 1]`
- [keras preprocess_input()](https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py#L72) 
    - notes `tf: will scale pixels between -1 and 1, sample-wise`.

Here is the key doc from Keras' `preprocess_input()`:

```python

def preprocess_input(x, data_format=None, mode='caffe'):
    """"""Preprocesses a tensor encoding a batch of images.
    # Arguments
        x: input Numpy or symoblic tensor, 3D or 4D.
        data_format: data format of the image tensor.
        mode: One of ""caffe"", ""tf"".
            - caffe: will convert the images from RGB to BGR,
                then will zero-center each color channel with
                respect to the ImageNet dataset,
                without scaling.
            - tf: will scale pixels between -1 and 1,
                sample-wise.
    # Returns
        Preprocessed tensor.
    """"""
```

Here are the key docs from the tf slim function `preprocess_for_train()` which specify a [0, 1] range:

```python
def preprocess_for_train(image, height, width, bbox,
                         fast_mode=True,
                         scope=None,
                         add_image_summaries=True):
  """"""Distort one image for training a network.
  Distorting images provides a useful technique for augmenting the data
  set during training in order to make the network invariant to aspects
  of the image that do not effect the label.
  Additionally it would create image_summaries to display the different
  transformations applied to the image.
  Args:
    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be
      [0, 1], otherwise it would converted to tf.float32 assuming that the range
      is [0, MAX], where MAX is largest positive representable number for
      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).
    height: integer
    width: integer
    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
      where each coordinate is [0, 1) and the coordinates are arranged
      as [ymin, xmin, ymax, xmax].
    fast_mode: Optional boolean, if True avoids slower transformations (i.e.
      bi-cubic resizing, random_hue or random_contrast).
    scope: Optional scope for name_scope.
    add_image_summaries: Enable image summaries.
  Returns:
    3-D float Tensor of distorted image used for training with range [-1, 1].
  """"""
```

side note: 

- https://github.com/tensorflow/models/issues/2217 seems relevant
- https://github.com/keras-team/keras/issues/8916 is the corresponding keras issue

### System information

Not relevant, this is a documentation + input value range issue.

### Source code / logs

relevant links + code included above"
15721,Is it possible to have labels for outputs( I found it on the documentation),"For example, currently if I want to run a graph with multiple output:
```
session.run([output1, output2], feed_dict = feed_dict)
```
which return a list of results. I would like to have a label for each result, so the code will look like:
```
session.run({label1: output1, label2: output2}, feed_dict = feed_dict)
```
which return a dictionary maps labels to results, so I can get specific result based on the output label."
15720,How to remove unwanted warning while using GPU with tensorflow,"### System information
- I am using tensorflow version :
- OS Platform and Distribution: Linux64-:
- TensorFlow installed from pip version 1.4.1
- Python 3.6.3 :: Anaconda custom (64-bit) 
- Cuda-8.0
- GPU model and memory: nVIDIA K20 (Kepler)

### Describe the problem
I am using Adam Optimizer with a normal sequential network created via keras using tensorflow as backend. 


I get the following logs repeatedly for fitting, and creating the network. I also applied batch-normalization for the Dense Layer

/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla K20Xm, pci bus id: 0000:84:00.0, compute capability: 3.5
Adam_2/decay: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0
IsVariableInitialized_14: (IsVariableInitialized): /job:localhost/replica:0/task:0/device:GPU:0
Adam_2/decay/read: (Identity): /job:localhost/replica:0/task:0/device:GPU:0
Adam_2/decay/Assign: (Assign): /job:localhost/replica:0/task:0/device:GPU:0
Adam_2/beta_2: (VariableV2): /job:localhost/replica:0/task:0/device:GPU:0
IsVariableInitialized_13: (IsVariableInitialized): /job:localhost/replica:0/task:0/device:GPU:0

training/Adam/gradients/batch_normalization_3_1/batchnorm/mul_grad/Shape_1: (Const): /job:localhost/replica:0/task:0/device:GPU:0
training/Adam/gradients/batch_normalization_3_1/batchnorm/mul_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
training/Adam/gradients/batch_normalization_3_1/moments/Squeeze_grad/Shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
training/Adam/gradients/zeros_87/Const: (Const): /job:localhost/replica:0/task:0/device:GPU:0

How to turn off these unwanted logs? 
I have already applied the following solution for switching off the warning logs from the tensorflow.
https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information

### Source code 
from keras.layers.normalization import BatchNormalization

model = Sequential()

model.add(Dense(64, input_dim=14, init='relu'))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Dense(64, init='uniform'))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.add(Dense(1, init='uniform'))
model.add(BatchNormalization())
model.add(Activation('softmax'))

model.compile(loss='binary_crossentropy', optimizer=Adam())

model.fit(X_train, y_train)"
15717,Performance issues when multiplying constant matrices,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, the code sample is provided below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Installed from official wheel
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**:  Python 3.6.3 | packaged by conda-forge | (default, Dec  9 2017, 16:18:26) 
[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**:  8.0/6.0.21
- **GPU model and memory**: GTX 1070, 8GB
- **Exact command to reproduce**: run the provided code sample

### Describe the problem
_I think this is a bug or an unclear performance issue. I also posted on StackOverflow to check if it was a known issue before posting, but not getting replies and I don't think it's a support problem._

I'm using Tensorflow for some non-DL computation, and I'm running into a behaviour I don't understand. I am testing the multiplication of a square matrix by itself: tf.matmul(a, a):

1. when the matrix is created with tf.constant
2. when the matrix is randomly initialized at each run

My expectation is that the first case should have some overhead for transferring the initial data, 100 MB (5000x5000 matrix using float32) but then the execution of the second case should be slightly slower due to the random initialization at each run.

However, what I see is that the multiplication of the constant is much slower even on successive runs in the same session.

Below I include logs generated on different GPUs: it seems that on lower-level GPUs (K1100M, GTX 940MX) constant multiplication is faster or the same, while on newer GPUs (GTX 1070, Tesla P100) it's slower. Details included in the logs.

### Source code 
```
import tensorflow as tf
import numpy as np
from timeit import timeit
import os

os.environ[""TF_CPP_MIN_LOG_LEVEL""]=""2""
SIZE = 5000
NUM_RUNS = 10

a = np.random.random((SIZE, SIZE))
_const_a = tf.constant(a, dtype=tf.float32, name=""Const_A"")
_mul_const_a = tf.matmul(_const_a, _const_a, name=""Mul_Const"")

_random_a = tf.random_uniform((SIZE, SIZE), dtype=tf.float32, name=""Random_A"")
_mul_random_a = tf.matmul(_random_a, _random_a, name=""Mul_Random"")

with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as s:
    # Run once to make sure everything is initialised
    s.run((_const_a, _mul_const_a, _random_a, _mul_random_a))

    # timeit
    print(""TF with const\t"", timeit(lambda: s.run((_mul_const_a.op)), number=NUM_RUNS))
    print(""TF with random\t"", timeit(lambda: s.run((_mul_random_a.op)), number=NUM_RUNS))

```
### Logs: I have accurate environment details only for the GTX 1070 and the P100, as reported above. 

#### GTX 1070 X (multiplying constants is much slower)
```
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0
TF with const    2.9953213009994215
TF with random   0.513827863998813
```

#### Tesla P100 (multiplying constants is much slower)
```
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0
/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:05.0, compute capability: 6.0
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0
TF with const     1.5770663949660957
TF with random     0.32687677699141204

```
#### K1100M (multiplying constants is much faster. But I am not sure which version of TF this was run with)
```
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Quadro K1100M, pci bus id: 0000:01:00.0, compute capability: 3.0
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A: (Add): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/device:GPU:0
Const_A: (Const): /job:localhost/replica:0/task:0/device:GPU:0
TF with const    4.3167382130868175
TF with random   9.889055849542306
```

#### GTX 940 MX (multiplying constants is slightly slower)
```
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0
Random_A/sub: (Sub): /job:localhost/replica:0/task:0/gpu:0
Random_A/RandomUniform: (RandomUniform): /job:localhost/replica:0/task:0/gpu:0
Random_A/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
Random_A: (Add): /job:localhost/replica:0/task:0/gpu:0
Mul_Random: (MatMul): /job:localhost/replica:0/task:0/gpu:0
Mul_Const: (MatMul): /job:localhost/replica:0/task:0/gpu:0
Random_A/max: (Const): /job:localhost/replica:0/task:0/gpu:0
Random_A/min: (Const): /job:localhost/replica:0/task:0/gpu:0
Random_A/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
Const_A: (Const): /job:localhost/replica:0/task:0/gpu:0
TF with const    3.5542741210010718
TF with random   3.519956939999247


```"
15716,ImportError: No module named contracts,
15715,ValueError: Batch length of predictions should be same,"Hi,

I'm trying to visualize the output of a convolutional autoencoder using TensorFlow Estimator API.
I use 64*64 images stored in a Numpy array as input, and use `tf.estimator.inputs.numpy_input_fn` to feed this input to my estimator.
Everything works perfectly fine during training, but as soon as I try to do predictions, it seems that I have an issue with my input_fn.
Please forgive me in advance, I am not 100% sure this is a bug, but I think I have tried everything I had in mind.

```
input_fn = tf.estimator.inputs.numpy_input_fn(
    x={""x"": train_data},
    y=None,
    batch_size=8,
    num_epochs=None,
    shuffle=True)

autoencoder = tf.estimator.Estimator(model_fn=autoencoder_model_fn, model_dir=model_dir)
tensors_to_log = {""loss"": ""loss""}
logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=1000)

autoencoder.train(
    input_fn=input_fn,
    steps=50000,
    hooks=[logging_hook])

input_fn_predict = tf.estimator.inputs.numpy_input_fn(
    x={""x"": train_data},
    y=None,
    batch_size=1,
    num_epochs=None,
    shuffle=False)
predictions = autoencoder.predict(input_fn=input_fn_predict)
predictions = [p['decoded_image'] for p in predictions]
print predictions[0].shape
```
I tried among other things to set `batch_size` to the same value for both input_fn, but it doesn't work and I get the following error : 
```bash 
Traceback (most recent call last):
  File ""AutoEncoder.py"", line 164, in <module>
    main()
  File ""AutoEncoder.py"", line 157, in main
    predictions = [p['decoded_image'] for p in predictions]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 425, in predict
    for i in range(self._extract_batch_length(preds_evaluated)):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 592, in _extract_batch_length
    'different batch length then others.' % key)
ValueError: Batch length of predictions should be same. features has different batch length then others.
```

Can anybody see what's wrong?
Thanks in advance :) "
15706,Feature request: unsafe_div op,"As discussed with @drpngx in #14667 , we found that several PRs are related to division by zero problem, for example, #15443, #14865. 

#### 1. why do we need the op

In `metrics`, `loss` and `math_ops` modules, all create a `_safe_div` or `_safe_scalar_div` method with help of `array_ops.where` to resolve the problem. However, we think those implementations have three disadvantages:
1. Lack of generality: most are designed for only scalar.
2. Not efficient.
3. Since `where` ops propagates NaNs in gradients (#2540), we have to use nested `where` trick which is a little counter-intuitive.

#### 2. what behavior do we expect it

Above all, we propose to create new c++ op: `safe_div`:
+ When denominator is zero, return 0 or numerator. The behavior can be selected by user themselves.
+ Optional: Treat negative as zero, which is sometime useful for loss calculation.
+ Create its own gradient op to avoid NaN problem for `where`.

I think for metric, loss and gradient calculation, they could benefit from the op and get rid of NaN.
And I'd like to contribute the op in **contrib** at first if the proposition is approved by tensorflowers.

#### 3. how to implement it

By the way, since  the name`safe_div` has been used in cwise_ops.h, whose behavior is opposite: raise an exception for integer when divide by zero. 
https://github.com/tensorflow/tensorflow/blob/3629fc4e98254c37e614ac3f77fa250b75c70f8d/tensorflow/core/kernels/cwise_ops.h#L703
So perhaps we need to either rename it or create a new name for our op. Does anyone has a good idea?"
15701,Cannot run mobilenet_0.25_128_quantized image retrain,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: python tensorflow/examples/image_retraining/retrain.py --image_dir /path/to/image/dir/  --architecture mobilenet_0.25_128_quantized

### Describe the problem
while trying to create a mobilenet model, getting this error. The url being created in the retrain.py file, is not accessible via browser either.

### Source code / logs
tensorflow.python.framework.errors_impl.NotFoundError: /tmp/imagenet/mobilenet_v1_0.25_128_quantized_frozen/quantized_frozen_graph.pb; No such file or directory

  "
15699,[Android] Dex cannot parse version 52 byte code,"When including:

`compile 'org.tensorflow:tensorflow-lite:0.1.1'`

I get the error:

> [Android] Dex cannot parse version 52 byte code

If I use AGP 3.0.0+ the problem goes away since it has support for Java 8, but the problem exists if I try to use 2.3.3. 
"
15698,Exception trying to import a retrained model in android classifier demo app,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
('v1.3.0-rc1-5733-gb43d0f3', '1.4.0')
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.9.0
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


I have retrained a mobilenet_v1_1.0_224 frozen_graph.pb model with the following script:

export PYTHONPATH=/usr/local/lib/python2.7/dist-packages:/usr/lib/python2.7/dist-packages
export IMAGE_SIZE=224
export WIDTH_MUL=1.0 # 0.75 0.50 0.25
export ARCHITECTURE=""mobilenet_${WIDTH_MUL}_${IMAGE_SIZE}""
export BASE_DIR=""$( cd ""$( dirname ""${BASH_SOURCE[0]}"" )"" && pwd )""
export TF_FILES_DIR=""tf_files""
python -m scripts.retrain \
  --bottleneck_dir=""${TF_FILES_DIR}""/bottlenecks \
  --how_many_training_steps=4000 \
  --model_dir=""${TF_FILES_DIR}""/models/ \
  --summaries_dir=""${TF_FILES_DIR}""/training_summaries/""${ARCHITECTURE}"" \
  --output_graph=""${TF_FILES_DIR}""/retrained_graph.pb \
  --output_labels=""${TF_FILES_DIR}""/retrained_labels.txt \
  --architecture=""${ARCHITECTURE}"" \
  --image_dir=""${TF_FILES_DIR}""/flower_photos

I copied ""retrained_graph.pb"" and ""retrained_labels.txt"" in the ""assets"" directory of the android demo app in tensorflow/examples/android and modified the source code in ClassifierActivity.java as follows:

/* Original code:
  private static final String INPUT_NAME = ""input"";
  private static final String OUTPUT_NAME = ""output"";
  private static final String MODEL_FILE = ""file:///android_asset/tensorflow_inception_graph.pb"";
  private static final String LABEL_FILE = ""file:///android_asset/imagenet_comp_graph_label_strings.txt"";
*/
/* Replaced by: */
  private static final String INPUT_NAME = ""input"";
  private static final String OUTPUT_NAME = ""final_result"";
  private static final String MODEL_FILE = ""file:///android_asset/retrained_graph.pb"";
  private static final String LABEL_FILE = ""file:///android_asset/retrained_labels.txt"";
/* End */

I cleaned and rebuilt the whole project in Android Studio, successfully.

The app was then loaded on a Huawei P8 Lite (Android 7.0) and starting TF Classify, the following error occurs:

E/tensorflow: CameraActivity: Exception!
              java.lang.RuntimeException: Failed to load model from 'file:///android_asset/retrained_graph.pb'
                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:113)
                  at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:103)
                  at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:118)
                  at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:120)
                  at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1204)
                  at android.os.Handler.dispatchMessage(Handler.java:105)
                  at android.os.Looper.loop(Looper.java:156)
                  at android.app.ActivityThread.main(ActivityThread.java:6523)
                  at java.lang.reflect.Method.invoke(Native Method)
                  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:942)
                  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:832)
               **Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[""SAME"", ""VALID""]; attr=data_format:string,default=""NHWC"",allowed=[""NHWC"", ""NCHW""]>; NodeDef: MobilenetV1/MobilenetV1/Conv2d_0/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", dilations=[1, 1, 1, 1], padding=""SAME"", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true](input, MobilenetV1/Conv2d_0/weights/read)**. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)
                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:105)
                  at org.tensorflow.demo.TensorFlowImageClassifier.create(TensorFlowImageClassifier.java:103) 
                  at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:118) 
                  at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:120) 
                  at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1204) 
                  at android.os.Handler.dispatchMessage(Handler.java:105) 
                  at android.os.Looper.loop(Looper.java:156) 
                  at android.app.ActivityThread.main(ActivityThread.java:6523) 
                  at java.lang.reflect.Method.invoke(Native Method) 
                  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:942) 
                  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:832) 
Application terminated.

How to fix this error?"
15697,Very slow tf.transpose on CPU (compared to numpy),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Tested on Linux Ubuntu 16.04 and Mac OS
- **TensorFlow installed from (source or binary)**: Both affected
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**:  3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: 

### Describe the problem
Tensorflow transpose is 10000 slower than numpy transpose on my example.

### Source code / logs
```
import numpy as np
a = np.random.randn(*(10, 10, 10, 100, 10, 10, 10))
%timeit np.transpose(a, [3, 0, 1, 2, 4, 5, 6])
# 744 ns on my machine
b = tf.Variable(tf.random_normal((10, 10, 10, 100, 10, 10, 10))) # variable to avoid generating random numbers while measuring time
sess = tf.Session()
sess.run(tf.global_variables_initializer())
op = tf.transpose(b, [3, 0, 1, 2, 4, 5, 6]).op
%timeit sess.run(op)
# 7.94 s
```"
15696,A fix for error in tf.layers.conv3d_transpose when inferred batch size,"## Context
When using the `tf.layers.conv3d_tranpose` Op with a dynamic batch size and when `use_bias=True` then there is a [well known error that occurs](https://github.com/tensorflow/tensorflow/issues/10520).
The error is due to a [tf.reshape Op that chunks together some of the axes before adding the bias for a slight performance improvement](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1628).
E.g. in the case of `data_format == 'channels_last'`, 
```
outputs_4d = array_ops.reshape(outputs, [
            outputs_shape[0], outputs_shape[1],
            outputs_shape[2] * outputs_shape[3], outputs_shape[4]
        ])
```
gives an error when `outputs_shape[0] == None`, i.e. when batch size is inferred. 

## Simple fix
To fix this with minimal modification to other code, it would be great if someone could replace `outputs_shape[0]` with `-1` in these two lines:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1627
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L1632"
15695,LookupError: No gradient defined for operation for assign,"I wish to do assign ops in a layer such as below 
           **with tf.name_scope('conv1_1') as scope:
                kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,
                                                         stddev=1e-1), name='weights')
                kernel = kernel[:, :, : 0:32].assign(tf.zeros([3, 3, 3, 32]))
                conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')
                biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),
                                     trainable=True, name='biases')
                out = tf.nn.bias_add(conv, biases)
                self.conv1_1 = tf.nn.relu(out, name=scope)
                self.parameters += [kernel, biases]**

But later I train again. I will have error.
**LookupError: No gradient defined for operation for assign**"
15694,Latency of simple tf.data.Dataset transformations is higher than raw Python,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip install tensorflow (CPU only)
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5.2

### Describe the problem
I'm trying to improve performance by moving to `tf.data.Datasets` to manage epochs and minibatches (particularly I/O performance on a GPU when I come to scaling up). However I'm finding that this is much slower than just using nested `for` loops in Python.

### Source code / logs
Here's an example using a dataset with 10,000 numbers, 10 epochs and a minibatch size of 100:

```python
import tensorflow as tf
import numpy as np
from time import time

MINI_BATCH = 100
EPOCHS = 10

# Dataset consisting of 10000 random numbers
raw_data = np.random.randn(10000)

# Raw Python implementation
start = time()
split_data = np.split(raw_data, 10000 // MINI_BATCH)

for _ in range(EPOCHS):
    for i, batch in enumerate(split_data):
        # Do stuff with batch data
        x = batch * 2
print(""Raw Python done in"", time() - start)


# TensorFlow implementation
start = time()
dataset = tf.data.Dataset.from_tensor_slices(raw_data)
dataset = dataset.repeat(EPOCHS)
dataset = dataset.batch(MINI_BATCH)
iterator = dataset.make_one_shot_iterator()
next_chunk = iterator.get_next()

with tf.Session() as sess:
    while True:
        try:
            batch = sess.run(next_chunk)
            # Do stuff with batch data
            x = batch * 2
        except tf.errors.OutOfRangeError:
            break
print(""TensorFlow done in"", time() - start)

```
Output:
```
Raw Python done in 0.0011773109436035156
TensorFlow done in 0.14212393760681152
```

Does anyone know why this might be the case? 

I'm guessing that most of the overhead is in the evaluation of `iterator.get_next()` on every loop. If this is not supposed to be evaluated it would be useful to have some examples of how it should be used without using `sess.run` each time.
"
15693,Pruning some features,"I'm doing some work about pruning VGG16. And my method is set some kernel to be zero.
               **kernel = tf.Variable(tf.truncated_normal([3, 3, 3, 64], dtype=tf.float32,
                                                         stddev=1e-1), name='weights')
                kernel1 = tf.Variable(tf.zeros([3, 3, 3, 64], dtype=tf.float32), name='pruning_weights',
                                      trainable=False)
                kernel1 = kernel1[:, :, :, 0:32].assign(kernel[:, :, :, 0:32])**

But I want to train VGG again. the problem said that, 
**LookupError: No gradient defined for operation 'conv1/conv1_1/conv1/conv1_1/strided_slice/_assign' (op type: StridedSliceAssign)**

Anybody came across such issues? Or have some idea to set the kernel last dim to be zero?
Thanks a lot! "
15692,tf.image.draw_bounding_boxes don't support boxes with different color,"I want to draw boxes with different color for different classes, but it seems that  `tf.image.draw_bounding_boxes` don't support, could you add color paramters to `tf.image.draw_bounding_boxes`?
"
15691,The problem of the tensorboard,"Hi:
  I am the newbie of the tensorflow,  there is a problem during learning the usage of  tensorboard. 
  There is no problem with the first code compilation after start the Compiler(Anaconda spyder), but recompiling the code will go wrong, that is very strange. can anyone help me?

thank you very much!

**First compilation:**
![1](https://user-images.githubusercontent.com/31270354/34410598-60c20af0-ec0c-11e7-9acc-b3a5757b2101.PNG)
![2](https://user-images.githubusercontent.com/31270354/34410606-6776095a-ec0c-11e7-8dcb-6607336bd7d2.PNG)
![3](https://user-images.githubusercontent.com/31270354/34410611-6cab0768-ec0c-11e7-8f39-38a7cee2087f.PNG)
everything is ok during first compilation

**Second compilation:**
![4](https://user-images.githubusercontent.com/31270354/34410636-8f812b64-ec0c-11e7-91c9-22ad651245d9.PNG)
Something was wrong!!!

**the code of the tensorflow:**
```
import tensorflow as tf

x = tf.placeholder(tf.int32)
y = x + 2
                   
sess = tf.Session()

tf.summary.scalar('Accuracy' , y)
merged = tf.summary.merge_all()
writer = tf.summary.FileWriter(""logs/"", sess.graph)

for i in range(200):     
    rs = sess.run(merged , feed_dict = {x: 10})
    writer.add_summary(rs, i)
```
**Error report:**
```
runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')
Traceback (most recent call last):

  File ""<ipython-input-2-66eb2d566452>"", line 1, in <module>
    runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')

  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)

  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/Administrator/.spyder-py3/temp.py"", line 13, in <module>
    rs = sess.run(merged , feed_dict = {x: 10})

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 895, in run
    run_metadata_ptr)

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1321, in _do_run
    options, run_metadata)

  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)

InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype int32
	 [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op 'Placeholder', defined at:
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\ipython\start_kernel.py"", line 223, in <module>
    main()
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\ipython\start_kernel.py"", line 219, in main
    kernel.start()
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\ioloop.py"", line 162, in start
    super(ZMQIOLoop, self).start()
  File ""C:\Program Files\Anaconda3\lib\site-packages\tornado\ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""C:\Program Files\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""C:\Program Files\Anaconda3\lib\site-packages\ipykernel\zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""C:\Program Files\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""C:\Program Files\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-66eb2d566452>"", line 1, in <module>
    runfile('C:/Users/Administrator/.spyder-py3/temp.py', wdir='C:/Users/Administrator/.spyder-py3')
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 866, in runfile
    execfile(filename, namespace)
  File ""C:\Program Files\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""C:/Users/Administrator/.spyder-py3/temp.py"", line 3, in <module>
    x = tf.placeholder(tf.int32)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 1548, in placeholder
    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2094, in _placeholder
    name=name)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype int32
	 [[Node: Placeholder = Placeholder[dtype=DT_INT32, shape=<unknown>, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]    
```




"
15690,mkl_cpu_allocator.h is not compiled under windows anymoe,"git branch v1.5/master

[mkl_cpu_allocator.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/mkl_cpu_allocator.h)

is not compiled on windows anymore since in includes unistd.h, which dosn't exist in windows.
"
15689,TensorFlowInferenceInterface: readNodeFloat error,"This is part of my Tensorflow frozen graph, I have named the input and output nodes.

    >>> g.ParseFromString(open('frozen_graph.pb','rb').read())
    >>> g
    node {
      name: ""input""
      op: ""Placeholder""
      attr {
        key: ""dtype""
        value {
          type: DT_FLOAT
        }
      }
      attr {
        key: ""shape""
        value {
          shape {
            dim {
              size: -1
            }
            dim {
              size: 68
            }
          }
        }
      }
    }
    ...
    node {
      name: ""output""
      op: ""Softmax""
      input: ""add""
      attr {
        key: ""T""
        value {
          type: DT_FLOAT
        }
      }
    }

I ran this model by the following code
(CELL is name of directory where my file is located)

    final String MODEL_FILE = ""file:///android_asset/"" + CELL + ""/optimized_graph.pb"" ;
    final String INPUT_NODE = ""input"" ;
    final String OUTPUT_NODE = ""output"" ;
    final int[] INPUT_SIZE = {1,68} ;
    float[] RESULT = new float[8];
    
    inferenceInterface = new TensorFlowInferenceInterface();
    inferenceInterface.initializeTensorFlow(getAssets(),MODEL_FILE) ;
    inferenceInterface.fillNodeFloat(INPUT_NODE,INPUT_SIZE,input);

and finally

    inferenceInterface.readNodeFloat(OUTPUT_NODE,RESULT);


But I get this error in Log

    12-28 16:42:48.622 9890-12178/com.getfocus.signalsimilarity I/native: tensorflow_inference_jni.cc:151 Initialization done in 52.275ms
    12-28 16:42:51.048 9890-12178/com.getfocus.signalsimilarity E/native: tensorflow_inference_jni.cc:170 Output [output] not found, aborting!


I have searched a lot for the solution but nothing seems to solve this. Thanks in advance"
15688,Reduced accuracy with retrained Inception v3 model on Android ,"I have follow instructions on TensorFlow website and the source code from examples on Github to retrain my own image classifier model which is basing on Inception v3.

The result is, for same picture, if I use python script for prediction I got the right category with confidence 93.3%. But I use Android Inference interface can only get the right category with 81.3% confidence.

I think the problem comes from the way that how to use the model.

In Github code, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/ClassifierActivity.java

Here is a snippet of comments to indicate how to user Inception v3 model:
```java
  // These are the settings for the original v1 Inception model. If you want to
  // use a model that's been produced from the TensorFlow for Poets codelab,
  // you'll need to set IMAGE_SIZE = 299, IMAGE_MEAN = 128, IMAGE_STD = 128,
  // INPUT_NAME = ""Mul"", and OUTPUT_NAME = ""final_result"".
  // You'll also need to update the MODEL_FILE and LABEL_FILE paths to point to
  // the ones you produced.
  //
  // To use v3 Inception model, strip the DecodeJpeg Op from your retrained
  // model first:
  //
  // python strip_unused.py \
  // --input_graph=<retrained-pb-file> \
  // --output_graph=<your-stripped-pb-file> \
  // --input_node_names=""Mul"" \
  // --output_node_names=""final_result"" \
  // --input_binary=true
```
We start from Input named ""Mul"" because DecodeJpeg is NOT supported in Android. So, we need to decode bitmap and resize it to 299 x 299 and flatten it with Android way.  I think that is the difference between python script and Android Inference interface. In python script, we use tf.gFile to get the content of image and direct pass to the start node ""DecodeJpeg""

I review the graph of retrained model, node ""Mul"" is not the direct successor of DecodeJpeg. There are four nodes ""Cast"", ""ExpandDims"", ""ResizeBilinear"", ""Sub"" between ""Mul"" and ""DecodeJpeg"". I think it does the same thing I mentioned to preprocess the image. I think may be we could pass input data a little bit earlier than ""Mul"".

First, I strip the mode with follow command:
```shell
strip_unused \
--input_graph=tf_files/retrained_graph.pb \
--output_graph=tf_files/stripped_retrained_graph..pb \
--input_node_names=""Cast"" \
--output_node_names=""final_result"" \
--input_binary=true
```
Then I change the recognizeImage() to pass input to node Cast
```Java
  @Override
  public List<Recognition> recognizeImage(final Bitmap bitmap) {
    // Log this method so that it can be analyzed with systrace.
    Trace.beginSection(""recognizeImage"");

    Trace.beginSection(""preprocessBitmap"");
    // Preprocess the image data from 0-255 int to normalized float based
    // on the provided parameters.
    int[] origIntValues = new int[bitmap.getWidth() * bitmap.getHeight()];
    float[] flatValues = new float[bitmap.getWidth() * bitmap.getHeight() * 3];
    bitmap.getPixels(origIntValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
    for (int i = 0; i < origIntValues.length; ++i) {
        final int val = origIntValues[i];
        flatValues[i * 3 + 0] = ((val >> 16) & 0xFF);
        flatValues[i * 3 + 1] = ((val >> 8) & 0xFF) ;
        flatValues[i * 3 + 2] = (val & 0xFF);
     }
    Trace.endSection();

    // Copy the input data into TensorFlow.
    Trace.beginSection(""feed"");
    inferenceInterface.feed(inputName, flatValues, new long[] { bitmap.getHeight(), bitmap.getWidth() , 3  });
    Trace.endSection();
```
Here the inputNames is ""Cast"", not ""Mul"". After that I get the exact the same result as python script. 

Conclusion, I think the way currently we used on Android side to preprocess image is NOT doing the same tasks as the nodes ""Cast"", ""ExpandDims"", ""ResizeBilinear"", ""Sub"" do. I suggest to update the code of Android example to fix this problem.
"
15687,How to load a metagraph via C++,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.2
- **Python version**: 2.7

### Describe the problem
I want to load a metagraph via C++ code, and later the checkpoint weights. To load the metagraph, I first generate a pb file from it

```
with tf.Session() as sess:
	new_saver = tf.train.import_meta_graph(root_dir + meta_graph)
	tf.train.write_graph(sess.graph_def, root_dir, export_pb, as_text=False)
```
Then I use selective registration to generate the ops and kernels needed

`bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=xinmei/rnn_dict/model_test.pb > tensorflow/core/framework/ops_to_register.h`
Next, I compile my runnable using this registration. However, when I run the executable on my Android device, it says

```
Error creating graph: Invalid argument: No OpKernel was registered to support Op 'Const' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: save/RestoreV2_8/shape_and_slices = Const[_output_shapes=[[1]], dtype=DT_STRING, value=Tensor<type: string shape: [1] values: >]()]]
```
How can I load the metagraph? The motivation of this is that I want to continue training the model on my Android device.
"
15685,"fake_quant_with_min_max_vars doesn't change min, max vars ","# System Information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip3 install --upgrade tensorflow-gpu
- TensorFlow version (use command below): v1.4.0-19-ga52c8d9, 1.4.1
- Python version:3.5.2 
- Bazel version (if compiling from source): 0.7.0
- GCC/Compiler version (if compiling from source): GCC 5.4.0
- CUDA/cuDNN version: Cuda compilation tools, release 8.0, V8.0.61, cuDNN : 6.0.21
- GPU model and memory: Two GeForce GTX 1080 Ti devices.
- Exact command to reproduce: N/A
# Problem description
I've got a problem with tf-lite conversion tool. There is learned graph which should be converted in tflite format and quantinized.
I have read the answer https://stackoverflow.com/questions/47463204/tensorflow-lite-convert-error-for-the-quantized-graphdef where authors recommend to create new network with fake_quant operations and retrain it. However variables passed in tf.fake_quant_with_min_max_vars op did not change their values during training. Here is modeling code which shows the problem.
# Code to reproduce
```
import tensorflow as tf
import numpy as np

khe_init = tf.random_normal_initializer(mean=0.0, stddev=np.sqrt(2.0 / 1000))


def quant_conv_op(inpt, num_filters, filter_size=[3, 3], strides=[1, 1, 1, 1], padding=""VALID"", layer_name=""layer1"", use_acivation=True):
    num_input_map = inpt.get_shape().as_list()[-1]
    kernel_shape = filter_size + [num_input_map, num_filters]    
    with tf.variable_scope(layer_name):
        W = tf.get_variable(""weights"", shape=kernel_shape, initializer=khe_init)
        max_w = tf.get_variable(""max_quant_weights"", shape=[], initializer=tf.constant_initializer(1), trainable=True)
        min_w = tf.get_variable(""min_quant_weights"", shape=[], initializer=tf.constant_initializer(-1), trainable=True)
        b = tf.get_variable(""bias"", shape=[num_filters, ], initializer=tf.zeros_initializer)
 
        q_W = tf.fake_quant_with_min_max_vars(W, min_w, max_w)
        out = tf.nn.conv2d(inpt, q_W, strides=strides, padding=padding, name=""2d_convolution_operation"")
        out = tf.nn.bias_add(out, b)
        
        if use_acivation: 
            out = tf.nn.relu6(out, name=layer_name+""out"")
            out = tf.fake_quant_with_min_max_args(out, 0, 6)
        else:
            max_out = tf.get_variable(""max_quant_output"", shape=[], initializer=tf.constant_initializer(1), trainable=True)
            min_out = tf.get_variable(""min_quant_output"", shape=[], initializer=tf.constant_initializer(-1), trainable=True)  
            out = tf.fake_quant_with_min_max_vars(out, min_out, max_out, name=""fake_quant_with_min_max_out_quantinization"")
    
    return out, max_w, min_w, W


def loss(logits, batch):
    return tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.ones(shape=[batch, 1]))


def build_net(ph_input):
    inp = tf.fake_quant_with_min_max_args(ph_input, -1, 1)
    out, max_w1, min_w1, W1 = quant_conv_op(inp, num_filters=64, filter_size=[3, 3], layer_name=""layer1"")    
    out, max_w2, min_w2, W2 = quant_conv_op(out, num_filters=128, filter_size=[3, 3], layer_name=""layer2"")
    out, max_w3, min_w3, W3 = quant_conv_op(out, num_filters=256, filter_size=[3, 3], layer_name=""layer3"")
    out = tf.reduce_mean(out, axis=[1, 2], keep_dims=True, name=""avg_pool"")
    out = tf.fake_quant_with_min_max_args(out, 0, 6, name=""fake_quant_with_min_max_avgpool_quantinization"")
    logits, max_w4, min_w4, W4 = quant_conv_op(out, num_filters=1, filter_size=[1, 1], layer_name=""layer4"", use_acivation=False)
    
    max_list = [max_w1, max_w2, max_w3, max_w4]
    min_list = [min_w1, min_w2, min_w3, min_w4]
    W_list = [W1, W2, W3, W4]
    logits = tf.reshape(logits, [-1, 1])
    sig_loss = tf.reduce_mean(loss(logits, batch=64))
    adam_op = tf.train.AdamOptimizer(10**-0)
    train_op = adam_op.minimize(sig_loss, var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)) 
    return train_op, max_list, min_list, sig_loss, W_list


def main():
    sess = tf.InteractiveSession()
    ph_input = tf.placeholder(tf.float32, [None, 28, 28, 3], name=""network_input"") 
    train_op, max_list, min_list, sig_loss, W_list = build_net(ph_input)
    sess.run(tf.global_variables_initializer())
    tf.summary.FileWriter('.', graph=tf.get_default_graph())
    trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
    for t in trainable_vars:
        if len(t.shape) == 0:
           print(t.name, sess.run(t))
        if len(t.shape) == 4:
           v = sess.run(t)
           print(t.name, np.max(v), np.min(v))

    for i in range(10):
        res = sess.run([train_op, sig_loss, W_list[0]]+max_list, feed_dict={ph_input:np.random.uniform(low=-1, high=1, size=[64, 28, 28, 3])})
    
    print(""========="")
    for t in trainable_vars:
        if len(t.shape) == 0:
           print(t.name, sess.run(t))
        if len(t.shape) == 4:
           v = sess.run(t)
           print(t.name, np.max(v), np.min(v))

if __name__ == ""__main__"":
    main()
```

  
  "
15684,speech commands check_nans doesnt work,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I'm running the simple audio recognition tutorial code.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:tf-nightly-gpu15
- **Python version**: 3.5
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA8.0/cuDNNv7
- **GPU model and memory**: 1060 6GB
- **Exact command to reproduce**:python train.py --check-nans=True

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
As the tutorial said, by enabling the --check_nans flag I could track down the source of the not-a-number error in model tuning. But I got following errors instead, which I guess maybe a bug or something?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Traceback (most recent call last):
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float
         [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[Node: global_step/read/_18 = _Send[T=DT_INT64, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4_global_step/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](global_step/read)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""train.py"", line 432, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""train.py"", line 217, in main
    dropout_prob: 0.5
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float
         [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[Node: global_step/read/_18 = _Send[T=DT_INT64, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4_global_step/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](global_step/read)]]

Caused by op 'Placeholder_1', defined at:
  File ""train.py"", line 432, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""train.py"", line 106, in main
    FLAGS.testing_percentage, model_settings)
  File ""/home/renq/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 163, in __init__
    self.prepare_processing_graph(model_settings)
  File ""/home/renq/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 355, in prepare_processing_graph
    self.foreground_volume_placeholder_ = tf.placeholder(tf.float32, [])
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py"", line 1680, in placeholder
    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3141, in _placeholder
    ""Placeholder"", dtype=dtype, shape=shape, name=name)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3143, in create_op
    op_def=op_def)
  File ""/home/renq/.conda/envs/py35_tfnightly_gpu15/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1611, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float
         [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
         [[Node: global_step/read/_18 = _Send[T=DT_INT64, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_4_global_step/read"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](global_step/read)]]

"
15682,Eager: tfe.implicit_value_and_gradients uses functions operating on raw tf variables,"## System information
- Tensorflow version: 1.5.0-dev20171126
- Python version: Python 3.5.0 (v3.5.0:374f501f4567, Sep 12 2015, 11:00:19)

## Problem
Forgive me if I'm re-iterating something that's discussed before. Even though I don't think the issue described here is a bug, I nevertheless believe it is worthy to point out. The specific issue is that when we pass a loss function, e.g. ```loss```, to ```tfe.implicit_value_and_gradients```, it seems that backprop only happens if the variables used by ```loss``` are is their ""raw states"". Here's an example:

```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()
v = tf.get_variable(name='v', initializer=1., trainable=True)
v_add_1 = v + 1.  # this causes the problem

def loss():
    return 2. * v_add_1
value_and_gradients_fn = tfe.implicit_value_and_gradients(loss)
print (value_and_gradients_fn())
```
In this case I get the error as follows:
```
Traceback (most recent call last):
  File ""test.py"", line 17, in <module>
    val = g()
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/eager/backprop.py"", line 360, in grad_fn
    raise ValueError(""No trainable variables were accessed while the ""
ValueError: No trainable variables were accessed while the function was being computed.
```
After a little bit of pondering, I found the problem to be the line ```v = v + 1.```. As soon as we **delete** this line, the program runs without bugs. My understanding of this behavior is that, the gradients and the backprop process somehow only ""live"" in the scope of the loss function. We **cannot** backprop to some variable that is modified outside of ```loss```, even if, implicitly, the computed loss depends on that variable. 

Here's a more obscure example:

```python
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()

v = tf.get_variable(name='v', initializer=1., trainable=True)
v_add_1 = v + 1.
u = tf.get_variable(name='u', initializer=20., trainable=True)


def loss():
    result = v_add_1 + u
    return 2. * result

value_and_gradients_fn = tfe.implicit_value_and_gradients(loss)
optimizer = tf.train.AdamOptimizer(1e-1)

# before training
print (v)
print (u)

for i in range(100):
    _, gradients_and_variables = value_and_gradients_fn()
    optimizer.apply_gradients(gradients_and_variables)

# after training
print (v)
print (u)
```
After running, we could see that ```u``` is updated and ```v``` is not:
```
<tf.Variable 'v:0' shape=() dtype=float32, numpy=1.0>
<tf.Variable 'u:0' shape=() dtype=float32, numpy=20.0>
<tf.Variable 'v:0' shape=() dtype=float32, numpy=1.0>
<tf.Variable 'u:0' shape=() dtype=float32, numpy=9.9999638>
```

This might be irrelevant, but is there a way we could by pass the restriction and have gradient pass outside the function given to ```tfe.implicit_value_and_gradients```?"
15681,tf.image.decode_image does not support png grayscale 16bit.,"Code to reproduce:
```
import tensorflow as tf
import numpy as np

print (""TF Version: %s"" % tf.__version__)

import urllib

png16 = urllib.request.urlopen('http://www.schaik.com/pngsuite/basn0g16.png').read(1000)
with tf.Session() as session:
    content = tf.placeholder(tf.string)
    tensor = tf.image.decode_image(
        contents=content,
        channels=1
    )
    
    out = (session.run(tensor, {content: png16}))
    np_out = np.array(out)
    print ('Shape', np_out.shape)
    print ('Max', np_out.max())
    

    
```
Outputs:
``` 
TF Version: 1.4.1
Shape (32, 32, 1)
Max 255
```
Same file, file command:
```
file basn0g16.png
basn0g16.png: PNG image data, 32 x 32, 16-bit grayscale, non-interlaced
```
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS
- **TensorFlow installed from (source or binary)**: pip3 install tensorflow
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: Python 3.5.2
- **Bazel version (if compiling from source)**: nope
- **GCC/Compiler version (if compiling from source)**: nope
- **CUDA/cuDNN version**: no gpu
- **GPU model and memory**: no gpu
- **Exact command to reproduce**: see abve


python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
v1.4.0-19-ga52c8d9 1.4.1

### Describe the problem
It should return uint16, but returns uint8.


### Source code / logs
see above
"
15679,"My validate loss is unchanged when training, what's the reason may it be?","Dears,
        Lately, I train a Inception-v3 model in RAP_dataset. BUT, entropy loss  on Validate data is always unchanged when training. The loss shows as follows:

- sorry, I do not find the port attaching images. ........

And, yesterday, I add tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)) in code, it still not work. What reasons may it be? Sincerely hope your replies, and BEST WISHES TO YOU!"
15672,matmul back-propagation quadratic memory consumption,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 3.6.3
- **CUDA/cuDNN version**: using CPU only

### Describe the problem
tf.matmul in back-propagation has memory consumption quadratic in the number of records of data. Test case and discussion here:
https://stackoverflow.com/questions/47991747/back-propagation-exhibiting-quadratic-memory-consumption

One answer at time of writing suggests a workaround using mini-batches, appears to confirm quadratic memory consumption is not expected. I've also tried using tf.tensordot(a,b,1) which seems to be a synonym of tf.matmul(a,b) and does not use as much memory. This despite the existence of another discussion indicating tf.matmul should be more efficient:
https://stackoverflow.com/questions/43100679/tensorflow-einsum-vs-matmul-vs-tensordot
"
15669,Session::Run() allocates a lot of memory after the first call,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**: Binary ([CPU C API](https://www.tensorflow.org/install/install_c))
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

I am working on an application that deploys several TensorFlow models using TensorFlow's C API. I have noticed that there seems to be a behavior where TensorFlow takes a long time to run the first time `TF_SessionRun()` is called, and it allocates a lot of extra memory that hangs around until the session is destroyed. In my case, my program's memory footprint is ~85MB after all of the models are loaded (which makes sense, that's about how large the model .pb files are on disk) but after the first call to `TF_SessionRun()` it jumps to ~250MB. After profiling my code it appears that TensorFlow is the culprit, and I've observed similar behavior on Android as well.

TensorFlow seems to be doing some lazy initialization, but there doesn't appear to be much documentation or discussion about this. Could someone shed some light on what is happening here? Why does it require so much memory? Is this a bug or expected behavior?

### Source code / logs

Here's a memory call tree from Xcode showing *persistent* memory allocations after the first call to `TF_SessionRun()` for one of my models:

<img width=""996"" alt=""screen shot 2017-12-27 at 1 14 59 pm"" src=""https://user-images.githubusercontent.com/3229244/34394457-1af8625c-eb0e-11e7-8cd8-ff61737dcb50.png"">

Let me know if there is any more information that I can provide. I'm curious what's going on here."
15668,MNIST dataset - gzip: train-images-idx3-ubyte.gz: not in gzip format,"initiated from tensorflow-discuss From: greina@eng.ucsd.edu 

> 
> 
> I'm trying to use:
> 
> from tensorflow.examples.tutorials.mnist import input_data
> mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)
> 
> but I am getting the error that the downloaded file is not in GZip format.
> 
> There are several bug reports on this, but none of them seem to solve the issue. 
> 
> I found train-images-idx3-ubyte.gz in the local directory MNIST_data, but even trying `gunzip` fails:
> 
> ```(tf) [bduser@param03 MNIST_data]$ gunzip
> gzip: compressed data not read from a terminal. Use -f to force decompression.
> For help, type: gzip -h
> (tf) [bduser@param03 MNIST_data]$ gunzip train-images-idx3-ubyte.gz
> 
> gzip: train-images-idx3-ubyte.gz: not in gzip format
> ```
> 
> I'm thinking that this is a problem with the original datafile. Maybe the GZip format has changed or is in conflict?? Or perhaps my OS' version of GZip can't understand the GZip file??
> 
> I am using TF 1.4 on CentOS Linux release 7.4.1708 (Core)
> 
> Thanks.
> -Tony
> 
> 
> 
> ```
> >>> from tensorflow.examples.tutorials.mnist import input_data
> >>> mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)
> Successfully downloaded train-images-idx3-ubyte.gz 727 bytes.
> Extracting MNIST_data/train-images-idx3-ubyte.gz
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/home/bduser/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py"", line 242, in read_data_sets
>     train_images = extract_images(f)
>   File ""/home/bduser/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py"", line 56, in extract_images
>     magic = _read32(bytestream)
>   File ""/home/bduser/miniconda2/envs/tf/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py"", line 38, in _read32
>     return numpy.frombuffer(bytestream.read(4), dtype=dt)[0]
>   File ""/home/bduser/miniconda2/envs/tf/lib/python2.7/gzip.py"", line 268, in read
>     self._read(readsize)
>   File ""/home/bduser/miniconda2/envs/tf/lib/python2.7/gzip.py"", line 303, in _read
>     self._read_gzip_header()
>   File ""/home/bduser/miniconda2/envs/tf/lib/python2.7/gzip.py"", line 197, in _read_gzip_header
>     raise IOError, 'Not a gzipped file'
> IOError: Not a gzipped file
> >>> exit()
> ```
> "
15662,S3 Support does not work for private bucket,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: -
- **GPU model and memory**: - 
- **Exact command to reproduce**: -



### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When trying to access a file on one of my private S3 buckets, I get an error message that the object does not exist (see below for source code and traceback). Using the AWS CLI downloading the object works fine(aka I'm sure I have the access rights to access the bucket). Also accessing the object in a public S3 bucket (like the one in issue #15159) works fine. I tried looking into the source code [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L404) to see if it's maybe an issue with missing or wrong environment variables concerning the AWS credentials, but I couldn't find any code checking for any credentials at all. Am I missing something simple?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

When running the following code

```python
from tensorflow.python.lib.io import file_io
file_io.stat('s3://myprivatebucket/filethatexists')
```

I get the following error

```
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py"", line 98, in size
    return stat(self.__name).length
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py"", line 540, in stat
    return file_statistics
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Object s3://myprivatebucket/filethatexists does not exist
```"
15660,Distributed training fault tolerance,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04.5 LTS
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: Python 3.6.3
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: release 8.0, V8.0.44/ libcudnn v6.0.21
- **GPU model and memory**: Titan X (Pascal) 12 GB
- **Exact command to reproduce**: In the description

### Describe the problem
I am using the parameter server/master/worker paradigm to run model training in distributed mode. The master node does the training and evaluation, while the worker nodes only do the training (on their shard of the data). I should also note that I am using the `tf.contrib.learn.Experiment` interface.

This model of distributed training works as expected, however, sometimes one or more of the worker nodes fail. While they have failed, the master node and other worker nodes continue the training. The problem is that when this occurs (even when only one of the worker nodes have failed), the loss suddenly becomes zero, and as a result gradients as well become zero, while the metrics suddenly change to the value of a random model, as can be seen in the figures below.

* Loss curve. As can be seen one or more of the workers have failed three times during the training.
![loss_fail](https://user-images.githubusercontent.com/1921165/34386146-3ed3d652-eaf5-11e7-99de-7923862089e6.jpg)

* Gradient norm curve
![gradient_fail](https://user-images.githubusercontent.com/1921165/34386155-48760dba-eaf5-11e7-86f9-d653cda03a3e.PNG)

* Accuracy (on the validation set)
![accuracy_fail](https://user-images.githubusercontent.com/1921165/34386161-51b1f114-eaf5-11e7-8a6c-303d8972b2b8.PNG)


**Is there a way to prevent this behavior, either by stopping the training when one of the workers fails, or pausing the training until the failed worker comes back online again (like in the beginning of the training when training only starts when all of the workers come online)?**

### Source code / logs
As indicated above, I use the experiment interface. This is the configuration for distributed training:
```python
dist_config = {}
dist_config['cluster'] = {
    'master': ['127.0.0.1:{}'.format(dist_start_port + 1)],
    'ps': ['127.0.0.1:{}'.format(dist_start_port)],
    'worker': ['127.0.0.1:{}'.format(dist_start_port + 2 + i)
            for i in range(worker_count)]
}
dist_config['task'] = {
    'type': dist_type,
    'index': (worker_index if args.dist_type == 'worker' else 0)
}
dist_config['environment'] = 'cloud'
os.environ['TF_CONFIG'] = json.dumps(dist_config)
```
And this is how I start each node:
```python
if dist_type == 'master':
    experiment.train_and_evaluate()
elif dist_type == 'ps':
    experiment.run_std_server()
else:
    experiment.train()
```
"
15659,Document Bazel-Tensorflow-Cuda interdependencies,"Since each version of Tensorflow appears to require some specific release of bazel, it would be helpful to have documentation like [this](https://www.tensorflow.org/install/install_sources#tested_source_configurations) also for people who are stuck on an older version of CUDA. For instance, I cannot upgrade to CUDA 8 on the machine I am using and am now left with the exercise of finding a working config in a space of 5 dimensions (python version, bazel version, tf version, cuda version, cudnn version).
I had it once working with CUDA 7.0 and python 3.5 (and I think bazel 0.3), but cannot reproduce now.
In this concrete case, I am trying to build `r0.11` with python 3.6, cuda 7.5, cudnn 6 and bazel 0.3/0.4/0.8 and nothing's working."
15656,CUDA 9.1 and TensorFlow,"I am using NVIDIA GeForce GTX 1050 and installed NVIDIA 387.26. I installed cuDNN 7.0.5 and CUDA 9.1. As of my understanding, I know that, tensorflow is not supported in CUDA 9.1. My question is when I can expect the next build/release of TF to support CUDA 9.1. For the time being, shall I make a link from CUDA 9.0 to CUDA 9.1 and expect to work? Or is there any better way to solve the problem?"
15655,"tf.layers.conv3d with ""channels_first"" does not accept batch dimension to be None","code to reproduce:

```python
import tensorflow as tf
x = tf.placeholder(dtype=tf.float32, shape=[None, 1, 32, 32, 32])
y = tf.layers.conv3d(x, 32, 9, data_format='channels_first')
```

traceback
```
Traceback (most recent call last):
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 468, in make_tensor_proto
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 468, in <listcomp>
    str_values = [compat.as_bytes(x) for x in proto_values]
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
    (bytes_or_text,))
TypeError: Expected binary or unicode string, got None

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py"", line 809, in conv3d
    return layer.apply(inputs)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 671, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/base.py"", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py"", line 185, in call
    outputs_shape[4]])
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3938, in reshape
    ""Reshape"", tensor=tensor, shape=shape, name=name)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 513, in _apply_op_helper
    raise err
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 510, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 926, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 229, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 208, in constant
    value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/usr/local/Cellar/pyenv/1.2.0/versions/3.6.3/envs/mrtoct/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py"", line 472, in make_tensor_proto
    ""supported type."" % (type(values), values))
TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 32, 576, 24]. Consider casting elements to a supported type.
```

The error source appears [here][1] and can be simply fixed by adding

```python
if outputs_shape[0] is None:
  outputs_shape[0] = -1
```

however you might suggest a deeper fix?


[1]: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/layers/convolutional.py#L181-L185"
15651,Not found: FeedInputs: unable to find feed output Mul,"@satok16 I have already set up and was able to run `hexagon_graph_execution` on my hvx board, however, when I tried to use my own [inception-v3 pre-trained model](https://github.com/tensorflow/models/tree/master/research/slim#pre-trained-models) that I froze using [this quantization method](https://www.tensorflow.org/performance/quantization), I am receiving this error:

```
[ RUN      ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime
native : hexagon_graph_execution_test.cc:519 Fuse and run inception v3 on hexagon with tf runtime
native : hexagon_graph_execution_test.cc:94 Hexagon controller version is 90
native : hexagon_graph_execution_test.cc:142 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes
native : hexagon_graph_execution_test.cc:148 header size = 54
native : hexagon_graph_execution_test.cc:150 image size = 40
native : hexagon_graph_execution_test.cc:152 width = 299
native : hexagon_graph_execution_test.cc:154 height = -299
native : hexagon_graph_execution_test.cc:533 Ioading image finished.
t1(loading image time)=0.026770
native : hexagon_graph_execution_test.cc:546 Build fused graph
native : remote_fused_graph_execute_utils.cc:259 Error during inference: Not found: FeedInputs: unable to find feed output Mul
native : graph_transfer_utils.cc:110 Check failed: status.ok()
Aborted
```
Do you know if the issue is because of an incorrect input argument here: 

```
curl -L ""https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz"" |
  tar -C tensorflow/examples/label_image/data -xz
bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
  --in_graph=tensorflow/examples/label_image/data/inception_v3_2016_08_28_frozen.pb \
  --out_graph=/tmp/quantized_graph.pb \
  **--inputs=input \**
  --outputs=InceptionV3/Predictions/Reshape_1 \
  --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,299,299,3"")
    remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true)
    fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes
    strip_unused_nodes sort_by_execution_order'
```

I found on [this] (https://stackoverflow.com/questions/43022516/tensorflow-inception-feedinputs-unable-to-find-feed-output-input) and also [this][https://github.com/tensorflow/tensorflow/issues/2883#issuecomment-226591095](url) posts that we might have to use `Mul` instead. Tried that with no success. Interestingly, when I test my frozen_quantized graph with:

`bazel-bin/tensorflow/examples/label_image/label_image --graph=/tmp/my_inception_quantized_graph_hvx.pb`

I receive similar results compared to a non-quantized version, so it shows that my frozen_quantized is not faulty. Can you verify the issue here? 
Was the file `https://storage.googleapis.com/download.tensorflow.org/models/tensorflow_inception_v3_stripped_optimized_quantized.pb` used in the original hvx hexgon_graph_execution produced differently?"
15650,Unable to compile tensorflow r1.4 from source with cuda 8.0 and cudnn 7 and after downgrading bazel?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.4
- **Python version**:  2.7.12
- **Bazel version (if compiling from source)**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8.0/7.0.4
- **GPU model and memory**: 1080 Ti
- **Exact command to reproduce**: 
`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" --action_env=""LD_LIBRARY_PATH=${LD_LIBRARY_PATH}""`


### Describe the problem
I'm trying to compile TF r1.4 from source but didn't manage to get this working although I tried several fixes:

1. Downgrading bazel from 0.9.0 to 0.8.1 based on #15492 

2. `sudo sh -c ""echo '/usr/local/cuda-8.0/lib64' >> /etc/ld.so.conf.d/nvidia.conf""`  and `sudo ldconfig` based on #13481

3. adding the `action_env` argument based on https://stackoverflow.com/questions/47080760/tensorflow-fails-to-compile/47295278#47295278

Note: When installing cudnn, I used both the runtime library and the tar file which i extracted and placed it in the /usr/local/cuda library respective folders.

### Source code / logs
```
ERROR: /home/kwotsin/tensorflow/tensorflow/core/BUILD:2131:1: C++ compilation of rule '//tensorflow/core:gpu_runtime_impl' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/kwotsin/.cache/bazel/_bazel_kwotsin/041f6cc3555a2d9f6211c6d126ede477/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64 \
    PATH=/usr/local/cuda/bin:/home/kwotsin/bin:/home/kwotsin/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -g0 -MD -MF bazel-out/host/bin/tensorflow/core/_objs/gpu_runtime_impl/tensorflow/core/common_runtime/gpu/gpu_device.pic.d '-frandom-seed=bazel-out/host/bin/tensorflow/core/_objs/gpu_runtime_impl/tensorflow/core/common_runtime/gpu/gpu_device.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DSNAPPY -iquote . -iquote bazel-out/host/genfiles -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/host/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/host/genfiles/external/local_config_sycl -iquote external/nsync -iquote bazel-out/host/genfiles/external/nsync -iquote external/gif_archive -iquote bazel-out/host/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/host/genfiles/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/host/genfiles/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/host/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/host/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/host/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/host/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/host/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/host/genfiles/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/host/genfiles/external/local_config_cuda -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/host/genfiles/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/host/genfiles/external/nsync/public -isystem external/gif_archive/lib -isystem bazel-out/host/genfiles/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/host/genfiles/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/host/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/host/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/host/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/host/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/host/genfiles/external/local_config_cuda/cuda/cuda/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DGOOGLE_CUDA=1' -msse3 -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c tensorflow/core/common_runtime/gpu/gpu_device.cc -o bazel-out/host/bin/tensorflow/core/_objs/gpu_runtime_impl/tensorflow/core/common_runtime/gpu/gpu_device.pic.o)
In file included from ./tensorflow/stream_executor/stream_executor.h:35:0,
                 from ./tensorflow/core/platform/stream_executor.h:38,
                 from ./tensorflow/core/common_runtime/gpu/gpu_event_mgr.h:28,
                 from ./tensorflow/core/common_runtime/gpu/gpu_device.h:30,
                 from tensorflow/core/common_runtime/gpu/gpu_device.cc:22:
./tensorflow/stream_executor/stream_executor_pimpl.h:87:63: internal compiler error: Segmentation fault
   PlatformKind platform_kind() const { return platform_kind_; }
                                                               ^
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 145.189s, Critical Path: 22.73s
FAILED: Build did NOT complete successfully

```

Thank you.

====

Further updates:

1. I tried switching to the more updated 7.0.5 CuDNN (although some mentioned in #12052 that their build worked with 7.0.4. I'm now using CUDA 9.0 + CuDNN 7.05 for CUDA 9.0, and with bazel 0.8.1. The build unfortunately still doesn't work.

2. CUDA 8.0 + CuDNN 6.0.21 also doesn't work, with the similar reasons as such:

```
C++ compilation of rule '//tensorflow/core/kernels:sparse_conditional_accumulator_op' failed (Exit 1)
In file included from tensorflow/core/kernels/sparse_conditional_accumulator_op.cc:19:0:
./tensorflow/core/kernels/sparse_conditional_accumulator.h: In destructor 'tensorflow::SparseConditionalAccumulator<Device, T>::~SparseConditionalAccumulator() [with Device = Eigen::ThreadPoolDevice; T = float]':
./tensorflow/core/kernels/sparse_conditional_accumulator.h:68:3: internal compiler error: Segmentation fault
   };
   ^
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 505.239s, Critical Path: 114.19s
FAILED: Build did NOT complete successfully

```

```
ERROR: /home/kwotsin/tensorflow/tensorflow/core/kernels/BUILD:2554:1: C++ compilation of rule '//tensorflow/core/kernels:cwise_op' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/kwotsin/.cache/bazel/_bazel_kwotsin/041f6cc3555a2d9f6211c6d126ede477/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/local/cuda-9.0 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=6.1 \
    TF_CUDA_VERSION=9.0 \
    TF_CUDNN_VERSION=7.0.5 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL=0 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++11' '-march=native' '-D_GLIBCXX_USE_CXX11_ABI=0' -MD -MF bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/cwise_op/tensorflow/core/kernels/cwise_op_floor_div.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/cwise_op/tensorflow/core/kernels/cwise_op_floor_div.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DSNAPPY -iquote . -iquote bazel-out/k8-opt/genfiles -iquote external/nsync -iquote bazel-out/k8-opt/genfiles/external/nsync -iquote external/bazel_tools -iquote bazel-out/k8-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/k8-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/k8-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/k8-opt/genfiles/external/jpeg -iquote external/protobuf_archive -iquote bazel-out/k8-opt/genfiles/external/protobuf_archive -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/k8-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/k8-opt/genfiles/external/zlib_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/genfiles/external/local_config_cuda -isystem external/nsync/public -isystem bazel-out/k8-opt/genfiles/external/nsync/public -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/k8-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/k8-opt/genfiles/external/gif_archive/lib -isystem external/protobuf_archive/src -isystem bazel-out/k8-opt/genfiles/external/protobuf_archive/src -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/k8-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/k8-opt/genfiles/external/zlib_archive -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/genfiles/external/local_config_cuda/cuda/cuda/include -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DGOOGLE_CUDA=1' -msse3 -pthread '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers -c tensorflow/core/kernels/cwise_op_floor_div.cc -o bazel-out/k8-opt/bin/tensorflow/core/kernels/_objs/cwise_op/tensorflow/core/kernels/cwise_op_floor_div.pic.o)
In file included from tensorflow/core/kernels/cwise_op_floor_div.cc:16:0:
./tensorflow/core/kernels/cwise_ops_common.h: In instantiation of 'void tensorflow::functor::BinaryFunctor<Eigen::ThreadPoolDevice, Functor, NDIMS, false>::BCast(const CPUDevice&, typename tensorflow::TTypes<typename Functor::out_type, NDIMS>::Tensor, typename tensorflow::TTypes<typename Functor::in_type, NDIMS>::ConstTensor, Eigen::array<long int, NDIMS>, typename tensorflow::TTypes<typename Functor::in_type, NDIMS>::ConstTensor, Eigen::array<long int, NDIMS>, bool*) [with Functor = tensorflow::functor::floor_div_real<double>; int NDIMS = 4; tensorflow::functor::CPUDevice = Eigen::ThreadPoolDevice; typename tensorflow::TTypes<typename Functor::out_type, NDIMS>::Tensor = Eigen::TensorMap<Eigen::Tensor<double, 4, 1, long int>, 16, Eigen::MakePointer>; typename tensorflow::TTypes<typename Functor::in_type, NDIMS>::ConstTensor = Eigen::TensorMap<Eigen::Tensor<const double, 4, 1, long int>, 16, Eigen::MakePointer>]':
./tensorflow/core/kernels/cwise_ops_common.h:136:7:   required from 'void tensorflow::BinaryOp<Device, Functor>::Compute(tensorflow::OpKernelContext*) [with Device = Eigen::ThreadPoolDevice; Functor = tensorflow::functor::floor_div_real<double>]'
tensorflow/core/kernels/cwise_op_floor_div.cc:53:1:   required from here
./tensorflow/core/kernels/cwise_ops_common.h:417:3: internal compiler error: Segmentation fault
   }
   ^
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-5/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 430.853s, Critical Path: 77.17s
FAILED: Build did NOT complete successfully

```"
15649,AttributeError:  'Tensor' object has no attribute 'assign_add',"### Describe the problem
I have constructed an object detector architecture based on ResNet-101. APIs in TF-Slim are mainly used in the structure. However when I finally create a train op by 'slim.learning.create_train_op' I receive such error. Tracebacks are showing below. 
My environments: Ubuntu 16.04, CUDA 8.0, tensorflow 1.3.0

### Source code / logs
![screenshot from 2017-12-27 10-08-30](https://user-images.githubusercontent.com/30883678/34368357-4c744366-eaee-11e7-8dd2-df459b85314c.png)
I found another issue same as mine but I can assure there is no variable accidentally named as 'tf' in my code as that issue suggests. I just try to build the model and no images or labels are feeded since both of them are set as tf.placeholder. It seems that such error emerges during the process of building computation graph for update ops. 
"
15647,Tensorflow.org - master version is not updated,"
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Not Relevant
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Not Relevant
- **TensorFlow installed from (source or binary)**: Not Relevant
- **TensorFlow version (use command below)**: Not Relevant
- **Python version**: Not Relevant
- **Bazel version (if compiling from source)**: Not Relevant
- **GCC/Compiler version (if compiling from source)**: Not Relevant
- **CUDA/cuDNN version**: Not Relevant
- **GPU model and memory**: Not Relevant
- **Exact command to reproduce**: Not Relevant

### Describe the problem
tensorflow.org master version should be updated to master, however it seems that it hasn't been regenerated for a while.

For example the latest addition of the performance guide for `tf.data` (https://github.com/tensorflow/tensorflow/commit/ba32ea1547af74d549f35a42e4de83c88652a636) hasn't yet made it to the website:

Doc source: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/performance/performance_guide.md

Generated web page in tensorflow.org (master version):
https://www.tensorflow.org/versions/master/performance/performance_guide

(Currently shows ""Last updated November 14, 2017."" in the bottom)

"
15645,Tensorflow lite 0.1.1 causing Build to fail,"I am trying to use tensrflow-lite in Android. When I add 

compile 'org.tensorflow:tensorflow-lite:0.1.1'

I get:

```
Error:Execution failed for task ':sample:transformClassesWithJarMergingForDebug'.
> com.android.build.api.transform.TransformException: java.util.zip.ZipException: duplicate entry: R.class
```

I am using multidex and AGP 2.3.3. 

When I take tensorflow-lite off, the app builds correctly. When I put it back, the build fails. I believe this is a bug in the library. "
15644,[Feature request] define axis in 'tf.unique()' and 'tf.unique_with_counts',"Hi, just a small feature request:
It would be cool if one could directly
* use 'tf.unique()' and 'tf.unique_with_counts' in n-dimensional arrays
* define an axis along which 'tf.unique()' and 'tf.unique_with_counts' are applied
"
15643,fp16 inference is slower than fp32 on Nvidia Jetson TX2,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: r1.5
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: Cuda 8.0 and cuDNN 7.0
- **GPU model and memory**: Jetson TX2

### The problem
I created a fully convolutional float 16 (half precision) neural network in tensorflow. When I run this network with some inputs, the inference time is slower than when I run the same network in float 32 (full precision) mode. 
I should also note that the following variables are set:

`
os.environ['TF_FP16_CONV_USE_FP32_COMPUTE'] = '0'
os.environ['TF_FP16_MATMUL_USE_FP32_COMPUTE'] = '0'
`

As Nvidia Jetson TX2 support FP16 operations, I expected an inference time not worse than when I use FP32, but surprisingly it is about 1.5 times worse! (36 miliseconds vs 22 miliseconds). I guess it is becuase of the overhead of internal type conversion in the tensorflow core between float16 and float32!

Is it a problem with Tensorflow or TX2?"
15642,contrib/all_reduce not update to latest nccl,"send_op, dst_tensors = nccl.broadcast(level_2_output[w], dst_devices)

this line is out of date, hope update to latest"
15641,Compile with selective register on meta file,"I want to apply the selective registration feature on my model to decrease the lib size. However, I need to apply it on a meta file saved via `saver` rather than a frozen pb file as shown in many posts I have found. When I try to run 

`bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=model_test.ckpt-390760.meta`

it comes to the error

`[libprotobuf ERROR external/protobuf/src/google/protobuf/wire_format_lite.cc:621] String field 'tensorflow.NodeDef.op' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes.`

I tried to add `--proto_fileformat=textproto` but another error comes up:

`raise self.ParseError('Expected identifier or number.')
google.protobuf.text_format.ParseError: 2:1 : Expected identifier or number.`

Is it even possible to do this at all? The ultimate goal of compiling this lib is to restore a pretrained model and incrementally train it on Android."
15638,PS:0 runs nothing but seizes the network in the distributed training,"   It's strange but I think is a bug in tensorflow. When I use multi machine as PS, I specify the operations in PS:* but not PS:0. And I not use the PS:0, but the variable transfer between the PS:* and PS:0. By the way, I  use the lenet5 about 1.6M parameters, but when iterating one time, the data between PS:* and PS:0 is 4.7M in the network using tcpdump to calculate it. I don't know why. The following is my main code in worker machine and PS server just run server.join().
https://github.com/niewuya/tensorflow-distributed-training/blob/master/code.py
I will appreciate your reply.

```python
import tensorflow as tf
slim = tf.contrib.slim

parameter_servers = [""172.16.101.248:2225"",""172.16.101.249:2225"",""172.16.101.105:2225""]
workers = [""172.20.110.94:2225""]
cluster = tf.train.ClusterSpec({""ps"": parameter_servers, ""worker"": workers})
server = tf.train.Server(
    cluster,
    job_name=""worker"",
    task_index=0)

def dataset_input_fn():
    buffer_size = 1024
    batch = 128
    num_epochs = 50
    filenames = ['../datasets/mnist/train.tfrecord']
    dataset = tf.data.TFRecordDataset(filenames)

    def parser(record):
        keys_to_features = {
            ""image/encoded"": tf.FixedLenFeature((), tf.string, default_value=""""),
            ""image/class/label"": tf.FixedLenFeature((), tf.int64,
                                                    default_value=tf.zeros([], dtype=tf.int64)),
        }
        parsed = tf.parse_single_example(record, keys_to_features)

        image = tf.image.decode_jpeg(parsed[""image/encoded""])
        image = tf.image.convert_image_dtype(image, dtype=tf.float32)
        image = tf.reshape(image, [28, 28, 1])
        label = tf.cast(parsed[""image/class/label""], tf.int32)
        label = slim.one_hot_encoding(label, 10)
        return image, label

    dataset = dataset.repeat()
    dataset = dataset.map(parser, num_parallel_calls=8)
    dataset = dataset.prefetch(buffer_size=batch)
    dataset = dataset.prefetch(buffer_size=buffer_size)
    dataset = dataset.shuffle(buffer_size)
    dataset = dataset.batch(batch)
    iterator = dataset.make_one_shot_iterator()
    images, labels = iterator.get_next()
    return images, labels

def lenet(images,labels,flag):
    num_classes = 10
    dropout_keep_prob = 0.5
    scope = tf.variable_scope(""lenet"", reuse=flag)
    with scope, slim.arg_scope([slim.conv2d, slim.fully_connected],
                               activation_fn=tf.nn.relu,
                               weights_initializer=tf.truncated_normal_initializer(stddev=0.1),
                               weights_regularizer=slim.l2_regularizer(0.0)):
        net = slim.conv2d(images, 20, [5, 5], scope='conv1_1')
        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_1')
        net = slim.conv2d(net, 50, [5, 5], scope='conv1_2')
        net = slim.max_pool2d(net, [2, 2], 2, scope='pool1_2')
        net = slim.flatten(net)
        net = slim.fully_connected(net, 500, scope='fc1_3')
        net = slim.dropout(net, dropout_keep_prob, scope='dropout1_3')
        logits = slim.fully_connected(net, num_classes, activation_fn=None, scope='fc1_4')
        loss = tf.losses.softmax_cross_entropy(
            logits=logits, onehot_labels=labels)
        loss = tf.reduce_mean(loss)
        optimizer = tf.train.AdagradOptimizer(0.01)
        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        grads = optimizer.compute_gradients(loss)
    return grads, accuracy, optimizer

with tf.Graph().as_default():
    with tf.device('/CPU:0'):
        all_grads = []
        with tf.device('/job:ps/task:2'):
            images, labels = dataset_input_fn()
            grads, accuracy_ps, optimizer =lenet(images,labels,False)

        all_grads.clear()
        all_grads.append(grads)
        train_op_all=[]
        for i, grad_and_vars in enumerate(zip(*all_grads)):
            grads = []
            for g, _ in grad_and_vars:
                g = tf.expand_dims(g, 0)
                grads.append(g)
            grad = tf.concat(axis=0, values=grads)
            grad = tf.reduce_mean(grad, 0)
            v = grad_and_vars[0][1]
            train_op_all.append(optimizer.apply_gradients([(grad, v)]))
        train_op=tf.group(*train_op_all)

    with tf.train.MonitoredTrainingSession(master=server.target,
                                               is_chief=True
                                           )as mon_sess:
        frequency=10
        for i in range(1000):
            _ ,accuracy= mon_sess.run([train_op,accuracy_ps])
            if i % frequency ==0 :
                print(""accuracy is :%f""%accuracy)
```"
15636,Read tflite file failed on iOS,"Hi

I tried the examples on iOS according to TF Lite guide, but failed when assign data to tflite because address ""out"" is NULL. probably my tflite file is incorrect, but I am not sure, can anybody give some help? 

My test step is as follows:
1.  Try the following code(https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite),  get the tflite file converteds_model.tflite

```
import tensorflow as tf
img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""converteds_model.tflite"", ""wb"").write(tflite_model)
```

2. Integrated the tflite into my app, which is from iOS sample code ""simple""(/Users/Sensteer/Software/tensorflowclone/tensorflow/tensorflow/contrib/lite/examples/ios/simple).But exception happed because address ""out"" is NULL

```
int input = interpreter->inputs()[0];                                 //input is 3
float* out = interpreter->typed_tensor<float>(input);          //out is NULL
```

So my questions are:
1. The tflite created above is right or not?
2. The reading tflite code is right or not?
2. If the tflite file is not right, do I must create tflite with  ""pb"", ""ckpt"" and ""FrozenGraphDef"" mentioned in guide?

Thanks
"
15635,Android: Op type not registered 'GatherTree' in binary running on localhost.,"-----------------------

# System information
- **OS Platform and Distribution : Linux Ubuntu 14.04
- **TensorFlow installed from source 
- **TensorFlow version 1.4.0
- **Python 2.7
- **Bazel version [bazel release 0.8.0]
- **GCC/Compiler version gcc version 4.9.4 (GCC)
- **CUDA/cuDNN (only for cpu)


# Describe the problem
Hi.  I have tried to load the rnn model inside Android that I generated from python for machine translation. When I want to use beam_search in decode I meet an (can't find ** op) error at Android. I have tried below solutions but the error is continue.
## solution 1:
use python script “tensorflow/python/tools/print_selective_registration_header.py” to create ""ops_to_register.h"", then copy it into ""tensorflow/core/framework/"", then generate ""//tensorflow/contrib/android:libtensorflow_inference.so""
### I change ""print_selective_registration_header.py"":
`parser.add_argument(
'--default_ops',
type=str,
#default='NoOp:NoOp,_Recv:RecvOp,_Send:SendOp',
 default='all',`
...)
### cmd like below:
`bazel build tensorflow/python/tools:print_selective_registration_header &&   bazel-bin/tensorflow/python/tools/print_selective_registration_header     --graphs=/path/to/my/model/decode-model_1213_real_model_with_beam.pb > ops_to_register.h`
`bazel build -c opt --copt=""-DSELECTIVE_REGISTRATION""     --copt=""-DSUPPORT_SELECTIVE_REGISTRATION""   //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a`

## solution 2:
I met the same type of mistake before, and with ""Op type not registered ListDiff"" error. I find ""listdiff_op.cc"" is at ""tensorflow/core/kernels"". Then I add a line at ""tensorflow/core/kernels/BUILD"", and re-generate libtensorflow_inference.so to solve that error. But the ""beam_search_ops.cc"" is at ""tensorflow/contrib/seq2seq/kernels"", when I add it like ""ListDiff"" it's still reporting that error at android studio.
### add line like below:
` filegroup(
name = ""android_extended_ops_group1"",
srcs = [
""listdiff_op.cc"",
#""//tensorflow/contrib/seq2seq/kernels/beam_search_ops.cc"",
...]
)
`

I need some help for solving this problem. thanks.

# Source code / logs
## error log at android studio:
`E/AndroidRuntime: FATAL EXCEPTION: main
                  Process: com.example.phua.mt_1201, PID: 20817
                  java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.phua.mt_1201/com.example.phua.mt_1201.MainActivity}: org.tensorflow.TensorFlowException: Op type not registered 'GatherTree' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.
                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2955)
                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3030)
                      at android.app.ActivityThread.-wrap11(Unknown Source:0)
                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1696)
                      at android.os.Handler.dispatchMessage(Handler.java:105)
                      at android.os.Looper.loop(Looper.java:164)
                      at android.app.ActivityThread.main(ActivityThread.java:6938)
                      at java.lang.reflect.Method.invoke(Native Method)
                      at com.android.internal.os.Zygote$MethodAndArgsCaller.run(Zygote.java:327)
                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1374)
                   Caused by: org.tensorflow.TensorFlowException: Op type not registered 'GatherTree' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.
                      at org.tensorflow.Graph.importGraphDef(Native Method)
                      at org.tensorflow.Graph.importGraphDef(Graph.java:118)
                      at org.tensorflow.Graph.importGraphDef(Graph.java:102)
                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:396)
                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:97)
                      at com.example.phua.mt_1201.tfonandroid.Loadmodel(tfonandroid.java:37)
                      at com.example.phua.mt_1201.MainActivity.onCreate(MainActivity.java:52)
                      at android.app.Activity.performCreate(Activity.java:7174)
                      at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1220)
                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2908)
                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3030) 
                      at android.app.ActivityThread.-wrap11(Unknown Source:0) 
                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1696) 
                      at android.os.Handler.dispatchMessage(Handler.java:105) 
                      at android.os.Looper.loop(Looper.java:164) 
                      at android.app.ActivityThread.main(ActivityThread.java:6938) `


"
15634,ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory with python 2.7,"Ubuntu 16.04
GPU: 1080 Ti
Cuda 9.0
CuDDN 7.0 v7
Using my PC, not a VM
Installed Intel MKL-DNN by this [guilde](https://github.com/mind/wheels#mkl), but looks like something wrong, because when trying to make a test for tensorflow, got error:

```
gagazet@woof:~/Desktop$` python 123.py 
Traceback (most recent call last):
  File ""123.py"", line 1, in <module>
    import tensorflow as tf
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```

Recently someone created same problem and it was closed with reason: PR [#12975](https://github.com/tensorflow/tensorflow/pull/12975), but it was for a VM.
Can anyone explain, please, what i can be and how to fix it? Dont have any build_pip_package scrips at the TF folder. 
Its doesnt looks like same problem as PR [#12975](https://github.com/tensorflow/tensorflow/pull/12975)
"
15633,[Question&Error] Is there detection model like a SSD-Mobile-net in tensorflow-lite?,"HI.

Developing an android application using tensorflow-lite.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md
Not found detection model.

Also, I try to convert SSD-Inceptionv2 using tensorflow-lite-API. But there seems to be a problem.

##Command
<pre><code>
bazel run --config=opt --copt=-msse4.1 --copt=-msse4.2 \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=/home/danshin/tensorflow_lite/lite_model/fire_incpetion_v2.pb \
  --output_file=/home/danshin/tensorflow_lite/lite_model/fire_inception_v2.lite \
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --input_shape=1,300,300,3 \
  --input_array=image_tensor \
  --output_array={detection_boxes,detection_scores,detection_classes,num_detections}
</code></pre>

##Error code
<pre><code>
2017-12-26 14:59:25.159220: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 2029 operators, 3459 arrays (0 quantized)
2017-12-26 14:59:25.251633: F tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_switch.cc:95] Check failed: other_op->type == OperatorType::kTensorFlowMerge 
</code></pre>

The fire_inception_v2 file is created, but its size is zero bytes.
What is a problem?


also,
**please let me know what's the best way to deploy custom model for object detection?**

Somebody help me plz!.

thank you."
15631,ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory,"GPU: 1080 Ti
cuda 9.0
cuddn 7.0 v7
centos 7.
installed Intel MKL-DNN but the error is still present.


here is the output:
````
ipython
Python 3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>()
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~/anaconda3/lib/python3.6/imp.py in load_module(name, file, filename, details)
    242         else:
--> 243             return load_dynamic(name, filename, file)
    244     elif type_ == PKG_DIRECTORY:

~/anaconda3/lib/python3.6/imp.py in load_dynamic(name, path, file)
    342             name=name, loader=loader, origin=path)
--> 343         return _load(spec)
    344 

ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-41389fad42b5> in <module>()
----> 1 import tensorflow as tf

~/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py in <module>()
     47 import numpy as np
     48 
---> 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

~/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     70 for some common reasons and solutions.  Include the entire stack trace
     71 above this error message when asking for help."""""" % traceback.format_exc()
---> 72   raise ImportError(msg)
     73 
     74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""/home/sb0709/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sb0709/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sb0709/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/sb0709/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/sb0709/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
`



"
15630,tf.name_scope does not work with tf.layers,"When I define a layer with
```
with tf.name_scope(""MY_SCOPE""):
    layer1 = tf.layers.dense(inputs = X,
                             units = 100,
                             kernel_initializer = he_init,
                             activation = tf.nn.elu,
                             name = ""layer1"")


```

and try to get its variables with

`tf.global_variables(scope=""MY_SCOPE"")`

it returns nothing because name scope did not apply to the layers from tf.layers

Shouldn't their name be

[<tf.Variable 'MY_SCOPE/layer1/kernel:0' shape=(784, 100) dtype=float32_ref>,
 <tf.Variable 'MY_SCOPE/layer1/bias:0' shape=(100,) dtype=float32_ref>]

instead of

[<tf.Variable 'layer1/kernel:0' shape=(784, 100) dtype=float32_ref>,
 <tf.Variable 'layer1/bias:0' shape=(100,) dtype=float32_ref>]

so that I can use my scope to reach my layers? This works with everything but tf.layers module."
15628,Support truly pluggable protocol/transport for distributed mode,"At this moment Distributed TensorFlow supports only one type of transport/protocol which is gRPC, however, it does seem to be configurable (cluster, server, session).

So, there are at least three things that need to be covered:
1. Document the intercommunication protocol (session to a server), i.e. what session sends to a server, what server should respond, etc. The good example here would some kind of swagger spec.
2. Make protocol configurable from Python.
3. Give all a Python interface to implement new types of protocols.

The whole idea is to let developers an ability to implement the protocol that would let distributed TensorFlow spin up and talk a number compute units (serverless, containers, VMs, etc.) instead of having a bunch of processes (cluster servers) running during computations within the session.

Please note, I wasn't able to find any corresponding issues related to given topic."
15627,Cannot compute output tensor of tf.keras.layers.Lambda + tf.unstack,"### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: tf-nightly 1.5.0-dev20171224
- **Python version**: 3.5.4

### Source code

This is a tiny code that creates a model which stacks and unpacks input tensors.

```python
import tensorflow as tf
from tensorflow.python import keras

x = [keras.layers.Input([2]) for _ in range(3)]
h = keras.layers.Lambda(lambda inputs: tf.stack(inputs, axis=1))(x)
y = keras.layers.Lambda(lambda inputs: tf.unstack(inputs, axis=1))(h)

model = keras.models.Model(x, y)
model.compile('adam', 'mse')
```

This code raises a `AssertionError`.

```
Traceback (most recent call last):
  File ""example.py"", line 9, in <module>
    model.compile('adam', 'mse')
  File "".../tf-nightly/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py"", line 681, in compile
    masks = self.compute_mask(self.inputs, mask=None)
  File "".../tf-nightly/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 787, in compute_mask
    _, output_masks = self._run_internal_graph(inputs, masks)
  File "".../tf-nightly/lib/python3.5/site-packages/tensorflow/python/layers/network.py"", line 927, in _run_internal_graph
    assert str(id(x)) in tensor_map, 'Could not compute output ' + str(x)
AssertionError: Could not compute output Tensor(""lambda_1/unstack:1"", shape=(?, 2), dtype=float32)
```"
15626,TensorFlowInferenceInterface's feed method - a performance bottleneck,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Compiled on macos 10.13.2, Observed on Android 
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: commit ab0fcaceda on master - between release of 1.4.0 and 1.4.1 (compared to 1.0.1)
- **Python version**: N/A (java android code)
- **Bazel version (if compiling from source)**: 0.7.0-homebrew
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Observed on a Huawei Nexus 6P
- **Exact command to reproduce**: N/A (java android code)

### Describe the problem
Following the move to Java API in commit 1a9769dc79fdd27c347633df210ff64f48de8d07, it seems that it is very ineffective to feed nodes.
I am feeding my model an input array of about 1100 floats, and when I sample CPU usage using CPU Profiler on Android Studio (Instrumented) it seems that the feed method takes ~x4 time than running the inference. If I leave everything the same but I use android libs compiled in tensorflow 1.0.1 CPU time of feed method (used to be fillNodeFloat) becomes negligible.
It seems that putting a float array into the Tensor's FloatBuffer is a very costly operation.

### Source code / logs
**TF 1.4.0:**
Relevant inference code:
```
tensorflow.feed(INPUT_NODE_NAME, input, shape);
tensorflow.run(OUTPUT_NAMES);
tensorflow.fetch(OUTPUT_NAMES[0], output);
```

Screenshot of CPU Profiler's call chart: https://www.dropbox.com/s/nx5q730l0fbd05x/TF_1.4_CallChart.png?dl=0
Screenshot of CPU Profiler's top-down breakdown of the 2 methods: https://www.dropbox.com/s/gh9vza3jmb5uzrn/TF_1.4_TopDown.png?dl=0

**TF 1.0.1:**
Relevant inference code:
```
tensorflow.fillNodeFloat(INPUT_NODE_NAME, shape, input);
tensorflow.runInference(OUTPUT_NAMES);
tensorflow.readNodeFloat(OUTPUT_NAMES[0], output);
```

Screenshot of CPU Profiler's call chart: https://www.dropbox.com/s/jrl2ggnsncx97ry/TF_1.0.x_CallChart.png?dl=0
Screenshot of CPU Profiler's bottom-up breakdown of the 2 methods: https://www.dropbox.com/s/tz5ldp4qnavhx17/TF_1.0.x_BottomUp.png?dl=0"
15625,cross compile tensorflow C++ API for armeabi-v7a runtime erreors,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS Sierra 10.13.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.3
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**:0.9.0-homebrew
- **GCC/Compiler version (if compiling from source)**:4.2.1
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
i follow tensorflow/contrib/makefile/README.md to compile static library and there are two *.a file under tensorflow/contrib/makefile/gen. but when i link those two libs with my test application (Android Application with Cmake), there ara some errors.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Error:error: undefined reference to 'google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)'
Error:error: undefined reference to 'google::protobuf::UnknownFieldSet::MergeFrom(google::protobuf::UnknownFieldSet const&)'
Error:error: ld returned 1 exit status"
15624,Problem with tf.data.Dataset managing shapes of sparse tensors,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 16.04.3 LTS (Xenial Xerus)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171224
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A

### Describe the problem
The tf-1.5-dev supports `tf.SparseTensor` when using `tf.data.Dataset.from_tensor_slices`, but it cannot infer the shape of new tensor after some operations such as `tf.data.Dataset.map`.

The shape of tensor becomes `Unknown`, which is troublesome for downstream operations. For example, we have to call `set_shape()` if we want to feed the new tensor into a `tf.layers.dense`.

### Source code / logs
<pre>
import tensorflow as tf
x = tf.SparseTensor([[0,0],[1,1],[2,2]], [1,1,1], dense_shape=[3,3])
ds = tf.data.Dataset.from_tensor_slices(x)
ds.output_shapes   # TensorShape([Dimension(3)])
ds = ds.map(lambda x: tf.sparse_tensor_to_dense(x))
ds = ds.batch(1)
ds.output_shapes   # TensorShape([Dimension(None), Dimension(None)])

iterator = ds.make_one_shot_iterator()
next_elem = iterator.get_next()   # TensorShape([Dimension(None), Dimension(None)])

y = tf.layers.dense(next_elem, 100)
ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.

</pre>
@mrry "
15623,"I cannot use Binomial.sample(), could you please help me?","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15622,Unable to compile from source on High Sierra (10.13.2) with bazel 0.9.0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.2
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: tf 1.4
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.9.0
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **Exact command to reproduce**: bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=- msse4.1 --copt=-msse4.2 --config=opt -k //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
I'm unable to compile tensorflow from source. I get too many errors as shown below in the logs:

### Source code / logs
```
Rakshiths-MacBook-Pro:tensorflow rakshithgb$ ./configure
WARNING: Running Bazel server needs to be killed, because the startup options are different.
You have bazel 0.9.0-homebrew installed.
Please specify the location of python. [Default is /Users/rakshithgb/miniconda3/bin/python]: 


Found possible Python library paths:
  /Users/rakshithgb/miniconda3/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/Users/rakshithgb/miniconda3/lib/python3.6/site-packages]

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL support? [y/N]: n
No OpenCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 


Add ""--config=mkl"" to your bazel command to build with MKL support.
Please note that MKL on MacOS or windows is still not supported.
If you would like to use a local MKL instead of downloading, please set the environment variable ""TF_MKL_ROOT"" every time before build.
Configuration finished
Rakshiths-MacBook-Pro:tensorflow rakshithgb$ bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=- msse4.1 --copt=-msse4.2 --config=opt -k //tensorflow/tools/pip_package:build_pip_package
..............
ERROR: Skipping 'msse4.1': no such target '//:msse4.1': target 'msse4.1' not declared in package '' defined by /Users/rakshithgb/Documents/Tensorflow/tensorflow/BUILD
WARNING: Target pattern parsing failed.
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/local_config_sycl/sycl/BUILD:4:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/local_config_sycl/sycl/BUILD:6:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/local_config_sycl/sycl/BUILD:30:9: Traceback (most recent call last):
	File ""/private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/local_config_sycl/sycl/BUILD"", line 27
		cc_library(name = ""syclrt"", srcs = [sycl_libr..."")], <3 more arguments>)
	File ""/private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/local_config_sycl/sycl/BUILD"", line 30, in cc_library
		sycl_library_path
name 'sycl_library_path' is not defined
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/local_config_sycl/sycl/BUILD:39:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:98:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:100:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:102:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:104:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:106:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:108:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:110:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:112:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:114:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:116:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:118:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:120:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:122:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:124:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:126:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:131:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:136:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:141:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:146:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:151:1: name 're2_test' is not defined (did you mean 'ios_test'?)
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/bitmap256.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/bitstate.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/compile.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/dfa.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/filtered_re2.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/mimics_pcre.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/nfa.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/onepass.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/parse.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/perl_groups.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/prefilter.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/prefilter.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/prefilter_tree.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/prefilter_tree.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/prog.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/prog.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/re2.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/regexp.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/regexp.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/set.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/simplify.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/stringpiece.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/tostring.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/unicode_casefold.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/unicode_casefold.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/unicode_groups.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/unicode_groups.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/walker-inl.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/flags.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/logging.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/mix.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/mutex.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/rune.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/sparse_array.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/sparse_set.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/strutil.cc' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/strutil.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/utf.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:util/util.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/filtered_re2.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/re2.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/set.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /private/var/tmp/_bazel_rakshithgb/fde7bc60972656b0c2db4fd0b79e24fb/external/com_googlesource_code_re2/BUILD:11:1: Target '@com_googlesource_code_re2//:re2/stringpiece.h' contains an error and its package is in error and referenced by '@com_googlesource_code_re2//:re2'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/platform/default/build_config/BUILD:115:1: Target '@com_googlesource_code_re2//:re2' contains an error and its package is in error and referenced by '//tensorflow/core/platform/default/build_config:platformlib'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/third_party/eigen3/BUILD:20:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//third_party/eigen3:eigen3'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3169:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:pooling_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3798:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:variable_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:717:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:compare_and_bitpack_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3776:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:scatter_nd_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3764:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:dense_update_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:643:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:gather_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:607:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:bitcast_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:619:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:constant_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:625:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:diag_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:631:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:edit_distance_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:687:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:mirror_pad_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:711:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:quantize_and_dequantize_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:787:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:split_v_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:774:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:slice_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3770:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:scatter_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:3758:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:count_up_to_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/BUILD:2215:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//tensorflow/core:sycl_runtime'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:780:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:split_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:681:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:matrix_set_diag_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:601:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:bcast_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:756:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:reverse_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:699:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:pack_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:813:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:transpose_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:705:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:pad_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:693:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:one_hot_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:649:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:identity_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:661:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:listdiff_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:533:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:immutable_constant_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:655:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:identity_n_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:613:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:concat_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:675:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:matrix_diag_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:839:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:where_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:762:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:reverse_sequence_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:794:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:inplace_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:827:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:unique_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:768:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:shape_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:667:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:matrix_band_part_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:637:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:gather_nd_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:750:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:reshape_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:800:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:tile_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:833:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:unpack_op'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/core/kernels/BUILD:550:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '//tensorflow/core/kernels:debug_ops'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/tools/pip_package/BUILD:101:1: Target '@com_googlesource_code_re2//:LICENSE' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:licenses'
ERROR: /Users/rakshithgb/Documents/Tensorflow/tensorflow/tensorflow/tools/pip_package/BUILD:101:1: Target '@local_config_sycl//sycl:LICENSE.text' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:licenses'
WARNING: errors encountered while analyzing target '//tensorflow/tools/pip_package:build_pip_package': it will not be built
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (204 packages loaded).
INFO: Found 0 targets...
ERROR: command succeeded, but there were errors parsing the target pattern
INFO: Elapsed time: 51.902s, Critical Path: 0.02s
FAILED: Build did NOT complete successfully
```


"
15621,Errors_impl-NotFoundError-Undefined symbol-fused_conv2d_bias_activation_op,"**What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?**
None.

### System information
- **Operating System**: CentOS 7.3
- **Linux Kernel**: 3.10.0-514
- **TensorFlow installed from source**: https://github.com/tensorflow/tensorflow/
- **TensorFlow version**: 1.4.0
- **Python version**: Python 2.7.5
- **The output of bazel version**:
```
Build target: bazel-out/k8-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Jan 01 00:00:00 1970 (0)
Build timestamp: Thu Jan 01 00:00:00 1970 (0)
Build timestamp as int: 0
```
- **GCC/Compiler version (if compiling from source)**: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
- **CUDA/cuDNN version**: cuda 8.0/cudnn 7.0
- **GPU model and memory**: NVIDA Tesla P4

### Describe the problem
When exec fused_conv2d_bias_activation_op.py or import the package using `import tensorflow.contrib.fused_conv.python.ops` ，'undefined symbol' error occurs

The source code file path is https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/fused_conv/python/ops/fused_conv2d_bias_activation_op.py

The output of `python fused_conv2d_bias_activation_op_test.py` is as follows:
`tensorflow.python.framework.errors_impl.NotFoundError: /usr/lib/python2.7/site-packages/tensorflow/contrib/fused_conv/python/ops/_fused_conv2d_bias_activation_op.so: undefined symbol: _ZN10tensorflow7functor8PadInputIN5Eigen9GpuDeviceEiiLi4EEclERKS3_NS2_9TensorMapINS2_6TensorIKiLi4ELi1EiEELi16ENS2_11MakePointerEEERKSt5arrayIiLm2EESG_NS7_INS8_IiLi4ELi1EiEELi16ESB_EENS_12TensorFormatE`

It seems that something wrong when loading Eigen library

### The other logs
The output of `objdump -t /usr/lib/python2.7/site-packages/tensorflow/contrib/fused_conv/python/ops/_fused_conv2d_bias_activation_op.so | grep UND | grep Eigen` is as follows:
`0000000000000000       F *UND*  0000000000000000              _ZN10tensorflow25BrainPadding2EigenPaddingENS_7PaddingE
0000000000000000         *UND*  0000000000000000              _ZN10tensorflow7functor8PadInputIN5Eigen9GpuDeviceEiiLi4EEclERKS3_NS2_9TensorMapINS2_6TensorIKiLi4ELi1EiEELi16ENS2_11MakePointerEEERKSt5arrayIiLm2EESG_NS7_INS8_IiLi4ELi1EiEELi16ESB_EENS_12TensorFormatE
0000000000000000         *UND*  0000000000000000              _ZN10tensorflow7functor8PadInputIN5Eigen9GpuDeviceEfiLi4EEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi4ELi1EiEELi16ENS2_11MakePointerEEERKSt5arrayIiLm2EESG_NS7_INS8_IfLi4ELi1EiEELi16ESB_EENS_12TensorFormatE
0000000000000000       F *UND*  0000000000000000              _ZNK10tensorflow15OpKernelContext12eigen_deviceIN5Eigen9GpuDeviceEEERKT_v
0000000000000000         *UND*  0000000000000000              _ZN5Eigen8internal14TensorExecutorIKNS_14TensorAssignOpINS_9TensorMapINS_6TensorIfLi4ELi1EiEELi16ENS_11MakePointerEEEKNS_17TensorReshapingOpIKNS_6DSizesIiLi4EEEKNS_17TensorShufflingOpIKNS9_IiLi3EEEKNS8_ISE_KNS3_INS4_IKfLi4ELi1EiEELi16ES6_EEEEEEEEEENS_9GpuDeviceELb0EE3runERSQ_RKSR_
0000000000000000         *UND*  0000000000000000              _ZN10tensorflow7functor10NHWCToNCHWIN5Eigen9GpuDeviceEfLi4EEclERKS3_NS2_9TensorMapINS2_6TensorIKfLi4ELi1ElEELi16ENS2_11MakePointerEEENS7_INS8_IfLi4ELi1ElEELi16ESB_EE`
"
15620,Tf Lite only support 4D l2_normalize?,"I build some feature extract network model and converted tflite using by toco successfully.
But I got error `""tensorflow/contrib/lite/kernels/l2norm.cc:47 NumDimensions(input) != 4 (2 != 4)`, when run interpreter->AllocateTensors().

I extract feature using by tf.nn.l2_normalize.
`embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name='embeddings')`
where prelogits is 2D tensor.
How can I extract normalized feature with tflite?
"
15619,Crelu should have axis,"Currently, the `tf.nn.crelu` activation concatenates along the last axis. This would work fine for dense layers and conv layers where the `data_fromat=channels_last`, but this would be incorrect if invoked on the widely used `data_format=channels_first` for conv layers on the GPU.
"
15618,Tensorflow does not build in a python3 only environment,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Fedora 27
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
0.8.1
- **GCC/Compiler version (if compiling from source)**:
Using built-in specs.
COLLECT_GCC=/usr/bin/gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/7/lto-wrapper
OFFLOAD_TARGET_NAMES=nvptx-none
OFFLOAD_TARGET_DEFAULT=1
Target: x86_64-redhat-linux
Configured with: ../configure --enable-bootstrap --enable-languages=c,c++,objc,obj-c++,fortran,ada,go,lto --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared --enable-threads=posix --enable-checking=release --enable-multilib --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-gcc-major-version-only --with-linker-hash-style=gnu --enable-plugin --enable-initfini-array --with-isl --enable-libmpx --enable-offload-targets=nvptx-none --without-cuda-driver --enable-gnu-indirect-function --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux
Thread model: posix
gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC) 
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:

export LANG=""en_US.UTF-8""
export PYTHON_BIN_PATH=""/usr/bin/python3""
export PYTHON_LIB_PATH=""/usr/lib64/python3.6/site-packages""
export TF_NEED_JEMALLOC=""1""
export TF_NEED_S3=""0""
export TF_NEED_GCP=""0""
export TF_NEED_OPENCL=""0""
export TF_ENABLE_XLA=""0""
export TF_NEED_GDR=""0""
export TF_NEED_VERBS=""0""
export TF_NEED_MPI=""0""
export TF_NEED_CUDA=""0""
export TF_NEED_HDFS=""0""
export CC_OPT_FLAGS=""-march=native""
./configure

bazel build --action_env PATH=""$PATH"" --verbose_failures //tensorflow/tools/pip_package:build_pip_package


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When building tensorflow in an environment with only python3 (e.g. no /usr/bin/python but instead /usr/bin/python3) build fails.  As this is likely to become increasingly the case as other distributions drop python2.7 from default installs (and, eventually drop it altogether), this ought to be addressed.

### Source code / logs

ERROR: /builddir/build/BUILD/tensorflow-1.4.1/tensorflow/python/BUILD:4363:1: Executing genrule //tensorflow/python:framework_fast_tensor_util_cython_translation failed (Exit 127): bash failed: error executing command 
  (cd /builddir/.cache/bazel/_bazel_mockbuild/88de5ec7248fb8215eb84aeff796b606/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/sbin:/builddir/.local/bin:/builddir/bin \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib64/python3.6/site-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; PYTHONHASHSEED=0 bazel-out/host/bin/external/cython/cython_binary --cplus tensorflow/python/framework/fast_tensor_util.pyx && python -c '\''import shutil, sys; n = len(sys.argv); [shutil.copyfile(src.split(""."")[0] + "".cpp"", dst) for src, dst in zip(sys.argv[1:], sys.argv[1+n//2:])]'\'' tensorflow/python/framework/fast_tensor_util.pyx bazel-out/k8-py3-opt/genfiles/tensorflow/python/framework/fast_tensor_util.cpp')
/usr/bin/env: 'python': No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 575.085s, Critical Path: 26.26s
FAILED: Build did NOT complete successfully

"
15613,Tensorflow doesn't show the Cuda import messages ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15611,'saved_model_cli.py' bug fix!,"In file `python/tools/saved_model_cli.py`  at function `def _print_tensor_info(tensor_info):`
The first line should be:

 `  print('    dtype: ' + {value:key for (key,value) in types_pb2.DataType.items()}[tensor_info.dtype])`

Not be : ` print('    dtype: ' + types_pb2.DataType.keyss()[tensor_info.dtype])`

because `tensor_info.dtype`  is an Integer which is the value of types(not the index of type values)."
15610,Cannot load pretrained models in Android via jcenter-provided library,"It's a great step to support importing Android lib via jcenter. However, I'm having trouble in loading pretrained models into `TensorFlowInferenceInterface`, which says `NodeDef mentions attr 'dilations' not in Op...`. I think it's a compatibility issue, meaning that the model graph is not consistent with the graph interpreter. The models directly downloaded from `slim` and frozen by myself. Anyone can help me?"
15609,The relationship between neural network depth and accuracy,"Hi:
I am learning to design a simple neural network, and try to identify 28x28 pixel greyscale images in the MNIST dataset.
I find that the neural network depth is not directly proportional to the recognition rate,

one layer neural network recognition rate: 92%
two layer neural network recognition rate: 94%
four layer neural network recognition rate: 91.8%

Can someone help me analyze it?
![6](https://user-images.githubusercontent.com/31270354/34325172-85768d48-e8c5-11e7-831a-6d11b9b02bf5.PNG)
(Please click on the picture to see the complete picture information)

**thank you very much!**"
15604,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,"I installed tf-nightly build and I get the following error on import of tensorflow.
`ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory`.

If I check for cuda 9, I get the following:
```
ldconfig -v
/usr/local/cuda-8.0/targets/x86_64-linux/lib:
	libnvgraph.so.8.0 -> libnvgraph.so.8.0.61
	libnppicom.so.8.0 -> libnppicom.so.8.0.61
	libnppial.so.8.0 -> libnppial.so.8.0.61
	libcufftw.so.8.0 -> libcufftw.so.8.0.61
	libcufft.so.8.0 -> libcufft.so.8.0.61
	libnppif.so.8.0 -> libnppif.so.8.0.61
	libcublas.so.8.0 -> libcublas.so.8.0.88
	libnvblas.so.8.0 -> libnvblas.so.8.0.88
	libnppi.so.8.0 -> libnppi.so.8.0.61
	libcusolver.so.8.0 -> libcusolver.so.8.0.61
	libnppidei.so.8.0 -> libnppidei.so.8.0.61
	libnvrtc-builtins.so.8.0 -> libnvrtc-builtins.so.8.0.61
	libnvrtc.so.8.0 -> libnvrtc.so.8.0.61
	libnpps.so.8.0 -> libnpps.so.8.0.61
	libcuinj64.so.8.0 -> libcuinj64.so.8.0.61
	libnppig.so.8.0 -> libnppig.so.8.0.61
	libOpenCL.so.1 -> libOpenCL.so.1.0.0
	libnppicc.so.8.0 -> libnppicc.so.8.0.61
	libnppist.so.8.0 -> libnppist.so.8.0.61
	libnppisu.so.8.0 -> libnppisu.so.8.0.61
	libnppim.so.8.0 -> libnppim.so.8.0.61
	libcurand.so.8.0 -> libcurand.so.8.0.61
	libcudart.so.8.0 -> libcudart.so.8.0.61
	libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0
	libnppitc.so.8.0 -> libnppitc.so.8.0.61
	libnppc.so.8.0 -> libnppc.so.8.0.61
	libcusparse.so.8.0 -> libcusparse.so.8.0.61
/usr/local/cuda-9.1/targets/x86_64-linux/lib:
	libnppicc.so.9.1 -> libnppicc.so.9.1.85
	libnppisu.so.9.1 -> libnppisu.so.9.1.85
	libcufftw.so.9.1 -> libcufftw.so.9.1.85
	libcufft.so.9.1 -> libcufft.so.9.1.85
	libnppial.so.9.1 -> libnppial.so.9.1.85
	libnppist.so.9.1 -> libnppist.so.9.1.85
	libcublas.so.9.1 -> libcublas.so.9.1.85
	libnvblas.so.9.1 -> libnvblas.so.9.1.85
	libnppitc.so.9.1 -> libnppitc.so.9.1.85
	libcusolver.so.9.1 -> libcusolver.so.9.1.85
	libnvrtc.so.9.1 -> libnvrtc.so.9.1.85
	libnvrtc-builtins.so.9.1 -> libnvrtc-builtins.so.9.1.85
	libnppidei.so.9.1 -> libnppidei.so.9.1.85
	libOpenCL.so.1 -> libOpenCL.so.1.0.0
	libnppig.so.9.1 -> libnppig.so.9.1.85
	libnppc.so.9.1 -> libnppc.so.9.1.85
	libcudart.so.9.1 -> libcudart.so.9.1.85
	libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0
	libnvgraph.so.9.1 -> libnvgraph.so.9.1.85
	libnppif.so.9.1 -> libnppif.so.9.1.85
	libcusparse.so.9.1 -> libcusparse.so.9.1.85
	libaccinj64.so.9.1 -> libaccinj64.so.9.1.85
	libcuinj64.so.9.1 -> libcuinj64.so.9.1.85
	libnppim.so.9.1 -> libnppim.so.9.1.85
	libnppicom.so.9.1 -> libnppicom.so.9.1.85
	libnpps.so.9.1 -> libnpps.so.9.1.85
	libcurand.so.9.1 -> libcurand.so.9.1.85
```
I that due to a name mismatch. `libcublas.so.9.0 =! libcublas.so.9.1`? And if so how can we overcome this?"
15589,Segmentation fault on get_session_handle after 1.4.1 upgrade,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 (from 1.4.1 pip install)
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**: N/a
- **GCC/Compiler version (if compiling from source)**: N/a
- **CUDA/cuDNN version**: N/a
- **GPU model and memory**: N/a
- **Exact command to reproduce**: 

After upgrading from 1.3 to 1.4.1, running the following code produces a segmentation fault:

```
import tensorflow as tf

with tf.Session() as S: S.run( tf.get_session_handle(tf.constant(1, dtype=tf.float32)) )
```


### Source code / logs

GDB stack traces:

```
(gdb) py-bt 
0x00007fffb765b307 in nsync::nsync_mu_lock(nsync::nsync_mu_s_*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
(gdb) py-bt
#22 Frame 0xfea2d0, for file /usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py, line 1302, in _run_fn (session=<SwigPyObject at remote 0x7fff6e664330>, feed_dict={}, fetch_list=['GetSessionHandle:0'], target_list=[], options=None, run_metadata=None, status=<SwigPyObject at remote 0x7fff6e670f00>)
    status, run_metadata)
#27 Frame 0xff8a00, for file /usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py, line 1323, in _do_call (self=<Session(_config=None, _graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={}, _name_stack='', _gradient_override_map={}, _seed=None, _handle_movers={}, _op_to_kernel_label_map={}, _nodes_by_id={1: <Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fffeb2f2150>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=1) at remote 0x7ffff377d950>, _consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fff6e612810>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=7) at remote 0x7ffff377db10>, _consumers=[], _id=1L) at remote 0x7fff6e612750>], _control_flow_context=None, _id_value=2, _original_op=None, _traceback=[('minimal_core_dump.py', 3, '<module>', {'__builtins__': <module at remote 0x7ffff7f9ab08>, '__fi...(truncated)
    return fn(*args)
#31 Frame 0xfe2fe0, for file /usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py, line 1317, in _do_run (self=<Session(_config=None, _graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={}, _name_stack='', _gradient_override_map={}, _seed=None, _handle_movers={}, _op_to_kernel_label_map={}, _nodes_by_id={1: <Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fffeb2f2150>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=1) at remote 0x7ffff377d950>, _consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fff6e612810>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=7) at remote 0x7ffff377db10>, _consumers=[], _id=1L) at remote 0x7fff6e612750>], _control_flow_context=None, _id_value=2, _original_op=None, _traceback=[('minimal_core_dump.py', 3, '<module>', {'__builtins__': <module at remote 0x7ffff7f9ab08>, '__fil...(truncated)
    options, run_metadata)
#35 Frame 0xf12bc0, for file /usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py, line 1120, in _run (self=<Session(_config=None, _graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={}, _name_stack='', _gradient_override_map={}, _seed=None, _handle_movers={}, _op_to_kernel_label_map={}, _nodes_by_id={1: <Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fffeb2f2150>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=1) at remote 0x7ffff377d950>, _consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fff6e612810>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=7) at remote 0x7ffff377db10>, _consumers=[], _id=1L) at remote 0x7fff6e612750>], _control_flow_context=None, _id_value=2, _original_op=None, _traceback=[('minimal_core_dump.py', 3, '<module>', {'__builtins__': <module at remote 0x7ffff7f9ab08>, '__file__...(truncated)
    feed_dict_tensor, options, run_metadata)
#39 Frame 0xfa91e0, for file /usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py, line 889, in run (self=<Session(_config=None, _graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={}, _name_stack='', _gradient_override_map={}, _seed=None, _handle_movers={}, _op_to_kernel_label_map={}, _nodes_by_id={1: <Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fffeb2f2150>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=1) at remote 0x7ffff377d950>, _consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_op=<...>, _shape=<TensorShape(_dims=[]) at remote 0x7fff6e612810>, _handle_data=None, _value_index=0, _dtype=<DType(_type_enum=7) at remote 0x7ffff377db10>, _consumers=[], _id=1L) at remote 0x7fff6e612750>], _control_flow_context=None, _id_value=2, _original_op=None, _traceback=[('minimal_core_dump.py', 3, '<module>', {'__builtins__': <module at remote 0x7ffff7f9ab08>, '__file__':...(truncated)
    run_metadata_ptr)
#43 Frame 0x7ffff7f4da00, for file minimal_core_dump.py, line 3, in <module> ()
    with tf.Session() as S: S.run( tf.get_session_handle(tf.constant(1, dtype=tf.float32)) )
```


```
(gdb) bt  
#0  0x00007fffb765b307 in nsync::nsync_mu_lock(nsync::nsync_mu_s_*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007fffb494de1f in tensorflow::SessionState::GetNewId() () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#2  0x00007fffb636bd24 in tensorflow::GetSessionHandleOp::Compute(tensorflow::OpKernelContext*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fffb7852729 in tensorflow::grappler::ConstantFolding::EvaluateNode(tensorflow::NodeDef const&, tensorflow::gtl::InlinedVector<tensorflow::TensorValue, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorValue, 4>*) const () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fffb7858a03 in tensorflow::grappler::ConstantFolding::EvaluateOneFoldable(tensorflow::NodeDef const&, std::vector<tensorflow::NodeDef, std::allocator<tensorflow::NodeDef> >*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007fffb7859486 in tensorflow::grappler::ConstantFolding::FoldNode(tensorflow::NodeDef*, tensorflow::GraphDef*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fffb785ab03 in tensorflow::grappler::ConstantFolding::FoldGraph(tensorflow::GraphDef*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fffb785b526 in tensorflow::grappler::ConstantFolding::RunOptimizationPass(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007fffb785b9c9 in tensorflow::grappler::ConstantFolding::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007fffb7843657 in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007fffb7844925 in tensorflow::grappler::RunMetaOptimizer(tensorflow::grappler::GrapplerItem const&, tensorflow::RewriterConfig const&, tensorflow::DeviceBase*, tensorflow::grappler::Cluster*, tensorflow::GraphDef*)
    () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007fffb782f316 in tensorflow::GraphExecutionState::OptimizeGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007fffb782fe80 in tensorflow::GraphExecutionState::BuildGraph(tensorflow::BuildGraphOptions const&, std::unique_ptr<tensorflow::ClientGraph, std::default_delete<tensorflow::ClientGraph> >*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007fffb76678ae in tensorflow::DirectSession::CreateGraphs(tensorflow::BuildGraphOptions const&, std::unordered_map<std::string, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> >, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, std::unique_ptr<tensorflow::Graph, std::default_delete<tensorflow::Graph> > > > >*, std::unique_ptr<tensorflow::FunctionLibraryDefinition, std::default_delete<tensorflow::FunctionLibraryDefinition> >*, tensorflow::DirectSession::RunStateArgs*, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*, tensorflow::gtl::InlinedVector<tensorflow::DataType, 4>*)
    () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007fffb7669daa in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#15 0x00007fffb766b5bb in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#16 0x00007fffb5d5e0fa in TF_Run_Helper(tensorflow::Session*, char const*, TF_Buffer const*, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, TF_Tensor**, std::vector<std::string, std::allocator<std::string> > const&, TF_Buffer*, TF_Status*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#17 0x00007fffb5d5e434 in TF_Run () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#18 0x00007fffb5a7c9da in tensorflow::TF_Run_wrapper_helper(TF_DeprecatedSession*, char const*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#19 0x00007fffb5a7cdd1 in tensorflow::TF_Run_wrapper(TF_DeprecatedSession*, TF_Buffer const*, _object*, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, TF_Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#20 0x00007fffb5a410b1 in _wrap_TF_Run () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#21 0x00000000004c7f54 in call_function (oparg=<optimized out>, pp_stack=0x7fffffffd1a0) at ../Python/ceval.c:4020
#22 PyEval_EvalFrameEx (
    f=f@entry=Frame 0xfea2d0, for file /usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py, line 1302, in _run_fn (session=<SwigPyObject at remote 0x7fff6e664330>, feed_dict={}, fetch_list=['GetSessionHandle:0'], target_list=[], options=None, run_metadata=None, status=<SwigPyObject at remote 0x7fff6e670f00>), throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#23 0x00000000004704ea in PyEval_EvalCodeEx (closure=<optimized out>, defcount=<optimized out>, defs=0x0, kwcount=<optimized out>, kws=<optimized out>, argcount=<optimized out>, args=<optimized out>, locals=0x0,
    globals=<optimized out>, co=<optimized out>) at ../Python/ceval.c:3252
#24 function_call.15337 (func=<optimized out>, arg=<optimized out>, kw=<optimized out>) at ../Objects/funcobject.c:526
#25 0x00000000004c9aa5 in PyObject_Call (kw=0x0, arg=(<SwigPyObject at remote 0x7fff6e664330>, {}, ['GetSessionHandle:0'], [], None, None), func=<function at remote 0x7fff6e610d70>) at ../Objects/abstract.c:2529
#26 ext_do_call (nk=<optimized out>, na=<optimized out>, flags=<optimized out>, pp_stack=0x7fffffffd3e0, func=<function at remote 0x7fff6e610d70>) at ../Python/ceval.c:4333
... # partial output
```
"
15588,Tensorflow crashes on AVX512 systems (Core i9 / Xeon etc),"(for now, placeholder for notes while investigating)
using the r1.5 branch (but 1.4 and earlier have the same issues)

Tensorflow crashes when compiled for AVX512. The cause is a misalignment exception; AVX512 has a 64 byte natural alignment, and Eigen and others often use instructions that explicitly fault on misaligned loads.

tensorflow/core/framework/allocator.h has this code
class Allocator {
 public:
#ifdef EIGEN_VECTORIZE_AVX512
  // Align to 64 byte boundary.
  static constexpr size_t kAllocatorAlignment = 64;
#else
  // Align to 32 byte boundary.
  static constexpr size_t kAllocatorAlignment = 32;
#endif


which implies that at least this allocator tries to do the right thing, however it seems EIGEN_VECTORIZE_AVX512 is not properly defined (in cpp meaning) at this place, because when adding an #error in the 32 byte alignment case, the #error hits, so the 64 bit alignment case is not used.

This is not the only case; brute forcing the 32 to be 64 still faults in misalignment... just later on in a different place.

"
15587,lite model file size,"how to reduce my model size(my own trained tensorflow model )
i want to use tensorflow lite converter get a smaller tflite file, but the tflite file has the same size with my trained model,
-------------------------------------------------------------------------

bazel-bin/tensorflow/contrib/lite/toco/toco \
  --allow_custom_ops \
  --input_file=/data/log/frozen_model.pb --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \
  --output_file=/data/log//mobilenet.tflite --inference_type=FLOAT \
  --input_data_types=FLOAT --input_arrays=input \
  --output_arrays=output --input_shapes=1,224,224,3

--------------------------------------------------------------------------"
15585,FP16 slower than FP32,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Partly
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
RHEL 7
- **TensorFlow installed from (source or binary)**:
unknown
- **TensorFlow version (use command below)**:
('unknown', '1.4.0')
- **Python version**: 
python2.7
- **Bazel version (if compiling from source)**:
unknown
- **GCC/Compiler version (if compiling from source)**:
gcc 4.8
- **CUDA/cuDNN version**:
9.0 / 7.0
- **GPU model and memory**:
Pascal P-100
- **Exact command to reproduce**:
N/A

### Describe the problem
I tried running the tutorial/rnn/ptb and tutorial/images/mnist examples with the --use_fp16 option, to see if speedup was achievable by utilizing the new half-precision features.
It turned out that a single training step for MNIST with FP32 took 3.3ms, with FP16 it was 4ms. For PTB small (I had to use lstm_cell=basic, because other types are not yet supported in FP16), the WPS dropped from 24000 to 22000 when switching to FP16.

So the performance **decreases** when using FP16 in real-world examples.

To check this, I've created a small benchmark for myself (since I can't get the nightly tf build on my machine, I can't run the official benchmarks), which is basically one big matrix multiplication in Tensorflow.

I've run it with square matrices with a width of 8k, 16k and 32k. In each case, FP16 and FP32 yielded nearly the same runtime. Profiling with nvprof I found out that the used CUDA function is **maxwell_fp16_segmemm_fp16_128x128_nn** for FP16 and **sgemm_128x128x8_NN_vec** for FP32.

Since I wanted to double check if matrix multiplication in FP16 is really slower than in FP32 on my GPU, I tried to directly benchmark the GPU using cuBlas with a similar operation. It turns out that here, FP16 is nearly twice as fast as FP32. CuBlas internally uses **maxwell_hgemm_256x128_nn** for matrix multiplication of 16k x 16k square matrices in FP16. (again  according to the nvprof profiler)

So I'm wondering why Tensorflow is unable to achieve similar results in terms of speed, or if I'm doing something wrong in my tests.

### Source code

Tensorflow Code snippet:
```
    graph = tf.Graph()
        with graph.as_default():
          tf_input1 = tf.Variable(tf.truncated_normal([FLAGS.size, FLAGS.size], dtype=get_dtype()))
          tf_input2 = tf.Variable(tf.truncated_normal([FLAGS.size, FLAGS.size], dtype=get_dtype()))
          tf_output = tf.matmul(tf_input1, tf_input2)
  
      with tf.Session(graph=graph) as session:
          tf.global_variables_initializer().run()
          print(""Initialized"")
          for i in range(FLAGS.times):
              out = session.run([tf_output])#, feed_dict=feed_dict)
          print(""Done"")
```


cuBlas Code FP16 (Snippet):
```
        uint16_t *d_a;          // d_a - a on the device
        uint16_t *d_b;          // d_b - b on the device
        uint16_t *d_c;          // d_c - c on the device
        cudaStat = cudaMalloc ((void **) &d_a, m * k * sizeof (*a));    // device memory alloc for a
        cudaStat = cudaMalloc ((void **) &d_b, k * n * sizeof (*b));    // device memory alloc for b
        cudaStat = cudaMalloc ((void **) &d_c, m * n * sizeof (*c));    // device memory alloc for c
        stat = cublasCreate (&handle);  // initialize CUBLAS context
        // copy matrices from the host to the device
        stat = cublasSetMatrix (m, k, sizeof (*a), a, m, d_a, m);   //a -> d_a
        stat = cublasSetMatrix (k, n, sizeof (*b), b, k, d_b, k);   //b -> d_b
        stat = cublasSetMatrix (m, n, sizeof (*c), c, m, d_c, m);   //c -> d_c
        uint16_t al = FP_16_ONE;       // al = 1 
        uint16_t bet = FP_16_ONE;      // bet =1
        // matrix - matrix multiplication : d_c = al*d_a *d_b + bet *d_c
        // d_a -mxk matrix , d_b -kxn matrix , d_c -mxn matrix ;
        // al ,bet -scalars

        stat = cublasGemmEx(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, &al, d_a, CUDA_R_16F, m, d_b, CUDA_R_16F, k, &bet, d_c, CUDA_R_16F, m, CUDA_R_16F, CUBLAS_GEMM_DEFAULT); 

        stat = cublasGetMatrix (m, n, sizeof (*c), d_c, m, c, m);   // cp d_c - >c
```
  "
15584,explained function generate_batch in Deep Learning Assignment 5 word2vec,"please explain formula : data_index = (data_index + 1) % len(data) in function generate_batch
thank you so so much"
15583,tensorflow logging glog redefined warning,"I just integrated a tensorflow module to my existing c++ project. I was already using glog for logging in my existing project, logging to files.

Now when I build the new project it throws warnings like:
`/usr/local/include/google/tensorflow/tensorflow/core/platform/default/logging.h:254:0: warning: ""CHECK_GT"" redefined
#define CHECK_GT(val1, val2) CHECK_OP(Check_GT, >, val1, val2)
/usr/local/include/glog/logging.h:793:0: note: this is the location of the previous definition
#define CHECK_GT(val1, val2) CHECK_OP(_GT, > , val1, val2)`

Is this behavior safe? I am not concerned that much with the logs that tensorflow generates, I need my existing modules to continue logging to files.

If this behavior is unsafe, this could be a good feature request to have glog logging not affected by tensorflow logging."
15582,upgrade tensorflow 1.4 from 1.2，get undefined symbol:error,"I import c++ api of concat op
and  add  ""//tensorflow/core/kernels:concat_lib_hdrs"", to the deps
my code work ok based on tf1.2 .
when I upgrade tf to 1.4 ,compile and install is ok.
when I run my model ,I got the error as :


Traceback (most recent call last):
  File ""/home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/contrib/own_concat/python/ops/own_concat_ops_test.py"", line 5, in <module>
    from tensorflow.contrib import own_concat
  File ""/home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/contrib/own_concat/__init__.py"", line 19, in <module>
    from tensorflow.contrib.own_concat.python.ops.own_concat_ops import *
  File ""/home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/contrib/own_concat/python/ops/own_concat_ops.py"", line 11, in <module>
    resource_loader.get_path_to_datafile('_own_concat_ops.so'))
  File ""/home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py"", line 56, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)
  File ""/home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: /home/my_work/.cache/bazel/_bazel_my_work/ce8941cb5767b65fdf1825ce866fc372/execroot/org_tensorflow/bazel-out/local-opt/bin/tensorflow/contrib/own_concat/own_concat_ops_test.runfiles/org_tensorflow/tensorflow/contrib/own_concat/python/ops/_own_concat_ops.so: undefined symbol: _ZN10tensorflow9ConcatCPUIfEEvPNS_10DeviceBaseERKSt6vectorISt10unique_ptrINS_6TTypesIT_Li2ElE11ConstMatrixESt14default_deleteIS8_EESaISB_EEPNS7_6MatrixE"
15581,TfLiteCameraDemo only contains 32-bit libtensorflowlite_jni.so,"I strictly followed the steps on https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/ to
build the TfLiteCameraDemo. But I found only 32-bit libtensorflowlite_jni.so was contained in the final APK.

I modified the source code of libneuralnetworks.so to test my employer's NN accelerator, which needed the 64-bit libtensorflowlite_jni.so.

even I configed bazel with
./configure --config=android_arm64

and built with 
bazel build --cxxopt=--std=c++11 --cpu=arm64-v8a //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo

could not work.

Where was my mistake? Or how can I pack the 64-bit  libtensorflowlite_jni.so into the final APK?
"
15580,there is no gen_summary_ops,"when i 
from tensorflow.contrib.summary import summary_ops

it raises an error
---> 29 from tensorflow.contrib.summary import gen_summary_ops
     30 from tensorflow.core.framework import graph_pb2
     31 from tensorflow.python.eager import context

ImportError: cannot import name 'gen_summary_ops'"
15576,Feature request: Possible to introduce tf.complex32 datatype,"Just recently I figured out, that our GPU (TitanX 12GB) is not big enough of its memory capacities to process our data. I was wondering whether there are attempts to ""quantize"" the complex datatypes as well. 

I've seen that there are approaches to quantize float32 datatypes for example and was wondering if this is possible for real/imag types as well. 

Thanks a lot! "
15575,TensorFlow automatically modify variable scope name,"check the following code:

```python
with tf.variable_scope('test'):
      v1 = tf.placeholder(tf.float32, shape=(10,10), name='v1')

with tf.variable_scope('test'):
      v2 = tf.placeholder(tf.float32, shape=(5, 5), name='v2')

print(v1)
print(v2)
```


the code output:

 ```python
Tensor(""test/v1:0"", shape=(10, 10), dtype=float32)
Tensor(""test_1/v2:0"", shape=(5, 5), dtype=float32)
```

It looks ridiculous for TF modfiy variable scope name 'test' into 'test_1' while my new placeholder named 'v2' is different from 'v1'. However, if i add variables, everything is going to be normal. code like:

```python
    with tf.variable_scope('test'):
        v1 = tf.placeholder(tf.float32, shape=(10,10), name='v1')
        w1 = tf.get_variable('w1', shape=(2,2))

    with tf.variable_scope('test'):
        v2 = tf.placeholder(tf.float32, shape=(5, 5), name='v2')
        w2 = tf.get_variable('w2', shape=(3, 3))
    print(v1)
    print(v2)
    print(w1)
    print(w2)
```
outputs:
```python
Tensor(""test/v1:0"", shape=(10, 10), dtype=float32)
Tensor(""test_1/v2:0"", shape=(5, 5), dtype=float32)
<tf.Variable 'test/w1:0' shape=(2, 2) dtype=float32_ref>
<tf.Variable 'test/w2:0' shape=(3, 3) dtype=float32_ref>
```

I dont know why TF **just modify the variable scope name** while i try to add a new placeholder into the existed scope.Is it a BUG?
"
15573,'tensorflow/contrib/reduce_slice_ops/_objs/python/ops/_reduce_slice_ops_gpu/tensorflow/contrib/reduce_slice_ops/kernels/reduce_slice_ops_gpu.cu.pic.o' was not created,"Hi i'm running the tensorflow from the source and after building the tensorflow using bazel using below command 

**bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package** 

**The error message pasted below**

10 errors detected in the compilation of ""/home/lb/.cache/bazel/_bazel_lb/144f5944ef8ff562c57e67fdaa41565f/execroot/org_tensorflow/tmpae8_5f0170552fd082f4/tmpxft_0000245c_00000000-6_reduce_slice_ops_gpu.cu.cpp1.ii"".
ERROR: /home/lb/WorkSpace/AI-WORK/tensorflow/tensorflow/contrib/reduce_slice_ops/BUILD:14:1: output 'tensorflow/contrib/reduce_slice_ops/_objs/python/ops/_reduce_slice_ops_gpu/tensorflow/contrib/reduce_slice_ops/kernels/reduce_slice_ops_gpu.cu.pic.o' was not created
ERROR: /home/lb/WorkSpace/AI-WORK/tensorflow/tensorflow/contrib/reduce_slice_ops/BUILD:14:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 74.030s, Critical Path: 8.38s
FAILED: Build did NOT complete successfully
"
15572,layers.Conv3DTranspose doesn't work with unspecified DWH dimensions,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes (n/a)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 (All affected)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: CPU
- **Exact command to reproduce**: n/a

### Describe the problem

tensorflow.layers.Conv3DTranspose doesn't work when the input dimensions are not specified and bias is added.  This occurs because the layer output is reshaped from five dimensions to 4 by combining the depth and height dimensions:  None * None throws an exception.  The code for this is in tensorflow/python/layers/convolutional.py, line 1608.

It appears that this reshaping is done because nn.bias.add can't handle 5 dimensional inputs.  This seems like it should be an easy fix since nn.bias.add just broadcasts across all but the channel dimension anyway.  The *Transpose layers should really all use the same general _ConvTranspose style that the non-transposed convolution layers use, to avoid code duplication.

In the meantime, tensorflow.layers.Conv3D DOES work with unspecified input dimensions and channel-last ordering.  It turns out that Conv3D and Conv3DTranspose use different code for adding the bias.  In lieu of a nn.bias.add fix, this problem can be alleviated by using the Conv3D bias code for Conv3DTranspose.

### Suggested fix (tested)

In tensorflow/python/layers/convolutional.py, replace lines 1609-1625 with (modified from lines 169-189): 

        if self.data_format == 'channels_first':
              outputs_shape = outputs.shape.as_list()
              outputs_4d = array_ops.reshape(outputs,
                                             [outputs_shape[0], outputs_shape[1],
                                              outputs_shape[2] * outputs_shape[3],
                                              outputs_shape[4]])
              outputs_4d = nn.bias_add(outputs_4d, self.bias, data_format='NCHW')
              outputs = array_ops.reshape(outputs_4d, outputs_shape)
          else:
            outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')
"
15571,why keras run slower and slower,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15570,Using grid_rnn_cell.Grid1LSTMCell makes stack_bidirectional_dynamic_rnn Throw different shape errors,"I encountered a problem using grid_rnn_cell.Grid1LSTMCell. I have no problems using it on contrib static_rnn and contrib static_bidirectional_rnn.

```
class GridRNNTest(tf.test.TestCase):
    def setUp(self):
        self.num_features = 1
        self.time_steps = 1
        self.batch_size = 1
        tf.reset_default_graph()
        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])
        self.cell = grid_rnn_cell.Grid1LSTMCell(num_units=8)

    def test_simple_grid_rnn(self):
        self.input_layer = tf.unstack(self.input_layer, self.time_steps, 1)
        rnn.static_rnn(self.cell, self.input_layer, dtype=tf.float32)

class BidirectionalGridRNNTest(tf.test.TestCase):
    def setUp(self):
        self.num_features = 1
        self.time_steps = 1
        self.batch_size = 1
        tf.reset_default_graph()
        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])
        self.cell_fw = grid_rnn_cell.Grid1LSTMCell(num_units=8)
        self.cell_bw = grid_rnn_cell.Grid1LSTMCell(num_units=8)

    def test_simple_bidirectional_grid_rnn(self):
        self.input_layer = tf.unstack(self.input_layer, self.time_steps, 1)
        rnn.static_bidirectional_rnn(self.cell_fw, self.cell_bw, self.input_layer, dtype=tf.float32)
```

However, when I test it on contrib stack_bidirectional_dynamic_rnn:

```
class StackBidirectionalGridRNNTest(tf.test.TestCase):
    def setUp(self):
        self.num_features = 1
        self.time_steps = 1
        self.batch_size = 1
        tf.reset_default_graph()
        self.input_layer = tf.placeholder(tf.float32, [self.batch_size, self.time_steps, self.num_features])
        self.cells_fw = [grid_rnn_cell.Grid1LSTMCell(num_units=8) for _ in range(2)]
        self.cells_bw = [grid_rnn_cell.Grid1LSTMCell(num_units=8) for _ in range(2)]

    def test_stack_bidirectional_grid_rnn(self):
        self.input_layer = tf.unstack(self.input_layer, self.time_steps, 1)
        rnn.stack_bidirectional_dynamic_rnn(self.cells_fw, self.cells_fw, self.input_layer, dtype=tf.float32)
```

I encounter these shape errors:

(1) When the input_layer is unstacked: `Shape (1, 1) must have rank at least 3`
(2) When the input_layer is not unstacked: Shape `(1, 2, 8) must have rank 2`

Which are, apparently,  conflicting with each other."
15569,Dataset shuffle operation is not deterministic,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:elementary OS 0.4.1 Loki
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Not related
- **GPU model and memory**: Not related 
- **Exact command to reproduce**: mentioned below


### Describe the problem
Dataset Shuffle operation is not determenastic 

### Source code / logs
```python
import numpy as np
import tensorflow as tf

def test():
  np.random.seed(42)
  tf.set_random_seed(42)
  numbers = np.arange(1,100)

  def get_data():
    dataset = tf.data.Dataset.from_tensor_slices(numbers)  # some initial dataset
    dataset =  dataset.shuffle(100)
    x = dataset.make_one_shot_iterator().get_next()
    return x

  # execution 1
  x = get_data()
  with tf.Session() as sess:
    x_batch1 = sess.run(x)
    print(x_batch1)
  # clear out everything
  tf.reset_default_graph()

  # execution 2
  x = get_data()
  with tf.Session() as sess:
    x_batch2 = sess.run(x)
    print(x_batch2)
  # results should be equivalent
  assert np.allclose(x_batch1, x_batch2)
test()
```
test code sample taken from @dusenberrymw"
15568,InvalidArgumentError: slice index 0 of dimension 0 out of bounds.,"Hi,

### Describe the problem
I am trying to encode and decode an image using tf.image.decode_jpeg and b64 encoding. The code is so simple but it seems I have an error regarding StrideSlice. I am not sure if the problem coming from the undefined shape of input placeholder or related to jpeg_decode.  Thanks. 

### Source code / logs
```
import tensorflow as tf
import base64
import functools


def build_graph(input_len=None):
    graph = tf.Graph()
    with graph.as_default():
        image_bytes = tf.placeholder(tf.string, name='input_node')
        images = tf.map_fn(
            functools.partial(tf.image.decode_jpeg, channels=3),
            image_bytes,
            dtype=tf.uint8
        )
        image_floats = tf.cast(images, tf.float32, name=""output_node"") / 255.0

    return graph


if __name__ == '__main__':
    file_name = ""test_1.jpg""
    with open(file_name, ""rb"") as imageFile:
        image_string = imageFile.read()
        image_encode = base64.b64encode(image_string).decode(""utf-8"")

    graph = build_graph(input_len=len(image_encode))

    with tf.Session(graph=graph) as session:
        init_op = tf.group(tf.global_variables_initializer(),
                           tf.local_variables_initializer())
        session.run(init_op)
        input_node = graph.get_tensor_by_name(""input_node:0"")
        output_node = graph.get_tensor_by_name(""output_node:0"")
        image_out = session.run(output_node, feed_dict={input_node: image_encode})
```

These is the traceback:

```
Caused by op u'map/TensorArrayUnstack/strided_slice', defined at:
  File ""/.../Simple_Graph_Design/ImageTest.py"", line 26, in <module>
    graph = build_graph(input_len=len(image_encode))
  File ""/.../Simple_Graph_Design/ImageTest.py"", line 13, in build_graph
    dtype=tf.uint8
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/functional_ops.py"", line 354, in map_fn
    elem_ta.unstack(elem) for elem_ta, elem in zip(elems_ta, elems_flat)]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py"", line 107, in wrapped
    return _add_should_use_warning(fn(*args, **kwargs))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py"", line 412, in unstack
    num_elements = array_ops.shape(value)[0]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 538, in _SliceHelper
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 706, in strided_slice
    shrink_axis_mask=shrink_axis_mask)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 5430, in strided_slice
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): slice index 0 of dimension 0 out of bounds.
	 [[Node: map/TensorArrayUnstack/strided_slice = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](map/TensorArrayUnstack/Shape, map/TensorArrayUnstack/strided_slice/stack, map/TensorArrayUnstack/strided_slice/stack_1, map/TensorArrayUnstack/strided_slice/stack_1)]]

```
### System information
- TF version: 1.4.0
- Linux Ubuntu 16.04
- Python version: 2.7
- No CUDA or GPU 




"
15565,Linux GPU build failing (__CUDACC_VER__ is no longer supported),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 17.10, kernel 4.14.8
- **TensorFlow installed from (source or binary)**:
Source (failed build)
- **TensorFlow version (use command below)**:
master
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
0.9.0
- **GCC/Compiler version (if compiling from source)**:
4.9
- **CUDA/cuDNN version**:
9.0/7.0.4
- **GPU model and memory**:
Two 1080 Ti (11Gb each)
- **Exact command to reproduce**:
bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
I note the build bot is failing too for Linux GPU, since the latest merge in the past 1 hour.

### Source code / logs
ERROR: /home/daniel/build/tensorflow/tensorflow/contrib/image/BUILD:106:1: error while parsing .d file: /home/daniel/.cache/bazel/_bazel_daniel/a40ff47569db15fec953d4e5b5812083/execroot/org_tensorflow/bazel-out/k8-py3-opt/bin/tensorflow/contrib/image/_objs/python/ops/_distort_image_ops_gpu/tensorflow/contrib/image/kernels/adjust_hsv_in_yiq_op_gpu.cu.pic.d (No such file or directory)
In file included from /usr/local/cuda-9.0/bin/../targets/x86_64-linux/include/common_functions.h:50:0,
                 from /usr/local/cuda-9.0/bin/../targets/x86_64-linux/include/cuda_runtime.h:115,
                 from <command-line>:0:
/usr/local/cuda-9.0/bin/../targets/x86_64-linux/include/crt/common_functions.h:64:24: error: token """"__CUDACC_VER__ is no longer supported.  Use __CUDACC_VER_MAJOR__, __CUDACC_VER_MINOR__, and __CUDACC_VER_BUILD__ instead."""" is not valid in preprocessor expressions
 #define __CUDACC_VER__ ""__CUDACC_VER__ is no longer supported.  Use __CUDACC_VER_MAJOR__, __CUDACC_VER_MINOR__, and __CUDACC_VER_BUILD__ instead.""
                        ^
./tensorflow/core/util/cuda_device_functions.h:37:7: note: in expansion of macro '__CUDACC_VER__'
 #elif __CUDACC_VER__ >= 7050
       ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 237.382s, Critical Path: 22.79s
"
15564,sparsemax implementation is not infinite-safe,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, but I have a simple reproducer below

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 27
- **TensorFlow installed from (source or binary)**: pip3 install --user tensorflow
- **TensorFlow version (use command below)**:  1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: no
- **GCC/Compiler version (if compiling from source)**: no
- **CUDA/cuDNN version**: no
- **GPU model and memory**: no (x86_64 CPU)
- **Exact command to reproduce**:

### Describe the problem
tf.contrib.sparsemax.sparsemax does not produce the correctly expected results when infinities are present in the input.

Mathematically, a negative infinity should be treated the same as a very large negative number, and produce a 0 in the output.

This is a real-world problem when sparsemax is combined with contrib.seq2seq.LuongAttention (as suggested in its documentation, and also as suggested in the sparsemax paper), because entries past the input length in the batch will have a score of -inf by default.

### Source code / logs

Reproducer (assume tensorflow as tf)
```
>>> tf.contrib.sparsemax.sparsemax([[1., -1e+5]]).eval(session=sess)
array([[ 1.,  0.]], dtype=float32)
>>> tf.contrib.sparsemax.sparsemax([[1., float('-inf')]]).eval(session=sess)
2017-12-21 22:13:55.697302: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
2017-12-21 22:13:55.697997: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
2017-12-21 22:13:55.699634: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
2017-12-21 22:13:55.699980: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
Traceback (most recent call last):
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call
    return fn(*args)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
	 [[Node: sparsemax_7/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](sparsemax_7/sub, sparsemax_7/stack)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 570, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 4455, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
	 [[Node: sparsemax_7/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](sparsemax_7/sub, sparsemax_7/stack)]]

Caused by op 'sparsemax_7/GatherNd', defined at:
  File ""<stdin>"", line 1, in <module>
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/contrib/sparsemax/python/ops/sparsemax.py"", line 69, in sparsemax
    tau_sum = array_ops.gather_nd(z_cumsum, indices)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1971, in gather_nd
    ""GatherNd"", params=params, indices=indices, name=name)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/redacted/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): flat indices[0, :] = [0, -1] does not index into param (shape: [1,2]).
	 [[Node: sparsemax_7/GatherNd = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](sparsemax_7/sub, sparsemax_7/stack)]]
```

"
15563,Cannot statically link against Tensorflow library in Golang,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 1.4.0
- **Bazel version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `go build -a -v -o hellotf --ldflags '-linkmode external -extldflags ""-static -L /usr/local/lib""' -x <GITHUB_PROJ_NAME>/hellotf`

### Describe the problem
I'm trying to compile a **statically-linked** binary of the hello world app against the TF 1.4.0 binary per the [golang install & hello-world instructions](https://www.tensorflow.org/install/install_go) and am not able to successfully link against the TF library as it reports that `ltensorflow` cannot be found by `/usr/bin/ld` in the `go build`.

The command used is:
`go build -a -v -o hellotf --ldflags '-linkmode external -extldflags ""-static -L /usr/local/lib""' -x <GITHUB_PROJ_NAME>/hellotf`

I've tried linking against `/usr/local/lib` (where libtensorflow lives) using `-extldflags`, CGO_LDFLAGS, LDFLAGS etc, done `sudo ldconfig` and the env setup with LD_LIBRARY_PATH and LIBRARY_PATH, but cannot move past this step and always get the error status:

```
/.gvm/gos/go1.8.3/pkg/tool/linux_amd64/link: running gcc failed: exit status 1
/usr/bin/ld: cannot find -ltensorflow
```

The only related issue I've encountered for this is: https://stackoverflow.com/questions/44428816/tensorflow-for-go-demo-example-run-failed, but that didn't help much either.

That being said, I can dynamically link and build the helloworld go code e.g. `go build hello_tf.go` and `go test github.com/tensorflow/tensorflow/tensorflow/go` all work successfully; the issue arises when I try to statically link and cannot link to libtensorflow after it compiles, no matter what settings I try using.

Any help or advice would be greatly appreciated. Thanks!"
15558,ONNX Model Support,Please add support for the [ONNX](https://github.com/onnx/onnx) open model standard or a conversion tool would be great.
15557,tensorflow::gtl::string_as_array crashes on Windows,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
None

### Describe the problem
Compile and run the following code in VS 2017 in **Debug** Mode.
```c++
#include <iostream>
#include <stdint.h>
using namespace std;

inline char* string_as_array(string* str) { return &*str->begin(); }
int main()
{
	string str;
	char* p = string_as_array(&str);
	std::cout << (uint64_t)p << std::endl;
	return 0;
}
```

It will crash.

```
Debug Assertion Failed!

Program: C:\WINDOWS\SYSTEM32\MSVCP140D.dll
File: c:\program files (x86)\microsoft visual studio\2017\enterprise\vc\tools\msvc\14.12.25827\include\xstring
Line: 1219

Expression: cannot dereference string iterator because it is out of range (e.g. an end iterator)

For information on how your program can cause an assertion
failure, see the Visual C++ documentation on asserts.
```

This function is extracted from  tensorflow\core\lib\gtl\stl_util.h

### Source code / logs

"
15556,Little error in example how to read data,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.5.4
- **Exact command to reproduce**: 

```
python tensorflow/tensorflow/examples/how_tos/reading_data/convert_to_record.py
python tensorflow/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py
```

### Describe the problem

Error when doing the above second command: `AttributeError: module 'tensorflow' has no attribute 'data'` The data attribute is actually in the contrib module then you should change the line 108 of the file `tensorflow/tensorflow/examples/how_tos/reading_data/fully_connected_reader.py`:

`dataset = tf.data.TFRecordDataset(filename)`
to
`dataset = tf.contrib.data.TFRecordDataset(filename)`

Sorry, I don't know if I should have submitted a pull request for such a little change.

"
15554,Tensorflow Lite exhibits longer inference time when build with Android NN API on Google Pixel 1,"

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
'v1.3.0-rc1-6055-gfdf34a8', '1.4.0'
- **Python version**: 
2.7.12
- **Bazel version (if compiling from source)**:
0.8.0
- **GCC/Compiler version (if compiling from source)**:
GCC 5.4.0-6ubuntu1~16.04.5
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


### Describe the problem
When enabling the NN API usage (edit interpreter.cc) one would expect that due to the HW acceleration, inferece times would be shorter. However, exactly the opposite happens. I tried this using the included demo app, using mobilenet_quant_v1_224.tflite and a custom (not quantized) model that I converted to tflite. In the mobilenet case, inference takes around 80ms without NNAPI, and ~100ms with NNAPI . My custom model, which sadly I cannot share , takes 40ms without , and ~90ms with NNAPI.

Please note that I have also tested this with FAST_SINGLE_ANSWER  and SUSTAINED_SPEED  NNAPI preference settings. There was no significant change in inference times.

My Pixel Build number is: OPM1.171019.011

### Source code / logs
--- a/tensorflow/contrib/lite/interpreter.cc
+++ b/tensorflow/contrib/lite/interpreter.cc
@@ -51,7 +51,7 @@ Interpreter::Interpreter(ErrorReporter* error_reporter)
   tensors_.reserve(kSlotsToReserve);
   nodes_and_registration_.reserve(kSlotsToReserve);
   next_allocate_node_id_ = 0;
-  UseNNAPI(false);
+  UseNNAPI(true);
"
15552,Tensorflow 1.4 C++ API considerably slower than Python,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source with all optimizations
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: 8.0 / 6.0
- **GPU model and memory**: GTX960M

### Describe the problem

I was trying to run several models and evaluate the performance with different batch sizes in python and c++ and noticed that the c++ API version is considerably slower than the python one. Both were compiled with the same optimizations and with cuda support. 

When I try to predict the output of a single 256x256 image in python it takes me 0.5 seconds, and when i do it in tensorflow c++ api it takes me 1.7 seconds. Notice that in python I was using a non deployed model (without freezing and transforming graph), whereas in C++ I did those transformations. 

Does anyone knows why this is happening? Is it because of the frozen and transformed graph?

I always thought the C++ API would be at least as fast as the Python version. 
"
15551,MutilGPU Model can't restore model,"Hi,I use multiple GPU training with tensorflow1.0, and save the model sucessfully, when I restore the model, the error appear here  #line:saver=tf.train.Saver(tf.all_variables()),ValueError:No Variable to save.
I try restore model in training,it works.So,i am confused what is wrong?can anybody help me.
Thank you"
15549,Segmetation fault(coredump),"Hi guys, am getting Segmentation fault(coredump) while running keras with tensorflow background in CPU . Can anyone help me 
(imag) research2@research-Precision-T1700:~/imag/ftune$ python3 finetune.py
Using TensorFlow backend.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Found 55 images of 2 classes
Found 54 images of 2 classes
Segmentaion falut(Coredump)

"
15547,"how to build tensorflow-lite.so  for linux  ubuntu, thanks?","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15546,DIGITS tensorflow distributed problem ：Graph is finalized and cannot be modified,"
I am a DIGITS novice, and I want to change the TensorFlow single machine from DIGITS to distributed。The following is the code that I modified。

sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
            logdir='/root/digits/digits/jobs/hello',
                        saver=saver,
                        init_op=init_op,
                        )

with sv.prepare_or_wait_for_session(server.target) as sess:
    inf_model.start_queue_runners(sess)
    val_model.start_queue_runners(sess)
    train_model.start_queue_runners(sess)
    try：
         while not train_model.queue_coord.should_stop():
            _, summary_str, step = sess.run                                 ([train_model.train,
                                                                                        train_model.summary,
                                                                                        train_model.global_step],
                                                                                        feed_dict=feed_dict,
                                                                                        options=run_options,
                                                                                        run_metadata=run_metadata)

and run it,but error:

2017-12-19 06:56:23.696588: I tensorflow/core/distributed_runtime/master_session.cc:999] S
tart master session ad6a96f02b5d215f with config: 
INFO:tensorflow:Starting standard services.
2017-12-19 06:56:23 [INFO] Starting standard services.
INFO:tensorflow:Starting queue runners.
INFO:tensorflow:Saving checkpoint to path /root/digits/digits/jobs/xwk/model.ckpt
2017-12-19 06:56:23 [INFO] Starting queue runners.
2017-12-19 06:56:23 [INFO] Saving checkpoint to path /root/digits/digits/jobs/xwk/model.ck
ptINFO:tensorflow:Errorreported to Coordinator: , exceptions.KeyError: 'pyfunc_1'     [[Node: val/data/data_reader = PyFuncTin=[DT_STRING], Tout=[DT_STRING, DT_INT32,DT_INT64,DT_INT32],token=""pyfunc_1"", _device=""/job:ps/replica:0/task:0/cpu:0""]]2017-12-19 06:56:23 [INFO] Error reported to Coordinator: , exceptions.KeyError: 'pyfunc_1'  [[Node: val/data/data_reader = PyFuncTin=[DT_STRING], Tout=[DT_STRING, DT_INT32,DT_INT64, DT_INT32],token=""pyfunc_1"",_device=""/job:ps/replica:0/task:0/cpu:0""]]INFO:tensorflow:/root/digits/digits/jobs/xwk/model.ckpt is not in all_model_checkpoint_pat
hs. Manually adding it.2017-12-19 06:56:24 [INFO] /root/digits/digits/jobs/xwk/model.ckpt is not in all_model_che
ckpoint_paths. Manually adding it.2017-12-19 06:56:24 [INFO] Starting queue runners (val)
Traceback (most recent call last):
  File ""/root/digits/digits/tools/tensorflow/main.py"", line 779, in 
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48
, in run    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/root/digits/digits/tools/tensorflow/main.py"", line 629, in main
    val_model.start_queue_runners(sess)
  File ""/root/digits/digits/tools/tensorflow/model.py"", line 208, in start_queue_runners
    tf.add_to_collection(digits.GraphKeys.QUEUE_RUNNERS, qr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 4
248, in add_to_collection    get_default_graph().add_to_collection(name, value)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2
792, in add_to_collection    self._check_not_finalized()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2
181, in _check_not_finalized    raise RuntimeError(""Graph is finalized and cannot be modified."")
RuntimeError: Graph is finalized and cannot be modified.

Do you know what is the cause of the final problem?
If you know, please tell me.
thx."
15543,Maven Nightlies,"@asimshankar Would it be possible to start releasing Maven nightlies for the Java API packages? I only depend on the org.tensorflow Proto package, but I guess it would be more consistent to do that for all the Java API packages."
15542,Cannot run run_cc_test_windows.bat: command line too long,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows Server 2012
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4.1
376e2cfdab31f4da251ea2e50992a9bf97fd171b
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
0.9.0, 
- **GCC/Compiler version (if compiling from source)**:
VS 2015
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
tensorflow/tools/ci_build/windows/cpu/bazel/run_cc_test_windows.bat

### Describe the problem
Indeed, I have some local modification.  I'm trying to fix some failed cc_tests on Windows, and turn on them in bazel_test_lib.sh 

The problem is: As the number of tests is growing,  we can't pass all their names through command line. We need a new way to filter the tests. 
What about: 
Remove the settings in tensorflow/tools/ci_build/windows/cpu/bazel/run_cc_test_windows.bat,  replace them with bazel tags like ""no_windows"", ""gpu_only"", ... ?

### Source code / logs
[build_log.txt](https://github.com/tensorflow/tensorflow/files/1577981/build_log.txt)
"
15541,TensorFlow grpc+gdr runtime error,"I have built tensorflow with gdr support following the [instruction](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gdr)，but when I run tf_cnn_benchmarks I got a runtime error.
![image](https://user-images.githubusercontent.com/3050438/34240351-43330544-e648-11e7-9543-aaea5abadc48.png)

"
15540,No PyPi package for Tensorflow 1.4 on Windows?,"Running Windows 10 with Python 3.6.
Just wondering when that's gonna come out."
15538,[solved]session->Create(graph_def) No OpKernel was registered to support Op 'RandomUniform',"issue: crashes when loading pb file in C++ program:

>     Session * session;
>     GraphDef graph_def;
>     SessionOptions opts;
>     TF_CHECK_OK(ReadBinaryProto(Env::Default(), heartPrintPbPathFile, &graph_def));
>     TF_CHECK_OK(NewSession(opts, &session));
>     TF_CHECK_OK(session->Create(graph_def));
> 

os: linux
train: python
inference: C++ interface

runtime error on inference part:

> Non-OK-status: session->Create(graph_def) status: Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:
>   <no registered kernels>
> 
> 	 [[Node: rnn_net/rnn/dropout_63/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](rnn_net/rnn/dropout_63/Shape)]]

python train code:

>         with tf.variable_scope(""rnn_net"") as scope:
>             cell = []
>             for i in range(num_layers):
>                 cell.append(tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True))
> 
>             cell = tf.nn.rnn_cell.MultiRNNCell(cell)
> 
>             cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)
> 
>             initial_state = cell.zero_state(batch_size, tf.float32)
> 
>             input_list = tf.unstack(conv_output, axis=1)
> 
>             rnn_output, _ = tf.nn.static_rnn(cell, input_list, dtype=tf.float32)
>             self.rnn_output = rnn_output[-1]
>             print ""rnn output shape: ""
>             print self.rnn_output.get_shape()

hint one : i found that if i delete this line:
cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = self.keep_prob)
then the trained pb file can be loaded normally.

hint two: beside rnn part, i also have cnn part in the network, and the dropout in cnn works just fine:

>         with tf.variable_scope(""conv_net"") as scope:
>             filters = [15, 11, 7, 5]
>             kernel_size = [64, 64, 32, 32]
>             input_layer = tf.reshape(self.x, [-1, seq_len, 1])
>             conv1_1 = tf.layers.conv1d(inputs=input_layer, filters=filters[0], kernel_size=kernel_size[0], padding=""same"", activation=tf.nn.tanh, name='conv1_1')
>             conv1_2 = tf.layers.conv1d(inputs=conv1_1, filters=filters[1], kernel_size=kernel_size[1], padding=""same"", activation=tf.nn.tanh)
>             pool1 = tf.layers.max_pooling1d(inputs=conv1_2, pool_size=4, strides=4)
> 
>             bn1 = batch_norm(pool1, self.is_train, scope='bn1')
>             dropout1 = tf.layers.dropout(inputs=bn1, rate=(1 - self.keep_prob))
> 
>             conv2_1 = tf.layers.conv1d(inputs=dropout1, filters=filters[2], kernel_size=kernel_size[2], padding=""same"", activation=tf.nn.tanh, name='conv2_1')
>             conv2_2 = tf.layers.conv1d(inputs=conv2_1, filters=filters[3], kernel_size=kernel_size[3], padding=""same"", activation=tf.nn.tanh)
>             pool2 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=4, strides=4)
> 
>             bn2 = batch_norm(pool2, self.is_train, scope='bn2')
>             dropout2 = tf.layers.dropout(inputs=bn2, rate=(1 - self.keep_prob))
> 
>             conv3_1 = tf.layers.conv1d(inputs=dropout2, filters=filters[2], kernel_size=kernel_size[2], padding=""same"", activation=tf.nn.tanh)
>             conv3_2 = tf.layers.conv1d(inputs=conv3_1, filters=filters[3], kernel_size=kernel_size[3], padding=""same"", activation=tf.nn.tanh)
>             pool3 = tf.layers.max_pooling1d(inputs=conv2_2, pool_size=2, strides=2)
> 
>             conv_output = pool3

"
15537,tensorflow lite converter: why empty lite file,"I have a tensorflow pb file and try to use tflite converter to convert it to lite file,but the result file is empty and no error. I don't know why
`bazel run --config=opt --copt=-msse4.1 --copt=-msse4.2  //tensorflow/contrib/lite/toco:toco --   --input_file=/Users/Lavector/code/keras_to_tensorflow/mobilenet_regression.pb   --output_file=/tmp/mobilenet_regression.lite   --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --inference_type=FLOAT   --input_shape=1,224,224,3   --input_array=input   --output_array=output_node0`

`WARNING: Config values are not defined in any .rc file: opt
INFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).
INFO: Found 1 target...
Target //tensorflow/contrib/lite/toco:toco up-to-date:
  bazel-bin/tensorflow/contrib/lite/toco/toco
INFO: Elapsed time: 0.223s, Critical Path: 0.01s
INFO: Build completed successfully, 1 total action

INFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/Users/Lavector/code/keras_to_tensorflow/mobilenet_regression.pb' '--output_file=/tmp/mobilenet_regression.lite' '--input_format=TENSORFLOW_GRAPHDEF' '--output_format=TFLITE' '--inference_type=FLOAT' '--input_shape=1,224,224,3' '--input_array=input' '--output_array=output_node0'
2017-12-21 11:20:11.351544: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 472 operators, 695 arrays (0 quantized)
2017-12-21 11:20:11.384604: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 85 operators, 200 arrays (0 quantized)
2017-12-21 11:20:11.387067: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 85 operators, 200 arrays (0 quantized)`

I use mobilenet to do regression, and it is successful when test.
I test the example code of [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md](url), and it is correct."
15530,Bug?: reading from Google Cloud Storage appears to be accessing cached version,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: observed on CPU & GPU.
- **GPU model and memory**: observed on CPU & GPU.
- **Exact command to reproduce**: See below.

### Describe the problem

How this arose:

We are trying to set up a basic distributed TF version, where we have separate pods (on Kubernetes) doing validation and training (a simple version, with 1 of each).  GCS is used as the backend to store model output (checkpoints, etc.).

The validation pod periodically (via Experiment’s continuous_eval https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L564) periodically polls for new checkpoints to evaluate (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L517).  

If it doesn’t find a new checkpoint, it (per the underlying code) echoes out “No new checkpoint ready for evaluation” and continues to wait for a new one.

In practice, we found that, even as the training pod produces new checkpoints, the validation pod *never* picks up a new checkpoint, beyond the first one.  I.e., it collects an initial checkpoint, does evaluation, and then, in all future cycles, echoes out ""No new checkpoint ready for evaluation"".

In debugging, we found that the checkpoint file the saver tries to load up is always found to be some earlier iteration of the file (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/python/training/saver.py#L1005) -- i.e., it seems like the GCS file loader reads the file once, and, from then on out, is continuous accessing a cached version of the data.  

Digging into the code further, this appears to be an issue with how the file reader (file_io.read_file_to_string(...) and downstream methods) loads GCS files.  We were able to replicate this behavior separately, below.

**Help appreciated!**

* Is this intended behavior?  Is there, e.g., some sort of GCS setting we have incorrectly set?  
* Assuming we're seeing something real, is there any suggested remediation here, with regards to our validation behavior?  Our next step is going to be to try monkey-patching some of the tf functions to just pull the GCS file local to disk and read it from there...although this is of course not preferred.

As a side note, Experiment does have a number of references to special handling around using GCS as the backend, although I don't have enough context to say if this is relevant to what we are seeing or not (https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L94, https://github.com/tensorflow/tensorflow/blob/f5f2f789ea395e585ddcbc43e088fa63d6b41d0e/tensorflow/contrib/learn/python/learn/experiment.py#L269).

### Source code / logs

Below is a pair of scripts that will replicate this issue.  Run the “Basic Reader” (using the same loading interface from get_checkpoint_state) and the “Basic Writer” simultaneously, and the reader will initially catch whatever is in the file, and then never update, even as the writer continues to write.

Other things we tried:

* Changing the read/write path to local disk, instead of GCS.  This, unsurprisingly, worked.
* A version of a reader with a context manager (below), to try to reset the reader each loop, and an explicit file.close() (not shown).  Both had the same behavior, i.e., new reads didn't provide the updated file.
* Writing from the same file (process) that we read from: probably unsurprisingly, this *does* work; i.e., the writing activity either updates the local cache or otherwise convinces the reader to grab a fresh copy from GCS (we didn’t actually test which this might be).  

Basic Reader:

```python
#!/usr/bin/env python

from tensorflow.python.lib.io import file_io
import time
import os

file='gs://[MYPATH]'

os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = '/usr/src/app/gcloud/keys/google-auth.json'

def read():
    counter=0
    while counter<15:
        print(""reading..."")
        print(""Contents:"")
        print(file_io.read_file_to_string(file))
        print("""")
        print(""Sleeping for a second..."")
        time.sleep(3)
        print("""")
        print("""")
        print("""")
        counter +=1

read()
```

Basic writer

```python
#!/usr/bin/env python

from tensorflow.python.lib.io import file_io
import time
import os

file='gs://[MYPATH]'

os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = '/usr/src/app/gcloud/keys/google-auth.json'

def write():
    counter=0
    while counter<15:
        with file_io.FileIO(file, mode='w') as f:
            f.write(str(counter))
        print(""Wrote {}"".format(counter))
        print("""")
        print(""Sleeping for a second..."")
        time.sleep(3)
        print("""")
        print("""")
        print("""")
        counter +=1

write()
```

Reader with context manager

```python
#!/usr/bin/env python

from tensorflow.python.lib.io import file_io

import time
import os

file='gs://[MYPATH]'

os.environ[""GOOGLE_APPLICATION_CREDENTIALS""] = '/usr/src/app/gcloud/keys/google-auth.json'

def read():
    counter=0
    while counter<15:
        print(""reading..."")
        print(""Contents:"")
        with file_io.FileIO(file, mode='r') as f:
           print(f.read())
        print("""")
        print(""Sleeping for a second..."")
        time.sleep(3)
        print("""")
        print("""")
        print("""")
        counter +=1

read()
```"
15529,Sample Distorted Bounding Box Bug,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Stock Example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
16.04.3 LTS
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
Python 3.5.2
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
cuda_9.0.176_384.81 / cudnn 7
- **GPU model and memory**:
GTX 755M 2gb Memory x2
- **Exact command to reproduce**:
begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
        tf.shape(image),
        bounding_boxes=bounding_boxes)


### Describe the problem
When using the tf.image.sample_distorted_bounding_box() function the parameter min_object_covered seems to default to value None which causes an error (ValueError: None values not supported.)  If you give an argument for min_object_covered it seems to work fine.

There seems to be two versions of this function in the source [v2 which takes min_object_covered](https://github.com/tensorflow/tensorflow/blob/fc49f43817e363e50df3ff2fd7a4870ace13ea13/tensorflow/core/ops/image_ops.cc#L930) as a argument and a [v1](https://github.com/tensorflow/tensorflow/blob/fc49f43817e363e50df3ff2fd7a4870ace13ea13/tensorflow/core/ops/image_ops.cc#L844) which has the default value of 0.1 as an attribute.  It appears v2 is the one [being used](https://github.com/tensorflow/tensorflow/blob/73658420db2498ad7f07363bfa72cba6e2d9fdd2/tensorflow/python/ops/image_ops_impl.py#L1536).  Not sure what approach is best to take for fixing this bug but believe the root of the issue is coming from tensorflow/core/ops/image_ops.cc

### Source code / logs
Attached
[boundingbox.txt](https://github.com/tensorflow/tensorflow/files/1576836/boundingbox.txt)

Examples of code being implemented [here](https://github.com/wagonhelm/image_augment/blob/master/DataAug.ipynb).

"
15527,[Bug] Tensorflow serving loads incorrect model weights when using saved model main_op,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 3.16.36 x86_64
- **TensorFlow installed from (source or binary)**: Binary (pip)
- **TensorFlow version (use command below)**: Git version 1.4.0-19-ga52c8d9 Release version 1.4.1
- **Python version**: 2.7.9
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: See attached gist

Hey there,

I've documented a lot of this bug over on this [issue](https://github.com/tensorflow/serving/issues/656) on the tensorflow serving repository, which was closed with the direction to open an issue here.

Essentially, the bug is as follows: I have an embedding layer in Keras that uses some pre-initialized weights. When I export the model for use by TF serving, I note the following behavior:

- The keras model itself has no issue outputting the correct results
- The exported model itself (upon inspection) has the correct weights
- The result values from TF serving are incorrect.

I've narrowed it down to an issue with `tensorflow.python.ops.variables.global_variables_initializer`, as follows:

When specifying the `main_op` argument in `tensorflow.saved_model.builder.SavedModelBuilder.add_meta_graph_and_variables`, if I use `tensorflow.saved_model.main_op.main_op()` I encounter this issue. 

If instead, I use a control flow group that excludes the global variables initializer as follows:

```
main_op_new = control_flow_ops.group(                 
            lookup_ops.tables_initializer(),          
            variables.local_variables_initializer(),  
)                                                     
```

I do not encounter this issue. I've attached the full code for reproducing this issue (with the caveat of needing `tensorflow_model_server` running) [here](https://gist.github.com/zmjjmz/ce9c7a896933a02953cae0069a2ca21e)

Here's the example output with the global variables initializer: https://gist.github.com/zmjjmz/d739cdfa52148eb814450e48cbf8ddb6

If you comment out line 83 of the repro code and uncomment line 84, you should get the correct output as shown here: https://gist.github.com/zmjjmz/9edee5b4eeff94f383122545d80ee55f

Thanks for helpin out




"
15525,Op type not registered HashTableV2 error while deploying model in cloud ml,"Problem while deploying model in Tensorflow 1.4.

**Code :**

```python
def model_fn(features, labels, mode):
    if mode == tf.estimator.ModeKeys.TRAIN:
        tf.keras.backend.set_learning_phase(True)
    else:
        tf.keras.backend.set_learning_phase(False)

    input_feature = features['x']
    table = lookup.index_table_from_file(vocabulary_file='vocab.txt', num_oov_buckets=1, default_value=-1)
    text = tf.squeeze(input_feature, [1])
    words = tf.string_split(text)
    dense_words = tf.sparse_tensor_to_dense(words, default_value=PADWORD)
    numbers = table.lookup(dense_words)
    padding = tf.constant([[0, 0], [0, MAX_LEN]])
    padded = tf.pad(numbers, padding)
    sliced = tf.slice(padded, [0, 0], [-1, MAX_LEN])
    print('words_sliced={}'.format(words))

    embeds = tf.keras.layers.Embedding(MAX_FEATURES+1, 128, input_length=MAX_LEN)(sliced)

    print('words_embed={}'.format(embeds))
    f1 = tf.keras.layers.Dropout(0.2)(embeds)
    f1 = tf.keras.layers.Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1)(f1)
    f1 = tf.keras.layers.GlobalAveragePooling1D()(f1)
    f1 = tf.keras.layers.Dense(hidden_dims)(f1)
    f1 = tf.keras.layers.Dropout(0.5)(f1)
    f1 = tf.keras.layers.Activation('relu')(f1)
    logits = tf.keras.layers.Dense(11)(f1)

    predictions_dict = {
        'class': tf.argmax(logits, 1),
        'prob': tf.nn.softmax(logits)
    }

    '''prediction_output = tf.estimator.export.PredictOutput({""classes"": tf.argmax(input=logits, axis=1),
                                                           ""probabilities"": tf.nn.softmax(logits,
                                                                                          name=""softmax_tensor"")})'''

    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions_dict, export_outputs={
            'prediction': tf.estimator.export.PredictOutput(predictions_dict)
        })

    loss = tf.losses.sparse_softmax_cross_entropy(labels, logits=logits)

    if mode == tf.contrib.learn.ModeKeys.TRAIN:
        train_op = tf.contrib.layers.optimize_loss(loss, tf.contrib.framework.get_global_step(), optimizer='Adam',
                                                   learning_rate=0.001)
        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)

    eval_metrics_ops = {
        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predictions_dict['class']),
        'precision': tf.metrics.precision(labels=labels, predictions=predictions_dict['class']),
        'recall': tf.metrics.recall(labels=labels, predictions=predictions_dict['class'])
    }
    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics_ops)

def get_train_record(record):
    vector = tf.decode_csv(record, DEFAULTS, use_quote_delim=True)
    return vector[1:], vector[0]

def preprocess(text):
    text = text.lower()
    result = ' '.join([word for word in text.split() if word not in (stop_words)])
    return result


def build_vocab(file_name, vocab_file_name):
    df = pd.read_csv(file_name, header=None, sep=',', skiprows=[1], names=['product', 'consumer_complaint_narrative'])
    df['consumer_complaint_narrative'] = df['consumer_complaint_narrative'].apply(preprocess)
    print(df['consumer_complaint_narrative'][0])
    vocab_processor = tflearn.preprocessing.VocabularyProcessor(max_document_length=MAX_FEATURES, min_frequency=10,
                                                                tokenizer_fn=tflearn.preprocessing.tokenizer)
    vocab_processor.fit(df['consumer_complaint_narrative'])
    with gfile.Open(vocab_file_name, 'wb') as f:
        f.write(""{}\n"".format(PADWORD))
        for word, index in vocab_processor.vocabulary_._mapping.items():
            f.write(""{}\n"".format(word))
    nwords = len(vocab_processor.vocabulary_)
    print('{} words into {}'.format(nwords, vocab_file_name))


def input_fn(file_name, batch_size, repeat_count, shuffle=False):
    def _input_fn():
        data_set = tf.data.TextLineDataset(filenames=file_name)
        data_set = data_set.map(get_train_record)
        if shuffle:
            data_set = data_set.shuffle(shuffle)
        data_set = data_set.repeat(repeat_count)
        batch = data_set.batch(batch_size)
        iterator = batch.make_one_shot_iterator()
        features, labels = iterator.get_next()
        return {'x': features}, labels

    return _input_fn()


def get_train_spec(file_name, batch_size, repeat_count):
    return tf.estimator.TrainSpec(input_fn=lambda: input_fn(file_name, batch_size, repeat_count, shuffle=True), max_steps=1000)


def get_test_spec(file_name, batch_size, repeat_count=1):
    return tf.estimator.EvalSpec(input_fn=lambda: input_fn(file_name, batch_size, repeat_count, shuffle=True))


def serving_input_fn():
    feature_tensor = tf.placeholder(tf.string, [None])
    # features = tf.py_func(preprocess, [feature_tensor], tf.string)
    features = tf.expand_dims(feature_tensor, -1)
    return tf.estimator.export.ServingInputReceiver({'x': features}, {'x': features})

finance_classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir)

print('\n Training .....')
finance_classifier.train(input_fn=lambda: input_fn('dataset/train.csv', batch_size, repeat_count=5, shuffle=True))

print('\n Evaluating.....')
eval_results = finance_classifier.evaluate(input_fn=lambda: input_fn('dataset/valid.csv', batch_size, repeat_count=1,
                                                                  shuffle=False))
for key in eval_results:
    print("" {} was {}"".format(key, eval_results[key]))

print('\n Exporting')
exported_model_dir = finance_classifier.export_savedmodel(model_dir, serving_input_receiver_fn=serving_input_fn)
decoded_model_dir = exported_model_dir.decode(""utf-8"")
```

[Screenshot](https://drive.google.com/open?id=1FAmoo9zCBJBAG2IFdySb_r4s1OV6YExn)

But when I tried with tf1.2 with some changes in the code in model_fn. Basically not using tf.keras but using tf.contrib.keras it was working. **is this bug ?**"
15522,line 123,"buffer failed to be initialized when data_index== len(data) (at the end of file it basically failed to go to the top) and gives the following error << TypeError: sequence index must be integer, not 'slice'
>> one work around is to replace line 123 with << buffer.extend(data[:span]) >> "
15521,Bug/Feature: constant_folding FP16 ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
RHEL 7
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
('v1.3.0-rc1-6207-ge210cb1', '1.4.0')
- **Python version**: 
python2.7
- **Bazel version (if compiling from source)**:
bazel 0.9.0
- **GCC/Compiler version (if compiling from source)**:
gcc 4.8
- **Exact command to reproduce**:

python tensorflow/models/tutorial/images/convolutional.py --use_fp16

### Describe the problem
When using FP16 in e.g. the case listed above, the following error occurs:
E tensorflow/core/grappler/optimizers/constant_folding.cc:1272] Unexpected type half
E tensorflow/core/grappler/optimizers/constant_folding.cc:1242] Unexpected type half

When looking into constant_folding.cc, i found out FP16 support exists at given lines, but is commented out.
Why is this not yet included in Tensorflow?

As far as I can see, this is more of a feature request than a bug report, since these code lines simply check if computational effort can be reduced (if the matrix is zero or one)

Also when using above command, the model trains until step 1100, then the learning rate drops to 0 (a known FP16 problem). Still it's annoying to encounter this in an official tutorial file.

"
15520,ar,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15518,Possible memory leak with tf.py_func() with distributed Tensorflow?,"When running Tensorflow as an distributed process to provide data with tf.data, it gradually consumes more and more memory, and finally consumes all memory of the system.

Scripts to reproduce:
We use a dummy dataset which produce [128, 28, 28, 1] tensors. 
Case1: Without distribute, which works fine, it will only consume 429Mb memory, no matter how many batches we run.
Codes in `test1.py`:
```
#test1.py
import tensorflow as tf
import numpy as np
from tqdm import tqdm

def dataset_generator():
    while True:
        yield np.random.uniform(size=[28, 28, 1]).astype(np.float32)
dataset = tf.data.Dataset.from_generator(dataset_generator, tf.float32)
dataset = dataset.batch(128)
value = dataset.make_one_shot_iterator().get_next()

sess = tf.Session()
for _ in tqdm(range(100000), ascii=True):
    sess.run(value)
```

Case: With distribute, it will consumes more and more memory while running more and more batches. It consumes 10+Gb with less than 1M batches. Use the following two commands in two processes to run the `test2.py`:
```
CUDA_VISIBLE_DEVICES="""" python test2.py dataset
CUDA_VISIBLE_DEVICES="""" python test2.py test
```
Codes in `test2.py`
```
# test2.py
import tensorflow as tf
import numpy as np
from tqdm import tqdm
import sys
def main(role):
    def dataset_generator():
        while True:
            yield np.random.uniform(size=[28, 28, 1]).astype(np.float32)
    cluster = tf.train.ClusterSpec({'dataset': ['localhost:2001'], 'test': ['localhost:2002']})
    if role == 'dataset':
        server = tf.train.Server(cluster, 'dataset', 0)
    elif role == 'test':
        server = tf.train.Server(cluster, 'test', 0)
    else:
        raise ValueError(""Uknown role {}."".format(role))
    with tf.device('/job:dataset/task:0')    :
        dataset = tf.data.Dataset.from_generator(dataset_generator, tf.float32)
        dataset = dataset.batch(128)
        value = dataset.make_one_shot_iterator().get_next()
    if role == 'dataset':
        server.join()
    elif role == 'test':
        sess = tf.Session(target=server.target)
        for _ in tqdm(range(100000000), ascii=True):
            sess.run(value)
            
if __name__ == ""__main__"":
    main(sys.argv[1])
```

Tensorflow: v1.4.0-rc1-11-g130a514 1.4.0
OS: ubuntu mate 16.04.1
Python: 3.6.1 (conda 4.3.30)


"
15517,fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h',"I am new to tensorflow, when I compile tensorfolw with VS2015 in Windows 7, I got the following error, could anyone help on this, thanks!
fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h'"
15505,Unable to generate my_frozen_graph.pb due to missing conv.ckpt checkpoint file,"------------------------

### System information
Linux ubuntu 16.04
CUDA 9.1
cuDNN 7
TensorFlow version ('v1.4.0-19-ga52c8d9', '1.4.1')

Additional info:

2017-12-20 07:36:22.294690: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU sup
ports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX
2 FMA
2017-12-20 07:36:22.360228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] succe
ssful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA 
node, so returning NUMA node zero
2017-12-20 07:36:22.360615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found de
vice 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: 0000:00:04.0
totalMemory: 11.17GiB freeMemory: 8.42GiB
2017-12-20 07:36:22.360643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating
 TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, 
compute capability: 3.7)

**Exact command to reproduce**:
According to https://www.tensorflow.org/versions/master/tutorials/audio_recognition#custom_training_data, specifically:

To train...
```
python tensorflow/examples/speech_commands/train.py
```
After training is finished, run freeze.py to generate a `my_frozen_graph.pb` which will later be used by `label_wav` for prediction.

```
python tensorflow/examples/speech_commands/freeze.py \
--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-18000 \
--output_file=/tmp/my_frozen_graph.pb
```

### Describe the problem
After training the speech commands app:
A `conv.ckpt-18000` file should appear after training is complete. 

However the only files which appear are ones with extensions:

- *.data-00000-of-00001
- *.meta
- *.index
- checkpoint

I've tried tensorflow releases 1.4.0-rc1, 1.4.0 and 1.4.1 but no luck generating a `conv.ckpt-18000` file.

I've even tried:
```
with tf.Session() as sess:
    new_saver = tf.train.import_meta_graph('/tmp/speech_commands_train/conv.ckpt-18000.meta')
    new_saver.restore(sess, tf.train.latest_checkpoint('./'))
```

which errors out due to:

`ValueError: No op named DecodeWav in defined operations.`

### Source code / logs
```
ls -ltr /tmp/speech_commands_train/
total 18348
...
-rw-r--r-- 1 root root  121649 Dec 20 07:07 conv.pbtxt
-rw-r--r-- 1 root root      60 Dec 20 07:07 conv_labels.txt
-rw-r--r-- 1 root root     315 Dec 20 09:17 conv.ckpt-17600.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:17 conv.ckpt-17600.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:17 conv.ckpt-17600.meta
-rw-r--r-- 1 root root     315 Dec 20 09:18 conv.ckpt-17700.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:18 conv.ckpt-17700.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:18 conv.ckpt-17700.meta
-rw-r--r-- 1 root root     315 Dec 20 09:18 conv.ckpt-17800.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:18 conv.ckpt-17800.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:18 conv.ckpt-17800.meta
-rw-r--r-- 1 root root     315 Dec 20 09:19 conv.ckpt-17900.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:19 conv.ckpt-17900.data-00000-of-00001
-rw-r--r-- 1 root root   75448 Dec 20 09:19 conv.ckpt-17900.meta
-rw-r--r-- 1 root root     315 Dec 20 09:20 conv.ckpt-18000.index
-rw-r--r-- 1 root root 3646008 Dec 20 09:20 conv.ckpt-18000.data-00000-of-00001
-rw-r--r-- 1 root root     433 Dec 20 09:20 checkpoint
-rw-r--r-- 1 root root   75448 Dec 20 09:20 conv.ckpt-18000.meta
```
"
15503,Behavior change of tf.app.flags parsing boolean args,"tf version 1.5.0-dev20171219
for example below args
flags.DEFINE_boolean('pre_calc_image_feature', False, '')

when using tf 1.4.1 it is ok to do --pre_calc_image_feature 0
which got FLAGS.pre_calc_image_feature == False.
But for tf 1.5 you must use --pre_calc_image_feature=0 if you still use --pre_calc_image_feature 0
then you will get FLAGS.pre_calc_image_feature == True. 

Not sure if this is a bug or just by design but personally I think tf version 1.4.1 is better handling this case.
"
15501,Env::MatchPath has different behavior on Windows and Linux,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:



### Describe the problem
For example,

name | pattern |  result on windows | result on Linux
-------|---------|----------------------|--------------
a/a,  |   \*,         |   Matches                 |  No match
a/a/a.txt| \*/\*  |   Matches                 |  No match

As GcsFileSystem uses this function for result filtering,  GcsFileSystem has different behavior on Windows and Linux. It's odd to me. 

### Source code / logs
```c++
#include <Windows.h>
#include <Shlwapi.h>
#include <iostream>
int main()
{
   std::cout << PathMatchSpec(L""aaa\\bbb\\ccc.txt"", L""*"") << std::endl;
    return 0;
}
```

```c
#include <stdio.h>
#include <fnmatch.h>

int main(){
  printf(""%d\n"",fnmatch(""aaa/bbb/ccc.txt"",""*/*"",FNM_PATHNAME));
  return 0;
}
```"
15499,Go bindings: No shape inference function exists for op 'CreateSummaryFileWriter',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: NA (using Go bindings)
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: cuda-9.1.85-1 cudnn-7.0.5-1
- **GPU model and memory**: GTX 1060 6GB
- **Exact command to reproduce**: See below

### Describe the problem
Calling `op.CreateSummaryFileWriter()` panics with: `panic: failed to add operation ""CreateSummaryFileWriter"": No shape inference function exists for op 'CreateSummaryFileWriter', did you forget to define it?`

### Source code / logs
```
package main

import (
	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/op""
)

func main() {
	s := op.NewScope()
	writer := op.SummaryWriter(s)
	createSummaryWriter := op.CreateSummaryFileWriter(s,
		writer,
		op.Const(s.SubScope(""log_dir""), ""tb_logs""),
		op.Const(s.SubScope(""max_queue""), int32(10)),
		op.Const(s.SubScope(""flush_millis""), int32(1000)),
		op.Const(s.SubScope(""filename_suffix""), ""tb_demo""),
	)
	scalar := op.Const(s.SubScope(""scalar""), float32(3.1415))
	step := op.Const(s.SubScope(""step""), int64(1))
	tag := op.Const(s.SubScope(""tag""), ""foo_scalar"")
	summary := op.ScalarSummary(s, tag, scalar)
	merged := op.MergeSummary(s, []tf.Output{summary})
	write := op.WriteSummary(s, writer, step, scalar, tag, merged)
	closeSummaryWriter := op.CloseSummaryWriter(s, writer)
	graph, err := s.Finalize()
	if err != nil {
		panic(err)
	}
	sess, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, nil, []*tf.Operation{createSummaryWriter})
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, nil, []*tf.Operation{write})
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, nil, []*tf.Operation{closeSummaryWriter})
	if err != nil {
		panic(err)
	}
}
```
Returns:
```
2017-12-19 20:39:06.314322: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
panic: failed to add operation ""CreateSummaryFileWriter"": No shape inference function exists for op 'CreateSummaryFileWriter', did you forget to define it? (Stacktrace: goroutine 1 [running]:
runtime/debug.Stack(0xc420082130, 0x13eb530, 0x14298a0)
	/usr/lib/go/src/runtime/debug/stack.go:24 +0xa7
github.com/tensorflow/tensorflow/tensorflow/go/op.(*Scope).UpdateErr(0xc42007c180, 0x4d9527, 0x17, 0x750140, 0xc42000e068)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/op/scope.go:120 +0x72
github.com/tensorflow/tensorflow/tensorflow/go/op.(*Scope).AddOperation(0xc42007c180, 0x4d9527, 0x17, 0x4d9527, 0x17, 0xc4200820f0, 0x5, 0x5, 0x0, 0xc4200181a0)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/op/scope.go:85 +0xfd
github.com/tensorflow/tensorflow/tensorflow/go/op.CreateSummaryFileWriter(0xc42007c180, 0xc420010200, 0x0, 0xc420010210, 0x0, 0xc420010220, 0x0, 0xc420010230, 0x0, 0xc420010240, ...)
	/home/isaac/go/src/github.com/tensorflow/tensorflow/tensorflow/go/op/wrappers.go:16474 +0x2cc
main.main()
	/home/isaac/go/src/github.com/is8ac/gotf/tb_demo.go:11 +0x282
)

goroutine 1 [running]:
main.main()
	/home/isaac/go/src/github.com/is8ac/gotf/tb_demo.go:27 +0x7cc
exit status 2
```"
15498,gradients_1 generated in graph but not connected with AdamOptimizer ,"System information: 
OS platform: Linux Unbuntu 16.04
Tensorflow install from: pip install...
Tensorflow version: 1.4.0
Python version: py2.7

Problem:
I want to write a CNN classification network for MNIST dataset. And I write a class named MNIST_classification, then define '_build_model()' and '_train_phase()' in this class. In main function, I define a object of MNIST_classification class, and callback the '_train_phase()' to start a training process. But I found in Graph(), there are two gradients generated at each computation node, i.e. ""gradients"" and ""gradients_1"". I use tf.gradients(loss, train_vars) to print all gradients' names and get '/gradients_1/*', but within the Graph(), gradients_1 are not connected with a AdamOptimizer, which leads to no backward propagation update for each trainable variable...

 
![image](https://user-images.githubusercontent.com/33562173/34189925-f3c6c4ac-e578-11e7-8b8f-3de98611d415.png)

Source code:

import tensorflow as tf
from utils import utils
import numpy as np

class mnist_classification(object):

    def __init__(self, sess, graph, train_param={'num_of_epoches': 1000,
                                        'num_of_classes': 10,
                                        'log_dir': './log',
                                        'model_dir': './model',
                                        'batch_size': 128,
                                        'learn_rate': 1e-4,
                                        'max_iter': 5000,
                                        'dim_feat': 28}):

        self.num_of_epoches = train_param['num_of_epoches']
        self.log_dir      = train_param['log_dir']
        self.model_dir    = train_param['model_dir']
        self.batch_size   = train_param['batch_size']

        self.learn_rate = train_param['learn_rate']
        self.max_iter   = train_param['max_iter']

        self.dim_feat = train_param['dim_feat']
        self.num_of_classes = train_param['num_of_classes']

        self.sess = sess
        self.graph = graph

        # !Build-up MNIST classification model...
        assert self.sess.graph is self.graph
        self._build_model()



    def _convolution_block(self, inp_feat, kernel_size, num_of_kernel_channels, conv_strides, conv_padding, var_scope):
        '''
            Function:
                        _convolution_block, i.e. convolution + Maxpooling + ReLU
            Input:
                    [1] <tensor> inp_feat, i.e. input feature, dimension->[batch_size, height, width, channel]
                    [2] <int32>  kernel_size
                    [3] <int32> num_of_kernel_channels
                    [4] <int32> conv_strides
                    [5] <string> conv_padding
                    [5] <string> var_scope
            Output:
                    <tensor> activ
        '''
        try:
            num_of_feat_channels = inp_feat.shape[3].value
        except:
            num_of_feat_channels = 1

        with tf.variable_scope(var_scope):
            weights = tf.get_variable(name='conv_weights', shape=[kernel_size, kernel_size, num_of_feat_channels, num_of_kernel_channels],
                                      initializer=tf.random_normal_initializer(stddev=0.1))

            biases = tf.get_variable(name='conv_biases', shape=[num_of_kernel_channels], initializer=tf.zeros_initializer())

        # !Convolution layer...
        conv = tf.nn.conv2d(inp_feat, weights, strides=conv_strides, padding=conv_padding, name='conv', data_format='NHWC') + biases

        # !Activation layer...
        activ = tf.nn.relu(conv)

        # !Pooling layer...
        pool = tf.nn.max_pool(activ,ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')

        return pool





    def _fc_layer(self, inp_feat, num_of_outputs, var_scope):
        '''
            Function:
                        _fc_layer
            Input:
                        [1] inp_feat, dimension->[batch_size, dim_feat]
                        [2] num_of_outputs
                        [3] var_scope: reuse=True
            Output:
                        fc
        '''

        dim_feat = inp_feat.shape[1].value

        with tf.variable_scope(var_scope):

            fc_weights = tf.get_variable(name='fc_weights', dtype=tf.float32, shape=[dim_feat, num_of_outputs], initializer=tf.random_normal_initializer(stddev=0.1))
            fc_bias    = tf.get_variable(name='fc_bias',    dtype=tf.float32, shape=[num_of_outputs], initializer=tf.zeros_initializer())


            # tf.nn.xw_plus_b(x, weights, bias) = tf.matmul(x, weights) + biases
            fc = tf.nn.xw_plus_b(x=inp_feat, weights=fc_weights, biases=fc_bias)

            return fc



    def _build_model(self):

        self.digit = tf.placeholder(dtype=tf.float32, shape=[self.batch_size, self.dim_feat, self.dim_feat, 1])
        self.label = tf.placeholder(dtype=tf.int64, shape=[self.batch_size, self.num_of_classes])

        # # !One-hot encoding for label...
        # with tf.name_scope('label_trans'):
        #     self.new_label = utils._array_sparse_to_dense(self.label, self.num_of_classes)

        conv1 = self._convolution_block(inp_feat=self.digit, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=32, var_scope='conv1')

        conv2 = self._convolution_block(inp_feat=conv1, conv_strides=[1,1,1,1], conv_padding='SAME', kernel_size=5, num_of_kernel_channels=64, var_scope='conv2')

        conv3 = self._convolution_block(inp_feat=conv2, conv_strides=[1, 1, 1, 1], conv_padding='SAME', kernel_size=7,num_of_kernel_channels=64, var_scope='conv3')

        flatt = tf.layers.flatten(conv3, name='flatten')

        fc1 = self._fc_layer(inp_feat=flatt, num_of_outputs=1024, var_scope='fc1')
        fc1 = tf.nn.relu(fc1)

        fc2 = self._fc_layer(inp_feat=fc1, num_of_outputs=10, var_scope='fc2')

        self.predict = tf.nn.softmax(logits=fc2, dim=-1)

        self.loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(onehot_labels=self.label, logits=fc2))

        # !Define MNIST classification accuracy...
        correct = tf.equal(tf.argmax(self.predict, 1), tf.argmax(self.label, 1))
        self.accuracy = tf.reduce_mean(tf.cast(correct, 'float'))

        # !Define training operations...
        self.train_op = tf.train.AdamOptimizer(self.learn_rate).minimize(self.loss)





    def _train(self, img_file, lab_file):

        # !Load data into memory...
        img, n_rows, n_cols = utils._read_MNIST_file(img_file, fmt='>IIII')
        lab, _, _ = utils._read_MNIST_file(lab_file, fmt='>II')


        # !Intialize the global_variables and local_variables...
        self.sess.run(tf.global_variables_initializer())
        self.sess.run(tf.local_variables_initializer())

        # !List all trainable variables...
        train_vars = tf.trainable_variables()
        for var in train_vars:
            print var.name

        # !Add gradients into tensorboard summary...
        gradients = tf.gradients(self.loss, train_vars)
        for ii in range(len(gradients)):
            if gradients[ii]!=None:
                tf.summary.histogram(train_vars[ii].name, gradients[ii])

        # !Add loss into tensorboard summary...
        tf.summary.scalar('loss', self.loss)
        tf.summary.scalar('accuracy', self.accuracy)

        tf.summary.image('input_image', self.digit)

        summary_writer = tf.summary.FileWriter(""./log"", self.sess.graph)

        merged = tf.summary.merge_all()

        # !Start training process...
        for ii_epoch in range(self.num_of_epoches):
            for ii_iter in range(self.max_iter):


                img_batch = utils._randomly_sample(img, self.batch_size)
                img_batch = np.expand_dims(img_batch, axis=3) / 255

                lab_batch = utils._randomly_sample(lab, self.batch_size)
                lab_batch = utils._array_sparse_to_dense(np.int64(lab_batch), num_of_classes=self.num_of_classes)

                _, pred, los, acc, summary= self.sess.run([self.train_op, self.predict, self.loss, self.accuracy, merged], feed_dict={self.digit: img_batch, self.label: lab_batch})

                if ( (ii_epoch * self.max_iter + ii_iter) % 100 == 0):
                    summary_writer.add_summary(summary, ii_epoch * self.max_iter + ii_iter)
                    print(pred[0,:])
                    print(lab_batch[0])

                print('!Loss at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, los))
                print('!Accuracy at No.%d Epoch, No.%d Iteration=%.5f' % (ii_epoch, ii_iter, acc))



Main function:
from utils.utils import _array_sparse_to_dense
from utils.utils import _read_MNIST_file
from matplotlib import pyplot
import numpy as np
import tensorflow as tf
from model.MNIST_classification import mnist_classification
import os
import sys


# !Check if tensorflow version == '1.4.0', API
assert tf.__version__ == '1.4.0'



# !Set system default encoding method == 'utf-8'
reload(sys)
sys.setdefaultencoding('utf-8')


os.environ[""CUDA_DEVICE_ORDER""] = ""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""


with tf.Graph().as_default() as graph:
    with tf.Session() as sess:
        MNIST_inst = mnist_classification(sess=sess, graph=graph)

        MNIST_inst._train(img_file='./data/train-images.idx3-ubyte', lab_file='./data/train-labels.idx1-ubyte')

"
15497,Image Input for GridLSTM,"I would like to use GridLSTM for a handwriting recognition task. Unfortunately, the documentation is lacking info on how to input images into GridLSTMs. 
"
15492,build issue: invalid paths,"### System information
Linux ubuntu 16.04
Bazel 0.9.0
CUDA 9.1
cuDNN 7
TF Branch r1.4

I am getting the following errors / warnings using the set-up above, whilst trying to build the python packages.

```
francesco@franny:~/Repositories/tensorflow$ git checkout r1.4
Branch 'r1.4' set up to track remote branch 'r1.4' from 'origin'.
Switched to a new branch 'r1.4'
francesco@franny:~/Repositories/tensorflow$ ./configure 
Extracting Bazel installation...
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.google.protobuf.UnsafeUtil (file:/home/francesco/.cache/bazel/_bazel_francesco/install/754ae0b065b3dfe883541ff567ae8b5e/_embedded_binaries/A-server.jar) to field java.nio.Buffer.address
WARNING: Please consider reporting this to the maintainers of com.google.protobuf.UnsafeUtil
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
You have bazel 0.9.0 installed.
Please specify the location of python. [Default is /usr/bin/python]: 


Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n
No jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL support? [y/N]: n
No OpenCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 9.1


Please specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 7


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:


Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]5.2


Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native]: 


Add ""--config=mkl"" to your bazel command to build with MKL support.
Please note that MKL on MacOS or windows is still not supported.
If you would like to use a local MKL instead of downloading, please set the environment variable ""TF_MKL_ROOT"" every time before build.
Configuration finished
francesco@franny:~/Repositories/tensorflow$

francesco@franny:~/Repositories/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
.........
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:4:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:6:1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=false to temporarily disable this check.
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:30:9: Traceback (most recent call last):
	File ""/home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD"", line 27
		cc_library(name = ""syclrt"", srcs = [sycl_libr..."")], <3 more arguments>)
	File ""/home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD"", line 30, in cc_library
		sycl_library_path
name 'sycl_library_path' is not defined
ERROR: /home/francesco/.cache/bazel/_bazel_francesco/4ce2bc3731d0d87739dc505f1772132b/external/local_config_sycl/sycl/BUILD:39:1: Target '@local_config_sycl//sycl:using_sycl' contains an error and its package is in error and referenced by '@local_config_sycl//sycl:sycl'
ERROR: /home/francesco/Repositories/tensorflow/third_party/eigen3/BUILD:20:1: Target '@local_config_sycl//sycl:sycl' contains an error and its package is in error and referenced by '//third_party/eigen3:eigen3'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed
INFO: Elapsed time: 13.322s
FAILED: Build did NOT complete successfully (93 packages loaded)
    currently loading: tensorflow/core/kernels ... (2 packages)

```

Any help?"
15490,Cannot reshape with shape=[tensorshapes...],"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Debian 9.3
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.3.0
- **Python version**: 
2.7.13
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
6.0.21
- **GPU model and memory**:
GTX titan X (pascal) 12GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I have several Conv layers and after the last max pooling step, I want to flatten the last pooled layer shape=(Batchsize, height, width, channels) to (Batchsize, -1). It returned error saying some dims are None.  
I tried to print the BS and other_dims, it can be printed to int numbers, none of them are None
If I entered explicit int numbers tf.reshape(x, [2,10]) it will work.
# top MLP
        shape = tf.shape(pooled_h[-1])
        BS = shape[0]
        other_dims = shape[1] * shape[2] * shape[3]
        last_pooled_flat = tf.reshape(pooled_h[-1], [BS, other_dims])  # (BS, n_flat_feats)
        mlp_h = [last_pooled_flat]  # to store mlp hidden layers
# MLP alyers
        for j in range(self.n_mlp_layers):
            h = tf.layers.dense(
                inputs=mlp_h[j],
                units=self.hidden_sizes[i],
                activation=tf.nn.relu,
                kernel_initializer=tf.contrib.layers.xavier_initializer(
                            uniform=True, seed=None, dtype=tf.float32),
                bias_initializer=tf.zeros_initializer(),
                kernel_regularizer=L2_regularizer,
                bias_regularizer=L2_regularizer,
                name=""mlp_{}"".format(j),
                reuse=False)
            mlp_h.append(h)
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
Traceback (most recent call last):
  File ""basemodel_builder.py"", line 143, in <module>
    out = model.apply_rel(x_q, x_d, 1.0)
  File ""basemodel_builder.py"", line 117, in apply_rel
    reuse=False)
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 215, in dense
    return layer.apply(inputs)
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 503, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/base.py"", line 443, in __call__
    self.build(input_shapes[0])
  File ""/u/nieyifan/anaconda2/lib/python2.7/site-packages/tensorflow/python/layers/core.py"", line 109, in build
    raise ValueError('The last dimension of the inputs to `Dense` '

"
15488,Bad access error when deserializing a fully connected TF Lite model,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
`('v1.3.0-rc1-5910-ge2174cc943', '1.4.0')`

### Describe the problem
I trained a very simple feed forward network (model structure is y = W*x + b so basically linear regression) using raw tensorflow code (matrix multiply, bias add and relu) so not using any Estimators or higher order APIs. My main purpose was to see if I could serialize the model, convert it to .lite format and then deserialize it correctly in C++.

I did freeze_graph on this graph.pbtxt and model checkpoints using tensorflow's provided freeze_graph method, and converted to .lite format using the bazel command line instruction (in the lite documentation) Lite conversion command used is

```
bazel run --config=opt \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=frozen_model.pb  \               
 --output_file=frozen_model.lite \               
 --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --input_shape=**1,1** \ 
 --input_array=**x** \          
 --output_array=**output**
``` 
As x is the name of the input 1-Dim placeholder tensor, output is the name of the result of W*x+b. I did not include y as part of the input_array as running with --input_array=x,y, --input_shape=1,1:1,1 as this produced a .lite model with 0 bytes (no output)

Using code very similar to what is in tflite_driver.cc and tflite_driver_test.cc, I was able to get the mobile_net example working fine but this simple model I described above fails with a EXC_BAD_ACCESS error. Upon debugging I saw that the error happens at fully_conncted.cc

```
template <KernelType kernel_type>
TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {
....
  switch (input->type) {  // Already know in/out types are same.
    case kTfLiteFloat32:
      return EvalFloat<**kernel_type**>(context, node, params, data, input, filter,
                                    bias, output);
....
  }
  return kTfLiteOk;
}

```

kernel_type is **kPie** at this point. Looking further into fully_connected.cc, I notice two things.

```
enum KernelType {
  kReference,
  kGenericOptimized,  // Neon-free
  kNeonOptimized,
  kPie,  **// Used by the PIE team**
};

```
And also

```
TfLiteRegistration* Register_FULLY_CONNECTED() {
  **// TODO(ahentz): We don't have a dedicated quantized version of the PIE
  // kernel. For now, the quantized version just defer to the corresponding
  // optimized MINI kernel. At some point we will allow different libraries to
  // be built with different kernels, but for now we have to pick one here.
  return Register_FULLY_CONNECTED_PIE();**
#ifdef USE_NEON
  return Register_FULLY_CONNECTED_NEON_OPT();
#else
  return Register_FULLY_CONNECTED_GENERIC_OPT();
#endif
}

```
Specifically, the EXC_BAD_ACCESS error happens at

```
TfLiteStatus EvalPie(TfLiteContext* context, TfLiteNode* node,
                     ...
  // Output = bias if bias tensor exists.
  if (bias) {
    tensor_utils::VectorBatchVectorAssign(bias->data.f, num_units, batch_size,
                                          output->data.f);
  } 
```

![upload](https://user-images.githubusercontent.com/3603839/34171209-63703e96-e4a2-11e7-89fd-446b1c1c44cb.png)

As we can see the filter and bias terms have bad memory addresses, the input and output tensors have valid memory addresses though

My questions are 
1) Why is kPie kernel_type being picked for my simple model?
2) Based on the comments it looks like kPie is not supported for external use, so could this explain the bad access error?
3) Is this an issue with how I converted to lite format? Here is my command again
```
bazel run --config=opt \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=frozen_model.pb  \               
 --output_file=frozen_model.lite \               
 --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --input_shape=**1,1** \ 
 --input_array=**x** \          
 --output_array=**output**
``` 
4) Is there any example of a very simple model composed out of matmul, add and relu which can be converted to .lite in such a way that it can be correctly deserialized in C++, just like the mobile_net example? I can build up from such an example
"
15487,Android Example breaks for old cameras not having support for FOCUS_MODE_CONTINUOUS_PICTURE,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:

No fixed a bug.

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

Ubuntu 16.04, Tried on Android 21,22,23,24,25

- **TensorFlow installed from (source or binary)**:

Android App

- **TensorFlow version (use command below)**:

Latest in Android App

- **Python version**: 

3.2

- **Bazel version (if compiling from source)**:

Not Applicable

- **GCC/Compiler version (if compiling from source)**:

Not Applicable


- **CUDA/cuDNN version**:

Not Applicable


- **GPU model and memory**:

Not Applicable

- **Exact command to reproduce**:

Compile the Android Example as it is and execute on any Android device with old camera not supporting FOCUS_MODE_CONTINUOUS_PICTURE

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Android Example breaks for old cameras not having support for FOCUS_MODE_CONTINUOUS_PICTURE

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Creating a pull request for the fix.
"
15485,Possible Bug with GPU: matmul_op.cc ,"Hello,

I am trying to run a matrix multiplication on GPU. This is the code i am running on python. 
```
import tensorflow as tf

with tf.device('/gpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)

sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
print(sess.run(c))
```

In the matmul_op.cc i have added an ```std::cout << ""Device: "" << ctx->device()->name << endl;``` in function ```Compute``` that is on line 456. The weird thing is that this ```cout``` prints: ```Device:  /job:localhost/replica:0/task:0/device:CPU:0 ``` while the log_device_placement from the session reports: 
```
2017-12-19 18:50:35.432196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GT 720 major: 3 minor: 5 memoryClockRate(GHz): 0.797
pciBusID: 0000:82:00.0
totalMemory: 1.95GiB freeMemory: 1.95GiB
2017-12-19 18:50:35.432273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GT 720, pci bus id: 0000:82:00.0, compute capability: 3.5)
Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GT 720, pci bus id: 0000:82:00.0, compute capability: 3.5
2017-12-19 18:50:35.455437: I tensorflow/core/common_runtime/direct_session.cc:300] Device mapping:
/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GT 720, pci bus id: 0000:82:00.0, compute capability: 3.5

Tensor(""MatMul:0"", shape=(2, 2), dtype=float32, device=/device:GPU:0)
MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
2017-12-19 18:50:35.456469: I tensorflow/core/common_runtime/placer.cc:874] MatMul: (MatMul)/job:localhost/replica:0/task:0/device:GPU:0
b: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2017-12-19 18:50:35.456525: I tensorflow/core/common_runtime/placer.cc:874] b: (Const)/job:localhost/replica:0/task:0/device:GPU:0
a: (Const): /job:localhost/replica:0/task:0/device:GPU:0
2017-12-19 18:50:35.456555: I tensorflow/core/common_runtime/placer.cc:874] a: (Const)/job:localhost/replica:0/task:0/device:GPU:0
```

I have also checked the ```bool USE_CUBLAS``` and it has value 0, in function ```Compute```. Is it a possible bug or i am doing something wrong?"
15484,[Building Error] clang: error: no such file or directory: 'x86_64',"Hi all,

I met this problem when I was trying to build the Tensorflow Lite for iOS following [this instruction](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/ios.md).



Every thing went well until I tried the command:
`tensorflow/contrib/lite/build_ios_universal_lib.sh`

The error occured:
`clang: error: no such file or directory: 'x86_64'`

What could be the problem? Thank you very much!
My environment: Mac Sierra 10.12.6, XCode 9.2"
15483,What is the best practice for running training and evaluation on the same machine?,"I ask the question at [stackoverflow](https://stackoverflow.com/questions/47883570/what-is-the-best-practice-for-running-training-and-evaluation-on-the-same-machin). No answer so far, maybe I can find people have similar needs.

Here is the question:

**What I want to do?**

1. I only have 1 machine. 

2. I want to evaluate the mode periodically. 

**What I have now?** 


1.  use a placeholder. Say I run 1000 step of training by feeding the training data. then I feed in validation dataset for evaluation. put it in a loop.

    But as google suggested, placeholder is not a good way for long run training.


2. So, I use slim dataset to feed in data. Now, the model is bonded with training dataset like this:
    >      net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID',
    >                                 scope='conv1')

 I have to construct another model(in another graph) which is bonded with validation dataset. 

**Is there a better way of doing that?**

I know that google is focusing on distribution training on large scale, but I think as tensorflow  is a low-level and flexible framwork. There must be a way can do what I want. "
15481,"[BUG] ""no viable conversion "" ERROR raised in ""tensorflow/core/kernels/eigen_pooling.h"" when build v1.4.1 for opencl","### System information
- **OS Platform and Distribution**:Linux Ubuntu 17.10
- **TensorFlow installed from**: source
- **TensorFlow version**:1.4.1
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:0.8.1
- **GCC/Compiler version (if compiling from source)**:7.2

### Describe the problem
""no viable conversion "" ERROR raised when build v1.4.1 with opencl (computecpp CE 0.5.0)

### Source code / logs
ERROR: .../tensorflow/tensorflow/core/kernels/BUILD:3169:1: C++ compilation of rule '//tensorflow/core/kernels:pooling_ops' failed (Exit 1)
In file included from tensorflow/core/kernels/pooling_ops_3d.cc:29:
./tensorflow/core/kernels/eigen_pooling.h:338:12: error: no viable conversion from '__m128' (vector of 4 'float' values) to 'cl::sycl::vec<float, 4>'
    Packet skip_mask =
           ^
./tensorflow/core/kernels/eigen_pooling.h:333:5: note: in instantiation of function template specialization 'Eigen::internal::AvgPoolMeanReducer<float>::reducePacketWithType<cl::sycl::vec<float, 4> >' requested here
    reducePacketWithType(static_cast<T>(0), p, accum);
    ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:186:15: note: in instantiation of function template specialization 'Eigen::internal::AvgPoolMeanReducer<float>::reducePacket<cl::sycl::vec<float, 4> >' requested here
      reducer.reducePacket(self.m_impl.template packet<Unaligned>(firstIndex + j), &p);
              ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:279:56: note: in instantiation of member function 'Eigen::internal::InnerMostDimReducer<Eigen::TensorEvaluator<const Eigen::TensorReductionOp<Eigen::internal::AvgPoolMeanReducer<float>, const Eigen::IndexList<Eigen::type2index<1>>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 3>, const Eigen::TensorVolumePatchOp<-1, -1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 5, 1, long>, 16, MakePointer> > >, MakePointer>, Eigen::ThreadPoolDevice>, Eigen::internal::AvgPoolMeanReducer<float>, true>::reduce' requested here
          InnerMostDimReducer<Self, Op, Vectorizable>::reduce(self, 0, num_coeffs, reducer);
                                                       ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:523:48: note: in instantiation of member function 'Eigen::internal::FullReducer<Eigen::TensorEvaluator<const Eigen::TensorReductionOp<Eigen::internal::AvgPoolMeanReducer<float>, const Eigen::IndexList<Eigen::type2index<1>>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 3>, const Eigen::TensorVolumePatchOp<-1, -1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 5, 1, long>, 16, MakePointer> > >, MakePointer>, Eigen::ThreadPoolDevice>, Eigen::internal::AvgPoolMeanReducer<float>, Eigen::ThreadPoolDevice, true>::run' requested here
      internal::FullReducer<Self, Op, Device>::run(*this, reducer, m_device, data);
                                               ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:133:19: note: in instantiation of member function 'Eigen::TensorEvaluator<const Eigen::TensorReductionOp<Eigen::internal::AvgPoolMeanReducer<float>, const Eigen::IndexList<Eigen::type2index<1>>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 3>, const Eigen::TensorVolumePatchOp<-1, -1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 5, 1, long>, 16, MakePointer> > >, MakePointer>, Eigen::ThreadPoolDevice>::evalSubExprsIfNeeded' requested here
    return m_impl.evalSubExprsIfNeeded(data);
                  ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:132:24: note: (skipping 2 contexts in backtrace; use -ftemplate-backtrace-limit=0 to see all)
    return m_rightImpl.evalSubExprsIfNeeded(m_leftImpl.data());
                       ^
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35:59: note: in instantiation of member function 'Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 5, 1, long>, 16, MakePointer>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 5>, const Eigen::TensorReductionOp<Eigen::internal::AvgPoolMeanReducer<float>, const Eigen::IndexList<Eigen::type2index<1>>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 3>, const Eigen::TensorVolumePatchOp<-1, -1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 5, 1, long>, 16, MakePointer> > >, MakePointer> > >, Eigen::ThreadPoolDevice, true>::run' requested here
      internal::TensorExecutor<const Assign, DeviceType>::run(assign, m_device);
                                                          ^
tensorflow/core/kernels/pooling_ops_3d.cc:108:71: note: in instantiation of function template specialization 'Eigen::TensorDevice<Eigen::TensorMap<Eigen::Tensor<float, 5, 1, long>, 16, MakePointer>, Eigen::ThreadPoolDevice>::operator=<Eigen::TensorReshapingOp<const Eigen::DSizes<long, 5>, const Eigen::TensorReductionOp<Eigen::internal::AvgPoolMeanReducer<float>, const Eigen::IndexList<Eigen::type2index<1>>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long, 3>, const Eigen::TensorVolumePatchOp<-1, -1, -1, const Eigen::TensorMap<Eigen::Tensor<const float, 5, 1, long>, 16, MakePointer> > >, MakePointer> > >' requested here
    output->tensor<T, 5>().device(context->eigen_device<CPUDevice>()) =
                                                                      ^
tensorflow/core/kernels/pooling_ops_3d.cc:194:39: note: in instantiation of member function 'tensorflow::LaunchPoolingOp<Eigen::ThreadPoolDevice, float, tensorflow::PoolingType::AVG>::launch' requested here
    LaunchPoolingOp<Device, T, Type>::launch(context, tensor_in, window, stride,
                                      ^
tensorflow/core/kernels/pooling_ops_3d.cc:133:12: note: in instantiation of member function 'tensorflow::Pooling3DOp<Eigen::ThreadPoolDevice, float, tensorflow::PoolingType::AVG>::Compute' requested here
  explicit Pooling3DOp(OpKernelConstruction* context) : UnaryOp<T>(context) {
           ^
tensorflow/core/kernels/pooling_ops_3d.cc:738:15: note: in instantiation of member function 'tensorflow::Pooling3DOp<Eigen::ThreadPoolDevice, float, tensorflow::PoolingType::AVG>::Pooling3DOp' requested here
TF_CALL_float(REGISTER_CPU_KERNELS);
              ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/vec.h:9461:3: note: candidate constructor not viable: no known conversion from '__m128' (vector of 4 'float' values) to 'const vec<float, 4> &' for 1st argument
  vec(const vec<dataT, kElems> &rhs) {
  ^
external/local_config_sycl/crosstool/../sycl/include/SYCL/vec.h:9437:3: note: candidate template ignored: could not match 'swizzled_vec<float, kElemsRhs, kIndexRhsN...>' against '__attribute__((__vector_size__(4 * sizeof(float)))) float' (vector of 4 'float' values)
  vec(const swizzled_vec<dataT, kElemsRhs, kIndexRhsN...> &rhs) {
  ^
1 error generated.
"
15480, sparse_multiclass_hinge_loss() Error,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows/MacOS
- **TensorFlow installed from (source or binary)**:N
- **TensorFlow version (use command below)**:1.4
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:N
- **GCC/Compiler version (if compiling from source)**:N
- **CUDA/cuDNN version**:NA
- **GPU model and memory**:NA
- **Exact command to reproduce**:See below

### Describe the problem
There seems to be a bug in sparse_multiclass_hinge_loss(), as per the example below.

### Source code / logs

```python
import numpy as np
import tensorflow as tf

x = np.random.uniform(0, 1, size = (100, 5))
y = np.random.choice(3, 100) 
y = y.reshape(100, 1)

X = tf.placeholder(""float32"", [None, 5])
Y = tf.placeholder(""int32"", [None, 1])

weights = {'w': tf.Variable(tf.random_uniform([5, 3]))}
biases = {'b': tf.Variable(tf.zeros([3]))}

logits = tf.add(tf.matmul(X, weights['w']), biases['b'])

loss = tf.reduce_mean(tf.contrib.kernel_methods.sparse_multiclass_hinge_loss(logits=logits, labels=Y))

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    res = sess.run(loss, feed_dict={X: x, Y: y}) 


res
```

 make_tensor_proto(values, dtype, shape, verify_shape)
    369   else:
    370     if values is None:
--> 371       raise ValueError(""None values not supported."")
    372     # if dtype is provided, forces numpy array to be the type
    373     # provided if possible.

ValueError: None values not supported.

"
15477,"[BUG] Undeclared error in: ""tensorflow/contrib/memory_stats/kernels/memory_stats_ops.cc""","### System information
- **Linux Ubuntu 17.10**:
- **TensorFlow installed from source**:
- **TensorFlow version 1.4.1**:
- **Python version 3.6**: 
- **Bazel version (0.8.1)**:
- **GCC/Compiler version (7.2)**:

### Describe the problem
undeclared error raised in ""tensorflow/contrib/memory_stats/kernels/memory_stats_ops.cc"" when build v1.4.1 with jemalloc, OpenCL

### Source code / logs
ERROR: .../tensorflow/tensorflow/contrib/memory_stats/BUILD:17:1: C++ compilation of rule '//tensorflow/contrib/memory_stats:python/ops/_memory_stats_ops.so' failed (Exit 1)
tensorflow/contrib/memory_stats/kernels/memory_stats_ops.cc:64:5: error: unknown type name '**MaxBytesInUseOp**'; did you mean 'BytesInUseOp'?
    MaxBytesInUseOp);
    ^~~~~~~~~~~~~~~
    BytesInUseOp
./tensorflow/core/framework/op_kernel.h:1209:68: note: expanded from macro 'REGISTER_KERNEL_BUILDER'
  REGISTER_KERNEL_BUILDER_UNIQ_HELPER(__COUNTER__, kernel_builder, __VA_ARGS__)
                                                                   ^
./tensorflow/core/framework/op_kernel.h:1212:53: note: expanded from macro 'REGISTER_KERNEL_BUILDER_UNIQ_HELPER'
  REGISTER_KERNEL_BUILDER_UNIQ(ctr, kernel_builder, __VA_ARGS__)
                                                    ^
./tensorflow/core/framework/op_kernel.h:1225:24: note: expanded from macro 'REGISTER_KERNEL_BUILDER_UNIQ'
            return new __VA_ARGS__(context);                          \
                       ^
tensorflow/contrib/memory_stats/kernels/memory_stats_ops.cc:44:7: note: 'BytesInUseOp' declared here
class BytesInUseOp : public MemoryStatsOp {
      ^
1 error generated.
"
15473,tf.contrib.ffmpeg.decode_audio() prints the ffmpeg stdout,"tf.contrib.ffmpeg.decode_audio() prints the ffmpeg stdout for each input and there seems to be not functionality available to suppress that. 


"
15472,"tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported 	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]","

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04  and 14.04and windows
- **TensorFlow installed from (source or binary):Anaconda
- **TensorFlow version (use command below):1.30
- **Python version:2.7 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:CUDA 8.0
- **GPU model and memory**:GeForce GTX TITAN 
- **Exact command to reproduce**:

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.669140: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:18.803520: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.803612: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:18.804101: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.804146: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:18.804578: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.804622: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:18.921353: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.921412: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:18.921736: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.921769: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:18.922064: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:18.922096: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.056649: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.056716: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.057046: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.057079: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.057369: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.057399: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.192128: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.192198: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.192519: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.192551: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.192829: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.192858: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.581540: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.581599: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.581928: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.581961: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.582241: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.582271: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.712218: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.712290: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.712602: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.712634: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:19.712909: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:19.712937: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:20.109602: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.109676: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
2017-12-18 14:27:20.110017: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.110051: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
2017-12-18 14:27:20.110337: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.110368: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
2017-12-18 14:27:20.258401: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.258473: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
2017-12-18 14:27:20.258812: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.258845: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
2017-12-18 14:27:20.259145: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.259175: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast/x)]]
2017-12-18 14:27:20.409659: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.409726: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:20.410061: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.410096: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]
2017-12-18 14:27:20.410375: W tensorflow/core/framework/op_kernel.cc:1182] Unimplemented: Cast float to string is not supported
2017-12-18 14:27:20.410406: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Unimplemented: Cast float to string is not supported
	 [[Node: Cast_6 = Cast[DstT=DT_STRING, SrcT=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](Cast_6/x)]]

### Source code / logs
import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import random
img_weight = 224
img_hight = 224
VOC_NUM_CLASS =15
img_channels=3

def getfile(datapath,labelpath):
    class_train = []
    label_train = []  
    for root ,dirs,files in os.walk(datapath):
        for pic in files:
            class_train.append(os.path.join(root,pic))
    with open(labelpath) as filee:
        i = 0
        for l in filee.readlines():
            if i != 0:
                t = []
               for j in l.split(','):
                    t.append(j.strip('\n'))
                label_train.append(t[0:15])
            else:
                i += 1
    temp=[]
    for i in label_train:
        array1=np.array(i,dtype=int).tostring()
        temp.append(array1)
    label_train=temp
    return  class_train,label_train

def get_batch(image, label, image_W, image_H, batch_size, capacity):
    '''
    Args:
        image: list type
        label: list type
        image_W: image width
        image_H: image height
        batch_size: batch size
        capacity: the maximum elements in queue
    Returns:
        image_batch: 4D tensor [batch_size, width, height, 3], dtype=tf.float32
        label_batch: 1D tensor [batch_size], dtype=tf.int32
    '''

    image = tf.cast(image, tf.string)
    label = tf.cast(label, tf.string)

    # # make an input queue 
    input_queue = tf.train.slice_input_producer([image, label],shuffle=True)

    label = input_queue[1]
    image_contents = tf.read_file(input_queue[0])
    image = tf.image.decode_png(image_contents, channels=3)
    image = tf.image.flip_left_right(image)#对图片进行水平翻转
    image.set_shape([image_H, image_W,3])
    image = tf.image.per_image_standardization(image)#(减去均值除以方差对图像进行标准化)
    label = tf.decode_raw(label, tf.int64)#字符串类型转换为float32的向量
   
    label = tf.cast(label, tf.float32)
    label = tf.reshape(label, [
        VOC_NUM_CLASS,
    ])
    image_batch, label_batch = tf.train.batch(
        [image, label],
        batch_size=batch_size,
        num_threads=64,
        capacity=capacity)
    image_batch = tf.cast(image_batch, tf.float32)
    return image_batch, label_batch
def shulffedata(image,label):
    a = [int(i) for i in range(len(image))]
    random.shuffle(a)
    temp_image = []
    temp_label = []
    for i in a:
        temp_image.append(image[i])
        temp_label.append(label[i])
    image=temp_image
    label=temp_label
    return image,label

def dataprovider():
    train_dir = '/media/thomas/办公/images/'
    train_dircsv = '/media/thomas/办公/cxr8/Binarylabels.csv'
    save_dir='/home/thomas/文档/Densenet/vision_networks-master/chexray/'
    BATCH_SIZE = 1
    name_test = 'datatest'
    images,labels = getfile(train_dir,train_dircsv)


    images,labels=shulffedata(images,labels)

  
    train_images=images[:(int(len(images)*0.8))]

    train_label=labels[:(int(len(images)*0.8))]
    test_images=images[int(len(images)*0.8):]
    test_label =labels[int(len(images)*0.8):]
   train_image_batch,train_label_batch=get_batch(train_images,train_label,img_weight,img_hight,BATCH_SIZE,2000)
    test_image_batch,test_label_batch=get_batch(test_images,test_label,img_weight,img_hight,BATCH_SIZE,2000)

    with tf.Session() as sess:
        i = 0
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)  #when exeute  this sentence ,it report error.
        try:
            while not coord.should_stop() and i < 1:
                image, label = sess.run([test_image_batch, test_label_batch])
                # image, label = sess.run([train_image_batch, train_label_batch])
                # image,label = sess.run([image_batch,label_batch])
                for j in np.arange(BATCH_SIZE):
                    print(""label:"")
                    print(label[j])
                    plt.imshow(image[j, :, :, :])
                    plt.show()
                i += 1
        except tf.errors.OutOfRangeError:
            print(""done!"")
        finally:

            coord.request_stop()

    coord.join(threads)"
15467,some proposal about  tf.metrics,"Have I written custom code  :  YES
OS Platform and Distribution  -Win10
TensorFlow installed from - pip3
TensorFlow version-1.4
Bazel version
CUDA/cuDNN version-8.0
GPU model and memory-2GB
Exact command to reproduce 
## Describe the problem
    

I want to know true-positive,ture-nagetive,false-positive,false-nagetive,recall,precision for each class.
 Although I can implement it at this version(1.40), it need lots of code. I mean the functions don't
 support the multi-class well, it just for the 2 class condition. I think if I can implement them with few
 code, it looks more elegant. 


"
15465,No gradient defined for operation 'MatrixExponential' (op type: MatrixExponential),"I want to optimize a function which contains tf.linalg.expm, however,

No gradient defined for operation 'MatrixExponential' (op type: MatrixExponential)

"
15464,[Feature Request] Sparse compute_gradient,"I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer.

**Have I written custom code**
Version I.
My feature size is huge (500Mil) and sparse, so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf.scatter_sub()
My graph is like this:
```
cost = fn(w)
vars_to_update = tf.gather(w, non_zero_indices)
grads = tf.gradients(cost, vars_to_update)
update_op = tf.scatter_sub(w, non_zero_indeces, grads)
```
I found that tf.graidents() always returns None for tf.gather(). Similar condition if I pass tf.gather() to any optimizer like tf.train.GradientDescentOpitmizer(cost, tf.gather(w, indices)), it will throw unsupported error for tf.gather(). 

I was wondering if I did anything wrong or TF just doesn't support sparse gradient computation? If latter does TF team plan to have that implemented in short future?

Version II.
In stead of creating a sparse tensor and do sparse_tensor_dense_matmul(), I also tried using tf.gather() follow by tf.segment_sum() to implement W*X. By doing this the optimizer apparently automatically performed sparse grad computation and sparse update. However, the speed of the optimizer was **horribly slower (15seconds)** than the sparse tensor approach. And idea why?

Pseudo code:
```
active_weights = tf.gather(weights, non_zero_indices)
total = tf.segment_sum(
                tf.reshape(activated_weights, [-1]),
                segment_ids //which is the row number e.g. [0,0,0,0,1,1,1,2,2,2,3,3,...]
                )
update_op = tf.train.GradientDescentOptimizer().minimize(total, active_weights)
```

**OS Platform and Distribution**
Centos Linux version 3.10.0-229.4.2.el7.x86_64 (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) )

**TensorFlow installed from (source or binary)**
pip install tensorflow

**TF version**
1.3.0

**Python version**
2.7.5

**Bazel version, CUDA/cuDNN, GPU model and memory, Exact command to reproduce**
N/A

**Also there might be a potential bug**
If in the second approach (tf.gather() and tf.segment_sum()) I replace GradientDescentOptimizer with Adam or Adagrad optimizer, the memory would blow up very quickly. I did not look into why that happened so I am not sure if this worth a bug ticket."
15463,Bug: StagingArea.size() always return 0 when placed on a different device,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:b'v1.3.0-rc1-6044-g0b80606' 1.4.0
- **Python version**:  3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:9.0/7.0
- **GPU model and memory**:
- **Exact command to reproduce**:

```python
import tensorflow as tf
from tensorflow.python.ops.data_flow_ops import StagingArea

areas = []
stage_ops = []
sizes = []
for idx, d in enumerate(['/gpu:0', '/gpu:1']):
    with tf.device(d):
        inputs = [tf.constant(1.0), tf.constant(2, dtype=tf.uint8)]
        dtypes = [k.dtype for k in inputs]
        stage = StagingArea(dtypes, shapes=None)
        stage_ops.append(stage.put(inputs))
        areas.append(stage)
        # sizes.append(stage.size())   # this gives correct result

sizes = [k.size() for k in areas]    # this gives wrong result
with tf.Session() as sess:
    print(sess.run(sizes))    # [0, 0]
    sess.run(stage_ops[0])
    sess.run(stage_ops[1])
    sess.run(stage_ops[0])
    sess.run(stage_ops[1])
    print(sess.run(sizes))  # expected: [2,2]; actual: [2,0]
```"
15452,Build break on locale Windows,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1703
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: d752244 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: cmake 3.9.6
- **GCC/Compiler version (if compiling from source)**: msvc 1900
- **CUDA/cuDNN version**: cuda 8.0.61 / cudnn 6.0
- **GPU model and memory**: 1080ti 11GiB
- **Exact command to reproduce**:

    cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^
    -DSWIG_EXECUTABLE=C:\Users\User\swigwin-3.0.10\swig.exe ^
    -DPYTHON_EXECUTABLE=C:\Users\User\Anaconda3\python.exe ^
    -DPYTHON_LIBRARIES=C:\Users\User\Anaconda3\python36.lib ^
    -Dtensorflow_ENABLE_GPU=ON ^
    -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0"" ^
    -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Because msvc use locale code page to open source file, build fail on re2's test if use locale Windows.

Already create a PR on upstream, https://github.com/google/re2/pull/163

Please help,

Thanks.

### Source code / logs
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1281): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1282): error C2064: 詞彙不等於使用 1 引數的函式 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1284): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1285): error C2064: 詞彙不等於使用 1 引數的函式 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1287): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1288): error C2064: 詞彙不等於使用 1 引數的函式 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1296): error C2059: 語法錯誤: ';' [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1298): error C2070: 're2::ErrorTest []': sizeof 運算元不合法，必須是運算式或類型名稱 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1365): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1366): error C2146: 語法錯誤: 遺漏 ';' (在識別項 'string' 之前) [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1375): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1376): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1377): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1378): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1379): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1380): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1382): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1383): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1384): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1385): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1386): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1387): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1389): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1390): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1391): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1392): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1393): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1394): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1416): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1417): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1418): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1630): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1631): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\re2_test.cc(1375): fatal error C1057: 巨集展開中未預期的檔案結尾 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(244): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(245): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(246): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(247): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(248): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(249): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(250): error C2001: 常數中包含新行字元 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(252): error C2064: 詞彙不等於使用 1 引數的函式 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(311): error C2064: 詞彙不等於使用 1 引數的函式 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(311): error C2059: 語法錯誤: ';' [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
    C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\re2\testing\search_test.cc(315): error C2070: 're2::RegexpTest []': sizeof 運算元不合法，必須是運算式或類型名稱 [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2\src\re2\search_test.vcxproj] [C:\Users\User\tensorflow\tensorflow\contrib\cmake\build\re2.vcxproj]
"
15451,Tensorflow Installation Problem in Anaconda3-5.0.1Environment,"After installing the Anaconda3-5.0.1 on Ubuntu 17.10, I have followed the following steps to install the Tesnorflow -

$ conda create -n tensorflow python=3.6
$ source activate tensorflow
(tensorflow)$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.0-cp36-cp36m-linux_x86_64.whl
After installing the above pakages, I have verified the above installation in Anaconda environment, following issues are faced -
we6aisol@we6aisol-H170-Gaming-3:$ source activate tensorflow
(tensorflow) we6aisol@we6aisol-H170-Gaming-3:$ python
Python 3.6.3 |Anaconda, Inc.| (default, Nov 20 2017, 20:41:42)
[GCC 7.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

import tensorflow as tf
/home/we6aisol/anaconda3/envs/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
return f(*args, **kwds)
Please help me to resolve this issue.

Thanks & Regards
Manoj Bansal"
15450,TensorFlow binary was not compiled to use: AVX AVX2 from Java 1.8,"
![image](https://user-images.githubusercontent.com/12063612/34111971-2b81c42a-e446-11e7-8482-6e3f3867e8d6.png)

![image](https://user-images.githubusercontent.com/12063612/34112074-6ad1b824-e446-11e7-8541-02ae054aefa0.png)

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform from Windows 10
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version 1.4.0
- **Java version** : 1.8.0_144
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 
- **GPU model and memory**: GTX 1060 6G and Memory 8G
- **Exact command to reproduce**: javac

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
""C:\Program Files\Java\jdk1.8.0_144\bin\java"" -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:56173,suspend=y,server=n -javaagent:C:\Users\Administrator\.IntelliJIdea2017.3\system\captureAgent\debugger-agent.jar=C:\Users\Administrator\AppData\Local\Temp\capture.props -Dfile.encoding=UTF-8 -classpath ""C:\Program Files\Java\jdk1.8.0_144\jre\lib\charsets.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\deploy.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\access-bridge-64.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\cldrdata.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\dnsns.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\jaccess.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\jfxrt.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\localedata.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\nashorn.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\sunec.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\sunjce_provider.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\sunmscapi.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\sunpkcs11.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\ext\zipfs.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\javaws.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\jce.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\jfr.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\jfxswt.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\jsse.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\management-agent.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\plugin.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\resources.jar;C:\Program Files\Java\jdk1.8.0_144\jre\lib\rt.jar;C:\gitspase\zczdemo\target\classes;E:\maven\Jars\org\tensorflow\tensorflow\1.4.0\tensorflow-1.4.0.jar;E:\maven\Jars\org\tensorflow\libtensorflow\1.4.0\libtensorflow-1.4.0.jar;E:\maven\Jars\org\tensorflow\libtensorflow_jni\1.4.0\libtensorflow_jni-1.4.0.jar;E:\maven\Jars\org\projectlombok\lombok\1.16.18\lombok-1.16.18.jar;C:\Program Files\JetBrains\IntelliJ IDEA 2017.3.1\lib\idea_rt.jar"" com.zcz.tensorflow.zczdemo.HelloTF
Connected to the target VM, address: '127.0.0.1:56173', transport: 'socket'
Hello from 1.4.0
Disconnected from the target VM, address: '127.0.0.1:56173', transport: 'socket'
"
15449,Tensorflow-gpu 1.4.1 windows binaries couldn't be found,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709
- **TensorFlow installed from (source or binary)**: looking for the binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.6.3 64-bit
- **Exact command to reproduce**: ""pip3 install --upgrade tensorflow-gpu""

### Describe the problem

Can't find the binaries for the 1.4.1 windows version"
15448,[Feature] Dataset API - Reinitializable Iterator resets to first dataset element,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: slightly altered stock example (see below)
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: 1.4.0 from source
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
- **CUDA/cuDNN version**: 8.0
- **GPU model and memory**: Nvidia 1060

### Describe the problem
Currently the re-initializable iterator API using .from_structure and Iterator.make_initializer always resets the get_next() op of the iterator to fetch the first element of its Dataset instance again after running `sess.run(training_init_op)` or `sess.run(validation_init_op)`, respectively. 

Is this really the intended behavior? This means, that if you want to switch between training and validation Datasets within one epoch (i.e. in a shorter rhythm than the full dataset length) you will always only iterate over the first `batch_size * number-of-training-steps-before-validation-step` elements of the training set during training. 

### Source code / logs
I guess the code example will make it clearer:
```
# Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(100)
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                  training_dataset.output_shapes)

next_element = iterator.get_next()


training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

with tf.Session() as sess:
   # Run 20 epochs in which the training dataset is traversed, followed by the
   # validation dataset.
   for i in range(5):
       # Initialize an iterator over the training dataset.
       print(""#########################  "", i)
       sess.run(training_init_op)
       for _ in range(10):
           nel = sess.run(next_element)
           print(""train: "", type(nel), nel)

       # Initialize an iterator over the validation dataset.
       sess.run(validation_init_op)
       for _ in range(5):
           nel = sess.run(next_element)
           print(""valid: "", type(nel), nel)
```

Produces the output:

```
#########################   0
train:  <class 'numpy.int64'> 0
train:  <class 'numpy.int64'> 1
train:  <class 'numpy.int64'> 2
train:  <class 'numpy.int64'> 3
train:  <class 'numpy.int64'> 4
train:  <class 'numpy.int64'> 5
train:  <class 'numpy.int64'> 6
train:  <class 'numpy.int64'> 7
train:  <class 'numpy.int64'> 8
train:  <class 'numpy.int64'> 9
valid:  <class 'numpy.int64'> 0
valid:  <class 'numpy.int64'> 1
valid:  <class 'numpy.int64'> 2
valid:  <class 'numpy.int64'> 3
valid:  <class 'numpy.int64'> 4
#########################   1
train:  <class 'numpy.int64'> 0
train:  <class 'numpy.int64'> 1
train:  <class 'numpy.int64'> 2
train:  <class 'numpy.int64'> 3
train:  <class 'numpy.int64'> 4
train:  <class 'numpy.int64'> 5
train:  <class 'numpy.int64'> 6
train:  <class 'numpy.int64'> 7
train:  <class 'numpy.int64'> 8
train:  <class 'numpy.int64'> 9
valid:  <class 'numpy.int64'> 0
valid:  <class 'numpy.int64'> 1
valid:  <class 'numpy.int64'> 2
valid:  <class 'numpy.int64'> 3
valid:  <class 'numpy.int64'> 4
...
```
Apparently, the latter 90 elements of the training set and the latter 45 elements of the validation set never get evaluated. I don't really see the real-world use-case for this behavior. 


I know that you can implement the other functionality via the feedable iterator scheme using one_shot_iterators (but not using initializable iterators) as highlighted by the code below (pay attention to the different iterators used for training and validation here):

```
# Define training and validation datasets with the same structure.
training_dataset = tf.data.Dataset.range(10000000).repeat(2)
validation_dataset = tf.data.Dataset.range(5000000).repeat(2)

# A feedable iterator is defined by a handle placeholder and its structure. We
# could use the `output_types` and `output_shapes` properties of either
# `training_dataset` or `validation_dataset` here, because they have
# identical structure.
handle = tf.placeholder(tf.string, shape=[])
iterator = tf.data.Iterator.from_string_handle(
    handle, training_dataset.output_types, training_dataset.output_shapes)
next_element = iterator.get_next()

# You can use feedable iterators with a variety of different kinds of iterator
training_iterator = training_dataset.make_one_shot_iterator()
validation_iterator = validation_dataset.make_initializable_iterator()

with tf.Session() as sess:
    # The `Iterator.string_handle()` method returns a tensor that can be evaluated
    # and used to feed the `handle` placeholder.
    training_handle = sess.run(training_iterator.string_handle())
    validation_handle = sess.run(validation_iterator.string_handle())
    # Loop forever, alternating between training and validation.
    for i in range(5):
        print(""######################## "", i)
        i += 1
        # Run 10 steps using the training dataset. Note that the training dataset is
        # 2 * the original set, i.e. we run 2 epochs (see .repeat() argument), and we resume from where
        # we left off in the previous `while` loop iteration.
        for _ in range(10):
            nel = sess.run(next_element, feed_dict={handle: training_handle})
            print(""train: "", type(nel), nel)

        # Run one pass over the validation dataset.
        sess.run(validation_iterator.initializer)
        for _ in range(5):
            nel = sess.run(next_element, feed_dict={handle: validation_handle})
            print(""valid: "", type(nel), nel)
```

creates output:

```
########################  0
train:  <class 'numpy.int64'> 0
train:  <class 'numpy.int64'> 1
train:  <class 'numpy.int64'> 2
train:  <class 'numpy.int64'> 3
train:  <class 'numpy.int64'> 4
train:  <class 'numpy.int64'> 5
train:  <class 'numpy.int64'> 6
train:  <class 'numpy.int64'> 7
train:  <class 'numpy.int64'> 8
train:  <class 'numpy.int64'> 9
valid:  <class 'numpy.int64'> 0
valid:  <class 'numpy.int64'> 1
valid:  <class 'numpy.int64'> 2
valid:  <class 'numpy.int64'> 3
valid:  <class 'numpy.int64'> 4
########################  1
train:  <class 'numpy.int64'> 10
train:  <class 'numpy.int64'> 11
train:  <class 'numpy.int64'> 12
train:  <class 'numpy.int64'> 13
train:  <class 'numpy.int64'> 14
train:  <class 'numpy.int64'> 15
train:  <class 'numpy.int64'> 16
train:  <class 'numpy.int64'> 17
train:  <class 'numpy.int64'> 18
train:  <class 'numpy.int64'> 19
valid:  <class 'numpy.int64'> 0
valid:  <class 'numpy.int64'> 1
valid:  <class 'numpy.int64'> 2
valid:  <class 'numpy.int64'> 3
valid:  <class 'numpy.int64'> 4
########################  2
train:  <class 'numpy.int64'> 20
train:  <class 'numpy.int64'> 21
train:  <class 'numpy.int64'> 22
train:  <class 'numpy.int64'> 23
train:  <class 'numpy.int64'> 24
train:  <class 'numpy.int64'> 25
train:  <class 'numpy.int64'> 26
train:  <class 'numpy.int64'> 27
train:  <class 'numpy.int64'> 28
train:  <class 'numpy.int64'> 29
valid:  <class 'numpy.int64'> 0
valid:  <class 'numpy.int64'> 1
valid:  <class 'numpy.int64'> 2
valid:  <class 'numpy.int64'> 3
valid:  <class 'numpy.int64'> 4
```"
15447,[cmake] CPU only build error in tf_stream_executor.cmake,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master
- **Python version**: N/A, building with cmake
- **Bazel version (if compiling from source)**: N/A, building with cmake
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
cd tensorflow/contrib/cmake
mkdir build && cd build
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=""../bin"" ..

### Describe the problem
cmake build fails when 
option(tensorflow_ENABLE_GPU ""Enable GPU support"" OFF)
with following error:
.../tensorflow-master/tensorflow/stream_executor/dso_loader.h:32:30: fatal error: cuda/cuda_config.h: No such file or directory
compilation terminated.

### Source code / logs
Pretty sure that the issue lies in this commit:
https://github.com/tensorflow/tensorflow/commit/f1582cf82f06810900ee99870f5d5d3a7478d044#diff-1d799fa350437420218e5e5aa680c481

in CMakeLists.txt the line
""  include_directories(${tensorflow_source_dir}/third_party/gpus)""
is still under tensorflow_ENABLE_GPU

Which is why dso_loader cannot find cuda_config.h

On the other hand, I suppose it should not use this include at all in the CPU mode."
15445,Cannot compile tensorflow lite (TfLiteCameraDemo and tensorflow/python/tools:freeze_graph) on macOS Sierra,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS Sierra 10.12.6
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.4.1 (fdf34a8 on master branch)
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: 0.8.1-homebrew
- **GCC/Compiler version (if compiling from source)**: Xcode 9.2
- **CUDA/cuDNN version**:  (not using cuda)
- **GPU model and memory**: (not using GPU)
- **Exact command to reproduce**: `bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo`

### Describe the problem
I can compile tensorflow android demo on macOS, but cannot compile tensorflow lite android demo successfully. What I actually want to do is convert a tensorflow model to tensorflow lite model. Similar errors happen.

**UPDATE on Dec 19, 2017: I found the workaround/solution. See my reply below.**

### Source code / logs
Compiled tensorflow android demo on macOS successfully.
```
$ bazel build -c opt //tensorflow/examples/android:tensorflow_demo
...
Target //tensorflow/examples/android:tensorflow_demo up-to-date:
  bazel-bin/tensorflow/examples/android/tensorflow_demo_deploy.jar
  bazel-bin/tensorflow/examples/android/tensorflow_demo_unsigned.apk
  bazel-bin/tensorflow/examples/android/tensorflow_demo.apk
INFO: Elapsed time: 862.549s, Critical Path: 112.20s
INFO: Build completed successfully, 776 total actions
```

But failed to compile tensorflow lite android demo.
```
$ bazel build -c opt --cxxopt='--std=c++11' //tensorflow/contrib/lite/java/demo/app/src/main:TfLiteCameraDemo
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/strings/BUILD.bazel' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/strings' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/strings:BUILD.bazel'?)
...
```

Similar errors happen when I wanted to build the tool of converting tensorflow model to tensorflow lite model which is what I really need.
```
$ bazel build tensorflow/python/tools:freeze_graph
WARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/core/BUILD:1806:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/tensorflow.bzl:1131:30
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/types/optional.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/types' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/types:optional.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/base/config_test.cc' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/base' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/base:config_test.cc'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/internal/address_is_readable.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:internal/address_is_readable.h'?)
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/debugging/leak_check.h' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/debugging' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/debugging:leak_check.h'?)
WARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
ERROR: /Users/XXX/GitRoot/OpenSourceProjects/tensorflow/tensorflow/contrib/lite/BUILD:193:12: Label '//tensorflow/contrib/lite:downloads/absl/absl/strings/BUILD.bazel' crosses boundary of subpackage 'tensorflow/contrib/lite/downloads/absl/absl/strings' (perhaps you meant to put the colon here: '//tensorflow/contrib/lite/downloads/absl/absl/strings:BUILD.bazel'?)
...
```

My config in `WORKSPACE`
```
android_sdk_repository(
    name = ""androidsdk"",
    api_level = 23,
    build_tools_version = ""26.0.1"",
    path = ""/Users/XXX/Resources/Android/sdk"",
)

android_ndk_repository(
    name=""androidndk"",
    path=""/Users/XXX/Resources/Android/ndk/android-ndk-r14b"",
    api_level=14,
)
```

Other
```
$ python --version
Python 2.7.13 :: Continuum Analytics, Inc.
$ bazel version
Build label: 0.8.1-homebrew
Build target: bazel-out/darwin-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Dec 5 19:33:07 2017 (1512502387)
Build timestamp: 1512502387
Build timestamp as int: 1512502387
```

```

== cat /etc/issue ===============================================
Darwin ITSG000227-MAC.local 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.39.2)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin ITSG000227-MAC.local 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""tensorflow/python/pywrap_tensorflow.py"", line 25, in <module>
    from tensorflow.python.platform import self_check
ImportError: No module named platform

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
```"
15442,Tensorflow installation error,"Tensorflow installation error.

Method followed: https://www.tensorflow.org/install/install_linux#InstallingAnaconda

(Environment ubuntu 16.04, anaconda 4.3.29, Python 2.7.13, nvidia 1070 GPU)
Please help.

>>>>>
gopi@gp:~$ source activate tensorflow
(tensorflow) gopi@gp:~$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl
Collecting tensorflow-gpu==1.4.0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl
  Using cached https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.4.0-cp27-none-linux_x86_64.whl
Collecting enum34>=1.1.6 (from tensorflow-gpu==1.4.0)
  Using cached enum34-1.1.6-py2-none-any.whl
Collecting six>=1.10.0 (from tensorflow-gpu==1.4.0)
  Using cached six-1.11.0-py2.py3-none-any.whl
Collecting protobuf>=3.3.0 (from tensorflow-gpu==1.4.0)
  Using cached protobuf-3.5.0.post1-cp27-cp27mu-manylinux1_x86_64.whl
Collecting numpy>=1.12.1 (from tensorflow-gpu==1.4.0)
  Using cached numpy-1.13.3-cp27-cp27mu-manylinux1_x86_64.whl
Collecting wheel (from tensorflow-gpu==1.4.0)
  Using cached wheel-0.30.0-py2.py3-none-any.whl
Collecting backports.weakref>=1.0rc1 (from tensorflow-gpu==1.4.0)
  Using cached backports.weakref-1.0.post1-py2.py3-none-any.whl
Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow-gpu==1.4.0)
  Using cached tensorflow_tensorboard-0.4.0rc3-py2-none-any.whl
Collecting mock>=2.0.0 (from tensorflow-gpu==1.4.0)
  Using cached mock-2.0.0-py2.py3-none-any.whl
Collecting setuptools (from protobuf>=3.3.0->tensorflow-gpu==1.4.0)
  Downloading setuptools-38.2.4-py2.py3-none-any.whl (489kB)
    100% |████████████████████████████████| 491kB 30kB/s 
Collecting futures>=3.1.1; python_version < ""3.2"" (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)
  Downloading futures-3.2.0-py2-none-any.whl
Collecting werkzeug>=0.11.10 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)
  Downloading Werkzeug-0.13-py2.py3-none-any.whl (311kB)
    100% |████████████████████████████████| 317kB 31kB/s 
Collecting html5lib==0.9999999 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)
Collecting markdown>=2.6.8 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)
  Downloading Markdown-2.6.10.zip (414kB)
    100% |████████████████████████████████| 419kB 43kB/s 
Collecting bleach==1.5.0 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4.0)
  Using cached bleach-1.5.0-py2.py3-none-any.whl
Collecting funcsigs>=1; python_version < ""3.3"" (from mock>=2.0.0->tensorflow-gpu==1.4.0)
  Using cached funcsigs-1.0.2-py2.py3-none-any.whl
Collecting pbr>=0.11 (from mock>=2.0.0->tensorflow-gpu==1.4.0)
  Using cached pbr-3.1.1-py2.py3-none-any.whl
Building wheels for collected packages: markdown
  Running setup.py bdist_wheel for markdown ... done
  Stored in directory: /home/gopi/.cache/pip/wheels/1e/5a/55/a80b200d12e234d575ad68c1528593d1ce488720b65b24e48c
Successfully built markdown
Installing collected packages: enum34, six, setuptools, protobuf, numpy, wheel, backports.weakref, futures, werkzeug, html5lib, markdown, bleach, tensorflow-tensorboard, funcsigs, pbr, mock, tensorflow-gpu
Exception:
Traceback (most recent call last):
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/req/req_set.py"", line 784, in install
    **kwargs
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/req/req_install.py"", line 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/req/req_install.py"", line 1064, in move_wheel_files
    isolated=self.isolated,
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/wheel.py"", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""/home/gopi/.local/lib/python2.7/site-packages/pip/wheel.py"", line 329, in clobber
    os.utime(destfile, (st.st_atime, st.st_mtime))
OSError: [Errno 1] Operation not permitted: '/home/gopi/anaconda2/lib/python2.7/site-packages/enum/README'
(tensorflow) gopi@gp:~$ 
"
15438,can tf  use the dataset from western faces to predict the Asia people's faces? ,"can tf  use the dataset from western faces to predict the Asia people's faces? 

是否可以 用西方人的人脸数据 检测 亚洲人脸？"
15435,tensorflow-gpu not working with pycharm,"I am trying to get the tensorflow-gpu working on pycharm but it doesn't compile. When I compile it, it gives me the following compile error

> ImportError: Could not find 'cudart64_80.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 8.0 from this URL:

I am using Pycharm with the Python 3.6 venv and I am pretty sure I have CUDA 8.0 installed. When I check the directory of CUDA\v8.0\bin, it shows the cudart64_80.dll 

It works perfectly on the CPU version but I want it working on the GPU side"
15433,[Feature Request] Automatic node placement,"I read tensorflow white papaer and found node placement which allocates graph nodes to devices without manual configuration.

https://www.reddit.com/r/MachineLearning/comments/4n6a0e/distributed_tensorflow_resource_allocation/

However, this post says this feature was removed because it did not perform well.

I think that automatic allocating graph nodes to devices for optimizing parallel execution is necessary to fully use distributed tensorflow. 

Do you have the plan to add this feature in the future tensorflow?

"
15432,[feature request] Switch to nvidia-docker v2?,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
None

### Describe the problem
Now we are using nvidia-docker v1 for CI build. We should switch to v2 because v1 is now being deprecated. (https://github.com/NVIDIA/nvidia-docker/wiki/About-version-2.0) 

### Source code / logs

"
15430,Placeholders should have a feeding schedule in TensorFlow?,"I have a parameter which should set **at the beginning** of each epoch and it is **constant** during the epoch's execution. Currently, we defined a placeholder for this param and during the training I have to pass the same value in each iteration:

`sess.run(train_op, feed_dict={param: const_param})`

It's a bit inefficient since pass the same value at each step of the same epoch. Is it possible to define a placeholder and feed it once just at the beginning of each epoch?

This feature is available in _tf.data_ when set the tfrecords file at the beginning and fetch data iteratively."
15429,RuntimeError: No C++ shape function registered for standard op: SingleImageRandomDotStereograms,"single_image_random_dot_stereograms (windows bug)
the function works fine on ubuntu 16.04 / tf 1.4.0 (CPU)

I know, that the support for unsupported libraries in tf.contrib on Windows is incomplete, and left up to the individual contributors. I found some sketchy solutions by editing gen_single_image_random_dot_stereograms_ops.py, but i could not figure it out correctly.


**Source code**
```
import tensorflow as tf
from tensorflow.contrib.image import single_image_random_dot_stereograms
img=[[1,2,3,3,2,1],
     [1,2,3,4,5,2],
     [1,2,3,4,5,3],
     [1,2,3,4,5,4],
     [6,5,4,4,5,5]]
session = tf.InteractiveSession()
sirds = single_image_random_dot_stereograms(
    img,
    convergence_dots_size=8,
    number_colors=256,normalize=True)
out = sirds.eval()
png = tf.image.encode_png(out).eval()
with open('picture_out.png', 'wb') as f:
  f.write(png)
```

**Error**
Windows 10 Pro, 1709
conda version : 4.3.30
python version: 3.6.3
tensorflow-gpu 1.4.0

```
File ""C:\Users\###\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 696, in _call_cpp_shape_fn_impl
    ""No C++ shape function registered for standard op: %s"" % op.type)
RuntimeError: No C++ shape function registered for standard op: SingleImageRandomDotStereograms
```

Windows 10 Pro, 1709
conda version : 4.3.30
python version: 3.5.4
tensorflow 1.3.0/tensorflow 1.2.0

`AttributeError: 'NoneType' object has no attribute 'single_image_random_dot_stereograms`
"
15428,[BUG] Cifar10 mutigpu loss does not decrease and is oscillating ,"Hi
I want to develope a resnet50 multigpu system in tensorflow,
so I want to replace my model in [**cifar10_multigpu_train**](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py)
but when I run this code, loss does not decrease efficiently,until step 5000
my question is : can I trust this code? Is  the code correct?
**I use:**
ubuntu 16.04
installed tensorflow with pip2
tensorflow 1.4
cudnn       6 
cuda     8.0.44
Gtx 1080 (2 gpus/8g memory)

command to produce:
go to the above link,download **cifar10_multi_gpu_train.py** and run it 
"
15426,"Unsuccessful TensorSliceReader constructor: Failed to find any matching files for          [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]","I am working on a TensorFlow Speech Recognition challenge and following https://www.tensorflow.org/tutorials/audio_recognition tutorial. The model training is completed, but I'm not able to Freeze the model.
This is what I get after typing the required command:

```
`C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\examples\speech_commands>python freeze.py \
2017-12-17 01:43:38.739183: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2017-12-17 01:43:39.455821: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce 940MX major: 5 minor: 0 memoryClockRate(GHz): 1.2415
pciBusID: 0000:03:00.0
totalMemory: 4.00GiB freeMemory: 3.36GiB
2017-12-17 01:43:39.455957: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce 940MX, pci bus id: 0000:03:00.0, compute capability: 5.0)
2017-12-17 01:43:39.580220: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.588122: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.596502: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.601314: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.607839: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
2017-12-17 01:43:39.613370: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\framework\op_kernel.cc:1192] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
Traceback (most recent call last):
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1323, in _do_call
    return fn(*args)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1302, in _run_fn
    status, run_metadata)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
         [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
         [[Node: save/RestoreV2_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_save/RestoreV2_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""freeze.py"", line 180, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""freeze.py"", line 117, in main
    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\examples\speech_commands\models.py"", line 123, in load_variables_from_checkpoint
    saver.restore(sess, start_checkpoint)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1666, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
         [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
         [[Node: save/RestoreV2_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_save/RestoreV2_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]

Caused by op 'save/RestoreV2_1', defined at:
  File ""freeze.py"", line 180, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""freeze.py"", line 117, in main
    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\Lib\site-packages\tensorflow\examples\speech_commands\models.py"", line 122, in load_variables_from_checkpoint
    saver = tf.train.Saver(tf.global_variables())
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1218, in __init__
    self.build()
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1227, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 1263, in _build
    build_save=build_save, build_restore=build_restore)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 751, in _build_internal
    restore_sequentially, reshape)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 427, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\training\saver.py"", line 267, in restore_op
    [spec.tensor.dtype])[0])
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 1020, in restore_v2
    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\Users\VinithaNair\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for
         [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save/Const_0_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
         [[Node: save/RestoreV2_4/_3 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device_incarnation=1, tensor_name=""edge_18_save/RestoreV2_4"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]`
```
OS - Windows 10
TensorFlow version - 1.4
Python version - 3.6.3
GPU - CUDA V 8 and cuDNN V 6.0

I came across [https://github.com/tensorflow/tensorflow/issues/6082] and [https://github.com/tensorflow/tensorflow/issues/7547](url) where the suggested fix was to add ""./"" to the model name. But, in this case I'm not able find the list of codes where I'm supposed to make the change. How do I find the code that needs the fix? Or is there another issue that I'm unaware of?

Please help."
15425,TypeError: broadcast() takes 1 positional argument but 2 were given,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**: b'v1.3.0-rc1-6044-g0b80606' 1.4.0    (2 days ago)
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Source code / logs
I ran `tensorflow/benchmarks`, and got the following error.
```
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 47, in <module>
    tf.app.run()
  File ""/MYHOME/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""tf_cnn_benchmarks.py"", line 43, in main
    bench.run()
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 956, in run
    return self._benchmark_cnn()
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1046, in _benchmark_cnn
    self._build_model_single_session())
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1563, in _build_model_single_session                                                                      all_top_5_ops, phase_train)
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1370, in _build_fetches
    self.variable_mgr.preprocess_device_grads(device_grads))
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/variable_mgr.py"", line 386, in preprocess_device_grads
    agg_small_grads_max_group=self._agg_small_grads_max_group)
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/allreduce.py"", line 332, in sum_gradients_all_reduce
    if is_hierarchical else aux_device_groups[group_index], num_shards))
  File ""/MYHOME/tf-benchmarks/scripts/tf_cnn_benchmarks/allreduce.py"", line 236, in sum_grad_and_var_all_reduce
    tf.add)
  File ""/MYHOME/.local/lib/python3.6/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py"", line 780, in build_nccl_then_ring
    return _build_nccl_hybrid(input_tensors, red_op, upper_level_f)
  File ""/MYHOME/.local/lib/python3.6/site-packages/tensorflow/contrib/all_reduce/python/all_reduce.py"", line 748, in _build_nccl_hybrid
    send_op, dst_tensors = nccl.broadcast(level_2_output[w], dst_devices)
TypeError: broadcast() takes 1 positional argument but 2 were given
```

The reason is that the invocation of `nccl.broadcast` is different from its signature:
https://github.com/tensorflow/tensorflow/blob/17e725c0558581cba19bd6c409698b2c3f88efe5/tensorflow/contrib/all_reduce/python/all_reduce.py#L748
https://github.com/tensorflow/tensorflow/blob/17e725c0558581cba19bd6c409698b2c3f88efe5/tensorflow/contrib/nccl/python/ops/nccl_ops.py#L173-L182 
Problems still exists in current HEAD."
15424,"""Not a valid TensorFlow Graph serialization"" at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph.loadGraph","Hi,
I build libtensorflow_inference.so & libandroid_tensorflow_inference_java.jar from source, then use them in an android studio project. But when I run
TensorFlowInferenceInterface tflite = new TensorFlowInferenceInterface(assetManager, MODEL_PATH);
the program always crashes and prints
""
Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDef
at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:551)
at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:105)
......
""
The tflite file in MODEL_PATH is generated successfully by bazel toco from a model graph, and the tflite file is successfully read into byte array. Are there any special restrictions on the graph? What are the possible reasons why function TensorFlowInferenceInterface.loadGraph() throws an Exception?

Thanks a lot."
15423,Can't build with basel Python Configuration Error: --define PYTHON_BIN_PATH,"Can't get what im doing wrong.
Win7 python 3.6, tensorflow from master, cuda 9.0, cudnn 7.0.5 for cuda 9.0, basel and swig loaded today 

https://github.com/tensorflow/tensorflow/issues/12052

> C:\Users\Andrey\Desktop\tensorflow>bazel clean
> ...........
> INFO: Starting clean (this may take a while). Consider using --async if the clea
> n takes more than several minutes.
> 
> C:\Users\Andrey\Desktop\tensorflow>python configure.py
> WARNING: Running Bazel server needs to be killed, because the startup options ar
> e different.
> You have bazel 0.8.1 installed.
> Please specify the location of python. [Default is C:\Users\Andrey\Anaconda3\pyt
> hon.exe]:
> 
> 
> Found possible Python library paths:
>   C:\Users\Andrey\Anaconda3\lib\site-packages
> Please input the desired Python library path to use.  Default is [C:\Users\Andre
> y\Anaconda3\lib\site-packages]
> 
> Do you wish to build TensorFlow with XLA JIT support? [y/N]: y
> XLA JIT support will be enabled for TensorFlow.
> 
> Do you wish to build TensorFlow with GDR support? [y/N]: y
> GDR support will be enabled for TensorFlow.
> 
> Do you wish to build TensorFlow with VERBS support? [y/N]: y
> VERBS support will be enabled for TensorFlow.
> 
> Do you wish to build TensorFlow with CUDA support? [y/N]: y
> CUDA support will be enabled for TensorFlow.
> 
> Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to d
> efault to CUDA 9.0]:
> 
> 
> Please specify the location where CUDA 9.0 toolkit is installed. Refer to README
> .md for more details. [Default is C:/Program Files/NVIDIA GPU Computing Toolkit/
> CUDA/v9.0]:
> 
> 
> Please specify the cuDNN version you want to use. [Leave empty to default to cuD
> NN 7.0]:
> 
> 
> Please specify the location where cuDNN 7 library is installed. Refer to README.
> md for more details. [Default is C:/Program Files/NVIDIA GPU Computing Toolkit/C
> UDA/v9.0]:
> 
> 
> Please specify a list of comma-separated Cuda compute capabilities you want to b
> uild with.
> You can find the compute capability of your device at: https://developer.nvidia.
> com/cuda-gpus.
> Please note that each additional compute capability significantly increases your
>  build time and binary size. [Default is: 3.5,5.2]
> 
> 
> Do you wish to build TensorFlow with MPI support? [y/N]: n
> No MPI support will be enabled for TensorFlow.
> 
> Please specify optimization flags to use during compilation when bazel option ""-
> -config=opt"" is specified [Default is -march=native]:
> 
> 
> Add ""--config=mkl"" to your bazel command to build with MKL support.
> Please note that MKL on MacOS or windows is still not supported.
> If you would like to use a local MKL instead of downloading, please set the envi
> ronment variable ""TF_MKL_ROOT"" every time before build.
> 
> Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
>  n
> Not configuring the WORKSPACE for Android builds.
> 
> 
> C:\Users\Andrey\Desktop\tensorflow>bazel build --config=opt --config=win-cuda //
> tensorflow/tools/pip_package:build_pip_package
> ...........
> Loading:
> Loading: 0 packages loaded
> Analyzing: target //tensorflow/tools/pip_package:build_pip_package (3 packages l
> oaded)
> Analyzing: target //tensorflow/tools/pip_package:build_pip_package (24 packages
> loaded)
> Analyzing: target //tensorflow/tools/pip_package:build_pip_package (34 packages
> loaded)
> Analyzing: target //tensorflow/tools/pip_package:build_pip_package (72 packages
> loaded)
> ERROR: C:/users/andrey/desktop/tensorflow/third_party/py/numpy/BUILD:11:1: no su
> ch package '@local_config_python//': Traceback (most recent call last):
>         File ""C:/users/andrey/desktop/tensorflow/third_party/py/python_configure
> .bzl"", line 291
>                 _create_local_python_repository(repository_ctx)
>         File ""C:/users/andrey/desktop/tensorflow/third_party/py/python_configure
> .bzl"", line 251, in _create_local_python_repository
>                 _check_python_bin(repository_ctx, python_bin)
>         File ""C:/users/andrey/desktop/tensorflow/third_party/py/python_configure
> .bzl"", line 204, in _check_python_bin
>                 _fail((""--define %s='%s' is not execut...)))
>         File ""C:/users/andrey/desktop/tensorflow/third_party/py/python_configure
> .bzl"", line 27, in _fail
>                 fail((""%sPython Configuration Error:%...)))
> Python Configuration Error: --define PYTHON_BIN_PATH='C:/Users/Andrey/Anaconda3/
> python.exe' is not executable. Is it the python binary?
>  and referenced by '//third_party/py/numpy:headers'
> Analyzing: target //tensorflow/tools/pip_package:build_pip_package (72 packages
> loaded)
> ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' fai
> led; build aborted: Loading failed
> INFO: Elapsed time: 6,710s
> FAILED: Build did NOT complete successfully (72 packages loaded)"
15420,IteratorGetNext should have a None gradient defined,"Currently `IteratorGetNext` has no gradient defined. This can cause failures like below in `tf.gradients`. The solution is to define `None` gradient, like the `tf.stop_gradient` op. A work-around when this failure occurs is to wrap dataset ops inside `tf.stop_gradient`

```
  File ""/Users/yaroslav/anaconda/envs/sep22/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py"", line 590, in gradients
    (op.name, op.type))
LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)

```"
15419,official MNIST example should avoid huge constants,"Right now MNIST model loads dataset as a huge MNIST constant
https://github.com/tensorflow/models/blob/master/official/mnist/mnist.py#L65

This makes graphdef > 1 GB in size. That causes slowness when trying to visualize graph/dump graphdef. It should instead avoid constant. IE, you can load dataset into tf.Variable"
15418,Eager:  `gradients_function` can't compute the gradient for simple functions,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64-bit
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171215
- **Python version**: 3.6.3 |Anaconda, Inc.| (default, Nov  8 2017, 15:10:56) [MSC v.1900 64 bit (AMD64)]
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA
- **Exact command to reproduce**: See description

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem

First, define a loss function:

```
import tensorflow as tf
import tensorflow.contrib.eager as tfe
tfe.enable_eager_execution()

def loss(w):
    prediction = 2 * w + 1
    true_value = 11
    return tf.cast((true_value - prediction)**2, tf.float32)
```

Then, compute the gradient when w=0.1:

`tfe.gradients_function(loss)(0.1)`

The output is as expected. Next, compute the gradient when w=50:

`tfe.gradients_function(loss)(50)`

The output is:

`[None]`

I expected the output to be 360 because the gradient is -40 + 8 w."
15417,no protobuf package for macos Python 3.6,"Following instructions on
https://www.tensorflow.org/install/install_mac

`pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp35-none-macosx_10_11_x86_64.whl
`

This doesn't work for Python 3.6 with error
`protobuf-3.1.0-cp35-none-macosx_10_11_x86_64.whl is not a supported wheel on this platform.
`
If I just change URL cp36, there's no such file

```pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp36-none-macosx_10_11_x86_64.whl

  Could not install requirement protobuf==3.1.0 from https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp36-none-macosx_10_11_x86_64.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp36-none-macosx_10_11_x86_64.whl
Could not install requirement protobuf==3.1.0 from https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp36-none-macosx_10_11_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp36-none-macosx_10_11_x86_64.whl for URL https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp36-none-macosx_10_11_x86_64.whl

```"
15416,tensorflow-aarch64 with keras,"
![screenshot_2017-12-17-15-05-30-239_ru iiec pydroid3](https://user-images.githubusercontent.com/31110466/34079284-0cd76cc4-e33c-11e7-8442-438e88e1a38d.png)
![screenshot_2017-12-17-15-04-20-194_ru iiec pydroid3](https://user-images.githubusercontent.com/31110466/34079285-0d1d5edc-e33c-11e7-9109-fbfdce775814.png)
![screenshot_2017-12-17-15-04-36-922_ru iiec pydroid3](https://user-images.githubusercontent.com/31110466/34079287-0d65de50-e33c-11e7-9b62-9d5b5027b131.png)


Hi! I want to use tensorflow library as backend of keras on my android device. I found and installed pydroid3, keras and tensorflow-aarch64. How can i use it? When i run code it throws exception ""no module named tensorflow"". Any ideas?

Ok, i will.
I used Keras. When i import, it throws exception.
My OS is Android 7.1.2 MIUI 9, CPU arch - aarch64 (arm), GPU is Snapdragon 505. Using PyDroid3 app
I installed tensorflow-aarch64 1.2 from pip.
No bazel.
No cuDNN."
15415,sparse_multiclass_hinge_loss() error,"Hello, 

I'm getting the error below using `sparse_multiclass_hinge_loss()`. Any hints would be highly appreciated.

```python
import numpy as np
import tensorflow as tf

x = np.random.uniform(0, 1, size = (100, 5))
y = np.random.choice(3, 100) 
y = y.reshape(100, 1)

X = tf.placeholder(""float32"", [None, 5])
Y = tf.placeholder(""int32"", [None, 1])

weights = {'w': tf.Variable(tf.random_uniform([5, 3]))}
biases = {'b': tf.Variable(tf.zeros([3]))}

logits = tf.add(tf.matmul(X, weights['w']), biases['b'])

loss = tf.reduce_mean(tf.contrib.kernel_methods.sparse_multiclass_hinge_loss(logits=logits, labels=Y))

init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    res = sess.run(loss, feed_dict={X: x, Y: y}) 


res
```
 make_tensor_proto(values, dtype, shape, verify_shape)
    369   else:
    370     if values is None:
--> 371       raise ValueError(""None values not supported."")
    372     # if dtype is provided, forces numpy array to be the type
    373     # provided if possible.

ValueError: None values not supported.


"
15414,Failed to convert a .pb file to a .lite file where there is a custom lite op sin,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 14.04.5 LTS 
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.4.0
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**: 0.8.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

I followed ""[How to use custom operators](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/custom_operators.md)"" to create a .pb file and ""sin.cc"" in //tensorflow/contrib/lite/kernel/. Then I added ""TfLiteRegistration* Register_SIN();"" and ""AddCustom(""Sin"", Register_SIN());"" in ""register.cc""
But when I used the bazel command to covert the pb file, the sin op can not be converted

Here is the command I used:
bazel build //tensorflow/contrib/lite/toco:toco
bazel-bin/tensorflow/contrib/lite/toco/toco --input_file=tftest/sin.pb --input_format=TENSORFLOW_GRAPHDEF --output_file=tftest/sin.tflite --output_format=TFLITE --inference_type=FLOAT --input_array=input --input_shape=1 --output_array=output
Here is the corresponding ERROE information:
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops. Here is a list of operators for which you will need custom implementations: Sin.

I tried to use ----allow_custom_ops, but it did not work. Here is the ERROR information:
Converting unsupported operation: Sin

I think I have to modify more files, but I do not know which files I should modify and how to modify. Could you please give a detailed demo?
Thx"
15413,Android Failed To Run Inference,"Have I written custom code: No
OS Platform and Distribution: Android
TensorFlow installed from: binary
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

### Describe the problem
With JNI libtensorflow_core.a etc. I can do inference with my model, which is frozen and stripped off unused op by transform_graph [tool](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/tools/graph_transforms/README.md).
But it took so long, about 50 secs to run on a 1x300x400x3 sized input image. I guess maybe the libtensorflow_core.a that I download from [TensorflowPrebuiltWebsite](http://ci.tensorflow.org/job/tensorflow-master-android/) is built in debug mode. The reason why I download libtensorflow_core.a is because I have trouble building it myself.

So I want to use Java API to do inference and see how much time it takes.
This is done by adding dependencies in build.gradle:
`
dependencies {
    compile 'org.tensorflow:tensorflow-android:+'
}
`

But with Java API it throws exceptions for parsing the .pb file. I guess my .pb is incompatible. So I took a step back, I only froze the graph but not stripping off unused op. This time Java API is able to parse the .pb file. But after feed inputs, it throws exception when I call run method on org.tensorflow.contrib.android.TensorFlowInferenceInterface.run().

I have also tried to download prebuilt libandroid_tensorflow_inference_java.jar and libtensorflow_inference.so from [TensorflowPrebuiltWebsite](http://ci.tensorflow.org/view/Nightly/job/nightly-android/lastSuccessfulBuild/artifact/out/), but not working.

Notice that I can do inference with C++ code, that means my neural network model *.pb is CORRECT. I think this is a bug with Java API or its corresponding native implementation.

### logs
```
12-16 11:33:59.954 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/System.out: debugger has settled (1330)
12-16 11:33:59.998 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/HwCust: Constructor found for class android.app.HwCustHwWallpaperManagerImpl
12-16 11:34:00.026 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
12-16 11:34:00.157 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded
12-16 11:34:00.157 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: TensorFlow native methods already loaded
12-16 11:34:00.231 23001-23012/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/art: humin current process: cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance
12-16 11:34:00.231 23001-23012/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/art: current process_level is : 0
12-16 11:34:00.437 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Model load took 169ms, TensorFlow version: 1.4.0
12-16 11:34:00.437 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Successfully loaded model from 'frozen_graph.pb'
12-16 11:34:14.460 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[is_training, feed_input], outputs:[hdr_conv_out/LeakyRelu/Maximum]
12-16 11:34:14.789 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/Process: Sending signal. PID: 23001 SIG: 9
```

### Source code
My project is on git [here](https://gitee.com/ZhongBaby/TestTensorflowJavaAPIPerformance), please help me, thanks!

"
15412,tf.contrib.memory_stats.MaxBytesInUse() got `Op type not registered 'MaxBytesInUse' in binary running` error,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Should be Yes, as subtitle Source code below.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 7 x64
- **TensorFlow installed from (source or binary)**:
`pip install tensorflow-gpu` with Anaconda on windows prompt following the tensorflow official tutorial
- **TensorFlow version (use command below)**:
tensorflow-gpu 1.4.0
- **Python version**: 
3.6, Anaconda
- **Bazel version (if compiling from source)**:
N/A
- **CUDA/cuDNN version**:
8.0/6.0
- **GPU model and memory**:
GTX 1080TI
- **Exact command to reproduce**:
a simply `python code.py` or following source in python

### Describe the problem
The GPU training is all fine on my placement. 
But when I wanna track the memory usage I got the error using MaxBytesInUse(),
the problem is not solved even I upgrade TF from 1.3 to 1.4.
And of course the same error using BytesInUse().

Is any solution or is the possibility that the method not support for Win7? Thanks.

### Source code / logs
The Op created failed even the simple code execute as follow, when I run MaxBytesInUse() to get a tensor to `a` then it failed.

```
import tensorflow as tf
a = tf.contrib.memory_stats.MaxBytesInUse()
```
And got the message
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\contrib\memory_stats\python\ops\memory_stats_ops.py"", line 41, in MaxBytesInUse
    return gen_memory_stats_ops.max_bytes_in_use()
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\contrib\memory_stats\ops\gen_memory_stats_ops.py"", line 88, in max_bytes_in_use
    ""MaxBytesInUse"", name=name)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2958, in create_op
    set_shapes_for_outputs(ret)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2209, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2159, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 627, in call_cpp_shape_fn
    require_shape_fn)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\common_shapes.py"", line 686, in _call_cpp_shape_fn_impl
    input_tensors_as_shapes, status)
  File ""C:\Users\my\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'MaxBytesInUse' in binary running on MY-PC. Make sure the Op and Kernel are registered in the binary running in this process.
```"
15410,Calling tf.contrib.lite.toco_convert results in global name 'tempfile' is not defined error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

Related SO post - https://stackoverflow.com/questions/47645056/tensorflow-lite-toco-python-apl-nameerror-name-tempfile-is-not-defined

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Followed example on Tensorflow Lite documentation

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
MacOS High Sierra

- **TensorFlow installed from (source or binary)**:
Source

- **TensorFlow version (use command below)**:
('v1.3.0-rc1-5910-ge2174cc943', '1.4.0')

- **Python version**: 
2.7.10

- **Bazel version (if compiling from source)**:
bazel release 0.5.4-homebrew

- **GCC/Compiler version (if compiling from source)**:
Apple LLVM version 9.0.0 (clang-900.0.34.1)

- **CUDA/cuDNN version**:
N/A (CPU only)

- **GPU model and memory**:
N/A

- **Exact command to reproduce**:

```
import tensorflow as tf
img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""converteds_model.tflite"", ""wb"").write(tflite_model)

```

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Opened python on terminal and ran

```
import tensorflow as tf
img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""converteds_model.tflite"", ""wb"").write(tflite_model)

```

Resulting output is

```
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/contrib/lite/python/lite.py"", line 198, in toco_convert
    input_data.SerializeToString())
  File ""/Library/Python/2.7/site-packages/tensorflow/contrib/lite/python/lite.py"", line 91, in toco_convert_protos
    with tempfile.NamedTemporaryFile() as fp_toco, \
NameError: global name 'tempfile' is not defined
```

As a sanity check I ran the following

```
import tempfile
with tempfile.NamedTemporaryFile() as fp_toco:
     print fp_toco.name
```
Output was /var/folders/hd/7yc9wgwj5wvd43_d94b4m47m0000gn/T/tmpxxdYMY


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem."
15403,Computing gradients of loop variables return None,"### Problem description
I got `None` when computing gradient of the two loop variables that are supposed to have gradient..

### Minimum code to reproduce the error
```python
def loop_cond(i, *_):
    with tf.control_dependencies([tf.Print(i, [i])]):
        return i < 5

def loop_body(i, a, b):
    c = tf.gradients(b, a)[0]
    b = b + c
    return i + 1, b,  b ** 2
        
a = tf.constant(3.0)
f_i, f_a, f_b = tf.while_loop(loop_cond, loop_body, [0, a, a])
```

It seems to have failed in the first iteration as there was no output from print statement.

### Complete logs
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-23-a766942a3da2> in <module>()
      9 
     10 a = tf.constant(3.0)
---> 11 f_i, f_a, f_b = tf.while_loop(loop_cond, loop_body, [0, a, a])

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)
   2814     loop_context = WhileContext(parallel_iterations, back_prop, swap_memory)  # pylint: disable=redefined-outer-name
   2815     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, loop_context)
-> 2816     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
   2817     return result
   2818 

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)
   2638       self.Enter()
   2639       original_body_result, exit_vars = self._BuildLoop(
-> 2640           pred, body, original_loop_vars, loop_vars, shape_invariants)
   2641     finally:
   2642       self.Exit()

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)
   2588         structure=original_loop_vars,
   2589         flat_sequence=vars_for_body_with_tensor_arrays)
-> 2590     body_result = body(*packed_vars_for_body)
   2591     if not nest.is_sequence(body_result):
   2592       body_result = [body_result]

<ipython-input-23-a766942a3da2> in loop_body(i, a, b)
      5 def loop_body(i, a, b):
      6     c = tf.gradients(b, a)[0]
----> 7     b = b + c
      8     return i + 1, b,  b ** 2
      9 

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    883       if not isinstance(y, sparse_tensor.SparseTensor):
    884         try:
--> 885           y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
    886         except TypeError:
    887           # If the RHS is not a tensor, it might be a tensor aware object

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)
    834       name=name,
    835       preferred_dtype=preferred_dtype,
--> 836       as_ref=False)
    837 
    838 

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)
    924 
    925     if ret is None:
--> 926       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    927 
    928     if ret is NotImplemented:

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    227                                          as_ref=False):
    228   _ = as_ref
--> 229   return constant(v, dtype=dtype, name=name)
    230 
    231 

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name, verify_shape)
    206   tensor_value.tensor.CopyFrom(
    207       tensor_util.make_tensor_proto(
--> 208           value, dtype=dtype, shape=shape, verify_shape=verify_shape))
    209   dtype_value = attr_value_pb2.AttrValue(type=tensor_value.tensor.dtype)
    210   const_tensor = g.create_op(

~/.conda/envs/conda-local/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py in make_tensor_proto(values, dtype, shape, verify_shape)
    369   else:
    370     if values is None:
--> 371       raise ValueError(""None values not supported."")
    372     # if dtype is provided, forces numpy array to be the type
    373     # provided if possible.

ValueError: None values not supported.
```

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Debian GNU/Linux 7.11 (wheezy)
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-4-g9283868 1.4.0
- **Python version**:  3.5.4
- **Bazel version (if compiling from source)**:
- **CUDA/cuDNN version**: NA
- **GPU model and memory**: NA"
15401,module 'tensorflow.contrib' has no attribute 'lite',"Hello folks.

Everytime I try to run the example fo TOCO:

```
import tensorflow as tf

img = tf.placeholder(name=""img"", dtype=tf.float32, shape=(1, 64, 64, 3))
val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])
out = tf.identity(val, name=""out"")
with tf.Session() as sess:
  tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [img], [out])
  open(""test.tflite"", ""wb"").write(tflite_modeL)
``` 

I get the error: **module 'tensorflow.contrib' has no attribute 'lite'**

OS Platform and Distribution: Mac OS High Sierra
Tensorflow installed from pip version 1.4.1. 
Python version: 2.7.14 and 3.6.3 :: Anaconda custom (64-bit)

The informations about my system are those:

== cat /etc/issue ===============================================
Darwin Leandros-MacBook-Pro.local 17.3.0 Darwin Kernel Version 17.3.0: Thu Nov  9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64 x86_64
Mac OS X 10.13.2

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 9.0.0 (clang-900.0.37)
Target: x86_64-apple-darwin17.3.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin Leandros-MacBook-Pro.local 17.3.0 Darwin Kernel Version 17.3.0: Thu Nov  9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.3)
numpydoc (0.7.0)
protobuf (3.5.0.post1)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 105: nvidia-smi: command not found

Seams like tensorflow lite is not available for reason =/

Sorry if this is not a bug and I am just being dumb about how to make TOCO works. 
"
15400,setuptools error on upgrading to 1.4.1,"- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Sierra
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6 (normal install, NO virtualenv, NO anaconda, ...)
- **Exact command to reproduce**: ```sudo pip3 install --upgrade tensorflow```

When upgrading TF 1.4.0 to 1.4.1 using the command above, I get the error message:
```
Could not import setuptools which is required to install from a source distribution.
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pip/req/req_install.py"", line 387, in setup_py
    import setuptools  # noqa
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/__init__.py"", line 10, in <module>
    from setuptools.extern.six.moves import filter, map
  File ""/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/setuptools/extern/__init__.py"", line 1, in <module>
    from pkg_resources.extern import VendorImporter
ModuleNotFoundError: No module named 'pkg_resources.extern'
```

I have been able to solve the problem with the following command:

```
pip3 install -U setuptools
```
After this, running pip3 install --upgrade Tensorflow runs successfully."
15398,Feature request: tf.info to show docstrings in jupyter notebook,"When working with jupyter notebooks, it is really helpful to see the documentation within the notebook. Numpy has a function called `np.info` which takes a numpy function as argument and prints its docstring. For example, np.info(np.mean) prints the docstring for `np.mean`. It would be really helpful to have an equivalent `tf.info` for those of us who work with jupyter notebooks (and who doesn't?)."
15397,Tensorflow c++ memory leak - Valgrind,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 17.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.5.1
- **GCC/Compiler version (if compiling from source)**: 6.0.3
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Describe the problem**:


I am executing simple tensorflow code to create graph def as shown below

```
tensorflow::NewSession (options, &session)
ReadBinaryProto (tensorflow::Env::Default(), ""/home/ashok/eclipseWorkspace/faceRecognition-x86_64/Data/models/optimized_facenet.pb"", &graph_def));
session->Create (graph_def);
```

But when I run Valgrind as shown below
```
valgrind --leak-check=full --show-leak-kinds=all --vex-guest-max-insns=25 ./faceRecognition-x86_64 -r -i
```
 I get below errors

```
==12366== 16,000 bytes in 1 blocks are still reachable in loss record 47,782 of 47,905
==12366==    at 0x4C2E19F: operator new(unsigned long) (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==12366==    by 0xBF875DC: std::vector<tensorflow::CostModel::MemUsage, std::allocator<tensorflow::CostModel::MemUsage> >::reserve(unsigned long) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0xBF90128: tensorflow::CostModel::InitFromGraph(tensorflow::Graph const&) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0xBEE48D3: tensorflow::SimpleGraphExecutionState::InitBaseGraph(tensorflow::BuildGraphOptions const&) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0xBEE52CF: tensorflow::SimpleGraphExecutionState::MakeForBaseGraph(tensorflow::GraphDef*, tensorflow::SimpleGraphExecutionStateOptions const&, std::unique_ptr<tensorflow::SimpleGraphExecutionState, std::default_delete<tensorflow::SimpleGraphExecutionState> >*) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0xBE68B9D: tensorflow::DirectSession::MaybeInitializeExecutionState(tensorflow::GraphDef const&, bool*) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0xBE68CF9: tensorflow::DirectSession::ExtendLocked(tensorflow::GraphDef const&) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0xBE68FC7: tensorflow::DirectSession::Create(tensorflow::GraphDef const&) (in /usr/lib/libtensorflow_cc.so)
==12366==    by 0x26B899: TensorFlow::initializeRecognition() (in /home/ashok/eclipseWorkspace/faceRecognition-x86_64/Debug/faceRecognition-x86_64)
==12366==    by 0x24197D: RecognitionWithImages::RecognitionWithImages() (in /home/ashok/eclipseWorkspace/faceRecognition-x86_64/Debug/faceRecognition-x86_64)
==12366==    by 0x12F27C: main (in /home/ashok/eclipseWorkspace/faceRecognition-x86_64/Debug/faceRecognition-x86_64)

```
These type of errors are also generated when I do **session -> run ()** 

Due to the above issues, the memory needed to run the program keeps increasing as time passes and the application crashes due to insufficient memory after  a certain point of time.

I have also posted the issue in stack overflow - https://stackoverflow.com/questions/47834054/tensorflow-c-memory-leak-valgrind"
15396,Bug: reshape shape inference for parital defined shape,"-----------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.6.3 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: see example

### Describe the problem
When the input shape for 'tf.reshape' is partial defined and the new shape contains a `-1` for known dimensions, 'tf.reshape' does not predict the shape. See the example code.

### Source code / logs

Second and third example have working shape inference:
```python
def foo(*shape):
    x = tf.placeholder(tf.float32, shape)
    return tf.reshape(x, tf.concat([tf.shape(x)[:-2], [-1]], 0))

print(foo(2, 3, 4, 5))  # Tensor(""Reshape_8:0"", shape=(2, 3, 20), dtype=float32)  # correct
print(foo(None, 3, 4, 5))  # Tensor(""Reshape_9:0"", shape=(?, 3, ?), dtype=float32)  # shape inference possible
print(foo(None, None, 4, 5))  # Tensor(""Reshape_10:0"", shape=(?, ?, ?), dtype=float32)  # shape inference possible
print(foo(2, 3, 4, None))  # Tensor(""Reshape_11:0"", shape=(2, 3, ?), dtype=float32)  # correct
```

#### Proof that shape inference is possible:
```python
import functools, operator 
def bar(*shape):
    x = tf.placeholder(tf.float32, shape)
    
    tmp = x.shape[-2:]
    if not tmp == tf.TensorShape(None):
        tmp = functools.reduce(operator.mul, tmp, tf.Dimension(1))
    if str(tmp) == '?' or tmp == tf.TensorShape(None):
        shape = [-1]
    else:
        shape = [tmp]
    
    return tf.reshape(x, tf.concat([tf.shape(x)[:-2], shape], 0))


print(bar(2, 3, 4, 5))  # Tensor(""Reshape_21:0"", shape=(2, 3, 20), dtype=float32)
print(bar(None, 3, 4, 5))  # Tensor(""Reshape_22:0"", shape=(?, 3, 20), dtype=float32)
print(bar(None, None, 4, 5))  # Tensor(""Reshape_23:0"", shape=(?, ?, 20), dtype=float32)
print(bar(2, 3, 4, None))  # Tensor(""Reshape_24:0"", shape=(2, 3, ?), dtype=float32)
```"
15395,OS X + GPU NVIDIA nccl dependency missing,"[Comment](https://github.com/tensorflow/tensorflow/pull/14016#discussion_r156704387) migrated to a full issue here.

- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.2 (Any)
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master @HEAD
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A (CMake)
- **GCC/Compiler version (if compiling from source)**: Xcode 8.3.3 (Any)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `cmake -GXcode ...`

### Describe the problem

I'm trying to extend [CMake-Linux support for GPU-build](https://github.com/tensorflow/tensorflow/pull/14016) to finish CMake + OSX testing w/ (NVIDIA) GPU.   I had started with CUDA 8.0 and cuDNN 6.0, but given recent activity here, it seems better to target a recent master branch w/ CUDA 9.0 + cuDNN 7.0.  The OS X CUDA installation does not come with `nccl` (see `find` output below for contents).  NVIDIA has a (login based) `nccl` download for v2.0, but it only has Linux libraries.  I see three other options to support OS X + GPU Builds:

1. https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/nccl (build from bundled source v1.3.5)
2. https://github.com/nvidia/nccl (build from source v1.?)
3. add `option(tensroflow_USE_NCCL ""Use NCCL lib"" ON)` to make it `nccl` optional (I'm not sure how complicated this is) and update the CMake and source code w/ preprocessor definitions as needed

Shall I add the bundled `nccl` (v1.3.5?) files to the CMake build?  I see notes about migrating to v2.0 in commit comments, which seems to be closed source.  If that's the case, then it may be best to try to make any internal tensorflow `nccl` operations optional in order to support single GPU configurations to start with. 

`find /Developer/NVIDIA/CUDA-9.0/lib -name ""*.a""`
```
/Developer/NVIDIA/CUDA-9.0/lib/libcublas_device.a
/Developer/NVIDIA/CUDA-9.0/lib/libcublas_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcudadevrt.a
/Developer/NVIDIA/CUDA-9.0/lib/libcudart_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcufft_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcufftw_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libculibos.a
/Developer/NVIDIA/CUDA-9.0/lib/libcurand_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcusolver_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libcusparse_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppc_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppial_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppicc_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppicom_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppidei_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppif_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppig_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppim_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppist_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppisu_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnppitc_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnpps_static.a
/Developer/NVIDIA/CUDA-9.0/lib/libnvgraph_static.a
```

### Source code / logs

N/A
"
15393,"Build tf_core_kernels on With VS2015 stops with ""fatal error C1060: compiler is out of heap space""","### System information
- Build tf_core_kernels.vcxproj
- Windows 10 Enterprise Build 1607
- TensorFlow installed from source
- TensorFlow version Release 1.4.0 from github
- VS2015 Enterprise 14.0.25431 Update 3 

Cannot build tf_core_kernels.vcxproj (generated with CMake) because of a fatal error C1060: compiler is out of heap space. 

### Source code / logs
1>------ Build started: Project: tf_core_kernels, Configuration: RelWithDebInfo x64 ------
1>  training_ops.cc
1>e:\software\tensorflow\tensorflow\contrib\cmake\build\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBase.h(245): fatal error C1060: compiler is out of heap space
1>  INTERNAL COMPILER ERROR in 'C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\x86_amd64\CL.exe'
"
15392,build_all_android.sh does not work on TF 1.4 branch,"Run `build_all_android.sh` on the `1.4` branch and it will fail with:

    cp: <PATH>/tensorflow/tensorflow/contrib/makefile/downloads/nsync/public: No such file or directory"
15391,tf.nn.leaky_relu does not work with float64,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Fedora 26
- **TensorFlow installed from (source or binary)**: binary, pip3 install tensorflow
- **TensorFlow version (use command below)**: v1.4.0-19-ga52c8d9 1.4.1
- **Python version**: Python 3.6.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: None
- **GPU model and memory**: Doesn't apply
- **Exact command to reproduce**: See below

### Describe the problem

`tf.nn.leaky_relu` does not work with float64. It only seems to work with float32. I can't think of a reason why it should not work with float64, so I consider this a bug, your mileage might vary. I'm also not familiar enough with tf code to fix it myself without any help. :-)

It seems at least [ops.py#L926](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/framework/ops.py#L926) should be in a `try` block just as [ops.py#L912](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/framework/ops.py#L912)

Also the unit tests only test float32.

### Source code / logs

```
In [1]: import tensorflow as tf
/usr/lib64/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)

In [2]: c = tf.constant(5.0, dtype=tf.float32)

In [3]: lr = tf.nn.leaky_relu(c)

In [4]: c = tf.constant(5.0, dtype=tf.float64)

In [5]: lr = tf.nn.leaky_relu(c)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-71e83d060e7b> in <module>()
----> 1 lr = tf.nn.leaky_relu(c)

~/.emacs.d/.python-environments/jedi/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py in leaky_relu(features, alpha, name)
   1541     features = ops.convert_to_tensor(features, name=""features"")
   1542     alpha = ops.convert_to_tensor(alpha, name=""alpha"")
-> 1543     return math_ops.maximum(alpha * features, features)
   1544 
   1545 

~/.emacs.d/.python-environments/jedi/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    883       if not isinstance(y, sparse_tensor.SparseTensor):
    884         try:
--> 885           y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name=""y"")
    886         except TypeError:
    887           # If the RHS is not a tensor, it might be a tensor aware object

~/.emacs.d/.python-environments/jedi/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)
    834       name=name,
    835       preferred_dtype=preferred_dtype,
--> 836       as_ref=False)
    837 
    838 

~/.emacs.d/.python-environments/jedi/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx)
    924 
    925     if ret is None:
--> 926       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    927 
    928     if ret is NotImplemented:

~/.emacs.d/.python-environments/jedi/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
    772     raise ValueError(
    773         ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
--> 774         (dtype.name, t.dtype.name, str(t)))
    775   return t
    776 

ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(""Const_1:0"", shape=(), dtype=float64)'
```"
15389,Fatal error while compiling Tensorflow with CUDA 9.1,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-104-generic x86_64)
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
unknown 1.4.0 (Source code is cloned from 798fa36d11119e6fdc13b90a14abfe1805e7de90)
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
0.8.1
- **GCC/Compiler version (if compiling from source)**:
gcc version 5.4.0 20160609
- **CUDA/cuDNN version**:
CUDA 9.1
cuDNN 7.0.5
- **GPU model and memory**:
2 * Tesla V100-PCIE-16GB
- **Exact command to reproduce**:
See description below.

### Describe the problem
While trying to compile the latest TensorFlow(cloned from 798fa36d11119e6fdc13b90a14abfe1805e7de90), such error will be raised:
```
ERROR: /home/ubuntu/tensorflow/tensorflow/contrib/seq2seq/BUILD:64:1: error while parsing .d file: /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow/bazel-out/k8-py3-opt/bin/tensorflow/contrib/seq2seq/_objs/python/ops/_beam_search_ops_gpu/tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.pic.d (No such file or directory)
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14:0,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/contrib/seq2seq/kernels/beam_search_ops.h:19,
                 from tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.cc:20:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:59:34: fatal error: math_functions.hpp: No such file or directory
```

It turns out that in CUDA 9.1, `math_functions.hpp` is located at `cuda/include/crt/math_functions.hpp`, rather than `cuda/include/math_functions.hpp` (CUDA 9.0 does), which leads to this error.
`ln -s /usr/local/cuda/include/crt/math_functions.hpp /usr/local/cuda/include/math_functions.hpp` will fix this problem and complete the compiling process.

#### Reference
https://stackoverflow.com/a/47807106/2666624

### Source code / logs
Traceback is available above.
"
15388,cannot install with virtualenv python3.6,"Have I written custom code      No
OS Platform and Distribution .  MacOS 10.13.2
TensorFlow installed from        conda  URL of the TensorFlow Python package
TensorFlow version .                1.4
Bazel version                             N/A
CUDA/cuDNN version              N/A
GPU model and memory          N/A
Exact command to reproduce  I just follow Install with conda, My python was installed with conda, I think maybe that is the problem.



virtualenv --system-site-packages -p python3 ~/tensorflow
Running virtualenv with interpreter /usr/local/bin/python3
Using base prefix '/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6'
New python executable in /Users/xinhai/tensorflow/bin/python3.6
Also creating executable in /Users/xinhai/tensorflow/bin/python
Installing setuptools, pip, wheel...
  Complete output from command /Users/xinhai/tensorflow/bin/python3.6 - setuptools pip wheel:
  stringstringstringstringstringstringstringstring
Traceback (most recent call last):
  File ""<stdin>"", line 7, in <module>
  File ""/usr/local/lib/python2.7/site-packages/virtualenv_support/pip-9.0.1-py2.py3-none-any.whl/pip/__init__.py"", line 5, in <module>
  File ""/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/logging/__init__.py"", line 28, in <module>
    from string import Template
ImportError: cannot import name 'Template'



...Installing setuptools, pip, wheel...done.
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"", line 2328, in <module>
    main()
  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"", line 713, in main
    symlink=options.symlink)
  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"", line 945, in create_environment
    download=download,
  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"", line 901, in install_wheel
    call_subprocess(cmd, show_stdout=False, extra_env=env, stdin=SCRIPT)
  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"", line 797, in call_subprocess
    % (cmd_desc, proc.returncode))
OSError: Command /Users/xinhai/tensorflow/bin/python3.6 - setuptools pip wheel failed with error code 1"
15387,from pb tf_dst_dtype == DT_UINT8 || tf_dst_dtype == DT_INT32 || tf_dst_dtype == DT_FLOAT  Abort trap: 6,"cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/contrib/lite/toco/toco \
>   --input_file=/Users/cambridge/Desktop/test/my_inception_v4_freeze.pb \
>   --output_file=/Users/cambridge/Desktop/test/my_inception_v4_freeze.pb.lite \
>   --input_format=TENSORFLOW_GRAPHDEF \
>   --output_format=TFLITE \
>   --inference_type=FLOAT \
>   --input_shapes=1,299,299,3 \
>   --input_arrays=input \
>   --output_array=InceptionV4/Logits/Predictions
2017-12-15 16:18:25.486891: I tensorflow/contrib/lite/toco/import_tensorflow.cc:140] Unsupported data type in placehoder op: 7
2017-12-15 16:18:25.487509: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: DecodeJpeg
2017-12-15 16:18:25.487725: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: StridedSlice
2017-12-15 16:18:25.487772: F tensorflow/contrib/lite/toco/import_tensorflow.cc:1160] Check failed: tf_dst_dtype == DT_UINT8 || tf_dst_dtype == DT_INT32 || tf_dst_dtype == DT_FLOAT 
Abort trap: 6"
15384,Can't convert nasnet pb to tflite: Pad not supported,"cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/contrib/lite/toco/toco \
>   --input_file=/Users/cambridge/Desktop/test/nasnet_mobile_freeze.pb \
>   --output_file=/Users/cambridge/Desktop/test/nasnet_mobile_freeze.lite \
>   --input_format=TENSORFLOW_GRAPHDEF \
>   --output_format=TFLITE \
>   --inference_type=FLOAT \
>   --input_shapes=1,224,224,3 \
>   --input_arrays=input \
>   --output_array=final_layer/predictions
2017-12-15 14:18:22.406487: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39 

] Before general graph transformations: 2988 operators, 4360 arrays (0 quantized)
2017-12-15 14:18:22.659788: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39 

] After general graph transformations pass 1: 663 operators, 1419 arrays (0 quantized)
2017-12-15 14:18:22.673152: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39 

] Before dequantization graph transformations: 663 operators, 1419 arrays (0 quantized)
2017-12-15 14:18:22.678500: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312 

] Total transient array allocated size: 4938176 bytes, theoretical optimal value: 3182720 bytes.
2017-12-15 14:18:22.685171: I tensorflow/contrib/lite/toco/toco_tooling.cc:264 

] Estimated count of arithmetic ops: 1.14687 billion (note that a multiply-add is counted as 2 ops).
2017-12-15 14:18:22.691550: F tensorflow/contrib/lite/toco/tflite/export.cc:192 

] Unsupported operator: Pad
Abort trap: 6"
15383,Feature request: Use placeholders to specify the inputs of TFGAN model.,
15380,CMake: external package: PIC option not working,"In many of external cmake files (```/tensorflow/contrib/cmake/external/*.cmake```), it tries to turn PIC on and off with:
```
      CMAKE_CACHE_ARGS
                if(tensorflow_ENABLE_POSITION_INDEPENDENT_CODE)
                        -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON
                else()
                        -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=OFF
                endif()
```

However, the result (with cmake 3.5) is not what we wanted in CMakeCache:
```
CMAKE_POSITION_INDEPENDENT_CODE:BOOL=OFF; endif();
```
Where it should be
```
CMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON
```
because ```tensorflow_ENABLE_POSITION_INDEPENDENT_CODE``` is ON.

This can be corrected by:
```
  -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=${tensorflow_ENABLE_POSITION_INDEPENDENT_CODE}
```

I'll send a PR after some testing along with other fixes (e.g., linking to ZLIB as shared object, not static linking)

---- update requested from @tensorflowbutler ----
Have I written custom code: No.
OS Platform and Distribution: PR-tested at Ubuntu-16.04 and Tizen
TensorFlow installed from: N/A
TensorFlow version: github master branch of last week: 00f8b97fc601381546aea89315dee549bdbbbdfc
Bazel version: N/A (doing it without bazel)
CUDA/cuDNN version: Tizen: 9/7 / Ubuntu: 8/6
GPU model and memory: Titan Xp
Exact command to reproduce: N/A (it is about build)"
15376,"With tf-nightly-gpu, getting error: ImportError: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.23' not found","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: `tf-nightly-gpu` -- I can't import TensorFlow to check the version
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: Cuda 9.0, cuDNN 7.0.4
- **GPU model and memory**: GTX 1080 8GB
- **Exact command to reproduce**:

```
virtualenv --system-site-packages ~/tftest
source ~/tftest/bin/activate
pip install tf-nightly-gpu
python -c 'import tensorflow'
```

### Describe the problem
When I run the commands above, I get the following error:
```
(tftest) reedwm@reedwm2:~$ python -c 'import tensorflow'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/buildtools/current/sitecustomize/sitecustomize.py"", line 152, in SetupPathsAndImport
    return real_import(name, globals, locals, fromlist, level)
  File ""/usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 73, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /lib/x86_64-linux-gnu/libm.so.6: version `GLIBC_2.23' not found (required by /usr/local/google/home/reedwm/tftest/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```

This occurs if I `pip install tf-nightly-gpu==1.5.0.dev20171212`, which is the earliest version of `tf-nightly-gpu` it occurs on. When I pip install the previous version with `pip install tf-nightly-gpu==1.5.0.dev20171207`, the issue does not occur.

This issue is similar to #53 and #3127.

/CC @gunan @jhseu @martinwicke, any ideas what the issue could be?
"
15375,Performance  problem TF VS Keras,"Hello , 
I just got huge difference in results using Keras (Back-end TensorFlow) and TensorFlow. I want to know if the difference in performances is normal .

The keras model produces a loss of 0.2
`model = k.models.Sequential()
model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3,3), input_shape=(75,75,3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(k.layers.convolutional.MaxPooling2D(pool_size=(3,3), strides=(2,2)))
model.add(k.layers.Dropout(0.2))
model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(k.layers.Dropout(0.2))
model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(k.layers.Dropout(0.3))
model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3)))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(k.layers.Dropout(0.3))
model.add(k.layers.Flatten())
model.add(k.layers.Dense(512))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(k.layers.Dropout(0.2))
model.add(k.layers.Dense(256))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(k.layers.Dropout(0.2))
model.add(k.layers.Dense(1))
model.add(Activation('sigmoid'))
mypotim=Adam(lr=0.01, decay=0.0)
model.compile(loss='binary_crossentropy', optimizer = mypotim, metrics=['accuracy'])`

The TensorFlow normal model produces 0.7 :

`x = tf.placeholder(tf.float32, [None, 75,75,3], name=""DNN_Input"") 
learningRateIn= tf.placeholder(tf.float32)
keep_prob = tf.placeholder(tf.float32)
isTrainPlace=tf.placeholder(tf.bool)
with tf.name_scope('conv_1'):  
    conv_1=tf.layers.conv2d(x,64,[3,3],activation=tf.nn.relu)
    batch_n1 = tf.contrib.layers.batch_norm(conv_1,center=True, scale=True, is_training=isTrainPlace, scope='bn1')
    mpool_1=tf.layers.max_pooling2d(batch_n1,pool_size=(2,2),strides=(2,2))
    dropout_1=tf.layers.dropout(mpool_1,rate=0.8,training=isTrainPlace)
with tf.name_scope('conv_2'):      
    conv_2=tf.layers.conv2d(dropout_1,128,[3,3],activation=tf.nn.relu)
    batch_n2 = tf.contrib.layers.batch_norm(conv_2, center=True, scale=True,is_training=isTrainPlace,scope='bn2')
    mpool_2=tf.layers.max_pooling2d(batch_n2,pool_size=(2,2),strides=(2,2))
    dropout_2=tf.layers.dropout(mpool_2,rate=0.8,training=isTrainPlace)
with tf.name_scope('conv_3'):      
    conv_3=tf.layers.conv2d(dropout_2,128,[3,3],activation=tf.nn.relu)
    batch_n3 = tf.contrib.layers.batch_norm(conv_3, center=True, scale=True,is_training=isTrainPlace,scope='bn3')
    mpool_3=tf.layers.max_pooling2d(batch_n3,pool_size=(2,2),strides=(2,2))
    dropout_3=tf.layers.dropout(mpool_3,rate=0.7,training=isTrainPlace)
with tf.name_scope('conv_4'):     
    conv_4=tf.layers.conv2d(dropout_3,64,[3,3],activation=tf.nn.relu)
    batch_n4 = tf.contrib.layers.batch_norm(conv_4,center=True, scale=True,is_training=isTrainPlace,scope='bn4')
    mpool_4=tf.layers.max_pooling2d(batch_n4,pool_size=(2,2),strides=(2,2))
    dropout_4=tf.layers.dropout(mpool_4,rate=0.7,training=isTrainPlace)
    h4=tf.contrib.layers.flatten(dropout_4)
with tf.name_scope('dense_1'):      
    y_dense_1=tf.layers.dense(h4,512,activation=tf.nn.relu)
    batch_dense_1 = tf.contrib.layers.batch_norm(y_dense_1,center=True, scale=True,is_training=isTrainPlace, scope='bn5')
    dropout_dense_1=tf.layers.dropout(batch_dense_1,rate=0.8,training=isTrainPlace)
with tf.name_scope('dense_2'):      
    y_dense_2=tf.layers.dense(dropout_dense_1,256,activation=tf.nn.relu)
    batch_dense_2 = tf.contrib.layers.batch_norm(y_dense_2, center=True, scale=True, is_training=isTrainPlace,scope='bn6')
    dropout_dense_2=tf.layers.dropout(batch_dense_2 ,rate=0.8, training=isTrainPlace)
    y_estimated=tf.layers.dense(dropout_dense_2,2)  `

PS : the code above , is inspired from : [ https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d](url)
Can anybody help me, please, to undersand , if it's normal or not ? does Keras, uses different tensorflow parameters than the default parameters of tensorflow ?
Thanks in advance.
Toetoe."
15374,tf.matching_files order of returned files,"As far as I can tell from `https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/file_system.cc`, the order of filenames returned by `tf.matching_files` can be non-determinstic. 

If that is correct, it would be nice if that were stated in the documentation (and also for `Dataset.list_files` and `train.match_filenames_once`).

Even better would be to guarantee alphabetical order, but I am not sure about the performance overhead that would incur.

This would enable to process files given as e.g.
A/1.png, A/2.png, ... and B/1.png, ... jointly by doing to match_files followed by a zip.

Have I written custom code No
OS Platform and Distribution N/A
TensorFlow installed from pip 
TensorFlow version 1.4.1
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce N/A"
15373,GPU memory usage changed from TF 1.3.0 to 1.4.0 - runs out of memory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code included below
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 14.04
- **TensorFlow installed from (source or binary)**: From pip
- **TensorFlow version (use command below)**: 1.3.0 and 1.4.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: cuda-8.0 cudnn-6.0
- **GPU model and memory**: GTX 1080 8GB
- **Exact command to reproduce**: python <example_script.py>

### Describe the problem
Bug. TensorFlow runs out of GPU memory (ResourceExhaustedError) when using version 1.4.0 when running code that runs fine on version 1.3.0. Please see the following script to reproduce.

### Source code / logs
```
import tensorflow as tf
import tensorflow.contrib.slim.nets as nets
import tensorflow.contrib.slim as slim
from tensorflow.contrib.slim.nets import resnet_v2

kBatchSize = 4
kCropSize = 500
kNumClasses = 10

with tf.device('/gpu:0'):
  images = tf.random_normal([kBatchSize, kCropSize, kCropSize, 3])
  labels = tf.constant(0, dtype=tf.int32, shape=[kBatchSize, kCropSize, kCropSize])

  with slim.arg_scope(resnet_v2.resnet_arg_scope()):
    backbone, end_points = resnet_v2.resnet_v2_101(
        images, None, is_training=True, global_pool=False,
        output_stride=8)

    final_conv = tf.layers.conv2d(backbone, kNumClasses, [1, 1], name='final_conv')
    logits = tf.image.resize_bilinear(final_conv, tf.slice(tf.shape(images), [1], [2]))

  loss = tf.nn.sparse_softmax_cross_entropy_with_logits(
        labels=labels, logits=logits)

optimizer = tf.train.GradientDescentOptimizer(learning_rate=.001)
train_op = slim.learning.create_train_op(loss, optimizer)
slim.learning.train(train_op, '/tmp/resnet')
```
"
15371,Standardize arguments in SessionRunHook APIs.,"Some hooks inheriting from `SessionRunHook` (https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/training/basic_session_run_hooks.py) use different input argument keywords, while implementing the exact same functionality. This should be ironed out.

I wanted to make a PR for this, but I realised this will be backwards incompatible. Still, I think we should standardise this.

E.g.:
`every_secs` (by `SecondOrStepTimer`)
`every_n_secs`  (by `LoggingTensorHook`) [this seems like most descriptive one, to me]
`save_secs` (by `CheckpointSaverHook`)
"
15370,Add the structural similarity (SSIM) index metric as a built-in loss operation,"In many cases existed built-in losses in TensorFlow do not satisfy needs.  We can add [ssim](https://en.wikipedia.org/wiki/Structural_similarity) or (1-ssim) as the loss function into TensorFlow.

There is existed solution provided on [StackOverflow](https://stackoverflow.com/questions/39051451/ssim-ms-ssim-for-tensorflow), but it is better to have the built-in function with fully covered unit tests."
15369,CMake OBJECT library Xcode problems,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.12.2 (Any)
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master @HEAD
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A (CMake)
- **GCC/Compiler version (if compiling from source)**: Xcode 8.3.3 (Any)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `cmake -GXcode ...`

### Describe the problem

CMake's OBJECT libraries don't play well with Xcode generators.  In particular, there is an incompatibility (effectively a bug) that prevents an object library from containing multiple files with the same base filename (""stem""), i.e.

* tensorflow//core/platform/env_time.cc
* tensorflow//core/platform/posix/env_time.cc

This pattern occurs in quite a few places in the tensorflow source code (and is otherwise perfectly reasonable).  For reference, here is a minimal sample project that directly reproduces a test case originally shared in a [post by Matthew Wheeler](http://cmake.3232098.n2.nabble.com/OBJECT-Libraries-with-Xcode-Generator-td7593197.html) on the CMake mailing list:

https://github.com/headupinclouds/cmake_xcode_object_lib

I'd like to help provide a fix for this, but would like some input on the preferred approach prior to implementing anything.  I see a few options:

1. identify duplicates manually and add an alias for the offending files in the repository: `for i in ${FAILURES}; do echo -e ""#include \""$i\"""" > ${i%.cc}_fix.cc; done` and then update CMake to include those files.  Maybe `_fix` could be replaced with a more unique directory name.  PRO: Reasonably easy; CON: The problem will likely occur again, `#include ""source.cc""` violates some style guides
2. iterate through each list of object files in CMake at generate time and identify duplicates automatically, then map each of these files to an alias for the build using something like `configure_file(${duplicate_file} ${CMAKE_CURRENT_BINARY_DIR}/${duplicat_file_w_suffix} COPYONLY)` (for Xcode only).  PRO: Automatic (future proof); CON: More complicated and users can't apply changes directly in their IDE 
3. (long term) replace OBJECT libraries with standard libraries (static or shared based on `CMAKE_BUILD_SHARED`): In addition to the Xcode related bug above, OBJECT libraries have a number of other limitations which make the CMake code more complicated, or rather, standard libraries have a number of benefits that could make the CMake code cleaner.  Perhaps the most significant drawback is that OBJECT libraries can't be used with `target_link_libraries()`, so we lose the ability to pass along transitive dependency chains and scoped [usage requirements](https://cgold.readthedocs.io/en/latest/rejected/object-libraries.html#usage-requirements) from  `find_package()` (future) system dependencies using `target_link_libraries()`.  This relates to [Proposal: Making the cmake build distribution friendly](https://github.com/tensorflow/tensorflow/issues/13061), where common system dependencies would be included using `find_package()` calls and linked directly to the tensorflow submodules: `target_link_libraries(tf_core_lib PRIVATE ${tensorflow_EXTERNAL_PACKAGES}) # zlib, etc`.  This would also allow most of the manual `add_dependencies()` calls to be removed.  (Note: I've already added CMake package config installation steps to most of the google repository dependencies in forks, and will try to get this stuff accepted upstream.)

The last one is broader in scope, so I'm hoping there is an initial workaround based on some variation of (1) or (2) that would be accepted upstream in the near future for CMake + Xcode.  If there is interest in using standard libraries (3), I can help work on putting an initial solution together in a branch for evaluation as a follow up effort.

I understand CMake status is [currently under discussion](https://github.com/tensorflow/tensorflow/issues/14014#issuecomment-340344678).  In any event, I'd like to help get tensorflow building through CMake for easy integration with other CMake based projects, including iOS builds, where Xcode is required.  I also appreciate tensorflow is an incredibly complicated piece of SW, and I appreciate the work that has gone in to supporting CMake builds to date.  Thanks!

### Source code / logs

Numerous ""no such file or directory"" errors such as these:
```
clang: error: no such file or directory: '/Users/developer/tensorflow/tensorflow/contrib/cmake/_builds/xcode-hid-sections/tensorflow.build/Release/tf_core_lib.build/Objects-normal/x86_64/env.o'
clang: error: no such file or directory: '/Users/developer/tensorflow/tensorflow/contrib/cmake/_builds/xcode-hid-sections/tensorflow.build/Release/tf_core_lib.build/Objects-normal/x86_64/env_time.o'
clang: error: no such file or directory: '/Users/developer/tensorflow/tensorflow/contrib/cmake/_builds/xcode-hid-sections/tensorflow.build/Release/tf_core_lib.build/Objects-normal/x86_64/tracing.o
```"
15367,tf.keras.backend.set_learning_phase doesn't work during evaluating model,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Exact command to reproduce**:

### Describe the problem
When I run following script，error  `InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'block1_conv1_bn/keras_learning_phase' with dtype bool`  occured.  After searching in keras repository and stackoverflow, I find it is caused by the design of learning phase parameter of BN layers which behave differently at training and testing time (See [here](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html)). fchollet have added `K.set_learning_phase()` for tensorflow to solve this problem. So when I use `keras` instead of `tf.keras`, no issue is reported. I wonder if this part is still not integrated into tensorflow completely. 

### Source code / logs
```python
import tensorflow as tf
# import keras  # work normally
keras = tf.keras
Xception = keras.applications.Xception
from keras import backend as K

data_path = ""val.tfrecord""
if not isinstance(data_path, (tuple, list)):
    data_path = [data_path]
feature = {'image/encoded': tf.FixedLenFeature([], tf.string),
           'image/class_id': tf.FixedLenFeature([], tf.int64)}
# create file queue
filename_queue = tf.train.string_input_producer(data_path)
# tfrecord file reader
reader = tf.TFRecordReader()
_, example_string = reader.read(filename_queue)
# decode record
features = tf.parse_single_example(example_string, features=feature)
image = tf.decode_raw(features['image/encoded'], out_type=tf.uint8)
image = tf.cast(image, dtype=tf.float32)
# restore shape
image = tf.reshape(image, (96, 96, 3))
label = tf.cast(features['image/class_id'], dtype=tf.int64)
image_batch, label_batch = tf.train.shuffle_batch(tensors=[image, label],
                                                  batch_size=128,
                                                  capacity=10000,
                                                  min_after_dequeue=3000,
                                                  num_threads=8,
                                                  allow_smaller_final_batch=True)

# convert label to one hot label
sess = K.get_session()
# declare learning phase for BN/dropout
K.set_learning_phase(0)
label_batch = tf.one_hot(label_batch, 2, dtype=tf.float32)
model_input = keras.layers.Input(tensor=image_batch)
base_model = Xception(include_top=True,
                      weights=None,   # no pre-trained weights used
                      pooling=""avg"",
                      input_shape=(96, 96, 3),  # modify first layer
                      classes=2)
model_output = base_model(model_input)
test_model = keras.models.Model(inputs=model_input, outputs=model_output)
test_model.load_weights(""weights.h5"")
optimizer = tf.train.RMSPropOptimizer(learning_rate=2e-3, decay=0.9)
test_model.compile(optimizer=optimizer,
                   loss=""categorical_crossentropy"",
                   metrics=['accuracy'])
acc_value = keras.metrics.categorical_accuracy(label_batch, model_output)
# Fit model using data from tf records queue
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)
acc_value_batch = sess.run([acc_value])
print(acc_value_batch)
coord.request_stop()
# wait for threads to stop
coord.join(threads=threads)
sess.close()
```

logs:
```
Caused by op 'block1_conv1_bn/keras_learning_phase', defined at:
  File ""/home/arkenstone/PycharmProjects/startdt/face_liveness_detect/model/patch_based_cnn/test_image.py"", line 66, in <module>
    classes=2)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/applications/xception.py"", line 161, in Xception
    x = BatchNormalization(name='block1_conv1_bn')(x)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/engine/topology.py"", line 252, in __call__
    output = super(Layer, self).__call__(inputs, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py"", line 575, in __call__
    outputs = self.call(inputs, *args, **kwargs)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/layers/normalization.py"", line 109, in call
    training = K.learning_phase()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py"", line 325, in learning_phase
    phase = array_ops.placeholder(dtype='bool', name='keras_learning_phase')
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py"", line 1599, in placeholder
    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 3091, in _placeholder
    ""Placeholder"", dtype=dtype, shape=shape, name=name)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'block1_conv1_bn/keras_learning_phase' with dtype bool
	 [[Node: block1_conv1_bn/keras_learning_phase = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=""/job:localhost/replica:0/task:0/device:GPU:0""]()]]
	 [[Node: Cast_2/_23 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_1603_Cast_2"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]
```"
15365,Automatic node placement (allocating graph nodes to multiple devices) feature  in distributed tensorflow,"I read tensorflow white papaer and found node placement which allocates graph nodes to devices without manual configuration.

https://www.reddit.com/r/MachineLearning/comments/4n6a0e/distributed_tensorflow_resource_allocation/

This post says this feature was removed because it did not perform well.
However, it was posted a year ago and I think you are still developing this feature.

Is it included in the current version of tensorflow?
If so, what code do i need to see?
If inot, do you plan to add this feature?
"
15364,[BUG] Default MaxPoolingOp/AvgPoolingOp only supports NHWC,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux CentOS 7
- **TensorFlow installed from (source or binary)**: pip install tensorflow with virtualEnv
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 2.7.5
- **Exact command to reproduce**:
```python
import numpy as np
import tensorflow as tf
a = tf.nn.max_pool(np.random.rand(1, 1,10,10), [1,1,2,2], [1,1,1,1], 'VALID', data_format='NCHW')
sess=tf.InteractiveSession()
sess.run(a)
```
### Describe the problem
When I try to run a node of type max or avg pool with data_format : 'NCHW' I got an error.
This seems to be a bug because the TF docs affirms that : 
> data_format: A string. 'NHWC', 'NCHW' and 'NCHW_VECT_C' are supported.

### Error logs
With max:
> 2017-12-14 12:40:23.250331: E tensorflow/core/common_runtime/executor.cc:643] Executor failed to create kernel. Invalid argument: Default MaxPoolingOp only supports NHWC.
>                 [[Node: MaxPool = MaxPool[T=DT_DOUBLE, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](MaxPool/input)]]

With Avg:
> tensorflow.python.framework.errors_impl.InvalidArgumentError: Default AvgPoolingOp only supports NHWC.
         [[Node: AvgPool_1 = AvgPool[T=DT_FLOAT, data_format=""NCHW"", ksize=[1, 1, 2, 2], padding=""VALID"", strides=[1, 1, 1, 1], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](AvgPool_1/input)]]
"
15363,how to feed a placeholder with the return values of tf.train.batch() ,"Code:  
images, raw_images, labels = tf.train.batch(
        [image, raw_image, label],
        batch_size = batch_size,
        num_threads = 1,
        capacity = 4 * batch_size,
        allow_smaller_final_batch = True)
    return images, raw_images, labels

 images, _, labels = load_batch(dataset, batch_size=batch_size)
        sess.run(train_op, feed_dict={x: x_img, y_true: label})

Errors:
 sess.run(train_op, feed_dict={x: images, y_true: labels})
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1074, in _run
    raise TypeError('The value of a feed cannot be a tf.Tensor object. '
TypeError: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.
"
15361,//tensorflow/python:bfloat16_test and //tensorflow/python:framework_dtypes_test failing on Windows,"http://ci.tensorflow.org/job/tf-master-win-bzl/2063/console
```
13:00:56 INFO: From Testing //py_test_dir/tensorflow/python:framework_dtypes_test:
13:00:56 ==================== Test output for //py_test_dir/tensorflow/python:framework_dtypes_test:
13:00:56 .........F\\?\C:\tmp\Bazel.runfiles_fnb6t73_\runfiles\org_tensorflow\py_test_dir\tensorflow\python\framework\dtypes_test.py:277: DeprecationWarning: Please use assertEqual instead.
13:00:56   self.assertEquals(dtype.min, np.finfo(numpy_dtype).min)
13:00:56 ......
13:00:56 ======================================================================
13:00:56 FAIL: testIsUnsigned (__main__.TypesTest)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_fnb6t73_\runfiles\org_tensorflow\py_test_dir\tensorflow\python\framework\dtypes_test.py"", line 219, in testIsUnsigned
13:00:56     self.assertEqual(dtypes.as_dtype(""bfloat16"").is_unsigned, False)
13:00:56 AssertionError: True != False
13:00:56 
13:00:56 ----------------------------------------------------------------------
13:00:56 Ran 16 tests in 0.009s
13:00:56 
13:00:56 FAILED (failures=1)
13:00:56 <dtype: 'float32'>: -3.40282e+38 - 3.40282e+38
13:00:56 <dtype: 'float64'>: -1.79769313486e+308 - 1.79769313486e+308
13:00:56 <dtype: 'int32'>: -2147483648 - 2147483647
13:00:56 <dtype: 'uint8'>: 0 - 255
13:00:56 <dtype: 'int16'>: -32768 - 32767
13:00:56 <dtype: 'int8'>: -128 - 127
13:00:56 <dtype: 'int64'>: -9223372036854775808 - 9223372036854775807
13:00:56 <dtype: 'bfloat16'>: 0 - 0
13:00:56 <dtype: 'uint16'>: 0 - 65535
13:00:56 <dtype: 'float16'>: -65504.0 - 65504.0
13:00:56 <dtype: 'uint32'>: 0 - 4294967295
13:00:56 <dtype: 'uint64'>: 0 - 18446744073709551615
13:00:56 <dtype: 'float32_ref'>: -3.40282e+38 - 3.40282e+38
13:00:56 <dtype: 'float64_ref'>: -1.79769313486e+308 - 1.79769313486e+308
13:00:56 <dtype: 'int32_ref'>: -2147483648 - 2147483647
13:00:56 <dtype: 'uint8_ref'>: 0 - 255
13:00:56 <dtype: 'int16_ref'>: -32768 - 32767
13:00:56 <dtype: 'int8_ref'>: -128 - 127
13:00:56 <dtype: 'int64_ref'>: -9223372036854775808 - 9223372036854775807
13:00:56 <dtype: 'bfloat16_ref'>: 0 - 0
13:00:56 <dtype: 'uint16_ref'>: 0 - 65535
13:00:56 <dtype: 'float16_ref'>: -65504.0 - 65504.0
13:00:56 <dtype: 'uint32_ref'>: 0 - 4294967295
13:00:56 <dtype: 'uint64_ref'>: 0 - 18446744073709551615
13:00:56 ================================================================================
13:00:56 INFO: From Testing //py_test_dir/tensorflow/python:bfloat16_test:
13:00:56 ==================== Test output for //py_test_dir/tensorflow/python:bfloat16_test:
13:00:56 FFF.F.FFFFFFFFFFFFFFFF.
13:00:56 ======================================================================
13:00:56 FAIL: testAdd (__main__.Bfloat16NumPyTest)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 189, in testAdd
13:00:56     self.assertAllClose(np.array([[5, 7, 9]]), x + y)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 1083, in assertAllClose
13:00:56     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 1053, in _assertArrayLikeAllClose
13:00:56     np.testing.assert_allclose(a, b, rtol=rtol, atol=atol, err_msg=msg)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 1411, in assert_allclose
13:00:56     verbose=verbose, header=header, equal_nan=equal_nan)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 796, in assert_array_compare
13:00:56     raise AssertionError(msg)
13:00:56 AssertionError: 
13:00:56 Not equal to tolerance rtol=1e-06, atol=1e-06
13:00:56 None
13:00:56 (mismatch 100.0%)
13:00:56  x: array([[5, 7, 9]])
13:00:56  y: array([[ 0.,  0.,  0.]], dtype=float16)
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testArray (__main__.Bfloat16NumPyTest)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 172, in testArray
13:00:56     self.assertEqual(""[[bfloat16(1) bfloat16(2) bfloat16(3)]]"", str(x))
13:00:56 AssertionError: '[[bfloat16(1) bfloat16(2) bfloat16(3)]]' != '[[bfloat16(0) bfloat16(0) bfloat16(0)]]'
13:00:56 - [[bfloat16(1) bfloat16(2) bfloat16(3)]]
13:00:56 ?            ^           ^           ^
13:00:56 + [[bfloat16(0) bfloat16(0) bfloat16(0)]]
13:00:56 ?            ^           ^           ^
13:00:56 
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testCasts (__main__.Bfloat16NumPyTest)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 181, in testCasts
13:00:56     self.assertTrue(np.all(x == y))
13:00:56 AssertionError: False is not true
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testLogSumExp (__main__.Bfloat16NumPyTest)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 196, in testLogSumExp
13:00:56     atol=2e-2)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 1083, in assertAllClose
13:00:56     self._assertArrayLikeAllClose(a, b, rtol=rtol, atol=atol)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\test_util.py"", line 1053, in _assertArrayLikeAllClose
13:00:56     np.testing.assert_allclose(a, b, rtol=rtol, atol=atol, err_msg=msg)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 1411, in assert_allclose
13:00:56     verbose=verbose, header=header, equal_nan=equal_nan)
13:00:56   File ""C:\Program Files\Anaconda3\lib\site-packages\numpy\testing\utils.py"", line 796, in assert_array_compare
13:00:56     raise AssertionError(msg)
13:00:56 AssertionError: 
13:00:56 Not equal to tolerance rtol=1e-06, atol=0.02
13:00:56 None
13:00:56 (mismatch 100.0%)
13:00:56  x: array([[ 4.048587,  5.048587,  6.048587]], dtype=float32)
13:00:56  y: array([[ 0.693359,  0.693359,  0.693359]], dtype=float16)
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testAdd (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 89, in testAdd
13:00:56     self._assertFloatIdentical(1, float(bfloat16(1) + bfloat16(0)))
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 48, in _assertFloatIdentical
13:00:56     self.assertEqual(v, w)
13:00:56 AssertionError: 1 != 0.0
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testDiv (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 123, in testDiv
13:00:56     self.assertTrue(math.isnan(float(bfloat16(0) / bfloat16(0))))
13:00:56 AssertionError: False is not true
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testEqual (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 156, in testEqual
13:00:56     self.assertEqual(v == w, bfloat16(v) == bfloat16(w))
13:00:56 AssertionError: False != True
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testGreater (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 146, in testGreater
13:00:56     self.assertEqual(v > w, bfloat16(v) > bfloat16(w))
13:00:56 AssertionError: True != False
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testGreaterEqual (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 151, in testGreaterEqual
13:00:56     self.assertEqual(v >= w, bfloat16(v) >= bfloat16(w))
13:00:56 AssertionError: False != True
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testHash (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 79, in testHash
13:00:56     self.assertEqual(0x3f80, hash(bfloat16(1.0)))
13:00:56 AssertionError: 16256 != 0
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testLess (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 136, in testLess
13:00:56     self.assertEqual(v < w, bfloat16(v) < bfloat16(w))
13:00:56 AssertionError: True != False
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testLessEqual (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 141, in testLessEqual
13:00:56     self.assertEqual(v <= w, bfloat16(v) <= bfloat16(w))
13:00:56 AssertionError: False != True
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testMul (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 114, in testMul
13:00:56     self._assertFloatIdentical(-1, float(bfloat16(1) * bfloat16(-1)))
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 48, in _assertFloatIdentical
13:00:56     self.assertEqual(v, w)
13:00:56 AssertionError: -1 != 0.0
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testNegate (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 85, in testNegate
13:00:56     self._assertFloatIdentical(-v, float(-bfloat16(v)))
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 48, in _assertFloatIdentical
13:00:56     self.assertEqual(v, w)
13:00:56 AssertionError: -0.0 != 4.591774807899561e-41
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testNotEqual (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 161, in testNotEqual
13:00:56     self.assertEqual(v != w, bfloat16(v) != bfloat16(w))
13:00:56 AssertionError: True != False
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testRepr (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 69, in testRepr
13:00:56     self.assertEqual(""bfloat16(1)"", repr(bfloat16(1)))
13:00:56 AssertionError: 'bfloat16(1)' != 'bfloat16(0)'
13:00:56 - bfloat16(1)
13:00:56 ?          ^
13:00:56 + bfloat16(0)
13:00:56 ?          ^
13:00:56 
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testRoundTripToFloat (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 52, in testRoundTripToFloat
13:00:56     self._assertFloatIdentical(v, float(bfloat16(v)))
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 48, in _assertFloatIdentical
13:00:56     self.assertEqual(v, w)
13:00:56 AssertionError: 1.0 != 0.0
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testRoundTripToInt (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 56, in testRoundTripToInt
13:00:56     self.assertEqual(v, int(bfloat16(v)))
13:00:56 AssertionError: -256 != 0
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testStr (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 60, in testStr
13:00:56     self.assertEqual(""1"", str(bfloat16(1.0)))
13:00:56 AssertionError: '1' != '0'
13:00:56 - 1
13:00:56 + 0
13:00:56 
13:00:56 
13:00:56 ======================================================================
13:00:56 FAIL: testSub (__main__.Bfloat16Test)
13:00:56 ----------------------------------------------------------------------
13:00:56 Traceback (most recent call last):
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 101, in testSub
13:00:56     self._assertFloatIdentical(1, float(bfloat16(1) - bfloat16(0)))
13:00:56   File ""\\?\C:\tmp\Bazel.runfiles_5lnmqasq\runfiles\org_tensorflow\py_test_dir\tensorflow\python\lib\core\bfloat16_test.py"", line 48, in _assertFloatIdentical
13:00:56     self.assertEqual(v, w)
13:00:56 AssertionError: 1 != 0.0
13:00:56 
13:00:56 ----------------------------------------------------------------------
13:00:56 Ran 23 tests in 0.014s
13:00:56 
13:00:56 FAILED (failures=20)
13:00:56 not close where =  (array([0, 0, 0], dtype=int64), array([0, 1, 2], dtype=int64))
13:00:56 not close lhs =  [5 7 9]
13:00:56 not close rhs =  [ 0.  0.  0.]
13:00:56 not close dif =  [ 5.  7.  9.]
13:00:56 not close tol =  [  1.01327896e-06   1.01327896e-06   1.01327896e-06]
13:00:56 dtype = int32, shape = (1, 3)
13:00:56 not close where =  (array([0, 0, 0], dtype=int64), array([0, 1, 2], dtype=int64))
13:00:56 not close lhs =  [ 4.04858732  5.04858732  6.04858732]
13:00:56 not close rhs =  [ 0.69335938  0.69335938  0.69335938]
13:00:56 not close dif =  [ 3.35522795  4.35522795  5.35522795]
13:00:56 not close tol =  [ 0.02000427  0.02000427  0.02000427]
13:00:56 dtype = float32, shape = (1, 3)
13:00:56 ================================================================================
```


@gunan "
15360,"python(2711,0x7fffcc8553c0) malloc: *** error for object 0x120b0fff0: pointer being freed was not allocated","cambridgedeMBP:tensorflow-master cambridge$ bazel-bin/tensorflow/python/tools/freeze_graph \
> --input_graph=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/inception_v4_inf_graph.pb \
> --input_checkpoint=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/my_train_10/model.ckpt \
> --input_binary=true \
> --output_graph=/Users/cambridge/Desktop/naset/models-master/research/slim/flowers_5/frozen_inception_v4.pb \
> --output_node_names=InceptionV4/Predictions/Reshape_1
python(2711,0x7fffcc8553c0) malloc: *** error for object 0x120b0fff0: pointer being freed was not allocated
*** set a breakpoint in malloc_error_break to debug
Abort trap: 6
"
15359,code is jammed when evaluate,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:win10
- **TensorFlow installed from (source or binary)**:pip3
- **TensorFlow version (use command below)**:1.4
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0 6.46
- **GPU model and memory**:2GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

the code is jammed when run `eval_results = pc_classifier.evaluate(input_fn = pcd.test_input_fn_np)`
I built model under the guidance of `cnn_mnist.py` . the differences are that I change the network architecture  and using my input_functioin. Everything is normal during the training process, but it jammed during the evaluate process. 
the call stack is:
![default](https://user-images.githubusercontent.com/22407275/33982216-b1cba1e0-e0ea-11e7-85e6-68d8f91457ff.JPG)
and it jammed at the code
`    for hook in self._hooks:
      hook.after_run(
          run_context,
          session_run_hook.SessionRunValues(
              results=outputs[hook] if hook in outputs else None,
              options=options,
              run_metadata=run_metadata))`

what's the problem?

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15358,how can I see the graphs in tensorboard?,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15357,Could not find a version that satisfies the requirement tensorflow (from versions: ),"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
Centos7
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

when i use ‘pip install python’，i got the follower errors：
[root@compute1 Object-Detector-App]# pip install tensorflow
Collecting tensorflow
  Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow
[root@compute1 Object-Detector-App]# 
[root@compute1 Object-Detector-App]# 
[root@compute1 Object-Detector-App]# python -V
Python 2.7.14
[root@compute1 Object-Detector-App]# 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15352,matmul causing segmentation fault in rev1.4.0,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.6
- **Bazel version (if compiling from source)**:
0.8.1
- **GCC/Compiler version (if compiling from source)**:
5.4.0
- **CUDA/cuDNN version**:
N/A
- **GPU model and memory**:
N/A
- **Exact command to reproduce**:
Here is the output from tf_env_collect.sh

== cat /etc/issue ===============================================
Linux Ubuntu 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux Ubuntu 4.4.0-101-generic #124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.5.0.post1)
tensorflow (1.4.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = b'v1.3.0-rc1-5916-g18c864c'
tf.COMPILER_VERSION = b'v1.3.0-rc1-5916-g18c864c'
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/lib/nx/X11/Xinerama:/usr/lib/nx/X11
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tensorflow-src/tensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Seeing a segmentation fault on matmul operation.

### Source code / logs
Here is the source code:
import tensorflow as tf
a = tf.random_normal([100, 200])
b = tf.random_normal([200, 300])
res = tf.matmul(a, b)
tf.Session().run(res)

Here is the backtrace from gdb:

#0  0x00007fff513b9296 in Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>::operator()(float*, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer> const&, long, long, long, long) ()
   from /tensorflow/python/_pywrap_tensorflow_internal.so
#1  0x00007fff5142ce94 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 48, 16, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 48, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorMap<Eigen::Tensor<float const, 2, 1, long>, 16, Eigen::MakePointer> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 16, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool) ()
   from /tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007fff4eab29c1 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from /tensorflow/python/../libtensorflow_framework.so
#3  0x00007fff4eab07d7 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /tensorflow/python/../---Type <return> to continue, or q <return> to quit---
libtensorflow_framework.so
#4  0x00007fff4e2ecc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#5  0x00007ffff7bc16ba in start_thread (arg=0x7ffe06ffd700)
    at pthread_create.c:333
#6  0x00007ffff71e73dd in clone ()
    at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15351,questions about shared variables between CPU and GPU ,"Dear developers:

I looked at cifar10_multi_gpu_train.py, the idea about sharing model params among CPU and GPUs is inspiring. However, I have a few questions that I want to understand well before I can apply to my own problem. 

As far as I can tell, the model params are stored in CPU by looking into the tower_loss() function since cifar10.py explicitly pinned down all variables at ""/cpu:0"". Then function train() wraps up tower_loss() with gpu device like this:

`for i in xrange(FLAGS.num_gpus):`
`       with tf.device('/gpu:%d' % i):`
`           loss = tower_loss(scope)`
`           tf.get_variable_scope().reuse_variables()`

Using this way, I bet model params are stored in CPU and there is no extra copy anywhere because it is set to just reuse the same variables in the scope, while GPU stored gradient operations written in tower_loss(). In the way, I believe the model params have to transfer from CPU to GPU whenever GPU calls for these params to operate upon. It would be inefficient if doing multiple transfer to GPU I believe. I notice ""identity"" operation in the end of tower_loss(). Is ""tf.identity(total_loss)"" doing the trick so CPU transfers model params to the GPU only once, then GPU just holds the local copy from then on?

"
15347,Object Detection frozen graph issue,"# Training environment 

### System information
- MAC OSX 10.13.2
- Tensorflow 1.4-rc1 (GPU support)
- Installation through source
- Python 3.6 (Anaconda)
- Bazel 0.8
- CUDA 9/ cuDNN7
- GPU 1080Ti

I have trained my own model for object detection. Extracted graph from checkpoint as well. This graph is working with the Mac GPU and CPU. It is also working with Raspberry PI but when I am trying to run it on AWS EC2 (Deep Learning AMI (Amazon Linux) and Deep Learning AMI (Ubuntu) both) instance. Built tensorflow 1.4-rc1 from source as well as installed using pip but it keep giving me following error:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1322     try:
-> 1323       return fn(*args)
   1324     except errors.OpError as e:

~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1301                                    feed_dict, fetch_list, target_list,
-> 1302                                    status, run_metadata)
   1303 

~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py in __exit__(self, type_arg, value_arg, traceback_arg)
    472             compat.as_text(c_api.TF_Message(self.status.status)),
--> 473             c_api.TF_GetCode(self.status.status))
    474     # Delete the underlying status object from memory otherwise it stays alive

InvalidArgumentError: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater)]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-25-7493eea60222> in <module>()
     20       (boxes, scores, classes, num) = sess.run(
     21           [detection_boxes, detection_scores, detection_classes, num_detections],
---> 22           feed_dict={image_tensor: image_np_expanded})
     23       # Visualization of the results of a detection.
     24       vis_util.visualize_boxes_and_labels_on_image_array(

~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    887     try:
    888       result = self._run(None, fetches, feed_dict, options_ptr,
--> 889                          run_metadata_ptr)
    890       if run_metadata:
    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1119       results = self._do_run(handle, final_targets, final_fetches,
-> 1120                              feed_dict_tensor, options, run_metadata)
   1121     else:
   1122       results = []

~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1315     if handle is None:
   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1317                            options, run_metadata)
   1318     else:
   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1334         except KeyError:
   1335           pass
-> 1336       raise type(e)(node_def, op, message)
   1337 
   1338   def _extend_graph(self):

InvalidArgumentError: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater)]]

Caused by op 'Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where', defined at:
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelapp.py"", line 478, in start
    self.io_loop.start()
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 281, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 232, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 397, in execute_request
    user_expressions, allow_stdin)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/ipkernel.py"", line 208, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2850, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-21-0d8b8f2357e8>"", line 7, in <module>
    tf.import_graph_def(od_graph_def, name='')
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/importer.py"", line 313, in import_graph_def
    op_def=op_def)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; NodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
	 [[Node: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater)]]
```

When I am extracting frozen graph on EC2 instance from the same previous checkpoint it gives me much lower accuracy than my MAC and raspberryPI"
15345,Using wrong location for x86_64 android build,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
A: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
A: OSX 10.13.1
- **TensorFlow installed from (source or binary)**:
A: Source
- **TensorFlow version (use command below)**:
A: 1.4.1
- **Python version**: 
A: 2.7
- **Bazel version (if compiling from source)**:
A: 0.8
- **GCC/Compiler version (if compiling from source)**:
A:
```
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 9.0.0 (clang-900.0.38)
Target: x86_64-apple-darwin17.2.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```

- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
`make -f tensorflow/contrib/makefile/Makefile TARGET=ANDROID ANDROID_ARCH=x86_64`

### Describe the problem
Android x86_64 build fails with Makefile using make -f tensorflow/contrib/makefile/Makefile TARGET=ANDROID ANDROID_ARCH=x86_64 because it cannot find the binary `x86-64-linux-android-g++`

It can be fixed by changing the `tensorflow/contrib/makefile/Makefile` at line 303 from 
`BIN_PREFIX := x86-64-linux-android` to
`BIN_PREFIX := x86_64-linux-android`
"
15343,Iterator on cached tf.data Dataset cannot be reinitialized ,"Found a likely bug when trying to use a reinitializable iterator to read from two cached datasets, one for validation and one for training. The iterator can however only be initialized once per cached dataset. Seems to me like the iterator should remove the lock file when being reinitialized, it is not in my case and that is why I get this issue. Here's a minimal example with only one cached dataset.

(basic system information below)

### Example
```python
import os

import numpy as np
import tensorflow as tf


data = np.random.rand(10, 3).astype(np.float32)
dataset = tf.data.Dataset.from_tensor_slices(data)
batches = dataset.shuffle(10).repeat().batch(5)

config = tf.ConfigProto(device_count = {'GPU': 0})
sess = tf.Session(config=config)

cache_dir = os.path.join(os.getcwd(), 'cache_dir')
try:
    os.makedirs(cache_dir)
except OSError:
    print('Cache directory already exists')

cached = batches.cache(os.path.join(cache_dir, 'cache'))
iterator = tf.data.Iterator.from_structure(output_types=tf.float32, output_shapes=(5, 3))
batch = iterator.get_next()

init1 = iterator.make_initializer(cached)
init2 = iterator.make_initializer(batches)

sess.run(init1)
sess.run(batch)
```
> array([[ 0.11960778,  0.3081578 ,  0.96522039],
       [ 0.90339011,  0.12458269,  0.30650312],
       [ 0.58160347,  0.55877644,  0.50363588],
       [ 0.2350398 ,  0.33509603,  0.4165386 ],
       [ 0.76757395,  0.50134581,  0.93601096]], dtype=float32)

```python
sess.run(init2)
sess.run(batch)
```
> array([[ 0.76757395,  0.50134581,  0.93601096],
       [ 0.2350398 ,  0.33509603,  0.4165386 ],
       [ 0.90339011,  0.12458269,  0.30650312],
       [ 0.13266359,  0.82675195,  0.26691398],
       [ 0.58160347,  0.55877644,  0.50363588]], dtype=float32)

```python
sess.run(init1)
sess.run(batch)
```
> AlreadyExistsError (see above for traceback): There appears to be a concurrent caching iterator running - cache lockfile already exists ('/home/ubuntu/ai_notebooks/notebooks/projects/deep-purple/cache_dir/cache.lockfile'). If you are sure no other running TF computations are using this cache prefix, delete the lockfile and re-initialize the iterator. Lockfile contents: Created at: 1513187725
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[5,3]], output_types=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Iterator)]]


### Sytem information
Tensorflow version: v1.4.0-rc1-11-g130a514 1.4.0 (installed from pip)
Python version: 3.5.2
OS: Linux Ubuntu 16.04.3
CUDA: 8.0.61
cuDNN: 6"
15342,Windows Environment and TF 1.4.1 - Unavailable through PyPI,"Hello dear Tensorflowers,

When running the following code `pip install tensorflow==1.4.1`, I obtain the following error:

```
Could not find a version that satisfies the requirement tensorflow==1.4.1 (from versions: 1.2.0rc2, 1.2.0, 1.2.1, 1.3.0rc0, 1.3.0rc1, 1.3.0rc2, 1.3.0, 1.4.0rc0, 1.4.0rc1, 1.4.0)
No matching distribution found for tensorflow==1.4.1
```

This error seem logical because the _wheel_ file does not exist for the windows distribution: 

- TF 1.4.1 - No Windows Compiled Library: https://pypi.python.org/pypi/tensorflow/1.4.1
- TF 1.4.0 - Windows Compiled Library is present: https://pypi.python.org/pypi/tensorflow/1.4.0

Is the support for the windows platform dropped ? Or maybe some compilation pipeline broke somewhere.

Thanks for your help,

Jonathan"
15341,Feature Request: enable rechanging tf.device of a tensor,"It seems that once a tensor's GPU was defined using tf.device, the GPU cannot be changed anymore. 
When loading saved graphs, the graph will use the same GPU that was chosen years ago and it cannot be set again.

thanks."
15340,StagingArea.get() ignores timeout,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 2.7.14
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
The `get()` method of a `tf.contrib.staging.StagingArea` is a blocking operation. I would expect it to respect any operation timeout that has been set for the Tensorflow session. This is important to avoid deadlocks, e.g., if the StagingArea is empty.

In comparison, the `dequeue()` method of a `tf.FIFOQueue` respects the timeout by raising`tf.errors.DeadlineExceededError`.


### Source code / logs
Example script:
```python
import tensorflow as tf
from __future__ import print_function

print(""Testing tf.FIFOQueue"")
empty_queue = tf.FIFOQueue(capacity=1, shapes=[1,], dtypes=tf.int32)
with tf.Session() as sess:
  try:
    print(sess.run(empty_queue.dequeue(), options=tf.RunOptions(timeout_in_ms = 500)))
  except tf.errors.DeadlineExceededError as e:
    print(""Error:"", e)


print(""Testing tf.contrib.staging.StagingArea"")
empty_stagingArea = tf.contrib.staging.StagingArea([tf.int64], shapes=[(1,)])
with tf.Session() as sess:
  try:
    print(sess.run(empty_stagingArea.get(), options=tf.RunOptions(timeout_in_ms = 500)))
  except tf.errors.DeadlineExceededError as e:
    print(""Error:"", e)
```
Example output:
```
Testing tf.FIFOQueue
Error: Timed out waiting for notification
Testing tf.contrib.staging.StagingArea
```
The final `sess.run` call hangs indefinitely."
15339,opencv cannot read frame from video with tensorflow,"I am using tensorflow r1.4 and opencv3.1 in ubuntu14.04.
When I include #include <tensorflow/core/public/session.h> or 
#include ""tensorflow/cc/ops/standard_ops.h"" I cannot read images from cv::VideoCapture adn I got empty mat. When I didn't include these tensorflow headers, I can read frame successfully. Anyone could help me? Thanks a lot!!!
I noticed other issues like [#1924](https://github.com/tensorflow/tensorflow/issues/1924?from=singlemessage) [#6496](https://github.com/tensorflow/tensorflow/issues/6496) but got no idea.

Here is my cpp file:
#include <tensorflow/core/platform/env.h>
#include <tensorflow/core/public/session.h>
#include ""tensorflow/cc/ops/standard_ops.h""
#include <opencv2/opencv.hpp>
#include <iostream>
using namespace std;
using namespace tensorflow;

int main()
{
cv::VideoCapture cap;
if(!cap.open(""/home/kx/project/RM-dataset/01.avi"")){
std::cout<<""cannot open video ""<<std::endl;
}
cv::Mat frame;
while(1){
cap>>frame;
if(frame.empty()){
std::cout<<""no frame""<<std::endl;
continue;
}
cv::imshow(""frame"",frame);
cv::waitKey(0);
}
return 0;
}

my cmake file:

cmake_minimum_required (VERSION 2.8)
project (tf_example)

set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -g -std=c++11 -W"")
find_package(OpenCV 3.1.0 REQUIRED)
include_directories(
/home/kx/something/tensorflow-r1.4
/home/kx/something/tensorflow-r1.4/tensorflow/bazel-genfiles
/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/protobuf/include
/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/host_obj
/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/gen/proto
/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/downloads/nsync/public
/home/kx/something/tensorflow-r1.4/tensorflow/contrib/makefile/downloads/eigen
/home/kx/something/tensorflow-r1.4/bazel-out/local-py3-opt/genfiles
${OPENCV_INCLUDE_DIRS}
)

add_executable(tf_test tf_test.cpp)
target_link_libraries(tf_test
/home/kx/something/tensorflow-r1.4/bazel-bin/tensorflow/libtensorflow_cc.so
/home/kx/something/tensorflow-r1.4/bazel-bin/tensorflow/libtensorflow_framework.so
${OpenCV_LIBS}
)

The results:
no frame

"
15338,Tensorflow AOT examples fail to compile,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 'v1.3.0-rc1-5779-g441571a', '1.4.0'
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.8.1
- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0
- **CUDA/cuDNN version**: CUDA 8.0, CUDNN 6.0.21
- **GPU model and memory**: GeForce GTX 1080, 8GB
- **Exact command to reproduce**: cd tensorflow/compiler/aot/tests ; bazel clean ; bazel build all_tests &>gcc5.log

### Describe the problem

I am trying to compile AOT examples, but the compilation fails. I tried to use two different compiler versions (GCC 5.4 and GCC 4.8), but I get errors with both versions. I also tried adding --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" option when using bazel with GCC 5.4, but it doesn't help.

So the exact commands commands were:
bazel build all_tests &>gcc5.log
bazel build --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" all_tests &>gcc5_abi0.log
bazel build all_tests  # Using GCC 4.8, I copied the output manually to gcc_4.8.txt

Tensorflow source code itself was build without any problems both with GCC 5.4 and GCC 4.8. I have built the two versions in separate python virtual environments and afterwards tried to compile aot tests with the corresponding GCC version. I used --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" option when building tensorflow source with GCC 5.4.

### Source code / logs
The logs are attached.
[gcc5.log](https://github.com/tensorflow/tensorflow/files/1555478/gcc5.log)
[gcc5_abi0.log](https://github.com/tensorflow/tensorflow/files/1555479/gcc5_abi0.log)
[gcc_4.8.txt](https://github.com/tensorflow/tensorflow/files/1555485/gcc_4.8.txt)"
15336,batch normalization layer which translated by toco cannot be run in TF Lite,"## Issue
Resolver for batch normalization layer(`ResolveBatchNormalization`) in toco has four inputs, which are input matrix, mean, multiplier, and offset respectively. Usually, input matrix has four dimensions (NHWC) while mean, multiplier, and offset only have 1 dimension for a channel. This resolver translates this 1 dimension vector to second input of `Mul` and `Add` layers in TF Lite. (first input of these layers is input matrix!) But the problem occurs `Mul` and `Add` layers in TF Lite have a process to check dimension of inputs. Need to fix this contradiction. :) 


## Codes related to this Issue
[Resolver](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc)
[Logic of checking dimension in add layer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/add.cc#L48)
[Logic of checking dimension in mul layer](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/mul.cc#L48)
"
15334,Quantized graph on ssd mobilenet fails with InvalidArgumentError,"I am using ssd_mobilenet_v1_coco_2017_11_17 and quantized it using following command:

bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
  --in_graph=ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb \
  --out_graph=ssd_mobilenet_v1_coco_2017_11_17/frozen_quant.pb \
  --inputs='image_tensor' \
  --outputs='detection_boxes,detection_scores,detection_classes' \
  --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,299,299,3"")
    remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true)
    fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes
    strip_unused_nodes sort_by_execution_order'

I am using tensorflow v 1.4.1 for detecting bounding box and it throws following error:

InvalidArgumentError: The node 'Preprocessor/map/while/ResizeImage/ResizeBilinear/eightbit' has inputs from different frames. The input 'Preprocessor/map/while/ResizeImage/size' is in frame 'Preprocessor/map/while/while_context'. The input 'Preprocessor/map/while/ResizeImage/ResizeBilinear_eightbit/Preprocessor/map/while/ResizeImage/ExpandDims/quantize' is in frame ''."
15332,Allow tf.Estimator.evaluate() to return summary protos / add tooling to produce useful eval image summaries,"Related to #14042.

`tf.Estimator.train()` writes a summary of all defined summaries (scalar, img) in the given `model_fn` when calling [MonitoredTrainingSession](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L801) ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py#L366)).

`tf.Estimator.evaluate()` does not write summaries defined somewhere in the `model_fn`. A workaround is defining `SummarySaverHook` inside the `model_fn`, which I think is not ideal since the Estimator has all the relevant information for saving summaries (steps, save directory, etc.).

A possible solution would be adding a `SummarySaverHook` during evaluation, (e.g. [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/evaluation.py#L206)) or create a new function `MonitoredEvaluationSession()` in [monitored_session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/monitored_session.py) that creates such a hook.

cc @ispirmustafa @martinwicke
"
15331,Graph building and optimization is really slow,"I'm using tensorflow 1.4 and tflearn 0.3.2. The os of my machine is Win 8.1. Apparently, the graph building and cost optimization in my code is real slow which I think is a bug in Tensorflow (either that or my machine is just real slow). Here's the code:

```
class Model(object):
    def __init__(self):
        self.num_classes = 80
        self.num_time_steps = 1596
        self.input_dimension = 48
        self.inputs = network_utils.input_data([None, self.num_time_steps, self.input_dimension], name=""input"")
        self.labels = network_utils.sparse_input_data()
        self.seq_lens = network_utils.input_data([None], name=""seq_len"", input_type=network_utils.get_type('int32'))
        self.learning_rate = 0.01

    def _inference(self):
        model = network_utils.bidirectional_lstm(self.inputs, 50, return_seq=True)
        model = network_utils.bidirectional_lstm(model, 100, return_seq=True)
        model = network_utils.bidirectional_lstm(model, 200)
        logits = network_utils.get_time_major(model, self.num_classes, network_utils.get_shape(self.inputs)[0], 200)
        return logits

    def loss(self):
        y_predict = self._inference()
        loss = network_utils.ctc_loss(predictions=y_predict, labels=self.labels, sequence_length=self.seq_lens)
        cost = network_utils.cost(loss)
        decoded = network_utils.decode(inputs=y_predict, sequence_length=self.seq_lens)
        label_error_rate = network_utils.label_error_rate(y_pred=decoded[0], y_true=self.labels)
        return loss, label_error_rate, cost

    def optimize(self, cost, optimizer):
        return network_utils.optimize(loss=cost, optimizer=optimizer, learning_rate=self.learning_rate)
```

```
import tensorflow as tf
import tflearn
from tflearn import bidirectional_rnn, BasicLSTMCell

from optimizer_enum import Optimizers

def ctc_loss(predictions, labels, sequence_length,
             preprocess_collapse_repeated_labels=True,
             ctc_merge_repeated=True,
             inputs_are_time_major=True):
    return tf.nn.ctc_loss(inputs=predictions, labels=labels, sequence_length=sequence_length,
                          preprocess_collapse_repeated=preprocess_collapse_repeated_labels,
                          ctc_merge_repeated=ctc_merge_repeated,
                          time_major=inputs_are_time_major)

def input_data(shape, name: str = 'InputData', input_type=tf.float32):
    return tflearn.input_data(shape=shape, dtype=input_type, name=name)

def reshape(tensor: tf.Tensor, new_shape: list):
    return tf.reshape(tensor, new_shape, name=""reshape"")

def bidirectional_lstm(inputs, num_hidden: int, return_seq=False):
    return bidirectional_rnn(inputs, BasicLSTMCell(num_hidden), BasicLSTMCell(num_hidden), return_seq=return_seq)


def decode(inputs, sequence_length, merge_repeated=True):
    decoded, _ = tf.nn.ctc_beam_search_decoder(inputs, sequence_length, merge_repeated)
    return decoded

def label_error_rate(y_pred, y_true):
    return tf.reduce_mean(tf.edit_distance(tf.cast(y_pred, tf.int32), y_true))

def optimize(loss, optimizer, learning_rate):
    if optimizer == Optimizers.MOMENTUM:
        return tf.train.MomentumOptimizer(learning_rate, momentum=0.9).minimize(loss)
    if optimizer == Optimizers.ADAM:
        return tf.train.AdamOptimizer(learning_rate).minimize(loss)
    if optimizer == Optimizers.ADADELTA:
        return tf.train.AdadeltaOptimizer(learning_rate).minimize(loss)
    if optimizer == Optimizers.RMSPROP:
        return tf.train.RMSPropOptimizer(learning_rate).minimize(loss)
    raise NotImplementedError(""{} is not implemented."".format(optimizer))

def sparse_input_data(input_type=tf.int32):
    return tf.sparse_placeholder(input_type)

def get_time_major(model, num_classes, batch_size, num_hidden_units):
    outputs = reshape(model, [-1, num_hidden_units])

    W = tf.Variable(tf.truncated_normal([num_hidden_units,
                                         num_classes],
                                        stddev=0.1, dtype=tf.float32), name='W')
    b = tf.Variable(tf.constant(0., dtype=tf.float32, shape=[num_classes], name='b'))

    logits = tf.matmul(outputs, W) + b
    logits = tf.reshape(logits, [batch_size, -1, num_classes])
    logits = tf.transpose(logits, (1, 0, 2))
    return logits

def cost(loss):
    return tf.reduce_mean(loss)


def get_type(type_str):
    if type_str == 'int32':
        return tf.int32
    return tf.float32


def get_shape(tensor):
    return tf.shape(tensor)
```

Can anyone help me address this issue? To reproduce it, you can run main/train.py in this [repository](https://github.com/selcouthlyBlue/simplified_bi_lstm_ocr)"
15329, tf.train.match_filenames_once() under Windows,"I use  tf.train.match_filenames_once() as follows:
 tf.train.match_filenames_once(""./*.py"")
I mean , I want to get all the py file in current directory.
But, the result is I also get subdirectory py file under Windows.
How can I get the specified files only in current directory?
Thank you！
-----------------------
Have I written custom code : No
OS Platform and Distribution: Windows
TensorFlow installed from :pip command
TensorFlow version: 1.4
Bazel version: N/A
CUDA/cuDNN version: CUDA8.0
GPU model and memory:  GTX1080 8G
Exact command to reproduce： tf.train.match_filenames_once(""./*.py"")
"
15327,Feature Request: Easy way to predict after training model with Estimator and Dataset API,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Windows 10
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: Python 3.5.2 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None

### Describe the problem

I have beed trained a image classification cnn model with the Estimator and Dataset(`tf.data.TFRecordsDataset`) API. The relative model files have bee saved in `model_dir`. The last few days I try very hard to figure out how to predict one or more images label using the saved model files. 

However I failed and don't know what to do. I can't find relative contents in the official doc. So adding an easy method to do this may be a good idea. Or is there another solution I missed?

FYI, my training code is [here](https://github.com/secsilm/understaing-datasets-estimators-tfrecords/blob/master/cifar10-estimator-dataset.py)."
15326,`import_scoped_meta_graph ()` use wrong name scope and fails to restore the collections,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.1
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

This is a tiny code occurs the problem. In this code, `import_scoped_meta_graph_def()` create the different variables `s/v` and `s_1/v` but returns only `s/v`.

```python
import tensorflow as tf
from tensorflow.python.framework import meta_graph

tf.Variable(0, name='v')
meta_graph_def, _ = meta_graph.export_scoped_meta_graph()

for i in range(2):
    var_list = meta_graph.import_scoped_meta_graph(meta_graph_def,
                                                   import_scope='s')
    print(i, ':', var_list)
    print('----------------------')
    for op in tf.get_default_graph().get_operations():
        print(op.name)
    print()
```

stdout:
```
0 : {'v:0': <tf.Variable 's/v:0' shape=() dtype=int32_ref>}
----------------------
v/initial_value
v
v/Assign
v/read
s/v/initial_value
s/v
s/v/Assign
s/v/read

1 : {'v:0': <tf.Variable 's/v:0' shape=() dtype=int32_ref>}
----------------------
v/initial_value
v
v/Assign
v/read
s/v/initial_value
s/v
s/v/Assign
s/v/read
s_1/v/initial_value
s_1/v
s_1/v/Assign
s_1/v/read
```

This problem occurs when the name scope created by `import_graph_def()` inside `import_scoped_meta_graph_def()` does not match  the argument `import_scope`.

https://github.com/tensorflow/tensorflow/blob/438604fc885208ee05f9eef2d0f2c630e1360a83/tensorflow/python/framework/meta_graph.py#L658-L663"
15325,Minor documentation mistake,"https://www.tensorflow.org/programmers_guide/tensors
Under the ""Getting a tf.Tensor object's rank"" subheading
`r = tf.rank(my3d)` should be `r = tf.rank(my_image)`"
15323,Beam Search Decoder API,"@ebrevdo Why is it that the user needs to call `tile_batch` explicitly for beam search decoders when using attention models? Couldn't the beam search decoder internally tile the provided `initial_state` in its constructor? It seems that this API is prone to wrong usage so I'm trying to understand why it's necessary.

Thank you!"
15322,Add full cmake support for Android builds,"Currently it doesn't seems like tensorflow support compiling with ndk r16, clang and c++ stl.
Is there any plans to update build flow to support that?
Also it would be nice to have pure CMake build for Android.
"
15321,Feature Request: Support for DT_STRING type in ScatterNd kernel.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: -
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOs, Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binaries
- **TensorFlow version (use command below)**: 
v1.3.0-rc1-5542-g03a1651cbb 1.5.0-dev20171206
and
v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**:
~~~python
import tensorflow as tf
indices = tf.constant(
    [[i] for i in range(37)] +\
    [[i] for i in range(37,37+18)] +\
    [[i] for i in range(37*2,37*2+9)] +\
    [[i] for i in range(37*3,37*3+36)]
)
updates = tf.ones([100,13])
# This line:
updates = tf.as_string(updates)
shape = tf.constant([37*4, 13])
sc=tf.scatter_nd(indices, updates, shape)
with tf.Session() as sess:
    print(sess.run(sc))
~~~

### Describe the problem
`tf.scatter_nd` supports most of the other types except `DT_STRING`, and throws the following error:
~~~console
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-196-71592cd7f940> in <module>()
      9 updates = tf.as_string(updates)
     10 shape = tf.constant([37*4, 13])
---> 11 sc=tf.scatter_nd(indices, updates, shape)

~/tf-nightly/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in scatter_nd(indices, updates, shape, name)
   4395     _attrs = (""T"", _attr_T, ""Tindices"", _attr_Tindices)
   4396     _result = _execute.execute(b""ScatterNd"", 1, inputs=_inputs_flat,
-> 4397                                attrs=_attrs, ctx=_ctx, name=name)
   4398   _execute.record_gradient(
   4399       ""ScatterNd"", _inputs_flat, _attrs, _result, name)

~/tf-nightly/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     64     else:
     65       message = e.message
---> 66     six.raise_from(core._status_to_exception(e.code, message), None)
     67   # pylint: enable=protected-access
     68   return tensors

~/tf-nightly/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

NotFoundError: No registered 'ScatterNd' OpKernel for CPU devices compatible with node ScatterNd = ScatterNd[T=DT_STRING, Tindices=DT_INT32](dummy_input, dummy_input, dummy_input)
	 (OpKernel was found, but attributes didn't match)
	.  Registered:  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT64]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT32]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_UINT16]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT16]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_UINT8]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_INT8]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_COMPLEX64]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_COMPLEX128]; Tindices in [DT_INT64]
 [Op:ScatterNd]

~~~

### Question
Is it possible to get `tf.scatter_nd` to work with strings, for example, an empty string as a default value?
Also, on the related note, rn the default values are `0` or `0.0`, can the function be extended to use an arbitrary value (e.g. a padding symbol)?
"
15320,Multi-core CPU performance dropped for MKL TF build,"### System information

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS (64-bit)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: Tensorflow r1.4
- **Python version**: Python version: 2.7.12
- **Bazel version (if compiling from source)**: Bazel release 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
- **CUDA/cuDNN version**: no CUDA
- **GPU model and memory**: no GPU, but i7-6850K with 32Gb ddr4
- **Exact command to reproduce**: run the script below

Tested on two machines:
1) i7-6850K with 32Gb ddr4
2) two Xeon x5650 with 24Gb ddr3

### Describe the problem
When I build Tensorflow with MKL it dropped CPU performance in a strange way. Performance of individual core is much higher, but for multicore is much worse.
It's a big epic bottleneck for my project and I can't solve it by myself. I will appreciate any help!

1) TF installation from sources with MKL support
> Tensorflow r1.4 installed from source. Configured with jemalloc as malloc support and other configure settings ignored.
> $ bazel build --config=mkl -c opt //tensorflow/tools/pip_package:build_pip_package
> $ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
> $ pip install /tmp/tensorflow_pkg/tensorflow-1.4.1-cp27-cp27mu-linux_x86_64.whl

**Run tests:** 
one core: 0.03s
all cores: 0.12s

2) TF installation with pip
> $ pip install tensorflow
> (tensorflow-1.4.1-cp27-cp27mu-manylinux1_x86_64.whl installed)

**Run tests:**
one core: 0.16s
all cores: 0.03s


### Source code / logs

```
    import time
    import numpy as np
    import tensorflow as tf

    from tensorflow.contrib import slim
    from tensorflow.contrib.slim.python.slim.nets.inception_v1 import inception_v1, inception_v1_arg_scope


    input_shape = (1, 224, 224, 3)
    features = tf.placeholder(tf.float32, input_shape)

    with slim.arg_scope(inception_v1_arg_scope()):
        predictions, end_points = inception_v1(features, is_training=False)

    # remove to utilize all cores
    session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,
                                  inter_op_parallelism_threads=1)

    with tf.Session(config=session_conf) as sess:
        sess.run(tf.global_variables_initializer())
        sess.run(tf.local_variables_initializer())

        images = np.random.random(input_shape)
        consumption = []
        for i in range(10):
            tick = time.time()
            sess.run(predictions, feed_dict={features: images})
            consumption.append(time.time() - tick)

        print np.mean(consumption)
```"
15319,Cannot import tensorflow after installing tensorflow-gpu - Windows,"I am running windows 10 64bit. 
Tensorflow-gpu version - 1.4.0
CUDA version - 8.0
cuDNN - v6.0

I installed it using the cmd command: `pip install tensorflow-gpu ` and do not have any other version of tensorflow installed. now when I try to execute 

```
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
```
I get the error `ModuleNotFoundError: No module named 'tensorflow'`

I am hoping getting this working will solve my bigger issue of tensorflow not recognizing my gpu for gpu processing. "
15318,tensorflow multigpu with dataset api is not converging,"
I am trying to train a resNet50  on multi_gpus,
I have used 
[https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py)](url)



and I have added tensorflow Dataset input pipeline to the link code
But after some steps loss is some value and does not changes any more!(value =0.693147 always)

I have tested this network with dataset API on single gpu,and worked fine.
Im sure something is wrong with my data feeding,because when I feed a simple random nd_array,it converges!!!!!

I have tested my tfrecord file,it was OK .
but I dont know the problem.

I use
ubuntu 16.04,

tensorflow 1.4,

python 2.7.12,

gtx 1080 Gpus

this is all my train code:





[github.txt](https://github.com/tensorflow/tensorflow/files/1552082/github.txt)
"
15317,no ,
15314,tensorflow.python.framework.errors_impl.NotFoundError: Can not get size for:,"D:\Python\Python35\models-master\research\object_detection>D:\Python\Python35\python train.py --logtostderr --train_dir=training\ --pipline_config_path=training\ssd_mobilenet_v1_pets.config
Traceback (most recent call last):
  File ""train.py"", line 163, in <module>
    tf.app.run()
  File ""C:\Users\USER\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\platform\app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 106, in main
    overwrite=True)
  File ""C:\Users\USER\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\lib\io\file_io.py"", line 384, in copy
    compat.as_bytes(oldpath), compat.as_bytes(newpath), overwrite, status)
  File ""D:\Python\Python35\lib\contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""C:\Users\USER\AppData\Roaming\Python\Python35\site-packages\tensorflow\python\framework\errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Can not get size for:  : path d\udc92acc\udce8s sp\udce9cifi\udce9 not found"
15312,iOS build_all_ios_ssd.sh 'double-conversion/double-conversion.h' file not found,"iOS `build_all_ios_ssd.sh` `'double-conversion/double-conversion.h' file not found`

```

export TF_ROOT=$(~/tensorflow-master)


cd ~/tensorflow_ios_detector/config
bash config.sh

export TF_ROOT=~/tensorflow-master
cd $TF_ROOT
tensorflow/contrib/makefile/build_all_ios_ssd.sh

gcc --std=c++11 -I. -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/ -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/eigen -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/gemmlowp -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/nsync/public -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/fft2d -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/host_obj/ -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf-host/include -I/usr/local/include -c tensorflow/core/lib/random/simple_philox.cc -o /Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/random/simple_philox.o
tensorflow/core/lib/strings/numbers.cc:26:10: fatal error: 
      'double-conversion/double-conversion.h' file not found
#include ""double-conversion/double-conversion.h""
         ^
1 error generated.
make: *** [/Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/strings/numbers.o] Error 1
make: *** Waiting for unfinished jobs....
+ '[' 2 -ne 0 ']'
+ echo 'arm64 compilation failed.'
arm64 compilation failed.
+ exit 1
Mac-Admin:tensorflow-master admin$ 

```
but script downloaded `double-conversion` in `downloads` folder located at `tensorflow/contrib/makefile`
"
15311,Support python3.6 Linux,Python3.6 support Linux
15306,GO Tests Fail for Tensorflow 1.4.0 but example code works on amd64 and arm64,"### System information
- ~**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**~:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04 on amd64 and arm64
- **TensorFlow installed from (source or binary)**: amd64: binary (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.4.0.tar.gz); arch64: source (d752244f) `//tensorflow:libtensorflow.so`
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: python3.5
- **Bazel version (if compiling from source)**:  arm64: 0.7.0
- **GCC/Compiler version (if compiling from source)**: arm64: 5.4.0-6ubuntu1~16.04.5
- **CUDA/cuDNN version**: amd64: cuda-8.0 | libcudnn.so.6
- **GPU model and memory**: amd64: GeForce GTX 1060 6071MiB
- **Exact command to reproduce**: `go test github.com/tensorflow/tensorflow/tensorflow/go`

### Describe the problem
Test fail but [example code](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go#example-package) work on both platforms. 

### Source code / logs
amd64:
```
2017-12-12 11:37:29.916413: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
2017-12-12 11:37:29.918709: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23
SIGABRT: abort
PC=0x7f9b403b4428 m=4 sigcode=18446744073709551610
signal arrived during cgo execution

goroutine 29 [syscall, locked to thread]:
runtime.cgocall(0x657730, 0xc4200479d0, 0xc4200479f8)
	/usr/local/go/src/runtime/cgocall.go:132 +0xe4 fp=0xc4200479a0 sp=0xc420047960 pc=0x405574
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0x7f9b0800c380, 0x7f9b0800e190, 0x7f9b0800c840, 0x7f9b0800dc80)
	github.com/tensorflow/tensorflow/tensorflow/go/_test/_obj_test/_cgo_gotypes.go:919 +0x45 fp=0xc4200479d0 sp=0xc4200479a0 pc=0x52d725
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0x7f9b0800c380, 0x7f9b0800e190, 0x7f9b0800c840, 0x7f9b0800dc80)
	/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xec fp=0xc420047a08 sp=0xc4200479d0 pc=0x539cdc
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0x7f9b0800c380, 0xc42000e0c0, 0x6f01be, 0x5, 0x6b70c0, 0xc4200ec4c0, 0x0, 0x0)
	/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0x10f1 fp=0xc420047c00 sp=0xc420047a08 pc=0x530481
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc42000e080, 0x6f0024, 0x5, 0xc42050a3b8, 0x6, 0x0, 0x0, 0x0, 0xc420080f00, 0x4b393b, ...)
	/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:209 +0x4a0 fp=0xc420047d60 sp=0xc420047c00 pc=0x52f190
github.com/tensorflow/tensorflow/tensorflow/go.Const(0xc42000e080, 0xc42050a3b8, 0x6, 0x683760, 0xc4200ec300, 0xc42050a3b8, 0x6, 0x4d499d, 0x7abe18)
	/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x221 fp=0xc420047e38 sp=0xc420047d60 pc=0x52a781
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0xc420102780)
	/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0x11e fp=0xc420047fa8 sp=0xc420047e38 pc=0x53708e
testing.tRunner(0xc420102780, 0xc4200ec480)
	/usr/local/go/src/testing/testing.go:746 +0xd0 fp=0xc420047fd0 sp=0xc420047fa8 pc=0x4d4a40
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc420047fd8 sp=0xc420047fd0 pc=0x45fa31
created by testing.(*T).Run
	/usr/local/go/src/testing/testing.go:789 +0x2de

goroutine 1 [chan receive]:
testing.(*T).Run(0xc420102000, 0x6f62b2, 0x1a, 0x703770, 0x47b401)
	/usr/local/go/src/testing/testing.go:790 +0x2fc
testing.runTests.func1(0xc420102000)
	/usr/local/go/src/testing/testing.go:1004 +0x64
testing.tRunner(0xc420102000, 0xc420057de0)
	/usr/local/go/src/testing/testing.go:746 +0xd0
testing.runTests(0xc4200ec220, 0xa423e0, 0x11, 0x11, 0xc420057e78)
	/usr/local/go/src/testing/testing.go:1002 +0x2d8
testing.(*M).Run(0xc420057f18, 0xc420057f70)
	/usr/local/go/src/testing/testing.go:921 +0x111
main.main()
	github.com/tensorflow/tensorflow/tensorflow/go/_test/_testmain.go:84 +0xdb

goroutine 25 [chan receive]:
testing.(*T).Run(0xc4201023c0, 0xc4200145a0, 0x13, 0xc4200ec480, 0x2)
	/usr/local/go/src/testing/testing.go:790 +0x2fc
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0xc4201023c0)
	/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x56e
testing.tRunner(0xc4201023c0, 0x703770)
	/usr/local/go/src/testing/testing.go:746 +0xd0
created by testing.(*T).Run
	/usr/local/go/src/testing/testing.go:789 +0x2de

rax    0x0
rbx    0x7f9b1fbfca30
rcx    0x7f9b403b4428
rdx    0x6
rdi    0x20a0
rsi    0x20a3
rbp    0x7f9b1fbfca20
rsp    0x7f9b1fbfc8e8
r8     0x7f9b0800eb80
r9     0x0
r10    0x8
r11    0x206
r12    0x7f9b1fbfcc50
r13    0x17
r14    0x5
r15    0x7f9b1fbfcc50
rip    0x7f9b403b4428
rflags 0x206
cs     0x33
fs     0x0
gs     0x0
FAIL	github.com/tensorflow/tensorflow/tensorflow/go	0.059s
```

arm64:
```
2017-12-12 11:40:20.357262: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23
SIGABRT: abort
PC=0x7f7a686528 m=0 sigcode=18446744073709551610
signal arrived during cgo execution

goroutine 56 [syscall, locked to thread]:
runtime.cgocall(0x5e9a48, 0x442003d9d8, 0x29)
	/usr/local/go/src/runtime/cgocall.go:132 +0xa0 fp=0x442003d9a0 sp=0x442003d960 pc=0x405280
github.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0xa2bac10, 0xa24bfa0, 0x9fcbb50, 0xa289620)
	github.com/tensorflow/tensorflow/tensorflow/go/_test/_obj_test/_cgo_gotypes.go:919 +0x38 fp=0x442003d9d0 sp=0x442003d9a0 pc=0x508468
github.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0xa2bac10, 0xa24bfa0, 0x9fcbb50, 0xa289620)
	/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xa4 fp=0x442003da00 sp=0x442003d9d0 pc=0x511e04
github.com/tensorflow/tensorflow/tensorflow/go.setAttr(0xa2bac10, 0x442008a0c0, 0x6809f9, 0x5, 0x648200, 0x4420106480, 0x0, 0x0)
	/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xd7c fp=0x442003dc00 sp=0x442003da00 pc=0x50aa3c
github.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0x442008a088, 0x680864, 0x5, 0x4420086728, 0x6, 0x0, 0x0, 0x0, 0x442007ef00, 0x4a1f7c, ...)
	/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:209 +0x3b8 fp=0x442003dd60 sp=0x442003dc00 pc=0x509b38
github.com/tensorflow/tensorflow/tensorflow/go.Const(0x442008a088, 0x4420086728, 0x6, 0x615100, 0x44201062c0, 0x4420086728, 0x6, 0x445a01, 0x80)
	/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x190 fp=0x442003de30 sp=0x442003dd60 pc=0x505a90
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0x442011e780)
	/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0xc4 fp=0x442003dfa0 sp=0x442003de30 pc=0x50fd44
testing.tRunner(0x442011e780, 0x4420106440)
	/usr/local/go/src/testing/testing.go:746 +0xb0 fp=0x442003dfc0 sp=0x442003dfa0 pc=0x4bd240
runtime.goexit()
	/usr/local/go/src/runtime/asm_arm64.s:931 +0x4 fp=0x442003dfc0 sp=0x442003dfc0 pc=0x456a44
created by testing.(*T).Run
	/usr/local/go/src/testing/testing.go:789 +0x244

goroutine 1 [chan receive]:
testing.(*T).Run(0x442011e000, 0x686c26, 0x1a, 0x694188, 0x5a2fb201)
	/usr/local/go/src/testing/testing.go:790 +0x258
testing.runTests.func1(0x442011e000)
	/usr/local/go/src/testing/testing.go:1004 +0x54
testing.tRunner(0x442011e000, 0x4420051dd0)
	/usr/local/go/src/testing/testing.go:746 +0xb0
testing.runTests(0x44201061c0, 0x7d8300, 0x11, 0x11, 0x3e7)
	/usr/local/go/src/testing/testing.go:1002 +0x280
testing.(*M).Run(0x4420051f18, 0x42d01c)
	/usr/local/go/src/testing/testing.go:921 +0xf0
main.main()
	github.com/tensorflow/tensorflow/tensorflow/go/_test/_testmain.go:84 +0xd0

goroutine 52 [chan receive]:
testing.(*T).Run(0x442011e3c0, 0x44200c02c0, 0x13, 0x4420106440, 0x2)
	/usr/local/go/src/testing/testing.go:790 +0x258
github.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0x442011e3c0)
	/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x540
testing.tRunner(0x442011e3c0, 0x694188)
	/usr/local/go/src/testing/testing.go:746 +0xb0
created by testing.(*T).Run
	/usr/local/go/src/testing/testing.go:789 +0x244

r0      0x0
r1      0x363f
r2      0x6
r3      0x7f7c729000
r4      0x363f
r5      0x7f7c7296f0
r6      0x0
r7      0x0
r8      0x83
r9      0x9fa59e0
r10     0x7fdb6f6760
r11     0x7fdb6f6760
r12     0xa3d70a3d70a3d70b
r13     0x7fdb6f6706
r14     0x0
r15     0x1db
r16     0x7f7a639120
r17     0x7f7a687830
r18     0x14
r19     0x7f7a797000
r20     0x7f7c729000
r21     0x7f7a7979d8
r22     0xa322700
r23     0x5
r24     0xa2bac10
r25     0x0
r26     0x6941e0
r27     0x10
r28     0x80b700
r29     0x7fdb6f66e0
lr      0x7f7a6879e0
sp      0x7fdb6f66e0
pc      0x7f7a686528
fault   0x0
FAIL	github.com/tensorflow/tensorflow/tensorflow/go	0.261s
```"
15305,Feature: Tensorflow-native doc2vec implementation planned?,"### System information
Have I written custom code N/A
OS Platform and Distribution N/A
TensorFlow installed from N/A
TensorFlow version N/A
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory N/A
Exact command to reproduce N/A

### Describe the problem

**Situation:**

- We are seeking for a doc2vec implementation based on Tensorflow.
- The reason for this is to be ""as PaaS as possible"" in model training and serving (using Google Cloud ML or AWS Sagemaker).

**Complication:**

- There is no native doc2vec implementation in Tensorflow (word2vec is available)
- [Stackoverflow](https://stackoverflow.com/search?q=tensorflow+doc2vec) does not list too much on this.

**Questions/Feature request:**

- Is a ""native"" doc2vec implementation planned in Tensorflow?
- if not, is there a common implementation to it, e.g. sum up all the individual word vectors and potentially add normalizing to each ""doc""?

### Source code / logs
not applicable"
15297,tf.bfloat16 is unsigned on Windows,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.0
- **Python version**: 
3.5.4
- **Bazel version (if compiling from source)**:
None
- **GCC/Compiler version (if compiling from source)**:
None
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:
```python
import tensorflow as tf
print(tf.bfloat16.is_unsigned)
```
Expected Output: False
Actual: True

### Describe the problem


### Source code / logs
https://ci.tensorflow.org/job/tf-master-win-bzl/2057/console
bfloat16_test/test.log
"
15296,variable_scopes_count miscalculates when reentering variable_scope again,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: mac 10.11
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4
- **Python version**:  3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

### Describe the problem

The unexpected results are fund when I  investigates #14703, see code here:

https://github.com/tensorflow/tensorflow/blob/4806cb0646bd21f713722bd97c0d0262c575f7e0/tensorflow/python/ops/variable_scope.py#L1621-L1623

variable_scope always restores its old `variable_scopes_count` after exit, unfortunately, it seems that we forget reentering case. I am not sure whether the behavior is a bug.

### Source code / logs
```python
import tensorflow as tf
from tensorflow.python.ops import variable_scope

def print_scope(scope):
    print(""scope: {}, variable_scopes_count: {}"".format(
        scope.name,
        variable_scope._get_default_variable_store().variable_scopes_count))

with tf.variable_scope(""a"") as scope:
    print_scope(scope)

with tf.variable_scope(scope) as scope2:
    print_scope(scope2)
    with tf.variable_scope(scope2) as scope3:
        print_scope(scope3)

print(""==============="")
print_scope(tf.get_variable_scope())
```

output:
```bash
~/Downloads ❯❯❯ python var_store_test.py
scope: a, variable_scopes_count: {'a': 1}
scope: a, variable_scopes_count: {'a': 2}
scope: a, variable_scopes_count: {'a': 3}
===============
scope: , variable_scopes_count: {'a': 2}
```
"
15294,Error tensorflow load library with Cuda 8 and 9,"Hello,
I use TF 1.0.1, and in my PC (Ubuntu 17.03), I already installed both Cuda 8.0 and Cuda 9.0.

When I run a demo code (Fast R_CNN), I got this error:

I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcudnn.so.5. LD_LIBRARY_PATH: /usr/local/cuda-8.0/lib64
I tensorflow/stream_executor/cuda/cuda_dnn.cc:3517] Unable to load cuDNN DSO
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""./tools/demo.py"", line 11, in <module>
    from networks.factory import get_network
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/__init__.py"", line 8, in <module>
    from .VGGnet_train import VGGnet_train
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/VGGnet_train.py"", line 2, in <module>
    from networks.network import Network
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/network.py"", line 3, in <module>
    import roi_pooling_layer.roi_pooling_op as roi_pool_op
  File ""/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/roi_pooling_layer/roi_pooling_op.py"", line 5, in <module>
    _roi_pooling_module = tf.load_op_library(filename)
  File ""/home/tung/Envs/Tensor1/lib/python3.4/site-packages/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: libcudart.so.9.0: cannot open shared object file: No such file or directory

It seem there is a conflict between cuda 8.0 and 9.0
Is there any suggest?
Thanks"
15293,Encrypted Data,"It is not easy/possible to use TensorFlow with encrypted data, such as via Homomorphic Encryption or Multi-Party Computation.  It would be useful if future versions of TensorFlow could support HE/MPC or provide the ability for third-party HE/MPC support.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**: N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A
"
15292,Converting a .pb file to .meta in TF 1.3,"Using `tf.slim`'s pre-trained models we can [export_inference_graph](https://github.com/tensorflow/models/tree/master/research/slim#exporting-the-inference-graph) to generate a `.pb` file for a given `.ckpt`, say `inception_v3`. Is there a way to generate `.meta` file of inception_v3 using these two files as well? 

My specific use case is that I need to see the pre-trained weights if inception in each tensor (`tf.variable`) and don't know any other way to retrieve other using .meta and .ckpt to do so and I lack `.meta` here:

```
#retrieve a pre-trained model
sess = tf.Session()
saver = tf.train.import_meta_graph('./model.meta')
saver.restore(sess,'./model.ckpt')
```


**Steps to reproduce:**

I used the instution in export_inference_graph and generated a .pb file, then I exported the .meta file as bellow:

```
sess=tf.Session()
INCEPTION_PB='./inception_v3_inf_graph.pb'
    
f=gfile.FastGFile(INCEPTION_PB,'rb')
graph_def = tf.GraphDef()
graph_def.ParseFromString(f.read())
_= tf.import_graph_def(graph_def,name='')
meta_graph_def = tf.train.export_meta_graph(filename='./inception.meta')
```
However, this results in a `.meta` file without collections, thus can not initialized:

```
>>> saver = tf.train.import_meta_graph('./inception.meta')
INFO:tensorflow:Saver not created because there are no variables in the graph to restore
```

```
 >>> saver.restore(sess,'../../inception_v3.ckpt')
Traceback (most recent call last):
File ""<stdin>"", line 1, in <module>
AttributeError: 'NoneType' object has no attribute 'restore'
```

What is the problem here? I guess it would be nice this conversion feature is added to TF.

Info: 
Have I written custom code: Not much except these above.
OS Platform and Distribution: Ubuntu 14.04.3 - 3.19.0-25-generic
TensorFlow installed from: pip installation 
TensorFlow version - v1.3
Bazel version: v5.4
CUDA/cuDNN version:  v6.0
GPU model and memory: NVIDIA GeForce GTX 1060 6GB - memoryClockRate (GHz) 1.7845



"
15291,Dockerfile.devel-gpu: infinite prompt loop,"```sh
$ docker build -f Dockerfile.devel-gpu github.com/tensorflow/tensorflow.git#master:tensorflow/tools/docker
[...]
Step 19/22 : RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 &&     LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs:${LD_LIBRARY_PATH}     tensorflow/tools/ci_build/builds/configured GPU     bazel build -c opt --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0""         tensorflow/tools/pip_package:build_pip_package &&     rm /usr/local/cuda/lib64/stubs/libcuda.so.1 &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &&     pip --no-cache-dir install --upgrade /tmp/pip/tensorflow-*.whl &&     rm -rf /tmp/pip &&     rm -rf /root/.cache
 ---> Running in 3e8560e2d441
/tensorflow /tensorflow
INFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch
Extracting Bazel installation...
You have bazel 0.5.4 installed.
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL support? [y/N]: No OpenCL support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Invalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 

Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

[... ad infinitum ... ]
```

Is it because the `1.4` branch doesn't support CUDA 9.0?
https://github.com/tensorflow/tensorflow/blob/abd5375ba8d373045321d1eebdb4501c36ab0ccd/tensorflow/tools/docker/Dockerfile.devel-gpu#L74-L76

@gunan"
15290,"Feature request: provide a means to configure, build, and install that includes cc","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Both Mac and Linux
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6.3, but not relevant 
- **Bazel version (if compiling from source)**: 0.8.1, but not relevant
- **GCC/Compiler version (if compiling from source)**: Both GCC and clang, but not relevant
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Tensorflow doesn't seem to have a clean way to install from sources to support both python and C++ development. When we install from sources, only the core tensorflow framework is installed in the python site-packages directory. The `cc` headers (and maybe others) are not included. Likewise the `libtensorflow_cc.so` is not built. It's surprising that there is so little documentation for how C++ developers are expected to develop tensorflow applications. My use case is probably common: I want to train and test my model using python, but I want to deploy an application that does prediction/inference with the app written in C++. 

I have managed once to successfully install the headers and libraries I need into `/usr/local/...` on a Mac, but in doing so I lost some of the CPU optimizations that I had specified when doing the standard build from sources. Now I need to repeat this process on Linux, where I need GPU support, and want to make sure I get it right.

It would be so nice if there was something close to the standard `./configure; make; make install` that could install headers and libraries into a chosen directory.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15288,Eager: eager mode considerably slower than standard TensorFlow for large matrix multiplications ,"We have been benchmarking eager mode versus standard TensorFlow for large square matrix multiplications, specifically the time to run

m = tf.matmul(A, B) (in eager mode) 

versus 

m = sess.run(self.c, feed_dict={self.A:A, self.B:B})

in non-eager mode. 

We find that while runtimes are comparable for small matrices, eager mode is considerably slower for repeated multiplications of large matrices (eg, of dimension 15,000). The first multiplication is fast, but subsequent multiplications take much longer, even after resetting the computation graph. Is this expected behavior? We are running everything on a GPU. 
"
15285,Add kappa coefficient as a new metric?,"Currently tensorflow supports using accuracy as a metric for model's performance.

However, for unbalanced datasets, kappa coefficient (https://www.wikiwand.com/en/Cohen%27s_kappa#) is a commonly used metric. Would it be possible to add this one in the model.metrics?"
15284,[RFE] Runtime GPU Docker image without Jupyter,"Current image size for `nightly-gpu`:
```sh
$ docker images tensorflow/tensorflow:nightly-gpu
REPOSITORY              TAG                 IMAGE ID            CREATED             SIZE
tensorflow/tensorflow   nightly-gpu         8f64c1fbb504        12 hours ago        2.62GB
```
Current Dockerfile:
https://github.com/tensorflow/tensorflow/blob/abd5375ba8d373045321d1eebdb4501c36ab0ccd/tensorflow/tools/docker/Dockerfile.gpu

I see two potential improvements:
1) We already switched the `FROM` to use the `runtime` base image of CUDA. We could go one step further and use `nvidia/cuda:9.0-base`. This flavor of CUDA is new with CUDA 9.0, it just installs the repos and libcudart. You have to manually install the CUDA libraries you want afterwards. The gain wouldn't be that big with TensorFlow since you use most of the libraries from the CUDA toolkit. But we will at least remove NPP from the shipped image.

2) Looks like many dependencies in the current Dockerfile are required for Jupyter. Can we provide a new tag without Jupyter? Or stop shipping Jupyter in the runtime image? Users will still be able to use the `devel` image.

I have a quick Dockerfile proof-of-concept with both improvements:
```
FROM nvidia/cuda:9.0-base-ubuntu16.04

LABEL maintainer=""Gunhan Gulsoy <gunan@google.com>""

RUN echo ""/usr/local/cuda-9.0/extras/CUPTI/lib64"" > /etc/ld.so.conf.d/cupti.conf && \
    apt-get update && apt-get install -y --no-install-recommends \
        libgomp1 \
        libcudnn7 \
        cuda-command-line-tools-9-0 \
        cuda-cudart-9-0 \
        cuda-cufft-9-0 \
        cuda-cublas-9-0 \
        cuda-cusparse-9-0 \
        cuda-curand-9-0 \
        cuda-cusolver-9-0 \
        python-pip \
        && \
    rm -rf /var/lib/apt/lists/

RUN pip --no-cache-dir install --upgrade \
        pip setuptools

RUN pip --no-cache-dir install http://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tf_nightly_gpu-1.head-cp27-cp27mu-manylinux1_x86_64.whl
```
Size is now 1.73 GB, down from 2.62 GB. And there is still room for improvement in CUDA 9.1 when CUPTI has its own package (today we have to pull `cuda-command-line-tools-9-0`), or if we disable CUPTI tracing (not sure if possible).
"
15280,Missing dlcose()/FreeLibrary() after dlopen()/LoadLibrary(),"Have I written custom code: N/A
 OS Platform and Distribution: N/A
 TensorFlow installed from: N/A
 TensorFlow version: N/A
 Bazel version: N/A
 CUDA/cuDNN version: N/A
 GPU model and memory: N/A
 Exact command to reproduce: N/A

Problem description:
A. Looking at code below, there are couple of issues:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h#L34-L59
   1.There is no dlcose() call after dlopen() and dysym() in the code above.
   2.There can be two successful getLibraryHandle() calls without dlclose() in loadFunction().

B. More generally, the code below shows there is no interface to unload DLL either.
https://github.com/tensorflow/tensorflow/blob/359d6f9716c0bb9bd8201ce600da98b0481a8049/tensorflow/core/platform/env.h#L254-L280"
15278,No gradient for argmax,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: 1.5.0-dev20171210 (nightly from today)
- **Python version**: 3.6.2

`ArgMax` crashes with `no gradient` error. I had a working version before I made slight adjustments to my code. I am very confused how this error can happen.

Stacktrace:
```
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\learn\python\learn\learn_runner.py"", line 46, in _execute_schedule
    return task()
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\learn\python\learn\experiment.py"", line 377, in train
    saving_listeners=self._saving_listeners)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\learn\python\learn\experiment.py"", line 824, in _call_train
    saving_listeners=saving_listeners)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 314, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 743, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\python\estimator\estimator.py"", line 725, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\gan\python\estimator\python\gan_estimator_impl.py"", line 162, in _model_fn
    add_summaries)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\gan\python\estimator\python\gan_estimator_impl.py"", line 235, in _gan_model_fn
    labels=None)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\gan\python\estimator\python\head_impl.py"", line 189, in create_estimator_spec
    self._discriminator_optimizer)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\gan\python\train.py"", line 540, in gan_train_ops
    **kwargs)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\contrib\training\python\training\training.py"", line 447, in create_train_op
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\python\training\optimizer.py"", line 456, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""C:\Development\Tools\miniconda\envs\mpgan-nightly\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 581, in gradients
    (op.name, op.type))
LookupError: No gradient defined for operation 'Generator/cond/generator/generator/while/BasicDecoderStep/TrainingHelperSample/ArgMax' (op type: ArgMax)
```"
15274,breaking change to distributed training moving from TF v1.3 to v1.4: “UnavailableError: Trying to connect an http1.x server”,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
n/a
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Red Hat Enterprise Linux Server release 7.3 (Maipo)
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4 (moving from 1,3)
b'v1.4.0-4-g9283868' 1.4.0 in specific
- **Python version**: 
Python 3.6.2 :: Anaconda custom (64-bit)
- **Bazel version (if compiling from source)**:
0.5.4
- **GCC/Compiler version (if compiling from source)**:
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
- **CUDA/cuDNN version**:
N/a
- **GPU model and memory**:
N/a
- **Exact command to reproduce**:
see below. Appears to be any distributed training use case with the cluster spec defined as below.

### Describe the problem

I believe this could be fairly characterized as a BUG.

I raised (and solved) this issue on stackoverflow [here](https://stackoverflow.com/questions/47143043/breaking-change-to-distributed-training-moving-from-tf-v1-3-to-v1-4-unavailabl/47191081#47191081)

In short, upgrading from tf v1.3 to 1.4 distributed training broke with the error
""tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server"".
I was training across multiple CPU cores all on the same localhost.

The fix was to change the ps to the  string ""localhost"" explicitly in the cluster spec instead of the IP ""127.0.0.1"". It stops trying to connect to the localhost via my proxy server (which indeed, was HTTP1.x only i think). I would call this a bug since that IP should be the equivalent, and I'm not sure what other kind of behavior might have inadvertently changed between versions (since this always worked in TF <= 1.3). 

To be fair, I'm also not sure if this is a tensorflow or more gRPC specific issue. In either case, the above is a work around for the problem.
"
15273,Dataset Iterator is not an iterator,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: confidential
- **TensorFlow installed from (source or binary)**: [Pypi](https://pypi.python.org/pypi/tensorflow-gpu/1.4.1)
- **TensorFlow version (use command below)**: `v1.4.0-19-ga52c8d9 1.4.1`
- **Python version**: 3.5.3
- **CUDA/cuDNN version**: (sensitive information replaced by `xxx`)
```
$ apt search cud | grep installed
libcublas8.0/xxx,now 8.0.44-4 amd64 [installed]
libcuda1/xxx,now 375.66-1 amd64 [installed,automatic]
libcuda1-i386/xxx,now 375.66-1 i386 [installed,automatic]
libcudart8.0/xxx,now 8.0.44-4 amd64 [installed]
libcudnn6/now 6.0.21-1+cuda8.0 amd64 [installed,local]
libcufft8.0/xxx,now 8.0.44-4 amd64 [installed]
libcurand8.0/xxx,now 8.0.44-4 amd64 [installed]
libnvidia-fatbinaryloader/xxx,now 375.66-1 amd64 [installed,automatic]
libnvidia-ptxjitcompiler/xxx,now 375.66-1 amd64 [installed,automatic]
```
- **GPU model and memory**: Quadro K1200, 4019 MiB
- **Exact command to reproduce**:
Run [convert_to_records.py](https://github.com/tensorflow/models/tree/5a5d330539dff11eef79ca2e716fb477baf13cf9/official/mnist) from the official MNIST example, then:
```python
>>> import tensorflow as tf
>>> ds = tf.data.TFRecordDataset(['/tmp/mnist_data'])
>>> i  = ds.make_one_shot_iterator()
>>> next(i)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: 'Iterator' object is not an iterator
```

### Describe the problem

The returned ""iterator"" is not an iterator, because it does not provide a `__next__` or `next` method. It does provide a `get_next` method, but that is not what Python expects.
"
15272,Wrongly used dropout bug,"Hi, 

    I guess it should use **tf.layers.dropout** instead of **tf.nn.dropout** here? Because in the inference stage, all the nodes should be used instead of dropout. I guess this is a bug. 

https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/tutorials/mnist/mnist_deep.py#L92

    Many thanks! 

Best wishes, 

Qiuqiang
    "
15271,TFGAN ideas for pretraining/training,"With the PR #14723 enabling `get_hooks_fn` to be set manually instead of the default `1` step generator and `1` step discriminator there comes a set of new ""problems"" / things to consider.

1. The `Estimator` saves configured tensor summaries in the background. This does not work when doing something like a `2/2` split for generator/discriminator or a `2/3`. Then `Estimator` will only save one step instead of the actual amounts of steps taken (right?). This means that we have to consider an option to configure the `FileWriter`. I believe that is possible for the vanilla `Estimator` with `scaffolds` but not for the `GANEstimator` currently. This `FileWriter` has to be accessible by the `RunTrainOpsHook`. We would also need a generator + discriminator specific ""global_step"" that will be used in the `RunTrainOpsHook`. A quick idea would be to use the `overall_global_step * train_steps` of a `RunTrainOpsHook` or to use `dummy_global_step_generator` and `dummy_global_step_discriminator`.

2. When ""pre-training"" (with a normal call to `.train()` and a modified `sequential_train_hook(10,10)`) the generator for e.g. `10` steps and then the discriminator for `10` steps. Does the discriminator `loss_fn` receive 10 times new data from the generator through `gan_model.discriminator_real_outputs` or will it always be the same data? For pre-training I would assume I can feed in the same output data from the generator in batches multiple epochs. I believe that is not possible in the current setup, but correct me if I am wrong.

3. I have different loss functions for both pre-training and training. There is not `ModeKeys.PRETRAIN` to switch between them.

If I find more things I'll add them here."
15269,tf.layers.Layer.set_scope() problem might cause unexpected duplicate name ValueError,"- **OS Platform and Distribution**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: 1.4.1
- **Python version**: 3.5.2
- **CUDA/cuDNN version**: CUDA 8.0, CUDNN 7.0.5
- **GPU model and memory**: GTX1080 (8G)
- **Exact command to reproduce**: python3 test.py
- **Have I written custom code**: True
- **Bazel version**: N/A
- **GCC version**: N/A


Repoduce code:

```python
import tensorflow as tf

_BATCH_NORM_DECAY = 0.997
_BATCH_NORM_EPSILON = 1e-5

def two_batchnorm(inputs):
    with tf.variable_scope('two_batchnorm'):
        inputs = tf.layers.batch_normalization(
            inputs=inputs,
            axis=3,
            momentum=_BATCH_NORM_DECAY,
            epsilon=_BATCH_NORM_EPSILON,
            center=True,
            scale=True,
            training=True,
            fused=True)
        inputs = tf.layers.batch_normalization(
            inputs=inputs,
            axis=3,
            momentum=_BATCH_NORM_DECAY,
            epsilon=_BATCH_NORM_EPSILON,
            center=True,
            scale=True,
            training=True,
            fused=True)
    return inputs

inputs = tf.placeholder(tf.float32, [1, 5, 5, 3])
x = inputs
x = two_batchnorm(x)
x = two_batchnorm(x)
```

It'll trigger an unexpected ValueError as following:

```
ValueError: Variable two_batchnorm/batch_normalization/gamma already exists, disallowed.
```

Removing the variable scope `with tf.variable_scope('two_batchnorm')` in `two_batchnorm` will work as expected.

All variables defined in the graph should be (in creation sequense):

```
two_batchnorm/batch_normalization/gamma:0
two_batchnorm/batch_normalization/beta:0
two_batchnorm/batch_normalization/moving_mean:0
two_batchnorm/batch_normalization/moving_variance:0
two_batchnorm/batch_normalization_1/gamma:0
two_batchnorm/batch_normalization_1/beta:0
two_batchnorm/batch_normalization_1/moving_mean:0
two_batchnorm/batch_normalization_1/moving_variance:0
two_batchnorm/batch_normalization_2/gamma:0
two_batchnorm/batch_normalization_2/beta:0
two_batchnorm/batch_normalization_2/moving_mean:0
two_batchnorm/batch_normalization_2/moving_variance:0
two_batchnorm/batch_normalization_3/gamma:0
two_batchnorm/batch_normalization_3/beta:0
two_batchnorm/batch_normalization_3/moving_mean:0
two_batchnorm/batch_normalization_3/moving_variance:0
```

However, with `tf.layers.Layer`'s `add_variable` logics, it'll result in an unexpected value name as following (in creation sequence):

```
two_batchnorm/batch_normalization/gamma:0
two_batchnorm/batch_normalization/beta:0
two_batchnorm/batch_normalization/moving_mean:0
two_batchnorm/batch_normalization/moving_variance:0
two_batchnorm/batch_normalization_1/gamma:0
two_batchnorm/batch_normalization_1/beta:0
two_batchnorm/batch_normalization_1/moving_mean:0
two_batchnorm/batch_normalization_1/moving_variance:0
two_batchnorm/batch_normalization/gamma:0                        <-- ValueError raised here.
two_batchnorm/batch_normalization/beta:0
two_batchnorm/batch_normalization/moving_mean:0
two_batchnorm/batch_normalization/moving_variance:0
two_batchnorm/batch_normalization_1/gamma:0
two_batchnorm/batch_normalization_1/beta:0
two_batchnorm/batch_normalization_1/moving_mean:0
two_batchnorm/batch_normalization_1/moving_variance:0
```

One solution might be using `self._name` to setup Layer's scope, not `self._base_name`."
15267,2017-12-11 17:53:55.834374: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Slice,"System information
https://stackoverflow.com/questions/tagged/tensorflow
### System information
- **OS Platform and Distribution **:Linux Ubuntu 16.04
- **TensorFlow installed from **:source
- **TensorFlow version ,installed from source**:1.4
- **Python version**:2.7 
- **Bazel version :1.5
- **GCC/Compiler version**: 5.4.0   20160609
- **cpu version(**:Intel® Core™ i5-7500 CPU @ 3.40GHz × 4
CUDA/cuDNN version
N/A
GPU model and memory
N/A
- **Exact command to reproduce**:


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
use this command:

bazel-bin/tensorflow/contrib/lite/toco/toco  \
--input_file=/home/liu/az/caffe-tensorflow-master/MobileNet/frozen_graph.pb \
--input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \
--output_file=/home/liu/az/caffe-tensorflow-master/MobileNet/mobilenet.lite --inference_type=FLOAT \
--inference_input_type=FLOAT --input_arrays=img \
--output_arrays=prob --input_shapes=1,20,20,3

**I am trying to convert a graph from frozen .pb to .lite format using toco, but I get this error:**

2017-12-11 17:53:55.833614: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1046] Converting unsupported operation: Pack
2017-12-11 17:53:55.833891: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 40 operators, 58 arrays (0 quantized)
2017-12-11 17:53:55.834169: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 14 operators, 30 arrays (0 quantized)
2017-12-11 17:53:55.834226: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 14 operators, 30 arrays (0 quantized)
2017-12-11 17:53:55.834281: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 128000 bytes, theoretical optimal value: 128000 bytes.
2017-12-11 17:53:55.834374: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Slice
Aborted (core dumped)

who can tell me how to get rid of this error?

### Source code / logs

# -*- coding: utf-8 -*-
import tensorflow as tf
import tensorflow.contrib.lite.python.lite
#创建一个交互式Session
sess = tf.InteractiveSession()
#创建两个占位符，x为输入网络的图像，y_为输入网络的图像类别
x = tf.placeholder(name=""img"",dtype=tf.float32, shape=[1,20,20,3])
y_ = tf.placeholder(name=""output"",dtype=tf.float32, shape=[None, 2])
#权重初始化函数
def weight_variable(shape):
    #输出服从截尾正态分布的随机值
    initial = tf.truncated_normal(shape, stddev=0.1)
    return tf.Variable(initial)
#偏置初始化函数
def bias_variable(shape):
    initial = tf.constant(0.1, shape=shape)
    return tf.Variable(initial)
#创建卷积op
#x 是一个4维张量，shape为[batch,height,width,channels]
#卷积核移动步长为1。填充类型为SAME,可以不丢弃任何像素点
def conv2d(x, W, type):
    if type == ""SAME"":
        return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding=""SAME"")
    else:
        return tf.nn.conv2d(x,W, strides=[1,1,1,1],padding=""VALID"")

#创建池化op
#采用最大池化，也就是取窗口中的最大值作为结果
#x 是一个4维张量，shape为[batch,height,width,channels]
#ksize表示pool窗口大小为2x2,也就是高2，宽2
#strides，表示在height和width维度上的步长都为2
def max_pool_2x2(x):
    return tf.nn.max_pool(x, ksize=[1,2,2,1],
                          strides=[1,2,2,1], padding=""SAME"")
#第1层，卷积层
W_conv1 = weight_variable([3,3,3,16])
b_conv1 = bias_variable([16])

#x_image = tf.reshape(x, [-1,20,20,3])
x_image = x;

h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1,""SAME"") + b_conv1)
W_conv2 = weight_variable([3,3,16,64])
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2,""SAME"") + b_conv2)
h_pool1 = max_pool_2x2(h_conv2)


W_conv3 = weight_variable([3,3,64,64])
b_conv3 = weight_variable([64])
h_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv3,""SAME"") + b_conv3)

h_pool2 = max_pool_2x2(h_conv3)

W_conv4 = weight_variable([2,2,64,16])
b_conv4 = weight_variable([16])
h_conv4 = tf.nn.relu(conv2d(h_pool2, W_conv4,""VALID"") + b_conv4)

W_conv5 = weight_variable([3,3,16,2])
b_conv5 = weight_variable([2])
h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5,""VALID"") + b_conv5)

h_pool3 = max_pool_2x2(h_conv5)

y_conv = tf.nn.softmax(h_pool3,name=""prob"")
out = tf.identity(y_conv, name=""prob"")
#预测值和真实值之间的交叉墒
cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))

#train op, 使用ADAM优化器来做梯度下降。学习率为0.0001
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

#评估模型，tf.argmax能给出某个tensor对象在某一维上数据最大值的索引。
#因为标签是由0,1组成了one-hot vector，返回的索引就是数值为1的位置
correct_predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))

#计算正确预测项的比例，因为tf.equal返回的是布尔值，
#使用tf.cast把布尔值转换成浮点数，然后用tf.reduce_mean求平均值
accuracy = tf.reduce_mean(tf.cast(correct_predict, ""float""))
saver=tf.train.Saver()
#初始化变量
with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    constant_graph = tf.get_default_graph().as_graph_def()
    with tf.gfile.FastGFile('../MobileNet/' + 'mobile.pb', mode='wb') as f:
        f.write(constant_graph.SerializeToString())
        saver.save(sess, ""../MobileNet/mobile.ckpt"")
    tflite_model = tf.contrib.lite.toco_convert(sess.graph_def, [x], [out])
    open(""converteds_model.tflite"", ""wb"").write(tflite_model)
"
15266, //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel  test fails on ppc64le,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
     Ubuntu 16.04 (ppc64le)
- **TensorFlow installed from (source or binary)**:
      Installed from source (v1.3.1)
- **TensorFlow version (use command below)**:
      TF1.3.1
- **Python version**: 
     Python 2.7.5
- **Bazel version (if compiling from source)**:
       0.5.4
- **CUDA/cuDNN version**:
     NA
- **GPU model and memory**:
      NA
- **Exact command to reproduce**:
      bazel test -c opt //tensorflow/compiler/xla/tests:array_elementwise_ops_test_cpu_parallel       


**Describe the problem**

Here 2 sub tests are failing on ppc64le i.e.` IsFiniteScalarF32`  and `IsFiniteR1F32s` in file array_elementwise_ops_test.cc

For IsFiniteScalarF32 sub-test , error at line 100 : 
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/compiler/xla/tests/array_elementwise_ops_test.cc#L100
`ComputeAndCompareR0<bool>(&builder, false, {});`
 The failure due to expected: false  vs actual: true

For IsFiniteR1F32s sub-test , error at line 126 :
https://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/compiler/xla/tests/array_elementwise_ops_test.cc#L126
`ComputeAndCompareR1<bool>(&builder, {false, true, false, true, false, false}, {});`
The failure due to expected: {010100}  vs actual: {111100}

Currently trying to find the root cause , started debugging further on this. Any inputs/help appreciated.Thanks!

**Source code / logs**

1 .**IsFiniteScalarF32 sub-test log :**
```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Note: This is test shard 5 of 25.
[==========] Running 6 tests from 2 test cases.
[----------] Global test environment set-up.
[----------] 5 tests from ArrayElementwiseOpTest
[ RUN      ] ArrayElementwiseOpTest.IsFiniteScalarF32
2017-12-11 09:36:20.653075: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:20.654000: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:20.654482: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x100062a6ea0 executing computations on platform Host. Devices:
2017-12-11 09:36:20.654493: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): <undefined>, <undefined>
tensorflow/compiler/xla/tests/literal_test_util.cc:157: Failure
Value of: Equal(expected, actual)
  Actual: false (expected: false
actual:   true)
Expected: true
expected:
false
        vs actual:
true
tensorflow/compiler/xla/tests/literal_test_util.cc:157: Failure
Value of: Equal(expected, actual)
  Actual: false (expected: false
actual:   true)
Expected: true
expected:
false
        vs actual:
true
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteScalarF32 (60 ms)
[ RUN      ] ArrayElementwiseOpTest.LogicalNotZeroElement
2017-12-11 09:36:20.712501: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.LogicalNotZeroElement (6 ms)
[ RUN      ] ArrayElementwiseOpTest.LogOfPowerF32
2017-12-11 09:36:20.719016: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.LogOfPowerF32 (12 ms)
[ RUN      ] ArrayElementwiseOpTest.Max3DAndScalarZeroElementS32s
2017-12-11 09:36:20.731087: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Max3DAndScalarZeroElementS32s (7 ms)
[ RUN      ] ArrayElementwiseOpTest.Compare1DTo2DS32Ne
2017-12-11 09:36:20.738675: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Compare1DTo2DS32Ne (13 ms)
[----------] 5 tests from ArrayElementwiseOpTest (99 ms total)

[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount
[ RUN      ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/0
2017-12-11 09:36:20.751273: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/0 (34 ms)
[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount (34 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test cases ran. (133 ms total)
[  PASSED  ] 5 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteScalarF32

 1 FAILED TEST

```
2. **IsFiniteR1F32s sub-test log:**

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
Note: This is test shard 6 of 25.
[==========] Running 6 tests from 2 test cases.
[----------] Global test environment set-up.
[----------] 5 tests from ArrayElementwiseOpTest
[ RUN      ] ArrayElementwiseOpTest.IsFiniteR1F32s
2017-12-11 09:36:21.201704: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:21.202563: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-12-11 09:36:21.203145: I tensorflow/compiler/xla/service/service.cc:187] XLA service 0x10015cc6ea0 executing computations on platform Host. Devices:
2017-12-11 09:36:21.203154: I tensorflow/compiler/xla/service/service.cc:195]   StreamExecutor device (0): <undefined>, <undefined>
tensorflow/compiler/xla/tests/literal_test_util.cc:157: Failure
Value of: Equal(expected, actual)
  Actual: false (expected: {010100}
actual:   {111100})
Expected: true
expected:
{010100}
        vs actual:
{111100}
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteR1F32s (17 ms)
[ RUN      ] ArrayElementwiseOpTest.CompareEqF32s
2017-12-11 09:36:21.218227: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.CompareEqF32s (10 ms)
[ RUN      ] ArrayElementwiseOpTest.MulOfExpF32
2017-12-11 09:36:21.228744: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.MulOfExpF32 (12 ms)
[ RUN      ] ArrayElementwiseOpTest.Min2DTo1DF32s
2017-12-11 09:36:21.240780: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Min2DTo1DF32s (15 ms)
[ RUN      ] ArrayElementwiseOpTest.Compare1DTo2DS32Ge
2017-12-11 09:36:21.255836: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTest.Compare1DTo2DS32Ge (19 ms)
[----------] 5 tests from ArrayElementwiseOpTest (73 ms total)

[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount
[ RUN      ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/1
2017-12-11 09:36:21.274589: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
[       OK ] ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount.SquareManyValues/1 (73 ms)
[----------] 1 test from ArrayElementwiseOpTestParamCount/ArrayElementwiseOpTestParamCount (73 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test cases ran. (146 ms total)
[  PASSED  ] 5 tests.
[  FAILED  ] 1 test, listed below:
[  FAILED  ] ArrayElementwiseOpTest.IsFiniteR1F32s

 1 FAILED TEST

```
"
15263,Cannot parse tensor from proto: dtype: DT_INT32 when using tf.extract_image_patches and tf.reshape,"Hi,
I'm experiencing a problem when using TensorFlow to extract image patches and then reshape the output. I'm using TensorFlow 1.3.0, what am i doing wrong?

That's my code:
```
import tensorflow as tf
import numpy as np
c = 3
h = 1024
p = 32

image = tf.random_normal([h,h,c])
patch_size = [1,p,p,1]
patches = tf.extract_image_patches([image],
   patch_size, patch_size, [1, 1, 1, 1], 'VALID')
patches = tf.reshape(patches, [h, p, p, c])

sess = tf.Session()
I,P,R_n = sess.run([image,patches])
print(I.shape)
print(P.shape)
```

The error i'm getting is this:
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1326     try:
-> 1327       return fn(*args)
   1328     except errors.OpError as e:

~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\client\session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
   1305                                    feed_dict, fetch_list, target_list,
-> 1306                                    status, run_metadata)
   1307 

~\AppData\Local\conda\conda\envs\tf\lib\contextlib.py in __exit__(self, type, value, traceback)
     65             try:
---> 66                 next(self.gen)
     67             except StopIteration:

~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\errors_impl.py in raise_exception_on_not_ok_status()
    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),
--> 466           pywrap_tensorflow.TF_GetCode(status))
    467   finally:

InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_INT32
tensor_shape {
  dim {
    size: 3
  }
}
tensor_content: ""\000\004\000\000\000\004\000\000\003\000\000\000""

	 [[Node: random_normal_21/shape = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [3] values: 1024 1024 3>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-159-454594e78931> in <module>()
     12 
     13 sess = tf.Session()
---> 14 I,P,R_n = sess.run([image,patches])
     15 print(I.shape)
     16 print(P.shape)

~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    893     try:
    894       result = self._run(None, fetches, feed_dict, options_ptr,
--> 895                          run_metadata_ptr)
    896       if run_metadata:
    897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1122     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1123       results = self._do_run(handle, final_targets, final_fetches,
-> 1124                              feed_dict_tensor, options, run_metadata)
   1125     else:
   1126       results = []

~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\client\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1319     if handle is None:
   1320       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1321                            options, run_metadata)
   1322     else:
   1323       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

~\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\client\session.py in _do_call(self, fn, *args)
   1338         except KeyError:
   1339           pass
-> 1340       raise type(e)(node_def, op, message)
   1341 
   1342   def _extend_graph(self):

InvalidArgumentError: Cannot parse tensor from proto: dtype: DT_INT32
tensor_shape {
  dim {
    size: 3
  }
}
tensor_content: ""\000\004\000\000\000\004\000\000\003\000\000\000""

	 [[Node: random_normal_21/shape = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [3] values: 1024 1024 3>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

Caused by op 'random_normal_21/shape', defined at:
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\traitlets\config\application.py"", line 658, in launch_instance
    app.start()
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\zmq\eventloop\ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tornado\ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\zmq\eventloop\zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\ipykernel\zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\IPython\core\interactiveshell.py"", line 2698, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\IPython\core\interactiveshell.py"", line 2802, in run_ast_nodes
    if self.run_code(code, result):
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\IPython\core\interactiveshell.py"", line 2862, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-159-454594e78931>"", line 7, in <module>
    image = tf.random_normal([h,h,c])
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\ops\random_ops.py"", line 71, in random_normal
    shape_tensor = _ShapeTensor(shape)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\ops\random_ops.py"", line 42, in _ShapeTensor
    return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\ops.py"", line 611, in convert_to_tensor
    as_ref=False)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\ops.py"", line 676, in internal_convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 121, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 106, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\Users\koko\AppData\Local\conda\conda\envs\tf\lib\site-packages\tensorflow\python\framework\ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot parse tensor from proto: dtype: DT_INT32
tensor_shape {
  dim {
    size: 3
  }
}
tensor_content: ""\000\004\000\000\000\004\000\000\003\000\000\000""

	 [[Node: random_normal_21/shape = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [3] values: 1024 1024 3>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
```"
15262,Bug with tf.layers.Dense,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
8.0
- **GPU model and memory**:
GTX 1080 ti
- **Exact command to reproduce**:

with tf.variable_scope('hello') as var_scope:
    var = tf.get_variable('var', [3,4,5])
    dense = tf.layers.Dense(5, name = 'dense_layer')
    b = dense(a)

And the error was : 
RuntimeError: Conversion function <function _TensorConversionFunction at 0x7f5bed522b90> for type <class 'tensorflow.python.ops.variables.Variable'> returned incompatible dtype: requested = float32_ref, actual = float32"
15261,"ValueError: Variable Model/LSTMenc/rnn/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:


### Describe the problem
If I put reuse=None while creating BasicLSTMCell in the following code, I get this error:
```
Traceback (most recent call last):
  File ""pretrain.py"", line 358, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""pretrain.py"", line 251, in main
    valid_model = build_model(word_vocab, train=False)
  File ""pretrain.py"", line 200, in build_model
    dropout=FLAGS.dropout))
  File ""/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py"", line 218, in lstm_doc_enc
    initial_state=initial_rnn_state, dtype=tf.float32)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py"", line 197, in static_rnn
    (output, state) = call_cell()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py"", line 184, in <lambda>
    call_cell = lambda: cell(input_, state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 235, in __call__
    with _checked_scope(self, scope or ""basic_lstm_cell"", reuse=self._reuse):
  File ""/usr/lib/python2.7/contextlib.py"", line 17, in __enter__
    return self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 93, in _checked_scope
    ""the argument reuse=True."" % (scope_name, type(cell).__name__))
ValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'Model/LSTMenc/rnn/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.
```
If I put reuse=True, I get this error
```
Traceback (most recent call last):
  File ""pretrain.py"", line 358, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""pretrain.py"", line 244, in main
    train_model = build_model(word_vocab, train=True)
  File ""pretrain.py"", line 146, in build_model
    dropout=FLAGS.dropout))
  File ""/home/raghuram.vadapalli/styletransfer/NeuralSum/model.py"", line 218, in lstm_doc_enc
    initial_state=initial_rnn_state, dtype=tf.float32)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py"", line 197, in static_rnn
    (output, state) = call_cell()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py"", line 184, in <lambda>
    call_cell = lambda: cell(input_, state)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 713, in __call__
    output, new_state = self._cell(inputs, state, scope)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 241, in __call__
    concat = _linear([inputs, h], 4 * self._num_units, True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"", line 1044, in _linear
    _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size], dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 1049, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 948, in get_variable
    use_resource=use_resource, custom_getter=custom_getter)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 356, in get_variable
    validate_shape=validate_shape, use_resource=use_resource)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 341, in _true_getter
    use_resource=use_resource)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 671, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable Model/LSTMenc/rnn/basic_lstm_cell/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
```
### Source code / logs
```
def lstm_doc_enc(input_cnn,
                   batch_size=20,
                   num_rnn_layers=2,
                   rnn_size=650,
                   max_doc_length=35,
                   dropout=0.0):

    # lstm document encoder
    with tf.variable_scope('LSTMenc') as scope:
        def create_rnn_cell():
            cell = tf.contrib.rnn.BasicLSTMCell(rnn_size, state_is_tuple=True, forget_bias=0.0, reuse=True)
            if dropout > 0.0:
                cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=1.-dropout)
            return cell

        if num_rnn_layers > 1:
            cell = tf.contrib.rnn.MultiRNNCell([create_rnn_cell() for _ in range(num_rnn_layers)], state_is_tuple=True)
        else:
            cell = create_rnn_cell()

        initial_rnn_state = cell.zero_state(batch_size, dtype=tf.float32)

        input_cnn = tf.reshape(input_cnn, [batch_size, max_doc_length, -1])
        input_cnn2 = [tf.squeeze(x, [1]) for x in tf.split(input_cnn, max_doc_length, 1)]

        outputs, final_rnn_state = tf.contrib.rnn.static_rnn(cell, input_cnn2,
                                         initial_state=initial_rnn_state, dtype=tf.float32)

    return adict(
        initial_enc_state=initial_rnn_state,
        final_enc_state=final_rnn_state,
        enc_outputs=outputs
    )

```
"
15259,Using tensorflow to compute gradients w.r.t. spectral decomposition error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS High Sierra 10.13.1
- **TensorFlow installed from (source or binary)**: pip install tensorflow
- **TensorFlow version (use command below)**: v1.2.0-5-g435cdfc 1.2.1
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: see code

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Hi,

I'm having issues with evaluating the gradients of eigenvalues/eigenvectors with respect to the underlying matrix. Tensorflow evaluates the gradients, however when compared against analytical derivations the gradients are generally inconsistent (I understand numerical can be unstable). I'd like to understand is there's a bug in the gradients or if a different methodology was employed to the one cited below.

We are using tf.self_adjoint_eig to evaluate the spectral decomposition for the tensorflow variable input. We have initialised this with a symmetric matrix to satisfy the self adjoint operator property. We wish to take the derivative of individual eigenvalues or eigenvector with respect to the original matrix (note for eigenvectors we take one element from one eigenvector, e.g. element 2 in eigenvector 1 to avoid the issue of gradient aggregation for now).

The methodology for evaluating analytical gradients of eigenvalues and vectors of a symmetric real matrix can be found in the paper ""On differentiating Eigenvalues and Eigenvectors"" by Magnus (1985), Theorem 1 eqn (6) + (7). We evaluated using our input matrix the gradients under this paper and compared it to tensorflow evaluated gradients and the gradients from finite difference approximation. For the eigenvalues, the gradients are similar (identical on diagonal entries, off by a factor of 2 on off-diagonal elements), however the eigenvectors are off by quite a bit outside the diagonal entries. To start, define a matrix A as (excuse the matrix output formatting from Python)

A=[[-3 -2  4]
      [-2  1  1]
      [ 4  1  5]]

using np.linalg.eig and tf.self_adjoint_eig on A (I simply initialised a variable with A and computed the gradient for the tf implementation)

Tensorflow eigenvalues: [-5.43071561  1.76904987  6.66166575]
Python eigenvalues: [-5.43071561  6.66166575  1.76904987]

I now wish to evaluate the gradient of eigenvalue 1 (-5.43071561) w.r.t. A. 

Analytical gradient:
[[ 0.75896178  0.28555906 -0.31842553]
 [ 0.28555906  0.10744148 -0.11980748]
 [-0.31842553 -0.11980748  0.13359674]]

Tensorflow gradient:
[[[ 0.75896178,  0.        ,  0.        ],
   [ 0.57111812,  0.10744148,  0.        ],
  [-0.63685107, -0.23961495,  0.13359674]]]

The diagonal entries are the same but the off-diagonal entries are clearly off by a factor of 2.  Now we try and evaluate gradients for the eigenvectors.

Tensorflow eigenvectors:
[[-0.87118413 -0.31452619 -0.37697678]
 [-0.32778267  0.94426587 -0.0303395 ]
 [ 0.36550888  0.09713517 -0.92572567]]
Python eigenvectors:
[[ 0.87118413  0.37697678 -0.31452619]
 [ 0.32778267  0.0303395   0.94426587]
 [-0.36550888  0.92572567  0.09713517]]

We try and find the gradient of the eigenvector 1 element 2 (+/-0.32778267). We expect the tensorflow gradient to the equivalent to the analytical gradient (after taking into account the sign difference).

Analytical gradient:
[[ 0.03511309 -0.10795607 -0.01312188]
 [ 0.01321128 -0.04061843 -0.0049371 ]
 [-0.01473184  0.04529341  0.00550534]]

Tensorflow gradient:
[[[-0.03511309,  0.        ,  0.        ],
   [ 0.09474478,  0.04061843,  0.        ],
   [ 0.02785372, -0.04035631, -0.00550534]]]

Besides the entries being different on the off-diagonal, one issue is that tensorflow only returns the lower triangle of the gradient. Despite A being symmetric, the contribution to the gradient is not symmetric as shown in the analytical evaluation above. Thank you for reading!

TL:DR, I'd like to understand where the gradient computations are coming from and why they differ substantially to the results we have been using in our research. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Here is a script that reproduces the above.

[eigen_decomp_examplev2.py.zip](https://github.com/tensorflow/tensorflow/files/1546631/eigen_decomp_examplev2.py.zip)
"
15258,[no such file or directory: 'x86_64'] when building the library in TensorFlow Lite for iOS,"Hi all, I encountered with an issur when trying to [setting up the environment to build TensorFlow Lite for iOS. ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/ios.md#building).
But when I was trying to build the library for all five supported architectures on iOS using `tensorflow/contrib/lite/build_ios_universal_lib.sh`, I have the follwing issue. 


    xcrun: error: SDK ""iphonesimulator"" cannot be located
    xcrun: error: SDK ""iphonesimulator"" cannot be located
    xcrun: error: unable to lookup item 'PlatformPath' in SDK 'iphonesimulator'
    xcrun: error: SDK ""iphonesimulator"" cannot be located
    xcrun: error: SDK ""iphonesimulator"" cannot be located
    xcrun: error: unable to lookup item 'Path' in SDK 'iphonesimulator'
    xcrun: error: SDK ""iphoneos"" cannot be located
    xcrun: error: SDK ""iphoneos"" cannot be located
    xcrun: error: unable to lookup item 'SDKVersion' in SDK 'iphoneos'
    gcc --std=c++11 -O3 -DNDEBUG -miphoneos-version-min=9.0 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -fembed-bitcode -Wno-c++11-narrowing -mno-thumb -fno-exceptions -isysroot  -arch x86_64 -O3 -I. -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/../../../ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/farmhash/src -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/allocation.cc -o /Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/allocation.o
    gcc -miphoneos-version-min=9.0 -fembed-bitcode -mno-thumb -isysroot  -arch x86_64 -O3 -I. -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/../../../ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/farmhash/src -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/context.c -o /Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/context.o
    gcc --std=c++11 -O3 -DNDEBUG -miphoneos-version-min=9.0 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -fembed-bitcode -Wno-c++11-narrowing -mno-thumb -fno-exceptions -isysroot  -arch x86_64 -O3 -I. -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/../../../ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/farmhash/src -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/downloads/farmhash/src/farmhash.cc -o /Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/downloads/farmhash/src/farmhash.o
    gcc --std=c++11 -O3 -DNDEBUG -miphoneos-version-min=9.0 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -fembed-bitcode -Wno-c++11-narrowing -mno-thumb -fno-exceptions -isysroot  -arch x86_64 -O3 -I. -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/../../../ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/farmhash/src -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/error_reporter.cc -o /Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/error_reporter.o
    gcc --std=c++11 -O3 -DNDEBUG -miphoneos-version-min=9.0 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -fembed-bitcode -Wno-c++11-narrowing -mno-thumb -fno-exceptions -isysroot  -arch x86_64 -O3 -I. -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/../../../ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/ -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/eigen -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/gemmlowp -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/neon_2_sse -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/farmhash/src -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/downloads/flatbuffers/include -I/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ -I/usr/local/include -c tensorflow/contrib/lite/interpreter.cc -o /Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/interpreter.o
    clang: error: no such file or directory: 'x86_64'
    clang: warning: no such sysroot directory: '-arch' [-Wmissing-sysroot]
    make: *** [/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/allocation.o] Error 1
    make: *** Waiting for unfinished jobs....
    clang: error: no such file or directory: 'x86_64'
    clang: warning: no such sysroot directory: '-arch' [-Wmissing-sysroot]
    clang: error: no such file or directory: 'x86_64'
    clang: warning: no such sysroot directory: '-arch' [-Wmissing-sysroot]
    make: *** [/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/context.o] Error 1
    make: *** [/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/downloads/farmhash/src/farmhash.o] Error 1
    clang: error: no such file or directory: 'x86_64'
    clang: warning: no such sysroot directory: '-arch' [-Wmissing-sysroot]
    make: *** [/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/error_reporter.o] Error 1
    clang: error: no such file or directory: 'x86_64'
    clang: warning: no such sysroot directory: '-arch' [-Wmissing-sysroot]
    make: *** [/Users/zhangjiawei/tensorflow/tensorflow/contrib/lite/gen/obj/ios_x86_64/tensorflow/contrib/lite/interpreter.o] Error 1


### System information
- **OS Platform and Distribution**: macOS High Sierra 10.13.2(17C88)
- **TensorFlow version (use command below)**: v1.3.0-rc2-20-g0787eee 1.3.0
- **Python version**: 3.6.1
- **GCC/Compiler version (if compiling from source)**: GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)
- **Exact command to reproduce**: `bash tensorflow/contrib/lite/build_ios_universal_lib.sh`
- **Have I written custom code?**: no
- **TensorFlow installed from**: source
- **Bazel version**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A

Has anyone else had the same problem?"
15257,can't read my own tfrecords and face FailedPreconditionError,"Please go to Stack Overflow for help and support:

### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 1604
- **TensorFlow installed from (source or binary)**: conda tensorflow
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7
- **Bazel version: N/A
- **CUDA/cuDNN version: N/A
- **GPU model and memory: N/A

### Describe the problem
I'm tryting to read my own datasets. And there exists FailedPreconditionError.
But my ` test.records` are in the right directory, I don't know why it ocurred.

### Source code / logs
these are the console error.
```
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.FailedPreconditionError'>, /home/tju/0_lvjc/deepnet348/data/tfrecords
	 [[Node: ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/cpu:0""](TFRecordReaderV2, input_producer)]]
Traceback (most recent call last):
  File ""/home/tju/Downloads/pycharm-community-2017.2.4/helpers/pydev/pydev_run_in_console.py"", line 37, in run_file
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/home/tju/0_lvjc/deepnet348/data_input.py"", line 199, in <module>
    coord.join(threads)
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 238, in _run
    enqueue_callable()
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1235, in _single_operation_run
    target_list_as_strings, status, None)
  File ""/home/tju/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/home/tju/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
```

these are my codes.
```
#%% Convert data to TFRecord

file_dir='/home/tju/0_lvjc/datasets/SALICON/train_images/*.jpg'
label_dir='/home/tju/0_lvjc/datasets/SALICON/salicon17_maps/train/*.png'

tfrecords_file = '/home/tju/0_lvjc/deepnet348/data/tfrecords'
BATCH_SIZE = 5


#Convert test data: you just need to run it ONCE !
name_test = 'test'
images, labels = get_file(file_dir, label_dir)
convert_to_tfrecord(images, labels, save_dir=tfrecords_file, name=name_test)


#%% TO test train.tfrecord file

def plot_images(images, labels):
    '''plot one batch size
    '''
    for i in np.arange(0, BATCH_SIZE):
        plt.subplot(5, 5, i + 1)
        plt.axis('off')
        plt.title(chr(ord('A') + labels[i] - 1), fontsize = 14)
        plt.subplots_adjust(top=1.5)
        plt.imshow(images[i])
    plt.show()



image_batch, label_batch = read_and_decode(tfrecords_file, batch_size=BATCH_SIZE)

with tf.Session()  as sess:
    
    i = 0
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)
    
    try:
        while not coord.should_stop() and i<1:
            # just plot one batch size
            image, label = sess.run([image_batch, label_batch])
            plot_images(image, label)
            i+=1
            
    except tf.errors.OutOfRangeError:
        print('done!')
    finally:
        coord.request_stop()
    coord.join(threads)

```"
15256,Problem about tf.data.Dataset.from_sparse_tensor_slices,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Win10
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.4
- **Python version**: 3.52
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0,6.46
- **GPU model and memory**:2GB
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
I used the tf.data.Dataset.from_sparse_tensor_slices to built a dataset. But the website has no enought information.
Here's my code
`    point_cloud_feature_dataset = tf.data.Dataset.from_sparse_tensor_slices(sparse_feature)
    point_cloud_feature_dataset = point_cloud_feature_dataset.shuffle(buffer_size = 100000)
    point_cloud_feature_dataset = point_cloud_feature_dataset.batch(batch_size = BATCH_SIZE)
    point_cloud_feature_dataset = point_cloud_feature_dataset.repeat()
    iterator_feature = point_cloud_feature_dataset.make_one_shot_iterator()`

when I called the iterator_feature.get_nest(). It return 3 Tensors of shape [none,none,1]. Instead of a SparseTensor.  The input Sparse Tensor of dataset has a shape of [1000000,300000]. Each row is a example. I hope talents can replenish the Doc. Thanks!!  

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15254,CMake build on Windows (tensorflow.dll) does not include many GPU ops,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
from source
- **TensorFlow version (use command below)**:
1.4

- **Python version**:  3.5.2
- **Bazel version (if compiling from source)**:
using CMake (3.8.2)
- **GCC/Compiler version (if compiling from source)**:
MSVC 14 (C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\CL.exe)
- **CUDA/cuDNN version**:
CUDA 8.0, cuDNN: 6 (6.14)
- **GPU model and memory**:
NVidia GTX 1070 (8GB)
- **Exact command to reproduce**:

### Describe the problem
I build tensorflow from source following these instructions:
 https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake
and I use this CMake command:
`cmake ..  -G ""Visual Studio 14 2015 Win64"" -T v140,host=x64 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DSWIG_EXECUTABLE=e:/dev/swigwin-3.0.12/swig.exe -Dtensorflow_ENABLE_GPU=ON  -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA""   -Dtensorflow_BUILD_SHARED_LIB=ON -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2  -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF
`
and `MSBuild /p:Configuration=RelWithDebInfo tensorflow.vcxproj`

(I also tried 'Release' as Configuration - same outcome).
The result of the build process is  `tensorflow.dll`. I use a separate C++ program (using Qt) to link against the built DLL. In general, everything works fine: I can load a saved tensorflow graph and run it (=inference).
The problem is now, that many GPU-ops are not linked into tensorflow.dll (for example, `Softmax`) - in my example most ops run on GPU but Softmax on CPU - with a huge performance impact (GPU use <10%). Why I think this is the case:
* `tensorflow::LogAllRegisteredKernels()` lists Softmax, but with CPU only
* looking at tensorflow.dll with DependecyWalker has the same result (Softmax CPU only)
* when I check `tf_core_gpu_kernels.lib`, then GPU code is there (e.g., `tf_core_gpu_kernels_generated_softmax_op_gpu.cu.cc.lib`).

### Workaround
After quite some time trying to figure this out, I found a hackish workaround:
Looking at the output of MSBuild (increased verbosity level), it looks as if the python script create_def_file.py is executed without using the tf_core_kernels.lib (`C:\Python35\python.exe E:/dev/tensorflow/tensorflow/contrib/cmake/tools/create_def_file.py --input E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow_static.lib;E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tf_protos_cc.lib --output E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow.def --target tensorflow.dll`). 
What I did is the following:
* create a def-file including the GPU kernels:
`C:\Python35\python.exe E:/dev/tensorflow/tensorflow/contrib/cmake/tools/create_def_file.py --input E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow_static.lib;E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tf_protos_cc.lib;E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tf_core_gpu_kernels.lib --output E:/dev/tensorflow/tensorflow/contrib/cmake/build/RelWithDebInfo/tensorflow_wr.def --target tensorflow.dll`

* Link tensorflow.dll with the created def file (tensorflow_wr.def). This did not work, since I got a couple of missing-unresolved-externals errors. As they were all related to LSTM/RNN, I ended up re-creating `tf_core_gpu_kernels.lib` (issuing the Lib.exe omitting tf_core_gpu_kernels_generated_gru_ops_gpu.cu.cc.obj and tf_core_gpu_kernels_generated_lstm_ops_gpu.cu.cc.obj)

* Finally linking tensorflow.dll worked after I manually dropped a couple of symbols from 'tensorflow_wr.def) (unresolved external symbols).

With this workaround it works fine - all ops (including Softmax) run on GPU, performance increased by a factor of 10. I submit as an issue, since I believe it should work out of the box!

Some more details on [StackOverflow](https://stackoverflow.com/questions/47636903/tensorflow-places-softmax-op-on-cpu-instead-of-gpu)
"
15252,vm compiled tensorflow - libmklml_intel.so ImportError,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04 VM
- **TensorFlow installed from (source or binary)**:
Source
- **TensorFlow version (use command below)**:
Branch `r1.4` and branch `master`
- **Python version**: 
3.6.3
- **Bazel version (if compiling from source)**:
Build label: 0.8.1 (Install using apt repository)
- **GCC/Compiler version (if compiling from source)**:
gcc-6 (Ubuntu 6.4.0-10ubuntu1~16.04.york0) 6.4.0 20171112

- **Exact command to reproduce**:
python -c ""import tensorflow as tf;""

### Describe the problem
After compiling Tensorflow from source with tutorial: `https://www.tensorflow.org/install/install_sources` and install the compiled pip package, I import tensorflow on python console and get those errors:

~~~
python -c ""import tensorflow as tf;""
Traceback (most recent call last):
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/potatoman/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/potatoman/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 73, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/potatoman/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/home/potatoman/anaconda3/lib/python3.6/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/home/potatoman/anaconda3/lib/python3.6/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: libmklml_intel.so: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
~~~

My machine is a headless KVM virtual machine running on a ubuntu 17.10, btw.

I figure out where the problem is somehow, which is the pip packaging script don't include those mkl so files, and in my case, replace `_solib_k8` in script `tensorflow/tools/pip_package/setup.py` at line 185 with `_solib_local` solves the issue.

"
15251,different output size for avg_pool and max_pool,"Hello,

I have the same bug as this user.

https://stackoverflow.com/questions/47423172/tensorflow-why-does-avg-pool-ignore-one-stride-dimension

My version is uo-to-date

Have I written custom code: Yes
OS Platform and Distribution: Linux Mint 18.3, codename ""Sylvia""
TensorFlow installed from Tensorflow Website
TensorFlow version 14.1.0
Bazel version N/A
CUDA/cuDNN version N/A
GPU model and memory GeForce 940MX
Exact command to reproduce: see link"
15250,Batch Norm variance output mismatches with tf 1.4.0,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from  binary**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  2.7.0
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0/5.0
- **GPU model and memory**: GTX1080 and 8 GB
- **Exact command to reproduce**: python test_google_bn.py

### Describe the problem
Batch normalization test failed with tensorflow version 1.4.0 but the same test passed with tensorflow version 1.3.0. 


### Source code / logs
```Python
# test_google_bn.py
import numpy as np
import pytest
import tensorflow as tf
from numpy.testing import assert_array_almost_equal
from tensorflow.python.ops import control_flow_ops
def test_delayed_update_moving_vars():
    with tf.Session() as sess:
        height, width = 3, 3
        image_shape = (10, height, width, 3)
        image_values = np.random.rand(*image_shape)
        expected_mean = np.mean(image_values, axis=(0, 1, 2))
        expected_var = np.var(image_values, axis=(0, 1, 2))
        images = tf.constant(image_values, shape=image_shape, dtype=tf.float32)
        decay = 0.1
        epsilon = 1e-5
        output = tf.contrib.layers.batch_norm(images, is_training=True, reuse=None, decay=decay, epsilon=epsilon,
                            updates_collections=tf.GraphKeys.UPDATE_OPS, name='BatchNorm')
        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
        # updates_ops are added to UPDATE_OPS collection.
        assert len(update_ops) == 2
        with tf.control_dependencies(update_ops):
            barrier = tf.no_op(name='barrier')
        output = control_flow_ops.with_dependencies([barrier], output)
        # Initialize all variables
        sess.run(tf.global_variables_initializer())
        moving_mean = tf.contrib.framework.get_variables('BatchNorm/moving_mean')[0]
        moving_variance = tf.contrib.framework.get_variables('BatchNorm/moving_variance')[0]
        mean, variance = sess.run([moving_mean, moving_variance])
        # After initialization moving_mean == 0 and moving_variance == 1.
        assert_array_almost_equal(mean, [0] * 3)
        assert_array_almost_equal(variance, [1] * 3)
        for _ in range(10):
            sess.run([output])
        mean = moving_mean.eval()
        variance = moving_variance.eval()
        # After 10 updates with decay 0.1 moving_mean == expected_mean and
        # moving_variance == expected_var.
        assert_array_almost_equal(mean, expected_mean, decimal=4)
        assert_array_almost_equal(variance, expected_var, decimal=4)
```

>           assert_array_almost_equal(variance, expected_var, decimal=4)
           AssertionError: 
           Arrays are not almost equal to 4 decimals
           
           (mismatch 100.0%)
            x: array([ 0.08  ,  0.0908,  0.0773], dtype=float32)
            y: array([ 0.0792,  0.0898,  0.0764])


"
15246,Error while running Tensor-Flow examples using Bazel build,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Ubuntu 16.04:
- **TensorFlow installed from source:
- **TensorFlow version 1.4.0:
- **Python 3.5.2: 
- **Bazel version 0.8.1:
- gcc version 5.4.1:
- CUDA/cuDNN version:
- GeForce GTX 980M  and 8GB:
- bazel build tensorflow/examples/label_image/...:



I am trying to run this by using the command bazel build tensorflow/examples/label_image/...
but i am getting the following error:

```
In file included from ./tensorflow/core/platform/default/logging.h:24:0,
                 from ./tensorflow/core/platform/logging.h:25,
                 from ./tensorflow/core/lib/core/status.h:25,
                 from ./tensorflow/core/kernels/range_sampler.h:21,
                 from tensorflow/core/kernels/range_sampler.cc:16:
./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_LEImpl(const T1&, const T2&, const char*) [with T1 = long unsigned int; T2 = long long int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
tensorflow/core/kernels/range_sampler.cc:86:5:   required from here
./tensorflow/core/platform/default/logging.h:230:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )
                                   ^
./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (x)
                             ^
./tensorflow/core/platform/default/logging.h:230:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'
 TF_DEFINE_CHECK_OP_IMPL(Check_LE, <= )
 ^
./tensorflow/core/platform/default/logging.h: In instantiation of 'std::__cxx11::string* tensorflow::internal::Check_EQImpl(const T1&, const T2&, const char*) [with T1 = long long int; T2 = long unsigned int; std::__cxx11::string = std::__cxx11::basic_string<char>]':
tensorflow/core/kernels/range_sampler.cc:244:3:   required from here
./tensorflow/core/platform/default/logging.h:228:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
                         == )  // Compilation error with CHECK_EQ(NULL, x)?
                         ^
./tensorflow/core/platform/macros.h:79:29: note: in definition of macro 'TF_PREDICT_TRUE'
 #define TF_PREDICT_TRUE(x) (x)
                             ^
./tensorflow/core/platform/default/logging.h:227:1: note: in expansion of macro 'TF_DEFINE_CHECK_OP_IMPL'
 TF_DEFINE_CHECK_OP_IMPL(Check_EQ,
 ^
ERROR: /home/hassaan/Downloads/tensorflow/tensorflow/core/BUILD:1739:1: C++ compilation of rule '//tensorflow/core:framework_internal_impl' failed (Exit 1)
In file included from ./tensorflow/core/framework/allocator.h:23:0,
                 from ./tensorflow/core/framework/tensor.h:20,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
./tensorflow/core/framework/numeric_types.h: In constructor 'tensorflow::bfloat16::bfloat16(float)':
./tensorflow/core/framework/numeric_types.h:49:16: error: 'isnan' was not declared in this scope
     if (isnan(v)) {
                ^
./tensorflow/core/framework/numeric_types.h:49:16: note: suggested alternatives:
In file included from /usr/include/c++/5/complex:44:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:99,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
/usr/include/c++/5/cmath:641:5: note:   'std::isnan'
     isnan(_Tp __x)
     ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:558:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GlobalFunctions.h:88:3: note:   'Eigen::isnan'
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(isnan,scalar_isnan_op,not-a-number test,\sa Eigen::isinf DOXCOMMA Eigen::isfinite DOXCOMMA ArrayBase::isnan)
   ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:392:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h:1111:46: note:   'Eigen::numext::isnan'
 template<typename T> EIGEN_DEVICE_FUNC bool (isnan)   (const T &x) { return internal::isnan_impl(x); }
                                              ^
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:433:0,
                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/tensor.h:19,
                 from ./tensorflow/core/util/strided_slice_op.h:18,
                 from tensorflow/core/util/strided_slice_op.cc:16:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/Half.h:380:45: note:   'Eigen::half_impl::isnan'
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool (isnan)(const half& a) {
```"
15242,Error using alexnet with Faster-RCNN?,"Hi everyone, 
I am doing object categories detection on COCO dataset using transfer learning (alexnet as a pre-trained with Faster RCNN). However, I am getting this error.

> Warning: An error occurred while using @(x)d.propose(x,minBoxSize,'MiniBatchSize',miniBatchSize) to process
> /train2014/COCO_train2014_000000256230.jpg:
> Expected input number 2, score, to be of size Mx1, but it is of size 0x0.
> Regions from this image will not be used for training. 
> In fastRCNNObjectDetector.invokeRegionProposalFcn (line 268)
  In fastRCNNObjectDetector>@(x,filename)fastRCNNObjectDetector.invokeRegionProposalFcn(fcnCopy,x,filename) (line 158)
  In fastRCNNObjectDetector.extractRegionProposals (line 218)
  In fastRCNNObjectDetector.train (line 168)
  In trainFasterRCNNObjectDetector (line 359)
  In detection (line 75)


**Can you please help me? 
Please have a look at the code, and let me know if there is any mistake?

Thank you very much for your help and time in advance**

P.S. training data (annotation) is stored in a table, where the first column contains paths and file names to images. The remaining columns contain bounding boxes related to the corresponding images. Each column represents a single object class, such as a person, bicycle, car … etc, as explained on https://uk.mathworks.com/help/vision/ref/trainfasterrcnnobjectdetector.html.

     ‘clear all
    close all
    clc
    Train_data= load('************.mat'); %Load vehicle data set
    addpath('************'); % path of the training images
    numClasses = width(Train_data);
    Train_data(1:3,:)% Display first few rows of the data set.
    I = imread(Train_data.imageFilename{6}); % display one of the images with the bbox, 
    I = insertShape(I, 'Rectangle', Train_data.person{6});
    I = imresize(I, 3);
    figure
    imshow(I)
    net = alexnet; % loading pre-trained model (alexnet in this case)
    net.Layers
    layersTransfer = net.Layers(1:end-3);
    layers = [
        layersTransfer
        fullyConnectedLayer(numClasses,'WeightLearnRateFactor',20,'BiasLearnRateFactor',20)
        softmaxLayer
        classificationLayer];
    optionsStage1 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-5);% Options for step 1.
    optionsStage2 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-5);% Options for step 2.
    optionsStage3 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-6); % Options for step 3.
    optionsStage4 = trainingOptions('sgdm', ...
        'MaxEpochs', 10, ...
        'InitialLearnRate', 1e-6);% Options for step 4.
    options = [
        optionsStage1
        optionsStage2
        optionsStage3
        optionsStage4
        ];
    doTrainingAndEval = true; % Training network 
    if doTrainingAndEval
        rng(0);
        detector = trainFasterRCNNObjectDetector(Train_data, layers, options, ...
            'NegativeOverlapRange', [0 0.3], ...
            'PositiveOverlapRange', [0.6 1], ...
            'BoxPyramidScale', 1.2);
    else
        detector=load('*********.mat').
    end
    Test_data= load('************.mat');% tesing and evaluation  
    addpath('************'); % path of the testing image
    Test_data.imageFilename =Test_data.imageFilename;
    I = imread(Test_data.imageFilename{452}); % Read one of the images.
     [bboxes, scores,label] = detect(detector, I);% Run the detector.
    I = insertObjectAnnotation(I, 'rectangle', bboxes, scores);% Annotate detections in the image.
    figure
    imshow(I)
    if doTrainingAndEval
            resultsStruct = struct([]); % Run detector on each image in the test set and collect results.
        for i = 1:height(Test_data)
             I = imread(Test_data.imageFilename{i});        % Read the image.
            [bboxes, scores, labels] = detect(detector, I);        % Run the detector.
            resultsStruct(i).Boxes = bboxes;        % Collect the results.
            resultsStruct(i).Scores = scores;
           resultsStruct(i).Labels = labels;
       end
         results = struct2table(resultsStruct);    % Convert the results into a table.
    else
        results = data.results;    % Load results from disk.
    end
    expectedResults = testData(:, 2:end); % Extract expected bounding box locations from test data.
     [ap, recall, precision] = evaluateDetectionPrecision(results, expectedResults);% Evaluate the    object detector using Average Precision metric.
    figure;% Plot precision/recall curve
    plot(recall, precision)
    xlabel('Recall')
    ylabel('Precision')
    grid on
    title(sprintf('Average Precision = %.1f', ap))’

  


Have I written custom code: I did the code, following the instructions available on matlab both Faster RCNN detection, and transfer learning webpages (https://uk.mathworks.com/help/vision/examples/object-detection-using-faster-r-cnn-deep-learning.html) and (https://uk.mathworks.com/help/nnet/ug/pretrained-convolutional-neural-networks.html#bvm8b5x) respectively  
OS Platform and Distribution: Linux, MATLAB2017a
CUDA/cuDNN version: 8.0, V8.0.44
GPU model and memory: NVIDIA Tesla K80
"
15241,Error using Faster RCNN in MATLAB. ,"Hi there, 
I am working on a project that is about detecting multiple object classes (object classes detection), where the dataset that I am using is MSCOCO (2014). 
The method that I am using is Faster RCNN detection method, where I am using matlab 2017a
Please note that all training is done on a machine with a GPU (NVIDIA Tesla K80)
I have wrote the code attached in the zipped file, dropbox link for downloading is presented below. I have done this code by following the instructions available on matlab transfer learning page; it is about using alexnet as a pre-trained mode for Faster RCNN. Can you kindly have a look at the code and let me know, it has any errors, because I am getting an error when doing the evaluation  
Error is:  
Error using fasterRCNNObjectDetector/parseDetectInputs (line 680)
The size of I must be larger than [227 227]. The minimum size is defined by the network's image input layer.
Error in fasterRCNNObjectDetector/detect (line 447)
            params = this.parseDetectInputs(I, varargin{:});
I have resized the image to [400 400], which passed this errors, but still have another error with plotting the accuracy, IF I use less than 400 (e.g., [300 300]), the error will still appear, which I am not sure why, because alexnet input layer is in the size of [227 227], where 300 is still larger than. 
Error is: I am getting all the average precision (ap), recall values as zeros (0). 

To download the code and all materials: https://www.dropbox.com/sh/9u56ragkuz1ltgd/AADKvUXESezWsoaGfgLyE0Exa?dl=0 
Please note the zipped file contains: 
1) the training (transfer learning) code, named as run_20_classes.m
2) .mat file,  named as pre-trained_20_classes.mat that contains the training and testing labels (annotations), stored as a table, where the first column contains paths and file names to images. The remaining columns contain bounding boxes related to the corresponding images. Each column represents a single object class, such as a person, bicycle, car … etc, as explain on https://uk.mathworks.com/help/vision/ref/trainfasterrcnnobjectdetector.html. This mat file also includes the results of detection, saved as detector  the evaluation results.
3) testing code, named as Testing.m

Training images can be downloaded from: http://images.cocodataset.org/zips/train2014.zip 
Testing images can be downloaded from: http://images.cocodataset.org/zips/val2014.zip 

**Can you please help me on how to improve the accuracy, or if my code is mistaken, can you please correct it?**
Thank you very much for your help and time in advance 


Have I written custom code: I did the code, following the instructions available on matlab both Faster RCNN detection, and transfer learning webpages (https://uk.mathworks.com/help/vision/examples/object-detection-using-faster-r-cnn-deep-learning.html) and (https://uk.mathworks.com/help/nnet/ug/pretrained-convolutional-neural-networks.html#bvm8b5x) respectively
OS Platform and Distribution: Linux, MATLAB2017a
CUDA/cuDNN version: 8.0, V8.0.44
GPU model and memory: NVIDIA Tesla K80
Exact command to reproduce: training code (run_20_classes.m), testing (Testing.m)"
15240,"in minimize     ([str(v) for _, v in grads_and_vars], loss)) ValueError: No gradients provided for any variable - This error occurs while using minimize for an adam optimizer()","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15239,No gradient defined for op: Pow,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4
- **Bazel version**: N/A
- **Python version**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: -

### Describe the problem
It seems there is no gradient defined for the Pow operation in the C++ API.

I am actually transferring this issue from https://github.com/migueldeicaza/TensorFlowSharp/issues/187. Similar to the case of Select (#14845), it seems there is also no gradient for the Pow operation in the C++ API."
15238,CPU usage drops after several steps,"I am running a tensorflow computation graph. The same graph was running fine before but all of a sudden I noticed that after several steps and checkpoint the CPU usage drops from more than 600% to 100% for the rest of the session. It seems like all executors are dying (when saving maybe) and the computation keeps running on only 1 Core shooting up and down from 100 to 200%.

I also posted the issue on stack overflow: https://stackoverflow.com/questions/47720893/tensor-flow-cpu-usage-drops-after-saving

  "
15237,"[Feature Request]Add SGDR, SGDW, AdamW and AdamWR","This is a duplicate request from pytorch issue, which I even reuse their issue title
https://github.com/pytorch/pytorch/issues/3790

And the fix from the paper seems to be trivial but I'm not sure how TF should approach this, perhaps just adding another parameter?"
15236,"Error while using cuda-9.0, libcublas.so.8.0: cannot open shared object file: No such file or directory","Hi,

I just installed cuda-9.0
and done all the requirements for cuda to run tensorflow like libcudnn7_7.0.5.15-1+cuda9.0_amd64.deb, libcudnn7-dev_7.0.5.15-1+cuda9.0_amd64.deb.
The test example of libcudnn are working fine.

I installed tensorflow-gpu, it finished normally while using ""$ sudo pip3 install tensorflow-gpu"" but at the time of import, it gives me  error "" 
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory""
Look like tensorflow doesn't support Cuda-9.0?

Error is as follows:

$ ipython
Python 3.5.2 (default, Nov 23 2017, 16:37:01) 
Type 'copyright', 'credits' or 'license' for more information
IPython 6.2.1 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py in <module>()
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

/usr/lib/python3.5/imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

/usr/lib/python3.5/imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>()
----> 1 import tensorflow as tf

/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py in <module>()
     22 
     23 # pylint: disable=wildcard-import
---> 24 from tensorflow.python import *
     25 # pylint: enable=wildcard-import
     26 

/usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py in <module>()
     47 import numpy as np
     48 
---> 49 from tensorflow.python import pywrap_tensorflow
     50 
     51 # Protocol buffers

/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py in <module>()
     70 for some common reasons and solutions.  Include the entire stack trace
     71 above this error message when asking for help."""""" % traceback.format_exc()
---> 72   raise ImportError(msg)
     73 
     74 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.



Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: No use pip install tensorflow
- **TensorFlow version (use command below)**: tensorflow_gpu-1.4.1-cp35-cp35m-manylinux1_x86_64.whl 
- **Python version**:  Python 3.5.2 (default, Nov 23 2017, 16:37:01)
- **Bazel version (if compiling from source)**:No
- **GCC/Compiler version (if compiling from source)**: No
- **CUDA/cuDNN version**:  cuda-9.0
- **GPU model and memory**: GeForce GT 750M
- **Exact command to reproduce**: No just import tensorflow as tf
                                                         
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15235,Loss should change depending on the number of epochs chosen even if I set the seed?,"Hi colleagues,

I am using Keras to train different NNs. I would like to know why if I increment the epochs, the result until the same number of epochs is not the same for the evolution of loss. I am using shuffle=False, and np.random.seed(2017), tf.set_random_seed(2017), and I have check that if I repeat with the same number of epochs, the result is the same, so the random initialization is working. After the epochs training, I am deleting the ANN so the training begins at 0 again.

Here I attach the picture of the resulting training with 10 epochs:

<img width=""676"" alt=""captura de pantalla 2017-12-09 a las 15 02 25"" src=""https://user-images.githubusercontent.com/23745991/33796312-05efe5da-dcf2-11e7-9780-09e0be902557.png"">

And here I attach the picture of the resulting training with 8 epochs:

<img width=""679"" alt=""captura de pantalla 2017-12-09 a las 15 02 34"" src=""https://user-images.githubusercontent.com/23745991/33796313-106a6b34-dcf2-11e7-820c-e5d279665785.png"">

Also, I would like to know why the training time is not exactly (8/10) the 10 epochs attempt and how is it possible that some of them have less accuracy with 2 more epochs!

Here is the link to open code Jupyter Notebook. [GitHub Jupyter Notebook - ANN Comparison](https://github.com/PabloRR100/Pruning-Algorithm-Method/blob/master/NN-Comparison.ipynb)

Thanks a lot!"
15232,"Install new TensorFlow via anaconda, but failed","Hello,

When I tried to install TensorFlow via anaconda.
I`ve searched the suitable cite to submit the issue, but failed to find out it.
If this is not sorry for it and advice me.

The target os is 'windows 10', and via anaconda 5.0.1 For Windows (Python 3.6 version 64bit).
After intall anaconda, from my terminal 'cmd.exe',
$ conda create -n tensorflow python=3.6
but received an error message.

But from 'Anaconda Prompt' below 'Anaconda3' of 'start button',it works correctly.

Thus I recommend to include the following description,
start 'Anaconda Prompt' below 'Anaconda3' of 'start button' between the steps."
15231,tensorboard doesn't show my graph,"In the morning I can use the following command to open my graph. 
`tensorboard --logdir=graph_file_dir`

However, in the evening, I use another PC, I can't see my graph any more. 
Error Information is 
![image](https://user-images.githubusercontent.com/4633426/33793649-ff2545c4-dc6f-11e7-8719-50c8ea543c3a.png)

Then, I tried to use the following command to inspect the content. 
![image](https://user-images.githubusercontent.com/4633426/33793657-1f43ab34-dc70-11e7-9c8b-84dc97190b85.png)

I know there is only one top node in my graph called ""import"". Could any one help me to diagnose what could be the issue? Thanks in advance. 
"
15230,tensorflow-gpu on mac,"I can use the following to install tensorflow on mac.

Python 2

~~~
pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.0-py2-none-any.whl
~~~

Python 3

~~~
pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.0-py3-none-any.whl
~~~

But I don't find the correponding files for tensorflow-gpu. Can it be generated and posted over there? Thanks.
"
15228,"Bug in XLA, if branches optimized by grappler/arithmetic_optimizer","grappler/arithmetic_optimizer may merge different Const op with same value into one. However, if two Const ops are in different branches (tf.cond, or SwitchOp, user-defined SwitchOp things), XLA will make them into one cluster, which would cause this XlaLaunchOp can't be run forever.

One way to walk around this is to disable arithmetic_optimizer."
15223,stdin,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15222,tfcompile error - no matching function for call to 'transform',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.  This is on a clean checkout of tensorflow.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  OSX Sierra
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: building from master (command outputs 1.3.0)
- **Python version**:  2.7
- **Bazel version (if compiling from source)**:  0.6.0
- **GCC/Compiler version (if compiling from source)**: 
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 9.0.0 (clang-900.0.38)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
- **CUDA/cuDNN version**: N/A (ran ./configure without CUDA)
- **GPU model and memory**: N/A (no GPU)
- **Exact command to reproduce**:
1. Check out tensorflow
2. Run ./configure, enable XLA support
3. cd tensorflow/compiler/aot
4.  bazel build :tfcompile

### Describe the problem
```
ERROR: /Users/mattrunchey/gitrepos/tensorflow/tensorflow/compiler/xla/service/llvm_ir/BUILD:171:1: C++ compilation of rule '//tensorflow/compiler/xla/service/llvm_ir:kernel_support_library' failed (Exit 1).
tensorflow/compiler/xla/service/llvm_ir/kernel_support_library.cc:101:5: error: no matching function for call to 'transform'
    std::transform(function->arg_begin(), function->arg_end(),
    ^~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1922:1: note: candidate template ignored: couldn't infer template argument '_UnaryOperation'
transform(_InputIterator __first, _InputIterator __last, _OutputIterator __result, _UnaryOperation __op)
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1932:1: note: candidate function template not viable: requires 5 arguments, but 4 were provided
transform(_InputIterator1 __first1, _InputIterator1 __last1, _InputIterator2 __first2,
^
1 error generated.
```
This happens across multiple OSes, as well (we tried to compile on a unix distro with the same error).  

### Source code / logs
This seems to stem from a recent change in kernel_support_library.cc (specifically https://github.com/tensorflow/tensorflow/commit/c572bc4fd7c73f4b8014ae43cdf9da5b99592f59#diff-877daea43ebeb1cd4756f960400ee922 ).  "
15221,Dataset.from_generator doesn't support strings,"I have hit the same problem described in https://stackoverflow.com/questions/47705684/tesnorflow-dataset-generator-does-not-work-with-strings

I think it is a missing feature instead of a bug?"
15220,ResidualWrapper and HighwayWrapper require rnn inputs' last dimension to be equal to num_units,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: -
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**:  v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: - 
- **GPU model and memory**: - 
- **Exact command to reproduce**:
~~~python
from tensorflow.contrib import rnn as rnn_cell
from tensorflow.python.ops import rnn
import tensorflow as tf

rnn_inputs = tf.random_uniform([10, 10, 10])
cell = rnn_cell.LSTMCell(128)
cell = rnn_cell.HighwayWrapper(cell) # rnn_cell.ResidualWrapper(cell)
_, _ = rnn.dynamic_rnn(cell, rnn_inputs, dtype=tf.float32)
~~~

### Problem
`rnn_cell.ResidualWrapper` and `rnn_cell.HighwayWrapper` throw an exception when rnn inputs' last dimension is not equal to `num_units`. Without wrappers, the input tensor can be different from `num_units`.
What's the reason for the different behaviour? Is it intended?

### Full Traceback
https://pastebin.com/YvTb3WM3"
15219,tf.while_loop and tf.foldl do not support second order gradients,"The example
```python
import tensorflow as tf
x = tf.Variable(1.)
A = tf.Variable(tf.ones((3,3))) 
cost = tf.trace(tf.foldl(tf.matmul,tf.stack([x*A for _ in range(3)])))
tf.gradients(tf.gradients(cost, A), x)  
# TypeError: Second-order gradient for while loops not supported.
```
illustrates that despite applying `tf.foldl` to a static list, the internal implementation via while loops leads to a type error. The problem disappears if the fold operation is carried out manually using a for loop. While implementing `foldl` using the while loop clearly makes the operation  more widely applicable, it seems problematic if syntactic sugar can lead to code that has qualitative differences from a naive implementation using a static loop. I cannot help but wonder whether `foldl` could be more efficient in the static case as well, although that is more of a conjecture.

I think it would be nice if `foldl` (and other while loop derivatives) had a keyword that enabled or disabled the ""dynamic mode"" using while, or if, at the very least, the TypeError would occur at the `foldl`operation so that the error is easier to trace.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Custom code.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**:
pip install.
- **TensorFlow version (use command below)**:
v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**:
3.5.4 
- **Bazel version (if compiling from source)**:
Not applicable.
- **GCC/Compiler version (if compiling from source)**:
Not applicable.
- **CUDA/cuDNN version**:
Did not use CUDA.
- **GPU model and memory**:
Did not use GPU.
- **Exact command to reproduce**:
```python
import tensorflow as tf
x = tf.Variable(1.)
A = tf.Variable(tf.ones((3,3))) 
cost = tf.trace(tf.foldl(tf.matmul,tf.stack([x*A for _ in range(3)])))
tf.gradients(tf.gradients(cost, A), x)  
# TypeError: Second-order gradient for while loops not supported.
```"
15218,stupid question but please help me to answer this,"I have a problem with parallel computing. I know that CUDA or pyCUDA can do such thing like 3D convolution in parallel. 
I think about using tensorflow GPU by calling tf.nn.conv3d(input, filter), does it uses build in functions in CUDA to operate 3D convolution with parallel computing or there are somethings else? 
I am not familiar with C++ or even with pyCuda I am not sure how to implement 3D convolution with it.

Same question with all type of other implement with tensorflow GPU.

Bests,   "
15216,"When data become large,parition variables can not initialized successfully","i use tensorflow to distributed trainning models,  i use the partition valriables to store an array data, when the data is not so bigger, everything looks ok,but when the array data become larger, when the session initialize, the partition variables can not  initialized and the session will wait util time out.
### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. the feat_info can initialize successfully, but the adj_info cannot initialized. the adj_info is larger than feat_info
### Source code / logs
i use ps_num = 4, worker_num =4 and i also try some other distributed config, like ps_num=1, worker_num=4, the result is the same
source code:
    with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % task_id,
        cluster=cluster_spec)):
      
      feat_info = tf.get_variable(""feature_info"", (len(id_map),FLAGS.features_column), tf.float32, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))
      adj_info = tf.get_variable(""adj_info"", (len(id_map),FLAGS.max_degree), tf.int64, trainable=False, partitioner=tf.fixed_size_partitioner(num_workers))
     
      with tf.device('/job:worker/task:%d' %task_id):
          adj_local = tf.Variable(tf.constant(minibatch.adj, dtype=tf.int64), trainable=False, name=""adj_local"", collections=[tf.GraphKeys.LOCAL_VARIABLES])
          feat_local = tf.Variable(tf.constant(features, dtype=tf.float32), trainable=False, name=""feat_local"", collections=[tf.GraphKeys.LOCAL_VARIABLES])
     
      length, begin, end = split_node_by_task(len(id_map), task_id, num_workers)
      adj = tf.nn.embedding_lookup(adj_info, [x for x in range(begin, end)])
      adj = adj_local
      
      feat = tf.nn.embedding_lookup(feat_info, [x for x in range(begin, end)])
      feat = feat_local

log:
2017-12-08 23:54:17.377290: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session c2b3ba9b700261ba with config: 
INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15
2017-12-09 00:00:35.637019: I tensorflow/core/distributed_runtime/master_session.cc:998] Start master session f35fcf332e3908ec with config: 
INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: adj_info/part_0, adj_info/part_1, adj_info/part_2, adj_info/part_3, adj_info/part_4, adj_info/part_5, adj_info/part_6, adj_info/part_7, adj_info/part_8, adj_info/part_9, adj_info/part_10, adj_info/part_11, adj_info/part_12, adj_info/part_13, adj_info/part_14, adj_info/part_15
and it will alway waiting adj_info to initialize"
15215,Tensorflow - Unable to import frozen graph with batchnorm : uninitialized value batch_normalization/moving_mean,"I am trying to freeze in a pbtxt file a checkpoint containing batchnorm layers (ubuntu, python 2.7, tf 1.1.0).

context : 
**Have I written custom code**
Yes, see below

**OS Platform and Distribution**
Docker with Ubuntu 14.04

**TensorFlow installed from**
pip installer

**TensorFlow version**
tensorflow and tensorflow-gpu 1.1.0

**Bazel version**
N/A

**CUDA/cuDNN version**
Cuda 8, CUDNN 5.1

**GPU model and memory**
Nvidia titan-x * 2, 12Go Ram each

**Exact command to reproduce**

For this, following these posts and issues :

https://github.com/davidsandberg/facenet/issues/161

https://github.com/davidsandberg/facenet/pull/172/commits/0f3ece502550714c91056f3a8630ce8c037f613f

I use this function:

    freeze_and_prune_graph(model_path_and_name, output_file=None):
		""""""
		freezes a model trained and saved by the trainer by :
		    - extracting the trainable variables between input_node and output_node
		    - turning them to constants
		    - changing the 1rst dim of input_node to None
		    -saving the resulting graph as a single .pb file

		:param model_path_and_name: must finish by .ckpt, and the checkpoint must be composed of
		3+ files : .ckpt.index, .ckpt.meta, and .ckpt.data-0000X-of-0000Y

		:param model_path_and_name: path to the trained model
		:param output_file: file to save to. If None, model_path_and_name.[-ckpt][+pb]
		:return: None
		""""""
		config_proto = tf.ConfigProto(allow_soft_placement=True)

		with tf.Session(config=config_proto) as sess:
		    new_saver = tf.train.import_meta_graph(model_path_and_name + '.meta', clear_devices=True)
		    tf.get_default_session().run(tf.global_variables_initializer())
		    tf.get_default_session().run(tf.local_variables_initializer())
		    new_saver.restore(sess, model_path_and_name)

		    # get graph definition
		    gd = sess.graph.as_graph_def()
		    # fix batch norm nodes
		    for node in gd.node:
		        if node.op == 'RefSwitch':
		            node.op = 'Switch'
		            for index in xrange(len(node.input)):
		                if 'moving_' in node.input[index]:
		                    node.input[index] = node.input[index] + '/read'
		        elif node.op == 'AssignSub':
		            node.op = 'Sub'
		            if 'use_locking' in node.attr: del node.attr['use_locking']
		        elif node.op == 'AssignAdd':
		            node.op = 'Add'
		            if 'use_locking' in node.attr: del node.attr['use_locking']

		    # tf.get_collection() returns a list. In this example we only want the
		    input_node = sess.graph.get_tensor_by_name('input_node:0')
		    new_shape = [None] + input_node.get_shape().as_list()[1:]

		    trainables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)
		    new_graph_def = tf.graph_util.convert_variables_to_constants(sess, gd, [""output_node""],
		                                                                 variable_names_whitelist=[t.name[:-2] for t in trainables] + ['output_node'])

		    for node in new_graph_def.node:
		        if node.name == 'input_node':
		            node.attr['shape'].CopyFrom(attr_value_pb2.AttrValue(shape=tf.TensorShape(new_shape).as_proto()))
		            break

		    with tf.gfile.GFile(output_file, ""wb"") as f:
		        f.write(new_graph_def.SerializeToString())
		    print(""{0} / {1} ops in the final graph."".format(len(new_graph_def.node), len(sess.graph.as_graph_def().node)))

This goes well and creates the pbtxt file with the following output :

> Converted 201 variables to const ops.
5287 / 41028 ops in the final graph.

I then try to load the pbtxt model using this function :

    def load_frozen_graph(frozen_graph_file):
	    """"""
	    loads a graph frozen via freeze_and_prune_graph and returns the graph, its input placeholder and output tensor

	    :param frozen_graph_file: .pb file to load
	    :return: tf.graph, tf.placeholder, tf.tensor
	    """"""
	    # We load the protobuf file from the disk and parse it to retrieve the
	    # unserialized graph_def
	    with tf.gfile.GFile(frozen_graph_file, ""rb"") as f:
	        graph_def = tf.GraphDef()
	        graph_def.ParseFromString(f.read())

	    # Then, we can use again a convenient built-in function to import a graph_def into the
	    # current default Graph
	    with tf.Graph().as_default() as graph:
	        tf.import_graph_def(
	            graph_def,
	            input_map=None,
	            return_elements=None,
	            name=""prefix"",
	            op_dict=None,
	            producer_op_list=None
	        )

	    input_images_placeholder = graph.get_tensor_by_name('prefix/input_node:0')
	    input_phase_placeholder = None
	    try:
	        input_phase_placeholder = graph.get_tensor_by_name('prefix/phase:0')
	    except KeyError:
	        pass
	    output = graph.get_tensor_by_name('prefix/output_node:0')

	    return graph, input_images_placeholder, input_phase_placeholder, output

using the following snippet:

    graph, input_images_placeholder, is_training_placeholder, output = load_frozen_graph(model_pbtxt)
	sess = tf.Session(config=tf_config, graph=graph)
	feed_dict = {input_images_placeholder: prepared_input}
	if is_training_placeholder is not None:
	    feed_dict[is_training_placeholder] = False
	ret = sess.run([output], feed_dict=feed_dict)

This, however, leads to the following error:

> FailedPreconditionError (see above for traceback): Attempting to use uninitialized value prefix/conv0/BatchNorm/batch_normalization/moving_mean
> [[Node: prefix/conv0/BatchNorm/batch_normalization/moving_mean/read = Identity[T=DT_FLOAT, _class=[""loc:@prefix/conv0/BatchNorm/batch_normalization/moving_mean""], _device=""/job:localhost/replica:0/task:0/gpu:0""](prefix/conv0/BatchNorm/batch_normalization/moving_mean)]]
	 [[Node: prefix/output_node/_381 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_2447_prefix/output_node"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Following the question :
https://stackoverflow.com/questions/36007883/tensorflow-attempting-to-use-uninitialized-value-in-variable-initialization
I tried initializing variables:

    graph, input_images_placeholder, is_training_placeholder, output = load_frozen_graph(model_pbtxt)
	sess = tf.Session(config=tf_config, graph=graph)
	init = [tf.global_variables_initializer(), tf.local_variables_initializer()]
	sess.run(init)

	feed_dict = {input_images_placeholder: prepared_input}
	if is_training_placeholder is not None:
	    feed_dict[is_training_placeholder] = False
	ret = sess.run([self.output], feed_dict=feed_dict)

This, however, changes the error to:

> ValueError: Fetch argument <tf.Operation 'init' type=NoOp> cannot be interpreted as a Tensor. 
(Operation name: ""init"" op: ""NoOp"" is not an element of this graph.)

which seems to show that there is no variable that needs to be initialized.

What am I missing ? How to I freeze and reload the relevant values of a batch_normalization layer ?

PS: I do realize that this might better be on stackoverflow, but I posted there first and got no answer in 2 weeks:
https://stackoverflow.com/questions/47434139/tensorflow-unable-to-import-frozen-graph-with-batchnorm-uninitialized-value"
15214,tf.profiler overrides shape_invariants in while_loop,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171120
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

``` python
import tensorflow as tf

a = tf.zeros((1,))
n = tf.constant(10.)
do_profile = True

_, b = tf.while_loop(
    lambda x, y: x[0] < n,
    lambda x, y: (x + 1, tf.concat((y, x), 0)),
    (a, tf.zeros((0,))),
    shape_invariants=(tf.TensorShape((1,)), tf.TensorShape((None,))))

with tf.Session() as sess:
    for _ in range(2):
        grads = tf.gradients(b, a)

        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
        run_metadata = tf.RunMetadata()
        print(sess.run((b, grads), options=run_options,
                       run_metadata=run_metadata))

        if do_profile:
            tf.profiler.profile(tf.get_default_graph(), run_meta=run_metadata)
```

If `do_profile=True`, this will give an error on the second pass through the for loop:
```
Traceback (most recent call last):
  File "".../tmp3.py"", line 15, in <module>
    grads = tf.gradients(b, a)
  File ""...\lib\site-packages\tensorflow\python\ops\gradients_impl.py"", line 638, in gradients
    % (op.name, i, t_in.shape, in_grad.shape))
ValueError: Incompatible shapes between op input and calculated input gradient.  Forward operation: while/Switch_1.  Input index: 0. Original input shape: (0,).  Calculated input gradient shape: (10,)
```

### Describe the problem

I believe this is caused by [this function](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/profiler/tfprof_logger.py#L37), which goes through the graph and fills in missing shapes from the `run_metadata`.  This modifies the graph in-place, so on the second pass through the for loop the loop variable that was intentionally defined with an unknown shape has been overwritten with the fixed shape from the last run.  This causes the shape mismatch error.
  "
15213,XLA/AOT Windows support,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: 0.8.0
- **GCC/Compiler version (if compiling from source)**: VS 2017 15.5
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A

Similar to #8310, but specifically about running `tfCompile` on Windows rather than Linux to produce `x86_64-windows-msvc` binaries.

XLA/AOT depends on LLVM which has excellent Windows support via CMake, but Bazel cannot interop with CMake. [llvm.BUILD](https://github.com/tensorflow/tensorflow/blob/master/third_party/llvm/llvm.BUILD) is auto-generated and the script to generate it is not open-sourced, this make it difficult for external contributor to make improvement. [tensorflow/compiler](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler) might not need too much changes as #9908 already addressed some of them.

One possible path is to let user to run CMake in host machine when invoking `configure.py`, then feed CMake generated files into custom script to generate `LLVM.BUILD`.

Note:

[Rumour has it](https://chromium-review.googlesource.com/c/chromium/src/+/753588) that there is a Google-internal tool called `tfNative` to generate `.h/.cpp` files instead of `.lib` binaries, though I suspect that even if the tool is open-sourced, it might not be immediately available for Windows developers."
15212,lookup.index_table_from_tensor() emits an error in eager mode when invoked more than once.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: +
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS
- **TensorFlow installed from (source or binary)**: tf-nightly
- **TensorFlow version (use command below)**: 1.5.0-dev20171206
- **Python version**: 3
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: -
- **GPU model and memory**: -
- **Exact command to reproduce**: 
~~~python
from tensorflow.python.ops import lookup_ops
import tensorflow.contrib.eager as tfe
tfe.enable_eager_execution()

inpt = ['1611', '1612', '1613', '1615', '1616', '1617', '1618', '1619', '1621']

a = lookup_ops.index_table_from_tensor(inpt, name='a')
b = lookup_ops.index_table_from_tensor(inpt, name='b')
~~~

### Problem
When the eager execution is enabled, the following error occurs:
~~~console
FailedPreconditionError: Table already initialized. [Op:InitializeTableV2] name: string_to_index/hash_table/string_to_index/hash_table//string_to_index/hash_table/table_init//
~~~

### Source code / logs
Full trace:
https://pastebin.com/GsKBjyV6

### Question
Is there a way to specify more than one lookup table (a `shared_name` or a special scope)?"
15211,Deep MNIST - exit code 139 (interrupted by signal 11: SIGSEGV),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I have copied all the code lines from the tutorial Deep MNIST for Experts manually into a python file.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch Linux, kernel: 4.13.12-1-ARCH
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.5
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})

### Describe the problem
I am trying to run the example code from the tutorial Deep MNIST for Experts by copying every line from the tutorial into a python file and running it. The first part of the script with the model with a single linear layer runs fine, but the second part with a multilayer convolutional network fails to run. When the last line of the script executes: `print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))` I get the following error: `Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)`. 

I tried to evaluate the accuracy with a batch of size 50 from the testing data instead of supplying mnist.test.images and mnist.test.labels and that worked fine.
I was directed here from Stackoverflow because this was believed to be a bug [(Stackoverflow question).](https://stackoverflow.com/questions/47640511/tensorflow-deep-mnist-exit-code-139)

### Source code / logs
I am unfamiliar with gdb so if I have missed to provide any relevant debugging output I'll try to add it if you can tell me how to get it.

[Source code](https://hastebin.com/ebidihiwey.py)
[Stackframe](https://hastebin.com/jukuzejira.cpp)
[Backtrace](https://hastebin.com/baqecavora.vbs)
"
15210,Incorrect Result from Add Function,"### System information

- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 16.04.3 LTS
- Bazel version: Not applicable 
- TensorFlow installed from binary
- TensorFlow version: 1.4.0
- Python version: 3.5.2
- CUDA/cuDNN version: 8.0 / 6.0 for CUDA 8.0
- GPU model and memory: GM107M [GeForce GTX 960M] 4GB
- Exact command to reproduce:

Here is a simple program to add: 

session = tf.Session()

a = tf.placeholder(tf.float32)
#print(""first"")
b = tf.placeholder(tf.float32)
#print(""second"")
result_node = tf.add(a,b)
#print(""starting"")
x = session.run(result_node, {a:2.0, b: 3.5})
print(x)

Output should be 5.5, while I am getting 2.0 on 2 machines

![screenshot from 2017-12-08 17-59-49](https://user-images.githubusercontent.com/19254286/33766026-af9682da-dc41-11e7-8f81-1ff054903deb.png)
![screenshot from 2017-12-08 18-00-21](https://user-images.githubusercontent.com/19254286/33766027-afd8aba6-dc41-11e7-9a85-02f2764a9d67.png)

"
15209,CMake: If/else statement in CMAKE_CACHE_ARGS breaks CMake build on Ubuntu 17.10,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 17.10.
- **TensorFlow installed from (source or binary)**: Source (CMake)
- **TensorFlow version (use command below)**: 2cfb088cf72b52c74a742d780cc5c4f93a74640e (tip of master at time of writing)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: 7.2.0
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: cmake ../../tensorflow/contrib/cmake && make

### Source code / logs
    [  1%] Performing build step for 'zlib'
    [ 40%] Built target zlibstatic
    [ 42%] Linking C shared library libz.so
    /usr/bin/ld: CMakeFiles/zlib.dir/deflate.o: relocation R_X86_64_PC32 against symbol `deflate' can not be used when making a shared object; recompile with -fPIC
    /usr/bin/ld: final link failed: Bad value
    collect2: error: ld returned 1 exit status

### Cause
In v1.4.0, you will find the argument `-DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON` given to  CMAKE_CACHE_ARGS for several external projects (png, zlip, sqlite etc). In master, this has been changed to 

	CMAKE_CACHE_ARGS
		if(tensorflow_ENABLE_POSITION_INDEPENDENT_CODE)
			-DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=ON
		else()
			-DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=OFF
		endif()

which yields the following init cache entries on my machine: 

	set(CMAKE_POSITION_INDEPENDENT_CODE ""ON;if;(;tensorflow_ENABLE_POSITION_INDEPENDENT_CODE;);else;(;)"" CACHE BOOL ""Initial cache"" FORCE)
	set(CMAKE_POSITION_INDEPENDENT_CODE ""OFF;endif;(;)"" CACHE BOOL ""Initial cache"" FORCE)

and the build fails because `CMAKE_POSITION_INDEPENDENT_CODE` ends up not being set to `ON`. I could imagine this breaks a lot of builds. Perhaps CMake behaves differently on Windows and therefore this has not been caught? Is there a reason for this change I am not aware of? 

### Solution
A possible solution is to not inline the if/else statement and instead use the argument

    -DCMAKE_POSITION_INDEPENDENT_CODE:BOOL=${tensorflow_ENABLE_POSITION_INDEPENDENT_CODE}

Are you interested in a PR?
"
15208,Eager bugs,"After I use eager to debug code, the default version of tf changed when I reusing ipython, and tf can not placement mode to GPU, but placed on CPU.

```
In [2]: tf.__version__
Out[2]: '1.5.0-dev20171201
```

In another environment, my code is work well and version is correct:
```
In [2]: tf.__version__
Out[2]: '1.4.0'
```
Code：
rerun the blew code more times.
```
# coding: utf-8
import tensorflow as tf
from  tensorflow.contrib.eager.python import tfe
tfe.enable_eager_execution()
from tensor2tensor.utils import input_fn_builder
from tensor2tensor.utils import trainer_utils
h = trainer_utils.create_hparams('blstm_bahdanau_attention_librispeech', 'data')
trainer_utils.add_problem_hparams(h, 'audio_librispeech_tokens30_en')
e = input_fn_builder.features_for_problem(h.problem_instances[0], h.problems[0], h, 'data', 1, tf.estimator.ModeKeys.TRAIN, 10)
```

OS Platform and Distribution
CentOS Linux 7 (Core)   4.4.77-1.el7.elrepo.x86_64

TensorFlow installed from
Instlled from Docker Hub

TensorFlow version
1.4.0

Bazel version
N/A

CUDA/cuDNN version
8.0

GPU model and memory
Titan XP

Exact command to reproduce
N/A"
15207,Feature request: automatically pick all defaults in ./configure,"Everytime a new configuration option is added my CI halts on the ./configure step as it's prompted for input. Instead of setting each flag could we have some `USE_DEFAULTS=1 ./configure` flag instead?

I assume the intention is to slowly move away from the shell script to something better (hence configure.py, I wager) but for now, when testing projects with the master release it would be very useful to be able to just pick all default options for the WORKSPACE without knowing about them."
15206,"Unusual memory allocation while running ""tf.assign""","### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from**: binary
- **TensorFlow version**: 1.4.0
- **Python version**: 2.7
- **Bazel version**: 0.8.1
- **CUDA/cuDNN version**: 8.0.61 / 6.0.21
- **GPU model and memory**: Tesla K80
- **Exact command to reproduce**: run the script attached below

### Describe the problem
In the minimal example below, I am observing an increase in RAM usage when calling `assign_new_values`. Strangely, the extend depends on the dataset size. 
I see no obvious connection between the dataset and the variables that get assigned. Commenting out either the iterator or the `sess.run(assign_op, ...)` prevents additional memory allocation.

How is this possible?

### Source code / logs
```python
import numpy as np
import tensorflow as tf

DATASET_SIZE = 1000000


def create_dataset():
    image_paths = tf.constant(DATASET_SIZE * ['image.jpg'])
    labels = tf.constant(DATASET_SIZE * [0])
    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))
    return dataset


def create_variables():
    for i in range(20):
       tf.get_variable('var_%d' % i, shape=[3, 3, 3, 32])


def create_assign_ops():
    for var in tf.global_variables():
        name = var.op.name
        placeholder = tf.placeholder(tf.float32, shape=var.shape, name=name + '/placeholder')
        tf.assign(var, placeholder, name=name + '/assign_op')


def assign_new_values(sess):
    for var in tf.global_variables():
        name = var.op.name
        assign_op = tf.get_default_graph().get_tensor_by_name(name + '/assign_op:0')
        sess.run(assign_op, feed_dict={name + '/placeholder:0': np.random.random(var.shape)})


if __name__ == '__main__':
    with tf.Graph().as_default():
        with tf.device('/cpu:0'):
            dataset = create_dataset()
            iterator = dataset.make_one_shot_iterator()

        create_variables()
        create_assign_ops()

        with tf.Session() as sess:
            sess.run(tf.global_variables_initializer())
            # Check RAM usage before
            assign_new_values(sess)
            # Check RAM usage after

```
"
15204,compile error with config sycl,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:source
- **TensorFlow version (use command below)**:1.4,the latest version I git from tensorflow
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**:0.8.1
- **GCC/Compiler version (if compiling from source)**:5.4.0
- **CUDA/cuDNN version**:no
- **GPU model and memory**:no
- **Exact command to reproduce**:bazel build -c opt --config=sycl //tensorflow/tools/pip_package:build_pip_package


##something else
OpenCl version:1.2
computecpp path:    /usr/local/computecpp  version 0.5.0


computecpp_info:
Device Info:
Discovered 1 devices matching:
  platform    : <any>
  device type : <any>
--------------------------------------------------------------------------------
Device 0:
  Device is supported                     : UNTESTED - Vendor not tested on this OS
  CL_DEVICE_NAME                          : Hainan
  CL_DEVICE_VENDOR                        : Advanced Micro Devices, Inc.
  CL_DRIVER_VERSION                       : 2482.3
  CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_GPU 



clinfo:
Number of platforms                               1
  Platform Name                                   AMD Accelerated Parallel Processing
  Platform Vendor                                 Advanced Micro Devices, Inc.
  Platform Version                                OpenCL 2.0 AMD-APP (2482.3)
  Platform Profile                                FULL_PROFILE
  Platform Extensions                             cl_khr_icd cl_amd_event_callback cl_amd_offline_devices 
  Platform Extensions function suffix             AMD

  Platform Name                                   AMD Accelerated Parallel Processing
Number of devices                                 1
  Device Name                                     Hainan
  Device Vendor                                   Advanced Micro Devices, Inc.
  Device Vendor ID                                0x1002
  Device Version                                  OpenCL 1.2 AMD-APP (2482.3)
  Driver Version                                  2482.3
  Device OpenCL C Version                         OpenCL C 1.2 
  Device Type                                     GPU
  Device Profile                                  FULL_PROFILE
  Device Board Name (AMD)                         AMD Radeon HD 8500M
  Device Topology (AMD)                           PCI-E, 04:00.0
  Max compute units                               4
  SIMD per compute unit (AMD)                     4
  SIMD width (AMD)                                16
  SIMD instruction width (AMD)                    1
  Max clock frequency                             850MHz
  Graphics IP (AMD)                               6.0
  Device Partition                                (core)
    Max number of sub-devices                     4
    Supported partition types                     none specified
  Max work item dimensions                        3
  Max work item sizes                             256x256x256
  Max work group size                             256
  Preferred work group size multiple              64
  Wavefront width (AMD)                           64
  Preferred / native vector sizes                 
    char                                                 4 / 4       
    short                                                2 / 2       
    int                                                  1 / 1       
    long                                                 1 / 1       
    half                                                 1 / 1        (n/a)
    float                                                1 / 1       
    double                                               1 / 1        (cl_khr_fp64)
  Half-precision Floating-point support           (n/a)
  Single-precision Floating-point support         (core)
    Denormals                                     No
    Infinity and NANs                             Yes
    Round to nearest                              Yes
    Round to zero                                 Yes
    Round to infinity                             Yes
    IEEE754-2008 fused multiply-add               Yes
    Support is emulated in software               No
    Correctly-rounded divide and sqrt operations  Yes
  Double-precision Floating-point support         (cl_khr_fp64)
    Denormals                                     Yes
    Infinity and NANs                             Yes
    Round to nearest                              Yes
    Round to zero                                 Yes
    Round to infinity                             Yes
    IEEE754-2008 fused multiply-add               Yes
    Support is emulated in software               No
    Correctly-rounded divide and sqrt operations  No
  Address bits                                    32, Little-Endian
  Global memory size                              2140311552 (1.993GiB)
  Global free memory (AMD)                        <printDeviceInfo:68: get number of CL_DEVICE_GLOBAL_FREE_MEMORY_AMD : error -33>
  Global memory channels (AMD)                    2
  Global memory banks per channel (AMD)           8
  Global memory bank width (AMD)                  256 bytes
  Error Correction support                        No
  Max memory allocation                           1591773593 (1.482GiB)
  Unified memory for Host and Device              No
  Minimum alignment for any data type             128 bytes
  Alignment of base address                       2048 bits (256 bytes)
  Global Memory cache type                        Read/Write
  Global Memory cache size                        16384
  Global Memory cache line                        64 bytes
  Image support                                   Yes
    Max number of samplers per kernel             16
    Max size for 1D images from buffer            134217728 pixels
    Max 1D or 2D image array size                 2048 images
    Base address alignment for 2D image buffers   256 bytes
    Pitch alignment for 2D image buffers          256 bytes
    Max 2D image size                             16384x16384 pixels
    Max 3D image size                             2048x2048x2048 pixels
    Max number of read image args                 128
    Max number of write image args                8
  Local memory type                               Local
  Local memory size                               32768 (32KiB)
  Local memory syze per CU (AMD)                  65536 (64KiB)
  Local memory banks (AMD)                        32
  Max constant buffer size                        65536 (64KiB)
  Max number of constant args                     8
  Max size of kernel argument                     1024
  Queue properties                                
    Out-of-order execution                        No
    Profiling                                     Yes
  Prefer user sync for interop                    Yes
  Profiling timer resolution                      1ns
  Profiling timer offset since Epoch (AMD)        1512650783761772748ns (Thu Dec  7 20:46:23 2017)
  Execution capabilities                          
    Run OpenCL kernels                            Yes
    Run native kernels                            No
    Thread trace supported (AMD)                  No
    SPIR versions                                 1.2
  printf() buffer size                            1048576 (1024KiB)
  Built-in kernels                                
  Device Available                                Yes
  Compiler Available                              Yes
  Linker Available                                Yes
  Device Extensions                               cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_image2d_from_buffer cl_khr_spir cl_khr_gl_event 

NULL platform behavior
  clGetPlatformInfo(NULL, CL_PLATFORM_NAME, ...)  AMD Accelerated Parallel Processing
  clGetDeviceIDs(NULL, CL_DEVICE_TYPE_ALL, ...)   Success [AMD]
  clCreateContext(NULL, ...) [default]            Success [AMD]
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CPU)  No devices found in platform
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU)  Success (1)
    Platform Name                                 AMD Accelerated Parallel Processing
    Device Name                                   Hainan
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ACCELERATOR)  No devices found in platform
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CUSTOM)  No devices found in platform
  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ALL)  Success (1)
    Platform Name                                 AMD Accelerated Parallel Processing
    Device Name                                   Hainan

ICD loader properties
  ICD loader Name                                 OpenCL ICD Loader
  ICD loader Vendor                               OCL Icd free software
  ICD loader Version                              2.2.8
  ICD loader Profile                              OpenCL 1.2
	NOTE:	your OpenCL library declares to support OpenCL 1.2,
		but it seems to support up to OpenCL 2.1 too.

### Describe the problem
I want Compile With sycl config  with the command 
bazel build -c opt --config=sycl //tensorflow/tools/pip_package:build_pip_package
 but  unfortunately get the error 

Illegal ambiguous match on configurable attribute ""deps"" in @local_config_sycl//sycl:sycl:
@local_config_sycl//sycl:using_sycl_ccpp
@local_config_sycl//sycl:using_sycl_trisycl
Multiple matches are not allowed unless one is unambiguously more specialized.

I did not know what casue this compile error. Please Help

"
15203,DataLossError : Checksum does not match,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:windows 7 professional,64bit
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.3.0
- **Python version**: 3.6.2
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**:N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**:N/A

### Describe the problem
I trained on Ubuntu16.04 to get the model, and then restore the model on  Windows7 Professional, but it occured such a mistake:

`DataLossError (see above for traceback): Checksum does not match: stored 1713499277 vs. calculated on the restored bytes 1894941567`

`[Node: save/RestoreV2_282 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""]]`

**Both machines have the same version of python and TensorFlow, and the model tested in another machine succeed, but this machine failed**, how to solve it? Thank you!

### Source code / logs

```
Traceback (most recent call last):
  File ""D:/tensorboxPy3/evaluate.py"", line 138, in <module>
    main()
  File ""D:/tensorboxPy3/evaluate.py"", line 117, in main
    get_results(args, H, os.path.dirname(args.datadir))
  File ""D:/tensorboxPy3/evaluate.py"", line 59, in get_results
    saver.restore(sess, args.weights)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 1560, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 895, in run
    run_metadata_ptr)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DataLossError: Checksum does not match: stored 1713499277 vs. calculated on the restored bytes 1894941567
	 [[Node: save/RestoreV2_282 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save/Const_0_0, save/RestoreV2_282/tensor_names, save/RestoreV2_282/shape_and_slices)]]

Caused by op 'save/RestoreV2_282', defined at:
  File ""D:/tensorboxPy3/evaluate.py"", line 138, in <module>
    main()
  File ""D:/tensorboxPy3/evaluate.py"", line 117, in main
    get_results(args, H, os.path.dirname(args.datadir))
  File ""D:/tensorboxPy3/evaluate.py"", line 55, in get_results
    saver = tf.train.Saver()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 1140, in __init__
    self.build()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 1172, in build
    filename=self._filename)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 688, in build
    restore_sequentially, reshape)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 407, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\training\saver.py"", line 247, in restore_op
    [spec.tensor.dtype])[0])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 663, in restore_v2
    dtypes=dtypes, name=name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

DataLossError (see above for traceback): Checksum does not match: stored 1713499277 vs. calculated on the restored bytes 1894941567
	 [[Node: save/RestoreV2_282 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_arg_save/Const_0_0, save/RestoreV2_282/tensor_names, save/RestoreV2_282/shape_and_slices)]]
```


`Process finished with exit code 1`

"
15199,missing instruction for BahdanauAttention,"This is just my opinion: 
when call BahdanauAttention instance , it create a variable scope with None name_or_scope variable.
While name_or_scope is None, and get_variable with the same name inside the variable scope repeatedly, it will automatically add '_N' to the name of the scope. And I think it is not compatible with some functions like stati_rnn, because there are explicit 'for loop' inside the function and every loop of 'for loop' will create different variables inside the variable scope but not creating once and sharing"
15198,Missing documentation for using the Dataset API in combination with image summaries,"The `Dataset` API is now the recommended input pipeline, however I am missing some guidance on how to include summaries of my images.

```python
def get_data():
  dataset = FixedLengthRecordDataset(...)
  dataset = dataset.map(parse_dataset, ...)
  if is_training:
    dataset = dataset.map(preprocess_for_train, ...)
  # Do shuffling, batching...
  return dataset

def preprocess_for_train(image, label):
  # Do preprocessing...
  image = tf.image.random_flip_left_right(image)
  # Add summary
  tf.summary.image('preprocessed_image', tf.expand_dims(image, 0))
  return image, label
```

This is what I would do intuitively, but since `map()` uses a different thread and therefore a different `tf.Graph` instance (?), the summaries are lost.

What is the recommended way of adding image summaries when using the `Dataset` API? I would like to request a comment / example on that in the official docs. "
15196,[XLA] OSX tfcompile compile failure in ../llvm_ir/kernel_support_library.cc ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.13.2 
- **TensorFlow installed from (source or binary)**: Source 
- **TensorFlow version (use command below)**: Top of Master (34bcd09c5fd4f6435517a499987b7e5044c8f2c0) 
- **Python version**: 
- **Bazel version (if compiling from source)**:   0.7.0
- **GCC/Compiler version (if compiling from source)**: Apple LLVM version 9.0.0 (clang-900.0.39.2)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: 

bazel build tensorflow/compiler/aot/tfcompile

### Describe the problem
Compiler error when compiling tfcompile on OSX. This was introduced by @sanjoy  Commit:
https://github.com/tensorflow/tensorflow/commit/c572bc4fd7c73f4b8014ae43cdf9da5b99592f59

You will need this PR to be able to fix other compile issues on OSX. https://github.com/tensorflow/tensorflow/pull/14893


ERROR: /Users/tfninja/github/tensorflow/tensorflow/compiler/xla/service/llvm_ir/BUILD:171:1: C++ compilation of rule '//tensorflow/compiler/xla/service/llvm_ir:kernel_support_library' failed (Exit 1).
tensorflow/compiler/xla/service/llvm_ir/kernel_support_library.cc:99:5: error: no matching function for call to 'transform'
    std::transform(function->arg_begin(), function->arg_end(),
    ^~~~~~~~~~~~~~
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1922:1: note: candidate template ignored: couldn't infer template argument '_UnaryOperation'
transform(_InputIterator __first, _InputIterator __last, _OutputIterator __result, _UnaryOperation __op)
^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/algorithm:1932:1: note: candidate function template not viable: requires 5 arguments, but 4 were provided
transform(_InputIterator1 __first1, _InputIterator1 __last1, _InputIterator2 __first2,
^
1 error generated.
Target //tensorflow/compiler/aot:tfcompile failed to build

### Source code / logs


The issue seems to be with this line of code in which works on Linux but fails on OSX/Clang tensorflow/compiler/xla/service/llvm_ir/kernel_support_library.cc

```
+    std::transform(function->arg_begin(), function->arg_end(),
+                   std::back_inserter(arg_values), std::addressof<llvm::Value>);
```
"
15190,S3 reads eventually fail with tensorflow's dataset API,"

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04.3 LTS
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514
- **Python version**: Python 2.7.12
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: CPU
- **GPU model and memory**: N/A
- **Exact command to reproduce**: https://gist.github.com/thunterdb/d5f86c79457eea0f1021117ea4bce0ba

### Describe the problem
The given script reads the MNIST data from S3 repeatedly from a public bucket, on an EC2 machine in the same region as the S3 bucket.

Running this script eventually leads to python crashing after a few hours, and the following error:

```
Finished step 31890, time: 05:45:28 12/07/17, result: 32
Finished step 31920, time: 05:46:01 12/07/17, result: 32
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
Aborted
```

### Source code / logs
https://gist.github.com/thunterdb/d5f86c79457eea0f1021117ea4bce0ba

It is hard to say what is happening without debugging symbols. From the very generic error, I suspect this is an issue with the S3 SDK. As a workaround, it would be nice for tensorflow's S3 plugin to retry or be more resilient to networking issues.

It is currently an annoying issue when running large distributed training jobs, because they crash after a few hours of reading data. Is anyone having a similar experience with S3?"
15188,error: 'isnan' was not declared in this scope,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: Source
- **TensorFlow version (use command below)**: Master branch commit: `4ad12049`
- **Python version**: N/A
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**: g++ 5.4.0
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `bazel build //tensorflow:libtensorflow.so`

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I'm trying to compile using `bazel build //tensorflow:libtensorflow.so`.
I'm getting this error:
```
ERROR: /home/rdi/Workspace/Common/tensorflow/tensorflow/core/BUILD:577:1: C++ compilation of rule '//tensorflow/core:random_ops_op_lib' failed (Exit 1)
In file included from ./tensorflow/core/framework/allocator.h:23:0,
                 from ./tensorflow/core/framework/tensor.h:20,
                 from ./tensorflow/core/framework/attr_value_util.h:24,
                 from ./tensorflow/core/framework/node_def_util.h:23,
                 from ./tensorflow/core/framework/shape_inference.h:20,
                 from ./tensorflow/core/framework/common_shape_fns.h:20,
                 from tensorflow/core/ops/random_ops.cc:16:
./tensorflow/core/framework/numeric_types.h: In constructor 'tensorflow::bfloat16::bfloat16(float)':
./tensorflow/core/framework/numeric_types.h:49:16: error: 'isnan' was not declared in this scope
     if (isnan(v)) {
                ^
```
"
15180,More simpler examples of using dataflow_ops.StagingArea,"### Describe the problem
Getting the below error when using StagingArea.
`ValueError: Fetch argument <tf.Operation 'group_deps' type=NoOp> cannot be interpreted as a Tensor. (Operation name: ""group_deps""
op: ""NoOp""`

The error happens only after completing a few 100 steps. It would be a great help if someone can place simpler examples of proper usage of StagingArea

### Source code / logs
`compute_stage_put_op = compute_stage.put(iterator.get_next())
  if compute_stage_put_op.type == 'Stage':
         compute_stage_ops.append(compute_stage_put_op)`
"
15179,Failure in LMDBReaderTest while reading testdata,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: s390x Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.4.0
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0
- **CUDA/cuDNN version**: No GPU
- **GPU model and memory**: No GPU
- **Exact command to reproduce**: bazel test -c opt  //tensorflow/python/kernel_tests:reader_ops_test

### Describe the problem
While executing `reader_ops_test`, came across failure in `LMDBReaderTest`. 
Since I am running it on a big endian system, the failure could be because the testdata(data.mdb) is platform specific and hence gets interpreted wrongly. 
@bowang, @jhseu , Is my understanding correct? How can I generate the above testdata for s390x(big endian)?

### Source code / logs
```
F tensorflow/core/kernels/lmdb_reader_op.cc:49] Check failed: mdb_env_open(mdb_env_, current_work().c_str(), flags, 0664) == 0 (-30793 vs. 0)Invalid argument
012
234
012
234
012
234
012
234
012
234
012
234
Aborted (core dumped)
```
"
15178,Dataset.from_generator doesn't play nice with feature_column.categorical_column_with_vocabulary_list,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.4.0-98-generic #121~14.04.1-Ubuntu SMP Wed Oct 11 11:54:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: ('v1.4.0-rc1-11-g130a514', '1.4.0')
- **Python version**: Python 2.7.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**:  -
- **GPU model and memory**: -
- **Exact command to reproduce**: curl -L -o predict_not_working.py 'https://drive.google.com/uc?authuser=0&id=1KHCNOfJOpEFSLzzJqjtP6oy0EvuLvETE&export=download' && python predict_not_working.py

### Describe the problem

I have the same code in two versions, [one using Dataset.from_generator](https://drive.google.com/open?id=1KHCNOfJOpEFSLzzJqjtP6oy0EvuLvETE) and [one using Dataset.from_tensor_slices](https://drive.google.com/open?id=1BFmIEnpuRWPeghUfeBD4225BXZqvLcmS). To me it looks like the created Datasets have the exact same content, but feature_column.categorical_column_with_vocabulary_list doesn't work with the `from_generator` one, which ought to be a bug, right?

### Source code / logs

Sources are in links above."
15175,"Got ""Attempting to use uninitialized value"" error after variable initalization","I am working on windows 10, Python 3.6 and tensorflow 1.4.0. I tested the code on two laptops, one with gpu and another without, both of them had this problem.

This is my code:

`def network(self, net_input):
        dense1 = tf.layers.dense(net_input, 64)
        norm1 = tf.contrib.layers.batch_norm(dense1)
        relu1 = tf.nn.relu(norm1)
        dense2 = tf.layers.dense(relu1, 32)
        norm2 = tf.contrib.layers.batch_norm(dense2)
        relu2 = tf.nn.relu(norm2)
        out = tf.layers.dense(relu2, 1)
        return out`

`def train(self):
        init_global = tf.global_variables_initializer()
        init_local = tf.local_variables_initializer()
        sess = tf.InteractiveSession()
        #sess = tf.Session()
        sess.run(init_global)
        sess.run(init_local)
        data = tf.placeholder(tf.float32, [self.batch_size, 53])
        label = tf.placeholder(tf.float32, [self.batch_size, 1])
        prediction = self.network(data)
        loss = tf.reduce_mean(tf.reduce_sum(tf.square(
                label - prediction),reduction_indices=[1]))
        train_step = tf.train.GradientDescentOptimizer(1e-3).minimize(loss)
    
        for i in range(self.epoch):
            for j in range(20000 // self.batch_size):
                batch_data, batch_label = self.next_batch(self.train_data, self.train_label)
                #batch_label = self.next_batch(self.train_label)
                sess.run(train_step, feed_dict = {data : batch_data, label : batch_label})
                if j % 50 == 0:
                    start = time.time()
                    loss = sess.run(loss, feed_dict = {data : batch_data, label : batch_label})
                    print('Epoch: [%2d/%2d], Iter: [%4d/%4d], Loss: %8f, Time cost: %8f'%\
                          (i, self.epoch, j, 20000//self.batch_size, loss, time.time()-start))`

and this is the error message:

`Traceback (most recent call last):

  File ""<ipython-input-17-6e018316c758>"", line 1, in <module>
    runfile('C:/Users/System_Error/Downloads/report1/regression_tf.py', wdir='C:/Users/System_Error/Downloads/report1')

  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 880, in runfile
    execfile(filename, namespace)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 99, in <module>
    main()

  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 92, in main
    regression.train()

  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 76, in train
    sess.run(train_step, feed_dict = {data : batch_data, label : batch_label})

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 889, in run
    run_metadata_ptr)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1317, in _do_run
    options, run_metadata)

  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\client\session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)

`FailedPreconditionError:` Attempting to use uninitialized value dense_18/bias
	 [[Node: dense_18/bias/read = Identity[T=DT_FLOAT, _class=[""loc:@dense_18/bias""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](dense_18/bias)]]

Caused by op 'dense_18/bias/read', defined at:
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\ipython\start_kernel.py"", line 231, in <module>
    main()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\ipython\start_kernel.py"", line 227, in main
    kernel.start()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\ipykernel\kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\zmq\eventloop\ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tornado\ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\zmq\eventloop\zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tornado\stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\ipykernel\kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\ipykernel\ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\ipykernel\zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2827, in run_ast_nodes
    if self.run_code(code, result):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-17-6e018316c758>"", line 1, in <module>
    runfile('C:/Users/System_Error/Downloads/report1/regression_tf.py', wdir='C:/Users/System_Error/Downloads/report1')
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 880, in runfile
    execfile(filename, namespace)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 102, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 99, in <module>
    main()
  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 92, in main
    regression.train()
  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 67, in train
    prediction = self.network(data)
  File ""C:/Users/System_Error/Downloads/report1/regression_tf.py"", line 26, in network
    dense1 = tf.layers.dense(net_input, 64)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\layers\core.py"", line 250, in dense
    return layer.apply(inputs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\layers\base.py"", line 671, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\layers\base.py"", line 559, in __call__
    self.build(input_shapes[0])
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\layers\core.py"", line 145, in build
    trainable=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\layers\base.py"", line 458, in add_variable
    trainable=trainable and self.trainable)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 1203, in get_variable
    constraint=constraint)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 1092, in get_variable
    constraint=constraint)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 425, in get_variable
    constraint=constraint)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 394, in _true_getter
    use_resource=use_resource, constraint=constraint)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variable_scope.py"", line 805, in _get_single_variable
    constraint=constraint)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variables.py"", line 213, in __init__
    constraint=constraint)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\variables.py"", line 356, in _init_from_args
    self._snapshot = array_ops.identity(self._variable, name=""read"")
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 125, in identity
    return gen_array_ops.identity(input, name=name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 2070, in identity
    ""Identity"", input=input, name=name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

FailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense_18/bias
	 [[Node: dense_18/bias/read = Identity[T=DT_FLOAT, _class=[""loc:@dense_18/bias""], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](dense_18/bias)]]`


I searched stack overflow, most of the answers told me to add an global_variables_initializer, and I tried tf.Session and tf.InteractiveSession, global and local variables initializer, but still got this error. 






"
15172,Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed,"ERROR: /Users/lion/Documents/opensoft/tensorflow/tensorflow/python/BUILD:2749:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow_internal.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o ... (remaining 573 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
clang: warning: argument unused during compilation: '-pthread'
ld: library not found for -lgomp
"
15171,[FeatureRequest] Decorator for estimator input_fn,"In the documentation for [Passing input_fn Data to Your Model](https://www.tensorflow.org/get_started/input_fn#passing_input_fn_data_to_your_model) there are a few methods provided for using a function to construct input data and then wrapping that to get a function object. The documentation suggests `functools.partial` or `lambda`.

Would it be possible to provide a python decorator (maybe under the `tf.estimator` module)? 

Looking at suggested decorator and usage below, I think it makes the code cleaner when making these reusable input functions. 

## Proposed decorator
_n.b. name to be improved/aligned with TF_
```python
import functools

def tf_data_input_fn(old_func):
    def inside(*args, **kwargs):
        return functools.partial(old_func, *args, **kwargs)
    return inside
```

## Usage
```python
@tf_data_input_fn
def my_input_fn(data_set):
    # Construct dataset, repeat, maps etc
    features, labels = dataset.make_one_shot_iterator().get_next()
    return features, labels

train_input_fn = my_input_fn(training_set)
eval_input_fn = my_input_fn(test_set)

classifier.train(input_fn=train_input_fn, steps=2000)
classifier.evaluate(input_fn= eval_input_fn, steps=2000)
```

If this is favourable, I'd be happy to provide a contribution towards such an addition.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: v1.4.0-8-gbca50da6eb 1.4.0
- **Python version**: 3.6.3
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A"
15165,LSTM layer in consistent with tf.keras v2.0.8-tf and keras 2.1.2,"It looks like there are some inconsistencies with the output shape of the LSTM layer. 

Running the following code does not produce an error in `keras 2.1.2`:
```python
model = Sequential()

conv_layer = Conv1D(filters=320,
                    kernel_size=26,
                    strides=1,
                    padding='valid',
                    activation='relu',
                    input_shape=(1000,4))

model.add(conv_layer)
model.add(MaxPooling1D(pool_size=13,
                       strides=13))

model.add(LSTM(320, return_sequences=True))

model.add(Flatten())
model.add(Dense(925,
                activation='relu'))
model.add(Dense(919,
                activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_1 (Conv1D)            (None, 975, 320)          33600     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 75, 320)           0         
_________________________________________________________________
lstm_1 (LSTM)                (None, 75, 320)           820480    
_________________________________________________________________
flatten_1 (Flatten)          (None, 24000)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 925)               22200925  
_________________________________________________________________
dense_2 (Dense)              (None, 919)               850994    
=================================================================
Total params: 23,905,999
Trainable params: 23,905,999
Non-trainable params: 0
_________________________________________________________________
```

but produces this error in `keras v2.0.8-tf`:

```python
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-389-956501e5fb90> in <module>()
     16 model.add(Flatten())
     17 model.add(Dense(925,
---> 18                 activation='relu'))
     19 model.add(Dense(919,
     20                 activation='sigmoid'))

~/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/models.py in add(self, layer)
    499           output_tensors=self.outputs)
    500     else:
--> 501       output_tensor = layer(self.outputs[0])
    502       if isinstance(output_tensor, list):
    503         raise TypeError('All layers in a Sequential model '

~/anaconda/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py in __call__(self, inputs, **kwargs)
    250     """"""
    251     # Actually call the layer (optionally building it).
--> 252     output = super(Layer, self).__call__(inputs, **kwargs)
    253 
    254     # Update learning phase info.

~/anaconda/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    557           input_shapes = [x.get_shape() for x in input_list]
    558           if len(input_shapes) == 1:
--> 559             self.build(input_shapes[0])
    560           else:
    561             self.build(input_shapes)

~/anaconda/lib/python3.6/site-packages/tensorflow/python/layers/core.py in build(self, input_shape)
    125     input_shape = tensor_shape.TensorShape(input_shape)
    126     if input_shape[-1].value is None:
--> 127       raise ValueError('The last dimension of the inputs to `Dense` '
    128                        'should be defined. Found `None`.')
    129     self.input_spec = base.InputSpec(min_ndim=2,

ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.
```

If I keep return_sequences = True and remove Flatten() after the LSTM I get the following:

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d_49 (Conv1D)           (None, 975, 320)          33600     
_________________________________________________________________
max_pooling1d_49 (MaxPooling (None, 75, 320)           0         
_________________________________________________________________
lstm_33 (LSTM)               (None, None, 320)         820480    
_________________________________________________________________
dense_92 (Dense)             (None, None, 925)         296925    
_________________________________________________________________
dense_93 (Dense)             (None, None, 919)         850994    
=================================================================
Total params: 2,001,999
Trainable params: 2,001,999
Non-trainable params: 0
_________________________________________________________________
```
More on the discussion in https://github.com/uci-cbcl/DanQ/issues/9#issuecomment-348377899"
15162,"tf.data.Dataset.from_generator creates too many threads throwing ""thread constructor failed""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Adapted an example from documentation
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Mac OS Siera (10.12.6)
- **TensorFlow installed from (source or binary)**:pip install tensorflow 
- **TensorFlow version (use command below)**: tensorflow-1.4.0-cp27-cp27m-macosx_10_11_x86_64.whl
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: NA
- **GCC/Compiler version (if compiling from source)**: NA
- **CUDA/cuDNN version**: CPU
- **GPU model and memory**: NA
- **Exact command to reproduce**:

```
import itertools
import tensorflow as tf

def gen():
  for i in itertools.count(1):
    yield (i, [1] * 5)

ds = tf.data.Dataset.from_generator(
    gen, (tf.int64, tf.int64), (tf.TensorShape([]), tf.TensorShape([None])))
ds = ds.make_one_shot_iterator()

with tf.Session() as sess:
    while True:
        sess.run(ds.get_next())  # (1, array([1, 1, 1, 1, 1]))...
```

### Describe the problem
If you run the code above, which is adapted from tf.data.Dataset.from_generator docstring, the program will crash with an error: `libc++abi.dylib: terminating with uncaught exception of type std::__1::system_error: thread constructor failed: Resource temporarily unavailable`.

I see the number of threads increasing in the activity monitor of the mac OS and when it reaches ~3K threads the program crashes. It takes several seconds. 

Please let me know if this is not intended use of this API, it is OS releated issue or there is a bug involved.
"
15161,Create Simple DNNClassifier ,"Hi, I'm beginner in Machine Learning and Tensorflow.
I edited [this](https://www.tensorflow.org/get_started/estimator) to adapt it to my dataset (102 features-input and 4 classes-output).

**Question:**
This simple approach is correct for a simple classifier?
Why can't I change the number of nodes and levels (compilier gives errors)? 

**Code:**

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import os
from six.moves.urllib.request import urlopen
import numpy as np
import tensorflow as tf
import EstraiFeature as ef
from pyAudioAnalysis import audioBasicIO
# Datasets (Training and Testing set doesn't refer to iris)
IRIS_TRAINING = ""/Users/giuseppeaccardo/Documents/python/Depressione/TrainingSet.csv"" 
IRIS_TEST = ""/Users/giuseppeaccardo/Documents/python/Depressione/TestingSet.csv"" 

def main():
    # Load datasets.
    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(
        filename=IRIS_TRAINING,
        target_dtype=np.int,
        features_dtype=np.float32)
    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(
        filename=IRIS_TEST,
        target_dtype=np.int,
        features_dtype=np.float32)

    # Specify that all features have real-value data
    feature_columns = [tf.feature_column.numeric_column(""x"", shape=[102])]
    
    # Build 3 layer DNN with 10, 20, 10 units respectively. How can I change this values? 
    classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,
                                          hidden_units=[10,20, 10],
                                          n_classes=4,
                                          model_dir=""/tmp/depres_model"")
    
   # Define the TRAINING inputs, includes both the feature (DNN input end) and target (DNN output end)
    train_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"": np.array(training_set.data)}, #training_set.data
        y=np.array(training_set.target), #training_set.target
        num_epochs=None,
        shuffle=True)
    
    # Fit model.
    print(""Training classfier..."")
    classifier.train(
        input_fn = train_input_fn,
        steps = 2000)

    #Define the TEST inputs, both feature and target
    test_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"":np.array(test_set.data)},
        y=np.array(test_set.target),
        num_epochs=1,
        shuffle=False)

    #Evaluate accuracy after training
    accuracy_score = classifier.evaluate(
        input_fn=test_input_fn)[""accuracy""]

    print(""\nTest Accuracy: {0:f}\n"".format(accuracy_score))
    # Bag of words  approach -> Conta le label più ripetute per ogni mid range
    # PREDIZIONE
    #Predict with new data
    filename = ""/Users/giuseppeaccardo/Documents/python/Depressione/dataset/audio/426_AUDIO.wav""
    [Fs, signal] = audioBasicIO.readAudioFile(filename)  # read audio signal
    [mtFeatures, _] = ef.estraiFeatureMt(signal, Fs)
    mtF = mtFeatures.T       
    new_samples = np.array(
        mtF, dtype=np.float32
    )        

    predict_input_fn = tf.estimator.inputs.numpy_input_fn(
        x={""x"":new_samples},
        num_epochs=1,
        shuffle=False
    )

    predictions = list(classifier.predict(input_fn=predict_input_fn))
    countLabel = [0,0,0,0]
    classPredict = 0
    
    for p in predictions:
        countLabel[int(p[""class_ids""])] +=1
        
    print(countLabel)
    print(""Prevision is ""+ str(countLabel.index(max(countLabel))) ) 
    
if __name__ == ""__main__"":
    main()
```"
15160,Installing Tensorflow from source,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
NO
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Redhat
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
2.7.14
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
gcc 4.8.5

- **CUDA/cuDNN version**:
8/6
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am trying to install TF. Its the last part of building TF from source.

pip install /tmp/tensorflow_pkg/tensorflow-1.4.1-cp27-cp27mu-linux_x86_64.whl 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

[amalik@node05 tensorflow]$ pip install /tmp/tensorflow_pkg/tensorflow-1.4.1-cp27-cp27mu-linux_x86_64.whl 
Processing /tmp/tensorflow_pkg/tensorflow-1.4.1-cp27-cp27mu-linux_x86_64.whl
Requirement already satisfied: enum34>=1.1.6 in /lfs1/software7/anaconda2/lib/python2.7/site-packages (from tensorflow==1.4.1)
Requirement already satisfied: backports.weakref>=1.0rc1 in /lfs1/software7/anaconda2/lib/python2.7/site-packages (from tensorflow==1.4.1)
Requirement already satisfied: wheel in /lfs1/software7/anaconda2/lib/python2.7/site-packages (from tensorflow==1.4.1)
Requirement already satisfied: mock>=2.0.0 in /lfs1/software7/anaconda2/lib/python2.7/site-packages (from tensorflow==1.4.1)
Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow==1.4.1)
  Retrying (Retry(total=4, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f384a2261d0>: Failed to establish a new connection: [Errno 101] Network is unreachable',)': /simple/tensorflow-tensorboard/
  Retrying (Retry(total=3, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f384a226350>: Failed to establish a new connection: [Errno 101] Network is unreachable',)': /simple/tensorflow-tensorboard/
  Retrying (Retry(total=2, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f384a2264d0>: Failed to establish a new connection: [Errno 101] Network is unreachable',)': /simple/tensorflow-tensorboard/
  Retrying (Retry(total=1, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f384a226650>: Failed to establish a new connection: [Errno 101] Network is unreachable',)': /simple/tensorflow-tensorboard/
  Retrying (Retry(total=0, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x7f384a2267d0>: Failed to establish a new connection: [Errno 101] Network is unreachable',)': /simple/tensorflow-tensorboard/
  Could not find a version that satisfies the requirement tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow==1.4.1) (from versions: )
No matching distribution found for tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow==1.4.1)



"
15159,Unable access S3 using the S3 filesystem,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  docker container based on centos7
- **TensorFlow installed from (source or binary)**: binary, from pip
- **TensorFlow version (use command below)**: ('v1.4.0-rc1-11-g130a514', '1.4.0')
- **Python version**: 2.7.5
- **Bazel version (if compiling from source)**: n/a
- **GCC/Compiler version (if compiling from source)**: n/a
- **CUDA/cuDNN version**: n/a
- **GPU model and memory**: n/a
- **Exact command to reproduce**:
```
from tensorflow.python.lib.io import file_io
file_io.stat('s3://datasets.elasticmapreduce/ngrams/books/20090715/eng-1M/1gram/data')
```


### Describe the problem
I'm unable to read files using the s3 filesystem. I believe my example above should work, please correct my usage of the api if not. I tried using both an object in a public bucket and one in a private bucket that I have credentials in my ~/.aws/config for. 

I'm not quite sure what the error is, or how to diagnose it further. Setting the log level to Debug had no effect. `tf.logging.set_verbosity(tf.logging.DEBUG)` 

### Source code / logs

Traceback from file_io.stat
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 540, in stat
    return file_statistics
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: Object s3://datasets.elasticmapreduce/ngrams/books/20090715/eng-1M/1gram/data does not exist
```

Using the aws cli, you can verify the object exists 
```
aws s3 ls s3://datasets.elasticmapreduce/ngrams/books/20090715/eng-1M/1gram/data
```"
15158,"Feature: MonitoredSession should have run() method with 'hooks_to_trigger' argument: run(..., hooks_to_trigger=[hooks[1], hooks[3], ...])","At the moment the session_run_hooks are passed to the constructor of MonitoredSession(..., hooks=[...]) 
and then they get executed for EVERY session.run() call within the MonitoredSession block.

This is inefficient and problematic.

E.g., if I define a LoggingTensorHook, I want the logging output to be evaluated and printed at most ONCE per global step and not after some auxiliary session.run() calls that only evaluate the size of some queue or whatever else.

If you use feedable iterators, the current MonitoredSession implementation actually crashes the program, see https://github.com/tensorflow/tensorflow/issues/12859#issuecomment-348290076

The best solution in my opinion would be, to be able to specify which run() calls should actually trigger the before_run and after_run methods of the hooks, e.g. via some flag-argument in MonitoredSession.run(..., execute_hooks=True)
or alternatively pass a list of specific hooks whose before_run and after_run methods should be triggered by a run call, via MonitoredSession.run(..., hooks_to_trigger=[...])
"
15157,Feature: GANEstimator allow passing of namedtuples,"In the current `GANEstimator` implementation in `train.py` `gan_model(..)` both `real_data` as well as `generator_inputs` is converted to tensors with either `_convert_tensor_or_l_or_d` or `ops.convert_to_tensor`. This prevents the user from using own data structures like `namedtuples` to pass information between the `generator` and `discriminator`.

In the current implementation when passing a `namedtuple` the result will be a `list` with all name information being lost.

I propose to either extend the tensor conversion to exclude namedtuples from them or to remove them entirely.

@joel-shor Do you think that is a good idea? I am currently passing logits as well as sample_id from a dynamic_decoding around and I would like to keep the meaning of these across loss_fn and discriminator_fn.

1. I could remove the conversions entirely. This would introduce breaking changes.
2. I could exclude namedtuples from the conversion.
3. Idk yet??

I would create a PR for any of them if we find a suitable solution. "
15156,Tensorflow set_random_seed,"I use `tf.set_random_seed` to set the seed of graph, and run programs many times, but the result is different.
Is it a bug or precision problem?

```python
import tensorflow as tf
slim =tf.contrib.slim

tf.set_random_seed(0)

def vgg16(inputs):
  with slim.arg_scope([slim.conv2d, slim.fully_connected],
                      activation_fn=tf.nn.relu,
                      weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),
                      weights_regularizer=slim.l2_regularizer(0.0005)):
    net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')
    net = slim.max_pool2d(net, [2, 2], scope='pool1')
    net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')
    net = slim.max_pool2d(net, [2, 2], scope='pool2')
    net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')
    net = slim.max_pool2d(net, [2, 2], scope='pool3')
    net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')
    net = slim.max_pool2d(net, [2, 2], scope='pool4')
    net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')
    net = slim.max_pool2d(net, [2, 2], scope='pool5')
    net = slim.flatten(net)
    net = slim.fully_connected(net, 4096, scope='fc6')
    net = slim.dropout(net, 0.5, scope='dropout6')
    net = slim.fully_connected(net, 4096, scope='fc7')
    net = slim.dropout(net, 0.5, scope='dropout7')
    net = slim.fully_connected(net, 1000, activation_fn=None, scope='fc8')
  return net

outputs = vgg16(tf.random_normal([32, 224, 224, 3]))
loss = tf.reduce_mean(tf.square(outputs-tf.random_normal([32, 1000])))
loss = tf.Print(loss, [loss])
optimizer = tf.train.GradientDescentOptimizer(0.001)
train_op = optimizer.minimize(loss)

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    for i in range(10):
        sess.run([loss, train_op])
```

Sometimes it prints
```
2017-12-06 22:12:46.008551: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00103784]
2017-12-06 22:12:48.309682: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01074851]
2017-12-06 22:12:49.039724: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00621808]
2017-12-06 22:12:49.683761: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00629878]
2017-12-06 22:12:50.326798: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.999040961]
2017-12-06 22:12:50.973835: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.991326749]
2017-12-06 22:12:51.621872: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01098168]
2017-12-06 22:12:52.266909: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.989544928]
2017-12-06 22:12:52.911945: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01077247]
2017-12-06 22:12:53.558982: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00654614]
```
Or

```
2017-12-06 22:14:15.614676: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00103784]
2017-12-06 22:14:17.945809: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01074851]
2017-12-06 22:14:18.633848: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00621808]
2017-12-06 22:14:19.283886: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00629878]
2017-12-06 22:14:19.932923: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.999040902]
2017-12-06 22:14:20.582960: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.99132669]
2017-12-06 22:14:21.231997: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01098168]
2017-12-06 22:14:21.878034: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [0.989544928]
2017-12-06 22:14:22.525071: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.01077247]
2017-12-06 22:14:23.137106: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [1.00654614]
```

The fifth and sixth float number are a little different.

If it is the precision problem, the output of program will be different while running on different situation.

If I use` resnet_v1.resnet_v1_101`, the difference becomes bigger.
See below
```
2017-12-06 22:36:10.263869: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.38138771]
2017-12-06 22:36:10.957909: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.37634754]
2017-12-06 22:36:11.511941: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.37431192]
2017-12-06 22:36:12.065973: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.32495236]
2017-12-06 22:36:12.618004: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.31184864]
2017-12-06 22:36:13.171036: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26968479]
2017-12-06 22:36:13.726067: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26032281]
2017-12-06 22:36:14.282099: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.21301842]
2017-12-06 22:36:14.831131: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.25101829]
2017-12-06 22:36:15.386162: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.14982963]
```
and
```
017-12-06 22:36:46.220926: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.38138771]
2017-12-06 22:36:46.913966: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.3763473]
2017-12-06 22:36:47.466997: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.37354136]
2017-12-06 22:36:48.022029: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.32750821]
2017-12-06 22:36:48.571060: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.30615568]
2017-12-06 22:36:49.126092: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26913476]
2017-12-06 22:36:49.682124: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.26520848]
2017-12-06 22:36:50.238156: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.21404171]
2017-12-06 22:36:50.793188: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.25153565]
2017-12-06 22:36:51.347219: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu
\PY\35\tensorflow\core\kernels\logging_ops.cc:79] [3.14605141]
``` 
"
15155,Input too short to compute filterbank,"Hi,
I am new to tensorflow and i am trying to train model with my own data but i am getting below error

2017-12-06 18:56:38.030081: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030095: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030105: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030162: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030203: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030243: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030256: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030267: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030305: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030347: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030359: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030370: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030408: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030446: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030458: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030469: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030481: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030492: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030534: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030547: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030558: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030569: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030632: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030645: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030656: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030668: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030679: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030720: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030732: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030743: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030754: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030790: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030851: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030865: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030877: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030937: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030954: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.030967: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031028: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031043: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031054: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031066: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031078: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031118: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031132: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031144: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031155: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031211: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031227: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031238: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031249: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031309: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031325: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031338: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031349: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031408: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031425: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031437: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031474: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031512: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031525: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031537: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031573: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031608: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031620: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031631: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031643: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031687: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031699: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031710: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031769: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031799: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031812: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031823: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031834: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.031965: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032014: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032024: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032036: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032046: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032057: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032069: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032081: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032128: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032141: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032153: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032165: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032176: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032236: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032248: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032260: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032272: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032313: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032326: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032336: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032347: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032360: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank
2017-12-06 18:56:38.032399: E tensorflow/core/kernels/mfcc_mel_filterbank.cc:181] Input too short to compute filterbank

and i am using below command to train
bazel run tensorflow/examples/speech_commands:train -- \ --data_dir=sound --wanted_words=yes,no --data_url=
"
15153,Tensorflow Unit Test //tensorflow/python/kernel_tests:depthtospace_op_test TIMEOUT,"System Information
Linux  ppc64le GNU/Linux
commit id 3fe5fa08dbed8134ad400f03be474aeb39bcc922
Python 2.7.5
Bazel Build label: 0.5.4- (@non-git)
gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)
cuda-9.0/
NVIDIA GPU driver 

command to reproduce  - bazel test tensorflow/python/kernel_tests:depthtospace_op_test

*Failure log* 

pci bus id: 0003:01:00.0, compute capability: 6.0)
2017-12-06 08:58:27.675099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0007:01:00.0, compute capability: 6.0)
2017-12-06 08:58:27.699874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0003:01:00.0, compute capability: 6.0)
2017-12-06 08:58:27.699885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: Tesla P100-SXM2-16GB, pci bus id: 0007:01:00.0, compute capability: 6.0)
Terminated
"
15152,Strange Dataset API behaviour,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux Ubuntu 14.04
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 
sys.version_info(major=3, minor=4, micro=3, releaselevel='final', serial=0)
- **Bazel version (if compiling from source)**:
n/a
- **GCC/Compiler version (if compiling from source)**:
n/a
- **CUDA/cuDNN version**:
Cuda 8.0 
- **GPU model and memory**:
Titan XP 12Gb
- **Exact command to reproduce**:

### Describe the problem
I get very strange behaviour of image read function. See attached screenshot from tensorboard. This is NOT a tensorboard problem as I get images as they are from Dataset object.
![kodak_messed](https://user-images.githubusercontent.com/6204851/33659749-37586c4e-da79-11e7-8977-7d8f6da31c2d.png)

Source images are fine, I have attached a zip archive with source images:
[Kodak.zip](https://github.com/tensorflow/tensorflow/files/1534996/Kodak.zip)

```
import glob
import tensorflow as tf

def simply_read_image(image_path):
    image_string = tf.read_file(image_path)
    image_source = tf.image.decode_png(image_string, channels=3)
    image_source = tf.image.convert_image_dtype(image_source, dtype=tf.float32)
    return image_source

validation_files = glob.glob(os.path.join(validation_folder, '*.png'))

dataset = tf.data.Dataset.from_tensor_slices(validation_files)
dataset = dataset.map(simply_read_image).batch(len(validation_files)).repeat(30)

next_element = iterator.get_next()

    with tf.Session() as s:
        for i in range(30):
            im = s.run(next_element)
            for j in range(25):
                current_image = im[j]
                pass

```
Any ` current_image` with portrait orientation seems to be read incorrectly. 
### Source code / logs
There are no logs that could help"
15151, model.fit crash ( keras example mnist) TensorFlow1.4," I run example : https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py
but it crashed when train, namely model.fit


The error is :
An error ocurred while starting the kernel
\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that thisTensorFlow binary was not compiled to use: AVX AVX2
\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties: 
\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) ‑> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
tensorflow\stream_executor\cuda\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
tensorflow\stream_executor\cuda\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
\tensorflow\core\kernels\conv_ops.cc:667] Check failed: stream‑>parent()‑>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) 

And I run another example it crashed too when run at  model.fit, but the error is not the same:
An error ocurred while starting the kernel
\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) ‑> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1)
 \tensorflow\stream_executor\cuda\cuda_dnn.cc:385] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
tensorflow\stream_executor\cuda\cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
 \tensorflow\core\kernels\conv_ops.cc:667] Check failed: stream‑>parent()‑>GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo(), &algorithms) 
 

# My environment:
win7
tensorflow-gpu 1.4
cuda 8.0 
cudnn6.0 
GeForce GTX 1080 Ti 

I really appreciate your help！"
15150,`variational_recurrent` in contrib DropoutWrapper causes extreme perplexity jumps,"I have done extensive testing of the `variational_recurrent` option in the tf.contrib dropout wrapper and neither me nor my colleagues can explain the extreme perplexity jumps that are caused by it.

I am training an RNN language model on the Penn Treebank Dataset. The model code is very similar to the one provided in the [TensorFlow Tutorial](https://www.tensorflow.org/tutorials/recurrent), using the same learning parameters, hidden sizes, etc. like the MEDIUM config. I am using the newest TensorFlow version (1.4.0).

Consider the following models together with the dropout values used in the tf.contrib Dropout Wrapper. If not mentioned, no further regularization was used.

**model1:** 

 - input dropout 0.3, state dropout: 0.3, output dropout: 0.3
 - variational_recurrent=True
 - Perplexity test set: 83.81
 - Perplexity validation set: 86.97

**model2:**

 - input dropout 0.5, state dropout: 0.3, output dropout: 0.5
 - variational_recurrent=True   
 - Perplexity test set: 639.65
 - Perplexity validation set: 686.95

**model3 (as a comparison):**

 - input dropout 0.5, output dropout: 0.5
 - variational_recurrent=False
 - Perplexity test set: 82.88
 - Perplexity validation set: 86.11


I have tested various architectures, with and without variational dropout. I could not find an explanation for the fact that the perplexity sometimes jumps up to >600 when using variational dropout. Also, the effects vanish when tying the embedding and softmax weights.
In general, variational dropout does not improve but worsen the results (which is different to the results reported in recent papers using variational dropout on the PTB dataset).

To test this problem further, I have adapted the official tensorflow tutorial to use variational dropout instead of standard dropout, by removing lines 131+132 and replacing lines 218-220 with:

    if is_training and config.keep_prob < 1:
      cell = tf.contrib.rnn.DropoutWrapper(cell,
                input_keep_prob=config.keep_prob,
                output_keep_prob=config.keep_prob,
                state_keep_prob=config.keep_prob,
                variational_recurrent=True, dtype=tf.float32,
                input_size=config.hidden_size)

Training the medium model with this configuration causes the same issues, i.e. perplexity > 600

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom code
- **OS Platform and Distribution**:  Debian GNU/Linux 8.9 (jessie)
- **TensorFlow version **: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: Python 3.5.4 
- **GCC/Compiler version**:
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514"
15149,BatchNorm/gamma not found in checkpoint,"I trained a model with tensorflow1.4， and want to finetune in tensorflow 1.3，following is part of my code:
1）train code with tf1.4:
            with slim.arg_scope(inception_v3.inception_v3_arg_scope()):
          y, endpoints = inception_v3.inception_v3(x, CLASSES, True)
2）test code with master:
     with slim.arg_scope(inception_v3.inception_v3_arg_scope()):
        y, end_points = inception_v3.inception_v3(x, label_dim, False)
    with tf.name_scope('train'):
        loss = custom_function.loss_function(y, y_)
        train_op = custom_function.train_function(loss, learn_rate)
        accuracy_op = custom_function.accuracy_function(y, y_)
        output_result = custom_function.output_result(y)
        init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
        saver = tf.train.Saver()
        sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)
        sess_config.gpu_options.allow_growth = True
        sess = tf.Session(config=sess_config)
        merged_summary = tf.summary.merge_all()
        train_writer = tf.summary.FileWriter(log_dir, sess.graph)
        #saver = tf.train.import_meta_graph('model_meishi/inception-v3/graph-1205-190241.meta',clear_devices=True)
        sess.run(init_op)
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(sess=sess, coord=coord)
        #saver.restore(sess, ""model_meishi/model-6690"")
        saver.restore(sess, ""model_meishi/inception-v3/model-12042"")
error is:NotFoundError (see above for traceback): Key InceptionV3/Mixed_7b/Branch_2/Conv2d_0a_1x1/BatchNorm/gamma not found in checkpoint
at first, i think the reason is slim.argscope is not the same in these two version tensorflow and 
I tried to replace the slim of tf1.4 with the slim of master，but the error still exist.
what's the problem of my code ?thx
     
"
15148,Using function defun and while loops,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: Tesla x Pascal 12gb
- **Exact command to reproduce**: run defun_while.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Function.defun when used alongside a while loop is throwing shape errors.

More explicitly: when using a concatenation operation of sliced tensors with the loop variable, the newly defined op throws no errors.  However, when the slices are added to the loop variable, it throws shape errors related to the while loop. 

It might be an issue with the fetch argument that fails to work in this case.

The code (along with a more detailed explanation) can be found on:
https://stackoverflow.com/questions/47646962/tensorflow-function-defun-with-a-a-while-loop-in-the-body-is-throwing-shape-err

 




### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15145,TensorFLow build Error,"
when iam trying to retrain as per sample given in tensorflow.org\tutorials.
given below command 
bazel build tensorflow/examples/image_retraining:retrain
after that gaving below errors . any clue on this?
Error 
tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': BUILD file not found on package path and referenced by '//third_party/py/numpy:headers'


Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15144,Error_Converting_TliteFormat,"  .....................................................## System information##........................................................................
-Python -2.7.12
-OS -Ubuntu 16.04
-Tensorflow version-1.4.0
-Bazel version-0.8.0
     ......................................................##Description ###...............................................................
1. I went through the following link and 
=>https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3
and successfully retrained the last layer of the model.

2. Now i was trying to use that retrained.pb file and convert into.tlite format.
=>https://github.com/tensorflow/tensorflow
--Downloaded the tensorflow-master directory.
--Install Bazel (0.8.0)
--Then, using the retrained.pb file,trying to do model format conversion
--Downloaded the checkpoints from 
=>https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.md
But got stucked while running the command for conversion.[bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb  --output_node_names=Softmax}



.........................................................### Source code ##..........................................................................................
1. 
(tensorflow) root@pcz-ee210201:/u/tensorflow-master# bazel build -c opt --copt=-msse4.1 --copt=-msse4.2 tensorflow/python/tools:freeze_graph

=>INFO: Elapsed time: 1057.269s, Critical Path: 44.92s
INFO: Build completed successfully, 2109 total actions
.................................................................................................................................

2. But while running the below script [To convert into .tlite format] ,i was unable to resolved the following error?
(tensorflow) root@pcz-ee210201:/u/tensorflow-master# bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/home/ee210201/tensorflow-for-poets-2/tf_files/retrained_graph.pb --input_checkpoint=/tmp/checkpoints/mobilenet_v1_0.50_224.ckpt.data-00000-of-00001 --input_binary=true --output_graph=/tmp/checkpoints/frozen_mobilenet.pb  --output_node_names=Softmax

Error:::::::::::::::::::::::::::::::::::::::::
```
Traceback (most recent call last):
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 56, in <module>
    from tensorflow.python.tools import saved_model_utils
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_utils.py"", line 21, in <module>
    from tensorflow.contrib.saved_model.python.saved_model import reader
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/__init__.py"", line 82, in <module>
    from tensorflow.contrib.eager.python import tfe as eager
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/eager/python/tfe.py"", line 75, in <module>
    from tensorflow.contrib.eager.python.datasets import Iterator
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/eager/python/datasets.py"", line 23, in <module>
    from tensorflow.contrib.data.python.ops import prefetching_ops
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/prefetching_ops.py"", line 25, in <module>
    resource_loader.get_path_to_datafile(""../../_prefetching_ops.so""))
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py"", line 55, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py"", line 56, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)
  File ""/u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))

=>tensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E
.........................................................................................................................
```
Please let me know what does above error
--(tensorflow.python.framework.errors_impl.NotFoundError: --_ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E)
means and how to solved it.

"
15143,tensorflow.python.framework.errors_impl.NotFoundError: /u/tensorflow-master/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/contrib/data/python/ops/../../_prefetching_ops.so: undefined symbol: _ZN6google8protobuf8internal26fixed_address_empty_stringB5cxx11E,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15142,Tensorflow (current master) build failure due to cuda/cudnn?,"I would like to try out `tf.contrib.framework.sort()`, which available on current master only.

Tried to build master but failed due to cuda/cudnn library cannot found by bazel. However, I verified these library are exist at `/usr/local/cuda/lib64`.

```
ERROR: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/lite/toco/BUILD:330:1: Linking of rule '//tensorflow/contrib/lite/toco:toco' failed (Exit 1)
/usr/bin/ld: warning: libcublas.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
```

System Environment:
Ubuntu 16.04, cuda8.0, cudnn6.0, gcc-5

Build Steps:
```
# checkout master
$ git clone https://github.com/tensorflow/tensorflow 
$ cd tensorflow
$ git checkout master

# python dependencies
$ sudo apt-get install python-numpy python-dev python-pip python-wheel
$ sudo apt-get install libcupti-dev 

# gcc-5
$ bazel build --config=opt --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package
```

Check cuda/cudnn
```
$ ls -alhF /usr/local/cuda/lib64

total 1.4G
drwxr-xr-x  3 root root  4.0K Nov 28 18:21 ./
drwxr-xr-x 17 root root  4.0K Nov 28 16:38 ../
-rw-r--r--  1 root root   51M Nov 28 16:37 libcublas_device.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libcublas.so -> libcublas.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libcublas.so.8.0 -> libcublas.so.8.0.61*
-rwxr-xr-x  1 root root   41M Nov 28 16:37 libcublas.so.8.0.61*
-rw-r--r--  1 root root   47M Nov 28 16:37 libcublas_static.a
-rw-r--r--  1 root root  543K Nov 28 16:37 libcudadevrt.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libcudart.so -> libcudart.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libcudart.so.8.0 -> libcudart.so.8.0.61*
-rwxr-xr-x  1 root root  406K Nov 28 16:37 libcudart.so.8.0.61*
-rw-r--r--  1 root root  757K Nov 28 16:37 libcudart_static.a
lrwxrwxrwx  1 root root    13 Nov 28 18:21 libcudnn.so -> libcudnn.so.6*
lrwxrwxrwx  1 root root    18 Nov 28 18:21 libcudnn.so.6 -> libcudnn.so.6.0.21*
-rwxr-xr-x  1 root root  148M Nov 28 18:19 libcudnn.so.6.0.21*
-rw-r--r--  1 root root  138M Nov 28 18:19 libcudnn_static.a
lrwxrwxrwx  1 root root    15 Nov 28 16:37 libcufft.so -> libcufft.so.8.0*
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libcufft.so.8.0 -> libcufft.so.8.0.61*
-rwxr-xr-x  1 root root  140M Nov 28 16:37 libcufft.so.8.0.61*
-rw-r--r--  1 root root  124M Nov 28 16:37 libcufft_static.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libcufftw.so -> libcufftw.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libcufftw.so.8.0 -> libcufftw.so.8.0.61*
-rwxr-xr-x  1 root root  466K Nov 28 16:37 libcufftw.so.8.0.61*
-rw-r--r--  1 root root   42K Nov 28 16:37 libcufftw_static.a
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libcuinj64.so -> libcuinj64.so.8.0*
lrwxrwxrwx  1 root root    20 Nov 28 16:37 libcuinj64.so.8.0 -> libcuinj64.so.8.0.61*
-rwxr-xr-x  1 root root  6.2M Nov 28 16:37 libcuinj64.so.8.0.61*
-rw-r--r--  1 root root  1.6M Nov 28 16:37 libculibos.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libcurand.so -> libcurand.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libcurand.so.8.0 -> libcurand.so.8.0.61*
-rwxr-xr-x  1 root root   57M Nov 28 16:37 libcurand.so.8.0.61*
-rw-r--r--  1 root root   57M Nov 28 16:37 libcurand_static.a
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libcusolver.so -> libcusolver.so.8.0*
lrwxrwxrwx  1 root root    21 Nov 28 16:37 libcusolver.so.8.0 -> libcusolver.so.8.0.61*
-rwxr-xr-x  1 root root   52M Nov 28 16:37 libcusolver.so.8.0.61*
-rw-r--r--  1 root root   22M Nov 28 16:37 libcusolver_static.a
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libcusparse.so -> libcusparse.so.8.0*
lrwxrwxrwx  1 root root    21 Nov 28 16:37 libcusparse.so.8.0 -> libcusparse.so.8.0.61*
-rwxr-xr-x  1 root root   42M Nov 28 16:37 libcusparse.so.8.0.61*
-rw-r--r--  1 root root   50M Nov 28 16:37 libcusparse_static.a
lrwxrwxrwx  1 root root    14 Nov 28 16:37 libnppc.so -> libnppc.so.8.0*
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppc.so.8.0 -> libnppc.so.8.0.61*
-rwxr-xr-x  1 root root  446K Nov 28 16:37 libnppc.so.8.0.61*
-rw-r--r--  1 root root   24K Nov 28 16:37 libnppc_static.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppial.so -> libnppial.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppial.so.8.0 -> libnppial.so.8.0.61*
-rwxr-xr-x  1 root root  9.7M Nov 28 16:37 libnppial.so.8.0.61*
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppicc.so -> libnppicc.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppicc.so.8.0 -> libnppicc.so.8.0.61*
-rwxr-xr-x  1 root root  3.7M Nov 28 16:37 libnppicc.so.8.0.61*
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppicom.so -> libnppicom.so.8.0*
lrwxrwxrwx  1 root root    20 Nov 28 16:37 libnppicom.so.8.0 -> libnppicom.so.8.0.61*
-rwxr-xr-x  1 root root 1007K Nov 28 16:37 libnppicom.so.8.0.61*
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppidei.so -> libnppidei.so.8.0*
lrwxrwxrwx  1 root root    20 Nov 28 16:37 libnppidei.so.8.0 -> libnppidei.so.8.0.61*
-rwxr-xr-x  1 root root  6.8M Nov 28 16:37 libnppidei.so.8.0.61*
lrwxrwxrwx  1 root root    15 Nov 28 16:37 libnppif.so -> libnppif.so.8.0*
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libnppif.so.8.0 -> libnppif.so.8.0.61*
-rwxr-xr-x  1 root root   46M Nov 28 16:37 libnppif.so.8.0.61*
lrwxrwxrwx  1 root root    15 Nov 28 16:37 libnppig.so -> libnppig.so.8.0*
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libnppig.so.8.0 -> libnppig.so.8.0.61*
-rwxr-xr-x  1 root root   21M Nov 28 16:37 libnppig.so.8.0.61*
lrwxrwxrwx  1 root root    15 Nov 28 16:37 libnppim.so -> libnppim.so.8.0*
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libnppim.so.8.0 -> libnppim.so.8.0.61*
-rwxr-xr-x  1 root root  4.2M Nov 28 16:37 libnppim.so.8.0.61*
lrwxrwxrwx  1 root root    14 Nov 28 16:37 libnppi.so -> libnppi.so.8.0*
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libnppi.so.8.0 -> libnppi.so.8.0.61*
-rwxr-xr-x  1 root root  104M Nov 28 16:37 libnppi.so.8.0.61*
-rw-r--r--  1 root root  131M Nov 28 16:37 libnppi_static.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppist.so -> libnppist.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppist.so.8.0 -> libnppist.so.8.0.61*
-rwxr-xr-x  1 root root   14M Nov 28 16:37 libnppist.so.8.0.61*
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppisu.so -> libnppisu.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppisu.so.8.0 -> libnppisu.so.8.0.61*
-rwxr-xr-x  1 root root  438K Nov 28 16:37 libnppisu.so.8.0.61*
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libnppitc.so -> libnppitc.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libnppitc.so.8.0 -> libnppitc.so.8.0.61*
-rwxr-xr-x  1 root root  2.8M Nov 28 16:37 libnppitc.so.8.0.61*
lrwxrwxrwx  1 root root    14 Nov 28 16:37 libnpps.so -> libnpps.so.8.0*
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libnpps.so.8.0 -> libnpps.so.8.0.61*
-rwxr-xr-x  1 root root  7.8M Nov 28 16:37 libnpps.so.8.0.61*
-rw-r--r--  1 root root   11M Nov 28 16:37 libnpps_static.a
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libnvblas.so -> libnvblas.so.8.0*
lrwxrwxrwx  1 root root    19 Nov 28 16:37 libnvblas.so.8.0 -> libnvblas.so.8.0.61*
-rwxr-xr-x  1 root root  487K Nov 28 16:37 libnvblas.so.8.0.61*
lrwxrwxrwx  1 root root    17 Nov 28 16:37 libnvgraph.so -> libnvgraph.so.8.0*
lrwxrwxrwx  1 root root    20 Nov 28 16:37 libnvgraph.so.8.0 -> libnvgraph.so.8.0.61*
-rwxr-xr-x  1 root root  5.0M Nov 28 16:37 libnvgraph.so.8.0.61*
-rw-r--r--  1 root root  7.8M Nov 28 16:37 libnvgraph_static.a
lrwxrwxrwx  1 root root    24 Nov 28 16:37 libnvrtc-builtins.so -> libnvrtc-builtins.so.8.0*
lrwxrwxrwx  1 root root    27 Nov 28 16:37 libnvrtc-builtins.so.8.0 -> libnvrtc-builtins.so.8.0.61*
-rwxr-xr-x  1 root root  9.3M Nov 28 16:37 libnvrtc-builtins.so.8.0.61*
lrwxrwxrwx  1 root root    15 Nov 28 16:37 libnvrtc.so -> libnvrtc.so.8.0*
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libnvrtc.so.8.0 -> libnvrtc.so.8.0.61*
-rwxr-xr-x  1 root root   18M Nov 28 16:37 libnvrtc.so.8.0.61*
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libnvToolsExt.so -> libnvToolsExt.so.1*
lrwxrwxrwx  1 root root    22 Nov 28 16:37 libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0*
-rwxr-xr-x  1 root root   37K Nov 28 16:37 libnvToolsExt.so.1.0.0*
lrwxrwxrwx  1 root root    14 Nov 28 16:37 libOpenCL.so -> libOpenCL.so.1
lrwxrwxrwx  1 root root    16 Nov 28 16:37 libOpenCL.so.1 -> libOpenCL.so.1.0
lrwxrwxrwx  1 root root    18 Nov 28 16:37 libOpenCL.so.1.0 -> libOpenCL.so.1.0.0
-rw-r--r--  1 root root   26K Nov 28 16:37 libOpenCL.so.1.0.0
drwxr-xr-x  2 root root  4.0K Nov 28 16:37 stubs/
```

Verbose Failure:
```
$ bazel build --verbose_failures  --config=opt --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package
WARNING: /srv/yg/researches/gits/tensorflow/tensorflow/core/BUILD:1806:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /srv/yg/researches/gits/tensorflow/tensorflow/tensorflow.bzl:1100:30
WARNING: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (2 packages loaded).
INFO: Found 1 target...
ERROR: /srv/yg/researches/gits/tensorflow/tensorflow/contrib/lite/toco/BUILD:330:1: Linking of rule '//tensorflow/contrib/lite/toco:toco' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/<usr>/.cache/bazel/_bazel_<usr>/eac5d1dca31d986f2b063251871502de/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda \
    CUDNN_INSTALL_PATH=/usr/local/cuda-8.0 \
    GCC_HOST_COMPILER_PATH=/usr/bin/gcc \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/home/<usr>/anaconda2/envs/ygtf/lib/python2.7/site-packages \
    TF_CUDA_CLANG=0 \
    TF_CUDA_COMPUTE_CAPABILITIES=3.7,3.7 \
    TF_CUDA_VERSION=8.0 \
    TF_CUDNN_VERSION=6 \
    TF_NEED_CUDA=1 \
    TF_NEED_OPENCL_SYCL=0 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/local_linux-opt/bin/tensorflow/contrib/lite/toco/toco '-Wl,-rpath,$ORIGIN/../../../../_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow' '-Wl,-rpath,$ORIGIN/../../../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' -Lbazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow -Lbazel-out/local_linux-opt/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..,-rpath,$ORIGIN/../../..' -pthread -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,@bazel-out/local_linux-opt/bin/tensorflow/contrib/lite/toco/toco-2.params)
/usr/bin/ld: warning: libcublas.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
/usr/bin/ld: warning: libcudnn.so.6, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
/usr/bin/ld: warning: libcufft.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
/usr/bin/ld: warning: libcurand.so.8.0, needed by bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetLRNDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan2d'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrot_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyrk_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataWorkspaceSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerMatrixParams'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardAlgorithm'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCaxpy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterWorkspaceSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemmBatched'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamax_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlanMany'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyr2k_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateConvolutionDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyConvolutionDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensorNdDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecD2Z'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetFilterNdDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetStream_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotmg_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSetPointerMode_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan1d'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDswap_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgeru_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsymm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionForward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher2k_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSswap_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemmBatched'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionNdForwardOutputDim'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCherk_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan2d'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNLinLayerBiasParams'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelBackward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCrotg_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniform'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtbsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingBackward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZaxpy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetConvolutionNdDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateTensorDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyDropoutDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardInference'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardData'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDdot_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateDropoutDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateUniformDouble'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2Z'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreatePoolingDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyFilterDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardInference'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSnrm2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamin_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgerc_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetPoolingNdDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrsm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgerc_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZswap_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftDestroy'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyTensorDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNParamsSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDaxpy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGetPointerMode_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateLRNDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZscal_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhemv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandCreateGenerator'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyRNNDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotc_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionForwardWorkspaceSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDscal_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZrotg_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScopy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyr2k_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsymv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetAutoAllocation'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZcopy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnAddTensor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyPoolingDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStpsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetFilterNdDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotmg_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnActivationForward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDger_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNWorkspaceSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetVersion'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotc_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZher_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnPoolingForward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher2k_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftCreate'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2k_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardWeights'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrot_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetRNNTrainingReserveSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetPseudoRandomGeneratorSeed'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSdot_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2R'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgemmBatched'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCswap_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScnrm2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateRNNDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDnrm2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDropoutGetStatesSize'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsscal_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandDestroyGenerator'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardBias'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationBackward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasGemmEx'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDcopy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardFilterAlgorithm'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecC2C'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDestroy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamin_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdscal_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZgbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsrot_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZsyrk_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormalDouble'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmEx'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateFilterDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetActivationDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDzasum_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSrotg_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnTransformTensor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecR2C'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtbsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDasum_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasStrmm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgemv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBackwardFilter'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetStream'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnLRNCrossChannelForward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2k_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyLRNDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCcopy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCdotu_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNBackwardData'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetRNNDescriptor_v6'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIzamin_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetStream'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreateActivationDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandSetGeneratorOffset'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnConvolutionBiasActivationForward'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyrk_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSaxpy_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsymm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIsamax_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDrotg_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetTensor4dDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZherk_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroy'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan3d'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetWorkArea'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnDestroyActivationDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDspr_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftPlan1d'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDgemm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamin_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChpr2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSscal_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgemmBatched'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSsyr2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDznrm2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtpmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsymm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnBatchNormalizationForwardTraining'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCsyrk_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSger_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIdamax_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftSetStream'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSasum_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftExecZ2D'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSgbmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtrmm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtpmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCreate_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZhpr_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlanMany'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCher_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdotu_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasScasum_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCscal_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasChemm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `curandGenerateNormal'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasIcamax_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDtrmm_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCtrmv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasCgeru_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnRNNForwardTraining'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZdrot_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnSetDropoutDescriptor'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cufftMakePlan3d'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasDsyr2_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasZtpsv_v2'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnCreate'
bazel-out/local_linux-opt/bin/_solib_local/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: undefined reference to `cublasSspr_v2'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1.557s, Critical Path: 0.36s
FAILED: Build did NOT complete successfully
```

"
15140,CUDA 9.1 planning ticket,"**Update 05-FEB-2018**
The plan of record is to stick with CUDA 9.x until CUDA 10.  That plan has an issue in that CUDA 9 and 9.1 cause problems with XLA that should be resolved with CUDA 9.2.  The soft plan is we would move to 9.2 when it comes out if it resolves the issues with XLA.  

**Update 23-JAN-2018**
CUDA 9.1 requires an upgrade to device driver 387 (CUDA 9 was 384).  Moving device drivers is painful for production environments.  We are not going to move the default builds to CUDA 9.1 or 9.2 we will stick with CUDA 9 likely until CUDA 10.  We will move cuDNN forward which will have a larger impact and not require device drive upgrades.  This space is developing as everyone involved evolves their processes and learns from the past.  

While I cannot promise anything, I do want to create a ""channel"" where we are building and testing the latest CUDA 9.x so we can track performance improvements and have some avenue for people to get those builds.  The testing infrastructure is large and maintaining this has a cost.  I hope to find a middle ground as I like perf testing the latest libraries.  

**Original Message**
The purpose of this thread is to keep CUDA 9.1 questions related to when it will be in TensorFlow in a single area.  Separate issues are fine.  I will try to keep this first comment updated with information as it comes out.  

**Current Status:**  Unknown, waiting for RC and gathering information to formulate a plan.  

p.s. There is a tendency to treat TensorFlow like a one way product.  I want to continue to change that with this type of dialog and transparency.  Many people outside Google will contribute to CUDA 9.1 support for TensorFlow.  "
15137,Tensorflow broken by new Bazel versions,"Simplest way to reproduce the issue, run:
`$ bazel build --config=opt --incompatible_load_argument_is_label --nobuild //tensorflow/tools/pip_package:build_pip_package`

Suggested fix to `tensorflow/third_party/sycl/sycl/BUILD.tpl`:
```
-load(""platform"", ""sycl_library_path"")
+load("":platform.bzl"", ""sycl_library_path"")

-load(""platform"", ""readlink_command"")
+load("":platform.bzl"", ""readlink_command"")
```

This should address the immediate need.
There are other issues to fix (although not as pressing). You can see them by building using `--all_incompatible_changes`.

Let me know if you need any help.
Thanks!"
15136,"Tensorflow is pulling enum34 in Python 3.5 and 3.6, which breaks code completion in Spyder","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5, 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: `pip install tensorflow`

### Describe the problem
When you run

    pip install tensorflow

in a virtualenv with Python 3.5 or 3.6, one of the dependencies pulled by `pip` is `enum34`, as the following console output shows

```
$ pip install tensorflow
Collecting tensorflow
  Downloading tensorflow-1.4.0-cp35-cp35m-manylinux1_x86_64.whl (40.7MB)
    100% |████████████████████████████████| 40.7MB 39kB/s 
Collecting numpy>=1.12.1 (from tensorflow)
  Using cached numpy-1.13.3-cp35-cp35m-manylinux1_x86_64.whl
Collecting six>=1.10.0 (from tensorflow)
  Using cached six-1.11.0-py2.py3-none-any.whl
Collecting protobuf>=3.3.0 (from tensorflow)
  Downloading protobuf-3.5.0.post1-cp35-cp35m-manylinux1_x86_64.whl (6.4MB)
    100% |████████████████████████████████| 6.4MB 217kB/s 
Requirement already satisfied: wheel>=0.26 in ./.virtualenvs/tf/lib/python3.5/site-packages (from tensorflow)
Collecting enum34>=1.1.6 (from tensorflow)
  Downloading enum34-1.1.6-py3-none-any.whl
```

This package is only necessary if `Python < 3.4`, as described here:

https://pypi.python.org/pypi/enum34/1.1.6

so it's an error that `tensorflow` pullis it for Python 3.5 and 3.6.

Besides, this package breaks Spyder code completion machinery in its Editor, as it has been verified by several users. See for example:

spyder-ide/spyder#5782."
15134,contrib STFT magnitudes different to librosa's,"------------------------

### System information
- **Have I written custom code**: Yes
- **OS Platform and Distribution**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version**: 1.4
- **Python version**: 3.5.2
- **Bazel version**: N/A
- **GCC/Compiler version**: N/A
- **CUDA/cuDNN version**: 6.0
- **GPU model and memory**: nvidia quadro m2000m 4gb
- **Exact command to reproduce**: See below code

Hi all!

I was comparing the TensorFlow's contrib STFT against librosa's and noticed there are some discrepancies in terms of output between the two. Not sure if this normal between libraries implementations, but I wanted to raise it in case it matters!

I'm also aware it could be some small bug or difference in implementation/argument that I have supplied.

Code:

```
import tensorflow as tf
import numpy as np
import librosa

np.random.seed(666)
np.set_printoptions(precision=5, suppress=True)

audio_length_seconds = 2
sample_rate = 44100
audio_frames_length = int(sample_rate * audio_length_seconds)
audio_shape = [None, audio_frames_length]
fft_size = 1024
hop_size = 512

tf.reset_default_graph()

audio = tf.placeholder(tf.float32, 
                       shape=audio_shape)
stfts = tf.contrib.signal.stft(audio, 
                               frame_length=fft_size, 
                               frame_step=hop_size,
                               fft_length=fft_size,
                               pad_end=True)
real = tf.real(stfts)
imag = tf.imag(stfts)
magnitudes = tf.abs(stfts)
phases = tf.atan2(imag, real)
features = tf.concat([magnitudes, phases], axis=2)

sess = tf.Session()
with sess.as_default():
    
    data = np.random.random((1, audio_frames_length))
    tf_results = magnitudes.eval({audio: data})
    
    lr_results = librosa.core.stft(y=data.reshape((-1)),
                                   n_fft=fft_size,
                                   hop_length=hop_size,
                                   win_length=fft_size)
                                   
    lr_results = np.abs(lr_results)
    
    difference = np.abs(tf_results - lr_results.T)
    print(""Differences:\nmin:"", np.min(difference), 
          ""max:"", np.max(difference), 
          ""mean:"", np.mean(difference), 
          ""std:"", np.std(difference))
```

And the expected output from the print would be:

```
Differences:
min: 6.97374e-05 max: 246.904 mean: 2.92715 std: 2.45132
```"
15131,Tensorflow Unit Test: //tensorflow/python/eager:core_test fails,"Tensorflow test failing on power hardware. 

W tensorflow/core/common_runtime/device_mgr.cc:97] Unknown device: GPU:5 all devices: /device:GPU:1, GPU:0, /device:GPU:0,

We are using 2 GPUs.

Any help appreciated"
15129,build error: undefined reference to `clock_gettime',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Linux CentOS 6.9
- **TensorFlow installed from (source or binary)**:
source 
- **TensorFlow version (use command below)**:
master branch: the latest version
- **Python version**: 
2.7
- **Bazel version (if compiling from source)**:
0.8.0
- **GCC/Compiler version (if compiling from source)**:
4.8.2
- **CUDA/cuDNN version**:
No
- **GPU model and memory**:
No
- **Exact command to reproduce**:
bazel build --linkopt=-lrt -c opt --verbose_failures //tensorflow:libtensorflow_cc.so

### Describe the problem
I tried to build the tensor flow c++ lib from the source code, but it failed. 

### Source code / logs
ERROR: /home/baigang/Projects/xylib/thirdparty/tenserflow/package/tensorflow/tensorflow/cc/BUILD:422:1: Linking of rule '//tensorflow/cc:ops/random_ops_gen_cc' failed (Exit 1): gcc failed: error executing command 
  (cd /home/baigang/.cache/bazel/_bazel_baigang/d3e5550086b82aa173767408d0f485e7/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/baigang/bin \
    PWD=/proc/self/cwd \
  /usr/bin/gcc -o bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc '-Wl,-rpath,$ORIGIN/../../../_solib_k8/_U_S_Stensorflow_Scc_Cops_Srandom_Uops_Ugen_Ucc___Utensorflow' -Lbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Scc_Cops_Srandom_Uops_Ugen_Ucc___Utensorflow '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..,-rpath,$ORIGIN/../..' -pthread -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc-2.params)
bazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Scc_Cops_Srandom_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `clock_gettime'
collect2: error: ld returned 1 exit status
Target //tensorflow:libtensorflow_cc.so failed to build
INFO: Elapsed time: 418.738s, Critical Path: 35.11s
FAILED: Build did NOT complete successfully"
15128,GPU memory increases in multiples of batch_size 64 with allow_growth=True,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: ('v1.4.0-14-gb5df90f', '1.4.1')
- **Python version**: 2.7.12
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: 5.4.0-6
- **CUDA/cuDNN version**: V9.0.176
- **GPU model and memory**: V100 AWS P3 8X large instance
- ** Exact command to reproduce**: Inception V3 training as mentioned in `models/research/slim`. `python train_image_classifier.py`


### Describe the problem
GPU memory is increasing in multiples of batch_size of 64. Using 8.9 GB of GPU memory for `batch_size=16` or `batch_size=32` or `batch_size=64`. And using 15.6 GB of GPU memory for `batch_size=96` and `batch_size=128`. I'd like to use `batch_size=96` so allocator won't throw warnings during global_step as it will have 2-3 GB unused.

Is this a feature? Can we change its functioning?"
15126,Is their any java spark api available for using Tensor,
15124,XLA Reshape_test failing for 3rd party platforms,"I have opened a discussion on the XLA dev mailing list, but I think that this counts as an issue since if it isn't fixed then potentially all XLA tests will migrate to being unusable for 3rd party devices.

https://groups.google.com/forum/#!topic/xla-dev/9cY21Hi0s_s

The issue is that the code in reshape_test.cc assumes that any devices which are not CPU/CPU_PARALLEL/GPU will use the bfloat16 format.  This isn't true for the Graphcore device.


"
15122,tensorflow lite: error when convert frozen model to lite format,"Hi,
I build the freeze .pb with the guide at https://github.com/tensorflow/models/tree/master/research/slim 
with the below step:
 
python train_image_classifier.py \
--train_dir /home/ubuntu/train/ \
--dataset_dir /home/ubuntu/vegetables/ \
--dataset_name=vegetables \
--dataset_split_name=train  \
--num_clones=2 \
--clone_on_cpu=True \
--checkpoint_path=/home/ubuntu/check_point/mobilenet_v1_1.0_224.ckpt \
--max_number_of_steps=10 \
--checkpoint_exclude_scopes=MobilenetV1/Logits,MobilenetV1/AuxLogits \
--model_name=mobilenet_v1


python tensorflow/python/tools/freeze_graph.py \
    --input_graph=/home/ubuntu/train/mobilenet_v1_224.pb \
    --input_checkpoint=/home/ubuntu/check_point/mobilenet_v1_1.0_224.ckpt \
    --input_binary=true \
    --output_graph=/home/ubuntu/train/frozen_mobilenet_v1_224.pb \
    --output_node_names=MobilenetV1/Predictions/Reshape_1

NOTE: I download mobilenet_v1_1.0_224.ckpt from http://download.tensorflow.org/models/mobilenet_v1_1.0_224_2017_06_14.tar.gz

But when I convert to lite mode with 

ubuntu@ip-172-31-27-248:~/tensorflow$ bazel-bin/tensorflow/contrib/lite/toco/toco \
  --input_format=TENSORFLOW_GRAPHDEF \
   --input_format=TENSORFLOW_GRAPHDEF \
   --input_file=/home/ubuntu/mobilenet_v1_1.0_224/frozen_mobilenet_v1_224.pb \
   --output_format=TFLITE \
   --output_file=/tmp/mobilenet_v1_1.0_224.lite --inference_type=FLOAT \
   --inference_input_type=FLOAT \
   --input_arrays=input \
   --output_arrays=MobilenetV1/Predictions/Reshape_1 --input_shapes=1,224,224,3
 
2017-12-05 09:53:56.604720: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 336 operators, 502 arrays (0 quantized)
2017-12-05 09:53:56.627922: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 31 operators, 88 arrays (0 quantized)
2017-12-05 09:53:56.628156: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 31 operators, 88 arrays (0 quantized)
2017-12-05 09:53:56.628327: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:312] Total transient array allocated size: 6422528 bytes, theoretical optimal value: 4816896 bytes.
2017-12-05 09:53:56.628487: I tensorflow/contrib/lite/toco/toco_tooling.cc:268] Estimated count of arithmetic ops: 1.14264 billion (note that a multiply-add is counted as 2 ops).
2017-12-05 09:53:56.628653: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Squeeze
Aborted (core dumped)

Pls help me! 

my other question is when I download the pretrain freeze pb from https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_1.0_224_float_2017_11_08.zip 
It's work when I use toco tools. where I can find guide which generate these freeze pb.


Pls Help! 


 





"
15120,[Feature Request] Please make Estimator.export_savedmodel support input types other than tf.Example,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Windows 10
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
1.4.1
- **Python version**: 
3.5.3
- **CUDA/cuDNN version**:
None
- **GPU model and memory**:
None
- **Exact command to reproduce**:

### Describe the problem
I have a model,  I want to export it into SavedModel format by using tf.estimator API, because I'm using this API for training. Unfortunately,tf.estimator.export.build_raw_serving_input_receiver_fn and tf.saved_model.signature_def_utils.classification_signature_def require the input features must be encoded in tf.Example format.

In order to use the ""export_savedmodel"" function for exporting, when writing a custom model_fn for Estimator, I must populate the export_outputs element of the tf.estimator.EstimatorSpec return value.  Each output value must be an ExportOutput object such as tf.estimator.export.ClassificationOutput, tf.estimator.export.RegressionOutput, or tf.estimator.export.PredictOutput. Those three output types only support tf.Example as the input. 

```python
    if (classes is not None
        and not (isinstance(classes, ops.Tensor)
                 and dtypes.as_dtype(classes.dtype) == dtypes.string)):
      raise ValueError('Classification classes must be a string Tensor; '
                       'got {}'.format(classes))
```

Because they will use signature_def_utils.classification_signature_def(or predict_signature_def,...) to build the signature.

Though I may build a new output type by myself, it doesn't. 
As the comment in tensorflow\python\estimator\export\export.py:build_all_signature_defs stated:
""the call to is_valid_signature here should not remove anything else.""
If you really want to remove it, please show me a warning.

### Source code / logs
```python
""""""Convolutional Neural Network Estimator for MNIST, built with tf.layers.""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import os
import sys

import tensorflow as tf

parser = argparse.ArgumentParser()

# Basic model parameters.
parser.add_argument('--batch_size', type=int, default=100,
                    help='Number of images to process in a batch')

parser.add_argument('--model_dir', type=str, default='/tmp/mnist_model',
                    help='The directory where the model will be stored.')


parser.add_argument('--data_format', type=str, default=None,
    choices=['channels_first', 'channels_last'],
    help='A flag to override the data format used in the model. channels_first '
         'provides a performance boost on GPU but is not always compatible '
         'with CPU. If left unspecified, the data format will be chosen '
         'automatically based on whether TensorFlow was built for CPU or GPU.')

_NUM_IMAGES = {
    'train': 50000,
    'validation': 10000,
}

def mnist_model(inputs, mode, data_format):
  """"""Takes the MNIST inputs and mode and outputs a tensor of logits.""""""
  # Input Layer
  # Reshape X to 4-D tensor: [batch_size, width, height, channels]
  # MNIST images are 28x28 pixels, and have one color channel
  inputs = tf.reshape(inputs, [-1, 28, 28, 1])

  if data_format is None:
    data_format = ('channels_first' if tf.test.is_built_with_cuda() else
                   'channels_last')

  if data_format == 'channels_first':
    inputs = tf.transpose(inputs, [0, 3, 1, 2])

  conv1 = tf.layers.conv2d(inputs=inputs,
      filters=32,
      kernel_size=[5, 5],
      padding='same',
      activation=tf.nn.relu,
      data_format=data_format)


  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2,
                                  data_format=data_format)


  conv2 = tf.layers.conv2d(inputs=pool1,
      filters=64,
      kernel_size=[5, 5],
      padding='same',
      activation=tf.nn.relu,
      data_format=data_format)

  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2,
                                  data_format=data_format)


  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])

  # Dense Layer
  # Densely connected layer with 1024 neurons
  # Input Tensor Shape: [batch_size, 7 * 7 * 64]
  # Output Tensor Shape: [batch_size, 1024]
  dense = tf.layers.dense(inputs=pool2_flat, units=1024,
                          activation=tf.nn.relu)

  # Add dropout operation; 0.6 probability that element will be kept
  dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=(mode == tf.estimator.ModeKeys.TRAIN))

  # Logits layer
  # Input Tensor Shape: [batch_size, 1024]
  # Output Tensor Shape: [batch_size, 10]
  logits = tf.layers.dense(inputs=dropout, units=10)
  return logits


def mnist_model_fn(features, labels, mode, params):
  if isinstance(features,dict):
    features = features['image_raw']
  """"""Model function for MNIST.""""""
  logits = mnist_model(features, mode, params['data_format'])

  predictions = {
      'classes': tf.argmax(input=logits, axis=1),
      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')
  }

  if mode == tf.estimator.ModeKeys.PREDICT:
    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,
                                      export_outputs={'class': tf.estimator.export.ClassificationOutput(classes=tf.as_string(predictions['classes']))})  

  loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)

  # Configure the training op
  if mode == tf.estimator.ModeKeys.TRAIN:
    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)
    train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())
  else:
    train_op = None

  accuracy = tf.metrics.accuracy(tf.argmax(labels, axis=1), predictions['classes'])
  metrics = {'accuracy': accuracy}

  # Create a tensor named train_accuracy for logging purposes
  tf.identity(accuracy[1], name='train_accuracy')
  tf.summary.scalar('train_accuracy', accuracy[1])

  return tf.estimator.EstimatorSpec(mode=mode,
      predictions=predictions,
      loss=loss,
      train_op=train_op,
      eval_metric_ops=metrics)

def main(unused_argv):
  # Create the Estimator
  mnist_classifier = tf.estimator.Estimator(model_fn=mnist_model_fn, model_dir=FLAGS.model_dir,
      params={'data_format': FLAGS.data_format})
  image = tf.placeholder(tf.float32,[None])
  mnist_classifier.export_savedmodel(""bb"", tf.estimator.export.build_raw_serving_input_receiver_fn({""image_raw"":image}))  

if __name__ == '__main__':
  tf.logging.set_verbosity(tf.logging.INFO)
  FLAGS, unparsed = parser.parse_known_args()
  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
```"
15119,a  small  problem   in  the  word2vec,"In  the  web  url  “https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py”；

In  the    code  line  123，“buffer[:] = data[:span]” ；
when  I  run  the   wiki data  using  1000  examples（1000 rows），
the  program    says  “sequence index must be integer not slice”，
so  I  changed     “buffer[:] = data[:span]”   to   “buffer.clear()” and  “buffer.extend(data[:span])”，
and  it  works  well。
"
15118,"Building Tensorflow from source failed, compilation error","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat Enterprise Linux Server release 6.9 (Santiago)
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:
- **Python version**:  2.7.13
- **Bazel version (if compiling from source)**:  0.6.1 
- **GCC/Compiler version (if compiling from source)**: 4.4.7
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:  
bazel build --config=opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package

### Describe the problem
The following errors appears at the building stage when I tried to install Tensorflow for CPU from source.   

### Source code / logs
```
WARNING: /home/localuser/tensorflow/tensorflow/core/BUILD:1813:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/localuser/tensorflow/tensorflow/tensorflow.bzl:1100:30.
WARNING: /home/localuser/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.
WARNING: /home/localuser/tensorflow/tensorflow/contrib/learn/BUILD:15:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.
INFO: Found 1 target...
ERROR: /home/localuser/tensorflow/tensorflow/core/grappler/costs/BUILD:112:1: C++ compilation of rule '//tensorflow/core/grappler/costs:robust_stats' failed (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_localuser/88f96db14f5044a661b2d9ab97596b51/execroot/org_tensorflow && \
  exec env - \
    PATH=/opt/jdk1.8.0_144/bin:/home/localuser/bazel-0.6.1/output:/usr/local/MATLAB/R2016a/bin:/Ansys/AnsysEM170/AnsysEM17.0/Linux64:/Ansys/AnsysEM170/LayoutIntegrations17.0/Linux64:/usr/local/bin:/usr/local/netscape:/usr/sbin:/usr/bin:/usr/lib:/bin:/sbin:/etc:/opt/lumerical/fdtd/bin:/lib:.:/root/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/local/bin/python2.7 \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/site-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL_SYCL=0 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-march=native' '-std=c++0x' -MD -MF bazel-out/local-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/tensorflow/core/grappler/costs/robust_stats.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/tensorflow/core/grappler/costs/robust_stats.pic.o' -fPIC -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/grappler/costs/robust_stats.cc -o bazel-out/local-opt/bin/tensorflow/core/grappler/costs/_objs/robust_stats/tensorflow/core/grappler/costs/robust_stats.pic.o).
tensorflow/core/grappler/costs/robust_stats.cc: In function 'std::pair<double, double> tensorflow::grappler::ScaledMedianAbsoluteDeviation(const std::vector<double, std::allocator<double> >&)':
tensorflow/core/grappler/costs/robust_stats.cc:71: error: expected initializer before ':' token
tensorflow/core/grappler/costs/robust_stats.cc:75: error: expected primary-expression before 'return'
tensorflow/core/grappler/costs/robust_stats.cc:75: error: expected ')' before 'return'
tensorflow/core/grappler/costs/robust_stats.cc: In constructor 'tensorflow::grappler::RobustStats::RobustStats(const std::vector<double, std::allocator<double> >&)':
tensorflow/core/grappler/costs/robust_stats.cc:79: error: type 'tensorflow::grappler::RobustStats' is not a direct base of 'tensorflow::grappler::RobustStats'
tensorflow/core/grappler/costs/robust_stats.cc: In function 'double tensorflow::grappler::UpdateHuberMean(const std::vector<double, std::allocator<double> >&, double, double)':
tensorflow/core/grappler/costs/robust_stats.cc:95: error: expected initializer before ':' token
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected primary-expression at end of input
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected ';' at end of input
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected primary-expression at end of input
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected ')' at end of input
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected statement at end of input
tensorflow/core/grappler/costs/robust_stats.cc:92: warning: unused variable 'num_within'
tensorflow/core/grappler/costs/robust_stats.cc:93: warning: unused variable 'sum'
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected '}' at end of input
tensorflow/core/grappler/costs/robust_stats.cc:152: warning: no return statement in function returning non-void
tensorflow/core/grappler/costs/robust_stats.cc: At global scope:
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected '}' at end of input
tensorflow/core/grappler/costs/robust_stats.cc:152: error: expected '}' at end of input
tensorflow/core/grappler/costs/robust_stats.cc:63: warning: 'std::pair<double, double> tensorflow::grappler::ScaledMedianAbsoluteDeviation(const std::vector<double, std::allocator<double> >&)' defined but not used
cc1plus: warning: unrecognized command line option ""-Wno-free-nonheap-object""
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 10.342s, Critical Path: 0.72s
```

### Comments
I checked that it's not a memory issue. 

### Related issues
[#8642](https://github.com/tensorflow/tensorflow/issues/8462)
"
15116,Any other official way(not public in github issues) to report security bug of tensorflow?,"Hi,

I have found a security issue in Tensorflow. An attacker can easily execute arbitary code on victim machine through this issue. I think it has severe secure impact on tensorflow users. So it is not proper to disclosure this issue on github issues publicly before it is fixed.

Is there any other official way to report security issue? I will explain the details.
Thanks."
15115,Wrong result when computing accuracy using tf.metrics.accuracy,"### System information

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 1709
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: Python 3.5.2 :: Anaconda custom (64-bit)

### Describe the problem

I found the result `tf.metrics.accuracy` returns is incorrect when I trained my model. To verify this I wrote a  simple program.

```python
import tensorflow as tf

sess = tf.Session()
labels = tf.placeholder(tf.int32)
predictions = tf.placeholder(tf.int32)
acc, _ = tf.metrics.accuracy(labels, predictions)
my_acc = tf.reduce_mean(tf.cast(tf.equal(labels, predictions), tf.float32))

feed_dict = {
    labels: [1, 2, 3, 4, 5], 
    predictions: [1, 2, 3, 4, 5]
}
sess.run(tf.global_variables_initializer())
sess.run(tf.local_variables_initializer())

sess.run(acc, feed_dict)  # 0.0
sess.run(my_acc, feed_dict)  # 1.0
```

You can see that `acc` and `my_acc` is different and acc is wrong. I double checked [the doc](https://www.tensorflow.org/api_docs/python/tf/metrics/accuracy) and still confused. Is there anything I missed? Thank you."
15114,Compiling CPU version on windows X86,"System Information:
WIN 10
Visual studio 2015
Swigwin 3.0.12
Python 3.5.3
Cmake 3.10.0

Question description:

I am a new one about tensorflow, I used cmake command in cmd just like this:

cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/Programs/Python/Python35/python.exe -DPYTHON_LIBRARIES=D:/Programs/Python/Python35/libs/python35.lib -Dtensorflow_ENABLE_GPU=OFF

and got the x64 vs project, but when I wanted to generate x86 version with similar commnd like:  

cmake .. -A x86 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/Programs/Python/Python35/python.exe -DPYTHON_LIBRARIES=D:/Programs/Python/Python35/libs/python35.lib -Dtensorflow_ENABLE_GPU=OFF

then I got a error:

cmake .. -A x86 -DCMAKE_BUILD_TYPE=Debug -DSWIG_EXECUTABLE=D:/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=D:/Programs/Python/Python35/python.exe -DPYTHON_LIBRARIES=D:/Programs/Python/Python35/libs/python35.lib -Dtensorflow_ENABLE_GPU=OFF
CMake Error at CMakeLists.txt:5 (project):
  Failed to run MSBuild command:

    C:/Program Files (x86)/MSBuild/14.0/bin/MSBuild.exe

  to get the value of VCTargetsPath:


Now I want to ask: does tensorflow support x86 windows? Did anyone build the x86 version once before?  "
15113,compiling CPU version under windows X86,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15108,"error: namespace ""Eigen::half_impl"" has no member ""__half_raw"" when building latest TensorFlow/CUDA 9.0","When trying to build latest TensorFlow for CUDA 9.0/CuDNN 7.0, from today's head

Complete instructions to reproduce are [here](https://github.com/yaroslavvb/tf_build), but basically I followed steps in in [Dockerfile.devel-gpu](https://github.com/tensorflow/tensorflow/blob/c5c642e051f1a7876d099bfcd9f8a2ecaf7227b8/tensorflow/tools/docker/Dockerfile.devel-gpu) to install dependencies, and then did `bazel build -c opt --config=cuda`

Here are the errors

```
INFO: From Compiling tensorflow/stream_executor/cuda/cuda_blas.cc:
tensorflow/stream_executor/cuda/cuda_blas.cc: In function 'cudaDataType_t perftools::gputools::cuda::{anonymous}::CUDAComputationType(perftools::gputools::blas::ComputationType)':
tensorflow/stream_executor/cuda/cuda_blas.cc:527:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
INFO: From Compiling tensorflow/core/kernels/dense_to_sparse_batch_dataset_op.cc:
tensorflow/core/kernels/dense_to_sparse_batch_dataset_op.cc: In member function 'virtual void tensorflow::{anonymous}::DenseToSparseBatchDatasetOp::MakeDataset(tensorflow::OpKernelContext*, tensorflow::DatasetBase*, tensorflow::DatasetBase**)':
tensorflow/core/kernels/dense_to_sparse_batch_dataset_op.cc:83:71: warning: 'batch_size' may be used uninitialized in this function [-Wmaybe-uninitialized]
         : batch_size_(batch_size), row_shape_(row_shape), input_(input) {
                                                                       ^
tensorflow/core/kernels/dense_to_sparse_batch_dataset_op.cc:41:11: note: 'batch_size' was declared here
     int64 batch_size;
           ^
INFO: From Compiling tensorflow/core/kernels/histogram_op_gpu.cu.cc:
./tensorflow/core/util/cuda_kernel_helper.h(109): error: namespace ""Eigen::half_impl"" has no member ""__half_raw""

./tensorflow/core/util/cuda_kernel_helper.h(109): error: expected a "")""

./tensorflow/core/util/cuda_kernel_helper.h(110): error: namespace ""Eigen::half_impl"" has no member ""__half_raw""

./tensorflow/core/util/cuda_kernel_helper.h(113): error: namespace ""Eigen::half_impl"" has no member ""__half_raw""

./tensorflow/core/util/cuda_kernel_helper.h(113): error: expected a "";""

./tensorflow/core/util/cuda_kernel_helper.h(119): error: namespace ""Eigen::half_impl"" has no member ""__half_raw""

./tensorflow/core/util/cuda_kernel_helper.h(119): error: expected a "")""

./tensorflow/core/util/cuda_kernel_helper.h(120): error: namespace ""Eigen::half_impl"" has no member ""__half_raw""

./tensorflow/core/util/cuda_kernel_helper.h(123): error: namespace ""Eigen::half_impl"" has no member ""__half_raw""

./tensorflow/core/util/cuda_kernel_helper.h(123): error: expected a "";""

10 errors detected in the compilation of ""/tmp/tmpxft_000137d9_00000000-6_histog

```"
15105,Using tfdbg with Monitored Session,"### System information
- I am using a modified version of  [CIFAR10 tutorial](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10) TensorFlow.
- CentOS Linux release 7.3.1611
- TensrFlow from Source
- TensorFlow v1.3
-  Python 2.7

### Describe the problem
Hello,

I see that I can not use tfdbg with Monitored session. That is if I try to wrap `mon_sess = tf_debug.LocalCLIDebugWrapperSession(mon_sess)` where `mon_sess` is `tf.train.MonitoredTrainingSession(` I get the following error:

`TypeError: Expected type <class 'tensorflow.python.client.session.BaseSession'>; got type <class 'tensorflow.python.training.monitored_session.MonitoredSession'>`

Can there be a support from Debugger with Monitored Sessions?"
15104,Building tensorflow from the sourcefile,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Redhat
- **TensorFlow installed from (source or binary)**:
source
- **TensorFlow version (use command below)**:
1.0
- **Python version**: 
2.7.14
- **Bazel version (if compiling from source)**:

- **GCC/Compiler version (if compiling from source)**:
4.8.5
- **CUDA/cuDNN version**:
8/5
- **GPU model and memory**:

- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Getting the following error:
```
ERROR: /home/amalik/tensorflow/tensorflow/tools/test/BUILD:81:1: Traceback (most recent call last):
	File ""/home/amalik/tensorflow/tensorflow/tools/test/BUILD"", line 81
		tf_cc_logged_benchmark(name = ""cast_op_benchmark"", target..."")
	File ""/home/amalik/tensorflow/tensorflow/tools/test/performance.bzl"", line 23, in tf_cc_logged_benchmark
		list((set(tags) + set([""benchmark-tes...""])))
	File ""/home/amalik/tensorflow/tensorflow/tools/test/performance.bzl"", line 23, in list
		set(tags)
The `set` constructor for depsets is deprecated and will be removed. Please use the `depset` constructor instead. You can temporarily enable the deprecated `set` constructor by passing the flag --incompatible_disallow_set_constructor=false.
ERROR: package contains errors: tensorflow/tools/test.
ERROR: /home/amalik/tensorflow/tensorflow/tools/test/BUILD:86:1: Traceback (most recent call last):
	File ""/home/amalik/tensorflow/tensorflow/tools/test/BUILD"", line 86
		tf_py_logged_benchmark(name = ""rnn_op_benchmark"", target ..."")
	File ""/home/amalik/tensorflow/tensorflow/tools/test/performance.bzl"", line 52, in tf_py_logged_benchmark
		tf_cc_logged_benchmark(name = name, target = target, benchm..., <2 more arguments>)
	File ""/home/amalik/tensorflow/tensorflow/tools/test/performance.bzl"", line 23, in tf_cc_logged_benchmark
		list((set(tags) + set([""benchmark-tes...""])))
	File ""/home/amalik/tensorflow/tensorflow/tools/test/performance.bzl"", line 23, in list
		set(tags)
The `set` constructor for depsets is deprecated and will be removed. Please use the `depset` constructor instead. You can temporarily enable the deprecated `set` constructor by passing the flag --incompatible_disallow_set_constructor=false.
ERROR: /home/amalik/tensorflow/tensorflow/core/kernels/BUILD:58:14: Traceback (most recent call last):
	File ""/home/amalik/tensorflow/tensorflow/core/kernels/BUILD"", line 53
		config_setting(name = ""xsmm_backward"", values = {...""})
	File ""/home/amalik/tensorflow/tensorflow/core/kernels/BUILD"", line 58, in config_setting
		{""define"": ""tensorflow_xsmm=1"", ""define"": ""tensorflow_xsmm_backward=1""}
Duplicated key ""define"" when creating dictionary.
ERROR: package contains errors: tensorflow/core/kernels.
ERROR: error loading package 'tensorflow/core/kernels': Package 'tensorflow/core/kernels' contains errors.
```

Note: Tried other plateforms but could get any reply. I am not sure its a bug or else. I apologize if I am using the wrong forum. I am trying to install tensorflow from source so I can use MPI


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15103,No GPU OpKernel for tf.exp() operation for Complex64,"I am running tensorflow 1.4.0 from nightly build ('v1.3.0-rc1-5297-g4b7d79b6ea'  on ubuntu 16.04). I've had success working in eager mode (great job with this guys!) however I think I found a small bug:

It seems that there is no OpKernel on device='GPU'  for the tf.exp() operation applied to complex numbers in eager mode.  This can be reproduced with the below code:

```
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution()

with tf.device('/gpu:0'):
  g = tf.spectral.rfft(tf.ones(64))
  
  tf.exp(g)
```
which results in
```NotFoundError: No registered 'Exp' OpKernel for GPU devices compatible with node Exp = Exp[T=DT_COMPLEX64](dummy_input)
	 (OpKernel was found, but attributes didn't match)
	.  Registered:  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
 [Op:Exp]
```

a more practical example that would lead to this same error:

```
import tensorflow as tf
import tensorflow.contrib.eager as tfe

tfe.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)

frame_length=256
frame_step=64
n_mels = 64
sr=16000
filename = 'path/to/a.wav'

some_signal = tf.contrib.ffmpeg.decode_audio(tf.read_file(filename), 
                                     file_format='wav', 
                                     samples_per_second=16000, 
                                     channel_count=1)

with tf.device('/gpu:0'):
  stft = tf.contrib.signal.stft(tf.transpose(some_signal), frame_length=frame_length, 
                                  frame_step=frame_step, fft_length=frame_length)

  linear_to_mel_weight_matrix = tf.contrib.signal.linear_to_mel_weight_matrix(
      n_mels, 1+frame_length//2, sr)

  magnitude_spectrograms = tf.abs(stft)
  log_mel_spec = tf.log(1e-6+ tf.tensordot(magnitude_spectrograms,
                                           linear_to_mel_weight_matrix, 
                                           axes = [[2], [0]]))

  mfccs = tf.contrib.signal.mfccs_from_log_mel_spectrograms(log_mel_spec)
```

Keeping operations on CPU works just fine but I figured this would be easy to implement for GPU as well. Thanks
"
15102,Documentation required for SetIsStateful() method in OP registration,"There are some examples with custom ops that use SetIsStateful() method during registration, e.g. https://www.tensorflow.org/extend/new_data_formats

But there is no documentation about that method."
15096,"java.lang.UnsatisfiedLinkError: No implementation found for void com.ppdai.tensorflow.tracking.ObjectTracker.initNative(int, int, boolean)","recently i begin to learn and use tensorflow but some errors i don't know why,  help me please, error as follow:

Process: com.ppdai.tensorflow, PID: 4226
                                                 java.lang.UnsatisfiedLinkError: No implementation found for void com.ppdai.tensorflow.tracking.ObjectTracker.initNative(int, int, boolean) (tried Java_com_ppdai_tensorflow_tracking_ObjectTracker_initNative and Java_com_ppdai_tensorflow_tracking_ObjectTracker_initNative__IIZ)
                                                     at com.ppdai.tensorflow.tracking.ObjectTracker.initNative(Native Method)
                                                     at com.ppdai.tensorflow.tracking.ObjectTracker.init(ObjectTracker.java:257)
                                                     at com.ppdai.tensorflow.tracking.ObjectTracker.getInstance(ObjectTracker.java:220)
                                                     at com.ppdai.tensorflow.tracking.MultiBoxTracker.onFrame(MultiBoxTracker.java:211)
                                                     at com.ppdai.tensorflow.DetectorActivity.processImage(DetectorActivity.java:250)
                                                     at com.ppdai.tensorflow.CameraActivity.onPreviewFrame(CameraActivity.java:149)
                                                     at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1285)
                                                     at android.os.Handler.dispatchMessage(Handler.java:111)
                                                     at android.os.Looper.loop(Looper.java:194)
                                                     at android.app.ActivityThread.main(ActivityThread.java:5868)
                                                     at java.lang.reflect.Method.invoke(Native Method)
                                                     at java.lang.reflect.Method.invoke(Method.java:372)
                                                     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1019)
                                                     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:814)

1、firstly compile aar from jcenter 1.4.0
2、secondly add related so to jniLibs 
      libtensorflow_demo.so
      libtensorflow_inference.so
      libandroid_tensorflow_lib.lo
      benchmark_model
3、then use offical demo code to test tensorflow detect function, error comes.

what will i can do to solve this problem?

i have add related so "
15093,tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Sub,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Linux Ubuntu 17.04
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:1.4.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0/6.0
- **GPU model and memory**:GTX 1060 with 6GB memory
- **Exact command to reproduce**:bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/wh/gitmodel/tensorflow/wh/frozen_1.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=/home/wh/gitmodel/tensorflow/wh/frozen_lite.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=image_1 --output_arrays=InferenceTower/output6 --input_shapes=1,320,480,3

### Describe the problem
I am trying to convert a graph from .pb to .lite format using toco, but I get this error:
2017-12-04 20:14:38.202653: F tensorflow/contrib/lite/toco/tflite/export.cc:192] Unsupported operator: Sub
I think Sub is the basic op, Lite shoud support it. Is it right?"
15091,"GatherNd InvalidArgumentError: flat indices[8, :] = [8, -1] does not index into param","### System information

- **OS Platform and Distribution**: Ubuntu 17.10 (Linux-4.13.0-17-generic-x86_64-with-debian-stretch-sid)
- **TensorFlow installed from**: binary
- **TensorFlow version**: v1.3.0-rc2-20-g0787eee 1.3.0 (same on 1.4.0)
- **Python version**: 3.6.3
- **GPU model and memory**: N/A (CPU only)
- **Numpy version:** 1.13.3
- **Bazel version**: N/A
- **CUDA/cuDNN version**: N/A
- **C++ compiler version**: (Ubuntu 7.2.0-8ubuntu3) 7.2.0
- **Have I written custom code**: Yes
- **Exact command to reproduce**: There is no single command. The error arises when trying to fetch a TensorFlow tensor. Please see the description below.

### Describe the problem

I am training a recurrent neural network (RNN) whereby I give it variable-length sequences of random steps in two dimensions and train it to recognize the quadrant in which the random walker ended up. This RNN works fine on a Windows machine with GPU (all other specs are otherwise the same as above). However, on a Linux machine with CPU only, I get an error which mysteriously traces back to a dimensionality hiccup with `GatherNd`. 

The code for the full RNN is too convoluted to post, but as you can see from below, I am printing out the fetches to two tensors `tf_weights` and `tf_last` at each iteration of the batching. (In this case the training data is consumed one batch at a time for a total of 28 batches). The batches are very basic loops so you'd think that if a fetch works in one iteration of the loop it should also work for the next. This is indeed the case for `tf_weights` but not for `tf_last` which, for no apparent reason, fails to evaluate at batch 7/28. `tf_last` can be traced to a `GatherNd` operation.

I thoroughly inspected the data and it looks fine. _Please keep in mind that my code does work under Windows with GPU with all other specs remaining the same, so it's hard to conceive of a bug from within the code itself._

### Source code

```
import tensorflow as tf

graph = tf.Graph()

with graph.as_default():

    tf_features = tf.placeholder(
            tf.float32, [batch_size, max_seq_len, input_dim], 
            name = 'tf_features')

    tf_targets = tf.placeholder(
            tf.float32, [batch_size, target_len],
            name = 'tf_targets')

    tf_seq_len = tf.placeholder(
            tf.int32, [batch_size],
            name = 'tf_seq_len')

    tf_cell = 'tf.contrib.rnn.'+cell_type+'('+str(num_hidden)+')'
    tf_cell = eval(tf_cell)

    tf_output, tf_state = tf.nn.dynamic_rnn(
            tf_cell, tf_features, sequence_length = tf_seq_len, 
            dtype = tf.float32)
  
    tf_output = tf_output[:, :, :num_hidden]
           
    tf_last = tf.gather_nd(
            tf_output, 
            tf.stack([tf.range(batch_size), tf_seq_len-1], axis = 1), # batch_size
            name = 'tf_last')
```

### Logs

```
---------------- RUN 0/0
 ---------------- FOLD 0/2
  ---------------- TRAIN
  Epoch 0
  - Optimizing optimize
   ---------------- BATCH 0/28 [0, 50], len_data = 1499
   *** tf_weights: -0.563565
   *** tf_last: -0.192192
   ---------------- BATCH 1/28 [50, 100], len_data = 1499
   *** tf_weights: -0.553565
   *** tf_last: -0.0799878
   ---------------- BATCH 2/28 [100, 150], len_data = 1499
   *** tf_weights: -0.546777
   *** tf_last: -0.118384
   ---------------- BATCH 3/28 [150, 200], len_data = 1499
   *** tf_weights: -0.538511
   *** tf_last: -0.142531
   ---------------- BATCH 4/28 [200, 250], len_data = 1499
   *** tf_weights: -0.529593
   *** tf_last: -0.147268
   ---------------- BATCH 5/28 [250, 300], len_data = 1499
   *** tf_weights: -0.520294
   *** tf_last: -0.014847
   ---------------- BATCH 6/28 [300, 350], len_data = 1499
   *** tf_weights: -0.510754
   *** tf_last: -0.094138
   ---------------- BATCH 7/28 [350, 400], len_data = 1499
   *** tf_weights: -0.504503
   *** Failed to evaluate tf_last
Traceback (most recent call last):

  File ""<ipython-input-25-49e8720a879a>"", line 1, in <module>
    runfile('/home/ala/Python/domains/main.py', wdir='/home/ala/Python/domains')

  File ""/home/ala/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 710, in runfile
    execfile(filename, namespace)

  File ""/home/ala/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 101, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""/home/ala/Python/domains/main.py"", line 166, in <module>
    metrics_valid = RNN_object.validate(data_train, KFolds)

  File ""/home/ala/Python/domains/classifiers.py"", line 727, in validate
    reinitialize = True))

  File ""/home/ala/Python/domains/classifiers.py"", line 366, in train
    self.optimize(data)

  File ""/home/ala/Python/domains/classifiers.py"", line 1102, in optimize
    optimized_driving_metric = self.evaluate(data, driving_metric)

  File ""/home/ala/Python/domains/classifiers.py"", line 1796, in evaluate
    evaluated_tf_var = self.sess.run(eval(tf_var), feed_dict)

  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)

  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)

  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)

  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)

InvalidArgumentError: flat indices[8, :] = [8, -1] does not index into param (shape: [50,300,2]).
	 [[Node: tf_last = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](strided_slice_2, stack)]]

Caused by op 'tf_last', defined at:
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/spyder/utils/ipython/start_kernel.py"", line 245, in <module>
    main()
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/spyder/utils/ipython/start_kernel.py"", line 241, in main
    kernel.start()
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py"", line 477, in start
    ioloop.IOLoop.instance().start()
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py"", line 888, in start
    handler_func(fd_obj, events)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py"", line 277, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 283, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 235, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py"", line 399, in execute_request
    user_expressions, allow_stdin)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py"", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2728, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2856, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-25-49e8720a879a>"", line 1, in <module>
    runfile('/home/ala/Python/domains/main.py', wdir='/home/ala/Python/domains')
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 710, in runfile
    execfile(filename, namespace)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/spyder/utils/site/sitecustomize.py"", line 101, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)
  File ""/home/ala/Python/domains/main.py"", line 109, in <module>
    RNN_object.define(data_test)
  File ""/home/ala/Python/domains/classifiers.py"", line 1514, in define
    name = 'tf_last')
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1338, in gather_nd
    name=name)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/ala/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): flat indices[8, :] = [8, -1] does not index into param (shape: [50,300,2]).
	 [[Node: tf_last = GatherNd[Tindices=DT_INT32, Tparams=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](strided_slice_2, stack)]]
```"
15090,RNNDROP?,"Has anyone implemented RNNDROP (https://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf) in tensorflow?
According to the paper this method show good performances in speech recognition tasks."
15089,Error when run label_image --graph=/tmp/quantized_graph.pb after quantized model ,"tensorflow:1.4.0
I followed the command line from tensorflow/tensorflow/docs_src/performance/quantization.md 
ran the following command is ok and  produce a new model quantized_graph.pb:
  bazel build tensorflow/tools/graph_transforms:transform_graph
  bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
  --in_graph=tensorflow/examples/label_image/data/inception_v3_2016_08_28_frozen.pb \
  --out_graph=/tmp/quantized_graph.pb \
  --inputs=input \
  --outputs=InceptionV3/Predictions/Reshape_1 \
  --transforms='add_default_attributes strip_unused_nodes(type=float, shape=""1,299,299,3"")
    remove_nodes(op=Identity, op=CheckNumerics) fold_constants(ignore_errors=true)
    fold_batch_norms fold_old_batch_norms quantize_weights quantize_nodes
    strip_unused_nodes sort_by_execution_order'

But there is a problem when  I was running with command:
  bazel build tensorflow/examples/label_image:label_image
  bazel-bin/tensorflow/examples/label_image/label_image \
  --graph=/tmp/quantized_graph.pb    (Else: it worked if I replace quantized_graph.pb with inception_v3_2016_08_28_frozen.pb here.)
The error info is:
  2017-12-04 08:27:02.891427: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op:    ""DenseToSparseBatchDataset"" device_type: ""CPU""') for unknown op: DenseToSparseBatchDataset
2017-12-04 08:27:02.891520: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""GroupByWindowDataset"" device_type: ""CPU""') for unknown op: GroupByWindowDataset
2017-12-04 08:27:02.891562: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""IgnoreErrorsDataset"" device_type: ""CPU""') for unknown op: IgnoreErrorsDataset
2017-12-04 08:27:02.891636: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""DatasetToSingleElement"" device_type: ""CPU""') for unknown op: DatasetToSingleElement
2017-12-04 08:27:02.891686: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""SerializeIterator"" device_type: ""CPU""') for unknown op: SerializeIterator
2017-12-04 08:27:02.891712: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""DeserializeIterator"" device_type: ""CPU""') for unknown op: DeserializeIterator
2017-12-04 08:27:02.891733: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""MapAndBatchDataset"" device_type: ""CPU""') for unknown op: MapAndBatchDataset
2017-12-04 08:27:02.891777: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""ParallelInterleaveDataset"" device_type: ""CPU""') for unknown op: ParallelInterleaveDataset
2017-12-04 08:27:02.891805: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""ScanDataset"" device_type: ""CPU""') for unknown op: ScanDataset
2017-12-04 08:27:02.891825: E tensorflow/core/framework/op_kernel.cc:1142] OpKernel ('op: ""SqlDataset"" device_type: ""CPU""') for unknown op: SqlDataset
2017-12-04 08:27:02.901109: E tensorflow/examples/label_image/main.cc:327] Invalid argument: Node 'InceptionV3/InceptionV3/Conv2d_1a_3x3/BatchNorm/batchnorm/mul_eightbit/input__port__0/reduction_dims': Unknown input node '^input:0'
how should I fix it?

"
15088,Make a State-ful LSTM with data input from TF Dataset,"#14906 
This is to reference a closed issue.
Thanks for @mrry suggestion on using Dataset.flat_map to slice the input signal sequence.
However, how could we know the beginning and ending of the original sequence after sliced?
And how could we reset the LSTM state so that we can make a state-ful LSTM?
Thanks!"
15087,Understanding LSTM cell Kernel values,"Hi all,

I want to understand better those values in LSTM cell Kernel values extracted from:
<tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(97, 280) dtype=float32_ref>
from tf.trainable_variables()

My model is very simple, input is a 27 element vector at each time step where the sequence length can be variable. The model is one layer LSTM model with 70 hidden states. 
```
        def lstm_cell():
            cell = tf.nn.rnn_cell.LSTMCell(num_units=state_size, state_is_tuple=True)
            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropKeepRate)
            return cell
        cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell() for _ in range(num_layers)], state_is_tuple=True)
        
```

So that is probably why the LSTM kernel is a matrix of 97 rows (27 input features and 70 hidden states). As to the columns, I can clearly see four groups by the pattern of values. I guess each group is consist of 70 columns, so totally 4 groups.

So my guess is that this LSTM kernel, extracted from tf.trainable_variables(), maps input and previous hidden states to current hidden states in order of forget, input, update cell states and output. However, it is hard time for me to figure out the correspondence of these gates and their matrices with the Kernel matrix extracted from tf.trainable_variables().

Could somebody help? Thanks!


---------------------
Update:
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7
TensorFlow installed from (source or binary): from pip
TensorFlow version (use command below): 1.3
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 8.0, 6.1
GPU model and memory: k2200"
15086,ctc_loss value problem,"------------------------
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 64bit
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.0
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None

### Describe the problem
I used the source code below to calculate ctc loss. The logit and target should extremely have no loss between them. But the tf.nn.ctc_loss return 1.91309595. What's the meaning of the tf ctc_loss result? 
But I use my custom ctc loss function, which shows the loss is nearly zero.

### Source code / logs

import numpy as np
import tensorflow as tf
logit = np.array([[[0.00001, 0.9999, 0.00001, 0.00001], [0.9999, 0.00001, 0.00001, 0.00001], [0.00001, 0.00001, 0.9999, 0.00001]]])
logit = tf.constant(logit, dtype='float32')
target = tf.SparseTensor(indices=[[0, 0], [0, 2]], values=[1, 2], dense_shape=[1, 3])
seq = tf.constant(np.array([3]))
loss_tf = tf.nn.ctc_loss(target, logit, seq, time_major=False, ctc_merge_repeated=True)
sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
print(loss_tf.eval())
"
15084,calculation gradients of tf.nn.embedding_lookup,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**:1.3.0
- **Python version**: 2.7

### Source code / logs
import tensorflow as tf
types_lookup_table = tf.get_variable(""types_lookup_table"", shape=[234, 10],
                                     initializer=tf.random_normal_initializer(0, 1), dtype=tf.float32,
                                     trainable=True)
embedding_types = tf.nn.embedding_lookup(types_lookup_table,[[2,3,4],[1,2,3]])
opt = tf.train.GradientDescentOptimizer(0.1)
gradients = tf.gradients(embedding_types, xs=types_lookup_table)
train = opt.apply_gradients([(gradients[0], types_lookup_table)])

with tf.Session() as sess:
    tf.global_variables_initializer().run()
    h = sess.run(gradients)
    print(sess.run(train))                                                                              #right
    print(sess.run(opt.apply_gradients([(h[0],types_lookup_table)]))).    # wrong

### Describe the problem
I tried to calculate the gradients of tf.nn.embedding_lookup, but the result shown is an IndexedSliceValue with 3 elements
<img width=""1250"" alt=""2017-12-04 9 23 45"" src=""https://user-images.githubusercontent.com/10001692/33532464-ec59088e-d8d4-11e7-9c08-d53c6d87abf5.png"">
however the corresponding gradient(without sess.run) is an indexSliceValue with 1 elements.I don't know why.
<img width=""1226"" alt=""2017-12-04 9 27 31"" src=""https://user-images.githubusercontent.com/10001692/33532533-6aa0a5bc-d8d5-11e7-9b0d-69a950cb5fb0.png"">

And therefore I can't sess.run(opt.apply_gradients([(h[0],types_lookup_table)]) because the shape of calculation value doesn't match the shape of types_lookup_table, however, when I didn't calculate the intermediate value, and directly 
sess.run(train) (ps:train = opt.apply_gradients([(gradients,types_lookup_table)]))
there is no problem.

But I need to calculate the intermediate value and do an add. I don't know how.
Thanks

"
15082,getting attribute error,"I executed the code and got this error-- 
File ""new1.py"", line 131, in main
    classifier = tf.estimator.Estimator(model_fn=model_fn)
AttributeError: 'module' object has no attribute 'estimator'

pls help
"
15079,could softmax_cross_entropy_with_logits's  label  has many 1.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Mac 10.13.1
- **TensorFlow installed from (source or binary)**:pip
- **TensorFlow version (use command below)**:v1.3.0-rc1-2456-g7abd587 1.4.0-dev20170922
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
```
import numpy as np
import tensorflow as tf

a = np.array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0])
# b = np.array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0])  
b = np.array([0.0, 1.0, 1.0, 0.0, 1.0, 0.0])
sess = tf.Session()
print(str(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels=b, logits=a))))
```
I think it maybe should throw a warn. Because the softmax_cross_entropy_with_logits's labels should not accept the label which has many 1.

If we should fix it. could you let me try to fix it ?I want to try, thanks.
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15077,The sequence of session.run and control_dependencies?,"See three examples:

```python
import tensorflow as tf

x = tf.constant(1.0)
x = tf.Print(x, ['x'])
y = tf.constant(2.0)
y = tf.Print(y, ['y'])
z = tf.constant(3.0)
z = tf.Print(z, ['z'])

with tf.Session() as sess:
    print(sess.run([x,y,z]))
```

The sequence of output of `tf.Print` is indeterminate, which means `sess.run` don't executes tensors from left to right.

```python
import tensorflow as tf

x = tf.constant(1.0)
x = tf.Print(x, ['x'])
y = tf.constant(2.0)
y = tf.Print(y, ['y'])
with tf.control_dependencies([x, y]):
    z = tf.constant(3.0)
    z = tf.Print(z, ['z'])

with tf.Session() as sess:
    print(sess.run(z))
```

The sequence  of `x` and `y` is indeterminate, which means `control_dependencies` don't executes tensors from left to right.

```python
import tensorflow as tf

x = tf.constant(1.0)
x = tf.Print(x, ['x'])
y = tf.constant(2.0)
y = tf.Print(y, ['y'])
d = tf.constant(3.0)
d = tf.Print(d, ['d'])
with tf.control_dependencies([x, y]):
    z = tf.add(d, 3.)
    z = tf.Print(z, ['z'])

with tf.Session() as sess:
    print(sess.run(z))
```

The sequence of `x`, `y` and `d` is indeterminate.

Is it intentional behavior or bug?  I find that if the sequence is indeterminate, the program may get different result.


Another example I can't explain:

```python
import tensorflow as tf

x = tf.placeholder(tf.float32, [])
y = tf.Variable(2.)
op = tf.assign(y, x)
op = tf.Print(op, ['op'])

with tf.control_dependencies([op]):
    q = tf.Print(y, [y])


with tf.Session() as sess:
    tf.global_variables_initializer().run()
    print(sess.run([q], feed_dict={x: -1.0}))
```

The `[op]` is printed before `[y]`, but `q=2.0`, why? If `op` is executed before `y`, y will be assigned by `x`, which means `y=-1.0`, and `q` should be `-1.0`.

"
15076,the source code to compile  about tensorflow1.1.0,"I am very distressed~~~
I need some help ~~~~

I refer to ""TensorFlow Bindings for H2O.ai""
I execute "" ./gradlew clean tensorflowCompile"",but always has error,likes
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [http://bazel-mirror.storage.googleapis.com/github.com/bazelbuild/rules_closure/archive/5ca1dab6df9ad02050f7ba4e816407f88690cf7d.tar.gz, https://github.com/bazelbuild/rules_closure/archive/5ca1dab6df9ad02050f7ba4e816407f88690cf7d.tar.gz] to /root/.cache/bazel/_bazel_root/c0282f68c3c9fe7828209fa3ece89ea6/external/io_bazel_rules_closure/5ca1dab6df9ad02050f7ba4e816407f88690cf7d.tar.gz: Checksum was 5afc2087ab53b160fb58fde30339a2c2826c1a171404b7b8ff7227d5ebc8225c but wanted 60fc6977908f999b23ca65698c2bb70213403824a84f7904310b6000d78be9ce. :deepwater-tensorflow:tensorflowCompile FAILED
errors with checksum
how can I do ,fix this problem
how can I checksum disabled

please ~~~~
thanks"
15075,CUDA_ERROR_LAUNCH_FAILED with TensorFlow example,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, this error happens when using TensorFlow example ""mnist_deep.py"". Modified the file to go for 1.000 iterations instead of the default 20.000 because it took a long time to finish, everything else is the same.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 64-bit
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v1.3.0-0-g9e76bf3 1.3.0
- **Python version**: Python 3 (Though the issue persists with python 2.7)
- **Bazel version (if compiling from source)**: bazel-0.5.2-dist
- **GCC/Compiler version (if compiling from source)**: GCC 5.4.0 20160609
- **CUDA/cuDNN version**: CUDA: 8.0 cuDNN: 6.0
- **GPU model and memory**: NVIDIA Tegra X2 8GB
- **Exact command to reproduce**: python3 mnist_deep.py

I am using the Nvidia Jetson TX2 developer kit with Jetpack 3.1 (The architecture is aarch64). I have tried installing Tensorflow for Python 2 and 3, but the issue persists with both installations.

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I had no problems installing from source for either Python 2.7 and 3. When executing ""mnist_deep.py"" I get a CUDA_ERROR_LAUNCH_FAILED error. Since I had no problems during install, I believe there is something wrong with communication between Tensorflow and CUDA, which is why I'm posting here.

I had no problems excuting ""mnist_softmax.py"", and so the issue seem to be related to more sophisticated CNNs.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

This is the terminal output:
`nvidia@tegra-ubuntu:~/Desktop/tensorflow-r1.3/tensorflow/examples/tutorials/mnist$ ./mnist_deep.py
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
Saving graph to: /tmp/tmpyJvseo
2017-12-02 00:56:23.092487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:857] ARM64 does not support NUMA - returning NUMA node zero
2017-12-02 00:56:23.092610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: NVIDIA Tegra X2
major: 6 minor: 2 memoryClockRate (GHz) 1.3005
pciBusID 0000:00:00.0
Total memory: 7.67GiB
Free memory: 5.76GiB
2017-12-02 00:56:23.092659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-02 00:56:23.092684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-02 00:56:23.092710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0)
step 0, training accuracy 0.04
step 100, training accuracy 0.86
step 200, training accuracy 0.96
step 300, training accuracy 0.94
step 400, training accuracy 0.86
step 500, training accuracy 0.92
step 600, training accuracy 0.96
step 700, training accuracy 0.96
step 800, training accuracy 0.96
step 900, training accuracy 1
2017-12-02 00:57:17.461035: E tensorflow/stream_executor/cuda/cuda_driver.cc:1068] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.461146: E tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.461188: E tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
Traceback (most recent call last):
  File ""./mnist_deep.py"", line 177, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""./mnist_deep.py"", line 169, in main
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 541, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 4085, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 895, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1321, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: No algorithm worked!
     [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](reshape/Reshape, conv1/Variable/read)]]
     [[Node: Mean_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_79_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'conv1/Conv2D', defined at:
  File ""./mnist_deep.py"", line 177, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""./mnist_deep.py"", line 138, in main
    y_conv, keep_prob = deepnn(x)
  File ""./mnist_deep.py"", line 64, in deepnn
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File ""./mnist_deep.py"", line 106, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 397, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 767, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): No algorithm worked!
     [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](reshape/Reshape, conv1/Variable/read)]]
     [[Node: Mean_1/_7 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_79_Mean_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

2017-12-02 00:57:17.738653: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.738769: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.738800: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
2017-12-02 00:57:17.738824: E tensorflow/stream_executor/event.cc:33] error destroying CUDA event in context 0x3372070: CUDA_ERROR_LAUNCH_FAILED
nvidia@tegra-ubuntu:~/Desktop/tensorflow-r1.3/tensorflow/examples/tutorials/mnist$`
"
15074,"When execute ""bash tensorflow/contrib/lite/build_ios_universal_lib.sh"", it gives the error: tensorflow/tensorflow/contrib/lite/ios_makefile.inc:2: *** missing separator.  Stop.","### System information
- **Install problem**:
- **Darwin MacBook-Pro-2.local 16.7.0 Darwin Kernel Version 16.7.0, xnu-3789.71.6~1/RELEASE_X86_64 x86_64**:
- **TensorFlow installed from source**:
- **v1.0.0-rc2-15-g47bba63-dirty 1.0.0**:
- **Python 3.6.0 :: Anaconda custom (x86_64)**: 
- **Bazel version (None)**:
- **Apple LLVM version 9.0.0 (clang-900.0.37)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

"
15073,"when execute ""bash tensorflow/contrib/lite/build_ios_universal_lib.sh"", it has the following error: tensorflow/tensorflow/contrib/lite/ios_makefile.inc:2: *** missing separator.  Stop.","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15072,Have to reinstall numpy,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Windows 10
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**:1.4.0
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Before I installed tensorflow, I have installed numpy through anaconda. But after I run the command provided in the website (https://www.tensorflow.org/install/install_windows), it automatically reinstalled numpy. Then when I import numpy or tensorflow, I got an import error ""cannot import name 'add_newdocs'"" which is required when importing numpy. I have to reinstall my numpy through anaconda to solve this problem. 

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15071,Tensorflow build fails with --config=sycl,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 17.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.3
Python version: 2.7
Bazel version (if compiling from source): 0.5.1
GCC/Compiler version (if compiling from source): 6.0.3
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:

> bazel build -c opt --config=sycl //tensorflow:libtensorflow_cc.so

**Logs**

> 
> ERROR: /home/ashok/Ashok/tensorflow-c++/tensorflow/core/kernels/BUILD:3355:1: C++ compilation of rule '//tensorflow/core/kernels:sendrecv_ops' failed: computecpp failed: error executing command external/local_config_sycl/crosstool/computecpp -fPIE -fno-omit-frame-pointer -Wall -msse3 -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF ... (remaining 119 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1
> In file included from tensorflow/core/kernels/sendrecv_ops.cc:16:
> In file included from ./tensorflow/core/kernels/sendrecv_ops.h:19:
> In file included from ./tensorflow/core/framework/op_kernel.h:19:
> In file included from /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:55:
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:1404:14: error: no matching constructor for initialization of 'tuple<const tensorflow::Status &&, const tensorflow::Rendezvous::Args &&, const tensorflow::Rendezvous::Args &&, const tensorflow::Tensor &&, bool &&>'
>     { return tuple<_Elements&&...>(std::forward<_Elements>(__args)...); }
>              ^                     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:992:13: note: in instantiation of function template specialization 'std::forward_as_tuple<const tensorflow::Status &, const tensorflow::Rendezvous::Args &, const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool>' requested here
>               std::forward_as_tuple(std::forward<_Args>(__args)...),
>                    ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:1731:2: note: in instantiation of function template specialization 'std::_Bind<(lambda at tensorflow/core/kernels/sendrecv_ops.cc:155:7) (std::function<void ()>, std::_Placeholder<1>, std::_Placeholder<2>, std::_Placeholder<3>, std::_Placeholder<4>, std::_Placeholder<5>)>::operator()<const tensorflow::Status &, const tensorflow::Rendezvous::Args &, const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool, void>' requested here
>         (*_Base::_M_get_pointer(__functor))(
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/functional:2115:33: note: in instantiation of member function 'std::_Function_handler<void (const tensorflow::Status &, const tensorflow::Rendezvous::Args &, const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool), std::_Bind<(lambda at tensorflow/core/kernels/sendrecv_ops.cc:155:7) (std::function<void ()>, std::_Placeholder<1>, std::_Placeholder<2>, std::_Placeholder<3>, std::_Placeholder<4>, std::_Placeholder<5>)> >::_M_invoke' requested here
>             _M_invoker = &_My_handler::_M_invoke;
>                                        ^
> tensorflow/core/kernels/sendrecv_ops.cc:154:38: note: in instantiation of function template specialization 'std::function<void (const tensorflow::Status &, const tensorflow::Rendezvous::Args &, const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool)>::function<std::_Bind<(lambda at tensorflow/core/kernels/sendrecv_ops.cc:155:7) (std::function<void ()>, std::_Placeholder<1>, std::_Placeholder<2>, std::_Placeholder<3>, std::_Placeholder<4>, std::_Placeholder<5>)>, void, void>' requested here
>   Rendezvous::DoneCallback done_cb = std::bind(
>                                      ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:600:18: note: candidate template ignored: disabled by 'enable_if' [with _Dummy = void]
>                  _TCC<_Dummy>::template
>                  ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:611:18: note: candidate template ignored: disabled by 'enable_if' [with _Dummy = void]
>                  _TCC<_Dummy>::template
>                  ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:628:5: note: candidate template ignored: disabled by 'enable_if' [with _UElements = <const tensorflow::Status &, const tensorflow::Rendezvous::Args &, const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool>]
>                   _TC<sizeof...(_UElements) == 1, _Elements...>::template
>                   ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:641:5: note: candidate template ignored: disabled by 'enable_if' [with _UElements = <const tensorflow::Status &, const tensorflow::Rendezvous::Args &, const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool>]
>                   _TC<sizeof...(_UElements) == 1, _Elements...>::template
>                   ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:737:19: note: candidate template ignored: disabled by 'enable_if' [with _Alloc = tensorflow::Rendezvous::Args, _UElements = <const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool>]
>         enable_if<_TMC<_UElements...>::template
>                   ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:748:19: note: candidate template ignored: disabled by 'enable_if' [with _Alloc = tensorflow::Rendezvous::Args, _UElements = <const tensorflow::Rendezvous::Args &, const tensorflow::Tensor &, bool>]
>         enable_if<_TMC<_UElements...>::template
>                   ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:579:17: note: candidate constructor template not viable: requires 0 arguments, but 5 were provided
>       constexpr tuple()
>                 ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:589:26: note: candidate constructor template not viable: requires 0 arguments, but 5 were provided
>       explicit constexpr tuple()
>                          ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:670:19: note: candidate constructor template not viable: requires single argument '__in', but 5 arguments were provided
>         constexpr tuple(const tuple<_UElements...>& __in)
>                   ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:682:28: note: candidate constructor template not viable: requires single argument '__in', but 5 arguments were provided
>         explicit constexpr tuple(const tuple<_UElements...>& __in)
>                            ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:694:19: note: candidate constructor template not viable: requires single argument '__in', but 5 arguments were provided
>         constexpr tuple(tuple<_UElements...>&& __in)
>                   ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:705:28: note: candidate constructor template not viable: requires single argument '__in', but 5 arguments were provided
>         explicit constexpr tuple(tuple<_UElements...>&& __in)
>                            ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:721:2: note: candidate constructor template not viable: requires 7 arguments, but 5 were provided
>         tuple(allocator_arg_t __tag, const _Alloc& __a,
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:732:11: note: candidate constructor template not viable: requires 7 arguments, but 5 were provided
>         explicit tuple(allocator_arg_t __tag, const _Alloc& __a,
>                  ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:711:2: note: candidate constructor template not viable: requires 2 arguments, but 5 were provided
>         tuple(allocator_arg_t __tag, const _Alloc& __a)
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:759:2: note: candidate constructor template not viable: requires 3 arguments, but 5 were provided
>         tuple(allocator_arg_t __tag, const _Alloc& __a, const tuple& __in)
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:763:2: note: candidate constructor template not viable: requires 3 arguments, but 5 were provided
>         tuple(allocator_arg_t __tag, const _Alloc& __a, tuple&& __in)
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:772:2: note: candidate constructor template not viable: requires 3 arguments, but 5 were provided
>         tuple(allocator_arg_t __tag, const _Alloc& __a,
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:784:11: note: candidate constructor template not viable: requires 3 arguments, but 5 were provided
>         explicit tuple(allocator_arg_t __tag, const _Alloc& __a,
>                  ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:796:2: note: candidate constructor template not viable: requires 3 arguments, but 5 were provided
>         tuple(allocator_arg_t __tag, const _Alloc& __a,
>         ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:808:11: note: candidate constructor template not viable: requires 3 arguments, but 5 were provided
>         explicit tuple(allocator_arg_t __tag, const _Alloc& __a,
>                  ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:654:17: note: candidate constructor not viable: requires 1 argument, but 5 were provided
>       constexpr tuple(tuple&&) = default; 
>                 ^
> /usr/lib/gcc/x86_64-linux-gnu/6.3.0/../../../../include/c++/6.3.0/tuple:652:17: note: candidate constructor not viable: requires 1 argument, but 5 were provided
>       constexpr tuple(const tuple&) = default;
>                 ^
> 1 error generated.
> Target //tensorflow:libtensorflow_cc.so failed to build
> Use --verbose_failures to see the command lines of failed build steps.
> INFO: Elapsed time: 1003.058s, Critical Path: 53.74s
> FAILED: Build did NOT complete successfully
"
15070,Multil-model restore in tensorflow,"I have two model without scope name but they have same variable name, I want load them simultaneously, but it will crash and throw error, which is ""Variable XXX already exists"".
I notice the issue[https://github.com/tensorflow/tensorflow/issues/3270](url), but the problem is solved by re-training the model again and save them under different scope.
However, I do not want to re-train them again. So how can I load existing models and save them into two different scope?
Any advise or help will be appreciated!"
15066,Failing to retrieve AWS credentials running in ECS with the s3 provider,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: master
- **Python version**: 3.6.0
- **Bazel version (if compiling from source)**: 0.5.4
- **GCC/Compiler version (if compiling from source)**: 5.4.0
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None

### Describe the problem
When using the S3 file system provider within an ECS container I am finding that even though my task has been assigned a task role that provides access to my S3 bucket it is unable to access it successfully.

Everything works fine if I supply the credentials manually using the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables.

After some extensive head-desking I have found that the version of aws-sdk-cpp that is used (1.0.90) appears to have been released before the ECS support was added to the sdk (https://github.com/aws/aws-sdk-cpp/commit/786666db02f5ac7918642c1ee056b822e37a6f30), at a minimum I think we would want 1.0.97 so that everything works as expected.

I had originally tried to bump the version but it appears that the bazel mirror has nothing but 1.0.90 available."
15062,Bus Error when running a session,"### System information
- Running on an ODROID-XU4
- Have I written custom code: No
- OS Platform and Distribution: Linux Ubuntu Mate 16.04
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A
- TensorFlow installed from: source
- TensorFlow version: 1.4.0
- Python version: 3.5.2
- Bazel version: 0.8.0
- GCC Version: 5.4.0
- Exact command to reproduce:
python3.5
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow')
sess - tf.Session()
print(sess.run(hello))

### Describe the problem
I have built and installed TensorFlow as a pip package onboard an ODROID-XU4 (32-bit ARM), following the steps in this guide: https://hackernoon.com/running-yolo-on-odroid-yolodroid-5a89481ec141
Everything went smoothly, and I was able to install TensorFlow after a lengthy build time. However, when I try to run any session (such as in the basic example above), the program fails with a Bus Error. Running `pip3 list` shows that Tensorflow is indeed installed, and no errors are thrown when I merely import TensorFlow.

### Source code / logs
I traced the bus error by looking into the /var/log/syslog file and found the following lines associated with the error: `Dec  2 21:24:21 odroid kernel: [ 3658.433306] Alignment trap: python3.5 (10189) PC=0xac0bac42 Instr=0xf9068a1f Address=0xbe8a7da4 FSR 0x811
Dec  2 21:24:21 odroid kernel: [ 3658.433313] Alignment trap: not handling instruction f9068a1f at [<ac0bac42>]
Dec  2 21:24:21 odroid kernel: [ 3658.439021] Unhandled fault: alignment exception (0x811) at 0xbe8a7da4`
So, it appears to be an alignment issue. I tried to force the kernel to attempt to fix the error instead of simply failing by using the following command: `echo 3 > /proc/cpu/alignment`
The three is meant to tell the kernel to fix these alignment issues. However, this strategy has not changed anything about the Bus Error when attempting to run a session. 

Perhaps this is related to the 32-bit architecture I am attempting to run on?
"
15061,saved_model.pb needs a different file extension,The `saved_model.pb` file extension type conflicts with many formats using the `.pb` extension. Apps that register the `.pb` file extension won't be able to tell apart Saved Models from other Protocol Buffer files.
15060,"AttentionWrapperZeroState: Input to reshape is a tensor with 32768 values, but the requested shape has 65536","I am building an encoder-decoder model with attention and BeamSearchDecoder using tensor flow documentation. I am getting following error:

    ---------------------------------------------------------------------------
    InvalidArgumentError                      Traceback (most recent call last)
    <ipython-input-160-ac947b28f4dd> in <module>()
         29                                           summary_length: [generagte_summary_length], #summary_length: [np.random.randint(5,8)],
         30                                           text_length: [len(text)]*batch_size,
    ---> 31                                           keep_prob: 1.0})[0] 
         32         # Remove the padding from the summaries
         33         pad = vocab_to_int[""<PAD>""]

    /Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
        893     try:
        894       result = self._run(None, fetches, feed_dict, options_ptr,
    --> 895                          run_metadata_ptr)
        896       if run_metadata:
        897         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

    /Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
       1122     if final_fetches or final_targets or (handle and feed_dict_tensor):
       1123       results = self._do_run(handle, final_targets, final_fetches,
    -> 1124                              feed_dict_tensor, options, run_metadata)
       1125     else:
       1126       results = []

    /Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
       1319     if handle is None:
       1320       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
    -> 1321                            options, run_metadata)
       1322     else:
       1323       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

    /Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
       1338         except KeyError:
       1339           pass
    -> 1340       raise type(e)(node_def, op, message)
       1341 
       1342   def _extend_graph(self):

    InvalidArgumentError: Input to reshape is a tensor with 32768 values, but the requested shape has 65536
         [[Node: decode_1/Reshape_2 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](tile_batch_2/Reshape_2, decode_1/concat_2)]]

    Caused by op u'decode_1/Reshape_2', defined at:
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
        ""__main__"", fname, loader, pkg_name)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/runpy.py"", line 72, in _run_code
        exec code in run_globals
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
        app.launch_new_instance()
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
        app.start()
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 474, in start
        ioloop.IOLoop.instance().start()
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
        super(ZMQIOLoop, self).start()
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py"", line 887, in start
        handler_func(fd_obj, events)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
        return fn(*args, **kwargs)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
        self._handle_recv()
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
        self._run_callback(callback, msg)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
        callback(*args, **kwargs)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
        return fn(*args, **kwargs)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
        return self.dispatch_shell(stream, msg)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
        handler(stream, idents, msg)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
        user_expressions, allow_stdin)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
        res = shell.run_cell(code, store_history=store_history, silent=silent)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
        interactivity=interactivity, compiler=compiler, result=result)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2821, in run_ast_nodes
        if self.run_code(code, result):
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
        exec(code_obj, self.user_global_ns, self.user_ns)
      File ""<ipython-input-160-ac947b28f4dd>"", line 18, in <module>
        loader = tf.train.import_meta_graph(checkpoint + '.meta')
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1698, in import_meta_graph
        **kwargs)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py"", line 656, in import_scoped_meta_graph
        producer_op_list=producer_op_list)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 313, in import_graph_def
        op_def=op_def)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2630, in create_op
        original_op=self._default_original_op, op_def=op_def)
      File ""/Users/tusharagarwal/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1204, in __init__
        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

    InvalidArgumentError (see above for traceback): Input to reshape is a tensor with 32768 values, but the requested shape has 65536
         [[Node: decode_1/Reshape_2 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](tile_batch_2/Reshape_2, decode_1/concat_2)]]

The error occurs when trying to Make predictions(Test the Model Section) .Training runs fine. The error occurs when I set beam_size >=2. (The error shown is for beam_size=2). However it runs fine for beam_size = 1. I am not able to figure out what is going wrong. I know the code is long. Any help will be highly appreciated as I am unable to debug it and stuck on it for days. My code is:

My code is here:
# Model Inputs

    def model_inputs():
        input_data = tf.placeholder(tf.int32, [None, None], name='input')
        targets = tf.placeholder(tf.int32, [None, None], name='targets')
        lr = tf.placeholder(tf.float32, name='learning_rate')
        keep_prob = tf.placeholder(tf.float32, name='keep_prob')
        summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')
        max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')
        text_length = tf.placeholder(tf.int32, (None,), name='text_length')

        return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length

    def process_encoding_input(target_data, vocab_to_int, batch_size):  
        ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1]) # slice it to target_data[0:batch_size, 0: -1]
        dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)

        return dec_input
# Encoding layer

    def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):
        for layer in range(num_layers):
            with tf.variable_scope('encoder_{}'.format(layer)):
                cell_fw = tf.contrib.rnn.LSTMCell(rnn_size,
                                                  initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))
                cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, 
                                                        input_keep_prob = keep_prob)

                cell_bw = tf.contrib.rnn.LSTMCell(rnn_size,
                                                  initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))
                cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, 
                                                        input_keep_prob = keep_prob)

                enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, 
                                                                        cell_bw, 
                                                                        rnn_inputs,
                                                                        sequence_length,
                                                                        dtype=tf.float32)
                enc_output = tf.concat(enc_output,2)
                # original code is missing this line below, that is how we connect layers 
                # by feeding the current layer's output to next layer's input
                #rnn_inputs = enc_output
        return enc_output, enc_state

# Training Decoding layer  

    def training_decoding_layer(dec_embed_input, summary_length, dec_cell, output_layer,
                                vocab_size, max_summary_length,batch_size,enc_state):
        training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,
                                                            sequence_length=summary_length,
                                                            time_major=False)

        training_decoder = tf.contrib.seq2seq.BasicDecoder(cell=dec_cell,
                                                           helper=training_helper,
                                            initial_state=dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size).clone(cell_state=enc_state),
                                                           output_layer = output_layer)

        training_logits,_,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,
                                                                impute_finished = True,
                                                               maximum_iterations=max_summary_length)
        return training_logits

# Inference Decoding layer  

    def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, output_layer,
                                 max_summary_length, batch_size,lengths,enc_state,beam_width):
        '''Create the inference logits'''

        start_tokens = tf.ones_like(lengths) * start_token



        inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(
                        cell          = dec_cell,
                        embedding     = embeddings,
                        start_tokens  = start_tokens,
                        end_token     = end_token,
                        initial_state = dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size * beam_width*2).clone(cell_state=enc_state) ,
                        beam_width    = beam_width,
                        output_layer  = output_layer)


        inference_logits,_,_ = tf.contrib.seq2seq.dynamic_decode(inference_decoder,
                                                                 impute_finished = False,
                                                                maximum_iterations=max_summary_length)

        return inference_logits

    def lstm_cell(lstm_size, keep_prob):
        cell = tf.contrib.rnn.BasicLSTMCell(lstm_size)
        return tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob = keep_prob)

# Decoding layer 

    def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length,
                       max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):
        '''Create the decoding cell and attention for the training and inference decoding layers'''
        output_layer = Dense(vocab_size,kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))

        with tf.variable_scope(""decode""):
            dec_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(rnn_size, keep_prob) for _ in range(num_layers)])
            attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,
                                                         enc_output,
                                                         text_length,
                                                         normalize=False,
                                                         )
            dec_cell = tf.contrib.seq2seq.AttentionWrapper(cell =dec_cell,
                                                           attention_mechanism = attn_mech, 
                                                           attention_layer_size=rnn_size)

            training_logits = training_decoding_layer(dec_embed_input,summary_length,dec_cell,
                                                      output_layer,
                                                      vocab_size,
                                                      max_summary_length,
                                                      batch_size,enc_state)


        beam_width = 2
        enc_output = tf.contrib.seq2seq.tile_batch(enc_output, multiplier=beam_width)
        lengths = tf.contrib.seq2seq.tile_batch(text_length, multiplier=beam_width)
        enc_state = tf.contrib.seq2seq.tile_batch(enc_state, multiplier=beam_width)

        with tf.variable_scope(""decode"", reuse=True):
            dec_cell = tf.contrib.rnn.MultiRNNCell([lstm_cell(rnn_size, keep_prob) for _ in range(num_layers)])
            attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,
                                                         enc_output,
                                                         lengths,
                                                         normalize=False,
                                                         )
            dec_cell = tf.contrib.seq2seq.AttentionWrapper(cell =dec_cell,
                                                           attention_mechanism = attn_mech, 
                                                           attention_layer_size=rnn_size)


            inference_logits = inference_decoding_layer(embeddings,
                                                        vocab_to_int['<GO>'],
                                                        vocab_to_int['<EOS>'],
                                                        dec_cell,
                                                        output_layer,
                                                        max_summary_length,
                                                        batch_size,lengths,enc_state,beam_width)
        return training_logits, inference_logits


    def seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, 
                      vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):
        '''Use the previous functions to create the training and inference logits'''

        # Use Numberbatch's embeddings and the newly created ones as our embeddings
        #embeddings = word_embedding_matrix
        embeddings_s = tf.get_variable(""word_embeddings"",[vocab_size, 300])
        embeddings_t = tf.get_variable(""word_embeddings2"",[vocab_size, 300])
        enc_embed_input = tf.nn.embedding_lookup(embeddings_s, input_data)
        enc_output, enc_state = encoding_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)
        dec_input = process_encoding_input(target_data, vocab_to_int, batch_size) #shape=(batch_size, senquence length) each seq start with index of<GO>
        dec_embed_input = tf.nn.embedding_lookup(embeddings_t, dec_input)
        training_logits, inference_logits  = decoding_layer(dec_embed_input, 
                                                            embeddings_t,
                                                            enc_output,
                                                            enc_state, 
                                                            vocab_size, 
                                                            text_length, 
                                                            summary_length, 
                                                            max_summary_length,
                                                            rnn_size, 
                                                            vocab_to_int, 
                                                            keep_prob, 
                                                            batch_size,
                                                            num_layers)
        return training_logits, inference_logits

# Set the Hyperparameters
    epochs = 100
    batch_size = 64
    rnn_size = 256
    num_layers = 2
    learning_rate = 0.005
    keep_probability = 0.95


# Build the graph
    train_graph = tf.Graph()
    # Set the graph to default to ensure that it is ready for training
    with train_graph.as_default():

        # Load the model inputs    
        input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()

        # Create the training and inference logits
        training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),
                                                          targets, 
                                                          keep_prob,   
                                                          text_length,
                                                          summary_length,
                                                          max_summary_length,
                                                          len(vocab_to_int)+1,
                                                          rnn_size, 
                                                          num_layers, 
                                                          vocab_to_int,
                                                          batch_size)

        # Create tensors for the training logits and inference logits
        training_logits = tf.identity(training_logits.rnn_output, 'logits')
        #inference_logits = inference_logits.predicted_ids[:,:,0]
        inference_logits = tf.identity(inference_logits.predicted_ids, name='predictions')

        # Create the weights for sequence_loss, the sould be all True across since each batch is padded
        masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')

        with tf.name_scope(""optimization""):
            # Loss function
            cost = tf.contrib.seq2seq.sequence_loss(
                training_logits,
                targets,
                masks)

            # Optimizer
            optimizer = tf.train.AdamOptimizer(learning_rate)

            # Gradient Clipping
            gradients = optimizer.compute_gradients(cost)
            capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]
            train_op = optimizer.apply_gradients(capped_gradients)
    print(""Graph is built."")
    graph_location = ""./graph""
    print(graph_location)
    train_writer = tf.summary.FileWriter(graph_location)
    train_writer.add_graph(train_graph)


# Train the Model
    learning_rate_decay = 0.95
    min_learning_rate = 0.0005
    display_step = 20 # Check training loss after every 20 batches
    stop_early = 0 
    stop = 3 # If the update loss does not decrease in 3 consecutive update checks, stop training
    per_epoch = 3 # Make 3 update checks per epoch
    #update_check = (len(sorted_texts_short)//batch_size//per_epoch)-1
    update_check = 2

    update_loss = 0 
    batch_loss = 0
    summary_update_loss = [] # Record the update losses for saving improvements in the model

    checkpoint = ""./best_model.ckpt"" 
    with tf.Session(graph=train_graph) as sess:
        sess.run(tf.global_variables_initializer())

        # If we want to continue training a previous session
        #loader = tf.train.import_meta_graph(""./"" + checkpoint + '.meta')
        #loader.restore(sess, checkpoint)

        for epoch_i in range(1, epochs+1):
            update_loss = 0
            batch_loss = 0
            for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(
                    get_batches(sorted_summaries_short, sorted_texts_short, batch_size)):
                start_time = time.time()
                _, loss = sess.run(
                    [train_op, cost],
                    {input_data: texts_batch,
                     targets: summaries_batch,
                     lr: learning_rate,
                     summary_length: summaries_lengths,
                     text_length: texts_lengths,
                     keep_prob: keep_probability})

                batch_loss += loss
                update_loss += loss
                end_time = time.time()
                batch_time = end_time - start_time

                if batch_i % display_step == 0 and batch_i > 0:
                    print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'
                          .format(epoch_i,
                                  epochs, 
                                  batch_i, 
                                  len(sorted_texts_short) // batch_size, 
                                  batch_loss / display_step, 
                                  batch_time*display_step))
                    batch_loss = 0

                if batch_i % update_check == 0 and batch_i > 0:
                    print(""Average loss for this update:"", round(update_loss/update_check,3))
                    summary_update_loss.append(update_loss)

                    # If the update loss is at a new minimum, save the model
                    if update_loss <= min(summary_update_loss):
                        print('New Record!') 
                        stop_early = 0
                        saver = tf.train.Saver() 
                        saver.save(sess, checkpoint)

                    else:
                        print(""No Improvement."")
                        stop_early += 1
                        if stop_early == stop:
                            break
                    update_loss = 0


            # Reduce learning rate, but not below its minimum value
            learning_rate *= learning_rate_decay
            if learning_rate < min_learning_rate:
                learning_rate = min_learning_rate

            if stop_early == stop:
                print(""Stopping Training."")
                break


    def text_to_seq(text):
        '''Prepare the text for the model'''

        text = clean_text(text)
        return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]
# Test The Model   

    input_sentences=[""The coffee tasted great and was at such a good price! I highly recommend this to everyone!"",
                   ""love individual oatmeal cups found years ago sam quit selling sound big lots quit selling found target expensive buy individually trilled get entire case time go anywhere need water microwave spoon know quaker flavor packets""]
    generagte_summary_length =  [3,2]

    # input_sentences = test_text[0:10]
    # generagte_summary_length = summary_l[0:10]
    texts = [text_to_seq(input_sentence) for input_sentence in input_sentences]
    checkpoint = ""./best_model.ckpt""
    if type(generagte_summary_length) is list:
        if len(input_sentences)!=len(generagte_summary_length):
            raise Exception(""[Error] makeSummaries parameter generagte_summary_length must be same length as input_sentences or an integer"")
        generagte_summary_length_list = generagte_summary_length
    else:
        generagte_summary_length_list = [generagte_summary_length] * len(texts)
    loaded_graph = tf.Graph()
    with tf.Session(graph=loaded_graph) as sess:
        # Load saved model
        loader = tf.train.import_meta_graph(checkpoint + '.meta')
        loader.restore(sess, checkpoint)
        input_data = loaded_graph.get_tensor_by_name('input:0')
        logits = loaded_graph.get_tensor_by_name('predictions:0')
        text_length = loaded_graph.get_tensor_by_name('text_length:0')
        summary_length = loaded_graph.get_tensor_by_name('summary_length:0')
        keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')
        #Multiply by batch_size to match the model's input parameters
        for i, text in enumerate(texts):
            generagte_summary_length = generagte_summary_length_list[i]
            answer_logits = sess.run(logits, {input_data: [text]*batch_size, 
                                              summary_length: [generagte_summary_length], #summary_length: [np.random.randint(5,8)], 
                                              text_length: [len(text)]*batch_size,
                                              keep_prob: 1.0})[0] 
            # Remove the padding from the summaries
            pad = vocab_to_int[""<PAD>""] 
            print('- Review:\n\r {}'.format(input_sentences[i]))
            print('- Summary:\n\r {}\n\r\n\r'.format("" "".join([int_to_vocab[i[0]] for i in answer_logits if i[0] != pad])))
tensorflow
"
15059,Running tensorflow-gpu in virtual env in remote Ubuntu system,"I was attempting to install tensorflow gpu version for my gpu system.
 - I don't have sudo access in the computer. 
 - Cuda version 7.5 (V7.5.17) is installed
After following all the steps and finding a suitable version of tensorflow suitable to cuda 7.5 I have installed everything. But after installing when I am trying to import tensorflow, these errors are coming. 
![image](https://user-images.githubusercontent.com/31855851/33518214-456db3ce-d75f-11e7-8d7e-a4f62f1c6dcc.png)

I don't know how to resolve it. Also, does this error affect the running of my code in gpu or can I ignore it and start coding?
The solutions I found on forum is related to reinstalling cuda but I cannot do that as I don't have sudo access. Can anyone please provide me some other solution to resolve this issue?
I really want to setup my environment soon for the project. 
Thank you!

Additional info

OS Platform and Distribution Ubuntu v 16.04
TensorFlow installed via creating virtualenv
TensorFlow version 0.12.0rc0
Bazel version - Not used
CUDA/cuDNN version - 7.5 
GPU model and memory - NA
Exact command to reproduce - NA
"
15058,Go bindings: Two variables interfere unless op.VarHandleOpSharedName is used,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Arch linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**:  NA
- **GPU model and memory**:

### Describe the problem
When creating and assigning values to two variables in the Go bindings, they conflict, one value gets assigned to both variables. The variables assign OPs race, so it is somewhat non deterministic which gets assigned to both.

Reproduce:
Use `op.VarHandleOp()` to create two variable handles, and then use `op.AssignVariableOp()` to create OPs to assign the constant 1 to the first variable, and 2 to the second. Pull on the two assign OPs.
Evaluate the variable reader outputs for the two variables.
Expected result: First variable has a value of 1, and second variable has a value of 2.
Observed result: Both variables have the same value, usually 2, but occasionally 1.

Is this behavior correct?

If I use the optional parameter `op.VarHandleOpSharedName` in op.VarHandleOp, giving the two variables different names, it works as expected, so this is easy to work around.


### Source code / logs
```
package main

import (
	""fmt""

	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/op""
)

func makeVariable(s *op.Scope, i int32, name string) (init *tf.Operation, output tf.Output) {
	constant := op.Const(s, i)
	variable := op.VarHandleOp(s, tf.Int32, tf.ScalarShape())
	//variable := op.VarHandleOp(s, tf.Int32, tf.ScalarShape(), op.VarHandleOpSharedName(name))
	init = op.AssignVariableOp(s, variable, constant)
	output = op.ReadVariableOp(s, variable, tf.Int32)
	return
}

func main() {
	s := op.NewScope()
	init1, output1 := makeVariable(s.SubScope(""var1""), 1, ""variable_1"")
	init2, output2 := makeVariable(s.SubScope(""var2""), 2, ""variable_2"")

	graph, err := s.Finalize()
	if err != nil {
		panic(err)
	}
	sess, err := tf.NewSession(graph, nil)
	if err != nil {
		panic(err)
	}
	_, err = sess.Run(nil, nil, []*tf.Operation{init1, init2})
	if err != nil {
		panic(err)
	}
	results, err := sess.Run(nil, []tf.Output{output1, output2}, nil)
	if err != nil {
		panic(err)
	}
	fmt.Println(results[0].Value(), results[1].Value())
}
```
Prints:
```
[isaac@d6-arch tfes]$ go run shape_bug_demo.go 
2017-12-02 09:17:06.516455: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2017-12-02 09:17:06.594468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-12-02 09:17:06.594676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1060 6GB major: 6 minor: 1 memoryClockRate(GHz): 1.7085
pciBusID: 0000:01:00.0
totalMemory: 5.93GiB freeMemory: 5.15GiB
2017-12-02 09:17:06.594688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)
2 2
```"
15057,gpu is slower than cpu,"Have I written custom code：No
OS Platform and Distribution: win10
TensorFlow installed from: pip install tensorflow-gpu or pip install tensorflow
TensorFlow version: 1.4 and 1.3
Bazel version: None
CUDA/cuDNN version: cuda8.0 and cudnn 6.0
GPU model and memory: GTX1050 2GB
Exact command to reproduce: no

I have trained a cnn+lstm mode, and use the model to predict one image, however, I find the GPU is slowly than CPU. I have test the tensorflow-gpu 1.4, tensorflow-gpu 1.3， tensorflow 1.4 and tensorflow 1.4
the code is 
```python
# -*- coding: utf-8 -*-
# @Time    : 2017/10/26 14:09
# @Author  : zhoujun

import tensorflow as tf
from scipy.misc import imread
import time
import os

class PredictionModel:
    
    def __init__(self, model_dir, session=None):
        if session:
            self.session = session
        else:
            self.session = tf.get_default_session()
        start = time.time()
        self.model = tf.saved_model.loader.load(self.session, ['serve'], model_dir)
        print('load_model_time:', time.time() - start)

        self._input_dict, self._output_dict = _signature_def_to_tensors(self.model.signature_def['predictions'])

    def predict(self, image):
        output = self._output_dict
        # 运行predict  op
        start = time.time()
        result = self.session.run(output, feed_dict={self._input_dict['images']: image})
        print('predict_time:',time.time()-start)
        return result


def _signature_def_to_tensors(signature_def):  # from SeguinBe
    g = tf.get_default_graph()
    return {k: g.get_tensor_by_name(v.name) for k, v in signature_def.inputs.items()}, \
           {k: g.get_tensor_by_name(v.name) for k, v in signature_def.outputs.items()}


def predict(model_dir, image,gpu_id = 0):
    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)

    with tf.Session() as sess:
        start = time.time()
        model = PredictionModel(model_dir,session=sess)
        predictions = model.predict(image)
        transcription = predictions['words']
        score = predictions['score']
        return [transcription[0].decode(), score, time.time() - start]


if __name__ == '__main__':
    model_dir = 'model/'
    image = imread('3_song.jpg', mode='L')[:, :, None]
    result = predict(model_dir, image,0)
    print(tf.__version__)
    print(result)
```
tensorflow-gpu 1.4 log
```sh
2017-12-02 22:30:30.147490: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2017-12-02 22:30:31.083045: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
totalMemory: 2.00GiB freeMemory: 1.62GiB
2017-12-02 22:30:31.083203: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)
load_model_time: 2.9134938716888428
predict_time: 4.135322570800781
1.4.0
```
tensorflow-gpu 1.3 log
```sh
2017-12-02 22:39:46.346092: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-02 22:39:46.346191: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-02 22:39:47.187559: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX 1050
major: 6 minor: 1 memoryClockRate (GHz) 1.493
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.62GiB
2017-12-02 22:39:47.187717: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0
2017-12-02 22:39:47.188099: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0:   Y
2017-12-02 22:39:47.188224: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0)
load_model_time: 2.595602512359619
predict_time: 1.6665771007537842
1.3.0
```
tensorflow 1.4 log
```sh
2017-12-02 22:47:21.368827: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
load_model_time: 2.340376853942871
predict_time: 3.538094997406006
1.4.0
```
tensorflow 1.3 log
```sh
2017-12-02 22:51:33.877932: W C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-02 22:51:33.878031: W C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
load_model_time: 2.2079925537109375
predict_time: 0.5485155582427979
1.3.0
```
As can be seen from the log, tensorflow1.4 slower than 1.3 #14942, and gpu mode slower than cpu. If needed, I can provide models and test images"
15056,tf.losses.mean_squared_error is actually sum of squares,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.3.0-rc1-5211-gab0fcac 1.5.0-dev20171124
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

To truly get mean squared error one has to explictly use `reduction=Reduction.MEAN`. This indicates bad naming. Maybe `squared_error` is a better name, also similar to other names in `tf.losses`"
15054,~,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15051,DataLossError ; Input/output error,"```
DataLossError (see above for traceback): Unable to open table file C:\Users\jk-pc\Desktop\little_fighter_project\log\little-figter-2-0.001-alexnetv2-3-epochs.model: Unknown: NewRandomAccessFile failed to Create/Open: C:\Users\jk-pc\Desktop\little_fighter_project\log\little-figter-2-0.001-alexnetv2-3-epochs.model : �s���Q�ڡC

; Input/output error
	 [[Node: save_1/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/device:CPU:0""](_arg_save_1/Const_0_0, save_1/RestoreV2_2/tensor_names, save_1/RestoreV2_2/shape_and_slices)]]
```
how can this be fixed? the model can not be loaded"
15050,upgraded tensorflow to use GPU - she's a no worky anymore,"Script was running fine (if a bit slow).  Decided it was  time to upgrade to the gpu version of tensorflow.  From what I can tell, for some reason it is looking for libcublas.so.8.0.  Since I just upgraded to the latest cuda libs, I'm running libcublas.so.9.0.176  (found in /usr/local/cuda-9.0/lib64/) and, yes, that is in my path (first item, by the way).  


Using TensorFlow backend.
```
Traceback (most recent call last):
  File ""/home/mitch/MitchEng/data_Analytics/conv_radar.py"", line 3, in <module>
    from keras.models import Sequential
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/keras/__init__.py"", line 3, in <module>
    from . import utils
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/keras/utils/__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/keras/utils/conv_utils.py"", line 3, in <module>
    from .. import backend as K
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/keras/backend/__init__.py"", line 83, in <module>
    from .tensorflow_backend import *
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py"", line 1, in <module>
    import tensorflow as tf
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/mitch/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.
```
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15049,No OpKernel was registered to support Op 'OneHot' with these attrs. Tensorflow1.4,"I have trained and saved a CNN model in python Tensorflow 1.3. 
I can successfully load and run the graph previously saved from my python model in Tensorflow 1.4 using CPU and c++ with no problem; but when I tried to load the same graph using Tensorflow 1.4 using GPU c++ and I get the following error:

`-		status	{state_=unique_ptr {code=INVALID_ARGUMENT (3) msg=""No OpKernel was registered to support Op 'OneHot' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\n  <no registered kernels>\n\n\t [[Node: one_hot = OneHot[T=DT_FLOAT, TI=DT_INT32, _... } }	tensorflow::Status
`

My system:
Windows 10
Cuda 8.0
Cudnn 6
cmake cmake-3.9.4-win64-x64
Python 3.5.2
VS2015
@cuevas1208"
15047,no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path,"### System information
- I have not written any of my own code. I downloaded Tensorflow through virtualenv as recommended by tensorflow
- My OS is High Sierra on a macbook pro
- : I am using python 2.7
- **Bazel version Build label: 0.7.0-homebrew:

### I'm following the tensorflow tutorial on how to retrain inception v3, which I have linked here; https://www.tensorflow.org/tutorials/image_retraining

When I input the bazel build tensorflow/examples/image_retraining:retrain  it says there is no build file. How do i get the build file. Im new to tensorflow so if you could put the code in here that would be extremely helpful because I am new to coding and new to github itself

### Source code / logs

bazel build tensorflow/examples/image_retraining:retrain

....................................................................................
ERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.
INFO: Elapsed time: 2.443s
"
15046,stop gradients for weights in tf.losses,"In the case that the weights given to tf.losses.* depend in some way on the model parameters, 
the derivative of that loss also calculated with respect to the weights. 
(Stupid) minimal example:
```python
import tensorflow as tf
x = tf.constant(0)
w = tf.get_variable(name=""W"", shape=(), initializer=tf.zeros_initializer())
L = tf.losses.mean_squared_error(x, x, weights=w)
tf.train.AdamOptimizer().compute_gradients(L)
```
results in 
```
[(<tf.Tensor 'gradients/mean_squared_error/Mul_grad/tuple/control_dependency_1:0' shape=() dtype=float32>,
  <tf.Variable 'W:0' shape=() dtype=float32_ref>)]
```

I would expect the weights to be considered constant for the calculation of a loss. In case you agree with me, I can make a PR that adds `stop_gradient` around the weights parameter.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: N/A
- **Python version**:  N/A
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: N/A
"
15045,"Updated Tensor flow, incompatible function parameters. (Float32>int)","Hi, 

### System information
Windows 10
TensorFlow installed using pip. 
I am using CDU 
Python 3.6.3 (using Spyder)
TensorFlow version: 1.4.0

Have I written custom code: No
OS Platform and Distribution:
TensorFlow installed from
Bazel version:NA
CUDA/cuDNN version:NA
GPU model and memory: using cpu.
Exact command to reproduce: 
activate myenvrionment
spyder 


This code was written on 0.x tensorFlow, it could be an update issue, but I can't find the outdated function. 

`
    
    from keras import optimizers
    from keras.models import Model
    from keras.layers import Dropout, Lambda
    from keras.layers import Input, average
    from keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose
    from keras.layers import ZeroPadding2D, Cropping2D
    from keras import backend as K
    
    
    def mvn(tensor):
        '''Performs per-channel spatial mean-variance normalization.'''
        epsilon = 1e-6
        mean = K.mean(tensor, axis=(1,2), keepdims=True)
        std = K.std(tensor, axis=(1,2), keepdims=True)
        mvn = (tensor - mean) / (std + epsilon)
        
        return mvn
    
    
    def crop(tensors):
        '''
        List of 2 tensors, the second tensor having larger spatial dimensions.
        '''
        h_dims, w_dims = [], []
        for t in tensors:
            b, h, w, d = K.get_variable_shape(t)
            h_dims.append(h)
            w_dims.append(w)
        crop_h, crop_w = (h_dims[1] - h_dims[0]), (w_dims[1] - w_dims[0])
        rem_h = crop_h % 2
        rem_w = crop_w % 2
        crop_h_dims = (crop_h / 2, crop_h / 2 + rem_h)
        crop_w_dims = (crop_w / 2, crop_w / 2 + rem_w)
        cropped = Cropping2D(cropping=(crop_h_dims, crop_w_dims))(tensors[1])
        
        return cropped
    
    
    def dice_coef(y_true, y_pred, smooth=0.0):
        '''Average dice coefficient per batch.'''
        axes = (1,2,3)
        intersection = K.sum(y_true * y_pred, axis=axes)
        summation = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes)
        
        return K.mean((2.0 * intersection + smooth) / (summation + smooth), axis=0)
    
    
    def dice_coef_loss(y_true, y_pred):
        return 1.0 - dice_coef(y_true, y_pred, smooth=10.0)
    
    
    def jaccard_coef(y_true, y_pred, smooth=0.0):
        '''Average jaccard coefficient per batch.'''
        axes = (1,2,3)
        intersection = K.sum(y_true * y_pred, axis=axes)
        union = K.sum(y_true, axis=axes) + K.sum(y_pred, axis=axes) - intersection
        return K.mean( (intersection + smooth) / (union + smooth), axis=0)
    
    
    def fcn_model(input_shape, num_classes, weights=None):
        ''' ""Skip"" FCN architecture similar to Long et al., 2015
        https://arxiv.org/abs/1411.4038
        '''
        if num_classes == 2:
            num_classes = 1
            loss = dice_coef_loss
            activation = 'sigmoid'
        else:
            loss = 'categorical_crossentropy'
            activation = 'softmax'
    
        kwargs = dict(
            kernel_size=3,
            strides=1,
            activation='relu',
            padding='same',
            use_bias=True,
            kernel_initializer='glorot_uniform',
            bias_initializer='zeros',
            bias_regularizer=None,
            activity_regularizer=None,
            kernel_constraint=None,
            bias_constraint=None,
            trainable=True,
        )
        
        data = Input(shape=input_shape, dtype='float', name='data')
        mvn0 = Lambda(mvn, name='mvn0')(data)
        pad = ZeroPadding2D(padding=5, name='pad')(mvn0)
    
        conv1 = Conv2D(filters=64, name='conv1', **kwargs)(pad)
        mvn1 = Lambda(mvn, name='mvn1')(conv1)
        
        conv2 = Conv2D(filters=64, name='conv2', **kwargs)(mvn1)
        mvn2 = Lambda(mvn, name='mvn2')(conv2)
    
        conv3 = Conv2D(filters=64, name='conv3', **kwargs)(mvn2)
        mvn3 = Lambda(mvn, name='mvn3')(conv3)
        pool1 = MaxPooling2D(pool_size=3, strides=2,
                        padding='valid', name='pool1')(mvn3)
    
        
        conv4 = Conv2D(filters=128, name='conv4', **kwargs)(pool1)
        mvn4 = Lambda(mvn, name='mvn4')(conv4)
    
        conv5 = Conv2D(filters=128, name='conv5', **kwargs)(mvn4)
        mvn5 = Lambda(mvn, name='mvn5')(conv5)
    
        conv6 = Conv2D(filters=128, name='conv6', **kwargs)(mvn5)
        mvn6 = Lambda(mvn, name='mvn6')(conv6)
    
        conv7 = Conv2D(filters=128, name='conv7', **kwargs)(mvn6)
        mvn7 = Lambda(mvn, name='mvn7')(conv7)
        pool2 = MaxPooling2D(pool_size=3, strides=2,
                        padding='valid', name='pool2')(mvn7)
    
    
        conv8 = Conv2D(filters=256, name='conv8', **kwargs)(pool2)
        mvn8 = Lambda(mvn, name='mvn8')(conv8)
    
        conv9 = Conv2D(filters=256, name='conv9', **kwargs)(mvn8)
        mvn9 = Lambda(mvn, name='mvn9')(conv9)
    
        conv10 = Conv2D(filters=256, name='conv10', **kwargs)(mvn9)
        mvn10 = Lambda(mvn, name='mvn10')(conv10)
    
        conv11 = Conv2D(filters=256, name='conv11', **kwargs)(mvn10)
        mvn11 = Lambda(mvn, name='mvn11')(conv11)
        pool3 = MaxPooling2D(pool_size=3, strides=2,
                        padding='valid', name='pool3')(mvn11)
        drop1 = Dropout(rate=0.5, name='drop1')(pool3)
    
    
        conv12 = Conv2D(filters=512, name='conv12', **kwargs)(drop1)
        mvn12 = Lambda(mvn, name='mvn12')(conv12)
    
        conv13 = Conv2D(filters=512, name='conv13', **kwargs)(mvn12)
        mvn13 = Lambda(mvn, name='mvn13')(conv13)
    
        conv14 = Conv2D(filters=512, name='conv14', **kwargs)(mvn13)
        mvn14 = Lambda(mvn, name='mvn14')(conv14)
    
        conv15 = Conv2D(filters=512, name='conv15', **kwargs)(mvn14)
        mvn15 = Lambda(mvn, name='mvn15')(conv15)
        drop2 = Dropout(rate=0.5, name='drop2')(mvn15)
    
    
        score_conv15 = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='score_conv15')(drop2)
        upsample1 = Conv2DTranspose(filters=num_classes, kernel_size=3,
                            strides=2, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=False,
                            name='upsample1')(score_conv15)
        score_conv11 = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='score_conv11')(mvn11)
        crop1 = Lambda(crop, name='crop1')([upsample1, score_conv11])
        fuse_scores1 = average([crop1, upsample1], name='fuse_scores1')
        
        upsample2 = Conv2DTranspose(filters=num_classes, kernel_size=3,
                            strides=2, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=False,
                            name='upsample2')(fuse_scores1)
        score_conv7 = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='score_conv7')(mvn7)
        crop2 = Lambda(crop, name='crop2')([upsample2, score_conv7])
        fuse_scores2 = average([crop2, upsample2], name='fuse_scores2')
        
        upsample3 = Conv2DTranspose(filters=num_classes, kernel_size=3,
                            strides=2, activation=None, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=False,
                            name='upsample3')(fuse_scores2)
        crop3 = Lambda(crop, name='crop3')([data, upsample3])
        predictions = Conv2D(filters=num_classes, kernel_size=1,
                            strides=1, activation=activation, padding='valid',
                            kernel_initializer='glorot_uniform', use_bias=True,
                            name='predictions')(crop3)
        
        model = Model(inputs=data, outputs=predictions)
        if weights is not None:
            model.load_weights(weights)
        sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)
        model.compile(optimizer=sgd, loss=loss,
                      metrics=['accuracy', dice_coef, jaccard_coef])
    
        return model
    
    
    if __name__ == '__main__':
        model = fcn_model((100, 100, 1), 2, weights=None)
    

`

# Spyder execution log:
runfile('E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py', wdir='E:/AB/cardiac-segmentation-master/cardiac-segmentation-master')
Using TensorFlow backend.
Traceback (most recent call last):

  File ""<ipython-input-3-d1b60b53383b>"", line 1, in <module>
    runfile('E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py', wdir='E:/AB/cardiac-segmentation-master/cardiac-segmentation-master')

  File ""C:\Users\PC\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 710, in runfile
    execfile(filename, namespace)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\spyder\utils\site\sitecustomize.py"", line 101, in execfile
    exec(compile(f.read(), filename, 'exec'), namespace)

  File ""E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py"", line 197, in <module>
    model = fcn_model((100, 100, 1), 2, weights=None)

  File ""E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py"", line 162, in fcn_model
    crop1 = Lambda(crop, name='crop1')([upsample1, score_conv11])

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\engine\topology.py"", line 603, in __call__
    output = self.call(inputs, **kwargs)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\layers\core.py"", line 651, in call
    return self.function(inputs, **arguments)

  File ""E:/AB/cardiac-segmentation-master/cardiac-segmentation-master/fcn_model.py"", line 36, in crop
    cropped = Cropping2D(cropping=(crop_h_dims, crop_w_dims))(tensors[1])

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\engine\topology.py"", line 603, in __call__
    output = self.call(inputs, **kwargs)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\keras\layers\convolutional.py"", line 1874, in call
    self.cropping[1][0]: -self.cropping[1][1],

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 538, in _SliceHelper
    name=name)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py"", line 706, in strided_slice
    shrink_axis_mask=shrink_axis_mask)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_array_ops.py"", line 5429, in strided_slice
    name=name)

  File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 609, in _apply_op_helper
    param_name=input_name)

  **File ""C:\Users\PC\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py"", line 60, in _SatisfiesTypeConstraint
    "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))

**TypeError: Value passed to parameter 'begin' has DataType float32 not in list of allowed values: int32, int64****


Please help."
15044,rolling window batch operation for tf.data.Dataset,"_This is a feature request_

For Datasets that represent a sequence or time series, it can be useful to have a Dataset op that creates a rolling window batch over the given Dataset. For example, if I have a tf.data.Dataset whose elements represent a time series (line breaks separate elements):
```
1
2
3
4
5
6
7
8
9
```
The rolling window batch would create a dataset with the following elements (for window size 4 and stride 1):
```
1 2 3 4
2 3 4 5
3 4 5 6
4 5 6 7
5 6 7 8
6 7 8 9
```
This operation will be extremely useful for extracting sub sequences from a time series for training RNNs and Reinforcement Learning models."
15043,a,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15041,"Gradient computation occupies too much memories in ""cnn (using while_loop) + lstm"" network","### System information
- **Have I written custom code**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.3
- **Python version**: 3.6
- **CUDA/cuDNN version**: 8.0/5.1
- **GPU model and memory**: GTX Titan X 12GB
- **Bazel version**: No use 
- **Exact command to reproduce**: using python *.py

### Describe the problem
I'm using while_loop function to build a cnn because of the scale of input tensors. And put the cnn feature into a lstm structure. The problem is that if I only do the forward computatoin it is good, but if I add the backward computation `GradientDescentOptimizer().minimize(loss))` the memory is **significantly insufficient** . 
I tried to split the two part of the model -- cnn and lstm part, and both do well with the whole computation. I think this is the fact:
* Single while_loop cnn net is treated as time distributed when computing gradient. Every temporary feature vector and gradients occupy the same memory location at each time step.
* When coneected with a lstm, the cnn net will be treated as many subnet in computing gradients. At every time step in backward computation, it will occupy new memory for its temporary feature vector and gradients. The number of timesteps is very large so that the memory is significantly not enough.

Here is a simplified code of my project. It will show my cnn+lstm structure:

### Source code
```
import tensorflow as tf
import tensorflow.contrib as contrib

def vgg_m(input_layer, reuse=None):
    # input shape [batch_size, 120, 120, 5]
    with tf.variable_scope('vgg_m', reuse=reuse):
        conv_1 = tf.layers.conv2d(input_layer, 96, [3, 3], padding='same', activation=tf.nn.relu, name='conv_1')
        pool_1 = tf.layers.max_pooling2d(conv_1, 3, 2, padding='same', name='pool_1')
        norm_1 = tf.layers.batch_normalization(pool_1, name='norm_1')

        conv_2 = tf.layers.conv2d(norm_1, 256, [3, 3], padding='same', activation=tf.nn.relu, name='conv_2')
        pool_2 = tf.layers.max_pooling2d(conv_2, 3, 2, padding='same', name='pool_2')
        norm_2 = tf.layers.batch_normalization(pool_2, name='norm_2')

        conv_3 = tf.layers.conv2d(norm_2, 512, [3, 3], padding='same', activation=tf.nn.relu, name='conv_3')

        conv_4 = tf.layers.conv2d(conv_3, 512, [3, 3], padding='same', activation=tf.nn.relu, name='conv_4')

        conv_5 = tf.layers.conv2d(conv_4, 512, [3, 3], padding='same', activation=tf.nn.relu, name='conv_5')
        pool_5 = tf.layers.max_pooling2d(conv_5, 3, 2, padding='same', name='pool_5')

        flatten_6 = contrib.layers.flatten(pool_5)
        fc_6 = tf.layers.dense(flatten_6, 512, name='fc6')

    return fc_6

# [batch, time_step, image_h, image_w, image_channel
input_tensor = tf.random_normal([64, 150, 120, 120, 5], dtype=tf.float32)

# vgg_m is a cnn net whose input and output size is [batch, 120, 120, 5], [batch, 512]
# in order to create vgg_m variables for reuse later.
vgg_m(input_tensor[:, 0, :, :, :])

time_steps = 150
initial_t = tf.constant(0, dtype=tf.int32)
initial_outputs = tf.TensorArray(dtype=tf.float32, size=time_steps)

def _should_continue(t, *args):
    return t < time_steps

def _iteration(t, outputs_):
    # compute cnn feature at time t
    single_output = vgg_m(input_tensor[:, t, :, :, :], reuse=True)
    outputs_ = outputs_.write(t, single_output)
    return t+1, outputs_

_, outputs = tf.while_loop(_should_continue, _iteration, [initial_t, initial_outputs])

# transpose the batch dim and time dim to build a [batch, time_step, 512] feature and send to lstm
outputs = tf.transpose(outputs.stack(), perm=[1, 0, 2])
outputs = tf.reshape(outputs, [-1, 150, 512])

lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(512)
lstm_outputs, lstm_state = tf.nn.dynamic_rnn(
            lstm_cell,
            outputs,
            sequence_length=tf.constant(150, dtype=tf.int32, shape=[64]),
            dtype=tf.float32,
        )

# not really a ""loss"", just perform an loss example
loss = tf.reduce_max(tf.reduce_max(tf.reduce_max(lstm_outputs, -1), -1), -1)
train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)

sess = tf.Session()
sess.run(tf.global_variables_initializer())
sess.run(train_op)
```

### Log
```
2017-12-01 22:44:24.228695: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228717: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228725: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228731: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:24.228736: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-12-01 22:44:26.620700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:4c:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-12-01 22:44:26.620728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0
2017-12-01 22:44:26.620735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y
2017-12-01 22:44:26.620742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:4c:00.0)
2017-12-01 22:44:29.102674: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-12-01 22:44:29.102971: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-12-01 22:44:29.103146: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 748.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2017-12-01 22:44:39.103321: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 112.50MiB.  Current allocation summary follows.
2017-12-01 22:44:39.103363: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256):   Total Chunks: 3, Chunks in use: 0 768B allocated for chunks. 20B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103372: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512):   Total Chunks: 1, Chunks in use: 0 512B allocated for chunks. 4B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103379: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024):  Total Chunks: 1, Chunks in use: 0 1.0KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103384: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
...(many Chunks)
2017-12-01 22:44:39.103507: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (67108864):      Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103514: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103521: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:39.103528: I tensorflow/core/common_runtime/bfc_allocator.cc:660] Bin for 112.50MiB was 64.00MiB, Chunk State:
2017-12-01 22:44:39.103536: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x230a3c0000 of size 1280
2017-12-01 22:44:39.103542: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x230a3c0500 of size 256
2017-12-01 22:44:39.103547: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x230a3c0600 of size 512
...(many Chunks)
2017-12-01 22:44:39.104420: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x25cc3c8000 of size 88473600
2017-12-01 22:44:39.104425: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Chunk at 0x25d1828000 of size 122539008
2017-12-01 22:44:39.104430: I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size:
2017-12-01 22:44:39.104438: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 19 Chunks of size 256 totalling 4.8KiB
...(many Chunks)
2017-12-01 22:44:39.104599: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 245891072 totalling 234.50MiB
2017-12-01 22:44:39.104605: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 268435456 totalling 256.00MiB
2017-12-01 22:44:39.104611: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 353894400 totalling 1.65GiB
2017-12-01 22:44:39.104617: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 405815296 totalling 387.02MiB
2017-12-01 22:44:39.104623: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 513720320 totalling 489.92MiB
2017-12-01 22:44:39.104629: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 4294967296 totalling 4.00GiB
2017-12-01 22:44:39.104635: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 11.22GiB
2017-12-01 22:44:39.104644: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                 12050517197
InUse:                 12049901824
MaxInUse:              12049901824
NumAllocs:                     297
MaxAllocSize:           4294967296

2017-12-01 22:44:39.104660: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ********x************************xxxxxxxxxxx********************************************************
2017-12-01 22:44:39.104678: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,512,30,30]
2017-12-01 22:44:49.104957: W tensorflow/core/common_runtime/bfc_allocator.cc:273] Allocator (GPU_0_bfc) ran out of memory trying to allocate 225.00MiB.  Current allocation summary follows.
2017-12-01 22:44:49.105020: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (256):   Total Chunks: 3, Chunks in use: 0 768B allocated for chunks. 20B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:49.105043: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (512):   Total Chunks: 1, Chunks in use: 0 512B allocated for chunks. 4B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
2017-12-01 22:44:49.105063: I tensorflow/core/common_runtime/bfc_allocator.cc:643] Bin (1024):  Total Chunks: 1, Chunks in use: 0 1.0KiB allocated for chunks. 1.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
...(similar chunks)
2017-12-01 22:44:49.107700: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 4294967296 totalling 4.00GiB
2017-12-01 22:44:49.107714: I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 11.11GiB
2017-12-01 22:44:49.107731: I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                 12050517197
InUse:                 11927362816
MaxInUse:              12049901824
NumAllocs:                     297
MaxAllocSize:           4294967296

2017-12-01 22:44:49.107769: W tensorflow/core/common_runtime/bfc_allocator.cc:277] ********x************************xxxxxxxxxxx*******************************************************_
2017-12-01 22:44:49.107799: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,60,60,256]
2017-12-01 22:44:49.107877: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[64,512,30,30]
         [[Node: while/vgg_m/conv_4/convolution = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](while/vgg_m/conv_3/Relu, while/vgg_m/conv_4/convolution/Enter)]]

....(same thing occuring again and again util it is closed.
```
### Is this an unknown bug
I saw a different processing with `loop_state` in gradients function, so is this an unknown bug with multiple loop operation(lstm contains loop as well)
"
15040,raw video files to tfrecords (code integration),"Since I had to address the issue of converting large (and many) raw RGB video files (e.g. .avi, .mp4 etc.) into tfrecords for threaded/QueueRunner training during a research project in the past, I was wondering if my resulting code [1] could be of any help to the TensorFlow community. If not, I would make a feature request and possibly participate or support the implementaton. 

When I had to address this at an early stage of my project, I couldn't find any useful implementations. This seems to have remained unchanged as of now.

[1] https://github.com/ferreirafabio/video2tfrecords

Thanks in advance.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04, macOS Sierra 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: -
- **GCC/Compiler version (if compiling from source)**: -
- **CUDA/cuDNN version**: I use the CPU version
- **GPU model and memory**: -
- **Exact command to reproduce**: -
"
15039,Why tensorflow don't support tf.float64 on some ops?,"Reproducing experiment of some paper using tensorflow may don't have good performance. I have tried my best to keep the structure and hyper-parameters unchanged. Does anyone encounter similar problem? Is it the code wrong?  I wonder that `caffe` can use `float64` but tensorflow only can use `float32`,  so there are more inaccuracy on `gradients`, why tf don't support `tf.float64`?"
15038,Why tensorflow don't support tf.float64 on some ops?,"Reproducing experiment of some paper using tensorflow may don't have good performance. I have tried my best to keep the structure and hyper-parameters unchanged. Does anyone encounter similar problem? Is it the code wrong?  I wonder that `caffe` can use `float64` but tensorflow only can use `float32`,  so there are more inaccuracy on `gradients`, why tf don't support `tf.float64`?"
15036,error while importing,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Traceback (most recent call last):
File """", line 1, in 
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/init.py"", line 24, in 
from tensorflow.python import *
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/init.py"", line 51, in 
from tensorflow.python import pywrap_tensorflow
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in 
from tensorflow.python.pywrap_tensorflow_internal import *
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in 
_pywrap_tensorflow_internal = swig_import_helper()
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: libcudnn.so.5: cannot open shared object file: No such file or directory
Failed to load the native TensorFlow runtime.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
15035,NadamOptimizer does not work with sparse gradients,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6.3

Code:
```
import tensorflow as tf
from tensorflow.contrib.opt import NadamOptimizer

optimizer = NadamOptimizer(learning_rate=0.001)
# optimizer = tf.train.AdamOptimizer(learning_rate=0.001)  # this works
w = tf.get_variable(""w"", shape=(100, 10))
idxs = tf.placeholder(tf.int32, shape=(None,))
emb = tf.gather(w, idxs)
loss = tf.reduce_sum(emb ** 2)
minimize = optimizer.minimize(loss)

with tf.Session() as sess:
  sess.run(tf.global_variables_initializer())
  sess.run(minimize, feed_dict={idxs: [1, 2, 3]})
```

This fails with:
```
...
  File ""/u/zeyer/.local/lib/python3.6/site-packages/tensorflow/contrib/opt/python/training/nadam_optimizer.py"", line 83, in _apply_sparse_shared
    m_bar = m_scaled_g_values + beta1_t * m_t
...

InvalidArgumentError (see above for traceback): Incompatible shapes: [3,10] vs. [100,10]
         [[Node: Adam/update_w/add = Add[T=DT_FLOAT, _class=[""loc:@w""], _device=""/job:localhost/replica:0/task:0/device:GPU:0""](Adam/update_w/mul_1, Adam/update_w/mul_3)]]
```

The bug is pretty obvious in `nadam_optimizer.py`. The fix would be to do it like in `adam.py`:
```
m_t = state_ops.assign(m, m * beta1_t, use_locking=self._use_locking)
with ops.control_dependencies([m_t]):
  m_t = scatter_add(m, indices, m_scaled_g_values)
```

"
15034,Optimize graph & graph transform tools do not support NCHW,"I tried optimizing graph using both [Graph transform tool](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md) and [Optimize graph for inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py). Both cases produced the same error because the fused batchnorm used not NCHW, but NHWC. I've got the error like this:

```
InvalidArgumentError (see above for traceback): Must provide as many biases as the channel dimension of the input tensor: [256] vs. 19 in [1,256,19,19]
	 [[Node: prefix/convblock/BatchNorm/FusedBatchNorm = BiasAdd[T=DT_FLOAT, data_format=""NHWC"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](prefix/convblock/Conv2D, prefix/convblock/Conv2D_bn_offset)]
```

Although NCHW is faster than NHWC in GPU environment, why the tools do not support NCHW?

"
15033,cuDNN on windows will speed up image retraining?,"If  I'll do 4 steps from http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#installwindows

it will speed up tensorflow image retraining? (https://www.tensorflow.org/versions/r0.12/how_tos/image_retraining/)

![screenshot_7](https://user-images.githubusercontent.com/8851301/33477760-8eea082a-d68f-11e7-89d3-f8386ada70b2.png)
"
15032,Error while implementing the feature requested in  #10767,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
RHEL 6.8 
- **TensorFlow installed from (source or binary)**:
binary
- **TensorFlow version (use command below)**:
'v1.3.0-rc1-5326-gcae852a', '1.4.0'
- **Python version**: 
2.7.14
- **Bazel version (if compiling from source)**:
Build label: 0.5.4- (@non-git)
- **GCC/Compiler version (if compiling from source)**:
4.8.5
- **CUDA/cuDNN version**:
Not installed
- **GPU model and memory**:
Using tensorflow for CPU
- **Exact command to reproduce**:
I want to implement _in_top_k_ operation with options to specify what to do when a tie occurs for [CIFAR-10](https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10) data-set. I came across this feature request in #10767, modified the 6-files as shown [here](https://github.com/nolanliou/tensorflow/commit/681724f94e025bbd8377c5406eec4047d58fc31b), and rebuilt from source. When I run _eval_CIFAR10.py_ which contains the _in_top_k_ op, I get the following error.

  File ""eval_CIFAR10.py"", line 146, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 129, in run
    _sys.exit(main(argv))
  File ""eval_CIFAR10.py"", line 141, in main
    evaluate()
  File ""eval_CIFAR10.py"", line 130, in evaluate
    eval_once(saver, summary_writer, top_k_op, summary_op)
  File ""eval_CIFAR10.py"", line 63, in eval_once
    saver.restore(sess, ckpt.model_checkpoint_path)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1686, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 889, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1317, in _do_run
    options, run_metadata)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Multiple OpKernel registrations match NodeDef 'in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=""SAMPLE""](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)': 'op: ""InTopKV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""predictions"" host_memory_arg: ""targets"" host_memory_arg: ""k"" host_memory_arg: ""precision""' and 'op: ""InTopKV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""predictions"" host_memory_arg: ""targets"" host_memory_arg: ""k"" host_memory_arg: ""precision""'
	 [[Node: in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=""SAMPLE""](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)]]

Caused by op u'in_top_k/InTopKV2', defined at:
  File ""eval_CIFAR10.py"", line 146, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 129, in run
    _sys.exit(main(argv))
  File ""eval_CIFAR10.py"", line 141, in main
    evaluate()
  File ""eval_CIFAR10.py"", line 116, in evaluate
    top_k_op = tf.nn.in_top_k(logits, labels, 1, handle_ties=""SAMPLE"")
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 2523, in in_top_k
    return gen_nn_ops._in_top_kv2(predictions, targets, k, handle_ties, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 2536, in _in_top_kv2
    handle_ties=handle_ties, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3101, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1583, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Multiple OpKernel registrations match NodeDef 'in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=""SAMPLE""](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)': 'op: ""InTopKV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""predictions"" host_memory_arg: ""targets"" host_memory_arg: ""k"" host_memory_arg: ""precision""' and 'op: ""InTopKV2"" device_type: ""CPU"" constraint { name: ""T"" allowed_values { list { type: DT_INT32 } } } host_memory_arg: ""predictions"" host_memory_arg: ""targets"" host_memory_arg: ""k"" host_memory_arg: ""precision""'
	 [[Node: in_top_k/InTopKV2 = InTopKV2[T=DT_INT32, handle_ties=""SAMPLE""](softmax_linear/softmax_linear, Reshape_2, in_top_k/InTopKV2/k)]]

If you can kindly look into the matter I shall be much helped. Thank you. "
15030,Could not find a version that satisfies the requirement tensorflow-gpu (from versions: ),"Can't install tensorflow on Windows using Aconda method:

> Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )

```
The following NEW packages will be INSTALLED:

    certifi:        2017.11.5-py35_0 conda-forge
    pip:            9.0.1-py35_0     conda-forge
    python:         3.5.4-1          conda-forge
    setuptools:     37.0.0-py35_0    conda-forge
    vs2015_runtime: 14.0.25420-0     conda-forge
    wheel:          0.30.0-py_1      conda-forge
    wincertstore:   0.2-py35_0       conda-forge

Proceed ([y]/n)? y

Fetching packages ...
vs2015_runtime 100% |###############################| Time: 0:00:21  95.29 kB/s
python-3.5.4-1 100% |###############################| Time: 0:01:48 162.13 kB/s
certifi-2017.1 100% |###############################| Time: 0:00:00 298.32 kB/s
wincertstore-0 100% |###############################| Time: 0:00:00  10.92 kB/s
setuptools-37. 100% |###############################| Time: 0:00:01 404.06 kB/s
wheel-0.30.0-p 100% |###############################| Time: 0:00:00 135.42 kB/s
pip-9.0.1-py35 100% |###############################| Time: 0:00:03 570.48 kB/s
Extracting packages ...
[      COMPLETE      ]|##################################################| 100%
Linking packages ...
[      COMPLETE      ]|##################################################| 100%
#
# To activate this environment, use:
# > activate tensorflow
#
# To deactivate this environment, use:
# > deactivate tensorflow
#
# * for power-users using bash, you must source
#

PS C:\Windows\system32>
PS C:\Windows\system32> activate tensorflow
PS C:\Windows\system32> pip install --ignore-installed --upgrade tensorflow-gpu
Collecting tensorflow-gpu
  Could not find a version that satisfies the requirement tensorflow-gpu (from versions: )
No matching distribution found for tensorflow-gpu
```"
15029,build tensorflow Image Recognition with c++,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 16.04
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**: 0.6.1
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:8.0
- **GPU model and memory**:5.4.0
- **Exact command to reproduce**:



I follow this [tutorial](https://tensorflow.google.cn/tutorials/image_recognition#usage_with_the_c_api) try to build a a c++ tensorflow program.

Here is the steps:

1. build tensorflow from source. I am sure this step is right, because I can install python tensorflow with the whl file built by this step.
2. in the tensorflow source code directory, I run this command:

`bazel build tensorflow/examples/label_image/...`

the build failed with following logs(partial, because whole log is too big)



> WARNING: /home/scott/github/tensorflow/tensorflow/tensorflow/core/BUILD:1781:1: in includes attribute of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/nsync/public' resolves to 'external/nsync/public' not below the relative path of its package 'tensorflow/core'. This will be an error in the future. Since this rule was created by the macro 'cc_header_only_library', the error might have been caused by the macro implementation in /home/scott/github/tensorflow/tensorflow/tensorflow/tensorflow.bzl:1044:30
> INFO: Analysed 2 targets (0 packages loaded).
> INFO: Found 2 targets...
> INFO: From ProtoCompile tensorflow/core/example/example.pb.cc:
> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
> INFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.cc:
> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
> INFO: From ProtoCompile tensorflow/contrib/cloud/kernels/bigquery_table_partition.pb.cc:
> bazel-out/local_linux-py3-opt/genfiles/external/protobuf_archive/src: warning: directory does not exist.
> INFO: From Executing genrule //tensorflow/cc:array_ops_genrule:
> 2017-12-01 15:02:52.546440: W tensorflow/core/framework/op_gen_lib.cc:372] Squeeze can't find input squeeze_dims to rename
> ERROR: /home/scott/github/tensorflow/tensorflow/tensorflow/examples/label_image/BUILD:14:1: Linking of rule '//tensorflow/examples/label_image:label_image' failed (Exit 1)
> /usr/bin/ld: warning: libcudnn.so.6, needed by bazel-out/local_linux-py3-opt/bin/_solib_local/_U_S_Stensorflow_Sexamples_Slabel_Uimage_Clabel_Uimage___Utensorflow/libtensorflow_framework.so, not found (try using -rpath or -rpath-link)
> bazel-out/local_linux-py3-opt/bin/_solib_local/_U_S_Stensorflow_Sexamples_Slabel_Uimage_Clabel_Uimage___Utensorflow/libtensorflow_framework.so: undefined reference to `cudnnGetConvolutionBackwardDataAlgorithm'
"
15028,ctc_loss with best align path,"The tf.nn.ctc_loss function only returns negative log probabilities according to truth labels for the sequence's best align path. 
But we also need this best align path in some situations.
Could you please supply this feature, thanks!
------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MINGW64_NT-6.1 xsk-PC 2.6.0(0.304/5/3) 2016-09-07 20:45 x86_64 Msys
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6.0
- **Bazel version (if compiling from source)**: None
- **GCC/Compiler version (if compiling from source)**: None
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**: None"
15027,Tutorial wrong code  cifar10_multi_gpu_train.py,"when I run 
`python cifar10_multi_gpu_train.py --num_gpus=2`
reported a error

```
usage: cifar10_multi_gpu_train.py [-h] [--batch_size BATCH_SIZE]
                                  [--data_dir DATA_DIR] [--use_fp16 USE_FP16]
cifar10_multi_gpu_train.py: error: unrecognized arguments: --num_gpus=2
```

So what is `[--use_fp16 USE_FP16]` ,it didn;a appear at anywhere in this code file"
15026,tensorflow 1.4 tf.keras gives different result compared with using keras directly,"I have tensorflow 1.4, when running the following code, the accuracy is different (78% vs. 34.90%) when I import Sequential, Dense, and model_from_json directly from keras (uncomment first 3 lines) compared with import from tensorflow.python.keras. Why is the big discrepancy? 
 
(the data pima-indians-diabetes.csv is available at http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data)

#from keras.models import Sequential
#from keras.layers import Dense
#from keras.models import model_from_json

from tensorflow.python.keras.layers import Dense
from tensorflow.python.keras.models import Sequential, model_from_json

import numpy
import os
# fix random seed for reproducibility
numpy.random.seed(7)
# load pima indians dataset
dataset = numpy.loadtxt(""pima-indians-diabetes.csv"", delimiter="","")
# split into input (X) and output (Y) variables
X = dataset[:,0:8]
Y = dataset[:,8]
# create model
model = Sequential()
model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))
model.add(Dense(8, kernel_initializer='uniform', activation='relu'))
model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))
# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# Fit the model
model.fit(X, Y, epochs=150, batch_size=10, verbose=0)
# evaluate the model
scores = model.evaluate(X, Y, verbose=0)
print(""%s: %.2f%%"" % (model.metrics_names[1], scores[1]*100))

# serialize model to JSON
model_json = model.to_json()
with open(""model.json"", ""w"") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights(""model.h5"")
print(""Saved model to disk"")"
15019,Tensorflow: how to save/restore tf.data.Dataset?,"I made a model with `tf.data.Dataset()` as a data IO function

then i exported the graph and tried to restore it with meta_graph file But it failed and following error messages occurred.

I think that `tf.data.Dataset()` made a C++ object instead of python queue used before.

And the graph_def only has a C++ object handler reference, so the graph_def alone without real C++ object can't load complete graph.

How can I load a executable graph with `tf.data.Dataset()`? Or is it impossible for now?

```
File ""/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

NotFoundError (see above for traceback): Function
_make_dataset_5150cb86 is not defined.
         [[Node: batch_processing/OneShotIterator = OneShotIterator[container="""", dataset_factory=_make_dataset_5150cb86[], output_shapes=[[?,1], [?,299,299,3]], output_types=[DT_INT32, DT_FLOAT], shared_name="""",
_device=""/job:workers/replica:0/task:0/device:CPU:0""]()]]
```

In short, all the tensorflow graphs without` tf.data.Dataset` work, when i add following codes. 
```
graph = tf.train.export_meta_graph()
tf.reset_default_graph()
tf.train.import_meta_graph(graph)

```
But the graphs with` tf.data.Dataset `make a error message above


"
15016,no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path. for Virtual Environment on mac. ,**Template ignored**
15014,Extend Dataset API to support writing to files (not just reading),"Just as we have a pipeline to read from files and convert them to output vectors/data via some model, It would be very useful to have a pipeline to take data and write it to files.

Otherwise, we have to use TFRecordWriters and a bit more code, but really much of this can be abstracted away, simplifying the data creation process, especially when writing to shards (as one might do using distributed Tensorflow)."
15013,GPU visual studio dependecies ,"I build tensorflow 1.4.0 for windows with GPU usage. But when I run my program in visual studio 2015 I get these error:
```
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)"" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)
1>tf_core_kernels.lib(fft_ops.obj) : error LNK2001: unresolved external symbol ""public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)"" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)
1>tf_core_kernels.lib(conv_ops_3d.obj) : error LNK2001: unresolved external symbol ""public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)"" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)
1>tf_core_kernels.lib(conv_ops.obj) : error LNK2001: unresolved external symbol ""public: virtual __cdecl perftools::gputools::ScratchAllocator::~ScratchAllocator(void)"" (??1ScratchAllocator@gputools@perftools@@UEAA@XZ)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnForward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> *,bool,class perftools::gputools::ScratchAllocator *,class perftools::gputools::ScratchAllocator *)"" (?ThenRnnForward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@M@23@AEBVRnnStateTensorDescriptor@523@23221PEAV723@3434_NPEAVScratchAllocator@23@6@Z)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnForward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> *,bool,class perftools::gputools::ScratchAllocator *,class perftools::gputools::ScratchAllocator *)"" (?ThenRnnForward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@N@23@AEBVRnnStateTensorDescriptor@523@23221PEAV723@3434_NPEAVScratchAllocator@23@6@Z)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnBackward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> const &,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<float> *,class perftools::gputools::DeviceMemory<unsigned char> *,class perftools::gputools::ScratchAllocator *)"" (?ThenRnnBackward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@M@23@AEBVRnnStateTensorDescriptor@523@2322123232222PEAV723@444PEAV?$DeviceMemory@E@23@PEAVScratchAllocator@23@@Z)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::Stream & __cdecl perftools::gputools::Stream::ThenRnnBackward(class perftools::gputools::dnn::RnnDescriptor const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnSequenceTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::dnn::RnnStateTensorDescriptor const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> const &,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<double> *,class perftools::gputools::DeviceMemory<unsigned char> *,class perftools::gputools::ScratchAllocator *)"" (?ThenRnnBackward@Stream@gputools@perftools@@QEAAAEAV123@AEBVRnnDescriptor@dnn@23@AEBVRnnSequenceTensorDescriptor@523@AEBV?$DeviceMemory@N@23@AEBVRnnStateTensorDescriptor@523@2322123232222PEAV723@444PEAV?$DeviceMemory@E@23@PEAVScratchAllocator@23@@Z)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::port::StatusOr<class std::unique_ptr<class perftools::gputools::dnn::RnnDescriptor,struct std::default_delete<class perftools::gputools::dnn::RnnDescriptor> > > __cdecl perftools::gputools::StreamExecutor::createRnnDescriptor(int,int,int,enum perftools::gputools::dnn::RnnInputMode,enum perftools::gputools::dnn::RnnDirectionMode,enum perftools::gputools::dnn::RnnMode,enum perftools::gputools::dnn::DataType,float,unsigned __int64,class perftools::gputools::ScratchAllocator *)"" (?createRnnDescriptor@StreamExecutor@gputools@perftools@@QEAA?AV?$StatusOr@V?$unique_ptr@VRnnDescriptor@dnn@gputools@perftools@@U?$default_delete@VRnnDescriptor@dnn@gputools@perftools@@@std@@@std@@@port@23@HHHW4RnnInputMode@dnn@23@W4RnnDirectionMode@723@W4RnnMode@723@W4DataType@723@M_KPEAVScratchAllocator@23@@Z)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::port::StatusOr<class std::unique_ptr<class perftools::gputools::dnn::RnnSequenceTensorDescriptor,struct std::default_delete<class perftools::gputools::dnn::RnnSequenceTensorDescriptor> > > __cdecl perftools::gputools::StreamExecutor::createRnnSequenceTensorDescriptor(int,int,int,enum perftools::gputools::dnn::DataType)"" (?createRnnSequenceTensorDescriptor@StreamExecutor@gputools@perftools@@QEAA?AV?$StatusOr@V?$unique_ptr@VRnnSequenceTensorDescriptor@dnn@gputools@perftools@@U?$default_delete@VRnnSequenceTensorDescriptor@dnn@gputools@perftools@@@std@@@std@@@port@23@HHHW4DataType@dnn@23@@Z)
1>tf_core_kernels.lib(cudnn_rnn_ops.cc.obj) : error LNK2001: unresolved external symbol ""public: class perftools::gputools::port::StatusOr<class std::unique_ptr<class perftools::gputools::dnn::RnnStateTensorDescriptor,struct std::default_delete<class perftools::gputools::dnn::RnnStateTensorDescriptor> > > __cdecl perftools::gputools::StreamExecutor::createRnnStateTensorDescriptor(int,int,int,enum perftools::gputools::dnn::DataType)"" (?createRnnStateTensorDescriptor@StreamExecutor@gputools@perftools@@QEAA?AV?$StatusOr@V?$unique_ptr@VRnnStateTensorDescriptor@dnn@gputools@perftools@@U?$default_delete@VRnnStateTensorDescriptor@dnn@gputools@perftools@@@std@@@std@@@port@23@HHHW4DataType@dnn@23@@Z)
1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_avgpooling_op_gpu.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync
1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_argmax_op_gpu.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync
1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync
1>tf_core_gpu_kernels.lib(tf_core_gpu_kernels_generated_concat_lib_gpu_impl.cu.cc.obj) : error LNK2001: unresolved external symbol cudaMemcpyAsync
```

My system:
Windows 10
Cuda 8.0
Cudnn 6
cmake cmake-3.9.4-win64-x64
Python 3.5.2
VS2015"
15010,feeding_functions._GeneratorFeedFn does not return correct num of batches,"feeding_functions._GeneratorFeedFn does not return correct #samples in mini batch. It actually returns mini batches with batch_size/key_size (key size is the length of dict yielded by the generator func). 
```python
gff = feeding_functions._GeneratorFeedFn(
    placeholders=placeholders,
    generator=generator_fn, # yields { 'feature_set_1': [] (shape 1x13), 'feature_set_2': [] (shape 1x20) }
    batch_size=32,
    random_start=False,
    seed=None,
    num_epochs=1,
    pad_value=None
)
actual = gff()
for k in actual:
    print(actual[k].shape)
# (16, 1, 13)
# (16, 1, 20)
```
https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/estimator/inputs/queues/feeding_functions.py
`list_dict_size` compared with `self._batch_size` in `_GeneratorFeedFn.__call__`

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, snippet above
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X 10.13.1
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Code snippet above"
15009,Train and release quantized models for other input sizes of mobilenet,"Trying to run /tensorflow/examples/image_retraining/retrain.py, getting the following error: 

```
  File ""/home/burjanviktor/DeepLearning/dog_breed/retraining.py"", line 1032, in main
    maybe_download_and_extract(model_info['data_url'])
  File ""/home/burjanviktor/DeepLearning/dog_breed/retraining.py"", line 344, in maybe_download_and_extract
    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)
... 
  File ""/home/burjanviktor/anaconda3/lib/python3.6/urllib/request.py"", line 650, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 403: Forbidden
```

I am trying to use MobileNet for retraining, but the following url: 

'http://download.tensorflow.org/models/mobilenet_v1_1.0_160_quantized_frozen.tgz'

gives the following error: 

```
<Error>
<Code>AccessDenied</Code>
<Message>Access denied.</Message>
<Details>Anonymous users does not have storage.objects.get access to download.tensorflow.org/models/mobilenet_v1_1.0_160_quantized_frozen.tgz.</Details>
</Error>
```

The 1.0_220 version works, but 1.0_190 does not work also.

Could you advise on this issue please? "
15006,tf.contrib.data: tf-slim training pipeline  raise  GetNext() failed because the iterator has not been initialized.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**: 
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:
```
        dataset = get_dataset()
        iterator = tf.contrib.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)
        train_init_op = iterator.make_initializer(dataset)

        inputs, labels = iterator.get_next()
        prob, end_points = model.nldf(inputs, labels)
        total_loss = tf.losses.get_total_loss()
        optimizer = tf.train.AdamOptimizer(1e-6)
        train_op = slim.learning.create_train_op(
                          total_loss,
                          optimizer,
                          clip_gradient_norm=FLAGS.max_grad_norm)
        def init_fn(sess):
            sess.run(train_init_op)
        slim.learning.train(
                        train_op,
                        FLAGS.checkpoint_dir,
                        init_fn=init_fn,
                        number_of_steps=1000,
                        save_summaries_secs=300,
                        save_interval_secs=600)
```
is going to fail with  

```
FailedPreconditionError (see above for traceback): GetNext() failed because the iterator has not been initialized. Ensure that you have run the initializer operation for this iterator before getting the next element.
	 [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,352,352,3], [?,176,176,?]], output_types=[DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](Iterator)]]
```

== cat /etc/issue ===============================================
Darwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64
Mac OS X 10.12.6

== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin16.7.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin

== uname -a =====================================================
Darwin MTL-PengYu 16.7.0 Darwin Kernel Version 16.7.0: Wed Oct  4 00:17:00 PDT 2017; root:xnu-3789.71.6~1/RELEASE_X86_64 x86_64

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-serving-api (1.3.0)
tensorflow-tensorboard (0.1.8)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================


You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""
('v1.3.0-rc2-20-g0787eee', '1.3.0')

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

`init_fn` of `slim.learning.train` doesn't  init the `tf.contrib.data.Iterator` properly

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

https://github.com/yupbank/NLDF-tf/blob/make-multi-gpu/trainer/multi_gpu_task.py#L148"
15004,compile error with cmake for windows 10 and GPU enabled,"Hi,
I am trying to compile the tensorflow.dll with cmake for windows 10 and GPU enabled. However, the it failed because of the following error:
```
"" C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow/stream_executor/stream.h(1921): error C2065: 'tf_shared_lock
': undeclared identifier (compiling source file C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\core\grappler\
devices.cc) [C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\contrib\cmake\build_GPU\tf_core_cpu.vcxproj]
  C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow/stream_executor/stream.h(1921): error C2146: syntax error: m
issing ';' before identifier 'lock' (compiling source file C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\cor
e\grappler\devices.cc) [C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\contrib\cmake\build_GPU\tf_core_cpu.vc
xproj]
  C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow/stream_executor/stream.h(1921): error C2065: 'lock': undecla
red identifier (compiling source file C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\core\grappler\devices.cc
) [C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\contrib\cmake\build_GPU\tf_core_cpu.vcxproj]
  C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow/stream_executor/stream.h(1921): error C2065: 'tf_shared_lock
': undeclared identifier (compiling source file C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\core\common_ru
ntime\gpu\gpu_cudamalloc_allocator.cc) [C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\contrib\cmake\build_GP
U\tf_core_cpu.vcxproj]
  C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow/stream_executor/stream.h(1921): error C2146: syntax error: m
issing ';' before identifier 'lock' (compiling source file C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\cor
e\common_runtime\gpu\gpu_cudamalloc_allocator.cc) [C:\Users\mcuevas\bin\tensorflow\tensorflow\tensorflow\contrib\cma
ke\build_GPU\tf_core_cpu.vcxproj]""
```
These are the commands I use:
cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\Users\mcuevas\bin\swigwin-3.0.12\swigwin-3.0.12\swig.exe -DPYTHON_EXECUTABLE=C:\Users\mcuevas\AppData\Local\Continuum\anaconda3\envs\acsis_cpu\python.exe -DPYTHON_LIBRARIES=C:\Users\mcuevas\AppData\Local\Continuum\anaconda3\pkgs\python-3.5.2-0\libs\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0""

MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj

Thanks in advance.

My system:
Windows 10
Cuda 8.0
Cudnn 6
cmake cmake-3.9.4-win64-x64
Python 3.5.2
VS2015"
15003,msvcp140.dll missing on win 7,"Hi everyone :)

I installed Tensorflow on Windows 7 ultimate with Python 3.5.4, via the `pip3 install --upgrade tensorflow` command. It even stated it successfully installed version 1.4

But if I try to invoke `import tensorflow as tf` in the shell I get the following error:
![grafik](https://user-images.githubusercontent.com/33151777/33433308-5b8fee18-d5db-11e7-8ddf-7037bae45e11.png)
 
Of course I installed the recommended Visual C++ 2015 Redistributablle 64bit Update 3, but there is neither the .dll file in my system folder, nor does tensorflow work. I get the same error as before.

Any help is appreciated, Thank you :)
"
15002,fatal error: cuda/include/cuda.h: No such file or directory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, I followed the official documentation for custom operations.
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:

```
Linux pc 4.4.0-81-generic #104-Ubuntu SMP Wed Jun 14 08:17:06 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
```

- **TensorFlow installed from (source or binary)**:
  tried both
- **TensorFlow version (use command below)**:

| version                               | status        | comment |
| -------------                         | ------------- | -----|
| ('v1.2.0-rc1-7529-g8a4d849', '1.4.0') | not working   | from pip or from source |
| ('v1.2.0-rc2-21-g12f033d', '1.2.0')   | working       | from [pypip](https://pypi.python.org/packages/4b/d3/d4fe94f4f370fbb3790444b8f0a007298a795c447e195d88a066de04930d/tensorflow-1.2.0-cp27-cp27mu-manylinux1_x86_64.whl#md5=7e1640384dfd705e17b2f668c1b0427b) |

- **Python version**: 2.7 (*irrelevant*)
- **Bazel version (if compiling from source)**:

```
Build label: 0.6.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Oct 5 21:54:59 2017 (1507240499)
Build timestamp: 1507240499
Build timestamp as int: 1507240499
```

- **GCC/Compiler version (if compiling from source)**: *irrelevant*
  tried both
  - g++4.8
  - g++5.0
- **CUDA/cuDNN version**: *irrelevant*

```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sun_Sep__4_22:14:01_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44
```

- **GPU model and memory**: irrelevant
- **Exact command to reproduce**:

```bash
cd /tmp
mkdir tf_issue
cd tf_issue
virtualenv test
source test/bin/activate
pip install tensorflow # in some way: either tensorflow-gpu or from wheel package created by bazel
git clone https://github.com/cgtuebingen/tf_custom_op
cd tf_custom_op
cmake .
make
```

### Describe the problem
Compiling custom ops with

```cpp
#include ""tensorflow/core/util/cuda_kernel_helper.h""
```

fails due to missing files


```
/code/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h:24:31: fatal error: cuda/include/cuda.h: No such file or directory
```

This file `cuda/include/cuda.h` does not exists! Neither in the pip package nor in the git repository.
Removing `#include ""tensorflow/core/util/cuda_kernel_helper.h""` 

gives plenty of other issues

```
/code/kernels/matrix_add_kernel.cu(13): error: namespace ""tensorflow"" has no member ""CudaLaunchConfig""
/code/kernels/matrix_add_kernel.cu(59): error: namespace ""tensorflow"" has no member ""CudaLaunchConfig""
/code/kernels/matrix_add_kernel.cu(59): error: expected a "";""
/code/kernels/matrix_add_kernel.cu(63): error: identifier ""cfg"" is undefined
/code/kernels/matrix_add_kernel.cu(88): error: namespace ""tensorflow"" has no member ""CudaLaunchConfig""
/code/kernels/matrix_add_kernel.cu(88): error: expected a "";""
/code/kernels/matrix_add_kernel.cu(92): error: identifier ""cfg"" is undefined
```

As I already wrote in a related issue #12860, the commit 2c598e874e6a7b6b3185846ce9bac97a7d5d0169 is causing this issue by changing

```diff
-#include ""third_party/gpus/cuda/include/cuda.h""
+#include ""cuda/include/cuda.h""
```

Copying the old `cuda.h` gives

```
[...]/local/lib/python2.7/site-packages/tensorflow/include/tensorflow/core/platform/default/mutex.h:25:22: fatal error: nsync_cv.h: No such file or directory
```

which does not exist, too.

This problem is not related to custom code, it is related to ignore/omitting files in commit 2c598e874e6a7b6b3185846ce9bac97a7d5d0169

As mention in #12860, this affects many people. In fact, the entire way of writing customs ops with CUDA seems to be broken. Copying own source-code to the TensorFlow-repo was not necessary until TF1.3. Interestingly, even recent NIPS paper implementations state in their readme, they only support TFv1.2. I don't think the proposed workaround of downgrading to TFv1.2 should be the way to go."
15001,How can i read csv file by file name and line number in tensorflow?,"I read some csv files using queue like [this](https://www.tensorflow.org/api_guides/python/reading_data#creating_threads_to_prefetch_using_queuerunner_objects).  Then, i get `key` and `value` when reading from file queues. The `key` contains file name and line number.

```
    filename_queue = tf.train.string_input_producer([""file0.csv"", ""file1.csv""]) 
    reader = tf.TextLineReader()
    key, value = reader.read(filename_queue)
```


I train model using Dynamic negative sampling like [IRGAN code](https://github.com/xf4fresh/irgan/blob/master/ltr-gan/ltr-gan-pointwise/ltr_dns_nn.py#L41). I need sample from large scale negative samples, so i want to save the example id such as filename:line rather than feature itself. 

However, i can not find a suitable function on document.
Thanks for your attention!"
14998,Extend reshape with begin_axis and end_axis like in cntk,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
CNTK has a generalized version of reshape and it would be nice to have such a version also in Tensorflow
(https://github.com/Microsoft/CNTK/blob/master/bindings/python/cntk/ops/__init__.py#L1972).
```python
def reshape(x, shape, begin_axis=None, end_axis=None, name=''):
    ...
```

The difference is, that the user can provide `begin_axis` and `end_axis` and if they are specified reshape only operate on a subset of the shape.

I can make a PR, when somebody says me, where I have to write the code.

### Source code / logs
Here a working example:
```python
def reshape(tensor, shape, begin_axis=None, end_axis=None, name=None) -> tf.Tensor:
    if begin_axis is None and end_axis is None:
        return tf.reshape(tensor, shape, name=name)

    with tf.name_scope(name, 'reshape', [tensor]):
        tensor_shape = tf.shape(tensor)
        to_concat = [shape]
        if begin_axis is not None:
            bs = tensor_shape[:begin_axis]
            to_concat.insert(0, bs)
        if end_axis is not None:
            es = tensor_shape[end_axis:]
            to_concat.append(es)

        tensor_shape = tf.concat(to_concat, 0)

        return = tf.reshape(tensor, tensor_shape)
```

and an example doctest
```python
    """"""

    Inspired from cntk.reshape to allow begin_axis and end_axis

    Assume you call reshape
    >> out = reshape(in, shape, b, e)
    Than the following will hold
    (Note: If b or e is None, the are interpreted as 0 and/or include the last axis)
    >> in_shape = in.shape
    >> in_shape[b:e] = shape
    >> assert out.shape == in_shape

    First example normal reshape, where the input has unknown dimension
    >>> import numpy as np
    >>> _ = tf.InteractiveSession()
    >>> x = tf.placeholder(tf.float32)
    >>> y = reshape(x, [-1])
    >>> y
    <tf.Tensor 'Reshape:0' shape=(?,) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4])}).shape
    (12,)

    Now keep first and last axis: (No shape inference expected, to difficult)
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape/Reshape:0' shape=<unknown> dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    Now with ndim defined:
    >>> x = tf.placeholder(tf.float32, shape=[None, None, None, None])
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape_1/Reshape:0' shape=(?, ?, ?) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    Now with partial defined shape:
    >>> x = tf.placeholder(tf.float32, shape=[3, 4, None, 6])
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape_2/Reshape:0' shape=(3, ?, 6) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    Now with full defined shape:
    >>> x = tf.placeholder(tf.float32, shape=[3, 4, 5, 6])
    >>> y = reshape(x, [-1], begin_axis=1, end_axis=-1)
    >>> y
    <tf.Tensor 'reshape_3/Reshape:0' shape=(3, 20, 6) dtype=float32>
    >>> y.eval({x: np.zeros([3, 4, 5, 6])}).shape
    (3, 20, 6)

    :param tensor:
    :param shape:
    :param name:
    :return:
    """"""
```
"
14996,How to read image_data and fill image_tensor by tensorflow c++ apis,"I want to infer a image by a trained model.first read a image as Mat by opencv,then fill plane_tensor with Mat.Does it work ? Is there any better way to the following code? waiting for some warming person ! thank you very much.

Mat img = imread(file_name);
std::vector<Mat> bgr;
split(img, bgr);
tensorflow::Tensor four_dim_plane(DT_UINT8, tensorflow::TensorShape({ 1, img.rows, img.cols, 3 }));
auto plane_tensor = four_dim_plane.tensor<unsigned char, 4>();
for (int  k = 0; k < 3; ++k)
{
        for (int  i = 0; i < img.rows; ++i)
	{
		for (int j = 0; j < img.cols; ++j)
		{
		   plane_tensor(0, i, j, k) = bgr[k].at<unsigned char>(i, j);
		}
	}
}
tensorflow::Status status3 = session->Run({ { ""image_tensor"", plane_tensor } },{ output_node },
          {}, &outputs);

**System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows10 
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): TF1.4
Python version:python3.5.2
GCC/Compiler version (if compiling from source): vs2015
CUDA/cuDNN version:cuda8.0/cudnn6.0
GPU model and memory:TXT1080TI/11G
Bazel version：
Exact command to reproduce：**"
14995,Bug: tf.estimator.Estimator.export_savedmodel does not work with pathlib.Path in py36,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**:binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**: 

### Describe the problem
The function `tf.estimator.Estimator.export_savedmodel` does not accept a `pathlib.Path` object, because 
`tensorflow.python.util.compat.as_bytes` used in `tensorflow.python.estimator.export.get_timestamped_export_dir` can not convert `pathlib.Path` to bytes.
Here the code snippet from `tensorflow.python.estimator.export.get_timestamped_export_dir`:
```python
    export_dir = os.path.join(
        compat.as_bytes(export_dir_base),
        compat.as_bytes(str(export_timestamp)))
```
I would write a PR, but I am not sure how to solve this problem in Python2. The following works in Python3.6 (If I remember correctly it was py36, where `os.path` start to accept `pathlib.Path`):

```python
    export_dir = compat.as_bytes(os.path.join(
        export_dir_base,
        str(export_timestamp)))
```
Since the name `tensorflow.python.util.compat.as_bytes` does not imply that the input is a path, I am not sure if that would be a better place to solve the problem.

### Source code / logs
Here some pseudo code (I hope with this example the tensoflowers are able to reproduce this bug in py36): 
```python
from pathlib import Path
tf.estimator.Estimator(...).export_savedmodel(
            Path('path/to/save'),
            export_input_fn,
            as_text=True,
        )
```"
14994,Tensorflow," >>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
ImportError: /home/sovietsky/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: cuDevicePrimaryCtxRetain


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
14993,Using tfdbg with errors.,"VERSION: TF-1.4.0

Problem:
  I want to use tfdbg to debug NaN problem with `tf_debug.LocalCLIDebugHook()` , but encounter thie problem.
  One more question, how to lower the size of dump files?

Logging is below:
```
Traceback (most recent call last):
  File ""./train.py"", line 166, in <module>
    _, loss, l2_loss, predicted, labels, label_lengths, step = sess.run(ops)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 521, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 892, in run
    run_metadata=run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 967, in run
    raise six.reraise(*original_exc_info)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 952, in run
    return self._sess.run(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1032, in run
    run_metadata=run_metadata))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/wrappers/hooks.py"", line 157, in after_run
    self._session_wrapper.on_run_end(on_run_end_request)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py"", line 321, in on_run_end
    self._dump_root, partition_graphs=partition_graphs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 495, in __init__
    self._load_all_device_dumps(partition_graphs, validate)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 517, in _load_all_device_dumps
    self._load_partition_graphs(partition_graphs, validate)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 798, in _load_partition_graphs
    self._validate_dump_with_graphs(debug_graph.device_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/debug/lib/debug_data.py"", line 874, in _validate_dump_with_graphs
    (node, datum.timestamp, repr(pending_inputs[node])))
ValueError: Causality violated in timing relations of debug dumps: model_train/model/model/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge (1512027705071447): these input(s) are not satisfied: [(u'model_train/model/model/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Switch_1', 1)]
```

"
14990,fcn network to tensorflow lite ?,"Input:
(u'input_image', (<tf.Tensor 'input_image:0' shape=<unknown> dtype=float32>,))
(u'image_width', (<tf.Tensor 'image_width:0' shape=<unknown> dtype=int32>,))
(u'image_height', (<tf.Tensor 'image_height:0' shape=<unknown> dtype=int32>,))

Output:
(u'Squeeze', (<tf.Tensor 'Squeeze:0' shape=(?, ?, 2) dtype=float32>,))
(u'Squeeze_1', (<tf.Tensor 'Squeeze_1:0' shape=(?, ?, 4) dtype=float32>,))
(u'Squeeze_2', (<tf.Tensor 'Squeeze_2:0' shape=(?, ?, 10) dtype=float32>,))

how to do?
 bazel-bin/tensorflow/contrib/lite/toco/toco \
  --input_file=PNet.pb \
  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \
  --output_file=PNet.float.lite --inference_type=FLOAT \
  --input_type=FLOAT --input_arrays=input_image,image_width,image_height \
  --output_arrays=Squeeze,Squeeze_1 --input_shapes=?


tensorflow/contrib/lite/toco/tooling_util.cc:1547] Check failed: array.final_data_type == array.data_type"
14989,gen_image_ops.py,
14988,tf.image.crop_and_resize,"- [ ] 

- [ ] #-

 **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:N/A
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 14.04LTS
- **TensorFlow installed from (source or binary)**: yes
- **TensorFlow version (use command below)**: 1.3.0
- **Python version**: 2.7.6
- **Bazel version (if compiling from source)**:N/A
- **GCC/Compiler version (if compiling from source)**:N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**:N/A
- **Exact command to reproduce**:N/A

Anyone know how the 
tf.image.crop_and_resize(images, boxes, batch_inds,
                                         [pooled_height, pooled_width],
                                         method='bilinear',
                                         name='Crop')
work? i cannot find the "" tf.image.crop_and_resize"" in  tensorflow/python/ops/gen_image_ops.py. 
Thank you"
14985,tf.nn.fractional_max_pool output have same batch size when feed with different input batch size,"
### Describe the problem
tf.nn.fractional_max_pool output have same batch size when feed with different input batch size.
Attached is test code I write. 2 different input is feed in with different batch size , outputs get same batch size.
[pool_test.py.txt](https://github.com/tensorflow/tensorflow/files/1516498/pool_test.py.txt)

###code result
shape of input_a (3, 32, 32, 3)
shape of output_a (3, 21, 21, 3)
shape of input_b **(4, 32, 32, 3)**
shape of output_b **(3, 21, 21, 3)**

### System information

== cat /etc/issue ===============================================
Linux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
numpydoc (0.7.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow'

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Nov 30 11:55:40 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
|  0%   51C    P8    21W / 280W |    860MiB / 11169MiB |      9%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |
|    0      1540      G   compiz                                       315MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61

== cat /etc/issue ===============================================
Linux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""16.04.3 LTS (Xenial Xerus)""
VERSION_ID=""16.04""
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux c-1080u 4.10.0-40-generic #44~16.04.1-Ubuntu SMP Thu Nov 9 15:37:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.5.0.post1)
tensorflow-gpu (1.4.0)
tensorflow-tensorboard (0.4.0rc3)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Thu Nov 30 11:56:18 2017       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:01:00.0  On |                  N/A |
|  0%   51C    P0    80W / 280W |    860MiB / 11169MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1060      G   /usr/lib/xorg/Xorg                           542MiB |
|    0      1540      G   compiz                                       315MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61




"
14980,tensorflow-gpu install from pip breaks conda on windows,"Your instructions for installing tensorflow-gpu on windows often breaks peoples conda installations forcing a complete reinstall. This also forces a rebuilding of previous environments which no longer function.

https://stackoverflow.com/questions/46356732/anaconda-prompt-corrupts-after-installation/46493533#46493533

Some kind of warning or recommendation to check the above thread could really help. This seems like a problem with the tensorflow website instructions as opposed to a tensorflow issue."
14978,Header mismatch when running 'Simple Audio Recognition',"tensorflow: 1.4, ubuntu 17.10, python3.6 anaconda, cuda 8.0, cudnn 6.0

Going with [Simple Audio Recognition](https://www.tensorflow.org/versions/master/tutorials/audio_recognition), I met an error when running 
```bash
python tensorflow/examples/speech_commands/train.py --data_dir=tensorflow/examples/speech_commands/train/audio
```

error:
```
Traceback (most recent call last):                                                                                                                            
  File ""/home/jihao/.conda/envs/tf_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1323, in _do_call                               
    return fn(*args)                                                                                                                                          
  File ""/home/jihao/.conda/envs/tf_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1302, in _run_fn                                
    status, run_metadata)                                                                                                                                     
  File ""/home/jihao/.conda/envs/tf_cpu/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in __exit__                         
    c_api.TF_GetCode(self.status.status))                                                                                                                     
tensorflow.python.framework.errors_impl.InvalidArgumentError: Header mismatch: Expected RIFF but found \udc87\udc9b\udc8f\udc8c                               
         [[Node: DecodeWav = DecodeWav[desired_channels=1, desired_samples=-1, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](ReadFile)]]
```
"
14975,master branch: compilation of llvm_gpu_backend failed,"### System information
- **OS Platform and Distribution**: slackware64-current
- **Python version**: 3.6.3
- **Bazel version**: 0.8.0
- **GCC/Compiler version**: 5.4.0
- **CUDA/cuDNN version**: 9 / 7
- **build environment**:
export PYTHON_BIN_PATH=/usr/bin/python3
export USE_DEFAULT_PYTHON_LIB_PATH=1
export CC_OPT_FLAGS=""-march=native""
export TF_NEED_JEMALLOC=1
export TF_NEED_S3=1
export TF_NEED_GCP=0
export TF_NEED_HDFS=0
export TF_NEED_GDR=0
export TF_ENABLE_XLA=1
export TF_NEED_VERBS=0
export TF_NEED_OPENCL=0
export TF_NEED_MKL=1
export TF_NEED_MPI=0
export TF_NEED_CUDA=1
export GCC_HOST_COMPILER_PATH=/opt/gcc54/bin/gcc-5.4.0
export TF_CUDA_CLANG=0
export TF_NEED_OPENCL_SYCL=0
export CLANG_CUDA_COMPILER_PATH=/usr/bin/clang
export CUDA_TOOLKIT_PATH=/usr/share/cuda
export TF_CUDA_VERSION=$($CUDA_TOOLKIT_PATH/bin/nvcc --version | sed -n 's/^.*release \(.*\),.*/\1/p')
export CUDNN_INSTALL_PATH=/usr/share/cuda
export TF_CUDNN_VERSION=$(sed -n 's/^#define CUDNN_MAJOR\s*\(.*\).*/\1/p' $CUDNN_INSTALL_PATH/include/cudnn.h)
export TF_CUDA_COMPUTE_CAPABILITIES=3.0
sed -i 's|/lib""|/lib64""|g' third_party/mkl/build_defs.bzl
sed -i 's|""lib""|""lib64""|g' third_party/mkl/build_defs.bzl
sed -i 's|/lib|/lib64|g' tensorflow/c/generate-pc.sh
- **build command**:
./configure
bazel build --config=opt --config=cuda --config=mkl //tensorflow:libtensorflow.so //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package tmp`

### Building from master fails
ERROR: /tmp/SBo-VCS/tensorflow_cuda-VCS/tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/BUILD:16:1: C++ compilation of rule '//tensorflow/compiler/xla/service/gpu/llvm_gpu_backend:llvm_gpu_backend' failed (Exit 1)
tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:37:41: fatal error: llvm/CodeGen/CommandFlags.def: No such file or directory
compilation terminated.
INFO: Elapsed time: 1828.121s, Critical Path: 131.49s
FAILED: Build did NOT complete successfully"
14973,Tensor as index to other tensor not supported?,"I have 2 tensors (one is constant and one is placeholder), lets say:
A = [0.1,0.2,0.3,0.4,0.5,0.6,0.7]
B = [[1,2,4],[5,0],[3]]
I want to build a tensor C like this:
C= [[0.2,0.3,0.5],[0.6,0.1],[0.4]] which is a tensor in the same size of B and every element in C is equal to element in A indexed by B elements.

is there any way to do that?

Thanks!"
14972,Support optional activation function to produce attentional hidden states,"*This is a feature request.*

When using an `AttentionWrapper` with the `attention_layer_size` argument set, the cell output and the context are combined and fed through a dense layer to produce an attentional hidden state.

However, it is also common to apply an activation function on this layer output (typically *tanh*). This is for example described in:

> Minh-Thang Luong, Hieu Pham, Christopher D. Manning. ""Effective Approaches to Attention-based Neural Machine Translation."" EMNLP 2015.  https://arxiv.org/abs/1508.04025

I would be happy to contribute. Do we want to add a new argument `attention_layer_activation=None` to the `AttentionWrapper` constructor?"
14970,AttributeError: module 'tensorflow' has no attribute 'session',"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug or a feature request.
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 (64bit)
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**: 1.4
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

### Describe the problem
Why in tensorflow 1.4 when running validating command in sess = tf.session() Line gives this error? is Session attribute changed in 1.4 version of tensorflow compare to previous versions Like 0.12?

### Source code / logs
>>> import tensorflow as tf
>>> hello = tf.constant ('hello, tensorflow!')
>>> sess = tf.session ()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'session'"
14969,remplace .npy weight file from a checkpoint,"Hi,
I went modify this line of code (loading weights from pretrained mode):
weights_dict = np.load(self.WEIGHTS_PATH, encoding = 'bytes').item()

where WEIGHTS_PATH is a an npy file WEIGHTS_PATH = 'bvlc_alexnet.npy'

by my own weights saved in checkpoint.

Thanks a lot"
14968,Question about tf.contrib.image.rotate,"Good Morning :) -
is it possible to parse the result from `tf.contrib.image.rotate` to a tensor to use it in `t.cast` ?

"
14966,why the size of filter is 3*3 in inceptionv1.py?,"https://github.com/tensorflow/tensorflow/blob/b5df90f91cde6eb12af9cbe818bd2cf4a9bcc687/tensorflow/contrib/slim/python/slim/nets/inception_v1.py#L103
according to the paper,  the size of filter in the scope of ""InceptionV1/Mixed_3b/Branch_2""  should be 5*5.
why is 3*3 in the script?"
14965,compile tensorflow with the source code-----ERROR,"when i compile tensorflow with the source code,an ERROR appear. If you know how to solve this problem,please help me. Thank you.

ERROR: /home/hy003/tensorflow/tensorflow/python/BUILD:4508:1 C++ compilation of rule '//tensorflow/python:framework/fast_tensor_util.so' failed(Exit 1). bazel-out/local-opt/genfiles/tensorflow/python/framework/fast_tensor_util.cpp: In function 'PyObject* __pyx_f_5numpy_PyDataType_SHAPE(PyArray_Descr*)': bazel-out/local/genfiles/tensorflow/python/framework/fastz_tensor_util.cpp:5500:48: error 'PyDataType_HASSUBARRAY' was not declared in this scope  __pyx_t_1 = (PyDataType_HASSUBARRAY(__pyx_v_d != 0))  "
14964,Has anybody ever written a gradient for the operator 'SparseReduceSumSparse' ?,"I could only find a gradient for `SparseReduceSum`.

```
@ops.RegisterGradient(""SparseReduceSum"")
def _SparseReduceSumGrad(op, out_grad):
  """"""Similar to gradient for the Sum Op (i.e. tf.reduce_sum()).""""""
  sp_indices = op.inputs[0]
  sp_shape = op.inputs[2]
  output_shape_kept_dims = math_ops.reduced_shape(sp_shape, op.inputs[3])
  out_grad_reshaped = array_ops.reshape(out_grad, output_shape_kept_dims)
  scale = sp_shape // math_ops.to_int64(output_shape_kept_dims)
  # (sparse_indices, sparse_values, sparse_shape, reduction_axes)
  return (None, array_ops.gather_nd(out_grad_reshaped, sp_indices // scale),
          None, None)
```

It seems uneasy to write a similar gradient for operator `SparseReduceSumSparse`.
Could anyone give me a hand? Thanks."
14963,Documentation of tf.nn.raw_rnn is confusing,"The documentation for the tf.nn.raw_rnn displays the following line as the pseudocode for the function:
<br>
`(finished, next_input, initial_state, _, loop_state) = loop_fn(
    time=time, cell_output=None, cell_state=None, loop_state=None)`
<br>
This is the first time the loop_fn is called by the raw_rnn interface. Here, the '_' for the emit_output returned by the loop_fn is a **_do not care_** for the function. This misleads the user into believing that returning `None` for the first time as the `emit_output` is OK.

However, the actual code has the line:
<br>
`(elements_finished, next_input, initial_state, emit_structure,
     init_loop_state) = loop_fn(
         time, None, None, None)  # time, cell_output, cell_state, loop_state`
<br>
The code uses the `emit_structure` from the `emit_output` that then determines the shape of the emitted output to be aggregated in the `emit_ta` array. 
So, even for the first time the `loop_fn` needs to output a mock tensor for setting the shape of the output values.

The documentation needs to include this as going through the framework implementation for figuring this out is too tiresome. 

Cheers!"
14962,Tensorflow Conv model crashes on GPU with zero size batch,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, I have created two CNN models
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: I installed tensorflow via pip install (Python 3)
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**: 
- **CUDA/cuDNN version**: 8.0/6
- **GPU model and memory**: NVIDIA Tesla k80 totalMemory: 11.17GiB freeMemory: 11.09GiB
- **Exact command to reproduce**: See below:

### Below is the log:

> keep_dims is deprecated, use keepdims instead
> _________________________________________________________________
> Layer (type)                 Output Shape              Param #   
> =================================================================
> input_1 (InputLayer)         (None, 7, 264)            0         
> _________________________________________________________________
> reshape_1 (Reshape)          (None, 7, 264, 1)         0         
> _________________________________________________________________
> conv2d_1 (Conv2D)            (None, 7, 264, 64)        16960     
> _________________________________________________________________
> max_pooling2d_1 (MaxPooling2 (None, 7, 132, 64)        0         
> _________________________________________________________________
> flatten_1 (Flatten)          (None, 59136)             0         
> _________________________________________________________________
> dense_1 (Dense)              (None, 1024)              60556288  
> _________________________________________________________________
> dropout_1 (Dropout)          (None, 1024)              0         
> _________________________________________________________________
> dense_2 (Dense)              (None, 512)               524800    
> _________________________________________________________________
> dropout_2 (Dropout)          (None, 512)               0         
> _________________________________________________________________
> dense_3 (Dense)              (None, 88)                45144     
> =================================================================
> Total params: 61,143,192
> Trainable params: 61,143,192
> Non-trainable params: 0
> _________________________________________________________________
> /home/hpnhxxwn/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py:2057: UserWarning: Using a generator with `use_multiprocessing=True` and multiple worker
> s may duplicate your data. Please consider using the`keras.utils.Sequence class.
>   UserWarning('Using a generator with `use_multiprocessing=True`'
> ld: learning rate is now 0.01
> 2017-11-29 04:58:20.964015: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX A
> VX2 FMA
> 2017-11-29 04:58:21.094051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUM
> A node, so returning NUMA node zero
> 2017-11-29 04:58:21.094719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties: 
> name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
> pciBusID: 0000:00:04.0
> totalMemory: 11.17GiB freeMemory: 11.09GiB
> 2017-11-29 04:58:21.094744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0
> , compute capability: 3.7)
> Epoch 1/1000
> 5180/6944 [=====================>........] - ETA: 3:43 - loss: 0.1382 - acc: 0.9637 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1640e-05switching to  ['AkPnStgb']
> 5212/6944 [=====================>........] - ETA: 3:39 - loss: 0.1384 - acc: 0.9636 - mean_absolute_error: 0.0715 - sparse_categorical_accuracy: 7.1200e-052017-11-29 05:09:22.210897: F
>  tensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not convert BatchDescriptor {count: 0 feature_map_count: 64 spatial: 7 264  value_min: 0.000000 value_max: 0.000000 layout: Batc
> hDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM




### Below is the model. 
```
def baseline_model():
    inputs = Input(shape=input_shape)
    reshape = Reshape(input_shape_channels)(inputs)
    #normal convnet layer (have to do one initially to get 64 channels)
    conv1 = Conv2D(50,(5,25),activation='tanh')(reshape)
    do1 = Dropout(0.5)(conv1)
    pool1 = MaxPooling2D(pool_size=(1,3))(do1)
    conv2 = Conv2D(50,(3,5),activation='tanh')(pool1)
    do2 = Dropout(0.5)(conv2)
    pool2 = MaxPooling2D(pool_size=(1,3))(do2)
    flattened = Flatten()(pool2)
    fc1 = Dense(1000, activation='sigmoid')(flattened)
    do3 = Dropout(0.5)(fc1)
    fc2 = Dense(200, activation='sigmoid')(do3)
    do4 = Dropout(0.5)(fc2)
    outputs = Dense(note_range, activation='sigmoid')(do4)
    model = Model(inputs=inputs, outputs=outputs)
    return model
````

I have found other github issue created for the same issue, not so far seems like there is no fix yet. I heard the workaround is to use tf.cond, can someone show me how to use it in such case. "
14960,Method of stabilizing prediction box,"I found that when I used other methods to detect objects, the prediction box was not stable. However, in the demo you provided, I found that the detection box is very stable. Why, can you give me the code to stabilize the detection box?"
14959,[BUG]Out-of-Bounds Read in DecodeBmpOp class(tensorflow/core/kernels/decode_bmp_op.cc),"------------------------

### System information
- **The following is output of tf_env_collect.sh**:
== cat /etc/issue ===============================================
Linux ubuntu 4.4.0-31-generic #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""14.04.5 LTS, Trusty Tahr""
VERSION_ID=""14.04""

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux ubuntu 4.4.0-31-generic #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc2)

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = v1.4.0-rc1-11-g130a514
tf.COMPILER_VERSION = v1.4.0-rc1-11-g130a514
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
                                                              

### Describe the problem
The DecodeBmpOp class is the decoder of bmp file. The class is in 
 tensorflow/core/kernels/decode_bmp_op.cc. When dealling with a bmp file, the decoder doesn't invalidate the meta info of bmp file, such as header_size, width, height. It causes a Out-of-Bound Read in DecodeBmpOp::Decode func or DecodeBmpOp ::Compute func. If given an evil bmp file, the program using this API will crash.

### Source code / logs

- **Here is the crash call stack of program**:
The bmp file  in the attachment causes a crash.

Program received signal SIGSEGV, Segmentation fault.
0x0000000004200bc0 in tensorflow::DecodeBmpOp::Decode (this=this@entry=0x602400032a40, input=input@entry=0x601c000214ce ""33"", output=0x7fffcefcf800 """", width=width@entry=2336, height=height@entry=61727, channels=channels@entry=3, top_down=top_down@entry=false) at tensorflow/core/kernels/decode_bmp_op.cc:122
Program received signal SIGSEGV (fault address 0x601c19caaa10)
pwndbg> bt
#0  0x0000000004200bc0 in tensorflow::DecodeBmpOp::Decode (this=this@entry=0x602400032a40, input=input@entry=0x601c000214ce ""33"", output=0x7fffcefcf800 """", width=width@entry=2336, height=height@entry=61727, channels=channels@entry=3, top_down=top_down@entry=false) at tensorflow/core/kernels/decode_bmp_op.cc:122
#1  0x0000000004202d3b in tensorflow::DecodeBmpOp::Compute (this=0x602400032a40, context=<optimized out>) at tensorflow/core/kernels/decode_bmp_op.cc:88
#2  0x00007ffff3ed8880 in tensorflow::ThreadPoolDevice::Compute (this=<optimized out>, op_kernel=0x602400032a40, context=0x7fffffff8320) at tensorflow/core/common_runtime/threadpool_device.cc:59
#3  0x00007ffff3d47110 in tensorflow::(anonymous namespace)::ExecutorState::Process (this=<optimized out>, tagged_node=..., scheduled_usec=<optimized out>) at tensorflow/core/common_runtime/executor.cc:1652
#4  0x00007ffff3d4cc0c in operator() (__closure=<optimized out>) at tensorflow/core/common_runtime/executor.cc:2055
#5  std::_Function_handler<void(), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(const TaggedNodeSeq&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::__lambda3>::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/4.8/functional:2071
#6  0x00007ffff3db2351 in operator() (this=0x7fffffff8790) at /usr/include/c++/4.8/functional:2471
#7  operator() (__closure=<optimized out>, c=...) at tensorflow/core/common_runtime/graph_runner.cc:146
#8  std::_Function_handler<void(std::function<void()>), tensorflow::GraphRunner::Run(tensorflow::Graph*, tensorflow::FunctionLibraryRuntime*, const NamedTensorList&, const std::vector<std::basic_string<char> >&, std::vector<tensorflow::Tensor>*)::__lambda2>::_M_invoke(const std::_Any_data &, std::function<void()>) (__functor=..., __args#0=...) at /usr/include/c++/4.8/functional:2071
#9  0x00007ffff3ce0258 in operator() (__args#0=..., this=<optimized out>) at /usr/include/c++/4.8/functional:2471
#10 tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady (this=0x6026000fd1a0, ready=..., inline_ready=0x0) at tensorflow/core/common_runtime/executor.cc:2055
#11 0x00007ffff3d00a0c in ScheduleReady (inline_ready=0x0, ready=..., this=<optimized out>) at tensorflow/core/common_runtime/executor.cc:2046
#12 RunAsync (done=<error reading variable: access outside bounds of object referenced via synthetic pointer>, this=<optimized out>) at tensorflow/core/common_runtime/executor.cc:1439
#13 tensorflow::(anonymous namespace)::ExecutorImpl::RunAsync (this=this@entry=0x602400032f40, args=..., done=...) at tensorflow/core/common_runtime/executor.cc:2564
#14 0x00007ffff3db999f in Run (args=..., this=0x602400032f40) at ./tensorflow/core/common_runtime/executor.h:117
#15 tensorflow::GraphRunner::Run (this=this@entry=0x6004002d08f0, graph=graph@entry=0x603a00003140, function_library=function_library@entry=0x602400033800, inputs=std::vector of length 0, capacity 0, output_names=std::vector of length 1, capacity 1 = {...}, outputs=outputs@entry=0x7fffffffa810) at tensorflow/core/common_runtime/graph_runner.cc:174
#16 0x00007ffff3c4f36d in tensorflow::ConstantFold (opts=..., function_library=function_library@entry=0x602400033800, env=env@entry=0x60060000e140, partition_device=partition_device@entry=0x6024000395c0, graph=graph@entry=0x603a00003480, was_mutated=was_mutated@entry=0x7fffffffb260) at tensorflow/core/common_runtime/constant_folding.cc:603
#17 0x00007ffff3db02bd in tensorflow::GraphOptimizer::Optimize (this=this@entry=0x7fffffffbe90, runtime=runtime@entry=0x602400033800, env=0x60060000e140, device=0x6024000395c0, graph=graph@entry=0x60060038d2f0, shape_map=shape_map@entry=0x0) at tensorflow/core/common_runtime/graph_optimizer.cc:66
#18 0x000000000ad04984 in tensorflow::DirectSession::GetOrCreateExecutors (this=this@entry=0x604000007080, inputs=..., outputs=..., target_nodes=..., executors_and_keys=executors_and_keys@entry=0x7fffffffc4f0, run_state_args=run_state_args@entry=0x7fffffffc730) at tensorflow/core/common_runtime/direct_session.cc:1208
#19 0x000000000ad0d0f7 in tensorflow::DirectSession::Run (this=<optimized out>, run_options=..., inputs=std::vector of length 0, capacity 0, output_names=std::vector of length 1, capacity 1 = {...}, target_nodes=std::vector of length 0, capacity 0, outputs=0x0, run_metadata=0x0) at tensorflow/core/common_runtime/direct_session.cc:472
#20 0x000000000ad6fa95 in tensorflow::ClientSession::Run (this=this@entry=0x7fffffffdc30, run_options=..., inputs=std::unordered_map with 0 elements, fetch_outputs=std::vector of length 1, capacity 1 = {...}, run_outputs=std::vector of length 0, capacity 0, outputs=outputs@entry=0x0, run_metadata=run_metadata@entry=0x0) at tensorflow/cc/client/client_session.cc:127
#21 0x000000000ad74b6d in Run (outputs=0x0, run_outputs=std::vector of length 0, capacity 0, fetch_outputs=std::vector of length 1, capacity 1 = {...}, inputs=std::unordered_map with 0 elements, this=0x7fffffffdc30) at tensorflow/cc/client/client_session.cc:90
#22 tensorflow::ClientSession::Run (this=this@entry=0x7fffffffdc30, fetch_outputs=std::vector of length 1, capacity 1 = {...}, outputs=outputs@entry=0x0) at tensorflow/cc/client/client_session.cc:76
#23 0x000000000048042a in main (argc=1, argc@entry=2, argv=argv@entry=0x7fffffffe2e8) at tensorflow/examples/decode_image/main.cc:99
#24 0x00007ffff03c1f45 in __libc_start_main (main=0x47e4b0 <main(int, char**)>, argc=2, argv=0x7fffffffe2e8, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffe2d8) at libc-start.c:287
#25 0x0000000000737eca in _start ()

- **source code of c++ program**:
#include <fstream>
#include <utility>
#include <vector>

#include ""tensorflow/cc/ops/const_op.h""
#include ""tensorflow/cc/ops/image_ops.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/graph.pb.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/graph/default_device.h""
#include ""tensorflow/core/graph/graph_def_builder.h""
#include ""tensorflow/core/lib/core/errors.h""
#include ""tensorflow/core/lib/core/stringpiece.h""
#include ""tensorflow/core/lib/core/threadpool.h""
#include ""tensorflow/core/lib/io/path.h""
#include ""tensorflow/core/lib/strings/stringprintf.h""
#include ""tensorflow/core/platform/env.h""
#include ""tensorflow/core/platform/init_main.h""
#include ""tensorflow/core/platform/logging.h""
#include ""tensorflow/core/platform/types.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/util/command_line_flags.h""
#include ""tensorflow/cc/client/client_session.h""

// These are all common classes it's handy to reference with no namespace.
using tensorflow::Flag;
using tensorflow::Tensor;
using tensorflow::Status;
using tensorflow::string;
using tensorflow::int32;

int main(int argc, char* argv[]) {
  string image = ""tensorflow/examples/label_image/data/grace_hopper.jpg"";
  std::vector<Flag> flag_list = {
      Flag(""image"", &image, ""image to be processed""),
  };
  string usage = tensorflow::Flags::Usage(argv[0], flag_list);
  const bool parse_result = tensorflow::Flags::Parse(&argc, argv, flag_list);
  if (!parse_result) {
    LOG(ERROR) << usage;
    return -1;
  }

  // We need to call this to set up global state for TensorFlow.
  tensorflow::port::InitMain(argv[0], &argc, &argv);
  if (argc > 1) {
    LOG(ERROR) << ""Unknown argument "" << argv[1] << ""\n"" << usage;
    return -1;
  }

        using namespace ::tensorflow::ops;

  auto root = tensorflow::Scope::NewRootScope();
  tensorflow::Output file_reader = ReadFile(root.WithOpName(""input_image""), image);
        tensorflow::Output gif_reader = DecodeGif(root.WithOpName(""gif_reader""), file_reader);
        tensorflow::Output bmp_reader = DecodeBmp(root.WithOpName(""bmp_reader""), file_reader);
        tensorflow::Output jpeg_reader = DecodeJpeg(root.WithOpName(""jpeg_reader""), file_reader);
        tensorflow::Output png_reader = DecodePng(root.WithOpName(""png_reader""), file_reader);

        std::vector<tensorflow::Tensor> outputs;
        tensorflow::ClientSession session(root);
  session.Run({gif_reader}, nullptr);
  session.Run({bmp_reader}, nullptr);
  session.Run({jpeg_reader}, nullptr);
  session.Run({png_reader}, nullptr);

  return 0;
}

- **source code of python program**:
import argparse
import tensorflow as tf

if __name__ == ""__main__"":
        file_name = ""tensorflow/examples/label_image/data/grace_hopper.jpg""
        parser = argparse.ArgumentParser()
        parser.add_argument(""--image"", help=""image to be processed"")
        args = parser.parse_args()
        if args.image:
            file_name = args.image
        file_reader = tf.read_file(file_name, ""file_reader"")
        image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')
        sess = tf.Session()
        sess.run(image_reader)

[evil.zip](https://github.com/tensorflow/tensorflow/files/1512398/evil.zip)

"
14957,tf.profiler reports 0B memory usage,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.5.0-dev20171103
- **Python version**: 3.5
- **Exact command to reproduce**:

``` python
import tensorflow as tf
import numpy as np

graph = tf.Graph()
with graph.as_default(), tf.device(""/cpu:0""):
    a = tf.constant(np.ones((1000, 1000)))
    b = tf.constant(np.ones((1000, 1000)))
    c = a * b

with tf.Session(graph=graph) as sess:
    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
    run_metadata = tf.RunMetadata()
    sess.run(c, options=run_options, run_metadata=run_metadata)

    options = tf.profiler.ProfileOptionBuilder.time_and_memory()
    options[""min_bytes""] = 0
    options[""select""] = (""bytes"", ""peak_bytes"", ""output_bytes"",
                         ""residual_bytes"")
    tf.profiler.profile(graph, run_meta=run_metadata, cmd=""scope"",
                        options=options)
```

### Describe the problem
The above script gives output
```
==================Model Analysis Report======================
node name | requested bytes | peak bytes | residual bytes | output bytes
_TFProfRoot (--/0B, --/0B, --/0B, --/8.00MB)
  mul (0B/0B, 0B/0B, 0B/0B, 8.00MB/8.00MB)
  _retval_mul_0_0 (0B/0B, 0B/0B, 0B/0B, 0B/0B)
```
`requested bytes` and `peak bytes` are both reported as 0, whereas I would have thought they would be 8MB (based on the description of these measures [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/g3doc/options.md)).  

I think the memory is not being recorded in the `RunMetadata` the way the profiler expects.  For example, if we look at 
``` python
    mul_stats = run_metadata.step_stats.dev_stats[0].node_stats[1]

    print(""total_bytes"", [x.total_bytes for x in mul_stats.memory])   # --> [0]
    print(""persistent_mem"", mul_stats.memory_stats.host_persistent_memory_size)  # --> 8000000
```
`""total_bytes""` is what the profiler reports as ""requested bytes"" above.  It seems like that data isn't being updated in the `run_metadata`.  The correct value is in `memory_stats.host_persistent_memory_size`, but that value isn't available in the profiler output.  And according to the [profiler proto](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/core/profiler/tfprof_log.proto) that value is supposed to represent the bytes allocated to persistent objects (like Variables), even though none of the values in the example are persistent.  So I'm not sure if this is an issue with `tf.profiler`, or with how memory information is stored in `RunMetadata`."
14956,traceback error,"Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec cod in run_globals
  File ""/usr/lib/python2.7/py_compile.py"", line 181, in <module>
    sys.exit(main())
  File ""/usr/lib/python2.7/py_compile.py"", line 173, in main
    compile(filename, doraise=True)
  File ""/usr/lib/python2.7/py_compile.py"", line 106, in compile
    with open(file, 'U') as f:
IOError: [Errno 2] No such file or directory: ''
[Finished in 0.7s with exit code 1]
[shell_cmd: python -m py_compile """"]
[dir: /opt/sublime_text]
[path: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/lib/jvm/java-8-oracle/bin:/usr/lib/jvm/java-8-oracle/db/bin:/usr/lib/jvm/java-8-oracle/jre/bin]c"
14954,enable get the 'mathematical' gradient of output w.r.t neural network parameters,"In some situation, it is necessary to get the 'mathematical' gradient of output w.r.t neural network parameters. 

For example, suppose I have a neural network `out = f(s)`, where `s` is a batch of input with shape`[None, dim_s]`, while out is a scaler, `f` is simply a MLP. With `tf.gradient(out, tf.trainable_variables())` I can get gradient of out w.r.t neural network parameters of f, which is a list of gradient. Now, I have two different batch of `s`: `s1` and `s2`, then we can get two different the above gradients `G1` and `G2`. It seems that it is impossible to compute cosine between `G1` and `G2` using current tensorflow? Do I need to flatten both gradients first? Do `G1` and `G2` are the usual gradient in math? "
14951,Document S3 `S3_REGION` constant,"This gave me a lot of grief recently as the AWS Region for S3 is controlled by an undocumented constant `S3_REGION` which defaults to `us-east-1` unless defined on the system-level. Extra frustrating as it departs from the common naming practice: `AWS_REGION`:

https://github.com/tensorflow/tensorflow/blob/79422ab39b5fe0e1491abb8deabc7ecb5fd9f3a2/tensorflow/core/platform/s3/s3_file_system.cc#L52

If somebody could suggest where to document this, I'd be happy to contribute. "
14950,Incorrect GPU memory usage ,"    with tf.device('/gpu:0') :
    	with tf.variable_scope('network1') :
    		x = tf.get_variable('inp1',shape = [256,50,50,3],dtype = tf.float32)
    		w1 = tf.get_variable('weight1',shape = [1,1,3,256],dtype = tf.float32)
    		y1 = tf.nn.conv2d(x, w1, strides=[1, 1, 1, 1], padding='VALID')
    		w1 = tf.get_variable('weight2',shape = [1,1,256,256],dtype = tf.float32)
    		y1 = tf.nn.conv2d(y1, w1, strides=[1, 1, 1, 1], padding='VALID')
    		w1 = tf.get_variable('weight3',shape = [1,1,256,1],dtype = tf.float32)
    		y1 = tf.nn.conv2d(y1, w1, strides=[1, 1, 1, 1], padding='VALID')
    	
    
    with tf.device('/gpu:0') :
    	with tf.variable_scope('network2') :
    		x1 = tf.get_variable('inp2',shape = [1,3],dtype = tf.float32)
    		w2 = tf.get_variable('weight4',shape = [3,8192],dtype = tf.float32)
    		y2 = tf.matmul(x1,w2)
    		w2 = tf.get_variable('weight5',shape = [8192,8192],dtype = tf.float32)
    		y2 = tf.matmul(y2,w2)
    		w2 = tf.get_variable('weight6',shape = [8192,1],dtype = tf.float32)
    		y2 = tf.matmul(y2,w2)

If I have the above model graph, then running it on a GPU and checking memory usage via nvidia-smi shows usage of 4200MB . However when running only the network1 and commenting out network2, nvidia-smi shows usage of 2200 MB. With only network2, it shows usage of 700MB.I have already set gpu_options.allow_growth = True

How is then the total graph using 4200 MB when it should have used only 2900(2200 + 700)MB ?

I am using Ubuntu 14.04, python version - 2.7 , tensorflow version - 1.2"
14948,Setup.py on CentOS7 pywrap_tensorflow_internal Error,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux CentOS7
TensorFlow installed from (source or binary):
Setup.py
TensorFlow version (use command below):
1.3
Python version:
2.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
4.8.5
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:
import tensorflow as tf
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

tf_env_collect.sh output:

== cat /etc/issue ===============================================
Linux rs-control1 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
VERSION=""7 (Core)""
VERSION_ID=""7""
CENTOS_MANTISBT_PROJECT_VERSION=""7""
REDHAT_SUPPORT_PRODUCT_VERSION=""7""

== are we in docker =============================================
No

== compiler =====================================================
c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-16)
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

== uname -a =====================================================
Linux rs-control1 3.10.0-327.36.1.el7.x86_64 #1 SMP Sun Sep 18 13:04:29 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================

== check for virtualenv =========================================
False

== tensorflow import ============================================
Traceback (most recent call last):
File """", line 1, in 
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/init.py"", line 24, in 
from tensorflow.python import *
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/init.py"", line 49, in 
from tensorflow.python import pywrap_tensorflow
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in 
from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions. Include the entire stack trace
above this error message when asking for help.

You can obtain the TensorFlow version with

python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""

Describe the problem

Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

Installing using setup.py works until trying to import tensorflow, causing an Import Error for pywrap_tensorflow_internal

Dependencies I believe are met and using setup.py because I'm building this into an rpm to deploy to different nodes and clusters.

Source code / logs

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Simply running setup.py and then import tensorflow as tf produces Import Error:
Traceback (most recent call last):
File ""/tmp/check_tf.py"", line 1, in 
import tensorflow as tf;
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/init.py"", line 24, in 
from tensorflow.python import *
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/init.py"", line 49, in 
from tensorflow.python import pywrap_tensorflow
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 52, in 
raise ImportError(msg)
ImportError: Traceback (most recent call last):
File ""/usr/local/python-tgt-201701/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 41, in 
from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal"
14947,Tensorflow minimize operation runs into shape mismatch with StridedSliceGrad,"System Info:
   - custom code
   - Linux Ubuntu 16.04
   - Tensorflow 1.4.0 installed with pip install tensorflow-gpu
   - python 2.7
   - CuDa 8
   - terminal command just calls my script with ""python GAN.py""

Source code:

input_points = tf.placeholder(shape=[batch_size, 2048, 3], dtype=tf.float32)
latent_vector = encoder(input_points, encoder_weights, encoder_biases)                       
reconstructed_points = decoder(latent_vector, decoder_weights, decoder_biases)               
                                                                                                 
AE_loss = chamfer_distance(input_points, reconstructed_points, batch_size)                   
                                                                                        
AE_optimizer = tf.train.AdamOptimizer(learning_rate=0.0005, beta1=0.9)                       
AE_minimizer = AE_optimizer.minimize(AE_loss)



Context: The input points and reconstructed points are the same shape. After the call to chamfer_distance(), AE_loss becomes a tf.constant.



Upon calling AE_minimizer, I receive the following error log:
Traceback (most recent call last):
  File ""GAN.py"", line 168, in <module>
    main()
  File ""GAN.py"", line 162, in main
    AE_minimizer = AE_optimizer.minimize(AE_loss, var_list=AE_parameters)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 343, in minimize
    grad_loss=grad_loss)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 414, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 353, in _MaybeCompile
    return grad_fn()  # Exit early
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 581, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/array_grad.py"", line 245, in _StridedSliceGrad
    shrink_axis_mask=op.get_attr(""shrink_axis_mask"")), None, None, None
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 5572, in strided_slice_grad
    shrink_axis_mask=shrink_axis_mask, name=name)
  File ""/home/adraganov/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 546, in _apply_op_helper
    inferred_from[input_arg.type_attr]))
TypeError: Input 'begin' of 'StridedSliceGrad' Op has type int64 that does not match type int32 of argument 'shape'.



I have seen traffic regarding problems with type mismatches with input 'begin', such as in Issue 11380. I have, however, seen nothing online for this specific problem, where the fields 'begin' and 'shape' have different types."
14946,Getting the given error while installing gpu version of tensorflow,"Exception:
Traceback (most recent call last):
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\commands\install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\req\req_set.py"", line 784, in install
    **kwargs
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\req\req_install.py"", line 851, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\req\req_install.py"", line 1064, in move_wheel_files
    isolated=self.isolated,
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\wheel.py"", line 345, in move_wheel_files
    clobber(source, lib_dir, True)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\site-packages\pip\wheel.py"", line 323, in clobber
    shutil.copyfile(srcfile, destfile)
  File ""C:\Users\Shivam\Anaconda2\envs\tensorflow\lib\shutil.py"", line 121, in copyfile
    with open(dst, 'wb') as fdst:
PermissionError: [Errno 13] Permission denied: 'C:\\Users\\Shivam\\Anaconda2\\envs\\tensorflow\\Lib\\site-packages\\numpy\\core\\multiarray.cp35-win_amd64.pyd'"
14944,[BUG]embedding_lookup can't convert out of index into zeros vector when embedding matrix is placed on CPU ,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.5.2
- **Bazel version (if compiling from source)**: 
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:  8.0 / 6
- **GPU model and memory**: nvidia geforce gtx 1080 ti
- **Exact command to reproduce**:

### Describe the problem

embedding_lookup can't convert out of index into zeros vector when embedding matrix is placed on CPU.

when the matrix is placed on GPU, embedding_lookup method automatically convert out_of_index components into zeros vector, but it doesn't work when the matrix is placed on CPU


### Source code / logs

import tensorflow as tf

inputs = tf.placeholder(tf.int32, [None, None])
with tf.device('/cpu'):  ### when tf.device('/gpu') it's okay
    embedding_matrix = tf.get_variable('embedding_matrix', [5, 2],
                                            dtype=tf.float32,
                                            initializer=tf.contrib.layers.xavier_initializer())
    embedded = tf.nn.embedding_lookup(embedding_matrix, inputs)



inputs_test = [[1],[2],[10]


]

sess = tf.Session()
sess.run(tf.global_variables_initializer())
res = sess.run(embedded,feed_dict = {inputs:inputs_test})
print(res)
"
14943,Update docker images and documentation to not use nvidia-docker by default.,"`nvidia-docker` is not used anymore by the [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) project.  Rather `nvidia-docker2` should be used:

```
$ docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi
```"
14942,tensorflow 1.4 is 8 times slower than tensorflow 1.3 when read data,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **TensorFlow installed from (source or binary)**: python wheel
- **TensorFlow version (use command below)**: 1.4 and 1.3
- **Python version**: 3.6.1
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: None
- **GPU model and memory**: None
- **Exact command to reproduce**:

when I run tensorflow1.4 script using estimator, the script is 8 times slower than tensorflow 1.3

### Source code / logs
`main` script
```python
#!/usr/bin/env python
__author__ = 'zj'

import argparse
import os
import sys
import numpy as np
import time
try:
    import better_exceptions
except ImportError:
    pass
import tensorflow as tf
from src.model_ori import crnn_fn
from src.data_handler import data_loader
from src.config import Params, Alphabet
from src.input_utils import input_fn


def main(unused_argv):
    models_path = FLAGS.input_model_dir
    if not os.path.exists(models_path):
        assert FileNotFoundError

    models_list = [os.path.join(models_path, x[:-5]) for x in os.listdir(models_path) if x.endswith('.meta')]

    if not os.path.exists(FLAGS.output_model_dir):
        os.makedirs(FLAGS.output_model_dir)

    parameters = Params(eval_batch_size=128,
                        input_shape=(32, 304),
                        digits_only=False,
                        alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,
                        alphabet_decoding='same',
                        image_channels=1,
                        csv_delimiter=' ',
                        csv_files_eval=FLAGS.csv_files_eval,
                        output_model_dir=FLAGS.output_model_dir,
                        gpu=FLAGS.gpu
                        )

    model_params = {
        'Params': parameters,
    }

    os.environ['CUDA_VISIBLE_DEVICES'] = parameters.gpu
    config_sess = tf.ConfigProto()
    config_sess.gpu_options.per_process_gpu_memory_fraction = 0.6

    # Config estimator
    est_config = tf.estimator.RunConfig()
    est_config = est_config.replace(session_config=config_sess,
                                    save_summary_steps=100,
                                    model_dir=parameters.output_model_dir)

    estimator = tf.estimator.Estimator(model_fn=crnn_fn,
                                       params=model_params,
                                       config=est_config,
                                       model_dir=parameters.output_model_dir,
                                       )
    try:
        with open(FLAGS.output_file, encoding='utf-8', mode='w') as save_file:
            for model in models_list:
                start = time.time()
                
                eval_results = estimator.evaluate(input_fn=data_loader(csv_filename=parameters.csv_files_eval,
                                                                       params=parameters,
                                                                       batch_size=parameters.eval_batch_size,
                                                                       num_epochs=1),
                                                  steps=3,
                                                  checkpoint_path=model)
                print('time:',time.time() - start)
                print('model: %s Evaluation results: %s' % (model, str(eval_results)))
                save_file.write(model + ' ' + str(eval_results) + '\n')

    except KeyboardInterrupt:
        print('Interrupted')


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-fe', '--csv_files_eval', required=False, type=str, help='CSV filename for evaluation',
                        nargs='*', default=['E:/val1.csv'])
    parser.add_argument('-o', '--output_model_dir', required=False, type=str,
                        help='Directory for output', default='models_vgg_100K_no_eval')
    parser.add_argument('-m', '--input_model_dir', required=False, type=str,
                        help='Directory for output', default='model_test')
    parser.add_argument('-g', '--gpu', type=str, help=""GPU 0,1 or '' "", default='0')
    parser.add_argument('-of', '--output_file', required=False, type=str, default='123.txt', help=""the log output file"")

    tf.logging.set_verbosity(tf.logging.DEBUG)
    FLAGS, unparsed = parser.parse_known_args()
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

```

`data_loader` script
```python
#!/usr/bin/env python
import tensorflow as tf
import numpy as np
from .config import Params, CONST
from typing import Tuple


def data_loader(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,
                num_epochs: int = None, image_summaries: bool = False):
    def input_fn():
        # Choose case one csv file or list of csv files
        if not isinstance(csv_filename, list):
            filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,
                                                            name='filename_queue')
        elif isinstance(csv_filename, list):
            filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')

        # Skip lines that have already been processed
        reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)
        key, value = reader.read(filename_queue, name='file_reading_op')

        default_line = [['None'], ['None']]
        path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,
                                    name='csv_reading_op')

        image, img_width = image_reading(path, resized_size=params.input_shape, params=params,
                                         data_augmentation=data_augmentation, padding=True)

        to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}
        prepared_batch = tf.train.shuffle_batch(to_batch,
                                                batch_size=batch_size,
                                                min_after_dequeue=500,
                                                num_threads=15, capacity=4000,
                                                allow_smaller_final_batch=False,
                                                name='prepared_batch_queue')

        if image_summaries:
            tf.summary.image('input/image', prepared_batch.get('images'), max_outputs=1)
        tf.summary.text('input/labels', prepared_batch.get('labels')[:10])
        tf.summary.text('input/widths', tf.as_string(prepared_batch.get('images_widths')))

        return prepared_batch, prepared_batch.get('labels')

    return input_fn


def image_reading(path: str, params: Params, resized_size: Tuple[int, int] = None, data_augmentation: bool = False,
                  padding: bool = False) -> Tuple[tf.Tensor, tf.Tensor]:
    # Read image
    image_content = tf.read_file(path, name='image_reader')
    image = tf.cond(tf.equal(tf.string_split([path], '.').values[1], tf.constant('jpg', dtype=tf.string)),
                    true_fn=lambda: tf.image.decode_jpeg(image_content, channels=params.image_channels,
                                                         try_recover_truncated=True),  # TODO channels = 3 ?
                    false_fn=lambda: tf.image.decode_png(image_content, channels=params.image_channels),
                    name='image_decoding')

    # Data augmentation
    if data_augmentation:
        image = augment_data(image)

    # Padding
    if padding:
        with tf.name_scope('padding'):
            image, img_width = padding_inputs_width(image, resized_size, increment=CONST.DIMENSION_REDUCTION_W_POOLING)
    # Resize
    else:
        image = tf.image.resize_images(image, size=resized_size)
        img_width = tf.shape(image)[1]

    with tf.control_dependencies([tf.assert_equal(image.shape[:2], resized_size)]):
        return image, img_width


def random_rotation(img: tf.Tensor, max_rotation: float = 0.1, crop: bool = True) -> tf.Tensor:  # from SeguinBe
    with tf.name_scope('RandomRotation'):
        rotation = tf.random_uniform([], -max_rotation, max_rotation)
        rotated_image = tf.contrib.image.rotate(img, rotation, interpolation='BILINEAR')
        if crop:
            rotation = tf.abs(rotation)
            original_shape = tf.shape(rotated_image)[:2]
            h, w = original_shape[0], original_shape[1]
            # see https://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders for formulae
            old_l, old_s = tf.cond(h > w, lambda: [h, w], lambda: [w, h])
            old_l, old_s = tf.cast(old_l, tf.float32), tf.cast(old_s, tf.float32)
            new_l = (old_l * tf.cos(rotation) - old_s * tf.sin(rotation)) / tf.cos(2 * rotation)
            new_s = (old_s - tf.sin(rotation) * new_l) / tf.cos(rotation)
            new_h, new_w = tf.cond(h > w, lambda: [new_l, new_s], lambda: [new_s, new_l])
            new_h, new_w = tf.cast(new_h, tf.int32), tf.cast(new_w, tf.int32)
            bb_begin = tf.cast(tf.ceil((h - new_h) / 2), tf.int32), tf.cast(tf.ceil((w - new_w) / 2), tf.int32)
            rotated_image_crop = rotated_image[bb_begin[0]:h - bb_begin[0], bb_begin[1]:w - bb_begin[1], :]

            # If crop removes the entire image, keep the original image
            rotated_image = tf.cond(tf.equal(tf.size(rotated_image_crop), 0),
                                    true_fn=lambda: img,
                                    false_fn=lambda: rotated_image_crop)

        return rotated_image


def random_padding(image: tf.Tensor, max_pad_w: int = 5, max_pad_h: int = 10) -> tf.Tensor:
    w_pad = list(np.random.randint(0, max_pad_w, size=[2]))
    h_pad = list(np.random.randint(0, max_pad_h, size=[2]))
    paddings = [h_pad, w_pad, [0, 0]]

    return tf.pad(image, paddings, mode='REFLECT', name='random_padding')


def augment_data(image: tf.Tensor) -> tf.Tensor:
    with tf.name_scope('DataAugmentation'):
        # Random padding
        image = random_padding(image)

        image = tf.image.random_brightness(image, max_delta=0.1)
        image = tf.image.random_contrast(image, 0.5, 1.5)
        image = random_rotation(image, 0.05, crop=True)

        if image.shape[-1] >= 3:
            image = tf.image.random_hue(image, 0.2)
            image = tf.image.random_saturation(image, 0.5, 1.5)

        return image


def padding_inputs_width(image: tf.Tensor, target_shape: Tuple[int, int], increment: int) -> Tuple[
    tf.Tensor, tf.Tensor]:
    target_ratio = target_shape[1] / target_shape[0]
    # Compute ratio to keep the same ratio in new image and get the size of padding
    # necessary to have the final desired shape
    shape = tf.shape(image)
    # 计算宽高比
    ratio = tf.divide(shape[1], shape[0], name='ratio')

    new_h = target_shape[0]
    new_w = tf.cast(tf.round((ratio * new_h) / increment) * increment, tf.int32)
    f1 = lambda: (new_w, ratio)
    f2 = lambda: (new_h, tf.constant(1.0, dtype=tf.float64))
    new_w, ratio = tf.case({tf.greater(new_w, 0): f1,
                            tf.less_equal(new_w, 0): f2},
                           default=f1, exclusive=True)
    target_w = target_shape[1]

    # Definitions for cases
    def pad_fn():
        with tf.name_scope('mirror_padding'):
            pad = tf.subtract(target_w, new_w)

            img_resized = tf.image.resize_images(image, [new_h, new_w])

            # Padding to have the desired width
            paddings = [[0, 0], [0, pad], [0, 0]]
            pad_image = tf.pad(img_resized, paddings, mode='SYMMETRIC', name=None)

            # Set manually the shape
            pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])

            return pad_image, (new_h, new_w)

    def replicate_fn():
        with tf.name_scope('replication_padding'):
            img_resized = tf.image.resize_images(image, [new_h, new_w])

            # If one symmetry is not enough to have a full width
            # Count number of replications needed
            n_replication = tf.cast(tf.ceil(target_shape[1] / new_w), tf.int32)
            img_replicated = tf.tile(img_resized, tf.stack([1, n_replication, 1]))
            pad_image = tf.image.crop_to_bounding_box(image=img_replicated, offset_height=0, offset_width=0,
                                                      target_height=target_shape[0], target_width=target_shape[1])

            # Set manually the shape
            pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])

            return pad_image, (new_h, new_w)

    def simple_resize():
        with tf.name_scope('simple_resize'):
            img_resized = tf.image.resize_images(image, target_shape)

            img_resized.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])

            return img_resized, target_shape

    # 3 cases
    pad_image, (new_h, new_w) = tf.case(
        {  # case 1 : new_w >= target_w
            tf.logical_and(tf.greater_equal(ratio, target_ratio),
                           tf.greater_equal(new_w, target_w)): simple_resize,
            # case 2 : new_w >= target_w/2 & new_w < target_w & ratio < target_ratio
            tf.logical_and(tf.less(ratio, target_ratio),
                           tf.logical_and(tf.greater_equal(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)),
                                          tf.less(new_w, target_w))): pad_fn,
            # case 3 : new_w < target_w/2 & new_w < target_w & ratio < target_ratio
            tf.logical_and(tf.less(ratio, target_ratio),
                           tf.logical_and(tf.less(new_w, target_w),
                                          tf.less(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)))): replicate_fn
        },
        default=simple_resize, exclusive=True)

    return pad_image, new_w  # new_w = image width used for computing sequence lengths


def preprocess_image_for_prediction(fixed_height: int = 32, min_width: int = 8):
    """"""
    Input function to use when exporting the model for making predictions (see estimator.export_savedmodel)
    :param fixed_height: height of the input image after resizing
    :param min_width: minimum width of image after resizing
    :return:
    """"""

    def serving_input_fn():
        # define placeholder for input image
        image = tf.placeholder(dtype=tf.float32, shape=[None, None, 1])

        shape = tf.shape(image)
        # Assert shape is h x w x c with c = 1

        ratio = tf.divide(shape[1], shape[0])
        increment = CONST.DIMENSION_REDUCTION_W_POOLING
        new_width = tf.cast(tf.round((ratio * fixed_height) / increment) * increment, tf.int32)

        resized_image = tf.cond(new_width < tf.constant(min_width, dtype=tf.int32),
                                true_fn=lambda: tf.image.resize_images(image, size=(fixed_height, min_width)),
                                false_fn=lambda: tf.image.resize_images(image, size=(fixed_height, new_width))
                                )

        # Features to serve
        features = {'images': resized_image[None],  # cast to 1 x h x w x c
                    'images_widths': new_width[None]  # cast to tensor
                    }

        # Inputs received
        receiver_inputs = {'images': image}

        return tf.estimator.export.ServingInputReceiver(features, receiver_inputs)

    return serving_input_fn
```

log
tensorflow1.4
```sh
INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.6
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002BAAA7A6780>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Starting evaluation at 2017-11-28-12:21:42
INFO:tensorflow:Restoring parameters from model_test\model.ckpt-54692
2017-11-28 20:22:04.720980: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.236689657]
INFO:tensorflow:Evaluation [1/3]
2017-11-28 20:28:32.360331: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.238805175]
INFO:tensorflow:Evaluation [2/3]
2017-11-28 20:35:41.020994: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.237995088]
INFO:tensorflow:Evaluation [3/3]
INFO:tensorflow:Finished evaluation at 2017-11-28-12:43:21
INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.0108218, eval/accuracy = 0.929688, global_step = 54692, loss = 0.23783
time:1306.1133954524994
model: model_test\model.ckpt-54692 Evaluation results: {'eval/CER': 0.01082176, 'eval/accuracy': 0.9296875, 'loss': 0.23782997, 'global_step': 54692}
```

tensorflow 1.3
```sh
INFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': gpu_options {
  per_process_gpu_memory_fraction: 0.6
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}
INFO:tensorflow:Starting evaluation at 2017-11-28-12:49:50
INFO:tensorflow:Restoring parameters from model_test\model.ckpt-54692
2017-11-28 20:50:12.841210: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.17519826]
INFO:tensorflow:Evaluation [1/3]
2017-11-28 20:51:03.366275: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.2987892]
INFO:tensorflow:Evaluation [2/3]
2017-11-28 20:51:49.843030: I C:\tf_jenkins\home\workspace\rel-win\M\windows\PY\36\tensorflow\core\kernels\logging_ops.cc:79] * Loss : [0.20660429]
INFO:tensorflow:Evaluation [3/3]
INFO:tensorflow:Finished evaluation at 2017-11-28-12:52:19
INFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.01188, eval/accuracy = 0.924479, global_step = 54692, loss = 0.226864
time:157.26274514198303
model: model_test\model.ckpt-54692 Evaluation results: {'eval/CER': 0.011879961, 'eval/accuracy': 0.92447919, 'loss': 0.22686392, 'global_step': 54692}
```"
14940,The keys in end_points of slim are not unified for different layers.,"Look at the code:

```python
  with tf.name_scope('xx'):
    end_points_collection = 'dd'
    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],
                      outputs_collections=end_points_collection):
      y = slim.conv2d(np.zeros([1,20,20,3],dtype=np.float32), 10, [2, 2])
      x = slim.max_pool2d(np.zeros([1,20,20,3],dtype=np.float32), [2, 2])
      end_points = slim.utils.convert_collection_to_dict(end_points_collection)
  print(end_points)
```

It output
```
OrderedDict([('Conv', <tf.Tensor 'xx/Conv/Relu:0' shape=(1, 20, 20, 10) dtype=fl
oat32>), ('xx/MaxPool2D', <tf.Tensor 'xx/MaxPool2D/MaxPool:0' shape=(1, 10, 10,
3) dtype=float32>)])
```

For `max_pool2d` layer, the key has prefix `xx`, but for `conv2d` layer, it don't have prefix `xx`. Because in `conv2d` it uses `variable_scope` but in `max_pool2d` it uses `name_scope`. So the behavior looks inconsistent, and may cause the code make mistake. Do we need to unify the behavior ?


For example, if we use multi-gpu to train the network, and we have many clones of network, which name_scope's prefix  are `clone_1`,  `clone_2` and so on. If we want to use the key of `end_points` to get the output of layer on different gpu. We should deal with `max_pool2d` and `conv2d`  differently."
14937,_dynamic_rnn_loop flat_output_size prevents arbitrary-shaped output tensors,"I want a custom RNN cell to output multiple tensors, each with a different shape. I can handle the logic internally, but I'm running into the issue that `_dynamic_rnn_loop` automatically constructs initial outputs using `flat_output_size = nest.flatten(cell.output_size)`. This is problematic because the flattening prevents me from specifying arbitrary-shapes for my output tensors.

For concreteness, I'd like to output three tensors with shapes (batch size, a), (batch size, b), (batch size, c, d, e). However, both

    @property
    def output_size(self):
        return (a, b, (c, d, e))

and 

    @property
    def output_size(self):
        return (a, b, c, d, e)

fail to create a third tensor with shape (batch size, 210, 160, 3). In the first case, `zero_output` is a tuple of (batch size, a), (batch_size, b), ((batch size, c), (batch size, d), and (batch size, e)). In the second case, the `zero_output` is a tuple of (batch size, a), (batch_size, b), (batch size, c), (batch size, d), and (batch size, e).

I feel that RNN cell outputs should be permitted to be arbitrary shapes. I don't know if this is a desired feature or a bug.

Linux Ubuntu 16.04
TensorFlow versions: ('v1.3.0-rc1-5211-gab0fcac', '1.5.0-dev20171127')"
14936,tensorflow lite: Some operations cannot be supported when convert to tflite format,"## System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
   No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
   Ubuntu 14.04
- TensorFlow installed from (source or binary):
   source
- TensorFlow version (use command below):
  1.3.0
- Python version:
  2.7
- Bazel version (if compiling from source):
  0.7.0
- GCC/Compiler version (if compiling from source):
  gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
- CUDA/cuDNN version:
  cuda8.0/cudnn6.0

# Issue:
When I convert pb file trained from tensorflow to tflite format, some operations cannot be supported, such as:
**Sign
Transpose
Unpack
Pack
Fill
RandomUniform
Select
ReverseSequence
ZerosLike
ArgMax**
and some operations cannot support INT64， such as Cast 、Gather
Hope this issure could be solved as soon?
"
14935,How to scale the weights at runtime in tensorflow?,"I have asked this questione in the stackoverflow.
https://stackoverflow.com/questions/47527384/how-to-scale-the-weights-at-runtime-in-tensorflow

Thanks for your help! "
14934,Multi-arch docker images,"Are there non-x86 (ppc64le, arm etc) docker images available for tensorflow? 

This looks like an intel image : https://hub.docker.com/r/tensorflow/tensorflow/

"
14933,"Support ""causal"" padding in tf.keras.layers.Conv1D by adding support to tf.layers.convolutional.Conv1D","TensorFlow version:1.4.0


In the API docs, tf.keras.layers.Conv1D supports ""causal"". However, if I use ""causal"" as the argument of 'padding', there will be an error like this: The 'padding' argument must be one of"" valid "","" same "". Received : causal.

I check the source code, the Conv1D uses the methods in tensorflow.python.layers.convolutional, but the default implementations of tensorflow do not support  ""causal"" as the padding.

(p.s., fchollet/keras uses the conv1d method in tensorflow_backend.py)

"
14932,tf.squared_difference does not work with complex dtypes,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, the provided minimal example
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary (tensorflow-gpu)
- **TensorFlow version (use command below)**: 1.4.0
- **Python version**: 3.6
- **CUDA/cuDNN version**: 8/6
- **GPU model and memory**: GeForce GTX 980 4GB

### Describe the problem

`tf.squared_difference` does not work with complex dtypes `tf.complex64` and `tf.complex128` although the documentation says so: https://www.tensorflow.org/api_docs/python/tf/squared_difference.

### Source code / logs

Minimal (not) working example:

```python
import tensorflow as tf

for dtype in [tf.complex128, tf.complex64]:
    try:
        print(f'*************** {dtype} ***************')
        x = tf.constant(1, dtype=dtype)
        y = tf.constant(2, dtype=dtype)
        result = tf.squared_difference(x, y)

        with tf.Session() as sess:
            sess.run(result)
    except Exception as e:
        print(e)
```

The error output:

```
*************** <dtype: 'complex128'> ***************
2017-11-28 10:33:08.695995: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2017-11-28 10:33:08.836822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785
pciBusID: 0000:04:00.0
totalMemory: 3.94GiB freeMemory: 3.86GiB
2017-11-28 10:33:08.836855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)
No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference = SquaredDifference[T=DT_COMPLEX128](Const, Const_1)]]

Caused by op 'SquaredDifference', defined at:
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/net/home/neumann/workspace/python/tensorflow/tf_speech/tf_speech/complex_squared_difference_example.py"", line 9, in <module>
    res = tf.squared_difference(x, y)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4601, in squared_difference
    ""SquaredDifference"", x=x, y=y, name=name)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference = SquaredDifference[T=DT_COMPLEX128](Const, Const_1)]]

*************** <dtype: 'complex64'> ***************
2017-11-28 10:33:08.858858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)
No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference_1 = SquaredDifference[T=DT_COMPLEX64](Const_2, Const_3)]]

Caused by op 'SquaredDifference_1', defined at:
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/net/home/neumann/workspace/python/tensorflow/tf_speech/tf_speech/complex_squared_difference_example.py"", line 9, in <module>
    res = tf.squared_difference(x, y)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 4601, in squared_difference
    ""SquaredDifference"", x=x, y=y, name=name)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[Node: SquaredDifference_1 = SquaredDifference[T=DT_COMPLEX64](Const_2, Const_3)]]
```"
14931,Missing gradient for tf.argmax,LookupError: No gradient defined for operation 'Argmax' (op type: Argmax)
14929,Number of bytes mismatch when reading tflite schema,"I train a model outside and convert it into.lite format and import it to the iOS project，but I  encounter a problem below:why?
Loaded model resolved reporter tensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 16)Tensor 88 is invalidly specified in schema.
Failed to construct interpreter

"
14924,What is supported by broadcasting? Is the dimensions still limited?,"This is related to issue #1519.

This is OK:

```
import tensorflow as tf
sess = tf.InteractiveSession()
xx = tf.constant(1, shape=[32,1,4,4,1], dtype=tf.float32)
yy = tf.constant(1, shape=[1,32,1,4,4], dtype=tf.float32)
zz = xx * yy
sess.run([zz])
```

However:
```
x2 = tf.constant(1, shape=[10,32,1,4,4,1])
y2 = tf.constant(1, shape=[10,1,32,1,4,4])
z2 = x2 * y2
sess.run(z2)
```
Gives an error:
`UnimplementedError (see above for traceback): Broadcast between [10,32,1,4,4,1] and [10,1,32,1,4,4] is not supported yet.
	 [[Node: mul_1 = Mul[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Const_2, Const_3)]]`

Log:
```

---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-2-eef82717f8d8> in <module>()
      2 y2 = tf.constant(1, shape=[10,1,32,1,4,4])
      3 z2 = x2 * y2
----> 4 sess.run(z2)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    887     try:
    888       result = self._run(None, fetches, feed_dict, options_ptr,
--> 889                          run_metadata_ptr)
    890       if run_metadata:
    891         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1118     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1119       results = self._do_run(handle, final_targets, final_fetches,
-> 1120                              feed_dict_tensor, options, run_metadata)
   1121     else:
   1122       results = []

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1315     if handle is None:
   1316       return self._do_call(_run_fn, self._session, feeds, fetches, targets,
-> 1317                            options, run_metadata)
   1318     else:
   1319       return self._do_call(_prun_fn, self._session, handle, feeds, fetches)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1334         except KeyError:
   1335           pass
-> 1336       raise type(e)(node_def, op, message)
   1337 
   1338   def _extend_graph(self):

UnimplementedError: Broadcast between [10,32,1,4,4,1] and [10,1,32,1,4,4] is not supported yet.
	 [[Node: mul_1 = Mul[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Const_2, Const_3)]]

Caused by op u'mul_1', defined at:
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/runpy.py"", line 174, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelapp.py"", line 474, in start
    ioloop.IOLoop.instance().start()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/ioloop.py"", line 177, in start
    super(ZMQIOLoop, self).start()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tornado/ioloop.py"", line 887, in start
    handler_func(fd_obj, events)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 440, in _handle_events
    self._handle_recv()
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py"", line 414, in _run_callback
    callback(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/kernelbase.py"", line 390, in execute_request
    user_expressions, allow_stdin)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/ipkernel.py"", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/ipykernel/zmqshell.py"", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2821, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-eef82717f8d8>"", line 3, in <module>
    z2 = x2 * y2
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 894, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 1117, in _mul_dispatch
    return gen_math_ops._mul(x, y, name=name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2726, in _mul
    ""Mul"", x=x, y=y, name=name)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
    op_def=op_def)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2956, in create_op
    op_def=op_def)
  File ""/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

UnimplementedError (see above for traceback): Broadcast between [10,32,1,4,4,1] and [10,1,32,1,4,4] is not supported yet.
	 [[Node: mul_1 = Mul[T=DT_INT32, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Const_2, Const_3)]]
```"
14923,_LayerRNNCell __call__() method incompatible with tuple of tensors,"I'm trying to build a custom LSTM cell that should accept a tuple of tensors in the call method. However, as part of the `dynamic_rnn` loop, `_LayerRNNCell`'s `__call__()` method requires that `inputs` be a `2-D` tensor with shape `[batch_size, input_size]`, which is incompatible with a tuple of tensors. Is there a way around this, or can the `__call__()1 method be expanded to be more flexible?

The error that I receive:
`ValueError: Layer action_conditioned_lstm_cell_1 expects 1 inputs, but it received 2 input tensors.`

Linux Ubuntu 16.04
TensorFlow versions: ('v1.3.0-rc1-5211-gab0fcac', '1.5.0-dev20171127')"
14921,Possible sparse gradients bug in 1.4,"
### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Slackware 14.2
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0
- **Python version**: 3.6

### Problem
I get the following warning when I run my code:
```
/usr/lib64/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
```
When I was using the exact same code with TF 1.3, I did not get the warning. I was wondering if this is a possible bug in 1.4 or simply the warning got added in the update?

I located the problem to this part of my code:

```
act_t_ph = tf.placeholder(tf.int32, [None])
# ...
with tf.variable_scope(""action_value""):
    x = tf.layers.dense(x, 512, activation=tf.nn.relu)
    x = tf.layers.dense(x, 6, activation=None)
z_net_locs = x
action_mask = tf.one_hot(act_t_ph, 6, on_value=True, off_value=False, dtype=tf.bool)
z_locations = tf.boolean_mask(z_net_locs, action_mask)
# ...
```
Later, gradients are computed with respect to the variables in the dense layers and these gradients are backpropagated through  `z_locations`. 

I also tried changing my code to:

```
self.act_t_ph = tf.placeholder(tf.int32, [None])
# ...
with tf.variable_scope(""action_value""):
    x = tf.layers.dense(x, 512, activation=tf.nn.relu)
    x = tf.layers.dense(x, 6, activation=None)
z_net_locs = x
bsize = tf.shape(self.act_t_ph)[0]
b_ind = tf.range(0, bsize, 1, tf.int32)
ind   = tf.concat([act_t_ph, b_ind], axis=-1)
z_locations = tf.gather_nd(z_net_locs, ind)
# ...
```
and I no longer get the warning in TF 1.4. As far as I can tell, one of the operations in the original code cannot handle sparse gradients. 
"
14918,This build requires an Android SDK. Please add the android_sdk_repository rule to your WORKSPACE,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS
- **TensorFlow installed from (source or binary)**:  Source
- **TensorFlow version (use command below)**:  Master from November 17 (11eefcd21f9f3d92740cb85d9576198507eeb118)
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: 0.7.0
- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609
- **CUDA/cuDNN version**: N/A (not trying to build Tensorflow GPU)
- **GPU model and memory**: 
- **Exact command to reproduce**:  `sudo tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`

### Describe the problem
I am trying to run unit tests following the instructions here: https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-unit-tests

I have installed Docker and am running: 
`sudo tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`

I receive the following error:
```
ERROR: /home/jovarty/git/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/bazel_tools/tools/android/BUILD:230:1: Executing genrule @bazel_tools//tools/android:no_android_sdk_repository_error failed (Exit 1): bash failed: error executing command
  (cd /home/jovarty/git/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; echo     This build requires an Android SDK. Please add the android_sdk_repository     rule to your WORKSPACE. ;     exit 1 ').
```

After this error I see that no tests were run: `Executed 0 out of 1666 tests: 1666 were skipped.`


Is the Android SDK required when running unit tests? Is this something that should be included in the Dockerfile? (I'm not very familiar with Docker)"
14916,"tf.nn.softmax(input, dim=-1, name=None), argument `dim` cannot take negative index other than -1?","I expect that in the function `tf.nn.softmax(input, dim=-1, name=None)`, the argument `dim` can take dim either positive or negative. However, it seems the only negative index can be taken is -1?

```
import tensorflow as tf

tf.__version__
> '1.4.0'

xx = tf.constant(1, shape=[10, 28, 28, 3], dtype=tf.float32)

tf.nn.softmax(xx, dim=-1)
> <tf.Tensor 'Reshape_1:0' shape=(10, 28, 28, 3) dtype=float32>

tf.nn.softmax(xx, dim=3)
> <tf.Tensor 'Reshape_3:0' shape=(10, 28, 28, 3) dtype=float32>

tf.nn.softmax(xx, dim=-2)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-8-c0dec6c1fa17> in <module>()
----> 1 tf.nn.softmax(xx, dim=-2)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in softmax(logits, dim, name)
   1665       dimension of `logits`.
   1666   """"""
-> 1667   return _softmax(logits, gen_nn_ops._softmax, dim, name)
   1668 
   1669 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in _softmax(logits, compute_op, dim, name)
   1624   # Swap logits' dimension of dim and its last dimension.
   1625   input_rank = array_ops.rank(logits)
-> 1626   logits = _swap_axis(logits, dim, math_ops.subtract(input_rank, 1))
   1627   shape_after_swap = array_ops.shape(logits)
   1628 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in _swap_axis(logits, dim_index, last_index, name)
   1596     return array_ops.transpose(logits,
   1597                                array_ops.concat([
-> 1598                                    math_ops.range(dim_index), [last_index],
   1599                                    math_ops.range(dim_index + 1, last_index),
   1600                                    [dim_index]

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc in range(start, limit, delta, dtype, name)
   1232       delta = cast(delta, inferred_dtype)
   1233 
-> 1234     return gen_math_ops._range(start, limit, delta, name=name)
   1235 
   1236 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc in _range(start, limit, delta, name)
   3257   if _ctx.in_graph_mode():
   3258     _, _, _op = _op_def_lib._apply_op_helper(
-> 3259         ""Range"", start=start, limit=limit, delta=delta, name=name)
   3260     _result = _op.outputs[:]
   3261     _inputs_flat = _op.inputs

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)
    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,
    786                          input_types=input_types, attrs=attr_protos,
--> 787                          op_def=op_def)
    788       return output_structure, op_def.is_stateful, op
    789 

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2956         op_def=op_def)
   2957     if compute_shapes:
-> 2958       set_shapes_for_outputs(ret)
   2959     self._add_op(ret)
   2960     self._record_op_seen_by_control_dependencies(ret)

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   2207       shape_func = _call_cpp_shape_fn_and_require_op
   2208 
-> 2209   shapes = shape_func(op)
   2210   if shapes is None:
   2211     raise RuntimeError(

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in call_with_requiring(op)
   2157 
   2158   def call_with_requiring(op):
-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)
   2160 
   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in call_cpp_shape_fn(op, require_shape_fn)
    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,
    626                                   input_tensors_as_shapes_needed,
--> 627                                   require_shape_fn)
    628     if not isinstance(res, dict):
    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).

/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)
    689       missing_shape_fn = True
    690     else:
--> 691       raise ValueError(err.message)
    692 
    693   if missing_shape_fn:

ValueError: Requires start <= limit when delta > 0: 0/-2 for 'range' (op: 'Range') with input shapes: [], [], [] and with computed input tensors: input[0] = <0>, input[1] = <-2>, input[2] = <1>.
```"
14915,Very different CPU usage/allocation behavior when using slightly different CPUs,"I am running the same exact model on two largely similar systems, let's call them system A and B. However, TF's behavior is very different. On system A, CPU utilization is around 60% (on a 12-core system), while on system B CPU utilization is only around 8%. Moreover, on system A the same model runs about 10x slower than system B, even though it's using far fewer CPU resources.

The systems are similar in that they're both running:

Ubuntu 14.04
TensorFlow 1.4.0 (compiled from source)
Python 2.7
gcc 4.8.4

What's different:

System A:
Bazel 0.6.0
2x E5-2643 v3

System B:
Bazel 0.7.0
2x E5-2643 v4

Why would they behave so differently?"
14914,"""and"", ""or"", etc, should be overloaded if possible","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.13.1
- **TensorFlow installed from (source or binary)**: Binary (anaconda)
- **TensorFlow version (use command below)**: 1.1.0
- **Python version**: 2.7
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**:  N/A
- **GPU model and memory**: Intel HD Graphics 630 1536 MB (not used)
- **Exact command to reproduce**: N/A

### Describe the problem
It would make code much cleaner if more of Python's binary boolean operations were overloaded for 
TF. I understand this can't be done for ""=="" because of hashmap key problems but ""and"", ""or"", ""^"", ""not"", really as many operations as possible, would be great.


### Source code / logs

Currently:
```
def cube_isect(x_m,x_M,y_m,y_M):
  return tf.logical_or(tf.logical_and(x_m >= y_m, x_m <= y_M), 
                                  tf.logical_and(y_m >= x_m, y_m <= x_M))
```
Proposed:
```
def cube_isect(x_m,x_M,y_m,y_M):
  return (x_m >= y_m and x_m <= y_M) or (y_m >= x_m and y_m <= x_M)
```
"
14913,[BUG] argparse (Argument Parser) is not working in nightly build,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: pip install tf-nightly-gpu
- **TensorFlow version (use command below)**: v1.3.0-rc1-5211-gab0fcac 1.5.0-dev20171125
- **Python version**: 3.5.3
- **Bazel version (if compiling from source)**:n/a
- **GCC/Compiler version (if compiling from source)**:n/a
- **CUDA/cuDNN version**:9.0/7.0
- **GPU model and memory**:Titan Xp (12Gb)
- **Exact command to reproduce**: python test.py --myarg buzz

### Describe the problem
Nightly build is not handing correctly arguments passed to the script. The arguments are parsed correctly in the official 1.4 version.

```
(nightly) daniyar@sleepy-prism:~/tmp/argsparse$ python test.py --myarg buzz
buzz
FATAL Flags parsing error: Unknown command line flag 'myarg'
Pass --helpshort or --helpfull to see help on flags.
```

### Source code
```
import numpy as np
import argparse
import tensorflow as tf

parser = argparse.ArgumentParser(description='argsparse test for tensorflow nightly build')
parser.add_argument('--myarg', type=str, help='fizz or buzz', default='fizz')
args = parser.parse_args()

def main(argv):
    print(args.myarg)

if __name__ == '__main__':
    main([]) # test before tf.app.run()
    tf.app.run()
```"
14909,Crossentropy loss function with weights by sample and by category and outcome,"In my loss function I would like to weight each sample differently and in each sample, each category should be weighted differently as well depending on the outcome. Meaning if in a cross entropy the one_hot is correctly specified, a different weight needs to be applied than when the output is incorrect. So I would need two weights per category. A tensor with rank 3. One dimension for the samples, a second dimension for the amount of classes, and a third dimension that differentiates between correct and incorrect match.

I have seen that with sparse_softmax_cross_entropy it is possible to pass in a weight, that serves as a coefficient for positive examples. This is a good start, but I would need to pass in a tensor instead, to treat each sample differently. weighted_cross_entropy_with_logits seems to work in a very similar way but doesn't offer that functionality.

Is this a feature that could be added?"
14906,Functionality Available?: Dataset Input perform slicing along time axis,"
### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7
- **TensorFlow installed from (source or binary)**: from pip
- **TensorFlow version (use command below)**: 1.3 
- **Python version**: 3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 8.0, 6.1
- **GPU model and memory**: k2200
- **Exact command to reproduce**:

### Describe the problem

Currently, as many suggested, when we want to train LSTM to predict the values of next time step, we would better slice all the samples along time axis to tuples of (lookback numbers of values, target predicted values) as (x, y), then store all these in a variable in RAM or as data file in disk. Then we build dataset to point to either form. However, this method makes LSTM stateless. Currently, our scheme to stateful LSTM is as follows:
for an input signal [1, 2, 3, 4, 5, 6, ..., 9, 10, 11]
we initialize LSTM and set state to 0.
feed ([1, 2, 3], 4) to train (`tf.nn.dynamic_rnn`), then feed ([2, 3, 4], 5) ....... ([8, 9, 10], 11), until end of this sequence.
In this batch, we have a number (Batch size, like 32) of signals like this and they will be processed in parallel in GPU by TF.
In the next batch of new signal samples, we reset LSTM with initial state being 0. And then repeat this process.

In this way, we think that given [8, 9, 10] to the model to predict next value (as 11), it is helpful for the model to choose whether to utilize the information of its current state (whether it is at beginning of a series of signal, zero initial; or it is at middle of a signal sequence).

Currently, before version 1.4, we built two generators, one (batch generator) is to generate a batch of signals. The other (time slicer) is to generate (x, y) [shape of (batch size, max time step, number of features) ] along time axis by using the data yield by the batch generator.

In version 1.4, we find Dataset, Estimator and Experiment pipeline powerful. Is there a way to implement the same idea using such pipeline?
Thanks!
"
14905,Running label_wav.py from Simple Audio Recognition on Windows 7/64 is generating errors: CRITICAL:tensorflow:Audio file does not exist CRITICAL:tensorflow:Labels file does not exist CRITICAL:tensorflow:Graph file does not exist,"Windows 7/64, GPU Nvidia M2000M, Python 3.5.4, tensorflow 1.5.0-dev20171120.

I was following the Simple Audio Tutorial. After retraining and freezing the model I was trying to run the script label_wav.py. The script produces an error: CRITICAL:tensorflow:Audio file does not exist CRITICAL:tensorflow:Labels file does not exist CRITICAL:tensorflow:Graph file does not exist:

C:\Users\bbb738>python tensorflow/tensorflow/examples/speech_commands/label_wav.py \--graph=/tmp/my_
frozen_graph.pb \--labels=/tmp/speech_commands_train/conv_labels.txt \--wav=/tmp/speech_dataset/left
/a5d485dc_nohash_0.wav
CRITICAL:tensorflow:Audio file does not exist
CRITICAL:tensorflow:Labels file does not exist
CRITICAL:tensorflow:Graph file does not exist
Traceback (most recent call last):
  File ""tensorflow/tensorflow/examples/speech_commands/label_wav.py"", line 135, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\bbb738\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\p
latform\app.py"", line 129, in run
    _sys.exit(main(argv))
  File ""tensorflow/tensorflow/examples/speech_commands/label_wav.py"", line 107, in main
    FLAGS.output_name, FLAGS.how_many_labels)
  File ""tensorflow/tensorflow/examples/speech_commands/label_wav.py"", line 93, in label_wav
    labels_list = load_labels(labels)
  File ""tensorflow/tensorflow/examples/speech_commands/label_wav.py"", line 58, in load_labels
    return [line.rstrip() for line in tf.gfile.GFile(filename)]
  File ""tensorflow/tensorflow/examples/speech_commands/label_wav.py"", line 58, in <listcomp>
    return [line.rstrip() for line in tf.gfile.GFile(filename)]
  File ""C:\Users\bbb738\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\l
ib\io\file_io.py"", line 214, in __next__
    return self.next()
  File ""C:\Users\bbb738\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\l
ib\io\file_io.py"", line 208, in next
    retval = self.readline()
  File ""C:\Users\bbb738\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\l
ib\io\file_io.py"", line 177, in readline
    self._preread_check()
  File ""C:\Users\bbb738\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\l
ib\io\file_io.py"", line 79, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""C:\Users\bbb738\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\f
ramework\errors_impl.py"", line 473, in __exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.NotFoundError: NewRandomAccessFile failed to Create/Open:  :
 The system cannot find the path specified.
; No such process"
14903,Non-deterministic result using  a pre-trained word embedding  in TensorFlow,"I use pre-trained word embedding to initialize embedding in tensorflow, but got a non-deterministic result. However, if I fix the seed and use random initialization, the result is almost the same.What's the problem here? Thanks.
The code is here:

```
with tf.variable_scope(""embedding""):
    if init_embedding is None:
        self.embedding = tf.get_variable(name='embedding', shape=[vocab_size, word_dim],
                                              dtype=np.float32)
    else:
        self.embedding = tf.get_variable(name=""embedding"", shape=init_embedding.shape,
                                         initializer=tf.constant_initializer(init_embedding), `trainable=True)`
```

init_embedding is the pre-trained word embedding
"
14902,tensorflow for python 3.6 will cause Jupyter notebook not executing properly,"Details refer to this issue I originally posted. -->https://github.com/jupyter/notebook/issues/3084
"
14900,How to control the thread number on Tensorflow?,"Hi all,

Do we have any options to control the number of threads in TF-Slim both in training and evaluation processes?

Specifically, I use [this network](https://github.com/pudae/tensorflow-densenet) for my classification problem. I changed the evaluation part in a way that runs train and evaluation in parallel like [this code](https://github.com/mnuke/tf-slim-mnist). I can run it on my own CPU without any problem. But I can't execute them on a supercomputer. It seems that it is related to the very large number of threads which are being created by Tensorflow. If the number of threads exceeds the maximum number of threads pre-set in SLURM (= 28) then the job will fail. Since it's unable to create new threads it will end up with error ""resource temporarily unavailable"".

This error provided when the code tries to restore parameters from checkpoints. If there is no limitation on the number of threads (like on my pc) it works fine:
```
INFO:tensorflow:Restoring parameters from ./model.ckpt-0
INFO:tensorflow:Starting evaluation at
I tensorflow/core/kernels/logging_ops.cc:79] eval/Accuracy[0]
I tensorflow/core/kernels/logging_ops.cc:79] eval/Recall_5[0]
INFO:tensorflow:Evaluation [1/60]
```

However, when there is a limitation on the number of threads (like SLURM job submission on supercomputers) we get:
```
INFO:tensorflow:Restoring parameters from ./model.ckpt-0
terminate called after throwing an instance of 'std::system_error'
  what():  Resource temporarily unavailable
```

I tried to limit the number of CPU threads used by Tensorflow to 1 by creating config like:

     FLAGS.num_preprocessing_threads=1
      config = tf.ConfigProto()
      config.intra_op_parallelism_threads = FLAGS.num_preprocessing_threads
      config.inter_op_parallelism_threads = FLAGS.num_preprocessing_threads
    
        slim.evaluation.evaluation_loop(
            master=FLAGS.master,
            checkpoint_path=each_ckpt,
            logdir=FLAGS.eval_dir,
            num_evals=num_batches,
            eval_op=list(names_to_updates.values()) + print_ops,
            variables_to_restore=variables_to_restore,
            session_config=config)
But unfortunately, that didn't help. In my opinion, the main problem we are having here is the fact that we are not able to control the number of threads here. Although we set it to 1 with various TF options you can actually see that this job is creating many more threads on the node:


slurm_script─┬─python───128*[{python}]
             └─python───8*[{python}]

Training script is creating 128 threads and evaluation script is creating 8 (both numbers vary over time).  

Any idea on the way to control the thread numbers will be highly appreciated because I do need to fix this issue urgently.
Ellie

P.S. I'm using Python 2.7.13 and Tensorflow 1.3.0."
14898,r1.4 build failed constexpr constructor calls non-constexpr function,"BLUF:
Build fails on OSX.
./tensorflow/core/framework/variant.h(343): error: constexpr constructor calls non-constexpr function ""std::__1::unique_ptr<_Tp, _Dp>::unique_ptr() [with _Tp=tensorflow::Variant::ValueInterface, _Dp=std::__1::default_delete<tensorflow::Variant::ValueInterface>]""

1 error detected in the compilation of ""/var/folders/96/nq247q_92n99r8hkfvlxg_6w0000gn/T//tmpxft_00004cf5_00000000-7_beam_search_ops_gpu.cu.cpp1.ii"".
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: output 'tensorflow/contrib/seq2seq/_objs/python/ops/_beam_search_ops_gpu/tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.pic.o' was not created.
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: not all outputs were created or valid.


### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
10.13.1 (17B48)
- **TensorFlow installed from (source or binary)**:
Trying to compile with sources. 
- **TensorFlow version (use command below)**:
r1.4 branch
- **Python version**: 
Python 3.6.3
- **Bazel version (if compiling from source)**:
0.7.0
- **GCC/Compiler version (if compiling from source)**:
Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1
Apple LLVM version 8.0.0 (clang-800.0.42.1)
Target: x86_64-apple-darwin17.2.0
Thread model: posix
- **CUDA/cuDNN version**:
CUDA Driver Version: 8.0.61
cuDNN 6 April 2017
- **GPU model and memory**:
NVIDIA GTX TITAN X, 12 GB, DVI, HDMI, 3 DP (3072 CUDA cores)
- **Exact command to reproduce**:
 bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures

### Describe the problem
Failed to build with
./tensorflow/core/framework/variant.h(343): error: constexpr constructor calls non-constexpr function ""std::__1::unique_ptr<_Tp, _Dp>::unique_ptr() [with _Tp=tensorflow::Variant::ValueInterface, _Dp=std::__1::default_delete<tensorflow::Variant::ValueInterface>]""

1 error detected in the compilation of ""/var/folders/96/nq247q_92n99r8hkfvlxg_6w0000gn/T//tmpxft_00004cf5_00000000-7_beam_search_ops_gpu.cu.cpp1.ii"".
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: output 'tensorflow/contrib/seq2seq/_objs/python/ops/_beam_search_ops_gpu/tensorflow/contrib/seq2seq/kernels/beam_search_ops_gpu.cu.pic.o' was not created.
ERROR: /Users/joa23/projects/tensorflow/tensorflow/contrib/seq2seq/BUILD:51:1: not all outputs were created or valid.
Target //tensorflow/tools/pip_package:build_pip_package failed to build



"
