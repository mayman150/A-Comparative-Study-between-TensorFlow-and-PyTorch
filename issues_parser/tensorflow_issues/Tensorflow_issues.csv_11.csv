Issue Number,Issue Title,Issue Body
51691,Error while converting mrcnn to tf dialect,"Actually I wanted to convert mrcnn model to tf dialect .I downloaded model from TensorFlow Hub. and I tried adding signatures to model using import tensorflow.compat.v2 as tf
loaded_model = tf.saved_model.load(’/maskedrcnn’)
call = loaded_model.call.get_concrete_function(
tf.TensorSpec(shape=(1, 1024, 1024, 3), dtype=tf.uint8))
signatures = {‘predict’: call}
tf.saved_model.save(loaded_model,’/ex’, signatures=signatures)

I got warning as Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 125). These functions will not be directly callable after loading.           
If I use tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate --savedmodel-objectgraph-to-mlir  /data/maskedrcnn -o sample.mlir
 I am getting error as tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate: Symbol `_ZN10tensorflow35_DeviceAttributes_default_instance_E' has different size in shared object, consider re-linking
tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate: Symbol `_ZN10tensorflow43_ConfigProto_Experimental_default_instance_E' has different size in shared object, consider re-linking
tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate: Symbol `_ZTVN10tensorflow4data11DatasetBaseE' has different size in shared object, consider re-linking
tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate: symbol lookup error:tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate: undefined symbol: _ZN10tensorflow28CollectiveParamResolverLocal22GetOrCreateInstanceRecEPKNS0_8GroupRecEPNS_16CollectiveParamsEPb
                                                                                                                                                                                                                           "
51690,NameError:,"
![1](https://user-images.githubusercontent.com/26819449/130900977-670c52ed-7327-4ce8-96f7-e782fe5c4a69.JPG)

![1 2](https://user-images.githubusercontent.com/26819449/130900986-0880d879-619e-425d-8e72-0cc208284706.jpg)
![1 3](https://user-images.githubusercontent.com/26819449/130901034-a2bc3c90-1edb-4cf3-881d-c5bfd8a120a2.JPG)

Can I add a direct link to the GitHub copy path like src/janggu/resources/pseudo_genome.fa.
Or do I have to download the files and then upload them?
Can you tell me how I should upload it then?
Both the ways would be fine for now.
Thank you

"
51688,Nan gradient when calling tf.gradients() more than 1 time in graph mode for TF Dormand-Prince solver,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.6.0
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

(Please see jupyter notebook in the attached ZIP file)

I notice that if `tf.gradients() ` is called more than one time inside a `@tf.function`-decorated function `ode_gradient_graph()` (graph mode) when using a Tensorflow Dormand-Prince ODE solver, the later gradients can evaluate incorrectly to have NaN values. Switching the order of the tf.gradients()` calls allows computation of the second gradient but not the first. 

However, all gradients are computed normally in eager mode using GradientTape with `persistent=True`. 

**Describe the expected behavior**

`tf.gradients()` should return a non-NaN answer for the second gradient computed inside the `@tf.function`-decorated function `ode_gradient_graph()`. Additionally, when parameters `ys` and `xs` to `tf.gradients()` are both single tensorflow tensors,` tf.gradients()` should have the same behavior as `tf.GradientTape.gradient()`.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): N/A

**Standalone code to reproduce the issue**
See attached ZIP file for notebook
[ode_gradients_bug.ipynb.zip](https://github.com/tensorflow/tensorflow/files/7049692/ode_gradients_bug.ipynb.zip)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached. N/A
"
51686,MaybeLockVariableInputMutexesInOrder() from training_op_helpers.h is broken when trying to lock only a subset of the input variables,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): binary from PyPI
- TensorFlow version (use command below): v2.6.0-rc2-32-g919f693420e 2.6.0
- Python version: 3.7.5
- CUDA/cuDNN version: 11.2, 8.1

**Describe the current behavior**

On current master `MaybeLockVariableInputMutexesInOrder()` does not behave correctly if I pass in `std::vector<int>{1}` for the argument `input_ids`.

Rather than try to acquire a lock on the variable associated to input id `1` here, it tries to acquire one for that with input id `0`, which may already be locked of course and shouldn't be touched at all by this function.

https://github.com/tensorflow/tensorflow/blob/3899a80bafd3fbb95edb717dded9ffd64af58b11/tensorflow/core/kernels/training_op_helpers.h#L176

**Describe the expected behavior**

It should lock the right variable.

At the highlighted line in the source the mutex is pulled in for the wrong input_id. I think it would make more sense here to use the mutex pointer that has already been put into the `mutexes` vector a couple of lines above.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): not really
- Briefly describe your candidate solution(if contributing): see under ""describe the expected behavior"", but I haven't tested that"
51685,ABSL_HAVE_ADDRESS_SANITIZER use in Tensorflow headers breaks build for MSVC 16.11 with /fsanitize=address,"**System information**
- TensorFlow installed from (source or binary): source, but does not really matter
- TensorFlow version (use command below): 2.5

**Describe the current behavior**
When compiling in MSVC with address sanitizer TF enables code guarded by ABSL_HAVE_ADDRESS_SANITIZER.
That guarded code (header includes, calls of functions) break the compile.

I would guess this happens since till recently only clang and gcc had sanitizers, and I presume they support all the functionality TF uses. 

**Describe the expected behavior**
Either ABSL_HAVE_ADDRESS_SANITIZER  should be fixed to be 1 only on gcc/clang or TF should use the ABSL_HAVE_ADDRESS_SANITIZER  only when gcc/clang are used. On MSVC this causes a ton of problems.
Alternatively ask MSFT if they plan to add all the headers soon, I doubt it, but if they do you can close as WONTFIX.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): I would discuss this with Abseil team and decide to either fix a macro in Abseil, or define a TF_SOMETHING macro that logically maps to ABSL_HAVE_ADDRESS_SANITIZER==1  &&  compiler_is_not_msvc

**Standalone code to reproduce the issue**
Include any header that will transitively include headers that use ABSL_HAVE_ADDRESS_SANITIZER  and compile on MSVC 16.11 with /fsanitize=address
Example of problematic header:
cpu\include\absl\base\internal\dynamic_annotations.h

"
51684,Can't find GPUs after updating tensorflow to 2.6.0 (with pip) in conda environment ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution : Linux/Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.1, trying to upgrade to 2.6.0
- Python version: 3.9.6
- Installed using virtualenv? pip? conda?: initially conda, then upgraded tensorflow and tensorflow-gpu with pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.2
- GPU model and memory: Tesla V100-SXM / 32510MiB

**Describe the problem**

I'm trying to use a GPU for my tensorflow modeling. I've downloaded anaconda and created a new conda environment which includes the packages t=tensorflow verion 2.4.1, tensorflow-gpu 2.4.1). I can initially see GPU devices available when running a python script find_gpu.py (which just outputs the result of tf.config.experimental.list_physical_devices('GPU')).

I need to update tensorflow to version 2.6.0 for my jupyter notebooks to run. However, after I upgrade either tensorflow or tensorflow-gpu to version 2.6.0 using pip install --upgrade, I can no longer see the GPU devices. I tried installing cudatoolkit with conda, but the issue still persists. A complicating factor is that I don't have sudo permissions on this machine.

This is my first tensorflow issue on Github, please do let me know if you need any additional information. Thank you so much for your help, I really appreciate it! 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

>> sh Anaconda3-2021.05-Linux-x86_64.sh
>> eval ""$(/storage/mkhambet/anaconda3/bin/conda shell.bash hook)""
>> conda create -n tf-gpu tensorflow-gpu
>> conda activate tf-gpu
>> conda install cudatoolkit
>> export CUDA_VISIBLE_DEVICES=0,1
>> python find_gpu.py # This is successful and outputs the first log
>> pip install --upgrade tensorflow
>> pip install --upgrade tensorflow-gpu
>> python find_gpu.py # This fails and outputs the second log

**Any other info / logs**

First log (successful run): 

2021-08-25 13:09:21.685015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-08-25 13:09:22.517016: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-08-25 13:09:22.517772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-08-25 13:09:27.746672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:1b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2021-08-25 13:09:27.748023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:1c:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0
coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s
2021-08-25 13:09:27.748047: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-08-25 13:09:27.750010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-08-25 13:09:27.750081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2021-08-25 13:09:27.751989: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-08-25 13:09:27.752289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-08-25 13:09:27.754163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-08-25 13:09:27.755219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2021-08-25 13:09:27.759360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2021-08-25 13:09:27.764501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]


Second log (failed run):

2021-08-25 14:07:55.083234: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:07:55.083263: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-08-25 14:08:00.970050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:08:00.970123: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:08:00.970172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:08:00.972063: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:08:00.972119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:08:00.972167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /storage/mkhambet/anaconda3/envs/tf-gpu/lib/libcudart.so.10.1
2021-08-25 14:08:00.972181: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[]
"
51682,Inconsistency in Gradients Calculation of max_pooling and reduce_max,"Hi, I found that the gradients calculations of `max_pooling` and `reduce_max`  are inconsistent in tensorflow, which make me really confused. The inconsistency exists when there are **multiple max elements**.

In `max_pooling`, only one of the max elements will get the gradients; while in `reduce_max`, all the max elements will divide the gradients equally. I want to know which algorithm is correct?

Here is an example code of the gradients calculation of `max_pooling` using tensorflow2.6.0:
```python
import numpy as np
import tensorflow as tf

with tf.GradientTape() as tape:
    x = tf.Variable([[[0.6],
                      [0.6],
                      [0.3]]])

    max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=3)
    y = max_pool_1d(x)

g = tape.gradient(y, x)


print(""gradients of max: "", g.numpy())
```
The result is:
```
gradients of max:  [[[1.]
                     [0.]
                     [0.]]]
```
And this is the code of `reduce_max`:
```python
import numpy as np
import tensorflow as tf

with tf.GradientTape() as tape:
    x = tf.Variable([[[0.6],
                      [0.6],
                      [0.3]]])

    y = tf.reduce_max(x)
g = tape.gradient(y, x)


print(""gradients of max: "", g.numpy())
```
The result is:
```
gradients of max:  [[[0.5]
                     [0.5]
                     [0. ]]]
```

Besides, I also found the gradients calculation of `max_pooling` in theano is different from either of the above methods. In theano's implementation, each of the max elements get the whole gradients, that is, the result of theano is:
```
gradients of max:  [[[1.]
                     [1.]
                     [0.]]]
```
Is it correct?

Any replies will be appreciated.
Thanks."
51681,Inconsistency in Gradients Calculation of reduce_max,"Hi, I found that the gradients calculation of `reduce_max` in tensorflow is different from other deep learning libraries such as theano, CNTK. And I want to know which algorithm is correct?

Here is an example code using TensorFlow2.6.0:
```python
import numpy as np
import tensorflow as tf

with tf.GradientTape() as tape:
    x = tf.Variable([[[0.6],
                      [0.6],
                      [0.3]]])

    y = tf.reduce_max(x)
g = tape.gradient(y, x)


print(""gradients of max: "", g.numpy())
```
The result is:
```
gradients of max:  [[[0.5]
                     [0.5]
                     [0. ]]]
```

And this is the code using CNTK2.7:
```python
import numpy as np
import cntk as C

x = C.input_variable(shape=(1, 3, 1), needs_gradient=True)
x_val = np.array([[[0.6],
                   [0.6],
                   [0.3]]])

y = C.reduce_max(x)
g = y.grad({x: x_val})


print(""gradients of max: "", g)
``` 
The result is:
```
gradients of max:  [[[[1.]
                      [1.]
                      [0.]]]]
```
The inconsistency exists when there are multiple max elements.

Any replies will be appreciated.
Thanks."
51680,Activity Regularizer not working with quantization aware training (QAT),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (or github SHA if from source): TF 2.3


**Provide the text output from tflite_convert**

```
  1/120 [..............................] - ETA: 0s - loss: 2.3153 - accuracy: 0.1040WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0110s). Check your callbacks.
120/120 [==============================] - 1s 11ms/step - loss: 2.2161 - accuracy: 0.3372
Quantizing model
[<tf.Tensor 'conv2d/ActivityRegularizer_2/truediv:0' shape=() dtype=float32>, <tf.Tensor: shape=(), dtype=float32, numpy=0.00021372623>, <tf.Tensor 'conv2d_1/ActivityRegularizer_2/truediv:0' shape=() dtype=float32>, <tf.Tensor: shape=(), dtype=float32, numpy=0.004322933>]
Traceback (most recent call last):
  File ""<path to python file>/tempTrain.py"", line 95, in <module>
    print(quantized_model.losses.numpy())
AttributeError: 'list' object has no attribute 'numpy'
```

**Standalone code to reproduce the issue** 
```
import numpy as np
import tensorflow as tf
from tensorflow_model_optimization.python.core.quantization.keras import quantize
from tensorflow.python import keras
l = keras.layers

tf.config.run_functions_eagerly(True)

def layers_list():
  return [
      l.Conv2D(32, 5, padding='same', activation='relu',
               input_shape=image_input_shape(), activity_regularizer=tf.keras.regularizers.l2(l=0.0001), kernel_regularizer=tf.keras.regularizers.l2(l=0.0001)),
      l.MaxPooling2D((2, 2), (2, 2), padding='same'),
      # TODO(pulkitb): Add BatchNorm when transformations are ready.
      # l.BatchNormalization(),
      l.Conv2D(64, 5, padding='same', activation='relu', activity_regularizer=tf.keras.regularizers.l2(l=0.0001), kernel_regularizer=tf.keras.regularizers.l2(l=0.0001)),
      l.MaxPooling2D((2, 2), (2, 2), padding='same'),
      l.Flatten(),
      l.Dense(1024, activation='relu'),
      l.Dropout(0.4),
      l.Dense(10, activation='softmax')
  ]


def sequential_model():
  return keras.Sequential(layers_list())


def functional_model():
  """"""Builds an MNIST functional model.""""""
  inp = keras.Input(image_input_shape())
  x = l.Conv2D(32, 5, padding='same', activation='relu', activity_regularizer=tf.keras.regularizers.l2(l=0.0001), kernel_regularizer=tf.keras.regularizers.l2(l=0.0001))(inp)
  x = l.MaxPooling2D((2, 2), (2, 2), padding='same')(x)
  # TODO(pulkitb): Add BatchNorm when transformations are ready.
  # x = l.BatchNormalization()(x)
  x = l.Conv2D(64, 5, padding='same', activation='relu', activity_regularizer=tf.keras.regularizers.l2(l=0.0001), kernel_regularizer=tf.keras.regularizers.l2(l=0.0001))(x)
  x = l.MaxPooling2D((2, 2), (2, 2), padding='same')(x)
  x = l.Flatten()(x)
  x = l.Dense(1024, activation='relu')(x)
  x = l.Dropout(0.4)(x)
  out = l.Dense(10, activation='softmax')(x)

  return keras.models.Model([inp], [out])


def image_input_shape(img_rows=28, img_cols=28):
  if tf.keras.backend.image_data_format() == 'channels_first':
    return 1, img_rows, img_cols
  else:
    return img_rows, img_cols, 1

def preprocessed_data(img_rows=28,
                      img_cols=28,
                      num_classes=10):
  """"""Get data for mnist training and evaluation.""""""
  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

  if tf.keras.backend.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
  else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)

  x_train = x_train.astype('float32')
  x_test = x_test.astype('float32')
  x_train /= 255
  x_test /= 255

  # convert class vectors to binary class matrices
  y_train = tf.keras.utils.to_categorical(y_train, num_classes)
  y_test = tf.keras.utils.to_categorical(y_test, num_classes)

  return x_train, y_train, x_test, y_test



model = functional_model() #sequential_model()
model.summary()
x_train, y_train, x_test, y_test = preprocessed_data()

model.compile(
    loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=500)
_, model_accuracy = model.evaluate(x_test, y_test, verbose=0)

print(""Quantizing model"")

quantized_model = quantize.quantize_model(model)
print(quantized_model.losses)
quantized_model.compile(
    loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
print(quantized_model.losses.numpy())

quantized_model.fit(x_train, y_train, batch_size=500)
_, quantized_model_accuracy = quantized_model.evaluate(
    x_test, y_test, verbose=0)
```

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
51679,Mask R-CNN on TFLite (Input and Output tensors Help),"Hello everyone,
the past couple of days I spent trying to get tflite running with select tf ops on my raspberry pi. How I did that you can find here:
tensorflow/tensorflow#51657
Now it works, great. I am using Mask R CNN from Leekunhee (https://github.com/leekunhee/Mask_RCNN)
Then I thought, there is so much logic going on behind this great opensource project, and the instance segmentation masks are not going to appear by themselves as they do when running on regular tensorflow.
I hope it is nothing that cannot be fixed. I counted 3 input tensors and 7 output tensors of which I do not have the slightest clue of what they are doing except for maybe the 512x512 input tensor for the image.

Btw, the conversion went fine, no issues there. I am only concerned how to use the outputs to gain useful information from the model.
Currently I am using tensorflow lite 2.5 on a 64 bit raspberry pi 4 (1GB of ram), with python 3.7.3.

Source code:

```
import numpy as np
import tflite_runtime.interpreter as tflite
#Download tflite_runtime here https://github.com/PINTO0309/TensorflowLite-bin
import cv2
import os
import sys
import numpy as np

def loadImage():
    image = '/home/pi/robotproject/13.08.2021_at_15-17-17.png'

    #img = io.imread(image_paths[0])
    img = cv2.imread(image)
    img_arr = np.array(img)
    
    #Obviously convert to float 32
    img_arr = np.float32(img_arr)
    img_arr = cv2.resize(img_arr, (512, 512), interpolation = cv2.INTER_AREA)

    #Create a batch of size 1 from image
    img_arr = np.concatenate([img_arr[np.newaxis, :, :]]*1)
        
    return img_arr

print(""Before loading the interpreter"")
interpreter = tflite.Interpreter(model_path=""/home/pi/robotproject/model.tflite"")
print(""Afterloading interpreter"")

# Get input and output tensors.
input_details = interpreter.get_input_details()

interpreter.resize_tensor_input(input_details[0]['index'], (1, 512, 512, 3))

interpreter.allocate_tensors()

# Test the model on random input data.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

image_np = loadImage()

for i in range(0, len(input_details)):
    print(""Mask R CNN input shape "" + str(input_details[i]['shape']))

for i in range(0, len(output_details)):
    print(""Mask R CNN output shape "" + str(output_details[i]['shape']))

interpreter.set_tensor(input_details[0]['index'], image_np)

print(""Before invoke"")
interpreter.invoke()
print(""After invoke"")

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
output_data = []
for i in range(0, len(output_details)-1):
    output_data.append([interpreter.get_tensor(output_details[i]['index']).copy()])
```

And here is the ouput:

> Before loading the interpreter
> INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
> INFO: Created TensorFlow Lite delegate for select TF ops.
> INFO: TfLiteFlexDelegate delegate: 13 nodes delegated out of 480 nodes with 6 partitions.
> 
> INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 3 nodes with 0 partitions.
> 
> INFO: TfLiteFlexDelegate delegate: 2 nodes delegated out of 18 nodes with 2 partitions.
> 
> Afterloading interpreter
> Beyond input details
> Mask R CNN input shape [ 1 512 512 3]
> Mask R CNN input shape [ 1 14]
> Mask R CNN input shape [1 1 4]
> Mask R CNN output shape [ 1 100 6]
> Mask R CNN output shape [ 1 500 2]
> Mask R CNN output shape [ 1 500 2 4]
> Mask R CNN output shape [ 1 100 28 28 2]
> Mask R CNN output shape [1 1 1]
> Mask R CNN output shape [1 1 2]
> Mask R CNN output shape [1 1 4]
> Before invoke
> 2021-08-25 17:58:07.981717: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 25088000 exceeds 10% of free system memory.
> After invoke

Yep, no errors. A reason to feel good? Not yet, I really need to figure out how to use this model now. Please help me with ideas on how to format inputs and use outputs so that one actually has masks for each instances in the end.

I do realize, this is a tensorflow repository and not one for mask r cnn. There is so little documentation on the internet on running this model with tflite, that I just hope someone who has some experience might stumble over this post and could help."
51677,py_function doesn't work with functions with no return values and inputs as keras.Input,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.6.0-rc2-32-g919f693420e 2.6.0
- Python version: 3.8.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.2
- GPU model and memory: GeForce RTX 2080; Memory: 8G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

```python
>>> import tensorflow as tf
>>> a = tf.keras.Input((1,), dtype=tf.int32, name='a')
>>> tf.py_function(lambda a: None, [a], [])
```

Raises error:

```
Traceback (most recent call last):
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 206, in wrapper
    return target(*args, **kwargs)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py"", line 512, in eager_py_func
    return _eager_py_func(
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py"", line 414, in _eager_py_func
    return _internal_py_func(
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py"", line 343, in _internal_py_func
    result = gen_script_ops.eager_py_func(
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/ops/gen_script_ops.py"", line 53, in eager_py_func
    return eager_py_func_eager_fallback(
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/ops/gen_script_ops.py"", line 96, in eager_py_func_eager_fallback
    _attr_Tin, input = _execute.convert_to_mixed_eager_tensors(input, ctx)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 295, in convert_to_mixed_eager_tensors
    v = [ops.convert_to_tensor(t, ctx=ctx) for t in values]
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 295, in <listcomp>
    v = [ops.convert_to_tensor(t, ctx=ctx) for t in values]
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py"", line 163, in wrapped
    return func(*args, **kwargs)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 346, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 271, in constant
    return _constant_impl(value, dtype, shape, name, verify_shape=False,
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 106, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/keras_tensor.py"", line 244, in __array__
    raise TypeError(
TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 210, in wrapper
    result = dispatch(wrapper, args, kwargs)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py"", line 126, in dispatch
    result = dispatcher.handle(op, args, kwargs)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/layers/core.py"", line 1473, in handle
    return TFOpLambda(op)(*args, **kwargs)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 976, in __call__
    return self._functional_construction_call(inputs, args, kwargs,
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1114, in _functional_construction_call
    outputs = self._keras_tensor_symbolic_call(
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 848, in _keras_tensor_symbolic_call
    return self._infer_output_signature(inputs, args, kwargs, input_masks)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 893, in _infer_output_signature
    outputs = tf.nest.map_structure(
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/util/nest.py"", line 869, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/util/nest.py"", line 869, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/keras_tensor.py"", line 584, in keras_tensor_from_tensor
    out = keras_tensor_cls.from_tensor(tensor)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/keras/engine/keras_tensor.py"", line 172, in from_tensor
    type_spec = tf.type_spec_from_value(tensor)
  File ""/home/kaiyu/tmp/py_env/lib/python3.8/site-packages/tensorflow/python/framework/type_spec.py"", line 609, in type_spec_from_value
    raise TypeError(""Could not build a TypeSpec for %r with type %s"" %
TypeError: Could not build a TypeSpec for <tf.Operation 'tf.py_function_1/EagerPyFunc' type=EagerPyFunc> with type Operation
```

**Describe the expected behavior**

Should simply pass.

If `a` is a constant instead, it works.

```python
>>> import tensorflow as tf
>>> a = tf.constant(1)
>>> tf.py_function(lambda a: None, [a], [])
[]
```

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): N/A

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/19qhwT5fPmVX0SB6FgNJYZvaI3kXCSzOG?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51676,TF-Nightly Broke for Multi GPU training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): Latest Git
- Python version: 3.8.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.4 & 8.2.2.26
- GPU model and memory: 2070 & 3080ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Getting this error half way through training.
```
tensorflow.python.framework.errors_impl.CancelledError:  [_Derived_]RecvAsync is cancelled.
	 [[{{node div_no_nan_1/ReadVariableOp_3/_40}}]] [Op:__inference_test_function_29082]
```


"
51675,A Suspected Bug in binary_crossentropy,"Hi, I found that the the calculation result of `binary_crossentropy` loss function is different from other deep learning libraries, such as theano.

Here is an example code using tensorflow2.6.0:
```python
import numpy as np
import tensorflow as tf

y_true = np.array([0., 1., 0.], dtype=np.float32)
y_pred = np.array([0.9999999, 0.9999999, 0.0000001], dtype=np.float32)

res = tf.keras.backend.binary_crossentropy(y_true, y_pred)

print(""loss = "", res.numpy())
```
The result is:
```
loss =  [15.333239 -0.       -0.      ]
```

And this is the code using theano1.0.4:
```python
import numpy as np
from theano import tensor as T

y_true = np.array([0., 1., 0.], dtype=np.float32)
y_pred = np.array([0.9999999, 0.9999999, 0.0000001], dtype=np.float32)

res = T.nnet.binary_crossentropy(y_pred, y_true)

print(""loss = "", res.eval())
```
The result is:
```
loss =  [1.5942385e+01 1.1920930e-07 1.1920930e-07]
```

I then found the cause of the inconsistency is that, tensorflow use the `epsilon`  to caculate the loss value,  which I think is redundant because the output has been clipped using `epsilon` eariler. Here is the source code location:
https://github.com/tensorflow/tensorflow/blob/fbd7286aba58ba180a2e3c8a280ed5379ee5435d/tensorflow/python/keras/backend.py#L5047-L5052

Besides, I found that the `categorical_crossentropy` doesn't use the `epsilon` to caculate the loss value. This makes me more suspicious of the usage of `epsilon` in `binary_crossentropy`:
https://github.com/tensorflow/tensorflow/blob/fbd7286aba58ba180a2e3c8a280ed5379ee5435d/tensorflow/python/keras/backend.py#L4906-L4908

Thanks."
51674,does lstm only running on CPU? Can it delegated to Apple Neural Engine(ANE) by CoreML delegate ?,"Such as title. 
And I have another confuse. When I split my model into two pieces, the second piece consists of two nodes(Dense and Softmax) can not be delegate to CoreML anymore.

who can tell me something about this? Any reply will be appreciate."
51673,failed to alloc X bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory,"

I am trying to run a tensorflow project and I am encountering memory problems on the university HPC cluster. I have to run a prediction job for hundreds of inputs, with differing length. We have GPU nodes with different amount of vmem, so I am trying to set up the scripts in a way that will not crash in any combination of GPU node - input length.

After searching the net for solutions, I played around with TF_FORCE_UNIFIED_MEMORY, XLA_PYTHON_CLIENT_MEM_FRACTION, XLA_PYTHON_CLIENT_PREALLOCATE and TF_FORCE_GPU_ALLOW_GROWTH, and also with tensorflow's set_memory_growth. As I understood, with unified memory, I should be able to use more memory than a GPU has in itself.

This was my final solution (only relevant parts)

```
os.environ['TF_FORCE_UNIFIED_MEMORY']='1'
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION']='2.0'
#os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false'
os.environ['TF_FORCE_GPU_ALLOW_GROWTH ']='true' # as I understood, this is redundant with the set_memory_growth part
```

```
import tensorflow as tf    
gpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      print(gpu)
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)

```
and I submit it on the cluster with` --mem=30G` (slurm job scheduler) and `--gres=gpu:1.`

And this is the error my code crashes with. As I understand, it does try to use the unified memory but is failing for some reason.

```
Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5582 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:02:00.0, compute capability: 3.5)
2021-08-24 09:22:02.053935: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 12758286336 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:22:03.738635: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 11482457088 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:22:05.418059: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 10334211072 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:22:07.102411: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 9300789248 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:22:08.784349: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 8370710016 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:22:10.468644: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 7533638656 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:22:12.150588: E external/org_tensorflow/tensorflow/stream_executor/cuda/cuda_driver.cc:764] failed to alloc 6780274688 bytes unified memory; result: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2021-08-24 09:23:10.326528: W external/org_tensorflow/tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.


Traceback (most recent call last):
  File ""scripts/script.py"", line 654, in <module>
    prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")
  File ""env/lib/python3.7/site-packages/alphafold/model/model.py"", line 134, in predict
    result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)
  File ""env/lib/python3.7/site-packages/jax/_src/traceback_util.py"", line 183, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File ""env/lib/python3.7/site-packages/jax/_src/api.py"", line 402, in cache_miss
    donated_invars=donated_invars, inline=inline)
  File ""env/lib/python3.7/site-packages/jax/core.py"", line 1561, in bind
    return call_bind(self, fun, *args, **params)
  File ""env/lib/python3.7/site-packages/jax/core.py"", line 1552, in call_bind
    outs = primitive.process(top_trace, fun, tracers, params)
  File ""env/lib/python3.7/site-packages/jax/core.py"", line 1564, in process
    return trace.process_call(self, fun, tracers, params)
  File ""env/lib/python3.7/site-packages/jax/core.py"", line 607, in process_call
    return primitive.impl(f, *tracers, **params)
  File ""env/lib/python3.7/site-packages/jax/interpreters/xla.py"", line 608, in _xla_call_impl
    *unsafe_map(arg_spec, args))
  File ""env/lib/python3.7/site-packages/jax/linear_util.py"", line 262, in memoized_fun
    ans = call(fun, *args)
  File ""env/lib/python3.7/site-packages/jax/interpreters/xla.py"", line 758, in _xla_callable
    compiled = compile_or_get_cached(backend, built, options)
  File ""env/lib/python3.7/site-packages/jax/interpreters/xla.py"", line 76, in compile_or_get_cached
    return backend_compile(backend, computation, compile_options)
  File ""env/lib/python3.7/site-packages/jax/interpreters/xla.py"", line 373, in backend_compile
    return backend.compile(built_c, compile_options=options)
jax._src.traceback_util.UnfilteredStackTrace: RuntimeError: Resource exhausted: Out of memory while trying to allocate 4649385984 bytes.

The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""scripts/script.py"", line 654, in <module>
    prediction_result, (r, t) = cf.to(model_runner.predict(processed_feature_dict, random_seed=seed), ""cpu"")
  File ""env/lib/python3.7/site-packages/alphafold/model/model.py"", line 134, in predict
    result, recycles = self.apply(self.params, jax.random.PRNGKey(random_seed), feat)
  File ""env/lib/python3.7/site-packages/jax/interpreters/xla.py"", line 373, in backend_compile
    return backend.compile(built_c, compile_options=options)
RuntimeError: Resource exhausted: Out of memory while trying to allocate 4649385984 bytes.
```

I would be glad for any ideas how to get it work and use all the available memory.

Thank you!


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): debian 5781
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: Python 3.7.3
- Bazel version (if compiling from source): - 
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 11
- GPU model and memory: several GPUs on the cluster (Tesla M60, vmem:8G ; RTX 2080Ti, vmem:10G; Quadro RTX 6000, vmem: 24G)


I would be glad for any ideas how to get it work and use all the available memory.

Thank you!
"
51671,Error EOF,"
![1](https://user-images.githubusercontent.com/26819449/130785201-768b1e8d-6897-40f2-9501-149ea3eca737.JPG)

![2](https://user-images.githubusercontent.com/26819449/130785213-978c460b-247b-4f41-96b8-447ec1c6e15c.JPG)

Hello,
Actually, I am trying to run a library from the Github repo.
All modules of the application are running Except this one. I haven't found any syntax error.
and code was not altered.
Can you tell me what's wrong?
Thankyou."
51669,micro: port op SLICE from lite,"This issue tracks my work porting operator SLICE from lite to micro. My work will be supervised by @mansnils. Proposed labels: comp:lite comp:micro:arm comp:micro

The port will be submitted in a number of PRs. Here's a rough flight plan per @advaitjain and @petewarden:

PR 1 #51670: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver
PR 2 #51672: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences

The remaining three PRs will instead be opened in tensorflow/tflite-micro, but are included here for clarity:
PR 3: Copy operator from lite to micro without making any changes or including in the build 
PR 4: Delete extra code from the micro copy of the operator
PR 5: Port micro copy of operator as necessary and add a corresponding test"
51668,Stateful LSTM can't be converted to TF Lite with Integer Quantization,"That is what I'm doing:

```
onnx_model = onnx.load(path_to_onnx)
model = prepare(onnx_model, 'CPU')
model.export_graph(path) 

converter = tf.lite.TFLiteConverter.from_saved_model(path)
converter.experimental_enable_resource_variables = True
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS,
  tf.lite.OpsSet.SELECT_TF_OPS
]

converter.optimizations = [tf.lite.Optimize.DEFAULT]

def representative_dataset():
    with open('dataset.p', 'rb') as fp:
        tensors_list = pickle.load(fp)
    for tensor in tensors_list:
        tensor = np.asarray(tensor, dtype = np.float32)
        h_tensor = np.zeros((1,1,512), dtype = np.float32)
        c_tensor = np.zeros((1,1,512), dtype = np.float32)
        yield [h_tensor, c_tensor, tensor]

converter.representative_dataset = representative_dataset
tflite_model = converter.convert()
```

And I get:
```
  File ""...\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py"", line 78, in __init__
    raise ValueError(""Failed to parse the model: %s."" % e)
ValueError: Failed to parse the model: Op FlexVarHandleOp missing inputs.
```

I'm trying to do it with the simplest stateful LSTM layer, but it has the issue.

Thanks,
Anastasiia

_Originally posted by @AnastGerus in https://github.com/tensorflow/tensorflow/issues/35194#issuecomment-903722201_"
51666,Syntax Error: unexpected EOF while parsing,"
![1](https://user-images.githubusercontent.com/26819449/130758213-9adecd0f-f20c-4bae-b581-2fd9ac565b60.JPG)
![2](https://user-images.githubusercontent.com/26819449/130758218-c12b6128-2f02-4cef-9b22-e2bca37ad38f.JPG)
Hello,
Actually, I am trying to run a library from the Github repo.
All modules of the application are running Except this one. I haven't found any syntax error.
and code was not altered.
Can you tell me what's wrong?
Thankyou.

"
51665,[tf2.6] Model saving error for a customized model and loss function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
-- Dockerfile: 
```
FROM python:3.8

WORKDIR /usr/src/app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ ""python"", ""./test.py"" ]
```
-- requirements.txt:
```
numpy
tensorflow
```
and
`docker build -t python-docker .`

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tested
- TensorFlow installed from (source or binary): Docker on Mac mini (2018)
- TensorFlow version (use command below): TF2.6
- Python version: 3.8
- Bazel version (if compiling from source): Not tested, unlikely to be related to this issue
- GCC/Compiler version (if compiling from source): Not tested, unlikely to be related to this issue
- CUDA/cuDNN version: No CUDA on this Mac mini
- GPU model and memory: N/A

**Describe the current behavior**
Typing `docker run -it --rm -v ""$PWD"":/usr/src/app -w /usr/src/app python-docker python test.py` in my environment will end up getting the following error, **if the `self.compiled_loss(targets, logits)` and `model.compile(optimizer=Adam(lr_schedule), loss=mean_huber_loss)` are used.**

```
KeyError: ""Failed to add concrete function b'__inference_train_step_1086' to object based saved model as it captures tensor tf.Tensor(<unprintable>, shape=(), dtype=resource) which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).""
```

**If instead I use `loss = self.criterion(targets, logits)` and `model.compile(optimizer=Adam(lr_schedule))` everything works perfectly.**

**Describe the expected behavior**
Model should be properly saved to the assigned folder regardless of the two different combinations above.


**Standalone code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.optimizers import Adam

BATCH_SIZE = 2 ** 7
NUM_ACTION = 11
STATE_DIM = 1

def _huber_loss(y_true, y_pred, max_grad=1.):
    a = tf.abs(y_true - y_pred)
    less_than_max = 0.5 * tf.square(a)
    greater_than_max = max_grad * (a - 0.5 * max_grad)
    return tf.where(a <= max_grad, x=less_than_max, y=greater_than_max)

def mean_huber_loss(y_true, y_pred):
    return tf.reduce_mean(_huber_loss(y_true, y_pred))

class NonDistributionalModel(keras.Model):
    def __init__(self, inputs, outputs):
        super(NonDistributionalModel, self).__init__(inputs=inputs, outputs=outputs)

        self.loss_tracker = keras.metrics.Mean(name=""loss"")
        self.abs_metric = keras.metrics.MeanTensor(name=""abs"") # Returns a tensor with the same shape of the input tensors

        self.criterion = mean_huber_loss

    @tf.function
    def train_step(self, data):
        states, targets = data

        with tf.GradientTape() as tape:
            logits = self(states, training=True)
            loss = self.compiled_loss(targets, logits)
            # loss = self.criterion(targets, logits)

        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        self.loss_tracker.update_state(loss)
        self.abs_metric.update_state(tf.reduce_mean(tf.math.abs(targets - logits), axis=-1))
        
        return {""loss"": self.loss_tracker.result(), ""abs"": self.abs_metric.result()}     

    @property
    def metrics(self):
        # We list our `Metric` objects here so that `reset_states()` can be
        # called automatically at the start of each epoch
        # or at the start of `evaluate()`.
        # If you don't implement this property, you have to call
        # `reset_states()` yourself at the time of your choosing.
        return [self.loss_tracker, self.abs_metric]   

inputs = keras.Input(shape=(STATE_DIM,))
outputs = keras.layers.Dense(NUM_ACTION)(inputs)
model = NonDistributionalModel(inputs, outputs)

lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(initial_learning_rate=0.1,
                                                                       first_decay_steps=1000)
model.compile(optimizer=Adam(lr_schedule), loss=mean_huber_loss)
# model.compile(optimizer=Adam(lr_schedule))

x = np.random.random((BATCH_SIZE, 1))
y = np.random.random((BATCH_SIZE, NUM_ACTION))
model.fit(x, y, batch_size=BATCH_SIZE, epochs=1)

model.save('model')

```

**Other info / logs** 
```
2021-08-25 08:06:24.613536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-08-25 08:06:24.613609: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Memory usage: 0.2776603698730469 GB
Total processing time: 1.830595807s
2021-08-25 08:06:26.613800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-08-25 08:06:26.613940: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2021-08-25 08:06:26.613981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b9da2514de51): /proc/driver/nvidia/version does not exist
2021-08-25 08:06:26.614187: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-25 08:06:26.669676: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
1/1 [==============================] - 1s 567ms/step - loss: 0.1817 - abs: 0.5033
2021-08-25 08:06:27.407536: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/function_serialization.py"", line 65, in serialize_concrete_function
    bound_inputs.append(node_ids[capture])
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/util/object_identity.py"", line 139, in __getitem__
    return self._storage[self._wrap_key(key)]
KeyError: <_ObjectIdentityWrapper wrapping <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test1.py"", line 238, in <module>
    model.save('model')
  File ""/usr/local/lib/python3.8/site-packages/keras/engine/training.py"", line 2145, in save
    save.save_model(self, filepath, overwrite, include_optimizer, save_format,
  File ""/usr/local/lib/python3.8/site-packages/keras/saving/save.py"", line 149, in save_model
    saved_model_save.save(model, filepath, overwrite, include_optimizer,
  File ""/usr/local/lib/python3.8/site-packages/keras/saving/saved_model/save.py"", line 90, in save
    saved_nodes, node_paths = save_lib.save_and_return_nodes(
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py"", line 1228, in save_and_return_nodes
    _build_meta_graph(obj, signatures, options, meta_graph_def))
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py"", line 1399, in _build_meta_graph
    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py"", line 1362, in _build_meta_graph_impl
    object_graph_proto = _serialize_object_graph(
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py"", line 936, in _serialize_object_graph
    serialized = function_serialization.serialize_concrete_function(
  File ""/usr/local/lib/python3.8/site-packages/tensorflow/python/saved_model/function_serialization.py"", line 67, in serialize_concrete_function
    raise KeyError(
KeyError: ""Failed to add concrete function b'__inference_train_step_1086' to object based saved model as it captures tensor tf.Tensor(<unprintable>, shape=(), dtype=resource) which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).""
```

Any ideas? Thank you for your time."
51664,TFLite Converter fails for models with embedding layer,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.0.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

This Colab notebook creates the TF Model as well as tries to it convert to a TF Lite Model.

https://colab.research.google.com/drive/1mmqmPvq9FMh47q1iYxUnDt2OUKcfbzkV?usp=sharing

Conversion fails with error 
```
ValueError: Input 0 of node StatefulPartitionedCall/model_2/embedding_2/embedding_lookup was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.
```

### 5. (optional) Any other info / logs

```
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, op_dict, producer_op_list)
    500         results = c_api.TF_GraphImportGraphDefWithResults(
--> 501             graph._c_graph, serialized, options)  # pylint: disable=protected-access
    502         results = c_api_util.ScopedTFImportGraphDefResults(results)

InvalidArgumentError: Input 0 of node StatefulPartitionedCall/model_2/embedding_2/embedding_lookup was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
12 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, op_dict, producer_op_list)
    503       except errors.InvalidArgumentError as e:
    504         # Convert to ValueError for backwards compatibility.
--> 505         raise ValueError(str(e))
    506 
    507     # Create _DefinedFunctions for any imported functions.

ValueError: Input 0 of node StatefulPartitionedCall/model_2/embedding_2/embedding_lookup was passed float from Func/StatefulPartitionedCall/input/_2:0 incompatible with expected resource.
```
"
51659,Upgrade TF to CUDA 11.4 and cuDNN 8.2 ,Upgrade TF to CUDA 11.4 and cuDNN 8.2 
51657,Compile TFLite wheel file for Raspberry Pi 4. (Tensorflow operators problem),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Raspbian(Buster) (64 bit version)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Raspberry Pi 4 (1GB RAM, but 2GB Swap memory I think)
- TensorFlow installed from (source or binary): trying to install
- TensorFlow version: 2.5.0, also TFLite 2..5.0
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: virtualenv, pip3
- Bazel version (if compiling from source): Build label: 4.2.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: 11.2/8.1 on ubuntu 20.04
- GPU model and memory: GTX 1070 8GB

So I started with a well working model on my computer and wanted to transfer it to the Raspberry Pi. My plan is to use TFLite on the RPI with verson 2.5.0(tflite), as the regular Tensorfow is also running on 2.5.0. My first instinct was to install the wheel file that was downloadable from the tensorflow website. (Here https://github.com/google-coral/pycoral/releases/)
I used this:  tflite_runtime-2.5.0.post1-cp37-cp37m-linux_aarch64.whl
It installed fine with pip3 in my venv.

Sadly, I get the following error:

>     interpreter.invoke()
>   File ""/home/pi/.local/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 833, in invoke
>     self._interpreter.Invoke()
> RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 275 (FlexCropAndResize) failed to prepare.

I understand, that I am using tensorflow operators that are not included in the tflite library. This is unfortunate but I believe there is one other option: To build the wheel file myself.

I found a readme file deep down in tensorflow, located here: tensorflow/tensorflow/lite/tools/pip_package/README.md

I used this part:

> ### Cross build with Flex for armhf Python 3.7
> 
> ```sh
> CI_DOCKER_EXTRA_PARAMS=""-e CUSTOM_BAZEL_FLAGS=--define=tflite_pip_with_flex=true"" \
>   tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
>   tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf
> ```

All I changed was, ""armhf"" to ""aarch64"" because of 64 bit OS and I added a flag ""--jobs=2"" to keep my computer from freezing up during the process.

The process ended with exit 0, so I thought everything should be fine, but then I get this error message when running the same script as with the first error message:

> Traceback (most recent call last):
>   File ""tfliteTest.py"", line 2, in <module>
>     import tflite_runtime.interpreter as tflite
>   File ""/home/pi/.local/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 42, in <module>
>     from tflite_runtime import metrics_portable as metrics
> ImportError: cannot import name 'metrics_portable' from 'tflite_runtime' (/home/pi/.local/lib/python3.7/site-packages/tflite_runtime/__init__.py)

Please help me, and thank you already for reading this. Also reply if you have another way around this problem, even if I have to take another route.


"
51654,Error: 'tf.UnsortedSegmentJoin' op is neither a custom op nor a flex op,"### 1. System information

- OS Platform and Distribution : google colab
- TensorFlow installation (pip package or built from source): tensorflow 2.6 gpu
- TensorFlow library: 2.6.0

### 2. Code

converter = tf.lite.TFLiteConverter.from_saved_model('translator') # path to the SavedModel directory
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

The output from the converter invocation
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-78-a4bd67ed5756> in <module>()
      4 converter.optimizations = [tf.lite.Optimize.DEFAULT]
----> 5 tflite_model = converter.convert()

6 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    311       for error_data in _metrics_wrapper.retrieve_collected_errors():
    312         converter_error.append_error(error_data)
--> 313       raise converter_error
    314 
    315   return _run_toco_binary(model_flags_str, toco_flags_str, input_data_str,

ConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(""RaggedSegmentJoin/UnsortedSegmentJoin@__inference_detokenize_676"" at ""StatefulPartitionedCall@__inference_restored_function_body_185084"") at ""StatefulPartitionedCall_2@__inference___call___187672"") at ""StatefulPartitionedCall@__inference_signature_wrapper_188041"") at ""StatefulPartitionedCall_4"")): 'tf.UnsortedSegmentJoin' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""StatefulPartitionedCall_4""): called from
<unknown>:0: note: loc(callsite(callsite(callsite(callsite(""RaggedSegmentJoin/UnsortedSegmentJoin@__inference_detokenize_676"" at ""StatefulPartitionedCall@__inference_restored_function_body_185084"") at ""StatefulPartitionedCall_2@__inference___call___187672"") at ""StatefulPartitionedCall@__inference_signature_wrapper_188041"") at ""StatefulPartitionedCall_4"")): Error code: ERROR_NEEDS_CUSTOM_OPS
<unknown>:0: error: loc(callsite(callsite(callsite(callsite(""RaggedSegmentJoin_1/UnsortedSegmentJoin@__inference_detokenize_676"" at ""StatefulPartitionedCall@__inference_restored_function_body_185084"") at ""StatefulPartitionedCall_2@__inference___call___187672"") at ""StatefulPartitionedCall@__inference_signature_wrapper_188041"") at ""StatefulPartitionedCall_4"")): 'tf.UnsortedSegmentJoin' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""StatefulPartitionedCall_4""): called from
<unknown>:0: note: loc(callsite(callsite(callsite(callsite(""RaggedSegmentJoin_1/UnsortedSegmentJoin@__inference_detokenize_676"" at ""StatefulPartitionedCall@__inference_restored_function_body_185084"") at ""StatefulPartitionedCall_2@__inference___call___187672"") at ""StatefulPartitionedCall@__inference_signature_wrapper_188041"") at ""StatefulPartitionedCall_4"")): Error code: ERROR_NEEDS_CUSTOM_OPS
<unknown>:0: error: failed while converting: 'main': 
Some ops in the model are custom ops, See instructions to implement custom ops: https://www.tensorflow.org/lite/guide/ops_custom 
Custom ops: UnsortedSegmentJoin
Details:
	tf.UnsortedSegmentJoin(tensor<?x!tf.string>, tensor<?xi64>, tensor<i32>) -> (tensor<1x!tf.string>) : {Tindices = i64, Tnumsegments = i32, device = """", separator = "" ""}
	tf.UnsortedSegmentJoin(tensor<?x!tf.string>, tensor<?xi64>, tensor<i32>) -> (tensor<?x!tf.string>) : {Tindices = i64, Tnumsegments = i32, device = """", separator = "" ""}

I was trying to convert the model from https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/transformer.ipynb
to a tflite model. The issue could be reproduced by running this in google colab and add 
converter = tf.lite.TFLiteConverter.from_saved_model('translator') # path to the SavedModel directory
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
at the bottom."
51653,"""ZeroDivisionError: integer division or modulo by zero"" while backpropagating","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):
tensorflow              2.5.0
tensorflow-estimator    2.5.0
tensorflow-probability  0.12.2

- Python version: 3.8
- CUDA/cuDNN version: 8101
- GPU model and memory: GeForce GTX 1060

**Describe the current behavior**
Trying to train a component of my model throws an error during backprop calculation inside `grads = tape.gradient(loss, varibs)`. The error isn't very clear about what I'm doing wrong. Other parts of the model are training okay, but one section is throwing the following error.

```
    grads = tape.gradient(loss, varibs)
  File ""C:\Users\Luke\Anaconda3\envs\ScDreamer\lib\site-packages\tensorflow\python\eager\backprop.py"", line 1074, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File ""C:\Users\Luke\Anaconda3\envs\ScDreamer\lib\site-packages\tensorflow\python\eager\imperative_grad.py"", line 71, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File ""C:\Users\Luke\Anaconda3\envs\ScDreamer\lib\site-packages\tensorflow\python\eager\backprop.py"", line 159, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File ""C:\Users\Luke\Anaconda3\envs\ScDreamer\lib\site-packages\tensorflow\python\ops\array_grad.py"", line 229, in _ConcatGradV2
    return _ConcatGradHelper(
  File ""C:\Users\Luke\Anaconda3\envs\ScDreamer\lib\site-packages\tensorflow\python\ops\array_grad.py"", line 119, in _ConcatGradHelper
    concat_dim._numpy().item(0) % input_values[0]._rank())  # pylint: disable=protected-access
ZeroDivisionError: integer division or modulo by zero
```

Investigating the line of code, the issue is the rank of a scalar is being used in the modulo
![image](https://user-images.githubusercontent.com/24449147/130629680-405695f9-642b-4be6-b4c0-acc6e3366267.png)

I'm not sure what I've done wrong that has caused this.

**Describe the expected behavior**
Ideally the error would be caught before getting this deep and suggest a proper fix. At the moment, being told ""ZeroDivisionError: integer division or modulo by zero"" isn't helping me figure out what is wrong.

**Standalone code to reproduce the issue**
I don't really understand what the issue is here so I'm not sure where to start to try and reproduce this. If I can be pointed in the right direction to reproduce, I'll be happy to write some code.
"
51652,My libnnappi_delegate.so is debug or release,"**System information**
- OS Platform: ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MI 9(mobile phone） 
- TensorFlow installed from: Source 
- TensorFlow version: 2.5.0
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.3.0
- CUDA/cuDNN version: 10.0
- GPU model and memory: Tesla K40m 


**Describe the problem**
I use bazel to build libnnappi_delegate.so.
Command :
```
bazel build -c opt  --config=android_arm64  --cxxopt=""-std=c++11""  --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain     //tensorflow/lite/delegates/nnapi:nnapi_delegate 
```
get libnnappi_delegate.so .
How can I know the shared library is ""Debug"" and ""Release""?

"
51651,NotFoundError:,"![3](https://user-images.githubusercontent.com/26819449/130610197-91537368-ef94-4440-b884-515bba21b770.JPG)

I could not find anything related to solving this Error.
I tried each and every possible way possible.
Please help.
Thankyou"
51649,What is the format setting used in the repository?,"I am trying to create a pr but I am having problems with the auto-formatting code.

What is the configuration used ? Right now I use yapf with :
```
yapf    ""--style"",   ""{based_on_style: google, indent_width: 2}""
```"
51648,【JavaAPI】IllegalStateException happended while running a model loading from SavedModel and the graph instance cant close itself ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, i will attach below.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 &&  Window 10 1909
- TensorFlow installed from (source or binary): Java Maven
```xml
        <dependency>
            <groupId>org.tensorflow</groupId>
            <artifactId>tensorflow</artifactId>
            <version>1.15.0</version>
        </dependency>
        <dependency>
            <groupId>org.tensorflow</groupId>
            <artifactId>libtensorflow</artifactId>
            <version>1.15.0</version>
        </dependency>
        <dependency>
            <groupId>org.tensorflow</groupId>
            <artifactId>libtensorflow_jni_gpu</artifactId>
            <version>1.15.0</version>
        </dependency>
```
- TensorFlow version (use command below): 1.15.0

**Describe the current behavior**
I try to load a Saved Model from keras. It all works well till I try to run the session——
Strange thing occurs: the code just can't continue and throw no exception. 
When i use 'try catch finally' style instead of 'try with resource' style, i finally got such error message below:
```
java.lang.IllegalStateException: Error while reading resource variable dense_2/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/dense_2/kernel)
	 [[{{node dense_2/MatMul/ReadVariableOp}}]]
```
And what's more, though I got the error message, the graph instance can't close itself,
when I paused the test code in idea, i found the code stop at the Object.wait() method，
which means that the graph.refcount kept 1 value all the time. 
The code couldn't escape from graph.close() method.
To prove the correctness of saved model, I try to load model in python code like below:
```python
import tensorflow as tf
import numpy as np

export_path = ""./test/"";

input = np.random.random((1, 30));

with tf.Session(graph=tf.Graph()) as sess:
    loaded = tf.saved_model.loader.load(sess, [""serve""], export_path)
    graph = tf.get_default_graph()
    # print(graph.get_operations())
    x = sess.graph.get_tensor_by_name('rp_input:0')
    y = sess.graph.get_tensor_by_name('dense_2/Sigmoid:0')
    scores = sess.run(y,
                      feed_dict={x: input});
    print(""predict: %d"" % (np.argmax(scores, 1)));
```
It works well and print predict result, in that case, I think the problem may not lie in the model. (maybe?) 
I tried hard to find solution or workaround on stackoverflow and issues here,
I saw several similar problems to mine, but they all occurs in python, such as :
https://github.com/tensorflow/tensorflow/issues/28287
and 
https://github.com/tensorflow/tensorflow/issues/22362
the second issues seems most alike, but the model export method is different.
**Standalone code to reproduce the issue**
Here is my model:
[model.zip](https://github.com/tensorflow/tensorflow/files/7036923/model.zip)
Here is the test code, because it fails all over the time, i ommit the code to close the resources.
```java
    public void test_09_justTestAPI() {
        float[] a = new float[]{1.53672f, 2.047399f, 1.42194f, 1.494959f, -0.69123f, -0.39482f, 0.236573f, 0.733827f, -0.531855f, -0.973978f, 1.704854f, 2.085134f, 1.615931f, 1.723842f, 0.102458f, -0.017833f, 0.693043f, 1.263669f, -0.217664f, -1.058611f, 1.300499f, 2.260938f, 1.156857f, 1.291565f, -0.42401f, -0.069758f, 0.252202f, 0.808431f, -0.189161f, -0.490556f};
        long[] shape = new long[]{1, 30};
        try {
            SavedModelBundle savedModelBundle = SavedModelBundle.load(""."", ""serve"");
            Graph graph = savedModelBundle.graph();
            Tensor<Float> data = Tensor.create(shape, FloatBuffer.wrap(a));
            Session session = new Session(graph);
            Session.Runner runner = session.runner()
                    .feed(""rp_input"", data)
                    .fetch(""dense_2/Sigmoid"");
            float[][] res = new float[1][1];
            Tensor<?> out = runner.run().get(0);
            out.copyTo(res); // <artifactId>commons-io</artifactId>
            BigDecimal pro = BigDecimal.valueOf(res[0][0]);
        } catch (Exception e) {
            throw e;
        }
    }
```

**Other info / logs** 
The model is produced by webank federal learining program,
In their code, the model is build by code using keras api:
```py
def _load_model(nn_struct_json):
    return tf.keras.models.model_from_json(nn_struct_json, custom_objects={})
```
The json content is definded like:
```json
      ""nn_define"": {
        ""class_name"": ""Sequential"",
        ""config"": {
          ""name"": ""sequential"",
          ""layers"": [
            {
              ""class_name"": ""RepeatVector"",
              ""config"": {
                ""name"":""rp"",
                ""n"":1
              }
            },
            {
              ""class_name"": ""LSTM"",
              ""config"": {
                ""name"":""lstm"",
                ""units"":32
              }
            },
            {
              ""class_name"": ""Dense"",
              ""config"": {
                ""name"": ""dense"",
                ""trainable"": true,
                ""dtype"": ""float32"",
                ""units"": 64,
                ""activation"": ""relu""
              }
            },
            {
              ""class_name"": ""Dense"",
              ""config"": {
                ""name"": ""dense_2"",
                ""trainable"": true,
                ""dtype"": ""float32"",
                ""units"": 1,
                ""activation"": ""sigmoid""
              }
            }
          ]
        },
        ""keras_version"": ""2.2.4-tf"",
        ""backend"": ""tensorflow""
      }
```
the model is saved by code below:
```py
    def export_model(self):
        with tempfile.TemporaryDirectory() as tmp_path:
            # try:
            #     tf.keras.models.save_model(self._model, filepath=tmp_path, save_format=""tf"")
            # except NotImplementedError:
            #     import warnings
            #     warnings.warn('Saving the model as SavedModel is still in experimental stages. '
            #                   'trying tf.keras.experimental.export_saved_model...')
            tf.keras.experimental.export_saved_model(self._model, saved_model_path=tmp_path)

            model_bytes = _zip_dir_as_bytes(tmp_path)

        return model_bytes
``` 
You can check the code in this link : 
https://github.com/FederatedAI/FATE/blob/master/python/federatedml/nn/backend/tf_keras/nn_model.py
In case, here is the log of my test code:
```c
2021-08-24 15:11:00.368680: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: .
2021-08-24 15:11:00.377471: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }
2021-08-24 15:11:00.382175: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2021-08-24 15:11:00.390552: I tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.
2021-08-24 15:11:00.409095: I tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: .
2021-08-24 15:11:00.416363: I tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 47658 microseconds.
```
I really stuck on this problem.
I would appreciate it if someone can help me out, many thanks!"
51646,Autograph could not transform <function Model.make_test_function.<locals>.test_function at 0x14ec9d430> and will run it as-is.,"**System information**
- Have I written custom code:
- OS Platform and Distribution : MacOS 11.5.2
- TensorFlow installed from TensorFlow_MacOS
- TensorFlow version (use command below): 2.4
- Python version: 3.8.10
- GPU model and memory: Using apple M1 CPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Occasionally will return during training: 
```
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x14c680d30> and will run it as-is.
Please report this to the TensorFlow team.
```
**

**Describe the expected behavior: no error message**

**Standalone code to reproduce the issue**

Training fashion-MNIST:

```from functools import partial

DefaultConv2D = partial(keras.layers.Conv2D,
                        kernel_size=3, activation='relu', padding=""SAME"")

model = keras.models.Sequential([
    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),
    keras.layers.MaxPooling2D(pool_size=2),
    DefaultConv2D(filters=128),
    DefaultConv2D(filters=128),
    keras.layers.MaxPooling2D(pool_size=2),
    DefaultConv2D(filters=256),
    DefaultConv2D(filters=256),
    keras.layers.MaxPooling2D(pool_size=2),
    keras.layers.Flatten(),
    keras.layers.Dense(units=128, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(units=64, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(units=10, activation='softmax'),
])
model.summary()

model.compile(loss=""sparse_categorical_crossentropy"", optimizer=""nadam"", metrics=[""accuracy""])
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))
score = model.evaluate(X_test, y_test)
X_new = X_test[:10] # pretend we have new images
y_pred = model.predict(X_new)
```
Sorry if I have not included the information correctly. I have never submitted a bug before."
51645,model.layers returns empty list,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom Code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.6
- Python version: `3.8.2`
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
`model.layers` returns an empty list `[]`


Minimum reproducible example:

```
# Third Party
import numpy as np
from tensorflow.keras.layers import Concatenate, Dense
from tensorflow.python.keras.models import Model

class MyModel(Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.con = Concatenate()
        self.dense = Dense(10, activation=""relu"")

    def call(self, x):
        x = self.con([x, x])
        return self.dense(x)

if __name__ == ""__main__"":
   model = MyModel()
   print(model.layers)
```

When I attach a pdb and step through the code, I find that there is a change in the boolean logic here:
https://github.com/tensorflow/tensorflow/blob/002e5f47fa2ea99aa910ba83e66240c0cda8ff8a/tensorflow/python/keras/engine/base_layer.py#L2853

I suspect that is part of the breaking changes described [here](https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0)




**Describe the expected behavior**
If the `model.layers` API is being deprecated, what is correct API to use? If not, what is the correct class to use to create layers."
51644,tensorflow-gpu==2.6 don't run on cuda by default ,"dear all dev,

tensorflow-gpu==2.6 by default use oneAPI/oneDNN library 

put on by default cuda lib like previous version 2.5.

problem:

previous version , when import tensorflow as tf then 2nd message gave Successfully opened dynamic library cudart64_110.dll
but now 2.6 version don't saw that message and by default use intel integrated gpu (oneAPI/oneDNN library). 

"
51643,tf.math.xdivy decorated with @tf.function returns 0 when the input is large,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.6.0
- Python version: 3.7.11
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: running on CPU
- GPU model and memory: running on CPU

**Describe the current behavior**
When we feed large inputs to tf.math.xdivy decorated with @tf.function, we get outputs of 0, which is wrong.

**Describe the expected behavior**
The function returns correct results, just like what it does in eager mode.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**

    import pickle
    import tensorflow as tf
    
    input_path = ""tf_math_xdivy_inputs.p""
    data = pickle.load(open(input_path, 'rb'))
    
    fun = tf.math.xdivy
    
    output1 = fun(**data) 
    print(output1)  # the results in eager mode is correct
    
    @tf.function
    def fun_wrapper(data):
        return fun(**data)
    
    output2 = fun_wrapper(data)
    print(output2)  # the results of tf function is wrong

The inputs are {'x': array([-3.0127542e+38+0.j], dtype=complex64), 'y': (2.0609168319398798e+37-2.2877970645017637e+38j)}.

Output1 is tf.Tensor([-0.11767363-1.3062797j], shape=(1,), dtype=complex64).

Output2 is tf.Tensor([-0.+0.j], shape=(1,), dtype=complex64).

This is the input for reproduction. Please decompress it before use.
[tf_math_xdivy_inputs.p.zip](https://github.com/tensorflow/tensorflow/files/7034126/tf_math_xdivy_inputs.p.zip)

We also detect similar issues with other apis. They are: tf.nn.compute_average_loss, tf.realdiv, tf.math.sign. We can provide corresponding inputs if necessary.



"
51642,How to wrap a CuPy function inside a function decorated by tf.function,"I have a CuPy function tweaking TF tensor as follows:
TF tensor => dlpack => CuPy device array => apply some CuPy functions => CuPy device array => dlpack => TF tensor.

The code will work in eager mode, but once I decorate the function with tf.function, it won't work.

```
dlcapsule = tf.experimental.dlpack.to_dlpack(x)
InvalidArgumentError: The argument to `to_dlpack` must be a TF tensor, not Python object
```

I believe the general question should be: how to wrap up a python function calling TF tensor and also returning TF tensor in graph mode? Thanks."
51641,Does a Docker container need to use the same exact libcuda version as the host's driver?,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version: libcuda reported version is: 450.142.0 kernel reported version is: 450.66.0
- GPU model and memory: GeForce RTX 2080 SUPER

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I'm trying to run an application that uses torch and tensorflow inside a docker container but I'm getting this error message:

""kernel version 450.66.0 does not match DSO version 450.142.0 -- cannot find working devices in this configuration""

The cuda-compat-11-0 version inside the container is 450.142.0 but the host driver version is 450.66.0.

As I can't find cuda-compat-11-0 version 450.66.0, I tried other versions around it but I got the same error.

I'm not able to change the Host driver, so my question is:

Do I really have to install the exact same version on the docker container in order to make it work, or am I doing something wrong?

Please help me understand this issue. Thanks in advance!

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51640,Cannot load model checkpoints: Two checkpoint references resolved to different objects,"I am trying to load model checkpoints saved during training. My model has custom layers and the full implementation can be found [here](https://github.com/AdityaKane2001/regnety/issues/15). 

My model looks as follows:
```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
PreStem (PreStem)            (None, 224, 224, 3)       0         
_________________________________________________________________
Stem (Stem)                  (None, 111, 111, 32)      992       
_________________________________________________________________
Stage_0 (Stage)              (None, 56, 56, 24)        4542      
_________________________________________________________________
Stage_1 (Stage)              (None, 28, 28, 56)        12390     
_________________________________________________________________
Stage_2 (Stage)              (None, 14, 14, 152)       277400    
_________________________________________________________________
Stage_3 (Stage)              (None, 7, 7, 368)         2567444   
_________________________________________________________________
Head (Head)                  (None, 1000)              369000    
=================================================================
Total params: 3,231,768
Trainable params: 3,210,920
Non-trainable params: 20,848
_________________________________________________________________
```

When I try to load the model checkpoint after initializing the model architecture, I get the following warning message with an error as described below. 

```
Two checkpoint references resolved to different objects (<regnety.models.blocks.Stage object at 0x7f3c2049e110> and <regnety.models.blocks.Stage object at 0x7f3c2058ed50>).
WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.
...
(many such messages)
...
ValueError                                Traceback (most recent call last)
<ipython-input-4-0c1dca79eafe> in <module>()
      1 from regnety.models import RegNetY
      2 
----> 3 model = RegNetY(""200mf"", load_weights=True)
      4 
 
(long traceback)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py in assert_is_compatible_with(self, other)
   1159     """"""
   1160     if not self.is_compatible_with(other):
-> 1161       raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))
   1162 
   1163   def most_specific_compatible_shape(self, other):

ValueError: Shapes (56,) and (24,) are incompatible
```
Gist [here](https://colab.research.google.com/gist/AdityaKane2001/424e9f482c52b2e205d344d6cc27a8d9/groupedconvissue.ipynb?authuser=5). 

Other info:

TF version: 2.6.0
Environment: Colab with GPU
"
51639,No module named 'keras.api' after compiling tensorflow,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.6.0
- Python version: 3.8.10
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: none
- GPU model and memory: none

**Describe the problem**

I manually compiled tensorflow from sources. After compiling, my script is giving the error message ""No module named 'keras.api'"". 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

i can't post my script but this is the import section...

import os
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from pandas import read_csv, DataFrame, concat
from numpy import array
import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import LSTM, Dense, Input, Bidirectional, Attention, Conv1D, TimeDistributed
import tensorflow as tf
tf.config.optimizer.set_jit(True)
from math import fabs, floor, ceil, isnan
from sklearn import preprocessing
from tensorflow.keras import Input, layers, models
import itertools
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import kpss
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
from deap import base, creator, tools, algorithms
import random
import multiprocessing
import pickle
from fredapi import Fred
import csv

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

There's no traceback. There's no error. The script pumps out that keras.api is missing.

I think I compiled it wrong. Any help greatly appreciated.


EDIT:

I dug in and its the tf.keras.optimizers.Adam function. 

Here's the traceback.

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py"", line 62, in __getattr__
    module = self._load()
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py"", line 45, in _load
    module = importlib.import_module(self.__name__)
  File ""/usr/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 973, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'keras.api'
"
51638,Failed to load the native TensorFlow runtime.,"

**System information**
- OS Platform and Distribution: Mac OS X 10.11.6
- TensorFlow installed:from terminal
- TensorFlow version:~
- Python version:3.8
- Installed using pip
- Bazel version ~
- GCC/Compiler version not compiled from source
- CUDA/cuDNN version:No cuda graphic card
- GPU model and memory:memory 10 gb GPU~



**Describe the problem**
So ive ran mlagents-learn config/trainer_config.yaml --run-id=firstrun3dball --train which give error Failed to load the native TensorFlow runtime. which ive traced that is not the package problem but instead tensor flow problem


**Any other info / logs**
full log:Traceback (most recent call last):
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: dlopen(/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation
  Referenced from: /Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib
  Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security
 in /Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/bin/mlagents-learn"", line 33, in <module>
    sys.exit(load_entry_point('mlagents', 'console_scripts', 'mlagents-learn')())
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/bin/mlagents-learn"", line 25, in importlib_load_entry_point
    return next(matches).load()
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/importlib/metadata.py"", line 77, in load
    module = import_module(match.group('module'))
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 843, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""/Users/phukhao/Downloads/ml-agents-release_1/ml-agents/mlagents/trainers/learn.py"", line 12, in <module>
    from mlagents import tf_utils
  File ""/Users/phukhao/Downloads/ml-agents-release_1/ml-agents/mlagents/tf_utils/__init__.py"", line 1, in <module>
    from mlagents.tf_utils.tf import tf as tf  # noqa
  File ""/Users/phukhao/Downloads/ml-agents-release_1/ml-agents/mlagents/tf_utils/tf.py"", line 3, in <module>
    import tensorflow as tf  # noqa I201
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/eager/context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: dlopen(/Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: _SecKeyCopyExternalRepresentation
  Referenced from: /Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib
  Expected in: /System/Library/Frameworks/Security.framework/Versions/A/Security
 in /Users/phukhao/opt/anaconda3/envs/ML-agent/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.2.dylib


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
51637,Tensor data is incorrectly loaded from FlatBuffers on big-endian targets,"Currently `InitializeTfLiteTensorFromFlatbuffer` and `InitializeTfLiteEvalTensorFromFlatbuffer` refer to a data in a FlatBuffer using a direct pointer. For example in https://github.com/tensorflow/tflite-micro/blob/a9f2e03b943990bc958ce3b92ca76ffc27fcf6d6/tensorflow/lite/micro/micro_allocator.cc#L440:

```
result->data.data = GetFlatbufferTensorBuffer(flatbuffer_tensor, buffers); 
``` 

Because data in FlatBuffers is always little-endian, on big-endian machines it causes problems because any type wider than 8 bits will be read with bytes swapped."
51635,"tf 2.6 break interfance of model.compile, unable to pass tf.keras.optimizers.Adam","tf 2.6
      from tensorflow.python.keras.optimizer_v1 import Optimizer
      from tensorflow.python.keras.optimizer_v2 import optimizer_v2
      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)
      ic(optimizer)
      ic(isinstance(optimizer, (Optimizer, optimizer_v2.OptimizerV2)))

ic| optimizer: <keras.optimizer_v2.adam.Adam object at 0x7fc5e03f32b0>
ic| isinstance(optimizer, (Optimizer, optimizer_v2.OptimizerV2)): False

So we can not pass optimizer to model.compile now as in tensorflow/python/keras/optimizers.py

@keras_export('keras.optimizers.get')
def get(identifier):
  """"""Retrieves a Keras Optimizer instance.

  Args:
      identifier: Optimizer identifier, one of
          - String: name of an optimizer
          - Dictionary: configuration dictionary. - Keras Optimizer instance (it
            will be returned unchanged). - TensorFlow Optimizer instance (it
            will be wrapped as a Keras Optimizer).

  Returns:
      A Keras Optimizer instance.

  Raises:
      ValueError: If `identifier` cannot be interpreted.
  """"""
  if isinstance(identifier, (Optimizer, optimizer_v2.OptimizerV2)):
    return identifier"
51634,Document XLA core functionality,"## URL(s) with the issue:

https://www.tensorflow.org/xla/operation_semantics

## Description of issue (what needs changing):

There are references throughout the XLA docs to various core types that aren't fully documented. These include `XlaBuilder`, `XlaOp`, `XlaComputation` and `Parameter`. There may be others. It would be really helpful if these were documented.

### Clear description

Ideally there would be comprehensive API docs including all public functionality, how and why to use each, but anything in this direction would be most appreciated.

### Correct links

Where they exist

### Parameters defined

No

### Returns defined

No

### Raises listed and defined

No

### Usage example

Some

### Request visuals, if applicable

I don't know. I don't think they're crucial. Don't know if they'd help.

### Submit a pull request?

No"
51633,Error in model.fit,"Made a Tensorflow fuctional API model on top of  TFAutoModelForSequenceClassification with 3 sentence as input. 

Training model directly on tokenized input raises
**ValueError: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {'(<class \'list\'> containing values of types {""<class \'tensorflow.python.framework.ops.EagerTensor\'>""})'}), (<class 'list'> containing values of types {""<class 'int'>""})**

If I convert it into numpy array it raises 
**ValueError: Data cardinality is ambiguous:**

`model(X_train[0])`  prduces the desired result in both cases but on training the model it raises errors.


Code can be found in this [notebook](https://colab.research.google.com/drive/1wsVVHiaqBF8joIEsP_XSMF35fnDQS19D?usp=sharing)"
51631,DeprecationWarning: the imp module is deprecated in favour of importlib,"- Python version: 3.8.10
- Tensorflow version: 2.6.0

Hi team,
I keep on getting the deprecation warning while using tensorflow:
`DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses`

I know that's just a warning, but do you plan to update this library?
Best!"
51629,tf.image.non_max_suppression does not return a dynamic valid detection number after converting to TFLite models,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1/2.5.0/2.6.0

### 2. Code
https://colab.research.google.com/drive/1F4L9cdlhkxKHe70_5_H2SOAlH9Zl-jn-?usp=sharing

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

In eager mode, after NMS, the valid detection number is zero. 
After conversion to the TFLite model, the shape of the `valid_detection` is always `100`.
And I checked that `tf.shape` works flawlessly after converting to TFLite models in https://colab.research.google.com/drive/1dFeffpoi3Cd3ua6x6ny4k_-foPC8_mOe?usp=sharing

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I check that `tf.image.non_max_suppression_padded` could output the correct valid detection number.
"
51626,Why my tf-lite model's fullyconnect and softmax options not be delegated with CoreML?,"*enviorment: iPhone 12*

I have a model converted by TFLiteConverter. It has some opttions like lstm、add、mul、fullyconnect、softmax. When I use the CoreML delegate like the example code in docs. I found that There are just some of the all options delegated by CoreML. I understand some option like lstm would not be delegated. But I have no idea when I found my fullyconnect and softmax are also not be delegated by profiling the app in Xcode Instrument. 
For contrast, I download a DensetNet model. I found CoreML delegate almost all the options include fc and softmax.

Why is that? Any reply will be appreciated."
51625,tf.keras.layers.ConvLSTM2D crashes when kernel_size contains zero,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4 and 2.6.0
- Python version: 3.6

**Standalone code to reproduce the issue**
```
import tensorflow as tf
data_format = ""channels_first""
return_sequences = False
filters = 2
kernel_size = [0, 1]
padding = ""valid""
layer = tf.keras.layers.ConvLSTM2D(data_format=data_format,return_sequences=return_sequences,filters=filters,kernel_size=kernel_size,padding=padding,)
x = tf.keras.Input(shape = (2, 2, 5, 5))
y = layer(x)
model = tf.keras.Model(x, y)
input = tf.random.uniform((2, 2, 2, 5, 5), dtype=tf.float32)
res = model(input)
```

**Describe the current behavior**
It crashes in both TF 2.4 and TF 2.6.
"
51624,tf.keras.layers.LocallyConnected2D crashes with implementation mode = 2 and negative strides,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4 and 2.6
- Python version: 3.6

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np                                                                                                                                                                         
strides = [-4,4,]
layer = tf.keras.layers.LocallyConnected2D(filters=3,kernel_size=3,padding=""valid"",strides=strides,implementation=2)
input = tf.random.uniform((3, 6, 10, 4), dtype=tf.float32)
res = layer(input)
```

**Describe the current behavior**
I run this snippet on TensorFlow 2.4 and it outputs `Floating point exception (core dumped)` and crashes. I tried to execute it on Google Colab with TensorFlow 2.6.0, and the session also crashes.


"
51623,calback pyfunc_18 is not found,"**tensorflow 2.5, python3.7**

I'm using tf.py_function in the model, and after training, the model is saved with tf.saved_model.save().

Is this the compatible problem of these two functions that causes this error?"
51622,ValueError: `tape` is required when a `Tensor` loss is passed.,"**tensorflow 2.5 python 3.7**

As said in https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer?hl=en#minimize,  the first parameter of minmize should satisfy the requirement,

_Tensor or callable. If a callable, loss should take no arguments and return the value to minimize. If a Tensor, the tape argument must be passed._

The first piece of code takes tensor as the input of minimize(), and it requires the gradient tape, but I don't know how.
The second piece of code takes callable function as the input of minimize(), which is easy 

```
import numpy as np
import tensorflow as tf
from tensorflow import keras

x_train = [1, 2, 3]
y_train = [1, 2, 3]

W = tf.Variable(tf.random.normal([1]), name='weight')
b = tf.Variable(tf.random.normal([1]), name='bias')
hypothesis = W * x_train + b


@tf.function
def cost():
    y_model = W * x_train + b
    error = tf.reduce_mean(tf.square(y_train - y_model))
    return error


optimizer = tf.optimizers.SGD(learning_rate=0.01)

cost_value = cost()
train = tf.keras.optimizers.Adam().minimize(cost_value, var_list=[W, b])

tf.print(W)
tf.print(b)
```
How to add the gradient tape, I know the following code certainly works.
```
import numpy as np
import tensorflow as tf
from tensorflow import keras

x_train = [1, 2, 3]
y_train = [1, 2, 3]

W = tf.Variable(tf.random.normal([1]), name='weight')
b = tf.Variable(tf.random.normal([1]), name='bias')
hypothesis = W * x_train + b


@tf.function
def cost():
    y_model = W * x_train + b
    error = tf.reduce_mean(tf.square(y_train - y_model))
    return error


optimizer = tf.optimizers.SGD(learning_rate=0.01)

cost_value = cost()
train = tf.keras.optimizers.Adam().minimize(cost, var_list=[W, b])

tf.print(W)
tf.print(b)
```
Please help me revise the first piece of code and let it run, thanks!
"
51621,"use SPICE tf-lite model in Swift but get error ""Provided data count 64000 must match the required count 4""","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): iOS15.0
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 
```
    'TensorFlowLiteSwift', '~> 0.0.1-nightly'  
    'TensorFlowLiteSelectTfOps', '~> 0.0.1-nightly'
```


**Provide the text output from tflite_convert**

```
Failed to invoke the interpreter with error: Provided data count 64000 must match the required count 4.
```

**Standalone code to reproduce the issue** 
I'm using the SPICE model [here](https://tfhub.dev/google/lite-model/spice/1) which is used to recognize the dominant pitch in sung audio. 

This model's input is like below:
<img width=""482"" alt=""截屏2021-08-22 下午2 05 14"" src=""https://user-images.githubusercontent.com/5517281/130344383-fac8767c-906e-474a-8184-5291435c0037.png"">


It says this input sample rate should be 16000, so I set the sameRate to 16000,I run model in Swift like this:
```swift
func runModel(onBuffer buffer: [Int16]) -> [Dictionary<String, Any>]? { // here buffer has 16000 elements.
   do {
            // Copy the `[Int16]` buffer data as an array of `Float`s to the audio buffer input `Tensor`'s.
            let audioBufferData = Data(copyingBufferOf: buffer.map { Float($0) / maxInt16AsFloat32 })
            try interpreter.copy(audioBufferData, toInputAt: 0)

            // Run inference by invoking the `Interpreter`.
            let startDate = Date()
            try interpreter.invoke(). <------ Here get the error:  Provided data count 64000 must match the required count 4
            ...
    }
}
```

But finally I got this error. Could anyone tell me where am I wrong?  Thanks!
"
51620,error,"Internal Server Error: /form/
Traceback (most recent call last):
  File ""C:\Users\MONZER\Desktop\progect\lib\site-packages\django\core\handlers\exception.py"", line 34, in inner
    response = get_response(request)
  File ""C:\Users\MONZER\Desktop\progect\lib\site-packages\django\core\handlers\base.py"", line 115, in _get_response
    response = self.process_exception_by_middleware(e, request)
  File ""C:\Users\MONZER\Desktop\progect\lib\site-packages\django\core\handlers\base.py"", line 113, in _get_response
    response = wrapped_callback(request, *callback_args, **callback_kwargs)
  File ""C:\Users\MONZER\Desktop\progect\djangoAPI\MyAPI\views.py"", line 80, in cxcontact
    answer=approvereject(ohevalue(df))[0]
  File ""C:\Users\MONZER\Desktop\progect\djangoAPI\MyAPI\views.py"", line 52, in approvereject
    y_pred=mdl.predict(X)
  File ""C:\Users\MONZER\Desktop\progect\lib\site-packages\keras\engine\training.py"", line 1693, in predict
    if self.distribute_strategy._should_use_with_coordinator:  # pylint: disable=protected-access
  File ""C:\Users\MONZER\Desktop\progect\lib\site-packages\keras\engine\training.py"", line 716, in distribute_strategy
    return self._distribution_strategy or tf.distribute.get_strategy()
AttributeError: 'Sequential' object has no attribute '_distribution_strategy'
[21/Aug/2021 22:54:34] ""POST /form/ HTTP/1.1"" 500 88802"
51619,tensorflow-gpu Docker Image - Python TensorRT Import Fails,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: no
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: `tensorflow/tensorflow:2.5.1-gpu` Docker image
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: N/A
-   **TensorFlow installed from (source or binary)**: N/A
-   **TensorFlow version (use command below)**: N/A
-   **Python version**: N/A
-   **Bazel version (if compiling from source)**: N/A
-   **GCC/Compiler version (if compiling from source)**: N/A
-   **CUDA/cuDNN version**: N/A
-   **GPU model and memory**: N/A
-   **Exact command to reproduce**: `docker run -it --rm tensorflow/tensorflow:2.5.1-gpu python`, then `import tensorrt`

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Unable to import tensorrt in `tensorflow/tensorflow:2.5.1-gpu`,  `tensorflow/tensorflow:2.5.0-gpu`, and `tensorflow/tensorflow:2.6.0-gpu`. No modifications to images -- straight pull from Dockerhub. Have attempted first importing tensorflow, then tensorrt, but tensorrt import still fails. Below error:

```
>>> import tensorrt
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorrt'
```

### Source code / logs
N/A
"
51618,tf.image.extract_glimpse crashes with negative input,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4
- Python version: 3.6

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
x = np.arange(9).reshape([1,3,3,1])
res = tf.image.extract_glimpse(x, size=[1023, -63], offsets=[1023, 63], centered=False, normalized=False) # Crash
```

**Describe the current behavior**

It crashes when I execute the above code.

**Describe the expected behavior**
Should throw a `ValueError`.

"
51617,XLA extension: expose output operand aliasing in ops.CustomCall python api,"**System information**
- TensorFlow version (you are using): latest/nightly
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Currently, the `output_operand_aliasing` is only exposed to CustomCallWithAliasing, which calls CustomCallWithLayout:
https://github.com/tensorflow/tensorflow/blob/0fb82942a0b9d734f066575eeb38963de1d7d1c9/tensorflow/compiler/xla/python/ops.cc#L172-L182
Actually the `output_operand_aliasing` is supported without specifying operands layout. But in `CustomCall` python api it is assigned as empty:
https://github.com/tensorflow/tensorflow/blob/0fb82942a0b9d734f066575eeb38963de1d7d1c9/tensorflow/compiler/xla/python/ops.cc#L137-L147
Why not expose the `output_operand_aliasing` in `CustomCall` python api? It will be convenient in use as users do not wanna consider layout custom calls e.g. elementwise ones or custom reduce. 

**Will this change the current api? How?**

As discussed above, `output_operand_aliasing` will be a args in `CustomCall` python api with default value `{}` as before. 

**Who will benefit with this feature?**

As discussed above. 

**Any Other info.**
"
51616,Error while building tflite python wheel for beaglebone black ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 10 (buster)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Beaglebone black
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5
- Python version: 3.7
- Installed using virtualenv? pip? conda?: Created inside a virtualenv then cross compiled using cmake v3.21.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the problem**

**Error while building custom Tflite python wheel for Beaglebone black**

I have a beaglebone black version with cpuinfo of:

processor       : 0
model name      : ARMv7 Processor rev 2 (v7l)
BogoMIPS        : 995.32
Features        : half thumb fastmult vfp edsp thumbee neon vfpv3 tls vfpd32
CPU implementer : 0x41
CPU architecture: 7
CPU variant     : 0x3
CPU part        : 0xc08
CPU revision    : 2
Hardware        : Generic AM33XX (Flattened Device Tree)
Revision        : 0000
Serial          : 2033SBI01413

I want to build a custom python wheel since the prebuilt wheels aren't compatible with my board. I followed the instructions on Tensorflow lite documentation for cross compiling the py wheel for ARM devices using cmake. Link to documentation: https://www.tensorflow.org/lite/guide/build_cmake_pip

The installation is done inside a virtualenv with python version 3.7 with these packages installed inside it:
- cmake         3.21.1.post1
- numpy         1.21.2
- pip           21.2.4
- pkg_resources 0.0.0
- pybind11      2.7.1
- setuptools    57.4.0
- wheel         0.37.0

I used docker to setup a cross build environment. Then, configured custom build flags to be compatible with my target in tensorflow/lite/tools/cmake/download_toolchains.sh as instructed in the documentation. 

I entered this command:
```
tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
  tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh armhf
```

The Docker container environment was created but the tflite py wheel failed to compile raising this error at 96%

```
make[3]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'
make[2]: *** [CMakeFiles/tensorflow-lite.dir/all] Error 2
CMakeFiles/Makefile2:1145: recipe for target 'CMakeFiles/tensorflow-lite.dir/all' failed
make[2]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'
make[1]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2
CMakeFiles/Makefile2:1253: recipe for target 'CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule' failed
make[1]: Leaving directory '/workspace/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.7/cmake_build'
Makefile:215: recipe for target '_pywrap_tensorflow_interpreter_wrapper' failed
make: *** [_pywrap_tensorflow_interpreter_wrapper] Error 2
```


**Any help to solve this issue will be greatly appreciated**
"
51614,Resource exhausted: EfficientNetB7 OOM,"<h1>1. System information</h1>
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
TensorFlow installation (pip package or built from source): 2.6.0
TensorFlow library (version, if pip package or github SHA, if built from source): all other libraries cloned from https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/

<h1>2. Error Code</h1>
Full Error code was saved in
https://github.com/cjfghk5697/Dacon_Code_Review/blob/main/cifar10.ipynb

Error code
```python
epochs = 40 
hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test, verbose=2)
````
Error
```python
ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted:  OOM when allocating tensor with shape[64,192,300,300] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node sequential_2/model_2/efficientnetb7/block2a_expand_conv/Conv2D (defined at /lib/python3.7/threading.py:926) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

	 [[div_no_nan_1/ReadVariableOp/_26]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

  (1) Resource exhausted:  OOM when allocating tensor with shape[64,192,300,300] and type half on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[node sequential_2/model_2/efficientnetb7/block2a_expand_conv/Conv2D (defined at /lib/python3.7/threading.py:926) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.

0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_308507]
```
I use a EfficientNetB7. But EfficientNetB7 fails fit model. Because the Resource exhausted in Colab. So I wish want to know how do fix this error.

<h1>3. After an Error</h1>
First, I added operations such as batch normalization because the efficientnetb7 parameter was too large to cause oom, but it didn't help.

Second, I followed the code on https://stackoverflow.com/questions/49665757/how-to-add-report-tensor-allocations-upon-oom-to-runoptions-in-keras, but the tensorflow version was different, so I couldn't use it.

Third
I've tried similar code on https://stackoverflow.com/questions/64197155/tf2-add-report-tensor-allocations-upon-oom-to-runoptions, but I don't know if this is the solution. The error remained the same.


"
51603,Android audio classification example does not work on a Pixel with Android 10,"## URL(s) with the issue:
https://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/android

## Description of issue (what needs changing):
Perhaps indicate that although hardware may support Android 6+, it may not be capable enough to run the example.

### Clear description
The README.md file indicates that any device supporting Android 6+ with audio support is sufficient. While the example worked fine on my Pixel 4 XL (Android 11), it would not on my Pixel (Android 10). The screen controls are displayed, but it only displays ""Silence"" as the classification, and does not update the bar to the right as it does on my 4 XL. The slider control is also extremely slow to respond, somewhere on the order of 3/4 of a second to a second. I think the hardware just isn't capable enough to run TensorFlow even though it does support Android 10."
51602,"RuntimeError: Given shapes, [1, 23], ] and [1, 10], are not broadcastable.Node number 1392 (SELECT_V2) failed to prepare.","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu1804
- TensorFlow installation (pip package or built from source): tf-nightly 2.7.0
- TensorFlow library (version, if pip package or github SHA, if built from source): pip

### 2. Code

Provide code to help us reproduce your issues using one of the following options:
I used dymamic axes when using onnx to convert pytorch model to onnx model, later on, I convert onnx to tensorflow model .pb and then to quantized tflite model.

Here shows the dynamic axes in my input data
                      dynamic_axes={
                          ""img_feat"": {0: ""batch_size"", 1: ""sequences""},
                          ""img_pos_feat"": {0: ""batch_size"", 1: ""sequences""},
                          ""obj_masks"": {0: ""batch_size"", 1: ""sequences""},
                          ""obj_boxes"": {0: ""batch_size"", 1: ""sequences""},
                          ""input_ids"": {0: ""batch_size"", 1: ""sequences""},
                          ""position_ids"": {0: ""batch_size"", 1: ""sequences""},
                          ""attn_masks"": {0: ""batch_size"", 1: ""sequences""},
                          ""gather_index"": {0: ""batch_size"", 1: ""sequences""}
                      },


### 3. Failure after conversion
I was able to convert the model successfully to int tflite model. 
During the inference phase of int tflite model, I resized the input_details to set tensor to match the dynamic axes in the tflite model. 

    shape_0 = list(named_args['img_feat'].shape)
    interpreter.resize_tensor_input(input_details[0]['index'], tuple(shape_0))

    shape_1 = list(named_args['img_pos_feat'].shape)
    interpreter.resize_tensor_input(input_details[1]['index'], tuple(shape_1))

    shape_2 = list(named_args['obj_masks'].shape)
    interpreter.resize_tensor_input(input_details[2]['index'], tuple(shape_2))

    shape_3 = list(named_args['position_ids'].shape)
    interpreter.resize_tensor_input(input_details[3]['index'], tuple(shape_3))

    shape_4 = list(named_args['attn_masks'].shape)
    interpreter.resize_tensor_input(input_details[4]['index'], tuple(shape_4))

    shape_5 = list(named_args['gather_index'].shape)
    interpreter.resize_tensor_input(input_details[5]['index'], tuple(shape_5))

    shape_6 = list(named_args['input_ids'].shape)
    interpreter.resize_tensor_input(input_details[6]['index'], tuple(shape_6))

All other input data work well except the obj_masks, and I got the error: 
  File ""/home/ubuntu/Projects/Vesta/uniter/scripts/uniter_model_convert_quant_test.py"", line 579, in model_prediction
    out_tflite_quant, pred_box_tflite_quant = run_tflite(interpreter, input_details, output_details, named_args, quant=True, detect_feature=detect_feature)
  File ""/home/ubuntu/Projects/Vesta/uniter/scripts/uniter_model_convert_quant_test.py"", line 436, in run_tflite
    interpreter.invoke()
  File ""/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py"", line 879, in invoke
    self._interpreter.Invoke()
RuntimeError: Given shapes, [1, 23], ] and [1, 10], are not broadcastable.Node number 1392 (SELECT_V2) failed to prepare.

I'm wondering why the shape is [1,23],], instead of [1,23]? Did I do anything wrong?

#### Option A: Reference colab notebooks

Here is the visualization of SELECTV2 node in Netron.
![image](https://user-images.githubusercontent.com/32310519/130302354-ad89e43f-4f8a-4320-a30d-f01c48776f94.png)


Even if I donot use dynamic axes, the int tflite model is much slower than the float tflite model.
"
51601,Build failure when building Tensorflow MLIR ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 7221ec4eace8d163954fd391c8f8e5accd3ae771
- Python version: Python 3.6.9
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

A build failure is seen while compiling for MLIR from the current HEAD, using a standard build command that's otherwise always worked. The error appears to be absl usage related, within  tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc

Assumed this was transient, but it has been present for 4 days now. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

$ bazel build --config=v2 --linkopt=""-fuse-ld=lld"" tensorflow/compiler/mlir/...  -j 32

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: {$MYPATH}/tensorflow/compiler/mlir/tfrt/BUILD:136:16: C++ compilation of rule '//tensorflow/compiler/mlir/tfrt:tf_cpurt_kernels' failed (Exit 1): gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 419 argument(s) skipped)
In file included from ./tensorflow/core/profiler/lib/traceme.h:27:0,
                 from tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:32:
./tensorflow/core/profiler/lib/traceme_encode.h: In instantiation of 'tensorflow::profiler::TraceMeArg::TraceMeArg(absl::lts_20210324::string_view, Value) [with Value = llvm::StringRef]':
tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:285:70:   required from here
./tensorflow/core/profiler/lib/traceme_encode.h:35:61: error: no matching function for call to 'absl::lts_20210324::AlphaNum::AlphaNum(llvm::StringRef&)'
   TraceMeArg(absl::string_view k, Value v) : key(k), value(v) {}
                                                             ^
In file included from external/com_google_absl/absl/container/internal/layout.h:176:0,
                 from external/com_google_absl/absl/strings/internal/cord_rep_ring.h:25,
                 from external/com_google_absl/absl/strings/cord.h:81,
                 from ./tensorflow/core/platform/default/cord.h:22,
                 from ./tensorflow/core/platform/cord.h:25,
                 from ./tensorflow/core/platform/tstring.h:24,
                 from ./tensorflow/core/platform/types.h:23,
                 from ./tensorflow/core/platform/logging.h:20,
                 from ./tensorflow/core/platform/status.h:25,
                 from ./tensorflow/core/lib/core/status.h:19,
                 from ./tensorflow/core/util/device_name_utils.h:21,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_structs.h:28,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_op_interfaces.h:27,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_ops.h:39,
                 from ./tensorflow/compiler/mlir/tensorflow/dialect_registration.h:24,
                 from tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:24:
external/com_google_absl/absl/strings/str_cat.h:283:3: note: candidate: template<class T, typename std::enable_if<(std::is_class<_Tp>::value && (std::is_same<T, std::_Bit_reference>::value || std::is_same<T, bool>::value))>::type* <anonymous> > absl::lts_20210324::AlphaNum::AlphaNum(T)
   AlphaNum(T e) : AlphaNum(static_cast<bool>(e)) {}  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:283:3: note:   template argument deduction/substitution failed:
external/com_google_absl/absl/strings/str_cat.h:282:11: error: no type named 'type' in 'struct std::enable_if<false, void>'
           nullptr>
           ^~~~~~~
external/com_google_absl/absl/strings/str_cat.h:282:11: note: invalid template non-type parameter
external/com_google_absl/absl/strings/str_cat.h:271:3: note: candidate: template<class T, class> absl::lts_20210324::AlphaNum::AlphaNum(T)
   AlphaNum(T e)  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:271:3: note:   template argument deduction/substitution failed:
external/com_google_absl/absl/strings/str_cat.h:269:13: error: no type named 'type' in 'struct std::enable_if<false, void>'
             typename = typename std::enable_if<
             ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:252:3: note: candidate: template<class Allocator> absl::lts_20210324::AlphaNum::AlphaNum(const std::__cxx11::basic_string<char, std::char_traits<char>, Allocator>&)
   AlphaNum(  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:252:3: note:   template argument deduction/substitution failed:
In file included from ./tensorflow/core/profiler/lib/traceme.h:27:0,
                 from tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:32:
./tensorflow/core/profiler/lib/traceme_encode.h:35:61: note:   'llvm::StringRef' is not derived from 'const std::__cxx11::basic_string<char, std::char_traits<char>, Allocator>'
   TraceMeArg(absl::string_view k, Value v) : key(k), value(v) {}
                                                             ^
In file included from external/com_google_absl/absl/container/internal/layout.h:176:0,
                 from external/com_google_absl/absl/strings/internal/cord_rep_ring.h:25,
                 from external/com_google_absl/absl/strings/cord.h:81,
                 from ./tensorflow/core/platform/default/cord.h:22,
                 from ./tensorflow/core/platform/cord.h:25,
                 from ./tensorflow/core/platform/tstring.h:24,
                 from ./tensorflow/core/platform/types.h:23,
                 from ./tensorflow/core/platform/logging.h:20,
                 from ./tensorflow/core/platform/status.h:25,
                 from ./tensorflow/core/lib/core/status.h:19,
                 from ./tensorflow/core/util/device_name_utils.h:21,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_structs.h:28,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_op_interfaces.h:27,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_ops.h:39,
                 from ./tensorflow/compiler/mlir/tensorflow/dialect_registration.h:24,
                 from tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:24:
external/com_google_absl/absl/strings/str_cat.h:249:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(absl::lts_20210324::string_view)
   AlphaNum(absl::string_view pc) : piece_(pc) {}  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:249:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'absl::lts_20210324::string_view'
external/com_google_absl/absl/strings/str_cat.h:248:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(const char*)
   AlphaNum(const char* c_str) : piece_(c_str) {}  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:248:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'const char*'
external/com_google_absl/absl/strings/str_cat.h:244:3: note: candidate: template<long unsigned int size> absl::lts_20210324::AlphaNum::AlphaNum(const absl::lts_20210324::strings_internal::AlphaNumBuffer<size>&)
   AlphaNum(  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:244:3: note:   template argument deduction/substitution failed:
In file included from ./tensorflow/core/profiler/lib/traceme.h:27:0,
                 from tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:32:
./tensorflow/core/profiler/lib/traceme_encode.h:35:61: note:   'llvm::StringRef' is not derived from 'const absl::lts_20210324::strings_internal::AlphaNumBuffer<size>'
   TraceMeArg(absl::string_view k, Value v) : key(k), value(v) {}
                                                             ^
In file included from external/com_google_absl/absl/container/internal/layout.h:176:0,
                 from external/com_google_absl/absl/strings/internal/cord_rep_ring.h:25,
                 from external/com_google_absl/absl/strings/cord.h:81,
                 from ./tensorflow/core/platform/default/cord.h:22,
                 from ./tensorflow/core/platform/cord.h:25,
                 from ./tensorflow/core/platform/tstring.h:24,
                 from ./tensorflow/core/platform/types.h:23,
                 from ./tensorflow/core/platform/logging.h:20,
                 from ./tensorflow/core/platform/status.h:25,
                 from ./tensorflow/core/lib/core/status.h:19,
                 from ./tensorflow/core/util/device_name_utils.h:21,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_structs.h:28,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_op_interfaces.h:27,
                 from ./tensorflow/compiler/mlir/tensorflow/ir/tf_ops.h:39,
                 from ./tensorflow/compiler/mlir/tensorflow/dialect_registration.h:24,
                 from tensorflow/compiler/mlir/tfrt/jit/tf_cpurt_kernels.cc:24:
external/com_google_absl/absl/strings/str_cat.h:241:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(absl::lts_20210324::Dec)
   AlphaNum(Dec dec);  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:241:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'absl::lts_20210324::Dec'
external/com_google_absl/absl/strings/str_cat.h:240:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(absl::lts_20210324::Hex)
   AlphaNum(Hex hex);  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:240:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'absl::lts_20210324::Hex'
external/com_google_absl/absl/strings/str_cat.h:237:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(double)
   AlphaNum(double f)  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:237:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'double'
external/com_google_absl/absl/strings/str_cat.h:235:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(float)
   AlphaNum(float f)  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:235:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'float'
external/com_google_absl/absl/strings/str_cat.h:231:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(long long unsigned int)
   AlphaNum(unsigned long long x)  // NOLINT(*)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:231:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'long long unsigned int'
external/com_google_absl/absl/strings/str_cat.h:228:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(long long int)
   AlphaNum(long long x)  // NOLINT(*)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:228:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'long long int'
external/com_google_absl/absl/strings/str_cat.h:225:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(long unsigned int)
   AlphaNum(unsigned long x)  // NOLINT(*)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:225:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'long unsigned int'
external/com_google_absl/absl/strings/str_cat.h:222:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(long int)
   AlphaNum(long x)  // NOLINT(*)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:222:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'long int'
external/com_google_absl/absl/strings/str_cat.h:219:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(unsigned int)
   AlphaNum(unsigned int x)  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:219:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'unsigned int'
external/com_google_absl/absl/strings/str_cat.h:216:3: note: candidate: absl::lts_20210324::AlphaNum::AlphaNum(int)
   AlphaNum(int x)  // NOLINT(runtime/explicit)
   ^~~~~~~~
external/com_google_absl/absl/strings/str_cat.h:216:3: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'int'
INFO: Elapsed time: 3705.770s, Critical Path: 377.10s
INFO: 11312 processes: 719 internal, 10593 local.
FAILED: Build did NOT complete successfully"
51600,TypeError: 'int' object is not callable,"TF Version: `2.6.0`

using `tf.random.set_seed(7) `  produce  TypeError: 'int' object is not callable

"
51598,tf.experimental.dlpack.from_dlpack() does not support negative strides,"Issue will arise when passing data from CuPy array with negative strides to TF tensor. Please refer to 
https://github.com/cupy/cupy/issues/5665
@kmaehashi
@leofang
"
51597,[TF Lite C API] XNNPACK option not available using C API ,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 11.4
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: Pixel 4
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: tensorflow-lite-2.5.0  AAR 
-   **Python version**: 3.7
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: n/a
-   **GPU model and memory**:
-   **Exact command to reproduce**:


### Describe the problem

I am using TFlite C API available with `tensorflow-lite-2.5.0`  AAR  binary downloaded from Maven. I can not find any way of setting XNNPACK. 

I am looking for **C API** to enable XNNPACK (not ObjC, or Java), something like this:
```
TFL_CAPI_EXPORT extern void TfLiteInterpreterOptionsSetXNNPACK(TfLiteInterpreterOptions* options, bool enable);
```
unless it is already available in some form 

"
51596,Determinism OP bug on TF 2.6.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.6.0
- Python version: 3.7.11
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 11.2
- GPU model and memory: Tesla K80 / 12MB

**Describe the current behavior**
I've setup the TF determinism environment like what I usually done on Google Colab with TF 2.4.1
-  Setup all the global seeds
- run ```os.environ['TF_DETERMINISTIC_OPS'] = '1'``` and ```os.environ['TF_CUDNN_DETERMINISTIC'] = '1'```

It used to work fine on 2.4.1 but when I run the training on 2.6.0 I got this error
```
UnimplementedError:  Deterministic GPU implementation of SparseSoftmaxXentWithLogitsOp not available.
	 [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-25-471bb77471a2>:5) ]] [Op:__inference_train_function_1044]
```


**Describe the expected behavior**
No error occured during training

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): -

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

[Colab link](https://colab.research.google.com/drive/1ogEnSN-E9ZKc09kMWRs8vXgBj9Zlfaoo?usp=sharing)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51594,AttributeError: module 'keras.engine' has no attribute 'Layer',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): using pip install tensorflow in jupyter
- TensorFlow version: 2.6.0
- Python version: 3.8.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
  While run the code I am getting below error. Kindly on this. 
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-7-fc46460c6aba> in <module>
      4 import mrcnn.config
      5 import mrcnn.utils
----> 6 from mrcnn.model import MaskRCNN
      7 from pathlib import Path
      8 

~\Documents\Mahe_Juptyer\Mask_RCNN-master\mrcnn\model.py in <module>
    253 
    254 
--> 255 class ProposalLayer(KE.Layer):
    256     """"""Receives anchor scores and selects a subset to pass as proposals
    257     to the second stage. Filtering is done based on anchor scores and

**AttributeError: module 'keras.engine' has no attribute 'Layer'**
-------------------------------------------------------------------------------------------
**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
51593,about the Dropout,"hi,dear all
when use Dropout as the **help** down, I got confused, **what sum is not changed** ??
```
>>> help(tf.keras.layers.Dropout)
class Dropout(tensorflow.python.keras.engine.base_layer.Layer)
 |  Dropout(*args, **kwargs)
 |  
 |  Applies Dropout to the input.
 |  
 |  The Dropout layer randomly sets input units to 0 with a frequency of `rate`
 |  at each step during training time, which helps prevent overfitting.
 |  Inputs not set to 0 are scaled up by 1/(1 - rate) such that the **sum** over
 |  all inputs is unchanged.
```

```
>>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))
>>> data = np.arange(10).reshape(5, 2).astype(np.float32)
>>> data
array([[0., 1.],
       [2., 3.],
       [4., 5.],
       [6., 7.],
       [8., 9.]], dtype=float32)
>>> outputs = layer(data, training=True)
>>> outputs
<tf.Tensor: shape=(5, 2), dtype=float32, numpy=
array([[ 0.  ,  1.25],
       [ 2.5 ,  3.75],
       [ 5.  ,  6.25],
       [ 7.5 ,  0.  ],
       [10.  , 11.25]], dtype=float32)>
>>> np.sum(outputs)
47.5
>>> np.sum(data)
45.0
>>> np.sum(data)/10
4.5
>>> np.sum(data)/8
5.625
>>> np.sum(data,axis=1)
array([ 1.,  5.,  9., 13., 17.], dtype=float32)
>>> np.sum(outputs,axis=1)
array([ 1.25,  6.25, 11.25,  7.5 , 21.25], dtype=float32)
>>> np.sum(outputs,axis=0)
array([25. , 22.5], dtype=float32)
>>> np.sum(data,axis=0)
array([20., 25.], dtype=float32)
>>> np.sum(outputs)/8
5.9375
>>> np.sum(outputs)/10
4.75

```
could you pls help me ?
thx
"
51592,AlreadyExistsError: Another metric with the same name already exists,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): [I used this example](https://keras.io/examples/vision/conv_lstm/)
- OS Platform and Distribution: Windows 10 10.0.19043 Build 19043
- TensorFlow installed from (source or binary): Using pip
- TensorFlow version (use command below): 2.6.0
- Python version: 3.9.6
- CUDA/cuDNN version: V11.4.48
- GPU model and memory: NVIDIA GeForce RTX 3090, 24 GB

**Describe the current behavior**
I’ve updated Tensorflow and Keras to 2.6.0.

```
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
```

I’ve faced the following issue.

```
---------------------------------------------------------------------------
AlreadyExistsError                        Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_16440/2264619257.py in <module>
      4 import tensorflow as tf
      5 from tensorflow import keras
----> 6 from tensorflow.keras import layers
      7 
      8 import io

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\api\_v2\keras\__init__.py in <module>
      8 import sys as _sys
      9 
---> 10 from keras import __version__
     11 from keras.api._v2.keras import __internal__
     12 from keras.api._v2.keras import activations

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\__init__.py in <module>
     23 
     24 # See b/110718070#comment18 for more details about this import.
---> 25 from keras import models
     26 
     27 from keras.engine.input_layer import Input

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\models.py in <module>
     18 import tensorflow.compat.v2 as tf
     19 from keras import backend
---> 20 from keras import metrics as metrics_module
     21 from keras import optimizer_v1
     22 from keras.engine import functional

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\metrics.py in <module>
     24 
     25 import numpy as np
---> 26 from keras import activations
     27 from keras import backend
     28 from keras.engine import base_layer

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\activations.py in <module>
     18 
     19 from keras import backend
---> 20 from keras.layers import advanced_activations
     21 from keras.utils.generic_utils import deserialize_keras_object
     22 from keras.utils.generic_utils import serialize_keras_object

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\layers\__init__.py in <module>
     21 
     22 # Generic layers.
---> 23 from keras.engine.input_layer import Input
     24 from keras.engine.input_layer import InputLayer
     25 from keras.engine.input_spec import InputSpec

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\engine\input_layer.py in <module>
     19 from keras import backend
     20 from keras.distribute import distributed_training_utils
---> 21 from keras.engine import base_layer
     22 from keras.engine import keras_tensor
     23 from keras.engine import node as node_module

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\engine\base_layer.py in <module>
     40 from keras.engine import node as node_module
     41 from keras.mixed_precision import autocast_variable
---> 42 from keras.mixed_precision import loss_scale_optimizer
     43 from keras.mixed_precision import policy
     44 from keras.saving.saved_model import layer_serialization

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\mixed_precision\loss_scale_optimizer.py in <module>
     16 
     17 from keras import backend
---> 18 from keras import optimizers
     19 from keras.mixed_precision import loss_scale as keras_loss_scale_module
     20 from keras.optimizer_v2 import optimizer_v2

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\optimizers.py in <module>
     24 from keras.optimizer_v1 import Optimizer
     25 from keras.optimizer_v1 import TFOptimizer
---> 26 from keras.optimizer_v2 import adadelta as adadelta_v2
     27 from keras.optimizer_v2 import adagrad as adagrad_v2
     28 from keras.optimizer_v2 import adam as adam_v2

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\optimizer_v2\adadelta.py in <module>
     20 import numpy as np
     21 from keras import backend_config
---> 22 from keras.optimizer_v2 import optimizer_v2
     23 from tensorflow.python.util.tf_export import keras_export
     24 

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\keras\optimizer_v2\optimizer_v2.py in <module>
     34 
     35 
---> 36 keras_optimizers_gauge = tf.__internal__.monitoring.BoolGauge(
     37     ""/tensorflow/api/keras/optimizers"", ""keras optimizer usage"", ""method"")
     38 

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\tensorflow\python\eager\monitoring.py in __init__(self, name, description, *labels)
    358       *labels: The label list of the new metric.
    359     """"""
--> 360     super(BoolGauge, self).__init__('BoolGauge', _bool_gauge_methods,
    361                                     len(labels), name, description, *labels)
    362 

c:\users\admin\appdata\local\programs\python\python39\lib\site-packages\tensorflow\python\eager\monitoring.py in __init__(self, metric_name, metric_methods, label_length, *args)
    133           self._metric_name, len(self._metric_methods)))
    134 
--> 135     self._metric = self._metric_methods[self._label_length].create(*args)
    136 
    137   def __del__(self):

AlreadyExistsError: Another metric with the same name already exists.
```

**Describe the expected behavior**

No error should appear
"
51591,"Tf lite model fails to provide inference - Output tensor at index 0 is expected to have 3 dimensions, found 2","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installation (pip package or built from source): 2.6.0
- TensorFlow library (version, if pip package or github SHA, if built from source):  all other libraries cloned from https://github.com/tensorflow/examples/tensorflow_examples/lite/model_maker/pip_package

### 2. Code
Trained a model using tf lite model maker. Attaching the colab with output but without input dataset below:
https://colab.research.google.com/drive/1RVa019JFQmODFQNPrfmpOTaSi_GMwtlE?usp=sharing

Convert to tflite using model maker's **model.export()**

### 3. Failure after conversion
Evaluates successfully with model maker's **model.evaluate_tflite**
But fails to run inference on colab as well as with tf object detection android demo app https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android

Python inference on colab:
```
#@title Load the trained TFLite model and define some visualization functions

import cv2

from PIL import Image

model_path = 'model.tflite'

# Load the labels into a list
classes = ['???'] * model.model_spec.config.num_classes
label_map = model.model_spec.config.label_map
for label_id, label_name in label_map.as_dict().items():
  classes[label_id-1] = label_name

# Define a list of colors for visualization
COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)

def preprocess_image(image_path, input_size):
  """"""Preprocess the input image to feed to the TFLite model""""""
  img = tf.io.read_file(image_path)
  img = tf.io.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.uint8)
  original_image = img
  resized_img = tf.image.resize(img, input_size)
  resized_img = resized_img[tf.newaxis, :]
  return resized_img, original_image


def set_input_tensor(interpreter, image):
  """"""Set the input tensor.""""""
  tensor_index = interpreter.get_input_details()[0]['index']
  input_tensor = interpreter.tensor(tensor_index)()[0]
  input_tensor[:, :] = image


def get_output_tensor(interpreter, index):
  """"""Retur the output tensor at the given index.""""""
  output_details = interpreter.get_output_details()[index]
  tensor = np.squeeze(interpreter.get_tensor(output_details['index']))
  return tensor


def detect_objects(interpreter, image, threshold):
  """"""Returns a list of detection results, each a dictionary of object info.""""""
  # Feed the input image to the model
  set_input_tensor(interpreter, image)
  interpreter.invoke()

  # Get all outputs from the model
  boxes = get_output_tensor(interpreter, 0)
  classes = get_output_tensor(interpreter, 1)
  scores = get_output_tensor(interpreter, 2)
  count = int(get_output_tensor(interpreter, 3))

  results = []
  for i in range(count):
    if scores[i] >= threshold:
      result = {
        'bounding_box': boxes[i],
        'class_id': classes[i],
        'score': scores[i]
      }
      results.append(result)
  return results


def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):
  """"""Run object detection on the input image and draw the detection results""""""
  # Load the input shape required by the model
  _, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']

  # Load the input image and preprocess it
  preprocessed_image, original_image = preprocess_image(
      image_path,
      (input_height, input_width)
    )

  # Run object detection on the input image
  results = detect_objects(interpreter, preprocessed_image, threshold=threshold)

  # Plot the detection results on the input image
  original_image_np = original_image.numpy().astype(np.uint8)
  for obj in results:
    # Convert the object bounding box from relative coordinates to absolute
    # coordinates based on the original image resolution
    ymin, xmin, ymax, xmax = obj['bounding_box']
    xmin = int(xmin * original_image_np.shape[1])
    xmax = int(xmax * original_image_np.shape[1])
    ymin = int(ymin * original_image_np.shape[0])
    ymax = int(ymax * original_image_np.shape[0])

    # Find the class index of the current object
    class_id = int(obj['class_id'])

    # Draw the bounding box and label on the image
    color = [int(c) for c in COLORS[class_id]]
    cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)
    # Make adjustments to make the label visible for all objects
    y = ymin - 15 if ymin - 15 > 15 else ymin + 15
    label = ""{}: {:.0f}%"".format(classes[class_id], obj['score'] * 100)
    cv2.putText(original_image_np, label, (xmin, y),
        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

  # Return the final image
  original_uint8 = original_image_np.astype(np.uint8)
  return original_uint8
```
```
#@title Run object detection and show the detection results

INPUT_IMAGE_URL = ""https://storage.googleapis.com/cloud-ml-data/img/openimage/3/2520/3916261642_0a504acd60_o.jpg"" #@param {type:""string""}
DETECTION_THRESHOLD = 0.3 #@param {type:""number""}

TEMP_FILE = '/tmp/image.png'

!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL
im = Image.open(TEMP_FILE)
im.thumbnail((512, 512), Image.ANTIALIAS)
im.save(TEMP_FILE, 'PNG')

# Load the TFLite model
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Run inference and draw detection result on the local copy of the original file
detection_result_image = run_odt_and_draw_results(
    TEMP_FILE,
    interpreter,
    threshold=DETECTION_THRESHOLD
)

# Show the detection result
Image.fromarray(detection_result_image)
```
Error:

> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-19-2bfddfa5022e> in <module>()
>      19     TEMP_FILE,
>      20     interpreter,
> ---> 21     threshold=DETECTION_THRESHOLD
>      22 )
>      23 
> 
> 1 frames
> <ipython-input-18-568dde2e930c> in run_odt_and_draw_results(image_path, interpreter, threshold)
>      77 
>      78   # Run object detection on the input image
> ---> 79   results = detect_objects(interpreter, preprocessed_image, threshold=threshold)
>      80 
>      81   # Plot the detection results on the input image
> 
> <ipython-input-18-568dde2e930c> in detect_objects(interpreter, image, threshold)
>      51   classes = get_output_tensor(interpreter, 1)
>      52   scores = get_output_tensor(interpreter, 2)
> ---> 53   count = int(get_output_tensor(interpreter, 3))
>      54 
>      55   results = []
> 
> TypeError: only size-1 arrays can be converted to Python scalars

Android studio fatal exception:

> E/AndroidRuntime: FATAL EXCEPTION: main
>     Process: org.tensorflow.lite.examples.detection, PID: 27414
>     java.lang.AssertionError: Error occurred when initializing ObjectDetector: Output tensor at index 0 is expected to have 3 dimensions, found 2.
>         at org.tensorflow.lite.task.vision.detector.ObjectDetector.initJniWithByteBuffer(Native Method)
>         at org.tensorflow.lite.task.vision.detector.ObjectDetector.access$100(ObjectDetector.java:86)
>         at org.tensorflow.lite.task.vision.detector.ObjectDetector$3.createHandle(ObjectDetector.java:211)
>         at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:91)
>         at org.tensorflow.lite.task.vision.detector.ObjectDetector.createFromBufferAndOptions(ObjectDetector.java:207)
>         at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.<init>(TFLiteObjectDetectionAPIModel.java:87)
>         at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:81)
>         at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:99)
>         at org.tensorflow.lite.examples.detection.CameraActivity$7.onPreviewSizeChosen(CameraActivity.java:446)
>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:357)
>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:362)
>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment.access$300(CameraConnectionFragment.java:66)
>         at org.tensorflow.lite.examples.detection.CameraConnectionFragment$3.onSurfaceTextureAvailable(CameraConnectionFragment.java:171)
>         at android.view.TextureView.getTextureLayer(TextureView.java:415)
>         at android.view.TextureView.draw(TextureView.java:360)
>         at android.view.View.updateDisplayListIfDirty(View.java:21389)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.updateDisplayListIfDirty(View.java:21380)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.updateDisplayListIfDirty(View.java:21380)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.draw(View.java:22538)
>         at android.view.View.updateDisplayListIfDirty(View.java:21389)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at androidx.coordinatorlayout.widget.CoordinatorLayout.drawChild(CoordinatorLayout.java:1246)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.draw(View.java:22538)
>         at android.view.View.updateDisplayListIfDirty(View.java:21389)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.updateDisplayListIfDirty(View.java:21380)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.updateDisplayListIfDirty(View.java:21380)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.updateDisplayListIfDirty(View.java:21380)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
>         at android.view.View.updateDisplayListIfDirty(View.java:21380)
>         at android.view.View.draw(View.java:22254)
>         at android.view.ViewGroup.drawChild(ViewGroup.java:4541)
>         at android.view.ViewGroup.dispatchDraw(ViewGroup.java:4302)
> E/AndroidRuntime:     at android.view.View.draw(View.java:22538)
>         at com.android.internal.policy.DecorView.draw(DecorView.java:848)
>         at android.view.View.updateDisplayListIfDirty(View.java:21389)
>         at android.view.ThreadedRenderer.updateViewTreeDisplayList(ThreadedRenderer.java:559)
>         at android.view.ThreadedRenderer.updateRootDisplayList(ThreadedRenderer.java:565)
>         at android.view.ThreadedRenderer.draw(ThreadedRenderer.java:647)
>         at android.view.ViewRootImpl.draw(ViewRootImpl.java:4417)
>         at android.view.ViewRootImpl.performDraw(ViewRootImpl.java:4144)
>         at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:3391)
>         at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:2182)
>         at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:8730)
>         at android.view.Choreographer$CallbackRecord.run(Choreographer.java:1352)
>         at android.view.Choreographer.doCallbacks(Choreographer.java:1149)
>         at android.view.Choreographer.doFrame(Choreographer.java:1049)
>         at android.view.Choreographer$FrameHandler.handleMessage(Choreographer.java:1275)
>         at android.os.Handler.dispatchMessage(Handler.java:106)
>         at android.os.Looper.loop(Looper.java:233)
>         at android.app.ActivityThread.main(ActivityThread.java:8010)
>         at java.lang.reflect.Method.invoke(Native Method)
>         at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:631)
>         at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:978)

This is a new issue that has cropped up since tf version upgrade to 2.6.0 and model maker to 0.3.3
I have older models trained the same way that work perfectly fine on both colab and with the demo app.
Is there something else that needs to be added while exporting the tflite model or is there some version conflict that is causing this.  Does anybody have any clue about this error?"
51590,TypeError: EndVector() takes 1 positional argument but 2 were given,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  ArchLinux
- TensorFlow installation (pip package or built from source):  pip package   
- TensorFlow library (version, if pip package or github SHA, if built from source):  v2.5.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

```
import tensorflow as tf
import numpy as np
import pathlib


gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
if gpus:
    for gpu in gpus:
        tf.config.experimental.set_memory_growth(device = gpu, enable = True)


# Set keras model name
keras_model = ""weight.h5""
        
# Load MNIST dataset
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()


# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images.astype(np.float32) / 255.0
test_images = test_images.astype(np.float32) / 255.0

# Define the model architecture
model = tf.keras.Sequential([
  tf.keras.layers.InputLayer(input_shape=(28, 28)),
  tf.keras.layers.Reshape(target_shape=(28, 28, 1)),
  tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(10)
])


# Set training details
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train model
model.fit(
  train_images,
  train_labels,
  epochs=5,
  validation_data=(test_images, test_labels)
)

# Save model
model.save_weights(filepath = keras_model, save_format = 'h5')

# Load keras model weight
model.load_weights(filepath = keras_model)


# Define representative dataset
def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):
    yield [input_value]


# Do conversion
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8

tflite_model_quant = converter.convert()   # FAILED HERE


# Save the quantized model
tflite_models_dir = pathlib.Path("""")
tflite_model_quant_file = tflite_models_dir/tflite_model
tflite_model_quant_file.write_bytes(tflite_model_quant)
```




### 3. Failure after conversion
Not able to convert

### 4. (optional) RNN conversion support
N/A

### 5. (optional) Any other info / logs
2021-08-20 16:27:43.366934: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9
Traceback (most recent call last):
  File ""/home/xxx/Desktop/TFLite_practice/convert_tflite.py"", line 56, in <module>
    tflite_model_quant = converter.convert()
  File ""/usr/lib/python3.9/site-packages/tensorflow/lite/python/lite.py"", line 1057, in convert
    result = super(TFLiteKerasModelConverterV2,
  File ""/usr/lib/python3.9/site-packages/tensorflow/lite/python/lite.py"", line 800, in convert
    result = _modify_model_io_type(result, **flags_modify_model_io_type)
  File ""/usr/lib/python3.9/site-packages/tensorflow/lite/python/util.py"", line 906, in modify_model_io_type
    return _convert_model_from_object_to_bytearray(model_object)
  File ""/usr/lib/python3.9/site-packages/tensorflow/lite/python/util.py"", line 556, in _convert_model_from_object_to_bytearray
    model_offset = model_object.Pack(builder)
  File ""/usr/lib/python3.9/site-packages/tensorflow/lite/python/schema_py_generated.py"", line 5630, in Pack
    operatorCodes = builder.EndVector(len(self.operatorCodes))
TypeError: EndVector() takes 1 positional argument but 2 were given

"
51589,google.protobuf.message.DecodeError: Error parsing message when using tf.function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 21.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): conda binary
- TensorFlow version (use command below): tf.2.5
- Python version: python 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 11.4, cudatoolkit 11.0.221,  cudnn 8.2.1.32
- GPU model and memory: NVIDIA TITAN RTX, 24Gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
Successfully opened dynamic library libcudart.so.11.0 v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
**Describe the current behavior**
I write a custom model involving the tf.gather_nd function. When the 'train_step' function is not decorated   by 'tf.function', the model can be well-trained. But when I use 'tf.function' to decorate the 'train_step' function, I get the error 'google.protobuf.message.DecodeError: Error parsing message'.

**Describe the expected behavior**
The model can be trained.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing): no

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
import tensorflow as tf
import numpy as np

class GatherModel(tf.keras.Model):
    def __init__(self,ind1,w1):
        super(GatherModel, self).__init__()
        self.ind1=ind1
        self.w1=tf.cast(w1,tf.float32)
        self.lambda1 = tf.Variable(initial_value=tf.constant(0.1), trainable=True, name='lambda1')

    def __call__(self, inputs,training=0):
        y=inputs
        for i in range(5):
            y=tf.transpose(y, [1, 2, 3, 0])
            y=tf.gather_nd(y*1.0, self.ind1)
            y=y*self.w1
            y=tf.reduce_sum(y,0)
            y=tf.transpose(y,[3,0,1,2])
            y = self.lambda1*y
        return y

# @tf.function
def train_step(model, inputs, labels, Loss, optimizer):
    with tf.GradientTape() as tape:
        predictions = model(inputs, training=1)
        loss = Loss(labels, predictions)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss

if __name__ == '__main__':
    ind1=np.random.randint(0,300,[367, 217, 721, 2])
    w1=np.random.normal(size=[367, 217, 721, 1, 1])
    Model=GatherModel(ind1,w1)
    inputs=tf.random.normal([2,256,256,1])
    labels= tf.random.normal([2,217,721,1])
    loss=tf.keras.losses.MeanSquaredError()
    optimizer=tf.keras.optimizers.Adam(0.001)
    for i in range(10):
        LL=train_step(Model,inputs,labels,loss,optimizer)
        print(LL)
  
In the google colab https://colab.research.google.com/drive/1TrTctTKjYOIrZ2rvKhQmdTDS77d0gmg9#scrollTo=WMcegEVFWW_M, it says that the program crashed because of  exhausting of RAM.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51588,google.protobuf.message.DecodeError: Error parsing message when using tf.function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 21.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): conda binary
- TensorFlow version (use command below): tf.2.5
- Python version: python 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 11.4, cudatoolkit 11.0.221,  cudnn 8.2.1.32
- GPU model and memory: NVIDIA TITAN RTX, 24Gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
Successfully opened dynamic library libcudart.so.11.0 v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
**Describe the current behavior**
I write a custom model involving the tf.gather_nd function. When the 'train_step' function is not decorated   by 'tf.function', the model can be well-trained. But when I use 'tf.function' to decorate the 'train_step' function, I get the error 'google.protobuf.message.DecodeError: Error parsing message'.

**Describe the expected behavior**
The model can be trained.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing): no

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import numpy as np

class GatherModel(tf.keras.Model):
    def __init__(self,ind1,w1):
        super(GatherModel, self).__init__()
        self.ind1=ind1
        self.w1=tf.cast(w1,tf.float32)
        self.lambda1 = tf.Variable(initial_value=tf.constant(0.1), trainable=True, name='lambda1')

    def __call__(self, inputs,training=0):
        y=inputs
        for i in range(5):
            y=tf.transpose(y, [1, 2, 3, 0])
            y=tf.gather_nd(y*1.0, self.ind1)
            y=y*self.w1
            y=tf.reduce_sum(y,0)
            y=tf.transpose(y,[3,0,1,2])
            y = self.lambda1*y
        return y

# @tf.function
def train_step(model, inputs, labels, Loss, optimizer):
    with tf.GradientTape() as tape:
        predictions = model(inputs, training=1)
        loss = Loss(labels, predictions)
    grads = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(grads, model.trainable_variables))
    return loss

if __name__ == '__main__':
    ind1=np.random.randint(0,300,[367, 217, 721, 2])
    w1=np.random.normal(size=[367, 217, 721, 1, 1])
    Model=GatherModel(ind1,w1)
    inputs=tf.random.normal([2,256,256,1])
    labels= tf.random.normal([2,217,721,1])
    loss=tf.keras.losses.MeanSquaredError()
    optimizer=tf.keras.optimizers.Adam(0.001)
    for i in range(10):
        LL=train_step(Model,inputs,labels,loss,optimizer)
        print(LL)
```


In the google colab   [https://colab.research.google.com/drive/1TrTctTKjYOIrZ2rvKhQmdTDS77d0gmg9#scrollTo=WMcegEVFWW_M](url), it says that the program is crashed because of  exhausting of RAM.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51587,"KeyError: ""Failed to add concrete function b'__inference_train_14141' to object based saved model as it captures tf.Tensor(<unprintable>, shape=(), dtype=resource)  tensor","**tensorflow 2.5 python 3.7**

I have totally no idea of what the error is when I'm using `tf.saved_model.save`. So less the hint what causes the error. At least it should tell us which tensor on earth is unreachable.

```
Traceback (most recent call last):
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/function_serialization.py"", line 65, in serialize_concrete_function
    bound_inputs.append(node_ids[capture])
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/util/object_identity.py"", line 139, in __getitem__
    return self._storage[self._wrap_key(key)]
KeyError: <_ObjectIdentityWrapper wrapping <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""main_Semantic3D.py"", line 628, in <module>
    main1()
  File ""main_Semantic3D.py"", line 566, in main1
    tf.saved_model.save(model, modeldir)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1193, in save
    save_and_return_nodes(obj, export_dir, signatures, options)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1228, in save_and_return_nodes
    _build_meta_graph(obj, signatures, options, meta_graph_def))
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1399, in _build_meta_graph
    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 1363, in _build_meta_graph_impl
    saveable_view, asset_info.asset_index)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/save.py"", line 937, in _serialize_object_graph
    concrete_function, saveable_view.captured_tensor_node_ids, coder)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/saved_model/function_serialization.py"", line 74, in serialize_concrete_function
    % (concrete_function.name, capture))
KeyError: ""Failed to add concrete function b'__inference_train_14141' to object based saved model as it captures tensor tf.Tensor(<unprintable>, shape=(), dtype=resource) which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).""

```"
51585,"For loop in ""call"" function not working with Autograph/tf.range","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code : Yes
- OS Platform and Distribution : Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.8
- CUDA/cuDNN version: N/A (testing on CPU)
- GPU model and memory: N/A (see above)

I am training a set of models in parallel as part of a more elaborate training procedure so as a result I am trying to implement a call function like the following one:

    class multi_model_test(tf.keras.Model):
        def __init__(self, num_models,width,depth):
            super(multi_model_test, self).__init__()

            self.n_traces = num_models
            self.net_list = []
            for i in range(self.n_traces):
                net = tf.keras.models.Sequential()
                net.add(tf.keras.Input(shape = (1,)))
                for i in range(depth):
                    net.add(tf.keras.layers.Dense(width,activation = 'swish'))
                net.add(tf.keras.layers.Dense(1))
                self.net_list.append(net)


        def call(self,ipts):
            outlist = []
            for i in tf.range(self.n_traces):
                outlist.append(self.net_list[i](ipts))
            out = tf.stack(outlist,-1)
            return out

When I build this as follows:
```
model = multi_model_test(10,50,10)
model.build((None,1))
```
I get the following error:

``ValueError: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, `call` your model on real tensor data (of the correct dtype).``

This appears to be a bug since the error here clearly does not affect the input, and this model can take float inputs. If I exchange the `tf.range` for simply `range` in the for loop in the call function I don't have an issue but then this doesn't work with Autograph and training takes a very long time.



"
51584,how to record loss with tf.summary in the tf.function graph mode,"**tensorflow 2.5, python 3.7**

```
import tensorflow as tf
import numpy as np
import datetime

class Dense(tf.Module):
    def __init__(self, input_dim, output_size, name=None):
        super(Dense, self).__init__(name=name)
        self.w = tf.Variable(
            tf.random.normal([input_dim, output_size]), name='w')
        self.b = tf.Variable(tf.zeros([output_size]), name='b')

    def __call__(self, x):
        y = tf.matmul(x, self.w) + self.b
        return tf.nn.relu(y)

model = Dense(2,4)

class Test(object):
    def __init__(self):
        self.output = model([[7.0, 3]])
        self.optimizer = tf.compat.v1.train.AdamOptimizer(0.4)

        self.step = 0

        stamp = datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
        logdir = 'logs/test8/%s' % stamp

        self.summary_writer = tf.summary.create_file_writer(logdir)
        tf.summary.trace_on(graph=True, profiler=False)

        for i in range(10):
            self.run()

    def compare(self, y_true, output):
        return tf.square(y_true - output)

    def loss_fn(self):
        y_true = tf.ones([1,4])
        self.output = model([[7.0, 3]])

        comp = tf.py_function(self.compare, [y_true , self.output], tf.float32)
        loss = tf.reduce_mean(comp) # error

        # output2 = model([[7.0, 3]])
        # loss = tf.reduce_mean(tf.square(y_true - output2))

        tf.print(loss)
        tf.print(self.step)

        with self.summary_writer.as_default():
            tf.summary.scalar('loss', loss, step=self.step)

        self.step += 1
        return loss

    # @tf.function(autograph=True, jit_compile=True)
    @tf.function()
    def run(self):
        train_op = self.optimizer.minimize(self.loss_fn)

Test()
```

As can be seen from the output, the variable `self.step` is not updated in `def loss_fn(self)`. The reason is simple from what is said in https://tensorflow.google.cn/tensorboard/migrate, 

```
The ""step"" value must be passed into each op via a the step argument

TensorBoard requires a step value to render the data as a time series
Explicit passing is necessary because the global step from TF 1.x has been removed, so each op must know the desired step variable to read
```

However, according to https://tensorflow.google.cn/api_docs/python/tf/compat/v1/train/AdamOptimizer?hl=en&version=nightly#expandable-3, 

`When eager execution is enabled, loss should be a Python function that takes no arguments and computes the value to be minimized`.

Definitely these two announcement contradict to each other when trying to use `tf.summary` in `def loss_fn(self)`. Any solutions? I just want to record the loss with `tf.summary`."
51583,Tensorflow 2.6 built without s3 support.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian Linux, python 3.7. 
- TensorFlow installed from (source or binary): binary using pip
- TensorFlow version: 2.6.0
- Python version: 3.7, 3.8
- Installed using virtualenv? pip? conda?: venv, conda



**Describe the problem**

tensorflow 2.6.0 built without s3 support however it was made default since 1.4.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


```
$ pip install tensorflow==2.6.0
Collecting tensorflow==2.6.0
  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)
     |████████████████████████████████| 458.3 MB 31 kB/s 
...
Installing collected packages: tensorflow
  Attempting uninstall: tensorflow
    Found existing installation: tensorflow 2.4.1
    Uninstalling tensorflow-2.4.1:
      Successfully uninstalled tensorflow-2.4.1
Successfully installed tensorflow-2.6.0

$ python
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from tensorflow.python.lib.io import file_io
2021-08-20 08:47:18.398430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2021-08-20 08:47:18.398446: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
>>> print(file_io.stat(""s3://bucket/model""))
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/bacek/miniconda3/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 871, in stat
    return stat_v2(filename)
  File ""/home/bacek/miniconda3/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 887, in stat_v2
    return _pywrap_file_io.Stat(compat.path_to_str(path))
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 's3' not implemented (file: 's3://bucket/model')
>>> 

```
"
51582,An easy way to update tensors that complies with numpy syntax,"**System information**
- TensorFlow version (you are using): 2.6
- Are you willing to contribute it (Yes/No): No (wouldn't know how)


**Describe the feature and the current behavior/state.**
I would love to be able to do something like the following:
```python
t1 = np.zeros((2, 4))
t2 = np.ones((2, 3))

t1[:, 1:4] += t2
t1[:, [3, 1, 1]] += t2
```
without having to use methods like `tensor_scatter_nd_update` over multiple lines of code...

**Will this change the current api? How?**
yes, it will be possible to use a syntax like in numpy, that everyone is familiar with.

**Who will benefit with this feature?**
everyone who needs to build tensors manually"
51579,"Error: ""Failed to connect to all addresses"", TPU on Colab","When I attempt to train on Colab using Keras and TPU, I get this error and training stops before the first epoch.

Link to code for reproduction: https://colab.research.google.com/drive/1ddTaQNmKbapwDPhrPlDKpnoCb8Exa_XI?usp=sharing"
51576,InvalidArgumentError in Model Maker Object Detection Tutorial ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No. I used this tutorial Jupyter notebook. https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_object_detection.ipynb#scrollTo=Fw5Y7snSuG51
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab 
- TensorFlow version (use command below): ('v2.1.0-0-ge5bf8de410', '2.1.0')
- Python version: 2.7.17

**Describe the current behavior**
In the step 6, I used the following command to evaluate the TFlite model but I got an error message.  
```
model.evaluate_tflite('model.tflite', test_data)
```

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-9-cf2cd774ff7b> in <module>()
----> 1 model.evaluate_tflite('model.tflite', test_data)

8 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py in evaluate_tflite(self, tflite_filepath, data)
    187     ds = data.gen_dataset(self.model_spec, batch_size=1, is_training=False)
    188     return self.model_spec.evaluate_tflite(tflite_filepath, ds, len(data),
--> 189                                            data.annotations_json_file)
    190 
    191   def _export_saved_model(self, saved_model_dir: str) -> None:

/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/object_detector_spec.py in evaluate_tflite(self, tflite_filepath, dataset, steps, json_file)
    386       normalize_factor = tf.constant([height, width, height, width],
    387                                      dtype=tf.float32)
--> 388       nms_boxes *= normalize_factor
    389       if labels['image_scales'] is not None:
    390         scales = tf.expand_dims(tf.expand_dims(labels['image_scales'], -1), -1)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in r_binary_op_wrapper(y, x)
   1398       #   r_binary_op_wrapper use different force_same_dtype values.
   1399       y, x = maybe_promote_tensors(y, x)
-> 1400       return func(x, y, name=name)
   1401 
   1402   # Propagate func.__doc__ to the wrappers

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in _mul_dispatch(x, y, name)
   1708     return sparse_tensor.SparseTensor(y.indices, new_vals, y.dense_shape)
   1709   else:
-> 1710     return multiply(x, y, name=name)
   1711 
   1712 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    204     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    205     try:
--> 206       return target(*args, **kwargs)
    207     except (TypeError, ValueError):
    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in multiply(x, y, name)
    528   """"""
    529 
--> 530   return gen_math_ops.mul(x, y, name)
    531 
    532 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py in mul(x, y, name)
   6234       return _result
   6235     except _core._NotOkStatusException as e:
-> 6236       _ops.raise_from_not_ok_status(e, name)
   6237     except _core._FallbackException:
   6238       pass

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6939   message = e.message + ("" name: "" + name if name is not None else """")
   6940   # pylint: disable=protected-access
-> 6941   six.raise_from(core._status_to_exception(e.code, message), None)
   6942   # pylint: enable=protected-access
   6943 

/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: required broadcastable shapes [Op:Mul]
```


**Standalone code to reproduce the issue**
https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_object_detection.ipynb#scrollTo=Fw5Y7snSuG51

"
51574,Missing _keras_logits from model.predict(x) leads to difference in loss evaluation,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.9.2
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 11.2/7.6.5 
- GPU model and memory: GeForce RTX 2080ti, 11019MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
`model.predict(x)` does not have attribute `_keras_logits`
**Describe the expected behavior**
`model.predict(x)` and `model(x)` produce identical outputs.
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import numpy as np
import tensorflow as tf
np.random.seed(999)

loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)
y_true = [[1, 0, 0]]
inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(3, 
            activation='softmax',
            kernel_initializer=tf.keras.initializers.glorot_normal(seed=42))(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)

x = np.random.random((1, 3))
y_pred1 = model.predict(x)
y_pred2 = model(x)

# losses are different. One uses logits, the other doesn't.
print('model.predict(x) loss = ', loss_fn(y_true, y_pred1))
print('model(x) loss = ', loss_fn(y_true, y_pred2))  

assert hasattr(y_pred1, '_keras_logits') == hasattr(y_pred2, '_keras_logits')
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51573,Build Fails with TF 2.6 on VS2019 (Win 10),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.6
- Python version: 3.8
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): VS2019 
- CUDA/cuDNN version: 11.2 / 8.1.0
- GPU model and memory: 2080 Max Q

When attempting to build from source using the following command, it fails to build the pip package,

**bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package**

```
ERROR: C:/sdks/tensorflow/tensorflow/python/util/BUILD:610:27: C++ compilation of rule '//tensorflow/python/util:fast_module_type.so' failed (Exit 2): cl.exe failed: error executing command
  cd C:/users/adam/_bazel_adam/e7merofc/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Tools\MSVC\14.29.30037\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Tools\MSVC\14.29.30037\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.18362.0\cppwinrt
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Tools\MSVC\14.29.30037\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\Tools\devinit;C:\Program Files (x86)\Windows Kits\10\bin\10.0.18362.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/Adam/anaconda3/envs/tensorflow/python.exe
    SET PYTHON_LIB_PATH=C:/Users/Adam/anaconda3/envs/tensorflow/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\Adam\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TMP=C:\Users\Adam\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio/2019/Enterprise/VC/Tools/MSVC/14.29.30037/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/pybind11 /Ibazel-out/x64_windows-opt/bin/external/pybind11 /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/pybind11/_virtual_includes/pybind11 /Ithird_party/eigen3/mkl_include /Ibazel-out/x64_windows-opt/bin/third_party/eigen3/mkl_include /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/pybind11/include /Ibazel-out/x64_windows-opt/bin/external/pybind11/include /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /arch:AVX /std:c++14 -fno-strict-aliasing -fexceptions /Fobazel-out/x64_windows-opt/bin/tensorflow/python/util/_objs/fast_module_type.so/fast_module_type.obj /c tensorflow/python/util/fast_module_type.cc
Execution platform: @local_execution_config_platform//:platform
cl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release
cl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'
cl : Command line warning D9002 : ignoring unknown option '-fno-strict-aliasing'
cl : Command line warning D9002 : ignoring unknown option '-fexceptions'
C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Tools\MSVC\14.29.30037\include\complex(675): error C2039: 'copysign': is not a member of '`global namespace''
C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC\Tools\MSVC\14.29.30037\include\complex(675): error C3861: 'copysign': identifier not found
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 69.130s, Critical Path: 6.47s
INFO: 29 processes: 24 internal, 5 local.
FAILED: Build did NOT complete successfully
```
"
51571,Make ```tf.data.experimental.make_csv_dataset``` return many labels,"**System information**
- TensorFlow version (you are using):2.6.0
- Are you willing to contribute it (Yes/No):Yes

**Describe the feature and the current behavior/state.**
```tf.data.experimental.make_csv_dataset``` not can only support setting one column for label name . However , in some model , such as MMoE , there are many outputs .   

**Will this change the current api? How?**
It will change the str parameter ```label_name``` to list parameter ```label_names``` like ```column_names``` 

**Who will benefit with this feature?**
Everyone who use model with multiple outputs .

**Any Other info.**
I would like to change the code 
```
  def map_fn(*columns):
    """"""Organizes columns into a features dictionary.
    Args:
      *columns: list of `Tensor`s corresponding to one csv record.
    Returns:
      An OrderedDict of feature names to values for that particular record. If
      label_name is provided, extracts the label feature to be returned as the
      second element of the tuple.
    """"""
    features = collections.OrderedDict(zip(column_names, columns))
    if label_name is not None:
      label = features.pop(label_name)
      return features, label
    return features
```
to 
```
  def map_fn(*columns):
    """"""Organizes columns into a features dictionary.
    Args:
      *columns: list of `Tensor`s corresponding to one csv record.
    Returns:
      An OrderedDict of feature names to values for that particular record. If
      label_name is provided, extracts the label feature to be returned as the
      second element of the tuple.
    """"""
    features = collections.OrderedDict(zip(column_names, columns))
    if label_names is not None:
      if len(label_names) >= 2:
        labels = collections.OrderedDict()
        for label_name in label_names :
          labels[label_name] = features.pop(label_name)
        return features, labels
      elif len(label_names) == 1:
        label= features.pop(label_names[0])
        return features, label
    return features
```
"
51570,RuntimeError: tensorflow/lite/kernels/conv.cc:349 input->dims->data[3] != filter->dims->data[3] (64 != 2)Node number 12 (CONV_2D) failed to prepare.,"### 1. System information

- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installation (pip package or built from source): pip package 
- TensorFlow library (version, if pip package or github SHA, if built from source): tf-nightly-2.7.0.dev20210818
- model arc: CRNN

- my converter code, succeeded in tf2.6.0 and tf-nightly but failed in tf2.3.0,
```
converter = tf.lite.TFLiteConverter.from_saved_model(model_path)
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter._experimental_lower_tensor_list_ops = False
converter.representative_dataset = representative_data_gen
lite_model = converter.convert()
lite_model_file = f'{fp16_model_path}/crnn_lite.tflite'
with open(lite_model_file, 'wb') as f:
    f.write(lite_model)
```
after call **interpreter.allocate_tensors()**, runtime errors occur。in this issue [https://github.com/tensorflow/tensorflow/issues/44548](url), install tf-nightly can fix this. please help me how can i fix this? thanks 
"
51569,`ModuleNotFoundError: No module named 'keras'` in most tensorflow calls,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): stock script
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Manjaro Pahvo 21.1.0
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary (official arch repository)
- TensorFlow version (use command below): 2.6.0
- Python version: 3.9.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 11.4.0-1/8.2.2.26-1
- GPU model and memory: Nvidia RTX 3060 Ti (8GB)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Most (if not all) of the library calls give a `ModuleNotFoundError: No module named 'keras'`.

**Describe the expected behavior**
All library calls should work without this import relative reference problem. 

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): A workaround for now is using `import tensorflow.keras as keras`

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf
print(tf.version.VERSION)
fashion_mnist = tf.keras.datasets.fashion_mnist
```
(code from: [https://www.tensorflow.org/tutorials/keras/classification](https://www.tensorflow.org/tutorials/keras/classification))

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
Traceback (most recent call last):
File ""<stdin>"", line 1, in <module>
File ""/usr/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py"", line 62, in __getattr__
module = self._load()
File ""/usr/lib/python3.9/site-packages/tensorflow/python/util/lazy_loader.py"", line 45, in _load
module = importlib.import_module(self.__name__)
File ""/usr/lib/python3.9/importlib/__init__.py"", line 127, in import_module
return _bootstrap._gcd_import(name[level:], package, level)
File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 972, in _find_and_load_unlocked
File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 972, in _find_and_load_unlocked
File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 972, in _find_and_load_unlocked
File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
File ""<frozen importlib._bootstrap>"", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'keras'
```
(output of code snippet above)"
51568,How can I make multiple sessions share a graph? Not found: Container localhost does not exist,"
How can I make multiple sessions share a graph by c_api?
My usage is as follows:
**The first session is created using TF_LoadSessionFromSavedModel.
The second session is created using TF_NewSession.**

It is normal to call the TF_SessionRun of the first session. However, when calling the TF_SessionRun of the second session from another thread, the following error is reported:

2021-08-19 14:56:00.772594: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at resource_variable_ops.cc:633 : **Not found: Container localhost does not exist**. (Could not find resource: localhost/embeddings/charactor_embeddings/weight)
{{function_node __inference__inference_5828_specialized_for_StatefulPartitionedCall_StatefulPartitionedCall_at_tf_graph}} {{function_node __inference__inference_5828_specialized_for_StatefulPartitionedCall_StatefulPartitionedCall_at_tf_graph}} Error while reading resource variable encoder/layer_._0/attention/self/key/bias from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/encoder/layer_._0/attention/self/key/bias)
	 [[{{node encoder/layer_._0/attention/self/key/BiasAdd/ReadVariableOp}}]]
terminate called after throwing an instance of 'std::runtime_error'
  what():  {{function_node __inference__inference_5828_specialized_for_StatefulPartitionedCall_StatefulPartitionedCall_at_tf_graph}} {{function_node __inference__inference_5828_specialized_for_StatefulPartitionedCall_StatefulPartitionedCall_at_tf_graph}} Error while reading resource variable encoder/layer_._0/attention/self/key/bias from Container: localhost. This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/encoder/layer_._0/attention/self/key/bias)
	 [[{{node encoder/layer_._0/attention/self/key/BiasAdd/ReadVariableOp}}]]
	 [[StatefulPartitionedCall/StatefulPartitionedCall]]
	 [[StatefulPartitionedCall/StatefulPartitionedCall]]Aborted (core dumped)



Why? Usage problem or bug? We look forward to your reply.


**System information**
tensorflow version(2.3.0)
Linux Ubuntu 16.04

**code snippet:**

static pthread_mutex_t sSpeakerClassToGraphMutex = PTHREAD_MUTEX_INITIALIZER;
static std::map<const void*, const void*> sSpeakerClassToGraph;

Model::Model(const void* classID, const std::string& model_filename, const std::vector<uint8_t>& config_options) {

	const char* v = TF_Version();
	printf(""Model********************************************************************** v(%s)\n"", v);
        this->status = TF_NewStatus();
	// Create the session.
	TF_SessionOptions* sess_opts = TF_NewSessionOptions();

	if (!config_options.empty())
	{
		TF_SetConfig(sess_opts, static_cast<const void*>(config_options.data()), config_options.size(), this->status);
		this->status_check(true);
	}


	pthread_mutex_lock(&sSpeakerClassToGraphMutex);

	 std::map<const void*, const void*>::const_iterator iter = sSpeakerClassToGraph.find(classID);
	if (iter != sSpeakerClassToGraph.cend())
	{
		this->graph = (TF_Graph* ) iter->second;
		printf(""(%p, %p)\n"", classID, this->graph);
		this->session =TF_NewSession(this->graph,sess_opts,status);
	}
	else
	{
		this->graph = TF_NewGraph();
		TF_Buffer* RunOpts = NULL;
		const char* tags = ""serve"";
		int ntags = 1;
		this->session = TF_LoadSessionFromSavedModel(sess_opts, RunOpts, model_filename.c_str(), &tags, ntags, this->graph, NULL, this->status);
		sSpeakerClassToGraph[classID] = graph;
		printf(""(%p, %p) create\n"", classID, graph);
	}
	pthread_mutex_unlock(&sSpeakerClassToGraphMutex);
	if (TF_GetCode(this->status) == TF_OK)
	{
		printf(""TF_LoadSessionFromSavedModel OK\n"");
	}
	else
	{
		printf(""%s"", TF_Message(this->status));
	}
	TF_DeleteSessionOptions(sess_opts);

	// Check the status
	this->status_check(true);
}

"
51566,Model input channel Question,"Generally, Tensorflow uses channel last. 

But I get input from channel first because I converted Torch --> ONNX --> Pb --> TFlite.

input = (1, 3, 224, 224)
out = TFLiteModel(input)

Is there a method that can be used as above?"
51565,setup(python_requires) argument,"**Describe the problem**

[`setup.py` uses only `setup(classifier)` argument to specify supported Python versions.](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py)

According to [Python Packaging User Guide > Packaging and distributing projects](https://packaging.python.org/guides/distributing-packages-using-setuptools/#classifiers),
> this information is only used for searching & browsing projects on PyPI, not for installing projects. To actually restrict what Python versions a project can be installed on, use the [`python_requires`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#python-requires) argument.

Adding `python_requires='>=3.7,<3.10'` would help version resolution for installing proper version of tensorflow."
51811,serving doc has error,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/tfx/tutorials/serving/rest_simple

## Description of issue (what needs changing):

### Clear description
I'm follow upper tutorial and using Google colab in tutorial.
When I was run this code that makes error.
How to fix it?

```
saved_model_cli show --dir {export_path} --all
```


```
MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:

signature_def['__saved_model_init_op']:
  The given SavedModel SignatureDef contains the following input(s):
  The given SavedModel SignatureDef contains the following output(s):
    outputs['__saved_model_init_op'] tensor_info:
        dtype: DT_INVALID
        shape: unknown_rank
        name: NoOp
  Method name is: 

signature_def['serving_default']:
  The given SavedModel SignatureDef contains the following input(s):
    inputs['Conv1_input'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 28, 28, 1)
        name: serving_default_Conv1_input:0
  The given SavedModel SignatureDef contains the following output(s):
    outputs['Dense'] tensor_info:
        dtype: DT_FLOAT
        shape: (-1, 10)
        name: StatefulPartitionedCall:0
  Method name is: tensorflow/serving/predict
WARNING: Logging before flag parsing goes to stderr.
W0819 04:35:50.096211 139702139606912 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.

Defined Functions:
  Function Name: '__call__'
    Option tensorflow/tensorflow#1
      Callable with:
        Argument tensorflow/tensorflow#1
          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')
        Argument tensorflow/tensorflow#2
          DType: bool
          Value: True
        Argument tensorflow/tensorflow#3
          DType: NoneType
          Value: None
    Option tensorflow/tensorflow#2
      Callable with:
        Argument tensorflow/tensorflow#1
          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')
        Argument tensorflow/tensorflow#2
          DType: bool
          Value: True
        Argument tensorflow/tensorflow#3
          DType: NoneType
          Value: None
    Option tensorflow/tensorflow#3
      Callable with:
        Argument tensorflow/tensorflow#1
          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'inputs')
        Argument tensorflow/tensorflow#2
          DType: bool
          Value: False
        Argument tensorflow/tensorflow#3
          DType: NoneType
          Value: None
    Option tensorflow/tensorflow#4
      Callable with:
        Argument tensorflow/tensorflow#1
          Conv1_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=u'Conv1_input')
        Argument tensorflow/tensorflow#2
          DType: bool
          Value: False
        Argument tensorflow/tensorflow#3
          DType: NoneType
          Value: None

  Function Name: '_default_save_signature'
Traceback (most recent call last):
  File ""/usr/local/bin/saved_model_cli"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py"", line 990, in main
    args.func(args)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py"", line 691, in show
    _show_all(args.dir)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py"", line 283, in _show_all
    _show_defined_functions(saved_model_dir)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/tools/saved_model_cli.py"", line 186, in _show_defined_functions
    function._list_all_concrete_functions_for_serialization()  # pylint: disable=protected-access
AttributeError: '_WrapperFunction' object has no attribute '_list_all_concrete_functions_for_serialization'
```

"
51561,LSTM & BiLSTM can't run correct results while batch processing on Mobile ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux and Android
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (or github SHA if from source): tensorflow2.5.0-gpu


**Provide the text output from tflite_convert**

```
run_model = tf.function(lambda x: basemodel(x))
# This is important, let's fix the input size.
BATCH_SIZE = 1
STEPS = 32
INPUT_SIZE = 320
CHANNEL = 1
concrete_func = run_model.get_concrete_function(
  tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE, CHANNEL], basemodel.inputs[0].dtype))


MODEL_DIR = ""BiLSTM""
basemodel.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)

converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_model = converter.convert()
open(""BiLSTM.tflite"", ""wb"").write(tflite_model)

```

**Standalone code to reproduce the issue** 
We developed a text recognition model including BiLSTM basing on TF2.5, and convert the model to TFlite, which can run on mobile GPU successfully. 

While the batch size=1, the model can recognize the text correctly. But when btachsize>1, only the first batch result is correct, and others are incorrect. And before using the tflite model, we need to reset all variables:
```
interpreter.reset_all_variables()
interpreter.set_tensor(input_details[0]['index'], X)
interpreter.invoke()
y_pred = interpreter.get_tensor(output_details[0]['index'])
```
I think the LSTM states need to be reset after being called. Is there any solution to reset them within a batch?

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
51559,Need TF-TRT support to INT32 OPs,"Currently, some TF-TRT converters already allow INT32 data types. Need to find out other TensorRT layers that support INT32 data types and make the TF-TRt converters to reflect that. Need to add test cases."
51556,"Faster R-CNN TFlite conversion and inference works on CPU, but when run on GPU results in segmentation fault during inference","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0

### 2. Code

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
import tensorflow as tf
import numpy as np
import cv2 as cv
import time

def reduce_size(im,percent=None,new_width=None):
    '''
    Get a reduced size version of an image
    
    Inputs:
        im: numpy array of an image
        percent: if not None, the percent at which to scale the image
        new_width: if not None, the new width to scale the image to (scales the
                   height proportinally)
                   
    Returns: numpy array of new, smaller image
    
    Note: please only set either percent OR new_width, it doesn't make sense
          to set both
    '''
    
    if percent:
        width = int(im.shape[1] * percent / 100)
        height = int(im.shape[0] * percent / 100)
        dim = (width, height)
    elif new_width:
        new_percent = new_width / im.shape[1]
        height = int(im.shape[0] * new_percent)
        dim = (new_width,height)
        
    small_im = cv.resize(im,dim,interpolation = cv.INTER_AREA)
    
    return small_im

print('tensorflow version: %s' %tf.__version__)

tf.config.list_physical_devices()

saved_model_dir = 'faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8/saved_model'

img_path = 'Test_image.jpg'
im = cv.imread(img_path)
small_im = reduce_size(im,percent=10)
input_tensor = tf.convert_to_tensor(small_im)
input_tensor = input_tensor[tf.newaxis, ...]

print('Loading model normally...', end='')
start_time = time.time()
detect_fn = tf.saved_model.load(saved_model_dir)
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

print('Inferring...', end='')
start_time = time.time()
detections = detect_fn(input_tensor)
end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

print('Converting model to tflite...', end='')
start_time = time.time()
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.allow_custom_ops=True
converter.experimental_new_converter = True

converter.target_spec.supported_ops = [
tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
end_time = time.time()
elapsed_time = end_time - start_time
tflite_model = converter.convert()
print('Done! Took {} seconds'.format(elapsed_time))

print('Creating an interpreter...', end='')
start_time = time.time()
interpreter = tf.lite.Interpreter(model_content=tflite_model)

input_index = interpreter.get_input_details()[0][""index""]
output_index = interpreter.get_output_details()[0][""index""]

interpreter.resize_tensor_input(0, [1, input_tensor.shape[1], input_tensor.shape[2], 3])
interpreter.allocate_tensors()
end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

print('Inferring image...', end='')
start_time = time.time()
interpreter.set_tensor(input_index, input_tensor)
interpreter.invoke()
raw_prediction = interpreter.tensor(output_index)
end_time = time.time()
elapsed_time = end_time - start_time
print('Done! Took {} seconds'.format(elapsed_time))

```
Example model used:  [Faster R-CNN ResNet50 V1 800x1333](http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_800x1333_coco17_gpu-8.tar.gz) from the tensorflow 2.0 model zoo

Test image I'm currently using (this is just to get any output at all, I plan to use a different image to test bounding boxes once I can get the code working):
![Test_image](https://user-images.githubusercontent.com/50996925/129928612-b0baa83e-4f0e-46bb-b47c-fbee8c8fca7a.jpg)

### 3. Failure after conversion

The above code runs fine on a CPU, but when run on a GPU, a segmentation fault is raised during the interpreter.invoke() command. I have tried a number of different options for the conversion step of converter.target_spec.supported_types = [tf.float16], including uint16 and some of the more experimental options, as well as just completely not including that step. In all cases, the code works on the CPU and results in a segment fault on the GPU, although for some the segmentation fault occurs much faster than with others.

I expect there is some fix in the conversion script, but I'm not sure if it's a problem with my commands, or if a model this large is not yet possible to use with TFlite on a GPU.
"
51555,"InvalidArgumentError:  indices[15,28] = 22105 is not in [0, 22015)  [[node encoder/embedding/embedding_lookup ","I am using tf 2.4.1, keras 2.4.3, and python 3.8.10 on CPU. 
I have downloaded pretrained GloVe word embeddings to train an Encoder-Decoder Model for abstractive summarization. 
I have created two embedding matrices, one to represent the vocabulary of the source input documents and one to represent the summary vocabulary. I am a little unsure if this is the correct practice but the model is able to train on 100 batches until the bug in the title stops training. 


Currently, the embedding matrix is of size 22015, 200. The first dimension represents the indices of the word embeddings and the second dimension represents the embedding dimension size for each word. The size of the encoder (source documents) vocabulary is taken directly from the embedding matrix = 22015. The summary vocabulary size is 7932 which is also the size of the first dimension of the summary embedding matrix. I should note that the original vocabulary sizes taken directly from dictionaries are different though come before the implementation of glove. 


The Decoder model is expected to output a probability distribution over the summary vocabulary (7932 ""classes""). It seems that the decoder output head is functioning as intended but the error occurs when the encoder starts to work on its word embeddings

CODE to SIMULATE issue
`from keras.layers import Embedding`

```
encoder_vocab_size = 22015
emb_dim = 200
```

```
input_dim = encoder_vocab_size 
output_dim = emb_dim
```
- Setting the weights of the Embedding layer to pretrained GloVe matrix (22015x200)
`weights = [embmatrix]`

- The Encoder uses this embedding layer with exact configuration
`embedding = Embedding(input_dim, output_dim, input_length=200, weights=weights, is_trainable=False)`

- Training the Encoder-Decoder Model
``for` epoch in range(25):`

    ``for` batch, (encoder_inp_batch, decoder_input_batch, target_input_batch) in enumerate(generator):`
        - encoder_inp_batch is shape (batch_size, 200)
        - decoder_input_batch is shape (batch_size, 49)
        - target_input_batch is shape (batch_size, 49)

        with tf.GradientTape() as tape:
            - Code breaks here AFTER successfully training over 100 batches of data
            encoder_output, encoder_hidden_states = encoder(encoder_inp_batch)


The loss used is sparse_categorical_crossentropy as targets are not one-hot encoded. Data is passed to the model in batches of 16. Number of data points used for training ~ 5,000. 
Still trying to pinpoint where exactly the embedding index out of bounds error might lie. Is it an issue arising from indices in the encoder embedding matrix or does the index out of bounds occur when feeding sequences of encoder training data where indices might be greater than the allowable range up to 22015
"
51554,numpy dependency on 1.19.2,"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L81

why is there a dependency on 1.19.2 when there are later version of numpy?"
51552,Tape Gradient ,"How to use Tape gradient in tensorflow/c/eager/gradients in C++ application?

- Cento 7
- tensorflow 2.6
- Cuda 11.2"
51551,esrgan failed on image over 50x50 pixels : error output tensor,
51550,What architecture do block3 and stack3 from tf.python.keras.applications.resnet correspond to?,"## URL(s) with the issue:

[https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet)

## Description of issue (what needs changing):

### Clear description
The building blocks provided in `tensorflow.python.keras.applications.resnet` are not well described. I am having a hard time identifying which architecture do block3 and stack3 come from. I posted a related question on StackOverflow hoping someone would know: [https://stackoverflow.com/questions/68815764/what-architecture-do-block3-and-stack3-from-keras-applications-resnet-correspond](https://stackoverflow.com/questions/68815764/what-architecture-do-block3-and-stack3-from-keras-applications-resnet-correspond)

### Correct links

[https://github.com/tensorflow/tensorflow/blob/b47b4139710fda407b56e1dc8de84b05779353e6/tensorflow/python/keras/applications/resnet.py#L345-L436](https://github.com/tensorflow/tensorflow/blob/b47b4139710fda407b56e1dc8de84b05779353e6/tensorflow/python/keras/applications/resnet.py#L345-L436)
"
51549,Layer_by_layer Boosting Tree,"<emThe issue related to the performance of the [BoostedTree classifier](https://github.com/tensorflow/estimator/blob/781c0d30c6bf100aa174591dd97cb70fc39d294d/tensorflow_estimator/python/estimator/canned/boosted_trees_test.py#L403) in terms of accuracy.</em>

**System information**

- OS Platform and Distribution: Linux Ubuntu 16.04, Windows 10
- TensorFlow installed from (source or binary): pip install TensorFlow
- TensorFlow version (use command below): 2.4.1
- Python version: 3.6

** Describe the model**
BoostedTree classifier is a model introduced by [N Ponomareva, T Colthurst, G Hendry.2017](https://ieeexplore.ieee.org/abstract/document/8257910).
It is built over the Xgboost idea and learning is done through building one layer of decision tree regressor over N boosting iteration.

**Describe the current behavior**
Build one tree for each boosting epoch

**Describe the expected behavior**
As mentioned in its paper, I want to build one tree for all Gradient Boosting Ensemble, and each boosting iteration would be layers of one tree.

**Standalone code to reproduce the issue**
You may find an example of the model, [here](https://www.tensorflow.org/tutorials/estimator/boosted_trees_model_understanding)"
51548, how to get the middle layer of tflite model with c++ API,"I want to know how to get the middle layer of tflite model with c++ API
i find some information in https://github.com/tensorflow/tensorflow/issues/49129, but it present with python
then I use the PreserveAllTensorsExperimental() of interpreterbuilder and interpreter->tensor() to extract middle layer tensor, but the tensor which i got is null, so how to do this correct with c++ API ?

"
51547,Initializing TFLite model causes crash on iOS,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0

**Describe the current behavior**
The model only has a preprocessing layer, being converted and tested to run successfully in Python environment. But when initializing this model on iOS project, it causes a crash on this side.

**Describe the expected behavior**
Expected to initialize and run successfully on iOS project.

**Standalone code to reproduce the issue**
Use the `get_mel_spectrogram()` function from kapre, [here](https://github.com/keunwoochoi/kapre/blob/ff6fe77cda572ee8eac4f35502925b62a84e491d/kapre/composed.py#L138), to create a custom mel-spectrogram layer in Tensorflow, then, convert to TFLite. 

Both the conversion and inference process run successfully in the Python environment but fail when initializing this model on the iOS project. The iOS project is mainly based on this [Tensorflow iOS tutorial](https://github.com/tensorflow/examples/tree/master/lite/examples/sound_classification/ios).

For convenience, the TFLite model is [here](https://drive.google.com/file/d/1BQt8Yi0H-WouBm48NYh_r78zrSfG0Oif/view?usp=sharing)

**Other info / logs** Log of the crash on iOS:
```
Exception Type:  EXC_BAD_ACCESS (SIGSEGV)
Exception Subtype: KERN_INVALID_ADDRESS at 0xd4000000010691ad
VM Region Info: 0xd4000000010691ad is not in any region.  Bytes after previous region: 15276209455021593006  
      REGION TYPE                 START - END      [ VSIZE] PRT/MAX SHRMOD  REGION DETAIL
      commpage (reserved)     1000000000-7000000000 [384.0G] ---/--- SM=NUL  ...(unallocated)
--->  
      UNUSED SPACE AT END
Termination Signal: Segmentation fault: 11
Termination Reason: Namespace SIGNAL, Code 0xb
Terminating Process: exc handler [3629]
Triggered by Thread:  0
Thread 0 name:  Dispatch queue: com.apple.main-thread
Thread 0 Crashed:
0   MyApp                   0x0000000105eca898 0x10293c000 + 56158360
1   MyApp                   0x0000000105eca884 0x10293c000 + 56158340
2   MyApp                   0x0000000105ec8fc0 0x10293c000 + 56152000
3   MyApp                   0x0000000105eca670 0x10293c000 + 56157808
4   MyApp                   0x0000000105ec4054 0x10293c000 + 56131668
5   MyApp                   0x0000000106138eb0 0x10293c000 + 58707632
6   MyApp                   0x00000001066a698c 0x10293c000 + 64399756
7   MyApp                   0x000000010677f398 0x10293c000 + 65287064
8   MyApp                   0x00000001068d7c54 0x10293c000 + 66698324
9   MyApp                   0x00000001068d850c 0x10293c000 + 66700556
10  MyApp                   0x0000000106748880 0x10293c000 + 65063040
11  MyApp                   0x0000000106748760 0x10293c000 + 65062752
12  MyApp                   0x0000000106679834 0x10293c000 + 64215092
13  MyApp                   0x00000001066791dc 0x10293c000 + 64213468
14  MyApp                   0x0000000106675c30 0x10293c000 + 64199728
15  MyApp                   0x0000000106675828 0x10293c000 + 64198696
16  MyApp                   0x000000010665df2c 0x10293c000 + 64102188
17  MyApp                   0x000000010665f35c 0x10293c000 + 64107356
18  UIKitCore                       0x00000001b5e3b27c 0x1b5308000 + 11743868
19  UIKitCore                       0x00000001b57d0254 0x1b5308000 + 5014100
20  UIKitCore                       0x00000001b57d0598 0x1b5308000 + 5014936
21  UIKitCore                       0x00000001b57ceed0 0x1b5308000 + 5009104
22  UIKitCore                       0x00000001b5e75f8c 0x1b5308000 + 11984780
23  UIKitCore                       0x00000001b5e778b4 0x1b5308000 + 11991220
24  UIKitCore                       0x00000001b5e52e50 0x1b5308000 + 11841104
25  UIKitCore                       0x00000001b5ed545c 0x1b5308000 + 12375132
26  UIKitCore                       0x00000001b5ed9bfc 0x1b5308000 + 12393468
27  UIKitCore                       0x00000001b5ed0ee0 0x1b5308000 + 12357344
28  CoreFoundation                  0x00000001b3551be0 0x1b34b7000 + 633824
29  CoreFoundation                  0x00000001b3551ae0 0x1b34b7000 + 633568
30  CoreFoundation                  0x00000001b3550e28 0x1b34b7000 + 630312
31  CoreFoundation                  0x00000001b354b3d0 0x1b34b7000 + 607184
32  CoreFoundation                  0x00000001b354ab90 0x1b34b7000 + 605072
33  GraphicsServices                0x00000001c986d598 0x1c986a000 + 13720
34  UIKitCore                       0x00000001b5e34638 0x1b5308000 + 11716152
35  UIKitCore                       0x00000001b5e39bb8 0x1b5308000 + 11738040
36  libswiftUIKit.dylib             0x00000001c6325b54 0x1c6312000 + 80724
37  MyApp                   0x000000010667101c 0x10293c000 + 64180252
38  MyApp                   0x0000000106670f94 0x10293c000 + 64180116
39  MyApp                   0x00000001066710b4 0x10293c000 + 64180404
40  libdyld.dylib                   0x00000001b3229588 0x1b3228000 + 5512
Thread 0 crashed with ARM Thread State (64-bit):
    x0: 0x000000016d4bf510   x1: 0x0000dc41303f3980   x2: 0x0000000000000003   x3: 0x0000000105eca83c
    x4: 0x000000016d4bfd68   x5: 0x000000016d4bfd60   x6: 0x0000000000000073   x7: 0x000000016d4bfad8
    x8: 0x34000000010691ad   x9: 0x00000002803c3980...
``` 
"
51546,metric_learning的损失函数如何应用在检索中，目前实现中都存在传labels给到度量损失函数,"https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/contrib/losses/python/metric_learning/metric_loss_ops_test.py
"
51545,"TFlite GPU Delegate Use input and output ssbo at the same time,the result is error.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): android ndk 21c
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 1.15
- Device: qcom snapdragon 855

My code step:
imread -> texture -> ssbo1 ->tflite ->ssbo2
I test ssbo1,the input ssbo1 is ok.
```
 glActiveTexture(GL_TEXTURE0);
  glBindTexture(GL_TEXTURE_2D, uInput);
  glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 256, 256, 0, GL_RGB, GL_FLOAT, data);

  glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, input_buffer);
  glUniform1i(2, 256);
  glUniform1i(3, 256);
  glDispatchCompute(32, 32, 1);
  glMemoryBarrier(GL_SHADER_STORAGE_BARRIER_BIT);
  auto outData = glMapBufferRange(GL_SHADER_STORAGE_BUFFER, 0, 256*256*12, GL_MAP_READ_BIT);
```


ssbo2 return error.
`coef 0,1,2,3:0.59072,0.842416,0.85824,0.454508`

When I don't use input ssbo:
imread ->tflite ->ssbo
the result is OK.
`coef 0,1,2,3:0.198929,0.524968,0.660745,0.634005`

Can I bind input and output ssbo at the same time?
Here is my c++ code.
```
  TfLiteDelegate* gpuDelegate = TfLiteGpuDelegateCreate(&options);
  std::cout<<""set output buffer handle""<<std::endl;
  interpreter->SetAllowBufferHandleOutput(true);
  // The buffer must be bound before the delegate is installed.
  std::cout<<""set tensor bind""<<std::endl;
  //just like bindBufferBase?
  TfLiteGpuDelegateBindBufferToTensor(gpuDelegate,input_buffer,interpreter->inputs()[0]);
  TfLiteGpuDelegateBindBufferToTensor(gpuDelegate,output_buffer,interpreter->outputs()[0]);
  std::cout<<""modify delegate""<<std::endl;
  if(interpreter->ModifyGraphWithDelegate(gpuDelegate) != kTfLiteOk){
    return;
  }

glUniform1i(2, 256);
glUniform1i(3, 256);
//texture to ssbo 
glBindBufferBase(GL_SHADER_STORAGE_BUFFER, 0, input_buffer);
glDispatchCompute(32, 32, 1);

glMemoryBarrier(GL_SHADER_STORAGE_BARRIER_BIT);
 // Run inference; the null input argument indicates use of the bound buffer for input.
 if (interpreter->Invoke() != kTfLiteOk) return;
 glMemoryBarrier(GL_SHADER_STORAGE_BARRIER_BIT);
```
It seems like the input_buffer ssbo data is not put into the tflite model,how can I use it?
Thanks!
"
51543,ios demo app version error,"hi, I want to build an object detection ios demo app using tflite model.
but your code support ios14.4, my ios is 14.6.
Apple doesn't assign ios to downgrade 14.6 to14.4.
so did you upgrade for ios 14.6?? 

thanks,"
51541,training accuracy different from history object,"Hi , I am dealing with a problem on the accuracy history.
As you can see, during training, we have:

```
Epoch 1/10
597/597 [==============================] - 4s 3ms/step - loss: 0.6822 - accuracy: 0.7007 - val_loss: 0.6607 - val_accuracy: 0.9228
Epoch 2/10
597/597 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.7838 - val_loss: 0.6463 - val_accuracy: 0.9228
Epoch 3/10
597/597 [==============================] - 1s 2ms/step - loss: 0.6537 - accuracy: 0.8284 - val_loss: 0.6329 - val_accuracy: 0.9228
Epoch 4/10
597/597 [==============================] - 2s 3ms/step - loss: 0.6408 - accuracy: 0.8598 - val_loss: 0.6204 - val_accuracy: 0.9228
Epoch 5/10
597/597 [==============================] - 1s 2ms/step - loss: 0.6287 - accuracy: 0.8876 - val_loss: 0.6087 - val_accuracy: 0.9228
Epoch 6/10
597/597 [==============================] - 1s 2ms/step - loss: 0.6174 - accuracy: 0.9024 - val_loss: 0.5978 - val_accuracy: 0.9228
Epoch 7/10
597/597 [==============================] - 1s 2ms/step - loss: 0.6068 - accuracy: 0.9103 - val_loss: 0.5875 - val_accuracy: 0.9228
Epoch 8/10
597/597 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.9146 - val_loss: 0.5779 - val_accuracy: 0.9228
Epoch 9/10
597/597 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.9146 - val_loss: 0.5688 - val_accuracy: 0.9228
Epoch 10/10
597/597 [==============================] - 1s 2ms/step - loss: 0.5785 - accuracy: 0.9146 - val_loss: 0.5603 - val_accuracy: 0.9228
```

So, accuracy reaches 0.9146.

But, If you see the accuracy values in the history:

```
history.history['accuracy']

[0.7472780346870422,
 0.7945979833602905,
 0.8073701858520508,
 0.8146985173225403,
 0.82097989320755,
 0.8243299722671509,
 0.8255862593650818,
 0.8262144327163696,
 0.8262144327163696,
 0.8262144327163696]
```


are different!

Code:

```
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, LSTM, \
    Bidirectional, RepeatVector
from tensorflow.keras import Sequential

X_train = np.load('./X_train.npy')
X_val = np.load('./X_val.npy')
y_train = np.load('./y_train.npy')
y_val = np.load('./y_val.npy')


model = Sequential()
model.add(Bidirectional(LSTM(2,
                        return_sequences=False,
                        activation='tanh',
                    input_shape=(12,
                                 10))))
model.add(RepeatVector(8))
# Decoder
model.add((LSTM(4,
                activation='tanh',
                return_sequences=True)))

model.add((Dense(1, activation='sigmoid')))
                    
model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.0001), 
              loss='binary_crossentropy',
              metrics=['accuracy'])

epochs = 10
batch_size = 1

history = model.fit(
    X_train,
    y_train, 
    validation_data = (X_val, y_val),
    steps_per_epoch=int(len(X_train) / batch_size),
    validation_steps=int(len(X_val) / batch_size),
    epochs=epochs,
    batch_size=batch_size,
    shuffle=False)


fig, axes = plt.subplots(figsize=(20, 12))
axes.plot(history.epoch, history.history['accuracy'], label = 'Train acc')
axes.plot(history.epoch, history.history['val_accuracy'], label = 'Val acc')
axes.legend()
```

You can download data [here](https://easyupload.io/m/5iv09z)



<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
You can see it at the end

**Describe the current behavior**

 Different training accuracy results between history object and history when printing on screen

**Describe the expected behavior**
 We should have the same results!

**Standalone code to reproduce the issue**
At the beginning



                  **System Info**
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

== check python ===================================================
python version: 3.8.10
python branch: 
python build version: ('default', 'Jun  2 2021 10:49:15')
python compiler version: GCC 9.4.0
python implementation: CPython


== check os platform ===============================================

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
protobuf                3.6.1               

== check for virtualenv =========================================
False


== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Wed Aug 18 09:48:39 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 1650    On   | 00000000:01:00.0  On |                  N/A |
| 24%   37C    P8    10W /  90W |   1096MiB /  3907MiB |      9%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1085      G   /usr/lib/xorg/Xorg                275MiB |
|    0   N/A  N/A      1727      G   cinnamon                           74MiB |
|    0   N/A  N/A      3228      G   ...AAAAAAAAA= --shared-files       30MiB |
|    0   N/A  N/A      3715      G   /usr/lib/firefox/firefox          125MiB |
|    0   N/A  N/A      3834      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A      4004      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A      4518      G   ...onda3/envs/dpl/bin/python        1MiB |
|    0   N/A  N/A      4593      C   ...onda3/envs/dpl/bin/python      577MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 8, 10, 'final', 0)

== bazel version  ===============================================

== check python ===================================================
python version: 3.8.8
python branch: 
python build version: ('default', 'Feb 24 2021 21:46:12')
python compiler version: GCC 7.3.0
python implementation: CPython


== check os platform ===============================================

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
neptune-tensorflow-keras          0.9.1
numpy                             1.19.2
numpydoc                          1.1.0
protobuf                          3.14.0
tensorflow                        2.4.1
tensorflow-datasets               1.2.0
tensorflow-estimator              2.4.0
tensorflow-metadata               0.14.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.4.1
tf.version.GIT_VERSION = unknown
tf.version.COMPILER_VERSION = 5.4.0
      8883:	find library=libpthread.so.0 [0]; searching

== nvidia-smi ===================================================
Wed Aug 18 09:49:20 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 1650    On   | 00000000:01:00.0  On |                  N/A |
| 24%   36C    P8    10W /  90W |   1107MiB /  3907MiB |      6%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1085      G   /usr/lib/xorg/Xorg                284MiB |
|    0   N/A  N/A      1727      G   cinnamon                           77MiB |
|    0   N/A  N/A      3228      G   ...AAAAAAAAA= --shared-files       30MiB |
|    0   N/A  N/A      3715      G   /usr/lib/firefox/firefox          125MiB |
|    0   N/A  N/A      3834      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A      4004      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A      4518      G   ...onda3/envs/dpl/bin/python        1MiB |
|    0   N/A  N/A      4593      C   ...onda3/envs/dpl/bin/python      577MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.4.1
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/ggousios/miniconda3/envs/dpl/lib/python3.8/site-packages
Required-by: neptune-tensorflow-keras, neptune-tensorboard

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 8, 8, 'final', 0)

== bazel version  ==============================================="
51539,Cannot convert models to tensorflowjs from tf hub by url,"I am using tensorflowjs_converter to convert a tflite model to tensorflowjs model.
The repository can be download with web browsers but failed when using tensorflowjs_converter.
I just redo the ```pip install tensorflowjs``` to make sure that I am in the latest version.

```
tensorflowjs_converter --input_format=tf_hub 'https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/dr/predict/1' ./web_model
```

It outputs an Http 404 but my connection is fine. When I run the example code it works fine and I downloaded it.
```
tensorflowjs_converter --input_format=tf_hub 'https://tfhub.dev/google/imagenet/mobilenet_v1_100_224/classification/1' ./web_model  
```

If you can tell me the reason or you can successfully convert tflite model from the following URLs, I will appreciate it a lot. Thank you so much. 

https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/dr/predict/1

https://tfhub.dev/sayakpaul/lite-model/cartoongan/dr/1
"
51536,"Support compression type ""SNAPPY"" in Tensorflow Python API","**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
From https://www.tensorflow.org/api_docs/python/tf/io/TFRecordOptions?hl=en, it does not appear that TensorFlow (up till v2.6.0) supports ""SNAPPY"" as a compression type in the Python API. However, in c++ source code https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/io/record_writer.h#L44, this is already supported. For my use case, ""SNAPPY"" is preferred over ""ZLIB"" or ""GZIP"". Therefore, having ""SNAPPY"" as an option in Python TFRecord API is a desirable feature.

**Will this change the current api? How?**
Yes. The `compression_type` field of TFRecordOptions will have valid values of ""GZIP"", ""ZLIB"", ""SNAPPY""(new) or """" (no compression).

**Who will benefit with this feature?**
Users who want to use snappy as their compression algorithm in order to take advantage of its speed.

**Any Other info.**

"
51535,Internal error: Tried to take gradients (or similar) of a variable without handle data ,"I am finetuning BERT for a binary sentiment analysis class using Tensorflow. I want to use a custom training loop to implement a custom loss function. However, when I try to train the model I get the following error: ValueError: Internal error: Tried to take gradients (or similar) of a variable without handle data: Tensor(""transformer_encoder/StatefulPartitionedCall:1019"", shape=(), dtype=resource).

To debug, I tried simplifying my training loop to just compute standard binary cross entropy, which should be equivalent to if I called model.fit() with binary cross entropy as the loss function (which works completely fine). However, I get the same error as above when running this simplified training loop and I am not sure what's causing it. Note: I am using tensorflow 2.3.0.

Here is the model:
```
def create_model():
  max_seq_length = 512
  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,
                                        name=""input_word_ids"")
  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,
                                     name=""input_mask"")
  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,
                                      name=""input_type_ids"")
  
  bert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2"", trainable=True)
  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])
  drop = tf.keras.layers.Dropout(0.3)(pooled_output)
  output = tf.keras.layers.Dense(1, activation='sigmoid', name=""output"")(drop)

  model = tf.keras.Model(
      inputs={
          'input_word_ids': input_word_ids,
          'input_mask': input_mask,
          'input_type_ids': input_type_ids
      },
      outputs= output 
  )

  return model
```
Here is the training loop function. The issue seems to come up when running ypred = model(train_x) inside tf.GradientTape():
```
def train_step(train_batch):
  train_x, train_y = train_batch
  with tf.GradientTape() as tape:
    ypred = model(train_x, training=True)
    loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(train_y, ypred))
  grads = tape.gradient(loss, model.trainable_weights)
  optimizer.apply_gradients(zip(grads, model.trainable_weights))
  return loss
```
Again, this seems to only happen with tf.GradientTape(), since model.fit() does not result in any issues.
```
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),
          loss=tf.keras.losses.BinaryCrossentropy(),
          metrics=[tf.keras.metrics.BinaryAccuracy()])

model.fit(train_data,
          validation_data=valid_data,
          epochs=epochs,
          verbose=1)
```"
51534, tf.GradientTape.gradients() does not support graph control flow operations,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
51532,"tf.print() mixes up the keys and values in a nested dictionary, leading to incorrect representation of the object content","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): pip binary
- TensorFlow version (use command below): 2.6.0
- Python version: 3.7.11
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

tf.print mixes up the order of dictionary keys and values when printing a dict which is nested inside a namedtuple. See example below, tf.print claims that the key 'a' has the value 2, when in fact it has the value 1.

**Describe the expected behavior**

tf.print represents the content of the object correctly.

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/Andreas5739738/d8abda0605692c3a37c28ba94da510d6/notebook.ipynb
```
import tensorflow as tf
from collections import namedtuple

# create a dict inside a namedtuple
X = namedtuple('X', ['x', 'y'])
data = X(x=tf.constant([0]), y={'b': tf.constant([2]), 'a': tf.constant([1])})

dataset = tf.data.Dataset.from_tensor_slices(data)
output_item = list(dataset)[0]

print(f'Actual tensor content:\n{output_item}\n')

print('tf.print mixes up the order of the keys and values in the dict:')
tf.print(output_item)
```
Output:
```
Actual tensor content:
X(x=<tf.Tensor: shape=(), dtype=int32, numpy=0>, y={'b': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'a': <tf.Tensor: shape=(), dtype=int32, numpy=1>})

tf.print mixes up the order of the keys and values in the dict:
X(x=0, y={'b': 1, 'a': 2})
```

"
51529, TensorRT 6.0 is linking to TensorRT 8.0.1.,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue: https://www.tensorflow.org/install/gpu#software_requirements


Please provide a link to the documentation entry, for example: https://www.tensorflow.org/install/gpu#software_requirements

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
51528,`tf.GradientTape.batch_jacobian` fails when slicing tensor with `int64` index,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.1.0
- GPU model and memory: NVIDIA GeForce RTX 2080 Ti

**Describe the current behavior**
If the target tensor of `batch_jacobian` is repeated and then sliced using an `int64` index, `batch_jacobian` fails due to concatenating shape vectors of different types. This can happen when `tf.RaggedTensor` is involved in calculation because `tf.RaggedTensor.row_lengths` returns an `int64` tensor.

The cause seems to be that `ops\parallel_for\pfor.py:2474` concatenates the batch size and the operation shape without checking the types. The batch size is retrieved at `eager\backprop.py:1293` as an `int32` value, so when the operation involves `int64` indices, it results in an error.

**Describe the expected behavior**
It should succeed whatever type is used to slice a tensor.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

x = tf.RaggedTensor.from_row_lengths([[1.0], [2.0], [3.0]], [1, 2])
length = x.row_lengths();
# length = tf.cast(length, tf.int32)
print('Type of length is', length.dtype)
x = x.to_tensor()
with tf.GradientTape() as tape:
    tape.watch(x)
    y = tf.repeat(x, [2], axis=1)
    y = y[:, :tf.math.reduce_max(length), :]
g = tape.batch_jacobian(y, x)
print('g =', g)
```
Running the code results in `TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, int64] that don't all match.`
If I uncomment line 5 it runs correctly.
If I comment out the `tf.repeat` line it also runs correctly."
51526,CUDA information inconsistent in PyPI (and missing in release notes),"@jvishnuvardhan, #43712 is not solved, unfortunately: it is still hard to find out which CUDA version has been used to build TensorFlow pip packages.

- Good: v2.5 release notes list ""CUDA11.2 and cuDNN 8.1.0"":
https://github.com/tensorflow/tensorflow/releases/tag/v2.5.0

- Bad: v2.6 release notes don't mention any CUDA/CuDNN information at all:
https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0

One might assume that v2.6 uses the same CUDA 11.2 as v2.5 if release notes don't report any change. (Still, it would be hard to find that information a few releases from now.)

PyPI might be a good source for this type of information. However:

- While PyPI lists ""GPU :: NVIDIA CUDA :: 11.2"" for `tf-nightly`, it lists ""GPU :: NVIDIA CUDA :: 11.0"" for `tensorflow` v2.6 (and v2.5):
https://pypi.org/project/tf-nightly/2.7.0.dev20210815/
https://pypi.org/project/tensorflow/2.6.0/

"
51525,"make_early_stopping_hook will always return _MultiWorkerEarlyStoppingHook, no matter what strategy is used","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): v2.2 ~ v2.6
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

make_early_stopping_hook will always return _MultiWorkerEarlyStoppingHook, no matter what strategy is used.( since TF2.2)

There is a bug in this line of code(early_stopping.py#L86), because the second condition is an array with two elements, which must be True, which means that this IF judgment is always True, so it will always return _MultiWorkerEarlyStoppingHook
``` python
train_distribute = estimator.config.train_distribute
mwms = ['CollectiveAllReduceStrategy', 'MultiWorkerMirroredStrategy']
if train_distribute and (train_distribute.__class__.__name__.startswith(
    strategy) for strategy in mwms): # <--- bug here. [False, False] will be considered TRUE.
  if run_every_secs:
    raise ValueError('run_every_secs should not be set when using '
                     'MultiWorkerMirroredStrategy.')
  return _MultiWorkerEarlyStoppingHook(should_stop_fn, run_every_steps)

if estimator.config.is_chief:
  return _StopOnPredicateHook(should_stop_fn, run_every_secs, run_every_steps)
else:
  return _CheckForStoppingHook()
```

https://github.com/tensorflow/estimator/blob/r2.6/tensorflow_estimator/python/estimator/early_stopping.py#L86

**Describe the expected behavior**

make_early_stopping_hook should return the correct hook according to the strategy"
51523,How to fuse tensors of two different dimensions?,"env：tf2.2

I have two sets of tensors. I want them to merge together as a new input. Which method should I use?

tensor 1：from bert-encoder-hidden: (batch_size, max_len, 768)
tensor 2:   from tensor 1 through tf.Gather(tensor1, position, batch_dim=1): (batch_size, 768)

Tensor 2 is the position tensor extracted from tensor 1 through TF. Gather() method. Now I want to integrate tensor 2 into tensor 1. What should I do?"
51522,resnet50.onnx --> tflite Convert Error,"### 1. System information
pip3 install tensorflow-gpu==2.4.0
pip3 install tensorflow-addons==0.13.0
onnx == 1.7.0

onnx model link (https://github.com/onnx/models/blob/master/vision/classification/resnet/model/resnet50-v1-7.onnx)

Our model uses backbone as Resnet-50.
The error occurred in our model, so even if we downloaded the official onnx model and converted it, it shows the same result.
In 2.2.0 and 2.3.0, the conversion is good.
And I have to use version 2.4.0.

If converter.allow_custom_ops is True, it is converted, but eventually problems occur at runtime.

### 2. Code

Provide code to help us reproduce your issues using one of the following options:
# onnx --> pb
onnx_model = onnx.load(""./resnet50-v1-7.onnx"")
tf_model_path = ""./saved_model""
tf_rep = prepare(onnx_model)
tf_rep.export_graph(tf_model_path)

# pb --> tflite
converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)
tflite_model = converter.convert()
tflite_model_path = ""./onnx_backbone/tf_2.4.0/tflite/backbone_v9_default.tflite""
with open(tflite_model_path, 'wb') as f:
    f.write(tflite_model)


```
(You can paste links or attach files by dragging & dropping them below)
- Provide links to your updated versions of the above two colab notebooks.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
(You can paste links or attach files by dragging & dropping them below)
- Include code to invoke the TFLite Converter Python API and the errors.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

### 3. Failure after conversion
In 2.4.0, the following error occurs:

loc(callsite(callsite(""MaxPool2d@__inference___call___1278"" at ""PartitionedCall@__inference_signature_wrapper_1497"") at ""PartitionedCall"")): error: 'tf.MaxPool' op is neither a custom op nor a flex op
error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.MaxPool {data_format = ""NCHW"", device = """", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = ""VALID"", strides = [1, 1, 2, 2]}
Traceback (most recent call last):
  File ""/workspace/venv/tensorflow2_4/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 213, in toco_convert_protos
    enable_mlir_converter)
  File ""/workspace/venv/tensorflow2_4/lib/python3.6/site-packages/tensorflow/lite/python/wrap_toco.py"", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(callsite(callsite(""MaxPool2d@__inference___call___1278"" at ""PartitionedCall@__inference_signature_wrapper_1497"") at ""PartitionedCall"")): 'tf.MaxPool' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""PartitionedCall""): called from
<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.MaxPool {data_format = ""NCHW"", device = """", explicit_paddings = [], ksize = [1, 1, 3, 3], padding = ""VALID"", strides = [1, 1, 2, 2]}
"
51521,"libcudnn_adv_train.so not found when using LSTM, unless I run a BatchNorm before","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7.9.2009
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): GCC 9.3.0
- CUDA/cuDNN version: CUDA 11.1, cuDNN 8.2
- GPU model and memory: NVidia V100 16GB

**Describe the current behavior**

Please note that I have CUDA and cuDNN installed in custom directories. This causes problems in dynamically loading cuDNN libs. (To be able to use TF with custom CUDA/cuDNN paths, I had to patch the built wheel, by setting RPATHs on the `*.so` inside the wheel)

When running an LSTM (see repro code below), I get this error:
```
Could not load library libcudnn_adv_train.so.8. Error: libcudnn_ops_train.so.8: cannot open shared object file: No such file or directory
Please make sure libcudnn_adv_train.so.8 is in your library path!
Aborted (core dumped)
```
However, if I execute a BatchNorm layer right before, there is no error and I can use the LSTM. This is because, using BatchNorm triggers the load of `libcudnn_ops_train.so.8`, which works this way.

**Describe the expected behavior**

LSTM should work.

Maybe `libcudnn_ops_train.so.8` should be manually loaded by TF ?

I also expect not having the patch the wheel. If I set CUDA/cuDNN paths when configuring the build, why won't TF use these paths?

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

# If I uncomment this, there is no crash.
# bn = tf.keras.layers.BatchNormalization()
# inputs = tf.random.normal([32, 10, 8, 8])
# output = bn(inputs)

inputs = tf.random.normal([32, 10, 8])
lstm = tf.keras.layers.LSTM(4)
output = lstm(inputs)
```
"
51519,Question about custom convolution layer,"Hi,

**Question**
Is it possible to make a custom convolution layer by scratch?
Can you tell me how to do it?

**What I'm thinking**
I am thinking to create a custom convolution layer that works like tf.keras.layers.Conv2D.
I still don't have codes but it will work like FIR filter.
Basic FIR filter could be implemented by Conv2D or Conv1D but the layer I want can't be, because it'll has some process that Conv2D and Conv1D don't have.
 
If I try to implement by tf.keras.layers.Layer, I need to have some for-loops or while-loops. 
And the loops will make the computation slow and consume a lot of GPU memory.


"
51517,Time Series Documentation Doesn't Display on Chrome,"


## URL(s) with the issue:

https://www.tensorflow.org/tutorials/structured_data/time_series#the_weather_dataset

## Description of issue (what needs changing):

In Chrome, the weather dataset table only shows a portion of the table.



ALSO, I have been struggling to learn from this documentation. It would be MUCH easier to learn if there were at least one complete script (preferably one per section) in a single code block. For example. It would be much easier to understand if I could see a code block that had everything needed to train and test a Single-Step and Multi-Step model

Also Also, it would help if all the variable's names were consistent with the diagrams and their purpose was described in text i.e.
 [https://www.tensorflow.org/tutorials/structured_data/time_series#multi-step_dense](CONV_WIDTH) is not described and it's purpose can only be guessed at from the diagram.

### Request visuals, if applicable
<img width=""951"" alt=""ZR61xt1sYW"" src=""https://user-images.githubusercontent.com/52757442/129586646-f7ae0920-2dfd-4f91-8ab8-26db833d1371.png"">
"
51515,Tensorflow 2.4: where is tf.contrib.layers.fully_connected?,"How can I replace tf.contrib.layers.fully_connected of tensorflow 1.x with a similar function in 2.4?

Got the following error:
    import tensorflow.contrib.layers as layers
ModuleNotFoundError: No module named 'tensorflow.contrib'"
51514,Links lead to 404 on food101 dataset page ,"## Whats Wrong?
The link of Homepage of Food101 on the Food101 page of the catalog section of tensorflow datasets doesnt work.
Link of the page: https://www.tensorflow.org/datasets/catalog/food101


### Description

The link given for the Homepage of the Food-101 doesn't work
![image](https://user-images.githubusercontent.com/43718923/129578159-57c489d4-b98b-47bc-930c-c993ee2a9999.png)

It leads to a 404 Page not found
![image](https://user-images.githubusercontent.com/43718923/129578246-4b2680d0-d519-4885-8135-edc51133f202.png)



### Correct links

Link to the correct paper: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/


### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
51512,I want to know Is it supported that the C_API can use the Core ML delegate? ,"
**System information**
- MacOS11.2 Compile the C_API for IOS 12


**Describe the problem**
I want to know Is it supported that the C_API can use the Core ML delegate? 
What I can learn about the Doc is CoreML only compiled as Framework not a static library. Now I have a project used the tf-lite with C API, And.I want to know whether it can use the CoreML delegate with C API . So that I don't need change the export way (just give a dynamic library out) to the caller . 

"
51510,How to get a coarse-grained op-level graph in tensorflow,"Hi, tensorflow community,
I want to use tensorflow to get the full computation graph (including forward, backward and parameter update). I tried tf.functions, but the graph I got is too fine-grained, as many ops (Adam for example) are splited into smaller operators (add, mul, div etc.). So is there any methods that I can get a coarse-grained op-level graph? Thanks a lot!

Jiangfei"
51509,Can't create multiple instances of tf.keras.Model subclasses,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.
- TensorFlow installed from (source or binary): pip install.
- TensorFlow version (use command below): v2.6.0-rc2-32-g919f693420e 2.6.0.
- Python version: 3.9.6.
- Bazel version (if compiling from source): NA.
- GCC/Compiler version (if compiling from source): NA.
- CUDA/cuDNN version: NA.
- GPU model and memory: GTX 2080 Ti.

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Here is an example of triggering the issue:
```python
import tensorflow as tf

class MyModel(tf.keras.Model):

  def __init__(self, input_shape):
    super(MyModel, self).__init__()
    self.my_model_input_shape = input_shape
    self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.relu)
    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)
    input_layer = tf.keras.layers.Input(self.my_model_input_shape)
    output_layer = self.call(input_layer)
    super(MyModel, self).__init__(
      inputs=input_layer,
      outputs=output_layer
    )

  def call(self, inputs, training=None):
    x = self.dense1(inputs)
    return self.dense2(x) + x


model_1 = MyModel((10,))
model_1.summary()

model_2 = MyModel((20,))
model_2.summary()
```
It fails at the creation of `model_2` with
```
File "".../lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py"", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
TypeError: __init__() missing 2 required positional arguments: 'inputs' and 'outputs'
```

Without the the second 2-param `super().__init__` call at the end of `MyModel.__init__`, it is OK to run, but the summary and `model_1.layers` outputs are different: the one with the second `__init__` call contains more and better information, such as the input and last addition layers and a `Connected to` columns:
```
Model: ""my_model_1""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 10)]         0                                            
__________________________________________________________________________________________________
dense (Dense)                   (None, 5)            55          input_1[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 5)            30          dense[0][0]                      
__________________________________________________________________________________________________
tf.__operators__.add (TFOpLambd (None, 5)            0           dense_1[0][0]                    
                                                                 dense[0][0]                      
==================================================================================================
Total params: 85
Trainable params: 85
Non-trainable params: 0
```
I would much prefer the one with better information. I learned this from various examples such as https://github.com/matterport/Mask_RCNN/issues/921#issuecomment-432846634.

**Describe the expected behavior**
Creating multiple instances of subclasses should have no issue and the variables and models should be independent from each other.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no.
- Briefly describe your candidate solution(if contributing): NA.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
See above.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51508,Use NNAPI to delegate model on DSP and how to I want to implement DSP zero-copy through Android Native Hardware Buffer,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

Now I‘m using NNAPI to delegate model on Qualcom DSP and I want to implement DSP zero-copy through Android Native Hardware Buffer and I want to know what should the values of the AHardwareBuffer_Format and  AHardwareBuffer_UsageFlags be.  Thanks a lot!

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
51506,Apple M1 - How to build 2.6 or Master (Fixed),"The genius command ""pip install tensorflow"" does not even work in Debian 11, so we have to compile from source. The instructions on the TF homepage do not work for the M1.

Has anyone compiled TF 2.6+ on the M1 and can share a guideline please ?"
51502,Could not find device for node (`reduce_max` of complex),"```python
tf.reduce_max(tf.constant([1 + 1j]))
```
[TF 2.5.0](https://anaconda.org/anaconda/tensorflow), Windows 10, Python 3.9.6.

<details>
  <summary><b>Error</b></summary>

```python
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\Anaconda\envs\tf25_env\lib\site-packages\tensorflow\python\util\dispatch.py"", line 206, in wrapper
    return target(*args, **kwargs)
  File ""D:\Anaconda\envs\tf25_env\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 2908, in reduce_max
    return reduce_max_with_dims(input_tensor, axis, keepdims, name,
  File ""D:\Anaconda\envs\tf25_env\lib\site-packages\tensorflow\python\ops\math_ops.py"", line 2920, in reduce_max_with_dims
    gen_math_ops._max(input_tensor, dims, keepdims, name=name))
  File ""D:\Anaconda\envs\tf25_env\lib\site-packages\tensorflow\python\ops\gen_math_ops.py"", line 5781, in _max
    _ops.raise_from_not_ok_status(e, name)
  File ""D:\Anaconda\envs\tf25_env\lib\site-packages\tensorflow\python\framework\ops.py"", line 6897, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of complex128 is not in the list of allowed values: float, double, int32, uint8, int16, int8, int64, bfloat16, uint16, half, uint32, uint64, qint8, quint8, qint32, qint16, quint16
        ; NodeDef: {{node Max}}; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, DT_INT8, DT_INT64, DT_BFLOAT16, DT_UINT16, DT_HALF, DT_UINT32, DT_UINT64, DT_QINT8, DT_QUINT8, DT_QINT32, DT_QINT16, DT_QUINT16]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Max]
```
</details>"
51501,Normalization and Quantization of inputs issue,"I have observed differences between the documentation and the example.
Reference - https://www.tensorflow.org/lite/convert/metadata#normalization_and_quantization_parameters
![tfliteinputnormalization](https://user-images.githubusercontent.com/47776253/129476236-f3d1dc4e-9202-4cf6-80ff-13d730870d50.JPG)

But in the example, I have found differences.

![Capturefgregtrgtr](https://user-images.githubusercontent.com/47776253/129476310-9b0f1b17-ae54-410a-82ff-2f334546e50a.JPG)

We are not doing normalization when input and output are int8 and uint8? why is that so?


![Capturesssssss](https://user-images.githubusercontent.com/47776253/129476426-ada45a4e-3624-46aa-842e-0868a154cc2b.JPG)

As per documentation, the output does not need normalization? why are we doing this in this example ?

In the example, we are not using any scale and zero point ? we are not using quantization params?
"
51500,TypeError: __array__() takes 1 positional argument but 2 were given,"https://colab.research.google.com/drive/1gfsLuugiqEgAbyj7P6_6trgiNaq1dAW2

I've tried downgrading Pillow to be 8.2.0 and 8.3.1 on my own machine, still not solving the problem,so it may be the tensorflow internal error.

Please teach me how to revise this code and let it run without bugs.

As I just paste the code onto the colab,I have no idea of the tf and python version, please help me check it."
51499,Apple M1 - tf.sort only sorts up to 16 values for float32,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Apple M1, macOS 11.5
- TensorFlow installed from (source or binary): Binary, following Apple's manual: https://developer.apple.com/metal/tensorflow-plugin/
- TensorFlow version (use command below): 2.5.0
- Python version: 3.9.6
- GPU model and memory: Apple M1

**Describe the current behavior**
```my_array``` is defined as a constant tensor with these values: 
```
<tf.Tensor: shape=(20,), dtype=float32, numpy=
array([0.39002007, 0.6232998 , 0.65246916, 0.51837456, 0.32046252,
       0.17287847, 0.1020941 , 0.05556634, 0.03855091, 0.04841335,
       0.08809784, 0.17805861, 0.29818463, 0.48202834, 0.63666624,
       0.68172085, 0.66695976, 0.64094126, 0.6494308 , 0.66173404],
      dtype=float32)>
```
```tf.sort(my_array)``` returns the following tensor:
```
<tf.Tensor: shape=(20,), dtype=float32, numpy=
array([ 0.03855091,  0.04841335,  0.05556634,  0.08809784,  0.1020941 ,
        0.17287847,  0.17805861,  0.29818463,  0.32046252,  0.39002007,
        0.48202834,  0.51837456,  0.6232998 ,  0.63666624,  0.64094126,
        0.6494308 , -0.        , -0.        , -0.        , -0.        ],
      dtype=float32)>
```
Only the first 16 elements are sorted. The same behavior occurs with argsort. When casting to float64 the error disappears. 

**Describe the expected behavior**

Sorting the whole tensor not just the first 16 values."
51495,AUC in the Classification on imbalanced data tutorial,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#check_training_history_2

## Description of issue (what needs changing):
In the documentation, the weighted model has the highest AUC, as shown below, but [the chart](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#plot_the_roc_3) shows that the baseline AUC is the highest. I think the AUC calculated by model.evaluate method may be incorrect.

>Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives.

```
# baseline
0.9296237826347351

# weighted
0.9428448677062988

# resampled
0.9575912952423096
```

The result of calculating the AUC using the sklearn.metrics.roc_auc_score method is as follows, as expected.
It can be confirmed that the AUC of the baseline is the highest.

```
baseline_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_baseline) 
weighted_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_weighted)  
resampled_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_resampled) 

# baseline
0.9685415795364084

# weighted
0.9387766618590307

# resampled
0.9665411665226982
```

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

After confirming this issue with other people, I will make a pull request.

"
51494,Apple M1 - TF Master - Build Error: Symbol not found,"**System information**
- OS Platform: Apple MacBook Pro - M1 - MacOS Monterey 12 Beta 5
- TensorFlow installed from (source or binary): Source
- TensorFlow version: Master
- Python version: 3.9.6
- Bazel version (if compiling from source): 3.7.2 using brew tap bazelbuild/tap




**Describe the problem**

Build string:

bazel build --config=v2 //tensorflow/tools/pip_package:build_pip_package


Build Error:

`WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/sqlite.org/2021/sqlite-amalgamation-3360000.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: /Users/XXX/tensorflow/tensorflow/python/BUILD:812:29: Executing genrule //tensorflow/python:spectral_ops_pygenrule failed (Aborted): bash failed: error executing command 
  (cd /private/var/tmp/_bazel_XXX/6fa7ea051f5393a8574f3349fa920010/execroot/org_tensorflow && \
  exec env - \
    PATH=/opt/homebrew/opt/bison/bin:/Users/XXX/miniforge3/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.9/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin \
    PYTHON_BIN_PATH=/opt/homebrew/opt/python@3.9/bin/python3.9 \
    PYTHON_LIB_PATH=/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash bazel-out/darwin-opt/bin/tensorflow/python/spectral_ops_pygenrule.genrule_script.sh)
Execution platform: @local_execution_config_platform//:platform
dyld[47884]: symbol not found in flat namespace '_ChaCha20_ctr32'`"
51493,No registered 'EagerPyFunc' OpKernel for XLA_GPU_JIT devices compatible with node {{node EagerPyFunc}}){{node EagerPyFunc}},"**tensorflow 2.6
ubuntu 18.10
python 3.6**

### The whole error message:

Traceback (most recent call last):
  File ""main_Semantic3D.py"", line 626, in <module>
    main1()
  File ""main_Semantic3D.py"", line 562, in main1
    model = Network(dataset, cfg)
  File ""/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py"", line 97, in __init__
    self.train( xyz_batch, color_batch)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 885, in __call__
    result = self._call(*args, **kwds)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 950, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3040, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1964, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 596, in call
    ctx=ctx)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
**tensorflow.python.framework.errors_impl.InvalidArgumentError: Detected unsupported operations when trying to compile graph __inference_train_8311[_XlaMustCompile=true,config_proto=""\n\007\n\0...02\001\000"",executor_type=""""] on XLA_GPU_JIT: EagerPyFunc (No registered 'EagerPyFunc' OpKernel for XLA_GPU_JIT devices compatible with node {{node EagerPyFunc}}){{node EagerPyFunc}}**
The op is created at: 
File ""main_Semantic3D.py"", line 626, in <module>
  main1()
File ""main_Semantic3D.py"", line 562, in main1
  model = Network(dataset, cfg)
File ""/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py"", line 97, in __init__
  self.train( xyz_batch, color_batch)
File ""/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py"", line 586, in train
  self.adjacency_sparse_batch, self.scaledLaplacian_sparse_batch = self.get_graph(xyz_batch,
File ""/home/sjtusmartboy/opt/Projects/RandLA-Net/Net.py"", line 176, in get_graph
  ret = tf.py_function(**DP.knn_search**, [xyz_batch, xyz_batch, cfg.k_n], [tf.int32, tf.float64]) [Op:__inference_train_8311]



---------------------------------------------------------------------------------------------------------------------


**knn_search is the wraper of an op, code is as follows,**


```
void cpp_knn_batch(const float* batch_data, const size_t batch_size, const size_t npts, const size_t dim,
			const float* queries, const size_t nqueries,
			const size_t K, long* batch_indices, float* batch_dist){

	for(size_t bid=0; bid < batch_size; bid++){

	    std::cout<<1111111111111<<std::endl;

		const float* points = &batch_data[bid*npts*dim];
		long* indices = &batch_indices[bid*nqueries*K];
		float* dist = &batch_dist[bid*nqueries*K];

		// create the kdtree
		typedef KDTreeTableAdaptor< float, float> KDTree;
		KDTree mat_index(npts, dim, points, 10);
		
		mat_index.index->buildIndex();

		std::vector<float> out_dists_sqr(K);
		std::vector<size_t> out_ids(K);

		// iterate over the points
		for(size_t i=0; i<nqueries; i++){
			nanoflann::KNNResultSet<float> resultSet(K);
			resultSet.init(&out_ids[0], &out_dists_sqr[0] );
			mat_index.index->findNeighbors(resultSet, &queries[bid*nqueries*dim + i*dim], nanoflann::SearchParams(10));
			for(size_t j=0; j<K; j++){
				indices[i*K+j] = long(out_ids[j]);
				dist[i*K+j] = float(out_dists_sqr[j]);

			}
		}

	}

}

void cpp_knn_batch_omp(const float* batch_data, const size_t batch_size, const size_t npts, const size_t dim, 
				const float* queries, const size_t nqueries,
				const size_t K, long* batch_indices, float* batch_dist){

# pragma omp parallel for
	for(size_t bid=0; bid < batch_size; bid++){

		const float* points = &batch_data[bid*npts*dim];
		long* indices = &batch_indices[bid*nqueries*K];
		float* dist = &batch_dist[bid*nqueries*K];

		// create the kdtree
		typedef KDTreeTableAdaptor< float, float> KDTree;
		KDTree mat_index(npts, dim, points, 10);
		
		mat_index.index->buildIndex();

		std::vector<float> out_dists_sqr(K);
		std::vector<size_t> out_ids(K);

		// iterate over the points
		for(size_t i=0; i<nqueries; i++){
			nanoflann::KNNResultSet<float> resultSet(K);
			resultSet.init(&out_ids[0], &out_dists_sqr[0] );
			mat_index.index->findNeighbors(resultSet, &queries[bid*nqueries*dim + i*dim], nanoflann::SearchParams(10));
			for(size_t j=0; j<K; j++){
				indices[i*K+j] = long(out_ids[j]);
				if(out_dists_sqr[j]>3.4028235e+37)
				    out_dists_sqr[j] = 0;
				dist[i*K+j] = sqrt(float(out_dists_sqr[j]));
// 				std::cout<<out_dists_sqr[j]<<std::endl;
			}
		}

	}

}
```

------------------------------------------------------------------------------------------------------------------------------------------------

So what causes the error, the **tf.py_function** is not compatible with the xla or the **c++ op** is not compatible with the xla? If the code is not decorated with     `@tf.function(autograph=True, jit_compile=True)`, the program runs well."
51492,Getting non-deterministic results on TF1.9,"Getting different results on different attempts of execution. 
I AM RUNNING IT ON CPU.
1. os.environ['TF_CUDNN_DETERMINISTIC']='1'
2. os.environ['HOROVOD_FUSION_THRESHOLD']='0'
The above 2 lines can be ignored for CPU execution.
Could anyone help me getting determinstic results?


```
import os

import numpy as np
import tensorflow as tf
from sklearn.metrics import precision_recall_fscore_support

import config
from data_helper import batch_index, load_word2id, load_y2id_id2y, load_word2vector, recover_data_from_files
from model.nn_layer import transition_layer, softmax_layer

import random

tf.set_random_seed(42)
np.random.seed(42)
os.environ['PYTHONHASHSEED']=str(42)
random.seed(42)

os.environ['TF_DETERMINISTIC_OPS'] = '1'
os.environ['TF_CUDNN_DETERMINISTIC']='1'
os.environ['HOROVOD_FUSION_THRESHOLD']='0'

class NetAbModel(object):
    def __init__(self, domain, flags, filter_list=(3, 4, 5), filter_num=100):
        self.config = flags
        self.filter_list = filter_list
        self.filter_num = filter_num
        # placeholder
        self.sen_x_batch = None
        self.sent_len_batch = None
        self.sen_y_batch = None
        self.keep_prob1 = None
        self.keep_prob2 = None
        # embedding
        self.add_placeholder()
        self.word2id = None
        # self.id2word = None
        self.vocab_size = None
        self.embedding = None
        inputs = self.add_embedding(domain)
        # model
        self.sen_logits, self.sen_logits2 = self.netAb(inputs)
        # noisy-loss
        self.loss = self.add_loss(self.sen_logits)
        self.accuracy, self.accuracy_num = self.add_accuracy(self.sen_logits)
        self.train_op = self.add_train_op(self.loss)
        # clean-loss
        self.loss2 = self.add_loss(self.sen_logits2)
        self.accuracy2, self.accuracy_num2 = self.add_accuracy(self.sen_logits2)
        self.train_op2 = self.add_train_op(self.loss2)

    def add_placeholder(self):
        self.sen_x_batch = tf.placeholder(tf.int32, [None, self.config.max_sentence_len])
        self.sent_len_batch = tf.placeholder(tf.int32, [None])
        self.sen_y_batch = tf.placeholder(tf.float32, [None, self.config.n_class])
        self.keep_prob1 = tf.placeholder(tf.float32)
        self.keep_prob2 = tf.placeholder(tf.float32)

    def add_embedding(self, domain):
        if self.config.pre_trained:
            self.word2id, w2v = load_word2vector(self.config.word2id_path, domain)
            # self.word2id, self.id2word, w2v = load_w2v_mongo(domain)
        else:
            self.word2id = load_word2id(self.config.word2id_path, domain)
            self.vocab_size = len(self.word2id)
            w2v = tf.random_uniform([self.vocab_size, self.config.embedding_dim], -1.0, 1.0, trainable=True, seed=42)
        if self.config.embedding_type == 'static':
            self.embedding = tf.constant(w2v, dtype=tf.float32, name='word_embedding')
        else:
            self.embedding = tf.Variable(w2v, dtype=tf.float32, name='word_embedding')
        inputs = tf.nn.embedding_lookup(self.embedding, self.sen_x_batch)
        return inputs

    def create_feed_dict(self, sen_x_batch, sent_len_batch, sen_y_batch, kp1=1.0, kp2=1.0):
        holder_list = [self.sen_x_batch, self.sent_len_batch, self.sen_y_batch,
                       self.keep_prob1, self.keep_prob2]
        feed_list = [sen_x_batch, sent_len_batch, sen_y_batch, kp1, kp2]
        return dict(zip(holder_list, feed_list))

    # cnn layer
    def add_cnn_layer(self, inputs, inputs_dim, max_len, scope_name='cnn'):
        inputs = tf.expand_dims(inputs, -1)
        pooling_outputs = []
        for i, filter_size in enumerate(self.filter_list):
            ksize = [filter_size, inputs_dim]
            conv = tf.contrib.layers.conv2d(inputs=inputs,
                                            num_outputs=self.filter_num,
                                            kernel_size=ksize,
                                            stride=1,
                                            padding='VALID',
                                            activation_fn=tf.nn.relu,
                                            scope='conv_' + scope_name + str(i))
            ksize = [max_len - filter_size + 1, 1]
            pooling = tf.contrib.layers.max_pool2d(inputs=conv,
                                                   kernel_size=ksize,
                                                   stride=1,
                                                   padding='VALID',
                                                   scope='pooling_' + scope_name)
            pooling_outputs.append(pooling)
        hiddens = tf.concat(pooling_outputs, 3)
        hiddens = tf.reshape(hiddens, [-1, self.filter_num * len(self.filter_list)])
        return hiddens

    # cnn layer
    def add_noisy_cnn_layer(self, inputs, inputs_dim, max_len, scope_name='cnn'):
        inputs = tf.expand_dims(inputs, -1)
        pooling_outputs = []
        for i, filter_size in enumerate(self.filter_list):
            ksize = [filter_size, inputs_dim]
            conv = tf.contrib.layers.conv2d(inputs=inputs,
                                            num_outputs=self.filter_num,
                                            kernel_size=ksize,
                                            stride=1,
                                            padding='VALID',
                                            activation_fn=tf.nn.relu,
                                            scope='conv_' + scope_name + str(i))
            ksize = [max_len - filter_size + 1, 1]
            pooling = tf.contrib.layers.max_pool2d(inputs=conv,
                                                   kernel_size=ksize,
                                                   stride=1,
                                                   padding='VALID',
                                                   scope='pooling_' + scope_name)
            pooling_outputs.append(pooling)
        hiddens = tf.concat(pooling_outputs, 3)
        hiddens = tf.reshape(hiddens, [-1, self.filter_num * len(self.filter_list)])
        return hiddens

    def netAb(self, inputs):
        print('Running NetAb...')
        inputs = tf.nn.dropout(inputs, keep_prob=self.keep_prob1, seed=42)
        inputs = tf.reshape(inputs, [-1, self.config.max_sentence_len, self.config.embedding_dim])
        # word-sentence: cnn
        outputs_sen = self.add_cnn_layer(inputs, self.config.embedding_dim, self.config.max_sentence_len, 'h')
        outputs_sen_dim = self.filter_num * len(self.filter_list)
        outputs_sen = tf.reshape(outputs_sen, [-1, outputs_sen_dim])
        noisy_cnn = self.add_noisy_cnn_layer(inputs, self.config.embedding_dim, self.config.max_sentence_len, 'u')
        noisy_cnn = tf.reshape(noisy_cnn, [-1, outputs_sen_dim])
        # fully-connection
        clean_logits = softmax_layer(outputs_sen, outputs_sen_dim, self.config.random_base, self.keep_prob2,
                                     self.config.l2_reg, self.config.n_class, 'sen_softmax')
        p1 = transition_layer(noisy_cnn, outputs_sen_dim, self.config.l2_reg, self.config.random_base, 'p1')
        p2 = transition_layer(noisy_cnn, outputs_sen_dim, self.config.l2_reg, self.config.random_base, 'p2')
        p1 = tf.expand_dims(p1, 2)
        p2 = tf.expand_dims(p2, 2)
        prob = tf.concat([p1, p2], 2)
        sen_logits = tf.expand_dims(clean_logits, 1)
        noisy_logits = tf.squeeze(tf.matmul(sen_logits, prob))
        return noisy_logits, clean_logits

    def add_loss(self, sen_logits):
        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=sen_logits, labels=self.sen_y_batch)
        self.sen_vars = [var for var in tf.global_variables()
                         if 'h' in var.name or 'u' in var.name or 'p1' in var.name or 'p2' in var.name]
        # print(self.sen_vars)
        reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope='sen_softmax')
        # print(reg_loss)
        loss = tf.reduce_mean(loss)  # TODO+ self.config.l1_reg * tf.add_n(reg_loss)
        return loss

    def add_accuracy(self, scores):
        correct_predicts = tf.equal(tf.argmax(scores, 1), tf.argmax(self.sen_y_batch, 1))
        accuracy_num = tf.reduce_sum(tf.cast(correct_predicts, tf.int32))  # the number of correct predicting docs
        accuracy = tf.reduce_mean(tf.cast(correct_predicts, tf.float32), name='accuracy')  # accuracy metric result
        return accuracy, accuracy_num

    def add_train_op(self, doc_loss):
        # new_learning_rate = current_learning_rate * decay_rate ^ (global_step / decay_steps)
        global_step = tf.Variable(0, name='global_step', trainable=False)  # record the current step (global step)
        self.lr = tf.train.exponential_decay(self.config.lr, global_step, self.config.decay_steps,
                                             self.config.decay_rate, staircase=True)
        # the optimizer used in this work
        # optimizer = tf.train.AdadeltaOptimizer(self.lr)
        optimizer = tf.train.AdamOptimizer(self.lr)
        grads, global_norm = tf.clip_by_global_norm(tf.gradients(doc_loss, self.sen_vars, gate_gradients=True), self.config.max_grad_norm)
        train_op = optimizer.apply_gradients(zip(grads, self.sen_vars), name='train_op', global_step=global_step)
        # train_op = optimizer.minimize(doc_loss, global_step=global_step, var_list=self.doc_vars)
        return train_op

    def run_op(self, sess, op, sen_x, sen_len, sen_y, kp1=1.0, kp2=1.0):
        res_list = []
        len_list = []
        for indices in batch_index(len(sen_x), self.config.batch_size, n_iter=1, is_shuffle=False, is_train=False):
            feed_dict = self.create_feed_dict(sen_x[indices], sen_len[indices], sen_y[indices], kp1, kp2)
            res = sess.run(op, feed_dict=feed_dict)
            res_list.append(res)
            len_list.append(len(indices))
        if type(res_list[0]) is list:  # if op is a list
            res = np.concatenate(res_list, axis=1)
        elif op is self.accuracy_num or op is self.accuracy_num2:
            res = sum(res_list)  # sum all batches
        elif op is self.sen_logits or op is self.sen_logits2:
            res = np.concatenate(np.asarray(res_list), 0)
        else:  # for los, etc.
            res = sum(res_list) * 1.0 / len(len_list)
        return res

    def run_cleaner(self, sess, feed_dict):
        sess.run([self.train_op2], feed_dict=feed_dict)

    def pre_run(self, sess, feed_dict):
        sess.run([self.train_op2], feed_dict=feed_dict)

    def run(self, sess, feed_dict):
        logits = sess.run([self.sen_logits2], feed_dict=feed_dict)
        _, loss, acc_num = sess.run([self.train_op, self.loss, self.accuracy_num], feed_dict=feed_dict)
        return loss, acc_num, np.concatenate(np.asarray(logits), 0)


def test_case(sess, classifier, sen_x, sen_len, sen_y):
    score = classifier.run_op(sess, classifier.sen_logits2, sen_x, sen_len, sen_y)
    loss = classifier.run_op(sess, classifier.loss2, sen_x, sen_len, sen_y)
    acc_num = classifier.run_op(sess, classifier.accuracy_num2, sen_x, sen_len, sen_y)
    y_pred = np.argmax(score, axis=1)
    y_true = np.argmax(sen_y, axis=1)
    p_class, r_class, f_class, support_micro = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred,
                                                                               labels=[0, 1], average=None)
    return acc_num * 1.0 / len(sen_y), loss, f_class[0]


def run_test(sess, classifier, domain, sen_x, sen_len, sen_y):
    scores = classifier.run_op(sess, classifier.sen_logits2, sen_x, sen_len, sen_y)
    acc_num = classifier.run_op(sess, classifier.accuracy_num2, sen_x, sen_len, sen_y)
    y_pred = np.argmax(scores, axis=1)
    y_true = np.argmax(sen_y, axis=1)
    p_class, r_class, f_class, support_micro = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred,
                                                                               labels=[0, 1], average=None)
    _, id2y = load_y2id_id2y('./data/y2id.txt')
    result_save_path = classifier.config.result_path + classifier.config.model + '/'
    if not os.path.exists(result_save_path):
        os.makedirs(result_save_path)
    with open(result_save_path + domain + '_test.txt', 'w', encoding='utf-8') as fin:
        fin.write('ACC: ' + str(acc_num * 1.0 / len(sen_x)) + '\t')
        fin.write('P: ' + str(p_class) + '\tR: ' + str(r_class) +
                  '\tF1: ' + str(f_class) + '\tF1_macro: ' + str(f_class.mean()) + '\n')
        for id_y in y_pred:
            fin.write(id2y[id_y] + '\n')
    with open(result_save_path + domain + '_true.txt', 'w', encoding='utf-8') as fin:
        for id_y in y_true:
            fin.write(id2y[id_y] + '\n')
    print('Test. Acc = {}, P = {}, R = {}, F1 = {}, F1_macro = {}'.
          format(acc_num * 1.0 / len(sen_x), p_class, r_class, f_class, f_class.mean()))


def train_run(_):
    flags_ = config.FLAGS
    domain = flags_.dataset  # movie, laptop, restaurant
    print('{} Learning start: >>>\n'.format(domain))
    tf.reset_default_graph()
#     os.environ['CUDA_VISIBLE_DEVICES'] = flags_.gpu
    classifier = NetAbModel(domain, flags_)

    gpu_config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)  #arguments I added
#     gpu_config.gpu_options.per_process_gpu_memory_fraction = 0.85
#     gpu_config.gpu_options.allow_growth = True
#     gpu_config.allow_soft_placement = True  # If 'True': allow cpu, if no gpu
    saver = tf.train.Saver(tf.global_variables())
    save_path = classifier.config.ckpt_path + classifier.config.model + '/' + domain + '/' + domain + '_ckpt'
    with tf.Session(config=gpu_config) as sess:
        sess.run(tf.global_variables_initializer())
        best_val_acc = 0
        best_val_epoch = 0
        # best_test_acc = 0
        training_path = os.path.join(flags_.data_path, 'TrainingSens/')
        train_sen_x, train_sen_len, train_sen_y = recover_data_from_files(
            training_path, 'training', domain, flags_.max_sentence_len)
        val_path = os.path.join(flags_.data_path, 'ValSens/')
        val_sen_x, val_sen_len, val_sen_y = recover_data_from_files(
            val_path, 'validation', domain, flags_.max_sentence_len)
        test_path = os.path.join(flags_.data_path, 'TestSens/')
        test_sen_x, test_sen_len, test_sen_y = recover_data_from_files(
            test_path, 'test', domain, flags_.max_sentence_len)
        # train_sen_x, train_sen_len, train_sen_y = load_inputs_document_mongo(
        #     domain, 'train_noisy', classifier.word2id, flags_.max_sentence_len, flags_.max_doc_len)
        # val_sen_x, val_sen_len, val_sen_y = load_inputs_document_mongo(
        #     domain, 'dev', classifier.word2id, flags_.max_sentence_len, flags_.max_doc_len)
        # test_sen_x, test_sen_len, test_sen_y = load_inputs_document_mongo(
        #     domain, 'test', classifier.word2id, flags_.max_sentence_len, flags_.max_doc_len)
        if classifier.config.is_train:
            for epoch_i in range(flags_.n_epoch):
                print('=' * 20 + 'Epoch ', epoch_i, '=' * 20)
                total_loss = []
                total_acc_num = []
                total_num = []
                if epoch_i < classifier.config.initial_epochs:  # initial epochs
                    for step, indices in enumerate(batch_index(len(train_sen_y), flags_.batch_size, n_iter=1, is_shuffle=False), 1):
                        indices = list(indices)
                        print(train_sen_x[indices], [train_sen_y])  #-------------------------------------- I added
                        feed_dict = classifier.create_feed_dict(train_sen_x[indices], train_sen_len[indices],
                                                                train_sen_y[indices],
                                                                flags_.keep_prob1, flags_.keep_prob2)
                        classifier.pre_run(sess, feed_dict=feed_dict)
                    continue
                for step, indices in enumerate(batch_index(len(train_sen_y), flags_.batch_size, n_iter=1, is_shuffle=False), 1):
                    indices = list(indices)
                    # if epoch_i < 10:
                    #print(""indices"", train_sen_x[indices], [train_sen_y])  #-------------------------------------- I added
                    
                    feed_dict = classifier.create_feed_dict(train_sen_x[indices], train_sen_len[indices],
                                                            train_sen_y[indices],
                                                            flags_.keep_prob1, flags_.keep_prob2)
                    loss, acc_num, logits = classifier.run(sess, feed_dict=feed_dict)
                    y_pred_set = np.argmax(logits, axis=1)
                    y_true_set = np.argmax(train_sen_y[indices], axis=1)
                    f_indices = np.arange(0, len(indices))
                    valid_indices = f_indices[y_pred_set == y_true_set]
                    indices_new = list(np.array(indices)[valid_indices])
                    # print(""newindices"", train_sen_x[indices], [train_sen_y])  #-------------------------------------- I added

                    if indices_new is None:
                        continue
                    # else:
                    #     indices_new = indices
                    # indices_new = indices
                    feed_dict = classifier.create_feed_dict(train_sen_x[indices_new], train_sen_len[indices_new],
                                                            train_sen_y[indices_new],
                                                            flags_.keep_prob1, flags_.keep_prob2)
                    classifier.run_cleaner(sess, feed_dict=feed_dict)
                    total_loss.append(loss)
                    total_acc_num.append(acc_num)
                    total_num.append(len(indices))
                    verbose = flags_.display_step
                    if step % verbose == 0:
                        print('[INFO] Len {}, Epoch {} - Batch {} : loss = {}, acc = {}'.format(
                            len(indices_new), epoch_i, step, np.mean(total_loss[-verbose:]),
                            sum(total_acc_num[-verbose:]) * 1.0 / sum(total_num[-verbose:])))
                loss = np.mean(total_loss)
                acc = sum(total_acc_num) * 1.0 / sum(total_num)
                print('\n[INFO] Epoch {} : mean loss = {}, mean acc = {}'.format(epoch_i, loss, acc))
                if np.isnan(loss):
                    raise ValueError('[Error] loss is not a number!')
                # validation
                val_acc, val_loss, val_f1 = test_case(sess, classifier, val_sen_x, val_sen_len, val_sen_y)
                print('[INFO] val loss: {}, val acc: {}, val f1: {}'.format(val_loss, val_acc, val_f1))
                # test
                test_acc, test_loss, test_f1 = test_case(sess, classifier, test_sen_x, test_sen_len, test_sen_y)
                print('[INFO] test loss: {}, test acc: {}, test f1: {}'.format(test_loss, test_acc, test_f1))
                print('=' * 25 + ' end', '=' * 25 + '\n')
                if best_val_acc < val_acc:
                    best_val_acc = val_acc
                    best_val_epoch = epoch_i
                    # best_test_acc = test_acc
                    if not os.path.exists(classifier.config.ckpt_path + classifier.config.model + '/'):
                        os.makedirs(classifier.config.ckpt_path + classifier.config.model + '/')
                    saver.save(sess, save_path=save_path)
                if epoch_i - best_val_epoch > classifier.config.early_stopping:
                    # here early_stopping is 5 :> 'the number of early stopping epoch'
                    print('Normal early stop at {}!'.format(best_val_epoch))
                    break
            print('Best val acc = {}'.format(best_val_acc))
            # print('Test acc = {}'.format(best_test_acc))
            best_val_epoch_save_path = classifier.config.result_path + classifier.config.model + '/'
            if not os.path.exists(best_val_epoch_save_path):
                os.makedirs(best_val_epoch_save_path)
            with open(best_val_epoch_save_path + domain + '_bestEpoch.txt', 'w', encoding='utf-8') as fin:
                fin.write('Best epoch: ' + str(best_val_epoch) + '\n')

            saver.restore(sess, save_path)
            print('Model restored from %s' % save_path)
            # # test now
            run_test(sess, classifier, domain, test_sen_x, test_sen_len, test_sen_y)
        else:
            saver.restore(sess, save_path)
            print('Model restored from %s' % save_path)
            # # test now
            run_test(sess, classifier, domain, test_sen_x, test_sen_len, test_sen_y)
        print('Domain {} is done..'.format(domain))
    print('\nTraining complete!\n')


if __name__ == '__main__':
    tf.app.run(train_run)
```"
51491,"""group_by_reducer"" scales badly with more images","I tried to use the tf.data.experimental.group_by_reducer Method for image-collage preprocessing. On my test-dataset (35 images collaged into 5 collages a 7 images) it worked well  and fast (~2.5sec with dataset.collage.take(1)). But then i used this setup for a set of 1414 images (to create 202 collages a 7 images) and found out that my method scales very bad (~90sec with dataset.collage.take(1)).
I didn't found the reason why the execution time is dependent on the size of the dataset because there is no import of the full dataset at any time in the grouping loop.
The cProfile Tool showed me that the time consumption is located in {built-in method tensorflow.python._pywrap_tfe.TFE_Py_FastPathExecute} but i dont know what to do with this information.



Code:

```Python
import numpy as np
import os

from tensorflow.python.keras.utils.np_utils import normalize
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Disable Tensorflow log messages
import tensorflow as tf
tf.compat.v1.enable_eager_execution()   # Enable Execution of in-function package functions (Needed for reducer)
import pandas as pd

from sklearn.model_selection import train_test_split
from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
from tensorflow.keras.layers.experimental.preprocessing import RandomTranslation
from tensorflow.keras.layers.experimental.preprocessing import RandomZoom
from tensorflow.keras.layers.experimental.preprocessing import Rescaling
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical


np.random.seed(0)
tf.random.set_seed(0)

# ----------------------------- #
# Class                         #
# ----------------------------- #
class D3VEG:
    def __init__(self, image_size=32, test_size: float = 0.2, validation_size: float = 0.33) -> None:
        # Paths
        DIR_IMG = '/home/denis/Schreibtisch/Masterarbeit/Daten/ProjektGemüse/imagesVegetables/'
        DIR_DATA = '/home/denis/Schreibtisch/Masterarbeit/Daten/ProjektGemüse/dataVegetables.csv'

        # User-defined constants
        self.batch_size = 6
        self.image_size = image_size
        file_colname = 'Image_Name'
        collage_group_colname = 'Object_Id'
        collage_label_colname = 'Kartoffel_count'

        # Load Data
        df = pd.read_csv(DIR_DATA)

        file_names = df[file_colname].values
        obj_ID = df[collage_group_colname].values
        labels = df[collage_label_colname].values
        # Convert File Names to full Paths
        file_paths = DIR_IMG + file_names

        # Data-defined constants
        self.num_collages = len(np.unique(obj_ID))
        self.num_images = file_names.size

        # ----------------------------- #
        # Collage (Reducer) functions   #
        
        # Create Reducer
        collage_reducer = tf.data.experimental.Reducer(self.init_func, self.reduce_func, self.finalize_func)

        # Define grouping key
        def key_f(tens):
            #tf.dtypes.cast(obj_ID, tf.int64)
            return tf.dtypes.cast(tens['ids'], tf.int64)
        # Create grouping function
        collage_function = tf.data.experimental.group_by_reducer(key_func=key_f,
                            reducer=collage_reducer)

        # End of Collage (Reducer) functions   #
        # ----------------------------------   #

        # Create Dataset
        ds_images = tf.data.Dataset.from_tensor_slices({'ids': obj_ID, 'img': file_paths})
        ds_labels = tf.data.Dataset.from_tensor_slices(labels)

        # Create Collage
        ds_collage = ds_images.apply(collage_function)
        # Get labels for Collage
        labels_collage = df.groupby(collage_group_colname)[collage_label_colname].first().values
        print(labels_collage.shape)
        labels_collage_norm = normalize(labels_collage)[0,:]
        print(labels_collage_norm.shape)

        ds_labels_collage = tf.data.Dataset.from_tensor_slices(labels_collage_norm)
        #print(ds_labels_collage.shape)


        # Add labels (y_data) to collage (x_data)
        ds_collage = tf.data.Dataset.zip((ds_collage, ds_labels_collage))
        #print(ds_collage.shape)

        # Finalize Collage
        self.collage = ds_collage.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
        self.collage_shape = (image_size*2, image_size*5, 3)

        # Generate Train, Test and Validation Sets
        dataset_size = labels_collage.shape[0]
        train_size = 1.0 - test_size

        train_count = int(train_size * dataset_size)
        val_count = int(validation_size * train_count)

        collage_shuffled = self.collage.shuffle(dataset_size, reshuffle_each_iteration=False)

        train_dataset = collage_shuffled.take(train_count)
        test_dataset = collage_shuffled.skip(train_count)
        val_dataset = train_dataset.take(val_count)
        train_dataset = train_dataset.skip(val_count)

        # Batch Datasets
        test_dataset = test_dataset.batch(batch_size=self.batch_size)
        val_dataset = val_dataset.batch(batch_size=self.batch_size)
        train_dataset = train_dataset.batch(batch_size=self.batch_size)

        # Finalize Datasets
        self.test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
        self.val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
        self.train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

        
    def get_train_set(self) -> tf.data.Dataset:
            return self.train_dataset
    
    def get_test_set(self) -> tf.data.Dataset:
        return self.test_dataset

    def get_val_set(self) -> tf.data.Dataset:
        return self.val_dataset

    # ----------------------------- #
    # Collage (Reducer) functions   #
    def init_func(self, _):
        ## Initiate Object to start (and store) the Loop ##
        img_stack = []
        img_top = []

        state = (img_stack, img_top)
        return state

    def reduce_func(self, state, feature):
        ## Loops over each element in the group ##
        img_stack = state[0]
        img_top = state[1]
        #print(feature)

        # Load File
        img = tf.io.read_file(feature['img'])
        # convert the compressed string to a 3D uint8
        img = tf.io.decode_jpeg(img, channels=3)
        # Crop from middle (to get rectangular image)
        img = tf.image.resize_with_crop_or_pad(img, 2500, 2500)

        img = tf.expand_dims(img, axis=0)
        if len(img_top) == 0:
            # Bigger top-down image
            img_top = tf.image.resize(img, [self.image_size*2, self.image_size*2])  # Resize to minimize shape (x2)
        else:
            img = tf.image.resize(img, [self.image_size, self.image_size])  # Resize to minimize shape
            if len(img_stack) == 0:
                # Just for first Image (transforms 'img_stack' to tensor)
                img_stack = img
            else:
                img_stack = tf.concat((img_stack, img), axis=0)

        state = (img_stack, img_top)
        return state

    def finalize_func(self, *state):
        ## Create one output per Group ##
        img_stack = state[0]
        img_top = state[1]

        for img_slot in np.arange(0, 5, 2):
            # Create vertical combination (coloumn)
            img_slot_single = tf.concat((img_stack[img_slot, :, :, :], 
                                        img_stack[img_slot+1, :, :, :]), axis=0)
            # Combine column images horizontal
            if img_slot == 0:
                img_slot_all = img_slot_single
            else:
                img_slot_all = tf.concat((img_slot_all, img_slot_single), axis=1)

        # Add bigger (top-down) image
        img_collage = tf.concat((img_slot_all, tf.squeeze(img_top, 0)), axis=1)

        #tf.ensure_shape(img_collage, [self.image_size*5, self.image_size*2, 3])
        #print(img_collage.shape)

        return img_collage
    # End of Collage (Reducer) functions   #
    # ----------------------------------   #


if __name__ == ""__main__"":
    data = D3VEG()        

    print(f""image size: {data.image_size}"")
    print(f""batch: {data.batch_size}"")
    print(f""n collages: {data.num_collages}"")
    print(f""n images: {data.num_images}"")
    for img, lab in data.collage.take(1):  # only take first element of dataset
        print(f""image shape: {img.shape}"")
        print(f""image shape: {lab.shape}"")
        single_img = img
        single_lab = lab

    #print(single_img)
    import matplotlib.pyplot as plt
    plt.imshow(single_img.numpy().astype(np.uint8))
    plt.title(f""{np.round(single_lab, 4)}"", fontsize=20)
    plt.show()
```"
51490,tf2.6 training speed can be ~1/10 of tf2.5 when embedding_column has medium bucket size(e.g. 4M),"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.7 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.6.0 and 2.5.0
- Python version: 3.6.11
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I run the same piece of code using tf 2.5.0 and 2.6.0, and the training is much slower on tf 2.6.0 (can be ~1/10 of tf 2.5.0)
The code is attached below. Using tf 2.5.0, the training speed on my server is ~58 step/s. Using tf 2.6.0, the training speed is ~ 0.9 step/s

**Describe the expected behavior**
The training speed should be similar on tf 2.5.0 and 2.6.0.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```Python
import tensorflow as tf
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)
from tensorflow.feature_column import categorical_column_with_hash_bucket, embedding_column
cat_column = categorical_column_with_hash_bucket('video_id', hash_bucket_size=4000000, dtype=tf.int64)
emb_column = embedding_column(cat_column, dimension=64, combiner='sum')
cls = tf.estimator.DNNClassifier([512,256], [emb_column], ""/tmp/model/"")

def input_fn():
    ds = tf.data.Dataset.range(10000000)
    ds = ds.map(lambda x: ({'video_id':x}, x % 2)).batch(1024)
    return ds

cls.train(input_fn)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51489,ValueError: No gradients provided for any variable,"tensorflow 2.6

```
import tensorflow as tf

class Dense(tf.Module):
    def __init__(self, input_dim, output_size, name=None):
        super(Dense, self).__init__(name=name)
        self.w = tf.Variable(
            tf.random.normal([input_dim, output_size]), name='w')
        self.b = tf.Variable(tf.zeros([output_size]), name='b')
    def __call__(self, x):
        y = tf.matmul(x, self.w) + self.b
        return tf.nn.relu(y)

test = Dense(2,4)
output = test([[7.0,3]])
# print(output)
# print(test.trainable_variables)

def loss_fn():
    y_true = tf.ones([1,4])

    loss = tf.reduce_mean(tf.square(y_true - output))
    return loss

for i in range(10):
    train_op = tf.compat.v1.train.AdamOptimizer(0.4).minimize(loss_fn, var_list=test.trainable_variables)
    print(train_op)
```


```
Traceback (most recent call last):
  File ""test8.py"", line 29, in <module>
    train_op = tf.compat.v1.train.AdamOptimizer(0.4).minimize(loss_fn, var_list=test.trainable_variables)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py"", line 418, in minimize
    ([str(v) for _, v in grads_and_vars], loss))
ValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [""<tf.Variable 'b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>"", ""<tf.Variable 'w:0' shape=(2, 4) dtype=float32, numpy=\narray([[-0.45559826,  0.6512007 , -0.9461316 ,  0.8137609 ],\n       [ 1.2699044 , -0.7115798 ,  0.60503614, -0.96902734]],\n      dtype=float32)>""] and loss <function loss_fn at 0x7f98016a3730>.


```"
51488,Support freezing ResourceGather ops in subgraphs,"Support freezing ResourceGather ops in subgraphs.  Currently skipped.
https://github.com/tensorflow/tensorflow/blob/00a29e825c5f1cd86fb2031f0c78326284637f7f/tensorflow/python/framework/convert_to_constants.py#L407

**Describe the feature and the current behavior/state.**
Not implemented

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Anyone freezing a graph with resource gather ops in the subgraph"
51487,Add support/upgrade for flatbuffers 2.0,"**System information**
- TensorFlow version (you are using): 2.6.0 / latest nightly
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
The TensorFlow pip package currently pins the flatbuffers dependency to `~1.12`:
https://github.com/tensorflow/tensorflow/blob/20b1e26b1df7b5dbe4548b9af8a6ff2348f620cc/tensorflow/tools/pip_package/setup.py#L86

Flatbuffers 2.0 has been release in May and it would be great if TensorFlow would support the new release as well, or upgrade it's required Flatbuffers version to ~2.0. This might require some minor code changes similar to https://github.com/google/jax/pull/6710, but I don't think there should be any major blockers that would prevent an upgrade.

**Will this change the current api? How?**

No

**Who will benefit with this feature?**

Anyone using Flatbuffers 2.0 in their code or relying on packages that require 2.0."
51486,How to convert savedmodel to frozen model(.pb),
51485,TPU performance increases (60x) when adding a dummy operation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 2.5.0
- device: TPU

**Describe the current behavior**
A model with 4 (or more) GRU layers and a Dense layer trains 60x faster if a dummy operation is inserted.

With the dummy operation the training time is around 2 **minutes** and 30 seconds per epoch:
<img width=""699"" alt=""Screenshot 2021-08-13 at 11 27 29"" src=""https://user-images.githubusercontent.com/1833211/129337565-70ff96aa-f4d0-4edd-933b-f3f4b7af3ae8.png"">

Without the dummy operation the training time is around 2 **hours**  and 30 mins per epoch:
<img width=""628"" alt=""Screenshot 2021-08-13 at 11 26 40"" src=""https://user-images.githubusercontent.com/1833211/129337771-c570e0a7-5ad3-45fc-ae59-d0cdfcda9872.png"">


**Describe the expected behavior**
The dummy operation should not have a large influence (and not be needed in the first place)

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1lbDTJp1JMWg5niM2Jtq2n2flWnkfLwpu?usp=sharing
Note the # dummy OP line, if this line is commented out the training loop runs ~60x slower.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51484,New TensorRT model occupying more GPU-Memory as compared to the older version,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.9.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: 11.1/8.1.0
- GPU model and memory: NVIDIA GeForce RTX 3080 10GB

**Describe the current behavior**
I am converting a tensorflow model (.h5 -> saved_model_format -> tensorrt model) to a tensorrt model using tensorflow 2.5.0 (attached tensorrt.py). The code is occupying almost **3.5GB** of GPU Memory. 

If I load the same model in the below specified environment, then that code is occupying max **~1.1GB** of GPU memory:
**TensorRT Version**: 5.1.2.2-1
**GPU Type**: GeForce RTX 2080 Ti
**Nvidia Driver Version**: 418.87.00
**CUDA Version**:  10.1
**CUDNN Version**: 7.6.2
**Operating System + Version**:  Ubuntu 16.04.7 LTS
**Python Version (if applicable)**: 3.6.13
**TensorFlow Version (if applicable)**:  1.14.1

**Describe the expected behavior**
I want to figure out what is causing this huge memory usage difference. The base models (.h5) are same just the way of converting the models differs in TF1.14.1 & TF2.5. 

Also I am getting this at inference time:
E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger INVALID_ARGUMENT: Cannot set empty memory.

I have attached codes & output for reference and reproducing this issue.

**Standalone code to reproduce the issue**
[attachment.zip](https://github.com/tensorflow/tensorflow/files/6981299/attachment.zip)
- tensorrt.py - code to convert the dummy_model to a tensorrt_model
- gpu_usage - to track the gpu usage
- Code-Output - tensorrt_output.txt


**Other info / logs**
[tensorrt_output.txt](https://github.com/tensorflow/tensorflow/files/6981335/tensorrt_output.txt)
[gpu_usage_dummy.txt](https://github.com/tensorflow/tensorflow/files/6981337/gpu_usage_dummy.txt)
"
51483,script exits after starting first epoch,"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.5.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA : 11.2, cuDNN : 8.1.0.77
- GPU model and memory: GEFORCE RTX 3090


**Describe the problem**
python code is exiting after starting first epoch with the exit code error 
""Process finished with exit code -1073740791 (0xC0000409)""
when I debugged it is observed that code is exiting when 
function 
tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
                                        inputs, attrs, num_outputs)
executing

**Provide the exact sequence of commands / steps that you executed before running into the problem**
just installed all the packages and updated the script for tensorflow 2.5.0 and using pycharm started running the script


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
2021-08-13 14:28:59.820107: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
3670
Found 3670 files belonging to 5 classes.
Using 2936 files for training.
2021-08-13 14:29:02.684243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll
2021-08-13 14:29:02.767638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:15:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 871.81GiB/s
2021-08-13 14:29:02.768344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:2d:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2021-08-13 14:29:02.769004: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
2021-08-13 14:29:02.815082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll
2021-08-13 14:29:02.815441: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll
2021-08-13 14:29:02.820867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll
2021-08-13 14:29:02.823516: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll
2021-08-13 14:29:02.836259: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll
2021-08-13 14:29:02.840952: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll
2021-08-13 14:29:02.842131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll
2021-08-13 14:29:02.842526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1
2021-08-13 14:29:02.843140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-13 14:29:03.199398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:15:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 871.81GiB/s
2021-08-13 14:29:03.200104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: 
pciBusID: 0000:2d:00.0 name: Quadro P2000 computeCapability: 6.1
coreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s
2021-08-13 14:29:03.200791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1
2021-08-13 14:29:04.474905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-08-13 14:29:04.475271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 
2021-08-13 14:29:04.475507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N 
2021-08-13 14:29:04.475734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N 
2021-08-13 14:29:04.476211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 18786 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:15:00.0, compute capability: 8.6)
2021-08-13 14:29:04.478811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3625 MB memory) -> physical GPU (device: 1, name: Quadro P2000, pci bus id: 0000:2d:00.0, compute capability: 6.1)
Found 3670 files belonging to 5 classes.
Using 734 files for validation.
['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']
2021-08-13 14:29:05.999112: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
(16, 180, 180, 3)
(16,)
0.0 0.9627812
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
rescaling_1 (Rescaling)      (None, 180, 180, 3)       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 180, 180, 16)      448       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 90, 90, 16)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 90, 90, 32)        4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 45, 45, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 45, 45, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         
_________________________________________________________________
flatten (Flatten)            (None, 30976)             0         
_________________________________________________________________
dense (Dense)                (None, 128)               3965056   
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 645       
=================================================================
Total params: 3,989,285
Trainable params: 3,989,285
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
2021-08-13 14:29:08.463012: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll

Process finished with exit code -1073740791 (0xC0000409)
"
51482,same issue with CUDA=10.0 CUDNN=7.4 Tensorflow=1.14.0,"same issue with CUDA=10.0 CUDNN=7 Tensorflow=1.14.0
stuck at `I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10`

"
51479,ValueError: Tensor data is null. Run allocate_tensors() first ,"class ImageEncoder(object):

    def __init__(self, checkpoint_filename, input_name=""images"",
                 output_name=""features""):
        self.session = tf.Session()
        interpreter = tf.lite.Interpreter(model_path=""model.tflite"")
        interpreter.allocate_tensors()
        self.input_var = interpreter.get_tensor(0)
        self.output_var = interpreter.get_tensor(130)


  File ""\tools\generate_detections.py"", line 115, in __init__
    self.output_var = interpreter.get_tensor(130)
  File ""C:\envs\yolov4-cpu\lib\site-packages\tensorflow\lite\python\interpreter.py"", line 810, in get_tensor
    return self._interpreter.GetTensor(tensor_index)
_**ValueError: Tensor data is null. Run allocate_tensors() first**_
"
51477,TFLite StaticHashTable always empty in Java,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installation (pip package or built from source): 2.5.0
- TensorFlow library (version, if pip package or github SHA, if built from source):

### 2. Code

Here is a simple model that looks up and returns the positions of string values:

```
class Lookup(tf.keras.layers.Layer):
    def build(self, input_shape):
        names = tf.constant([""a"", ""b""])
        numbers = tf.constant([1, 2], dtype=tf.int64)
        
        self.table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(names, numbers), -1)
        self.built = True
        
    def call(self, names):
        return self.table.lookup(tf.reshape(names, [-1]))

with tf.control_dependencies([tf.compat.v1.tables_initializer()]):  
    names = tf.keras.Input(shape=(2,), dtype=tf.string, name='names')
    model_outputs = Lookup()(names)
    model = tf.keras.Model(
        inputs=[names],
        outputs=model_outputs,
    )
    
model.save('./export')

converter = tf.lite.TFLiteConverter.from_saved_model('./export')
tflite_model = converter.convert()
with open('simple.tflite', 'wb') as f:
    f.write(tflite_model)
```

When calling from python, we can get the indices we expect:

```
interpreter = tf.lite.Interpreter(model_path='simple.tflite')
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
interpreter.allocate_tensors()
interpreter.set_tensor(input_details[0]['index'], np.array([['a', 'b']]))
interpreter.invoke()
output_data = interpreter.get_tensor(output_details[0]['index'])
print('output', output_data)
```
```
output [1 2]
```

But when called from Java, the strings are not found:

```
private void runTFModel() throws IOException {
    File file = new File(""simple.tflite"")
    FileInputStream inputStream = new FileInputStream(file);
    FileChannel fileChannel = inputStream.getChannel();
    MappedByteBuffer memoryMap =  fileChannel.map(FileChannel.MapMode.READ_ONLY, 0, fileChannel.size());

    Interpreter interpreter = new Interpreter(memoryMap, new Interpreter.Options());

    String[] names = new String[]{""a"", ""b""};
    Object[] inputArray = new Object[]{names};

    LongBuffer outputBuffer = ByteBuffer.allocateDirect(2 * 8).order(ByteOrder.nativeOrder()).asLongBuffer();
    Map<Integer, Object> outputMap = new HashMap<>();
    outputMap.put(0, outputBuffer);

    interpreter.runForMultipleInputsOutputs(inputArray, outputMap);

    System.out.println(outputBuffer.get(0));
    System.out.println(outputBuffer.get(1));
}               
```

This prints
```
-1
-1
```

### 3. Failure after conversion
The static hash table on the java side always returns the default element.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
51476,"""UnauthenticatedError: ioctl failed"" when creating tensors, after initializing JAX on a TPU","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): TPU v3-8 VM (so Ubuntu 20.04.2 LTS)
- TensorFlow installed from (source or binary): Binary (but I'm using what came pre-installed on the VM)
- TensorFlow version (use command below): `unknown 2.6.0` -- when I run `pip freeze` the version is `tf-nightly==2.6.0`.
- Python version: Python 3.8.5
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A (Using a TPU)

**Describe the current behavior**

I'm trying to load a dataset using Tensorflow Datasets, and run code with Jax, on a TPU VM. I'd like to do some preprocessing operations on that dataset in tensorflow. However, after initializing Jax, tensorflow can't seem to create any tensors. Here's a MWE:

* Setup: First create a [cloud TPU VM](https://cloud.google.com/tpu/docs/jax-quickstart-tpu-vm), ssh into it, and install JAX: `sudo pip3 install ""jax[tpu]==0.2.18"" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html`
*  Now I run:
```python
import jax
import tensorflow as tf
print('JAX process: {} / {}. Local devices {}'.format(jax.process_index(), jax.process_count(), jax.local_devices()), flush=True)
X = tf.constant(1.0, dtype=tf.float32)
```
and get
```python
---------------------------------------------------------------------------
UnauthenticatedError                      Traceback (most recent call last)
<ipython-input-2-9895b44de223> in <module>
      2 import tensorflow as tf
      3 print('JAX process: {} / {}. Local devices {}'.format(jax.process_index(), jax.process_count(), jax.local_devices()), flush=True)
----> 4 X = tf.constant(1.0, dtype=tf.float32)

/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    262     ValueError: if called on a symbolic tensor.
    263   """"""
--> 264   return _constant_impl(value, dtype, shape, name, verify_shape=False,
    265                         allow_broadcast=True)
    266

/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    274       with trace.Trace(""tf.constant""):
    275         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--> 276     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    277
    278   g = ops.get_default_graph()

/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    299 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
    300   """"""Implementation of eager constant.""""""
--> 301   t = convert_to_eager_tensor(value, ctx, dtype)
    302   if shape is None:
    303     return t

/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
     95     except AttributeError:
     96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
---> 97   ctx.ensure_initialized()
     98   return ops.EagerTensor(value, ctx.device_name, dtype)
     99

/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py in ensure_initialized(self)
    552         pywrap_tfe.TFE_ContextOptionsSetRunEagerOpAsFunction(
    553             opts, self._run_eager_op_as_function)
--> 554         context_handle = pywrap_tfe.TFE_NewContext(opts)
    555       finally:
    556         pywrap_tfe.TFE_DeleteContextOptions(opts)

UnauthenticatedError: ioctl failed
```

*My hunch about what is going on*

I suspect, but am not sure, that the problem is that Tensorflow is trying to create tensors on the TPU. This isn't intended because I'd like it to create tensors on the CPU instead. I've tried looking through [this guide](https://www.tensorflow.org/api_docs/python/tf/config/set_visible_devices) and also adding this line of code right after importing tensorflow:
```
tf.config.experimental.set_visible_devices([], 'GPU')
```
which I saw in a bunch of tutorials, but it doesn't help. (Which is perhaps not surprising because there aren't any GPUs on a TPU VM). When I run `tf.config.list_logical_devices()` afterwards I get

```python
[LogicalDevice(name='/device:CPU:0', device_type='CPU'),
 LogicalDevice(name='/device:TPU_SYSTEM:0', device_type='TPU_SYSTEM'),
 LogicalDevice(name='/device:TPU:0', device_type='TPU'),
 LogicalDevice(name='/device:TPU:1', device_type='TPU'),
 LogicalDevice(name='/device:TPU:2', device_type='TPU'),
 LogicalDevice(name='/device:TPU:3', device_type='TPU'),
 LogicalDevice(name='/device:TPU:4', device_type='TPU'),
 LogicalDevice(name='/device:TPU:5', device_type='TPU'),
 LogicalDevice(name='/device:TPU:6', device_type='TPU'),
 LogicalDevice(name='/device:TPU:7', device_type='TPU')]
```

More surprisingly though, for some reason, even when I run 
```python
tf.config.experimental.set_visible_devices([], 'GPU')
tf.config.experimental.set_visible_devices([], 'TPU_SYSTEM')
tf.config.experimental.set_visible_devices([], 'TPU')
```

I get the same result. so I'm not quite sure how to hide TPUs from tensorflow, or, for that matter, how anyone else is able to do so 😅 

**Describe the expected behavior**

I'd like the tensor to be initialized (a constant value of 1.0), and on the CPU. The reason I'm creating a tensor here is to do some data preprocessing and augmentation, like [what was used for the flax ImageNet examples](https://github.com/google/flax/blob/main/examples/imagenet/input_pipeline.py), and that augmentation should live on CPU.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no (I'm not sure what the fix is or what I'm doing wrong).
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**

See above.

**Other info / logs**

Inspecting the logs in `/tmp/tpu_logs/` I found:

```
cat /tmp/tpu_logs/tpu_driver.t1v-n-e14a9395-w-0.rowanz.log.ERROR.20210812-234557.16896
Log file created at: 2021/08/12 23:45:57
Running on machine: t1v-n-e14a9395-w-0
Binary: Built on May 19 2021 03:34:24 (1621420438)
Binary: Built at cloud-tpus-runtime-release-tool@a3446e09a7af769-324b9e30725.borgtask.google.com:/google/src/cloud/buildrabbit-username/buildrabbit-client/g3
Binary: Built for gcc-4.X.Y-crosstool-v18-llvm-grtev4-k8
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
E0812 23:45:57.936586   18120 kernel_dma_mapper.cc:88] Error setting number simples with FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']
E0812 23:45:57.936686   18119 kernel_dma_mapper.cc:88] Error setting number simples with FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']
E0812 23:45:57.936775   18120 tensor_node.cc:436] [0000:00:05.0 PE0 C1 MC-1 TN0] Failed to set number of simple DMA addresses: FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']
E0812 23:45:57.936795   18119 tensor_node.cc:436] [0000:00:07.0 PE0 C3 MC-1 TN0] Failed to set number of simple DMA addresses: FAILED_PRECONDITION: ioctl failed [type.googleapis.com/util.ErrorSpacePayload='util::PosixErrorSpace::Device or resource busy']
```"
51473,tf.stop_gradient sometimes does not work as expected when called from a @tf.function ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary. 
- TensorFlow version (use command below): Tested with 2.4 and 2.6
- Python version: 3.8.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda 11.0 / cuDNN 8.0.4
- GPU model and memory: 1080 ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The command 

quantized_grad_stop = z + tf.stop_gradient(quantized - z)

does not work as expected when it is called from a decorated function @tf.function

It works as it is expected when the @tf.function is removed (e.g. #@tf.function)

**Describe the expected behavior**

The expected behavior is to pass the value of quantized during the forward pass and use the value of z in the calculation of derivatives 

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

The following code demonstrates the problem. Run the code once with #@tf.function and once with @tf.function
[vector_quantizer.py.zip](https://github.com/tensorflow/tensorflow/files/6978589/vector_quantizer.py.zip)


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51472,OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.,"I'm Trying to implement a Triplet lose based NN, and for this cause I have implemented a custom Image Generator.
When I start the ```model.fit()``` I get the following error:
```
    OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.
```
Even Though I'm not even iterating a single tensor in My code.
My code is listed here below:

the Image Generator:
```python
class TripletDataGenerator(tf.keras.utils.Sequence):
    """"""
    NOTE: ON model.fit(SHUFFLE=FALSE) -> MUST BE FALSE!
    """"""

    def __init__(self,
                 df: pd.DataFrame,
                 batch_size=256,
                 shuffle=True,
                 rescale: {float, None} = 1. / 255.,
                 target_img_size=(128, 128),
                 preprocess_function=None,
                 rand_preproc_single: {ImageDataGenerator, dict} = None,
                 rand_preproc_batch: list = None):
        self.batch_counter = 0
        self.last_batch_index = 0
        if shuffle:
            self.triplets_df = df.sample(frac=1).reset_index(drop=True)  # randomizing it
        else:
            self.triplets_df = df.reset_index(drop=True)  # randomizing it
        self.preprocess_function = preprocess_function
        self.rescale = rescale
        self.target_img_size = target_img_size

        assert batch_size > 0, ""Minimum batch size is 1, must be positive.""
        self.batch_size = batch_size
        self.shuffle = shuffle
        # indexes of rows. every batch we draw 2 samples. 1 similar and 1 dissimilar
        self.indexes = np.arange(len(self.triplets_df))
        if self.shuffle:
            np.random.shuffle(self.indexes)

        self.rand_preproc_single = rand_preproc_single
        self.rand_preproc_batch = rand_preproc_batch

    def __len__(self):
        """"""Denotes the number of batches per epoch""""""
        return len(self.triplets_df) // self.batch_size

    def __getitem__(self, index):
        """"""Generate one batch of data""""""
        # Generate indexes of the batch
        indexes = self.indexes[index * self.batch_size:
                               (index + 1) * self.batch_size]
        self.last_batch_index = index

        anchors = []
        positives = []
        negatives = []
        for idx in indexes:
            a, p, n = self.triplets_df.iloc[idx]
            anchors.append(self.load_image(a))
            positives.append(self.load_image(p))
            negatives.append(self.load_image(n))

        anchors = np.array(anchors, dtype='float32')
        positives = np.array(positives, dtype='float32')
        negatives = np.array(negatives, dtype='float32')
        labels = np.zeros(self.batch_size)
        if self.rand_preproc_batch is not None:
            for func in self.rand_preproc_batch:
                anchors = func(anchors)
                positives = func(positives)
                negatives = func(negatives)

        return [anchors, positives, negatives], labels

    def on_epoch_end(self):
        """"""Updates indexes after each epoch""""""

        self.batch_counter += self.last_batch_index + 1  # indices starts from 0
        if self.batch_counter >= len(self):
            if self.shuffle:
                np.random.shuffle(self.indexes)
                self.triplets_df = self.triplets_df.sample(frac=1).reset_index(drop=True)
            self.batch_counter = 0
        else:
            self.indexes = np.append(self.indexes[self.last_batch_index + 1:],
                                     self.indexes[: self.last_batch_index + 1])

    def load_image(self, path):
        """"""
        loads an image using tensorflow tools
        :param path: absolute path (refers to the project's folder) to the image
        :return: an image array.
        """"""
        if self.rand_preproc_single is not None:
            if isinstance(self.rand_preproc, ImageDataGenerator):
                img_arr = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)
                img_arr = self.rand_preproc.random_transform(img_arr)
                img_arr = cv2.resize(img_arr, self.target_img_size)
            else:
                img_arr = my_utils.image_augmentations(path, **self.rand_preproc)
        else:
            img_arr = cv2.imread(path)
            img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)
            img_arr = cv2.resize(img_arr, self.target_img_size)
        if self.preprocess_function is not None:
            img_arr = self.preprocess_function(img_arr)
        elif self.rescale is not None:
            img_arr = img_arr * self.rescale
        return img_arr

```

The model's Architecture is as follows:
```python
def get_siamese_model(input_shape, conv2d_filters):
    # Define the tensors for the two input images
    anchor_input = Input(input_shape, name=""Anchor_Input"")
    positive_input = Input(input_shape, name=""Positive_Input"")
    negative_input = Input(input_shape, name=""Negative_Input"")

    body = build_body(input_shape, conv2d_filters)

    # Generate the encodings (feature vectors) for the two images
    encoded_a = body(anchor_input)
    encoded_p = body(positive_input)
    encoded_n = body(negative_input)

    ap_distance = tf.reduce_sum(tf.square(encoded_a - encoded_p), axis=-1, keepdims=True)
    an_distance = tf.reduce_sum(tf.square(encoded_a - encoded_n), axis=-1, keepdims=True)
    # Connect the inputs with the outputs
    siamese_net = Model(inputs=[anchor_input, positive_input, negative_input],
                        outputs=[ap_distance, an_distance])
    return siamese_net
```
and loss is:
```python
def get_loss(margin=1.0):
    def triplet_loss(y_true, y_pred):
        # The output of the network is a tuple containing the distances
        # between the anchor and the positive example, and the anchor and
        # the negative example.
        ap_distance, an_distance = y_pred

        # Computing the Triplet Loss by subtracting both distances and
        # making sure we don't get a negative value.
        loss = ap_distance - an_distance
        loss = tf.maximum(loss + margin, 0.0)
        return loss

    return triplet_loss
```
Main:
```python
if __name__ == '__main__':

    EPOCHS = configurations.EPOCHS
    BATCH_SIZE = configurations.BATCH_SIZE
    IMG_SIZE = configurations.IMG_SIZE
    MONITOR = configurations.MONITOR
    PATIENCE = configurations.PATIENCE
    EMBEDDING_NODES = configurations.EMBEDDING_NODES
    LEARNING_RATE = configurations.LEARNING_RATE
    STEPS_PER_EPOCH = configurations.STEPS_PER_EPOCH
    VALIDATION_STEPS = configurations.VALIDATION_STEPS
    CONV2D_FILTERS = configurations.CONV2D_FILTERS
    MARGIN = configurations.MARGIN
    DATA_FILE = 'LFW_triplets.csv'
    augment_params = None
    # augment_params = dict(
    #     resize=IMG_SIZE[:-1],
    #     random_gray_scale=0.2,
    #     random_contrast_range=[0.65, 1.5],
    #     hsv_noise_max_amps=[0.02, 0.2, 0],
    #     max_brightness_delta=0.15,
    #     LR_flip=True,
    #     UD_flip=False,
    #     rotate_range=30,
    #     random_shift=[0.1, 0.1],
    #     random_zoom_range=0.3,
    #     rescale=1. / 255.)

    NOTES = '\n'.join([
        f""batch size={BATCH_SIZE}"",
        f""learning_rate={LEARNING_RATE}"",
        f""embedding_nodes={EMBEDDING_NODES}"",
        f""DataFilePath={DATA_FILE}"",
        f""BatchNormalization_used={configurations.ADD_BATCHNORM}"",
        f""Conv2D_filters_count={CONV2D_FILTERS}"",
        f""Loss=triplet_loss"",
        ""Augmentations with: HSV, Brightness, Contrast.""
    ])

    np.random.seed(42)
    tf.random.set_seed(42)

    t = time.time()
    train_gen, test_gen = DataFrameGeneratorClass.create_train_test_generators(csv_path=DATA_FILE, pair_gen=False,
                                                                               validation_split=0.3, shuffle=True,
                                                                               batch_size=configurations.BATCH_SIZE,
                                                                               rescale=1. / 255.,
                                                                               img_size=configurations.IMG_SIZE[:-1],
                                                                               preprocess_func=None,
                                                                               rand_preproc_single=None,
                                                                               rand_preproc_batch=None)

    dt = time.time() - t
    print(f""TOOK {dt} seconds to create Train Generator with {len(train_gen)} Batches""
          f"" and Test Generator with {len(test_gen)} Batches"")

    siamese_model = get_siamese_model(input_shape=IMG_SIZE, conv2d_filters=CONV2D_FILTERS)
    siamese_model.summary()
    loss_func = get_loss(margin=MARGIN)
    siamese_model.compile(optimizer=Adam(learning_rate=0.0001),
                          loss=loss_func)

    early_stop = tf.keras.callbacks.EarlyStopping(monitor=MONITOR,
                                                  min_delta=1e-5,
                                                  patience=PATIENCE,
                                                  verbose=1,
                                                  mode='auto',
                                                  restore_best_weights=True)

    date_string = datetime.datetime.today().strftime(""%d-%m-%y_%H%M%S"")
    os.mkdir(f'check_points/{date_string}/')
    chk_point = tf.keras.callbacks.ModelCheckpoint(f'check_points/{date_string}/',
                                                   monitor=configurations.MONITOR,
                                                   verbose=1,
                                                   save_best_only=True,
                                                   save_weights_only=True)

    call_backs = [early_stop, chk_point, tf.keras.callbacks.TensorBoard(log_dir=f'logs/TRIPLET_{date_string}', write_images=True)]

    history = siamese_model.fit(train_gen,
                                shuffle=False,  # ITS MANDATORY WHEN USING MY CUSTOM GENERATOR
                                epochs=EPOCHS,
                                steps_per_epoch=STEPS_PER_EPOCH,
                                validation_steps=VALIDATION_STEPS,
                                callbacks=call_backs,
                                validation_data=test_gen)

    NOTES += f""\n\n{chk_point.monitor}={chk_point.best}""
    my_utils.save_results(notes=NOTES,
                          history_obj=history,
                          directory_dst='results',
                          model=siamese_model,
                          date_str=""TRIPLET_"" + date_string)
```"
51467,"""ERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors"" for a graph that doesn't appear to have dynamic-sized tensors","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary (pip wheel)
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.7.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When using the Edge TPU compiler on a TFLite model (converted via `tf.compat.v1.TFLiteConverter.from_session` from a TensorFlow model), the compiler fails with the error message:
`ERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`
I've examined the model in Netron and haven't been able to find a dynamic-sized tensor input.

**Describe the expected behavior**
The Edge TPU compiler successfully compiles the model as it has static-sized tensors.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): Sure, I would
- Briefly describe your candidate solution(if contributing): Not a solution, but it would be great to understand which part(s) of the model the compiler thinks have dynamic sizes.

**Standalone code to reproduce the issue**
`edgetpu_compiler -s <path/to/model>`
See attached file [mobilenet_v2_small_from_session_quant_exp_conv_exp_quant_sel_ops_static.zip](https://github.com/tensorflow/tensorflow/files/6977427/mobilenet_v2_small_from_session_quant_exp_conv_exp_quant_sel_ops_static.zip)
It's converted from the `mobilenet_v2_small` model in this repository: https://github.com/gsethi2409/tf-pose-estimation

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Snippet of code used for conversion to TFlite:
```
def rep_data_gen():
    for x in tf.data.Dataset.list_files(</path/to/training/images/):
        image = tf.io.read_file(x.numpy())
        image = tf.image.decode_jpeg(image)
        image = tf.image.convert_image_dtype(image, tf.float32)
        image = tf.image.resize(image, [320, 240])
        image = image[np.newaxis, :, :, :]
        # image = image / 255.0
        yield [image, tf.constant([160, 120])]

# Set input shape for non-placeholder, output tensors only look at name
self.tensor_image.set_shape([1, 320, 240, 3])
self.upsample_size.set_shape([2])
sess_converter = tf.compat.v1.lite.TFLiteConverter.from_session(
    self.persistent_sess,
    input_tensors=[self.tensor_image, self.upsample_size],
    output_tensors=[self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up]
)
sess_converter.experimental_new_converter = True
model_name = ""mobilenet_v2_small_from_session_quant_exp_conv_exp_quant_sel_ops_static.tflite""
sess_converter.optimizations = [tf.lite.Optimize.DEFAULT]
sess_converter.representative_dataset = rep_data_gen
sess_converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS,
                                            tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
sess_converter.inference_input_type = tf.int8  # or tf.uint8
sess_converter.inference_output_type = tf.int8  # or tf.uint8
sess_converter.experimental_new_quantizer = True
tflite_model = sess_converter.convert()
```
"
51466,TF2.6 How to avoid UnimplementedError error for non-deterministic ops?,"After I upgarde from 2.5 to 2.6, the non-deterministic ops will throw UnimplementedError after set TF_DETERMINISTIC_OPS = 1. 

However, I still want to use the exist implemented deterministic ops and keep unimplemented ops non-deterministic. 

What should I do to avoid UnimplementedError error for non-deterministic ops"
51465,"Output of tf.random.uniform can equal maxval, contrary to docstring","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Big Sur 11.2.3 (also observed on Mojave 10.14.6 and on Amazon Linux 2)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.6.0 (also observed on 2.4.1)
- Python version: 3.9.0 (also observed on 3.7 and 3.9.6)
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A (observed on CPU)
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The function tf.random.uniform sometimes returns values equal to `maxval`, as in the code below.

**Describe the expected behavior**
According to the docstring for `tf.random.uniform`, ""The generated values follow a uniform distribution in the range [minval, maxval). The lower bound `minval` is included in the range, while the upper bound `maxval` is excluded.""

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Python 3.9.0 (default, Nov 27 2020, 21:03:12)
Type 'copyright', 'credits' or 'license' for more information
IPython 7.19.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import tensorflow as tf

In [2]: tf.random.set_seed(42)

In [3]: tf.random.uniform((10000000,), minval=5, maxval=6, seed=42)[1739846]
2021-08-12 13:20:28.540136: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Out[3]: <tf.Tensor: shape=(), dtype=float32, numpy=6.0>

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51464,ResNetV2 implementation problem,"**System information**
(not related to installation)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.5.0 GPU
- Python version: 3.8



**Describe the expected behavior**
As shown in the image below from **Identity Mappings in Deep Residual Networks** by He et al.\
ResNetV2 block has its preactivation **after** branching (bn-relu-conv-bn-relu-conv are all in contained in residual)
![image](https://user-images.githubusercontent.com/49250812/129236962-d30af2fc-8bac-4ddf-a951-6d986d25bef3.png)
the **only** exception on preactivation is the first block of the first stage\
quote from the original paper:
> For the first Residual Unit (that follows a stand-alone convolutional layer,
> conv1), we adopt the first activation right after conv1 and before splitting into
> two paths

**Describe the current behavior**
ResNetV2 Falsefully put preactivation before branching when channel increases for **all stages**
![image](https://user-images.githubusercontent.com/49250812/129238244-89917129-a60f-45a0-a29c-26cd3134a249.png)
As shown in above image, the output of `ResNet50V2(weights=None).summary()`\
the red arrow I added points to the shortcut path, it is connected to preact_relu, which means the preactivation is done **before** branching to residual and shortcut, which is not true according to the original paper\
a simple drawing representing the first block of each stage in current implementation, which is obviously not equivalent to the image from the original paper:
![image](https://user-images.githubusercontent.com/49250812/129239135-4cf8449e-87c8-439a-89c1-070ccd09411f.png)



"
51463,Feature request: real and imag attributes for Tensors.,"**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): Yes, although I may need some help to point me where this code should be.

**Describe the feature and the current behavior/state.**
I would like to have a `real` and `imag` property for Tensors in Tensorflow. These would simply call  to `tf.math.real` and `tf.math.imag` internally. This will make writing code with tensorflow more flexible and will bring more compatibility with numpy and python's `complex` type, which do have these attributes. For instance, I would like to do something like:
```python
out = operation(input)  # Function that returns an output type depending on the input type
return out.real if isherm else out  # Different output depending on a variable (isherm) which I keep track of by other more means.
```

**Will this change the current api? How?**
Yes. It will add the `real` and `complex` attributes to Tensors/Variables. It will be backwards compatible as it only adds something new. 

**Who will benefit with this feature?**
Anyone working with complex numbers as will bring easy and intuitive access to the real and imaginary parts of a complex tensor. I think this is specially useful for the experimental numpy behaviour.

**Any Other info.**
I am working with complex numbers using TensorFlow. In particular,  I am developing a python package, [qutip-tensorflow](https://github.com/qutip/qutip-tensorflow), that allows backing [QuTiP's Qobj](https://github.com/qutip/qutip) with Tensorflow's Tensors. The goal is to make QuTiP benefit from some of the very useful features in TensorFlow such as operating with a GPU or auto-differentiation. The feature suggested here will help with the development of qutip-tensorflow."
51461,Grouped convolutions don't work in TensorFlow 2.6.0,"I am trying to implement [RegNetY](https://arxiv.org/abs/2003.13678) in TensorFlow. It uses grouped convolutions. I had developed and trained the models using TF 2.5. I am aware that grouped convs aren't supported on CPUs as of yet for batch size > 1 ([source](https://github.com/tensorflow/tensorflow/issues/29005#issuecomment-886029670)).  
But as of 2.6.0, grouped convs are *not* working on either CPU or GPU. Following is the minimum reproducible code

``` python
!pip uninstall tensorflow keras 
!pip install tensorflow==2.6.0

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D( 8, 3, groups=4),
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(5)
])
model.compile(
    optimizer=tf.keras.optimizers.Adam(0.0001),
    loss= tf.keras.losses.CategoricalCrossentropy(from_logits=True),
    metrics=[""accuracy""]    
)
randx = tf.random.uniform((20, 30, 30, 4))
randy = tf.random.uniform((20, 5))
model.fit(
    randx,
    randy,
    epochs=10,
)
```
Error trace:
```
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-15-90a8900d1ed2> in <module>()
     14     randx,
     15     randy,
---> 16     epochs=10,
     17 )

6 frames
/usr/local/lib/python3.7/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1182                 _r=1):
   1183               callbacks.on_train_batch_begin(step)
-> 1184               tmp_logs = self.train_function(iterator)
   1185               if data_handler.should_sync:
   1186                 context.async_wait()

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    883 
    884       with OptionalXlaContext(self._jit_compile):
--> 885         result = self._call(*args, **kwds)
    886 
    887       new_tracing_count = self.experimental_get_tracing_count()

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    948         # Lifting succeeded, so variables are initialized and we can run the
    949         # stateless function.
--> 950         return self._stateless_fn(*args, **kwds)
    951     else:
    952       _, _, _, filtered_flat_args = \

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   3038        filtered_flat_args) = self._maybe_define_function(args, kwargs)
   3039     return graph_function._call_flat(
-> 3040         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   3041 
   3042   @property

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1962       # No tape is watching; skip to running the function.
   1963       return self._build_call_outputs(self._inference_function.call(
-> 1964           ctx, args, cancellation_manager=cancellation_manager))
   1965     forward_backward = self._select_forward_and_backward_functions(
   1966         args,

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    594               inputs=args,
    595               attrs=attrs,
--> 596               ctx=ctx)
    597         else:
    598           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnimplementedError:  Fused conv implementation does not support grouped convolutions for now.
	 [[node sequential_2/conv2d_1/BiasAdd (defined at <ipython-input-15-90a8900d1ed2>:16) ]] [Op:__inference_train_function_49676]

Function call stack:
train_function
```

Colab gist [here](https://colab.research.google.com/gist/AdityaKane2001/369fd6f2a6a737a7449bd9449f6ac1ca/groupedconvissue.ipynb).

/cc @sayakpaul @MorganR"
51459,'tf.Roll' op is neither a custom op nor a flex op,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- TensorFlow installed from (source or binary): conda install
- TensorFlow version (or github SHA if from source): 2.4.0

Hello,

I am facing similr issue with tf.Roll function. Although I see the exhaustive list of tf.ops support by tf.Lite includes the Roll operation. My code looks like this for tfLite:

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()


**Provide the text output from tflite_convert**

```
Exception: /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/signal/fft_ops.py:459:0: error: 'tf.Roll' op is neither a custom op nor a flex op
/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:201:0: note: called from
/global/cscratch1/sd/jmunshi/4DCrystal/CNNTrainingNetwork/Crystal4d/utils/conv_utils.py:26:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/core.py:917:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:560:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:424:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/saving/saving_utils.py:135:0: note: called from
/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:634:0: note: called from
:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
tf.Roll {device = """"}
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
51458,high vram usage when setting architecture on rtx3090? ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8
- CUDA/cuDNN version: CUDA11.2/cuDNN8.2.1 for rtx3090, CUDA10.1/cuDNN7.6.5 for rtx2080ti
- GPU model and memory: rtx3090 24GB, rtx2080ti 11GB


**Describe the current behavior**
Use the same code below in a compatible environment,
the code was executed successfully on rtx2080ti but failed on rtx3090.
And I check the code step by step,
and this line will make the rtx3090 vram usage full.
`c1 = Conv2D(48, (3, 3), activation=None, kernel_initializer='he_normal', padding='same')(s)`

why rtx3090 using all vram when setting the architecture?

**Standalone code to reproduce the issue**
Use the following code:
```python
import os
import sys
import random
import warnings

import numpy as np
import pandas as pd
import cv2

import matplotlib.pyplot as plt
from PIL import Image
from tqdm import tqdm
from itertools import chain
from skimage.io import imread, imshow, imread_collection, concatenate_images
from skimage.transform import resize
from skimage.morphology import label
from PIL import ImageFile
import SimpleITK as sitk

from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dropout, Lambda,Activation
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import concatenate
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras import backend as K
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop,Adam,SGD,Adadelta


IMG_WIDTH = 512
IMG_HEIGHT = 512
IMG_CHANNELS = 3


DATA_PATH = 'G:/DenseUnet/input/test/'
np.random.seed = 42

sub_dir = 'image/'
image_ids =  next(os.walk(DATA_PATH + sub_dir))[2]

X = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH,3))
Y = np.zeros((len(image_ids), IMG_HEIGHT, IMG_WIDTH,1))
mask = np.zeros((IMG_WIDTH, IMG_HEIGHT),dtype=np.bool)
for n, id_ in tqdm(enumerate(image_ids), total=len(image_ids)):
    path = DATA_PATH +sub_dir + id_
    img = sitk.ReadImage(path)
    img = sitk.GetArrayFromImage(img)
    #img = cv2.resize(img, (256, 256))
    X[n] = img
    
    mask = sitk.ReadImage(DATA_PATH + 'label/'+id_[:-8]+'gt.tiff')
    mask = sitk.GetArrayFromImage(mask)
    mask = np.expand_dims(mask, axis=2)
    Y[n] = mask

print('load files finished')
gc.collect()
X = (X-np.min(X))/(np.max(X)-np.min(X))
x_train = X
Y=Y.astype(bool)
y_train = Y

def mean_iou(y_true, y_pred):
    prec = []
    for t in np.arange(0.5, 1.0, 0.05):
        y_pred_ = tf.to_int32(y_pred > t)
        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 4)
        tf.compat.v1.keras.backend.get_session().run(tf.local_variables_initializer())
        with tf.control_dependencies([up_opt]):
            score = tf.identity(score)
        prec.append(score)
    return tf.keras.backend.mean(tf.keras.backend.stack(prec), axis=0)


# COMPETITION METRIC
def dice_coeff(y_true, y_pred, smooth=1):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


#%% (Architecture)

def dense_block(inputs,growth_rate,n_layers):
    total_features=[]
    ini = inputs
    for i in range(n_layers):
        x = BatchNormalization()(ini)
        x = Activation('relu')(x)
        x = Conv2D(growth_rate, (3, 3),activation=None, kernel_initializer='he_normal', padding='same')(x)
        x = Dropout(0.2)(x)
        total_features.append(x)
        ini = concatenate([x,ini],axis=3)
        
        dense_out = total_features[0]
        for j in range(len(total_features)-1):
            dense_out = concatenate([dense_out,total_features[j+1]],axis=3)
        
    return dense_out,ini
       
def trans_down(inputs,filters):

    x = BatchNormalization()(inputs)
    x = Activation('relu')(x)
    
    x = Conv2D(filters, (1, 1), activation=None, kernel_initializer='he_normal', padding='same')(x)
    x = Dropout(0.2)(x)
    x = MaxPooling2D((2, 2))(x)
    
    return x

def trans_up(inputs,filters):
    x = Conv2DTranspose(filters, (3, 3), strides=(2, 2), padding='same')(inputs)
    return x

inputs = Input((IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS))
s = Lambda(lambda x: x / 1) (inputs)
c1 = Conv2D(48, (3, 3), activation=None, kernel_initializer='he_normal', padding='same')(s)
c1 = BatchNormalization()(c1)
c1 = Activation('relu')(c1)

b1,_ = dense_block(c1,16,4)
con1 = concatenate([b1,c1],axis=3)
d1 = trans_down(con1,112)

b2,_ = dense_block(d1,16,5)
con2 = concatenate([b2,d1],axis=3)
d2 = trans_down(con2,192)

b3,_ = dense_block(d2,16,7)
con3 = concatenate([b3,d2],axis=3)
d3 = trans_down(con3,304)

b4,_ = dense_block(d3,16,10)
con4 = concatenate([b4,d3],axis=3)
d4 = trans_down(con4,464)

b5,_ = dense_block(d4,16,12)
con5 = concatenate([b5,d4],axis=3)
d5 = trans_down(con5,656)

b6,block_to_up6 = dense_block(d5,16,15)

u7 = trans_up(block_to_up6,240)
con7 = concatenate([u7,con5],axis=3)
b7,block_to_up7 = dense_block(con7,16,12)

u8 = trans_up(block_to_up7,192)
con8 = concatenate([u8,con4],axis=3)
b8,block_to_up8 = dense_block(con8,16,10)

u9 = trans_up(block_to_up8,160)
con9 = concatenate([u9,con3],axis=3)
b9,block_to_up9 = dense_block(con9,16,7)


u10 = trans_up(block_to_up9,112)
con10 = concatenate([u10,con2],axis=3)
b10,block_to_up10 = dense_block(con10,16,5)


u11 = trans_up(block_to_up10,80)
con11 = concatenate([u11,con1],axis=3)
b11,block_to_up11 = dense_block(con11,16,4)
outputs = Conv2D(1, (1, 1), activation='sigmoid')(block_to_up11)

model = Model(inputs=[inputs], outputs=[outputs],name='DenseUNet')
model.compile(optimizer=RMSprop(1e-4),loss='binary_crossentropy', metrics=[dice_coeff])
model.summary()

filepath=""G:/DenseUnet/model/20210812/0812-{epoch:02d}-{val_dice_coeff:.4f}.h5"" 
earlystopper = EarlyStopping(patience=350, verbose=1)
checkpointer = ModelCheckpoint(filepath,monitor='val_loss', verbose=1, save_best_only=False)
results = model.fit(x_train, y_train, validation_split=0.2, batch_size=3, epochs=100, 
                    callbacks=[earlystopper,checkpointer])

import pickle
with open('G:/DenseUnet/0810_100e.txt', 'wb') as file_txt:
    pickle.dump(results.history, file_txt)
```
"
51457,Dereferencing null pointer in GPU delegate,"The following code in GPU delegate constructor should probably use `options_` instead of `options` that is potentially a null pointer

https://github.com/tensorflow/tensorflow/blob/8b06339173d65b9f48236f4051d31e32a2e86191/tensorflow/lite/delegates/gpu/delegate.cc#L95-L102"
51456,Default values of mean and standard deviation for TFLite RNN Models.,"Using TensorFlow version 2.4.1 ,

Default values for Mean and standard deviation for classification models is Mean - 127.5 and Std Deviation 127.5 .

Reference - https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/lite/examples/label_image/label_image.h 

![Capturedvdvrvrv](https://user-images.githubusercontent.com/47776253/129203242-fee6ea68-4a85-4a07-967a-7910075694c9.JPG)

What are the default values for RNN models?

Is Mean and Standard deviation the same?

(or)

Is Mean - 0 and Standard deviation 1 by default for RNN?"
51454,Normalizations based on TFLite input type,"Why there is a different kind of normalization technique used for each data type.

Could you explain the reasoning for using these.

Using Tensorflow version 2.4.1.
Reference - https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/lite/examples/label_image/bitmap_helpers_impl.h ,
https://github.com/tensorflow/tensorflow/blob/v2.4.1/tensorflow/lite/examples/label_image/get_top_n_impl.h

For input normalizing .
![Capturefgregtrgtr](https://user-images.githubusercontent.com/47776253/129198641-5f186ab7-7429-4f76-b7fa-29a4ee98b745.JPG)
For output .
![Capturesssssss](https://user-images.githubusercontent.com/47776253/129198676-1b67f9a0-1375-425a-b612-29980532d631.JPG)

Are these valid all kinds of TFLite Models?
"
51453,unable to create tf.variables inside a function that is decorated with @tf.function,"tf 2.5


```
@tf.function
def weight_fn():
    w = tf.Variable(tf.truncated_normal())
```

I have a function like above that would be called about **50 times**, each time it should generate a new variable and return. But according to the [rule](https://tensorflow.google.cn/guide/function#creating_tfvariables) and the hint below,

```
    ValueError: A tf.Variable created inside your tf.function has been garbage-collected. Your code needs to keep Python references to variables created inside `tf.function`s.
    
    A common way to raise this error is to create and return a variable only referenced inside your function:
    
    @tf.function
    def f():
      v = tf.Variable(1.0)
      return v
    
    v = f()  # Crashes with this error message!
    
    The reason this crashes is that @tf.function annotated function returns a **`tf.Tensor`** with the **value** of the variable when the function is called rather than the variable instance itself. As such there is no code holding a reference to the `v` created inside the function and Python garbage collects it.
    
    The simplest way to fix this issue is to create variables outside the function and capture them:
    
    v = tf.Variable(1.0)
    
    @tf.function
    def f():
      return v
    
    f()  # <tf.Tensor: numpy=1.>
    v.assign_add(1.)
    f()  # <tf.Tensor: numpy=2.>

```

I should define the weight variable outside the tf.function, which means I should manually define over 50 weight variables, each line with a weight variable.

```
w1 = tf.Variable(tf.truncated_normal())
w2 = tf.Variable(tf.truncated_normal())
w3 = tf.Variable(tf.truncated_normal())
......
w50 = tf.Variable(tf.truncated_normal())

```

Undoubtedly, this kind of behavior is really stupid, any solutions to this kind of unreasonable rule?

"
51451,Multiple versions of TensorFlow co-installed potentially cause ABI mismatch,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): both
- TensorFlow version (use command below): 2.6.0
- Python version: 3.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**

When multiple tensorflow instances are installed in different parts of your python path, TensorFlow will attempt to load kernel libraries from all of them, potentially resulting in an ABI mismatch.

```
$ python3 -c ""import tensorflow""
No protocol specified
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 438, in <module>
    _ll.load_library(_main_dir)
  File ""/home/sclarkson/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library
    py_tf.TF_LoadLibrary(lib)
tensorflow.python.framework.errors_impl.NotFoundError: /usr/lib/python3/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZNK10tensorflow8OpKernel11TraceStringB5cxx11ERKNS_15OpKernelContextEb

```

Observe above, the TensorFlow instance in `~/.local/lib/python3/` attempting to load a shared library from `/usr/lib/python3/`. Because of different compilation options, the library from the system-wide install is expecting symbols that do not exist in the pip install.

**Describe the expected behavior**

TensorFlow should only load kernels from its own install.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing): modify kernel preloading to only use its own install

**Standalone code to reproduce the issue**

Compile TensorFlow from source and install system-wide.
Install TensorFlow from pip with `pip install --user tensorflow`
Then run `python -c ""import tensorflow""`

**Other info**

This is a continuation of #42978"
51449,dtype of RNN cell's state is changed to tf.float32 during reset_states,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: both win10 and CentOS Linux
-   **TensorFlow installed from (source or binary)**: pip
-   **TensorFlow version (use command below)**: 2.6.0
-   **Python version**: 3.8
-   **Bazel version (if compiling from source)**:
-   **Exact command to reproduce**: see below

### Describe the problem
I have implemented a recurrent cell which is to be wrapped within a `tf.keras.layers.RNN.` The cell has a state whose data type is not `tf.float32` but `tf.complex64`. However, each time when `layer.reset_states()` is invoked, the data type of the state is changed to `tf.float32`. 

I assume, a reason for this issue is line 933, 934 in keras/layers/recurrent.py
```
      flat_states_variables = tf.nest.map_structure(
          backend.variable, flat_init_state_values)
```
Here, the initialized state values are stored in `flat_init_state_values` and `backend.variable` is called on each of the states. However, no `dtype` argument is passed to `backend.variable`. As a consequence it defaults to `tf.float32` for all states. Then a value error is thrown during the initial symbolic call. See attached stack trace. 

I would recommend the following patch, which solves the issue for me
```
      flat_states_variables = tf.nest.map_structure(
    lambda var: backend.variable(var, var.dtype), flat_init_state_values)
```

### Source code / logs
Currently, the example fails at the construction of the RNN layer.
```
import tensorflow as tf

class RecurrentCell(tf.keras.layers.Layer):
    def __init__(self, state_size):
        super(RecurrentCell, self).__init__()
        self.state_size = state_size

    def build(self, input_shape):
        super(RecurrentCell, self).build(input_shape)

    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):
        # explicit initialization with tf.complex64
        return tf.zeros((self.state_size, ), dtype=tf.complex64)

    @tf.function
    def call(self, inputs, states):
        # toy example
        x = inputs
        xfd = tf.signal.rfft(x)[..., :self.state_size]
        yfd = tf.multiply(xfd, states)
        return tf.signal.irfft(yfd), states


recCell = RecurrentCell(state_size=5)

inp = tf.keras.Input(shape=(None, 8),
                     batch_size=32)
out = tf.keras.layers.RNN(recCell,
                          return_sequences=True,
                          stateful=True,
                          return_state=False)(inp)
model = tf.keras.Model(inputs=[inp], outputs=[out])

y = model.predict(tf.random.normal((32, 16, 8)))
```

Stack trace:
[stacktrace.txt](https://github.com/tensorflow/tensorflow/files/6975576/stacktrace.txt)
"
51448,saved_model  bug,"tf version 2.3.2

when  train the model,some features is multi hot,use the split func like this:
```
        def split(x):
            x['seq_grade_clicks'] = tf.strings.split(x['seq_grade_clicks'], sep="":"").to_sparse()
            x['seq_subject_clicks'] = tf.strings.split(x['seq_subject_clicks'], sep="":"").to_sparse()
            x['seq_course_clicks'] = tf.strings.split(x['seq_course_clicks'], sep="":"").to_sparse()
            return x
```

but saved model,and load model
`model = tf.keras.models.load_model(saved_model_dir)`
the errors is
![image](https://user-images.githubusercontent.com/7404433/129173015-dc7a033a-c145-4801-a334-27e6fb88a775.png)

although I specified the name of to_sparse(name=""features""),it also report the above error,

when use `tf.saved_model.load(saved_model_dir)` is ok,but lose the feature name like this:

![image](https://user-images.githubusercontent.com/7404433/129173426-8f7b857c-4c0e-4688-b643-73811726cf41.png)


when use the tf serving ,serving the model ,it also can not konwn the feature name,

when  train the model,some features is multi hot,use the split func like this:
```
        def split(x):
            x['seq_grade_clicks'] = tf.strings.split(x['seq_grade_clicks'], sep="":"").to_tensor()
            x['seq_subject_clicks'] = tf.strings.split(x['seq_subject_clicks'], sep="":"").to_tensor()
            x['seq_course_clicks'] = tf.strings.split(x['seq_course_clicks'], sep="":"").to_tensor()
            return x
```
![image](https://user-images.githubusercontent.com/7404433/129179798-70a5974d-7025-4d02-9418-c76f3c344b85.png)

everything is ok ,but when use the tf serving ,serving the model or predict, it can not batch infer ,because some features is multi hot and is variable length, but the tensor is fixed length

"
51447,Error initializing parameters when inheriting from tf.keras.model！！！！,"env: tf2.2,  linux

**If there are two input parameters inherited from the tf.keras.model class and one of them is of bool type, it will directly report an error like this:**
![1628757059(1)](https://user-images.githubusercontent.com/34124260/129164925-5ca64255-cd04-45fe-978d-1cf8f4d42a27.png)

**However, the interesting thing is that if there are three input parameters and the third parameter has no effect, it will be correct，like this：**
![1628757177(1)](https://user-images.githubusercontent.com/34124260/129165214-ffe000af-e70a-46bd-bb78-2f11694680da.png)
![1628757205(1)](https://user-images.githubusercontent.com/34124260/129165314-a2ff8e99-45a0-4634-bb44-5eb6c7efb33b.png)
**If it has only one initial input, there will be no error if it is of bool type**

This is an interesting question. I don't know whether there is a problem with my environment or whether there is a small bug in the code"
51446,AttributeError: 'Operation' object has no attribute '_c_op',"tensorflow2.1
File ""run.py"", line 118, in <module>
    imgs_mask_test = model.predict(imagestest, verbose=1)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1013, in predict
    use_multiprocessing=use_multiprocessing)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 498, in predict
    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 475, in _model_iteration
    total_epochs=1)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 85, in distributed_function
    per_replica_function, args=args)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 763, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1819, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2164, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 212, in _predict_on_batch
    result = predict_on_batch(model, x)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 556, in predict_on_batch
    return predict_on_batch_fn(inputs)  # pylint: disable=not-callable
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 778, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 717, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 891, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 778, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 209, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 1135, in __call__
    return self.conv_op(inp, filter)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 640, in __call__
    return self.call(inp, filter)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py"", line 616, in _with_space_to_batch_call
    block_shape=self.dilation_rate)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 3303, in required_space_to_batch_paddings
    const_block_shape = tensor_util.constant_value(block_shape)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py"", line 827, in constant_value
    ret = _ConstantValue(tensor, partial)
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py"", line 673, in _ConstantValue
    if tensor.op.type == ""Const"":
  File ""/home/ma-user/anaconda3/envs/TensorFlow-2.1.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 2220, in type
    return c_api.TF_OperationOpType(self._c_op)
AttributeError: 'Operation' object has no attribute '_c_op'
I got this error, how to solve it?thank you."
51445,DLPack Tensor is only supported in TF Eager Mode now right? ,
51444,Incorrect metrics for ragged tensor as output,"**System information**
- OS Platform: Windows 10
- TensorFlow installed from pip, version 2.5.0
- Python version: 3.8

**Describe the current behavior**
The metrics for the ragged tensors are calculating incorrectly. 

**Standalone code to reproduce the issue**
The model:

```
class dummy(tf.keras.Model):
    def __init__(self):
        super(dummy, self).__init__()

    def call(self, inputs):
        lens = tf.map_fn(lambda x: len(x), inputs, fn_output_signature=tf.int32, name='get_lengths')
        tensored_input = inputs.to_tensor(0, shape=[None, 10])
        x = Lambda(lambda x: tf.cast(x, dtype=tf.float32))(tensored_input)
        outputs = tf.RaggedTensor.from_tensor(x, lengths=lens)
        return outputs
```

Running:
```
x_dataset = tf.data.Dataset.from_tensor_slices( tf.ragged.constant([[0,0,0,0,0],[0],[0,0,0],[0,0,0,0]]))
y_dataset = tf.data.Dataset.from_tensor_slices( tf.ragged.constant([[1,1,1,1,1],[1],[1,1,1],[1,1,1,1]]))
tensor_dataset = tf.data.Dataset.zip((x_dataset, y_dataset))
# Create batches
batched_ds = tensor_dataset.batch(2, drop_remainder=True)

model = dummy()
model.compile(loss='binary_crossentropy',metrics=['accuracy'])
history = model.fit(batched_ds,epochs=2)
```
Result (history.history) - 100% accuracy despite clear dismatches.

`
{'loss': [15.424947738647461, 15.424947738647461], 'accuracy': [1.0, 1.0]}
`
"
51443,n-api supports automatic downgrade instead of hard-coded,"### background
I used @tensorflow/tfjs-node to build a coding service, but the deployment failed due to the inconsistency of the node version during build and runtime.

Uncontrollable node version during build and runtime

### for example：

build：node v12.19.1 corresponds to N-API 7
runtime ：node v12.22.3 corresponds to N-API 8

### result：
""The Node.js native addon module (tfjs_binding.node) can not be found at path: /code/node_modules/_@tensorflow_tfjs-node@3.8.0@@tensorflow/tfjs-node/lib/napi-v8/tfjs_binding.node.""

### feature Request：

The higher version of n-api will automatically be compatible with the lower version, but [here](https://github.com/tensorflow/tfjs/blob/e36545270e8176aa14d03e82ccf2baf6e9693f69/tfjs-node/package.json#L84) is hard to write 




"
51441,dlopen/dlclose a so file which contain tensorflow static library cause memory leak,"In our scenario, there is only one process to serve the request, and the process will be closed only when an exception occurs. Each model inference algorithm is complied into a so file and loaded into this process.  Multiple model inference algorithms will be loaded in this process. Each so file contain a tensorflow static library.

In the service, the so file of different model inference algorithms (model _ 1.so...) will often be loaded and closed through dlopen and dlclose. Because some static variables in tensorflow are created through the “new” method , as shown below. When closing the “so” with dlclose，these static variables will not be released， which will cause memory leaks.
```
    typedef std::unordered_map<string, SessionFactory*> SessionFactories;     
    SessionFactories* session_factories() {
        static SessionFactories* factories = new SessionFactories;
        return factories;
    }
```

```
    DirectSession* session = new DirectSession(options, new StaticDeviceMgr(std::move(devices)), this);
    {
        mutex_lock l(sessions_lock_);
        sessions_.push_back(session);
    }
    *out_session = session;
    return Status::OK();
```

What is the purpose of tensorflow designed like this？Will it be optimized for this problem in the future?
"
51440,tf.identity cannot support a tuple value,"I have recently use v1.13 of Tensorflow.
In my code:
```
topk = tf.nn.top_k(out_softmax, k=100)
with tf.control_dependencies([some ops]):
      topk = tf.identity(topk)
      # topk[0] = tf.identity(topk[0])
      # topk[1] = tf.identity(topk[1])
```
it shows ： 
```
TypeError: Cannot convert a list containing a tensor of dtype <dtype: 'int32'> to <dtype: 'float32'> (Tensor is: <tf.Tensor 'Xpredict__scope__/TopKV2:1' shape=(?, 100) dtype=int32>)
````

or 

```
TypeError: 'TopKV2' object does not support item assignment
```
how can i fix it ?"
51438,SparseTensorToCSRSparseMatrix wastes so much time on cpu,"tensorflow 2.5

```

import tensorflow as tf
import numpy as np
import datetime
from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops

a_indices = np.array([[0, 0], [2, 3], [2, 4], [3, 0]])
a_values = np.array([1.0, 5.0, -1.0, -2.0], np.float32)
a_dense_shape = [4, 5]

b_indices = np.array([[0, 0], [3, 0], [3, 1]])
b_values = np.array([2.0, 7.0, 8.0], np.float32)
b_dense_shape = [5, 3]


stamp = datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
logdir = 'logs/csrmatrix_test/%s' % stamp
tf.profiler.experimental.start(logdir)

with tf.profiler.experimental.Trace(""Train"", step_num=0):
    # with tf.device('/gpu:0'):
        # with tf.compat.v1.Session() as sess:
            # Define (COO format) Sparse Tensors over Numpy arrays
    a_st = tf.sparse.SparseTensor(a_indices, a_values, a_dense_shape)
    b_st = tf.sparse.SparseTensor(b_indices, b_values, b_dense_shape)

    # Convert SparseTensors to CSR SparseMatrix
    a_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
        a_st.indices, a_st.values, a_st.dense_shape)
    b_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
        b_st.indices, b_st.values, b_st.dense_shape)

    # Compute the CSR SparseMatrix matrix multiplication
    c_sm = sparse_csr_matrix_ops.sparse_matrix_sparse_mat_mul(
        a=a_sm, b=b_sm, type=tf.float32)

    # Convert the CSR SparseMatrix product to a dense Tensor
    c_sm_dense = sparse_csr_matrix_ops.csr_sparse_matrix_to_dense(
        c_sm, tf.float32)
    # Evaluate the dense Tensor value
    # c_sm_dense_value = sess.run(c_sm_dense)

    print(c_sm_dense)
tf.profiler.experimental.stop()
```

### trace
![Screenshot from 2021-08-12 08-09-44](https://user-images.githubusercontent.com/12267324/129119243-edb879ee-6300-480d-b7ed-406f0277e116.png)

I wonder why **sparse_tensor_to_csr_sparse_matrix** and **sparse_matrix_sparse_mat_mul** is calculated on both cpu and gpu because theoretically they should be calculated on gpu only for the sake of performance acceleration. Also, I've found the corresponding code [sparse_mat_mul_op](https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/core/kernels/sparse/sparse_mat_mul_op.cc#L534) and [csr_sparse_matrix_to_dense_op](https://github.com/tensorflow/tensorflow/blob/0b6b491d21d6a4eb5fbab1cca565bc1e94ca9543/tensorflow/core/kernels/sparse/csr_sparse_matrix_to_dense_op.cc#L211) for gpu version. But unexpectedly, the calculation is placed on both the cpu and gpu for twice, so is it the duplicate calcualtion?"
51437,AUC in the Classification on imbalanced data tutorial ,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#check_training_history_2

## Description of issue (what needs changing):
In the documentation, the resampled model has the highest AUC, as shown below, but [the chart](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#plot_the_roc_3) shows that the baseline AUC is the highest. I think the AUC calculated by model.evaluate method may be incorrect.

>Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives.

```
# AUC calculated by model.evaluate method

# baseline
0.9296237826347351

# weighted
0.9428448677062988

# resampled
0.9575912952423096
```

I have tried other methods to check the correct value. The result of calculating the AUC using the sklearn.metrics.roc_auc_score method is as follows. As expected, it can be confirmed that the AUC of the baseline is the highest.

```
# AUC calculated by sklearn.metrics.roc_auc_score method

baseline_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_baseline) 
weighted_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_weighted)  
resampled_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_resampled) 

# baseline
0.9685415795364084

# weighted
0.9387766618590307

# resampled
0.9665411665226982
```

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

After confirming this issue with other people, I will make a pull request.

"
51433,How to add ARG_MAX operation in tensorflow lite android with GPU ?,"I am working with tensorflow 2.5.0. I take a 4d tensor and perform argmax in a lambda function:

```python
def activate_postprocess(tensor):
  res = []
  for i in range(k):
    res.append(tf.argmax(tensor[i]))
  return res

post_processe_layer = tf.keras.layers.Lambda(activate_postprocess)
post_processed_output = post_processed_layer(model.outputs)
```

then I convert, adding `TFLITE_BUILTINS` and `SELECT_TF_OPS`:

```python
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                             tf.lite.OpsSet.SELECT_TF_OPS
                                             ]
    tflite_model = converter.convert()
```

And then I run in the Android app, with GPU delegate

```
val options = Interpreter.Options()
val compatList = CompatibilityList()
val delegateOptions = compatList.bestOptionsForThisDevice
                gpuDelegate = GpuDelegate(delegateOptions)
                options.addDelegate(gpuDelegate)
```

After running the model, I receive the following error:
```
Failed for 'img.jpg' with error: Internal error: Failed to apply delegate: Following operations are not supported by GPU delegate:
    ARG_MAX: Operation is not supported.
```
I also tried `options.setUseNNAPI(true) `before creating the interpreter, but it doesn't help.
How can I solve it? 

I see this: https://www.tensorflow.org/lite/guide/ops_custom
But I don't understand how to register the operator (https://www.tensorflow.org/lite/guide/ops_custom#create_and_register_the_operator) 

Is there an example with argmax? 

Thanks



"
51431,AutoGraph warning when using auto-keras,"I was running auto-keras StructuredDataRegressor in Kaggle notebook, when this warning appeared:

WARNING: AutoGraph could not transform function <function Model.make_train_function.<locals>.train_function at ... and will run it as-is.
Please report this to the TensorFlow team.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()

The search for regression model seams to be working, but the warning appears at every trial.

This is the dataset I was using: https://www.kaggle.com/c/tabular-playground-series-aug-2021

And this is the code:

!pip install autokeras
import pandas as pd
import numpy as np
from sklearn.preprocessing import QuantileTransformer
from sklearn.model_selection import train_test_split
import tensorflow as tf
import autokeras as ak

TRAIN_PATH = '../input/tabular-playground-series-aug-2021/train.csv'
TARGET_NAME = 'loss'
VAL_SIZE = 0.2

data_train = pd.read_csv(TRAIN_PATH)

X = data_train.drop('id', axis='columns')
y = X.pop(TARGET_NAME)

scaler = QuantileTransformer(output_distribution='normal')
X = scaler.fit_transform(X)

groups = pd.cut(
    y, bins=10, labels=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

x_train, x_valid, y_train, y_valid = train_test_split(
    X, y, stratify=groups, test_size=VAL_SIZE,
    shuffle=True, random_state=0)

model = ak.StructuredDataRegressor(
    overwrite=False, max_trials=100)

model.fit(x_train, y_train, epochs=1,
          validation_data=(x_valid, y_valid))"
51430,Conversion fails at model loading,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.7
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): v2.6.0-rc2

### 2. Code

`converter = tf.lite.TFLiteConverter.from_saved_model(str(SAVED_MODEL_DIR))`

Where `SAVED_MODEL_DIR` is a path which contains an efficientnet-b4 in the expected `SavedModel` format.

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

N.A

### 4. (optional) RNN conversion support

N.A

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[output.log](https://github.com/tensorflow/tensorflow/files/6969158/output.log)

```
Traceback (most recent call last):
  File ""convert_to_tflite.py"", line 92, in <module>
    main()
  File ""convert_to_tflite.py"", line 74, in main
    converter = tf.lite.TFLiteConverter.from_saved_model(str(SAVED_MODEL_DIR))
  File ""/home/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1348, in from_saved_model
    saved_model = _load(saved_model_dir, tags)
  File ""/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 864, in load
    result = load_internal(export_dir, tags, options)[""root""]
  File ""/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 903, in load_internal
    ckpt_options, options, filters)
  File ""/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 162, in __init__
    self._load_all()
  File ""/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 259, in _load_all
    self._load_nodes()
  File ""/home/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py"", line 448, in _load_nodes
    slot_variable = optimizer_object.add_slot(
AttributeError: '_UserObject' object has no attribute 'add_slot'
```"
51429,Problem with mean OpenGL since 2.5 version,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 11 oct 5 2020
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 2 XL
- TensorFlow installed from (source or binary): Java modules. Also try to compile from sources and run using C++ API.
- TensorFlow version (use command below): 2.5
- GPU model and memory: Adreno 540 / 4GB RAM

**Describe the current behavior**

I have model, which makes something like chroma key. It returns 1 for pixel, where is person on image and 0 for other pixels. Starting with version 2.5, when I started recording to file, I have wrong output of model for some frames with OpenGL delegate. It looks like flashing. I attached video. I double check inputs, they are correct. Also for version 2.4 or 2.3 it works correct.

**Describe the expected behavior**

TFL 2.5 works the same as 2.4, without wrong output for my model.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

On my device TFL uses OpenGL. I compared code version 2.5 and 2.3 and I found, what the reason of my problem is mean (/tensorflow/lite/delegates/gpu/gl/kernels/mean.cc). For version 2.5 mean uses GenerateTiledMean function for calculation, if I forced call GenerateTrivialMean instead of GenerateTiledMean, all works correct for me.
Also I have this problem only if I record output to file. For preview (without recording to file) it works perfect. I think there is problem with synchronisation or data race. I tryed to fix shader of GenerateTiledMean, but I didn't succeed.
As solution I can sugguest can disable GenerateTiledMean for Adreno, because many of other phones with Adreno use OpenCL.

`   } else if (UseTiledImpl(ctx) && !ctx.gpu_info->IsAdreno()) {`


I forgot one thing. If I force use SSBO instead of texture it fix my problem. But with SSBOs work slower, I think it is a reason, why TFL use texture for Adreno. 

**Other info / logs**

I don't have any tfl errors in log.

https://user-images.githubusercontent.com/9623833/129029414-0ca2adf7-25b4-43c4-983d-771d1754c3c2.mov

"
51428,"GPU performance issue when calling slicing for tensors of types tf.int16, tf.int32 (op StridedSlice)","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- binary wheel via PyPI
- TensorFlow version (use command below):
- v2.5.0-0-ga4dfb8d1a71 2.5.0
- Python version:
- 3.6
- CUDA/cuDNN version:
- CUDA 11.2
- GPU model and memory:
- V100 32 GB

**Describe the current behavior**
When slicing tensors of shape int16 or int32 it takes significant amount of time comparing to float16, float32
*****************************************************
type array: <dtype: 'int16'>
took 35.05420684814453
*****************************************************
type array: <dtype: 'int32'>
took 22.861242294311523
*****************************************************
type array: <dtype: 'int64'>
took 5.330085754394531
*****************************************************
type array: <dtype: 'float16'>
took 1.550912857055664
*****************************************************
type array: <dtype: 'float32'>
took 2.5637149810791016
*****************************************************
type array: <dtype: 'float64'>
took 5.917549133300781
*****************************************************
type array: <dtype: 'bool'>
took 1.6639232635498047

**Describe the expected behavior**
takes around the same time as the float versions

**[Contributing](https://www.tensorflow.org/community/contribute)**
- Do you want to contribute a PR? (yes/no): no

when running the code using tf.debugging.set_log_device_placement(True) found that slicing int16 is not using gpu at all:
type array: <dtype: 'int16'>
Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0
Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0
Executing op StridedSlice in device /job:localhost/replica:0/task:0/device:CPU:0

for int32 I don't understand the reason for such difference comparing to float32

**Standalone code to reproduce the issue**
```
import tensorflow as tf
# tf.debugging.set_log_device_placement(True)
import numpy as np
import time

def test_slicing():

    with tf.device('/GPU:0'):
      shape = (52000, 2, 15, 15)
      np_array = np.ones(shape, dtype=np.uint16)

      dtypes= [tf.uint16, tf.int16, tf.int64, tf.float16, tf.float32, tf.float64, tf.bool]
      start = 0
      end = 50000
      for dtype in dtypes:
        print(""*****************************************************"")

        tf_array = tf.constant(np_array, dtype=dtype) * 1 if dtype != tf.bool else tf.math.logical_and(tf.constant(np_array, dtype=dtype) , tf.constant(np_array, dtype=dtype)) 
        print(f'type array: {tf_array.dtype}')
        
        for i in range(1):
            tf_array = tf.constant(np_array, dtype=dtype) * 1 if dtype != tf.bool else tf.math.logical_and(tf.constant(np_array, dtype=dtype) , tf.constant(np_array, dtype=dtype)) 

            tic = time.time()
            a = tf_array[start:end]
            a[0][0][0][0].numpy()
            toc = time.time()
            print(f'took {(toc - tic)*1000}')

print()          
print(tf.version.GIT_VERSION, tf.version.VERSION)
test_slicing()
```
"
51427,tensorflow distribute trainning error,"I just follow mnist_replica.py to write distribution code,when there is bug when run programs.It always report that RuntimeError: Init operations did not make model ready. How to fix it ?
It seemed when it call prepare_or_wait_for_session and failed
Codes as such below:
 ```
 if FLAGS.sync_replicas:
            if FLAGS.replicas_to_aggregate is None:
                replicas_to_aggregate = self.num_workers
            else:
                replicas_to_aggregate = FLAGS.replicas_to_aggregate
            self.opt = tf.train.SyncReplicasOptimizer(
                self.opt,
                replicas_to_aggregate=replicas_to_aggregate,
                total_num_replicas=self.num_workers,
                name=""sync"")

        self.optimizer = self.opt.minimize(self.loss, global_step=self.global_step)

        # init
        if FLAGS.sync_replicas:
            self.local_init_op = self.opt.local_step_init_op  
            if self.is_chief:
                self.local_init_op = self.opt.chief_init_op  

            self.ready_for_local_init_op = self.opt.ready_for_local_init_op 
            self.chief_queue_runner = self.opt.get_chief_queue_runner()  
            self.sync_init_op = self.opt.get_init_tokens_op()  

        self.global_var_init_op = tf.global_variables_initializer()
        self.train_auc_value, self.train_auc_op = tf.metrics.auc(self.label, self.out, name=""train_auc"" + str(FLAGS.task_index))
        self.valid_auc_value, self.valid_auc_op = tf.metrics.auc(self.label, self.out, name=""valid_auc"" + str(FLAGS.task_index))
        self.local_var_init_op = tf.local_variables_initializer()
if FLAGS.sync_replicas:
            sv = tf.train.Supervisor(
                is_chief=is_chief,
                logdir=train_dir,
                init_op=deepfm.global_var_init_op,
                local_init_op=deepfm.local_init_op,
                ready_for_local_init_op=deepfm.ready_for_local_init_op,
                recovery_wait_secs=1,
                global_step=deepfm.global_step)
sess = sv.prepare_or_wait_for_session(server.target, config=sess_config)

```"
51426,Can MLIR be disabled ?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.4
- Python version: 3.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
We compile tensorflow2.4 from source on our new architecture. Bus Error is reported while compiling MLIR. Is MLIR architecture related, and can it be disabled ?

Error log:
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -I/home/loongson/.cache/bazel/_bazel_loongson/1cc7edea620980ed4eb3fa576dab960a/external/local_config_cc -I/usr/opencv3/include -I/usr/caffe/include -MD -MF bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.d '-frandom-seed=bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o' -fPIC -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquote external/llvm-project -iquote bazel-out/loongarch64-opt/bin/external/llvm-project -iquote external/zlib -iquote bazel-out/loongarch64-opt/bin/external/zlib -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVAvailabilityIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVCanonicalizationIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpUtilsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVSerializationGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen -isystem external/llvm-project/mlir/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/include -isystem external/llvm-project/llvm/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/loongarch64-opt/bin/external/zlib -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=native' -Wno-sign-compare '-std=c++14' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/llvm-project/mlir/lib/Dialect/SPIRV/SPIRVDialect.cpp -o bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o)
Execution platform: @local_execution_config_platform//:platform
/tmp/ccHVDr8f.s: Assembler messages:
/tmp/ccHVDr8f.s:203387: Internal error (Bus error).


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
51425,import error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10
- TensorFlow version: 1.15
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: conda
- GPU model and memory: CPU



**Describe the problem**
Getting error while importing tensorflow

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

![Capture](https://user-images.githubusercontent.com/43055935/128979222-c29efaba-82db-451e-aef0-134e16b9a7d2.PNG)

"
51422,TfLiteGpuDelegate Init: CONCATENATION: Node 2 is already a consumer of the value 0,"2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Following operations are not supported by GPU delegate:
    DEPTH_TO_SPACE: Operation is not supported.
    DEQUANTIZE: 
    13 operations will run on the GPU, and the remaining 23 operations will run on the CPU.
2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: TfLiteGpuDelegate Init: CONCATENATION: Node 2 is already a consumer of the value 0
2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution I/tflite: Created 0 GPU delegate kernels.
2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: TfLiteGpuDelegate Prepare: delegate is not initialized
2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Node number 36 (TfLiteGpuDelegateV2) failed to prepare.
2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Restored original execution plan after delegate application failure.
2021-08-10 20:31:39.969 15740-15740/org.tensorflow.lite.examples.superresolution E/super_resolution::: Failed to create TFLite interpreter
"
51421,Depth_to_space,"**System information**
- OS Platform and Distribution (e.g., mac):
- TensorFlow installed from (tensorflow 2.5):
- TFLite: 2.5.0

2021-08-10 20:31:39.968 15740-15740/org.tensorflow.lite.examples.superresolution E/tflite: Following operations are not supported by GPU delegate:
    DEPTH_TO_SPACE: Operation is not supported.
    DEQUANTIZE: 
    13 operations will run on the GPU, and the remaining 23 operations will run on the CPU.


"
51420,Loading checkpoint by skipping the head layer,"Hi all!

I am using a model (SimCLR) to learn representations from images. While pre-training, the model was trained against a single dummy label. Now I want to fine-tune the model with 8-class data. 
While loading the pre-trained model checkpoint to the yet to be fine-tuned model with 8-class head I am encountering a ValueError.

```
ValueError: Tensor's shape (2048, 1) is not compatible with supplied shape [2048, 8]
```

Is there a solution to exclude the last head layer weights before loading to the checkpoint for fine-tuning the model?
If not, this would be a feature request.

------------------------

### System information

-   **TensorFlow version**: 2.5.0
-   **Python version**: 3.7.3

------------------------

Detailed error log:
```
run.py:581 single_step  *
        projection_head_outputs, supervised_head_outputs = model(
    /home/uil139/code/simclr/tf2/model.py:269 __call__  *
        supervised_head_outputs = self.supervised_head(supervised_head_inputs,
    /home/uil139/code/simclr/tf2/model.py:224 call  *
        inputs = self.linear_layer(inputs, training)
    /home/uil139/code/simclr/tf2/model.py:152 call  *
        inputs = self.dense(inputs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1023 __call__  **
        self._maybe_build(inputs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2625 _maybe_build
        self.build(input_shapes)  # pylint:disable=not-callable
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py:1198 build
        trainable=True)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:655 add_weight
        caching_device=caching_device)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:815 _add_variable_with_custom_getter
        **kwargs_for_getter)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:139 make_variable
        shape=variable_shape if variable_shape else None)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:260 __call__
        return cls._variable_v1_call(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call
        shape=shape)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/shared_variable_creator.py:69 create_new_variable
        v = next_creator(**kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2111 creator_with_resource_vars
        created = self._create_variable(next_creator, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:538 _create_variable
        distribute_utils.VARIABLE_POLICY_MAPPING, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_utils.py:306 create_mirrored_variable
        value_list = real_mirrored_creator(**kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:530 _real_mirrored_creator
        v = next_creator(**kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter
        return captured_getter(captured_previous, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:752 variable_capturing_scope
        lifted_initializer_graph=lifted_initializer_graph, **kwds)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:264 __call__
        return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:293 __init__
        initial_value = initial_value()
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:87 __call__
        self._checkpoint_position, shape, shard_info=shard_info)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:122 __init__
        self.wrapped_value.set_shape(shape)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1240 set_shape
        (self.shape, shape))

    ValueError: Tensor's shape (2048, 1) is not compatible with supplied shape [2048, 8]
```"
51419,tf.reduce_sum is hard to use in a numerical stable way,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

### Edited to add:

As 1st comment clarifies, the described behavior is probably ""working as intended"" due to accumulation of floating point errors, which is mitigated in many common cases but not all cases, leading to surprising inconsistency.

However, I still think at least 2 things could be improved:

- `tf.reduce_sum` could include a note in its documentation explaining this behavior, like [`np.sum`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html)
- `tf.reduce_sum` could take a `dtype` parameter to improve precision of the accumulator and output without needing to increase precision of the entire input tensor, also like [`np.sum`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html)

Original report follows.

---

**System information**
This bug is reproducible on standard Colab, so I've only included the following as system information:
- TensorFlow version: 2.5.0
- Python version: 3.7.11

**Code to reproduce**

```python
with tf.device(""cpu:0""):
  print(tf.reduce_sum(tf.ones((20_000_000, 2)), axis=0))
```

Full reproduction in colab on a GPU-enabled VM: https://gist.github.com/nfelt/e6edc45736740ed899eea95a36bea359

**Describe the current behavior**

On CPU, `tf.reduce_sum` on a rank-2 float32 tensor, along an axis containing more than 2^24 elements of value 1.0, emits an incorrect output that is truncated to 2^24 (the maximum integer precisely representable in float32).  I.e. the above code emits `tf.Tensor([16777216. 16777216.], shape=(2,), dtype=float32)`.

**Describe the expected behavior**

It should emit the same answer that it does in pretty much every other context, which is the numerically correct answer up to floating point representation error, in this case `tf.Tensor([20000000. 20000000.], shape=(2,), dtype=float32)`.

In particular, we get the expected answer in all of the following situations:
- Running `reduce_sum` on GPU instead of CPU
- Using `float64` instead of `float32`
- Summing a rank-1 tensor of more than 2^24 elements of value 1.0
- Summing a rank-2 tensor along an axis with fewer than 2^24, but individually larger, elements, e.g. `tf.reduce_sum(tf.ones((10_000_000, 2)) * 2.0, axis=0)`
  
**Notes**

It seems like the problem of stopping at 2^24 is affecting the count of how many elements get summed, rather than the actual sum itself, based on these cases:

```python
with tf.device(""cpu:0""):
  print(tf.reduce_sum(tf.ones((20_000_000, 2)) * 0.5, axis=0))
>>> tf.Tensor([8388608. 8388608.], shape=(2,), dtype=float32)
```

In particular, it seems to only include the trailing 2^24 elements, based on this:

```python
tensor_with_one_big_value = tf.concat([[[10_000_000, 0]], tf.ones((20_000_000, 2))], axis=0)
with tf.device(""cpu:0""):
  print(tf.reduce_sum(tensor_with_one_big_value, axis=0))
with tf.device(""cpu:0""):
  print(tf.reduce_sum(tf.reverse(tensor_with_one_big_value, axis=[0]), axis=0))
>>> tf.Tensor([16777216. 16777216.], shape=(2,), dtype=float32)
>>> tf.Tensor([26777216. 16777216.], shape=(2,), dtype=float32)
```

"
51418,Cannot properly install packages inside container ,"So I can run the Tensorflow Docker image without issue. However, I have one issue, I know that I am not suppose to run it as root so I run it under my user. When I do this and then try to install packages I get the following message:

`WARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.`

The packages seem to install fine but when I go to import them they are not found. 

However, if I run the image as root, there is absolutely no issue and it works fine. 
Ive searched and I can't seem to find an answer for this issue, I am running the latest stable version. 
"
51417,Incorrect Results of MatMul on TFLite with GPU Delegate,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung S10e
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): master
- Python version: 3.8.10
- Bazel version (if compiling from source): 4.0.0
- GCC/Compiler version (if compiling from source): 10.2.0
- CUDA/cuDNN version: 11.4
- GPU model and memory: RTX 2080 Ti 11GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`: v1.12.1-59750-g417a4452453 2.7.0


**Describe the current behavior**

I create a very simple model with only one `reshape` operator and one `matmul` operator. It seems that the TFLite converter will remove the reshape operator but keep the shape before the reshape operator, which is not a problem on CPU but however will cause incorrect results on GPU delegate.

We can visualize the model using netron and one of the inputs for `FullyConnected` op is 3-dimensional, while this may not be the problem since reshaping tensor may just be another view of the data in the memory, it does produce incorrect results when using it with GPU delegate (see below).

**Describe the expected behavior**
On GPU delegate, it should produce the correct results.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): Yes
- Briefly describe your candidate solution(if contributing): I haven't got a chance to view the codebase of FullyConnected op yet but I am willing to help :) I guess there are two possible solutions:
  - Let TFLite converter keep the reshape operator
  - Let TFLite interpreter able to handle such case

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


The python code to generate the model:
```python
import tensorflow as tf

tfv1 = tf.compat.v1


def convert_to_tflite_model(path: str, graph: tf.Graph, input_tensors, output_tensors, use_fp16_optimization=False):
  with graph.as_default(), tfv1.Session(graph=graph) as session:
    session.run(tfv1.global_variables_initializer())
    converter = tfv1.lite.TFLiteConverter.from_session(
      session, input_tensors=input_tensors, output_tensors=output_tensors)
    if use_fp16_optimization:
      converter.optimizations = [tf.lite.Optimize.DEFAULT]
      converter.target_spec.supported_types = [tf.float16]

    with open(path, ""wb"") as writer:
      writer.write(converter.convert())


def generate_matmul_tflite_model(basename: str,
                                 use_fp16_optimization=False):
  with tf.Graph().as_default() as graph:
    a = tfv1.placeholder(tf.float32, shape=[2, 8, 4], name=""a"")
    w = tfv1.get_variable(""w"", shape=[16, 4], dtype=tf.float32)
    s = tfv1.reshape(a, [2 * 8, -1])
    c = tfv1.matmul(s, w, transpose_b=True)

    convert_to_tflite_model(basename + '.tflite', graph, [a, w], [c],
                            use_fp16_optimization=use_fp16_optimization)


def main():
  generate_matmul_tflite_model(""matmul"", use_fp16_optimization=False)


if __name__ == ""__main__"":
  main()
``` 

We can visualize it in [netron](https://netron.app):

![Screenshot_20210810_174759](https://user-images.githubusercontent.com/23658877/128939552-6a8de325-0d4e-4cae-9077-55cd59e63cf4.png)

As you can see one of the inputs to the `FullyConnected` is 3-dimensional and the reshape op just get disappeared.

Then we can use the tool `run_delegate_testing.sh` to test the model (should change the kMaxPrint to 100 since the first 16 elements are correct):
```shell
$ tensorflow/lite/delegates/gpu/cl/testing/run_delegate_testing.sh -m matmul.tflite
```

The patch to modify the `kMaxPrint`:
```c++
diff --git a/tensorflow/lite/delegates/gpu/cl/testing/delegate_testing.cc b/tensorflow/lite/delegates/gpu/cl/testing/delegate_testing.cc
index eb924406ecd..d17b8a9c5bc 100644
--- a/tensorflow/lite/delegates/gpu/cl/testing/delegate_testing.cc
+++ b/tensorflow/lite/delegates/gpu/cl/testing/delegate_testing.cc
@@ -69,7 +69,7 @@ void CompareCPUGPUResults(tflite::Interpreter* cpu, tflite::Interpreter* gpu,
 
     std::cout << ""Output "" << tensor_ptr->name << "":"" << std::endl;
 
-    const int kMaxPrint = 10;
+    const int kMaxPrint = 100;
     int printed = 0;
     int total_different = 0;
     for (int k = 0; k < tensor_elements_count; ++k) {
```

Please refer to the log below.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
INFO: Replacing 1 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 1 partitions.
INFO: Initialized OpenCL-based API.
INFO: Created 1 GPU delegate kernels.
Output MatMul:
Element #0: CPU value - 1.55481, GPU value - 1.55469, abs diff - 0.000122547
Element #1: CPU value - -0.968265, GPU value - -0.967773, abs diff - 0.000491381
Element #3: CPU value - 1.34608, GPU value - 1.3457, abs diff - 0.000380635
Element #4: CPU value - -1.47071, GPU value - -1.46973, abs diff - 0.00098145
Element #5: CPU value - 0.576554, GPU value - 0.576172, abs diff - 0.000382423
Element #6: CPU value - 0.716986, GPU value - 0.716309, abs diff - 0.000677407
Element #7: CPU value - -1.51386, GPU value - -1.5127, abs diff - 0.00116575
Element #8: CPU value - 1.26207, GPU value - 1.26074, abs diff - 0.00132298
Element #9: CPU value - -0.136021, GPU value - -0.135742, abs diff - 0.000278458
Element #10: CPU value - -1.08425, GPU value - -1.08398, abs diff - 0.000262737
Element #11: CPU value - 1.55344, GPU value - 1.55273, abs diff - 0.000708699
Element #12: CPU value - -0.946549, GPU value - -0.946289, abs diff - 0.000260055
Element #13: CPU value - -0.316031, GPU value - -0.315918, abs diff - 0.000113398
Element #14: CPU value - 1.35969, GPU value - 1.35938, abs diff - 0.00031805
Element #15: CPU value - -1.46148, GPU value - -1.46094, abs diff - 0.000540376
Element #16: CPU value - -0.968265, GPU value - 1.26074, abs diff - 2.22901
Element #17: CPU value - 2.00199, GPU value - -1.80371, abs diff - 3.8057
Element #18: CPU value - -1.64891, GPU value - 1.09766, abs diff - 2.74657
Element #19: CPU value - 0.153611, GPU value - 0.369385, abs diff - 0.215774
Element #20: CPU value - 1.4481, GPU value - -1.58105, abs diff - 3.02915
Element #21: CPU value - -2.04669, GPU value - 1.69629, abs diff - 3.74298
Element #22: CPU value - 1.22751, GPU value - -0.637695, abs diff - 1.86521
Element #23: CPU value - 0.441976, GPU value - -0.863281, abs diff - 1.30526
Element #24: CPU value - -1.80531, GPU value - 1.76562, abs diff - 3.57093
Element #25: CPU value - 1.91808, GPU value - -1.44531, abs diff - 3.36339
Element #26: CPU value - -0.702171, GPU value - 0.123291, abs diff - 0.825462
Element #27: CPU value - -1.00014, GPU value - 1.2832, abs diff - 2.28334
Element #28: CPU value - 2.00964, GPU value - -1.80273, abs diff - 3.81237
Element #29: CPU value - -1.62704, GPU value - 1.07227, abs diff - 2.6993
Element #30: CPU value - 0.117366, GPU value - 0.400391, abs diff - 0.283024
Element #31: CPU value - 1.4736, GPU value - -1.59473, abs diff - 3.06833
Element #32: CPU value - -0.28901, GPU value - -0.967773, abs diff - 0.678764
Element #33: CPU value - -1.64891, GPU value - 2, abs diff - 3.64891
Element #34: CPU value - 2.44461, GPU value - -1.64648, abs diff - 4.09109
Element #35: CPU value - -1.5469, GPU value - 0.152832, abs diff - 1.69973
Element #36: CPU value - -0.422372, GPU value - 1.44727, abs diff - 1.86964
Element #37: CPU value - 2.09906, GPU value - -2.04492, abs diff - 4.14398
Element #38: CPU value - -2.3217, GPU value - 1.22656, abs diff - 3.54826
Element #39: CPU value - 0.936071, GPU value - 0.441895, abs diff - 0.494176
Element #40: CPU value - 1.09799, GPU value - -1.80371, abs diff - 2.9017
Element #41: CPU value - -2.37146, GPU value - 1.91602, abs diff - 4.28747
Element #42: CPU value - 2.00219, GPU value - -0.701172, abs diff - 2.70336
Element #43: CPU value - -0.245977, GPU value - -0.999023, abs diff - 0.753046
Element #44: CPU value - -1.68062, GPU value - 2.00781, abs diff - 3.68844
Element #45: CPU value - 2.44303, GPU value - -1.625, abs diff - 4.06803
Element #46: CPU value - -1.51312, GPU value - 0.117432, abs diff - 1.63056
Element #47: CPU value - -0.464946, GPU value - 1.47168, abs diff - 1.93663
Element #48: CPU value - 1.34608, GPU value - -0.135742, abs diff - 1.48183
Element #49: CPU value - 0.153611, GPU value - 1.91602, abs diff - 1.7624
Element #50: CPU value - -1.5469, GPU value - -2.37109, abs diff - 0.824197
Element #51: CPU value - 1.86863, GPU value - 1.18066, abs diff - 0.687964
Element #52: CPU value - -0.895937, GPU value - 0.825195, abs diff - 1.72113
Element #53: CPU value - -0.697382, GPU value - -2.26172, abs diff - 1.56434
Element #54: CPU value - 1.80761, GPU value - 2.12891, abs diff - 0.321292
Element #55: CPU value - -1.66569, GPU value - -0.523438, abs diff - 1.14225
Element #56: CPU value - 0.369921, GPU value - -1.44531, abs diff - 1.81523
Element #57: CPU value - 1.1821, GPU value - 2.41211, abs diff - 1.23001
Element #58: CPU value - -1.91526, GPU value - -1.70898, abs diff - 0.206277
Element #59: CPU value - 1.3217, GPU value - -0.178589, abs diff - 1.50029
Element #60: CPU value - 0.187421, GPU value - 1.94238, abs diff - 1.75496
Element #61: CPU value - -1.56671, GPU value - -2.35938, abs diff - 0.792663
Element #62: CPU value - 1.86072, GPU value - 1.14355, abs diff - 0.717167
Element #63: CPU value - -0.865786, GPU value - 0.865723, abs diff - 1.73151
Element #64: CPU value - -1.47071, GPU value - -0.289062, abs diff - 1.18165
Element #65: CPU value - 1.4481, GPU value - -1.64648, abs diff - 3.09458
Element #66: CPU value - -0.422372, GPU value - 2.44336, abs diff - 2.86573
Element #67: CPU value - -0.895937, GPU value - -1.54492, abs diff - 0.648985
Element #68: CPU value - 1.59362, GPU value - -0.421875, abs diff - 2.01549
Element #69: CPU value - -1.18738, GPU value - 2.09766, abs diff - 3.28504
Element #70: CPU value - -0.0413711, GPU value - -2.32031, abs diff - 2.27894
Element #71: CPU value - 1.24146, GPU value - 0.93457, abs diff - 0.306894
Element #72: CPU value - -1.58158, GPU value - 1.09766, abs diff - 2.67924
Element #73: CPU value - 0.826114, GPU value - -2.37109, abs diff - 3.19721
Element #74: CPU value - 0.501611, GPU value - 2, abs diff - 1.49839
Element #75: CPU value - -1.48186, GPU value - -0.245605, abs diff - 1.23626
Element #76: CPU value - 1.43561, GPU value - -1.67969, abs diff - 3.1153
Element #77: CPU value - -0.394892, GPU value - 2.44141, abs diff - 2.8363
Element #78: CPU value - -0.919374, GPU value - -1.5127, abs diff - 0.593322
Element #79: CPU value - 1.59678, GPU value - -0.464355, abs diff - 2.06113
Element #80: CPU value - 0.576554, GPU value - -1.08398, abs diff - 1.66054
Element #81: CPU value - -2.04669, GPU value - -0.701172, abs diff - 1.34552
Element #82: CPU value - 2.09906, GPU value - 2, abs diff - 0.0990589
Element #83: CPU value - -0.697382, GPU value - -1.91406, abs diff - 1.21668
Element #84: CPU value - -1.18738, GPU value - 0.501953, abs diff - 1.68933
Element #85: CPU value - 2.24963, GPU value - 1.25879, abs diff - 0.99084
Element #86: CPU value - -1.75353, GPU value - -2.14648, abs diff - 0.392954
Element #87: CPU value - 0.0427394, GPU value - 1.54785, abs diff - 1.50511
Element #88: CPU value - 1.69766, GPU value - 0.123291, abs diff - 1.57437
Element #89: CPU value - -2.26207, GPU value - -1.70898, abs diff - 0.553082
Element #90: CPU value - 1.25951, GPU value - 2.11133, abs diff - 0.851816
Element #91: CPU value - 0.615522, GPU value - -1.05078, abs diff - 1.6663
Element #92: CPU value - -2.06418, GPU value - -0.737305, abs diff - 1.32687
Element #93: CPU value - 2.08295, GPU value - 2.01562, abs diff - 0.0673242
Element #94: CPU value - -0.658837, GPU value - -1.89648, abs diff - 1.23765
Element #95: CPU value - -1.22166, GPU value - 0.464355, abs diff - 1.68602
Element #96: CPU value - 0.716986, GPU value - 1.3457, abs diff - 0.628717
Element #97: CPU value - 1.22751, GPU value - 0.152832, abs diff - 1.07468
Element #98: CPU value - -2.3217, GPU value - -1.54492, abs diff - 0.776779
Element #99: CPU value - 1.80761, GPU value - 1.86719, abs diff - 0.0595728
Element #100: CPU value - -0.0413711, GPU value - -0.895996, abs diff - 0.854625
Printed 100 different elements, threshhold - 0.0001, next different elements skipped
Total 254 different elements, for output #0, threshhold - 0.0001
CPU time - 0.013906ms
GPU time(CPU->GPU->CPU) - 2.14057ms
```"
51415,inference while recording video is possible in camera2 api? ,"I made tflite model and it infer quite well as I intended,
now , I want to record video but once video recorded, inference is stopped.  and once infer is done, video recored is not playable. 

I assume that rear camera is used to infer, and also I'm trying to record video with rear camera . that is the problem? 

on app, top right fab is to record video 
and bottom right fab is to take picture. 

my relevant github link is as below

https://github.com/kotran88/cameraapi8"
51414,Amazon SageMaker Debugger - 'RuleEvaluationStatus': 'Error',"I'm facing the following error while running Overfit built-in rule in tensorflow

'RuleConfigurationName': 'Overfit',
 'RuleEvaluationStatus': 'Error',
 'StatusDetails': 'ClientError: No debugging data was saved by the training '
                  'job. Check that the debugger hook was configured correctly '
                  'before starting the training job. Exception: Training job '
                  'has ended. All the collection files could not be loaded\n'
                  'Traceback (most recent call last):\n'

Below is my code,

import boto3
import sagemaker
from time import gmtime, strftime
from sagemaker.tensorflow import TensorFlow
from sagemaker.debugger import ProfilerConfig, DebuggerHookConfig, Rule, ProfilerRule, rule_configs, CollectionConfig

base_job_name_prefix= 'SDK-SMDebug-built-in-rules-'+ strftime(""%d-%H-%M-%S"", gmtime())

collection_config_biases = CollectionConfig(name='biases')
collection_config_weights = CollectionConfig(name='weights')
collection_config_metrics = CollectionConfig(name='metrics')

debugger_hook_config = DebuggerHookConfig(
    s3_output_path=f""s3://bgt-lensxraymodeling/URPM/MajorModel/SageMakerOutput/debug-output"",
    collection_configs=[
        collection_config_biases,
        collection_config_weights,
        collection_config_metrics
    ]
)

estimator = TensorFlow(
    entry_point='SCNN_custom_v1/sagemaker_train_v1.py',
    instance_type='ml.p2.xlarge',
    instance_count=1,
    image_uri='763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:1.15.5-gpu-py36-cu100-ubuntu18.04',
    #script_mode=True,
    framework_version=""1.15"",
    py_version=""py3"",
    role=role,
    base_job_name=base_job_name_prefix, 
    **debugger_hook_config=debugger_hook_config,
    rules=[
        Rule.sagemaker(rule_configs.overfit()),
        Rule.sagemaker(rule_configs.loss_not_decreasing())
    ],**
)
estimator.fit()

Could someone please suggest me a solution for this? I don't find any issue with regard to debugger hook configuration in the above code"
51413,"Amazon SageMaker Debugger - 'RuleEvaluationStatus': 'Error',",
51412,Outer dimensions of indices and update must match,"```python
x     = tf.random.normal((128, 4096))
x_slc = tf.random.normal((128, 1023))
slc = list(range(x_slc.shape[-1]))
tf.tensor_scatter_nd_update(x, slc, x_slc)
```
I cannot find any shape of `slc` that doesn't make the command fail, and the error message is inaccurate: the inner (non-assignment) dimensions do match:

```python
InvalidArgumentError: Inner dimensions of output shape must match inner dimensions of updates shape. 
Output: [128,4096] updates: [128,1023] [Op:TensorScatterUpdate]
```

Either a bug or a documentation issue. The intended behavior is to emulate `x[:, :1023] = x_slc`."
51410,Tensorflow 2.5: Segmentation Fault,"I am trying to run a large 3D U-net and my dataset size is 55GB. It doesn't finish more than 6 epochs and then I get a segmentation fault. 

System information: TF 2.5 / CUDA 11.2 / cuDNN 8.1
GPU : 10GB
Server has 32GB of RAM.

The code for my data generator is as follows: 

```
def open_data_file(filename, readwrite=""r""):
    return tables.open_file(filename, readwrite)

data_file_opened = open_data_file(os.path.abspath(""../data/data.h5""))

train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(
        data_file_opened,
        ......)
```

where:

```
def get_training_and_validation_generators(data_file, batch_size, ...):
    training_generator = data_generator(data_file, training_list,....)
```
data_generator function is as follows:

```
def data_generator(data_file, index_list,....):
      orig_index_list = index_list
    while True:
        x_list = list()
        y_list = list()
        if patch_shape:
            index_list = create_patch_index_list(orig_index_list, data_file, patch_shape,
                                                 patch_overlap, patch_start_offset,pred_specific=pred_specific)
        else:
            index_list = copy.copy(orig_index_list)

        while len(index_list) > 0:
            index = index_list.pop()
            add_data(x_list, y_list, data_file, index, augment=augment, augment_flip=augment_flip,
                     augment_distortion_factor=augment_distortion_factor, patch_shape=patch_shape,
                     skip_blank=skip_blank, permute=permute)
            if len(x_list) == batch_size or (len(index_list) == 0 and len(x_list) > 0):
                yield convert_data(x_list, y_list, n_labels=n_labels, labels=labels, num_model=num_model,overlap_label=overlap_label)
                x_list = list()
                y_list = list()

```

Can someone please tell me how to solve this issue? What causes the segmentation fault? Also, training is very slow. It takes about 7000s to complete one epoch.

"
51408,1.15.4,We found vulnerabilities about tensorflow on the website （https://nvd.nist.gov/vuln/search/results?form_type=Basic&results_type=overview&query=tensorflow&search_type=all&isCpeNameSearch=false）. These vulnerabilities are basically fixed in versions greater than 2.0. But how are these vulnerabilities fixed in version 1.15.4? Thank you.
51407,Question about tf.compat.v1.metrics.auc,"I try to migrate my code from tf1.* to tf2, while in [tf2 doc](https://www.tensorflow.org/api_docs/python/tf/compat/v1/metrics/auc) it says that `tf.compat.v1.metrics.auc` is deprecated because ""**The value of AUC returned by this may race with the update**"". This statement is vague to me. Does it mean that it can't be used in multithreading context? If not, in what situation can I use this function?"
51405,Add track_times=False to Model.save_weights('.h5'),"**System information**
- TensorFlow version: 2.4.1
- Are you willing to contribute it: Yes

**Describe the feature and the current behavior/state.**
Currently, when calling `keras.models.Model.save_weights()` in hdf5 format, the weights are saved using `h5py.Group.create_dataset` with the argument `track_times` set to the default value `True`. The effect of this is following: even when the weights are exactly the same, the resulting saved files will not be the same (see for example this [stack overflow question](https://stackoverflow.com/questions/16019656/hdf5-file-h5py-with-version-control-hash-changes-on-every-save)). This is a problem when one has a replicable model pipeline and uses some version control system (like [DVC](https://dvc.org/)). 
The proposed feature is adding `h5_track_times` argument to the `Model.save_weights()` function and pass it down to h5py. 

**Will this change the current api? How?**
Yes, the `Model.save_weights()` would get an additional optional `h5_track_times` argument. 

**Who will benefit with this feature?**
Everyone who needs to have replicable model pipeline and needs to version the model weights in hdf5 format."
51404,Error to run the tflite model: self._interpreter.Invoke() RuntimeError: Input tensor 1283 lacks data,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 18.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.7.0-dev20210804

### 2. Code
The code I use to convert the model and run the interpreter:

```
converter = tf.lite.TFLiteConverter.from_saved_model(""mask_rcnn_coco_1204"")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.experimental_new_converter = True
tflite_model = converter.convert()
fo = open(
    ""mask_rcnn_inception_1024_int_quantized.tflite"", ""wb"")
fo.write(tflite_model)
fo.close

interpreter = tf.lite.Interpreter(model_path=""mask_rcnn_inception_1024_int_quantized.tflite"")
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.uint8)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```
Here is the [tflite model](https://drive.google.com/file/d/1yvvxl9iq2CpFqZ7_a4LMKZkpTppRJdGV/view?usp=sharing) that converted. 
### 3. Failure after conversion
Model converting finished with no error, but the converted model couldn't run through the interpreter. 

### 4. Error traceback
`Traceback (most recent call last):
  File ""converter.py"", line 100, in <module>
    interpreter.invoke()
  File ""/home/dev/.local/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py"", line 858, in invoke
    self._interpreter.Invoke()
RuntimeError: Input tensor 1283 lacks data
`

_Originally posted by @JiashuGuo in https://github.com/tensorflow/tensorflow/issues/51209#issuecomment-895023730_"
51403,Problems setting up Tensorflow on M1 Mac,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOC Big Sur 11.4, Apple M1 2020
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.5.0
- Python version: 3.8.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a?
- GPU model and memory: Apple Silicon M1 Chip



**Describe the problem**

Hey! I've been trying to set up Tensorflow on my M1 Mac but have been unsuccessful in doing so. Any help would be appreciated! As a note, I was following [this installation guide](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/install/tensorflow-install-mac-metal-jul-2021.ipynb) as well as using other resources as well since I am relatively new to this. I also have a lot of logs, so I attached my terminal code as a [txt file](https://github.com/tensorflow/tensorflow/files/6959610/pain.txt).


<br>

I first set up `Miniforge` and `Jupyter Notebook`, which I believed worked out just fine.

<details> 
<summary>Here's the output (really long, added just in case)</summary>

```
(base) Anshul@Anshuls-MacBook-Pro ~ % xcode-select --install

xcode-select: error: command line tools are already installed, use ""Software Update"" to install updates
(base) Anshul@Anshuls-MacBook-Pro ~ % brew install miniforge

Updating Homebrew...
==> Auto-updated Homebrew!
Updated 5 taps (heroku/brew, homebrew/core, homebrew/cask, homebrew/services and mongodb/brew).
==> New Formulae
alda                                  demumble                              himalaya                              mapcidr                               openmama                              qt-mysql                              stp
alerter                               detect-secrets                        hubble                                marcli                                openmodelica                          qt-percona-server                     stylua
amfora                                djl-serving                           i2c-tools                             mariadb@10.5                          opensearch                            qt-postgresql                         svgbob
archey4                               doc8                                  iconsur                               marp-cli                              oras                                  qt-unixodbc                           sysstat
argocd-autopilot                      docuum                                imath                                 mathlibtools                          orgalorg                              qthreads                              systemd
argocd-vault-plugin                   dory                                  influxdb-cli                          matterbridge                          organize-tool                         range2cidr                            tbb@2020
as-tree                               dua-cli                               influxdb@1                            maturin                               osinfo-db                             rdkit                                 terminator
at-spi2-atk                           ehco                                  ipinfo-cli                            mbedtls@2                             osinfo-db-tools                       revive                                threemux
at-spi2-core                          elan-init                             iredis                                minisat                               pandoc-plot                           rhit                                  timg
atuin                                 elfutils                              jello                                 moar                                  parquet-cli                           rmw                                   tmuxp
autoconf@2.69                         enkits                                jrsonnet                              mongocli                              pcalc                                 ronn                                  tomcat@9
autorestic                            enzyme                                julia                                 mongodb/brew/mongodb-community@4.4    pcp                                   rosa-cli                              tracker
avahi                                 epr                                   kalker                                mongodb/brew/mongodb-mongocryptd      pgxnclient                            rover                                 trojan-go
baidupcs-go                           erlang@23                             kertish-dfs                           mongodb/brew/mongodb-mongocryptd@4.2  php-cs-fixer@2                        rpg-cli                               tssh
bas55                                 fabric-installer                      ki                                    mongodb/brew/mongodb-mongocryptd@4.4  phpbrew                               rsc_2fa                               tz
bash_unit                             fanyi                                 kickstart                             mongosh                               pillow                                rtl_433                               umple
bgpq4                                 fcp                                   klee                                  moto                                  plow                                  s4cmd                                 universal-ctags
bosh-cli                              fluid-synth@2.1                       kotlin-language-server                mr2                                   poppler-qt5                           samba                                 vala-language-server
brook                                 frum                                  kubeconform                           multi-git-status                      principalmapper                       saml2aws                              virtualenv
buildpulse-test-reporter              func-e                                kubergrunt                            multitime                             proj@7                                scorecard                             virtualenvwrapper
bupstash                              fuse-overlayfs                        latino                                mx                                    projectm                              scotch                                waffle
cadence-workflow                      gcc@10                                leaf-proxy                            name-that-hash                        psalm                                 scry                                  wasmtime
cadical                               geph4                                 lefthook                              nbsdgames                             pure                                  search-that-hash                      waypoint
caire                                 ghc@9                                 lexbor                                ncc                                   px                                    seqkit                                webhook
cidr2range                            git-xargs                             libfuse@2                             neovim-remote                         py-spy                                simde                                 wildmidi
ciphey                                gitbackup                             libmd                                 net-tools                             pydocstyle                            six                                   wllvm
clarinet                              gitwatch                              libmobi                               nomino                                pyflow                                slides                                xcprojectlint
clazy                                 glibc                                 libpipeline                           notcurses                             pyqt-3d                               slirp4netns                           xfig
clusterctl                            gnupg@2.2                             libunwind                             nox                                   pyqt-builder                          smu                                   xplr
code-minimap                          go-boring                             licensefinder                         ns-3                                  pyqt-networkauth                      snowpack                              xray
conftest                              go@1.15                               lima                                  numactl                               pyright                               soapyrtlsdr                           yubikey-agent
conmon                                gopass-jsonapi                        linux-headers@4.15                    obfs4proxy                            pyside@2                              soapysdr                              zellij
crackpkcs                             gpg-tui                               linux-pam                             oksh                                  python-launcher                       spaceship                             zet
crispy-doom                           gradle@6                              llvm@11                               open-adventure                        python-tabulate                       spectra                               zinit
crun                                  graphqurl                             lm-sensors                            openexr@2                             python-tk@3.9                         sql-lint                              zlib-ng
csvtk                                 grepip                                lsix                                  openfpgaloader                        pythran                               sqlancer                              zsh-vi-mode
darglint                              gtksourceview5                        lttng-ust                             openj9                                pywhat                                sqlbench
datalad                               haruhi-dl                             lychee                                openliberty-jakartaee8                qodem                                 sqlx-cli
ddcctl                                haskell-language-server               macchina                              openliberty-microprofile4             qt-libiodbc                           sqsmover
delve                                 hcl2json                              macos-term-size                       openliberty-webprofile8               qt-mariadb                            storj-uplink
==> Updated Formulae
Updated 5048 formulae.
==> Renamed Formulae
badtouch -> authoscope                                ht-rust -> xh                                         kde-ki18n -> ki18n                                    minizip2 -> minizip-ng                                weboob -> woob
envoy@1.17 -> envoy@1.18                              kde-extra-cmake-modules -> extra-cmake-modules        kde-threadweaver -> threadweaver                      parallelstl -> onedpl                                 wxmac -> wxwidgets
fcct -> butane                                        kde-karchive -> karchive                              libsasl2 -> cyrus-sasl                                pyqt5 -> pyqt@5                                       wxmac@3.0 -> wxwidgets@3.0
grakn -> typedb                                       kde-kdoctools -> kdoctools                            linux-headers -> linux-headers@4.4                    qt5 -> qt@5
==> Deleted Formulae
atlassian-cli                                avian                                        geant4                                       libinfinity                                  protobuf-swift                               terraform-provisioner-ansible
aurora-cli                                   erlang@20                                    giter8                                       osquery                                      protobuf@3.7                                 tj
==> New Casks
8x8-work                          chatterino                        evkey                             futurerestore-gui                 kubenav                           neat-reader                       safe-multisig                     uniflash
adrive                            chia                              fabfilter-micro                   goldenpassport                    kyokan-bob                        nordlocker                        samsung-dex                       universal-battle
affinity-designer                 cinc-workstation                  fabfilter-one                     goneovim                          lagrange                          nordpass                          sbarex-qlmarkdown                 usbimager
affinity-photo                    cinco                             fabfilter-pro-c                   google-drive                      landrop                           northernspysoftware-colorpicker   shield                            usr-sse2-rdm
affinity-publisher                cinderella                        fabfilter-pro-ds                  gosign                            librewolf                         nuage                             shimonote                         utterly
airbuddy                          classroom-mode-for-minecraft      fabfilter-pro-g                   guilded                           lightform                         odbc-manager                      shortcutor                        vamiga
alipay-development-assistant      clicker-for-netflix               fabfilter-pro-l                   hancom-word                       lightwright                       offset-explorer                   shottr                            veepn
android-commandlinetools          clicker-for-youtube               fabfilter-pro-mb                  hightop                           logseq                            old-school-runescape              simplelink-msp432-sdk             vial
arkiwi                            clock-signal                      fabfilter-pro-q                   hook                              maccleaner-pro                    openloco                          simplelink-msp432e4-sdk           vitals
around                            code-composer-studio              fabfilter-pro-r                   hush                              macstroke                         opgg                              simtoolkitpro                     vitalsigns
asana                             cog                               fabfilter-saturn                  hyperkey                          maestral                          optimus-player                    siyuan                            volanta
assinador-serpro                  coinomi-wallet                    fabfilter-simplon                 iconscout                         magicplot                         p4                                skychart                          vsd-viewer
astah-uml                         command-pad                       fabfilter-timeless                ilspy                             mailtrackerblocker                parsify                           sleek                             vsdx-annotator
atomic-wallet                     crescendo                         fabfilter-twin                    imdone                            mambaforge                        physics-101                       slidepilot                        waltr-pro
audacity                          cryptonomic-galleon               fabfilter-volcano                 infinity                          maxon                             pika                              sonic-robo-blast-2                wannianli
audiogridder-plugin               curseforge                        fawkes                            instatus-out                      megax                             pktriot                           sonic-robo-blast-2-kart           webull
audiogridder-server               daedalus-testnet                  final-fantasy-xiv-online          internxt-drive                    mem                               plasticscm-cloud-edition          sonobus                           wezterm
audius                            depthmapx                         finisher-fluxx                    invoker                           memory-cleaner                    polkadot-js                       sparrow                           wifi-explorer-pro
banksiagui                        devbook                           finisher-micro                    irpf2021                          menu-bar-splitter                 pop                               specter                           wolfram-player
battery-buddy                     devilutionx                       finisher-neo                      isyncer                           menuwhere                         portx                             sqlight                           wxmacmolplt
beeper                            devkinsta                         finisher-voodoo                   itraffic                          micro-sniff                       prisma-studio                     suuntodm5                         xbar
betelguese                        devutils                          firefly                           jamkazam                          microsoft-openjdk                 privileges                        swiftbar                          xournal-plus-plus
bit-fiddle                        diagnostics                       flameshot                         jandi-statusbar                   microsoft-remote-desktop          pronterface                       tabby                             yippy
blackhole-64ch                    dingtalk-lite                     flomo                             jellyfin-media-player             midiview                          pulse                             tabtopus                          youtube-dl-gui
bleunlock                         disk-expert                       fluent-reader                     jgrennison-openttd                millie                            qudedup-extract-tool              textbuddy                         zecwallet-lite
blobsaver                         dmidiplayer                       font-smoothing-adjuster           jidusm                            mixed-in-key                      radar                             the-archive                       zulufx
bluesnooze                        dnagedcom                         foobar2000                        jiohome                           moebius                           recut                             tint
brooklite                         dropzone                          forticlient-vpn                   jpadilla-rabbitmq                 mouse-fix                         redis-pro                         touch-portal
burp-suite-professional           drovio                            fpc-laz                           jpadilla-redis                    mubu                              redream                           touchosc
cakebrewjs                        duplicate-file-finder             fpc-src-laz                       katrain                           mutesync                          remnote                           transfer
calmly-writer                     ears                              free42-binary                     kdocs                             mxsrvs                            rhino                             trezor-suite
castr                             elpki                             free42-decimal                    keyboardholder                    n1ghtshade                        runelite                          ubports-installer
celestia                          enclave                           fspy                              kiwi-for-gmail                    nault                             safe-exam-browser                 unexpectedly
==> Updated Casks
Updated 2625 casks.
==> Deleted Casks
ableton-live                  beautune                      daedalus-catalyst             fpcsrc                        kode54-cog                    netbeans-java-ee              protonmail-unofficial         shoes                         wakeonlan
adafruit-arduino              beoplay-software-update       duckstation                   gitbox                        lingo                         netbeans-java-se              psequel                       spideroak-share               wraparound
adobe-air-sdk                 blue-jeans-browser-plugin     family-tree-builder           hex                           magicplotpro                  netbeans-php                  rabbitmq                      swift-explorer                xamarin
adobe-lens-profile-creator    caramba-switcher              filedrop                      hubic                         magicplotstudent              nndd                          racket-cs                     terminus                      yyets
adventure                     cellery                       flash-npapi                   imazing-mini                  mapillary-uploader            omniweb                       raven                         todos
adware-removal-tool           clipbuddy                     flash-player                  insomnia-designer             mega                          opennx                        redis                         touch-bar-pong
appstudio                     cliqz                         flash-player-debugger         iograph                       meshcommander                 opera-mail                    resxtreme                     tracks-live
audiobookbinder               craft                         flash-player-debugger-npapi   itrash                        mist                          pdftotext                     revisions                     transmit-disk
auristor-client               cricut-design-space           flash-player-debugger-ppapi   jira-client                   monitorearth                  pibakery                      rhinoceros                    use-engine
battery-guardian              crypt                         flash-ppapi                   kafka-tool                    mp3tag                        pins                          rss                           veonim
beatport-pro                  cuteclips                     foreman                       kk7ds-python-runtime          netbeans-cpp                  printrun                      screen                        vrep

==> Caveats
Please run the following to setup your shell:
  conda init ""$(basename ""${SHELL}"")""

==> Downloading https://github.com/conda-forge/miniforge/releases/download/4.10.3-4/Miniforge3-4.10.3-4-MacOSX-arm64.sh
==> Downloading from https://github-releases.githubusercontent.com/221584272/b4e53ae3-f8ef-4279-8dab-e8402c705255?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210810%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210810T045003Z&X-Amz-Expires=
######################################################################## 100.0%
==> Installing Cask miniforge
==> Running installer script 'Miniforge3-4.10.3-4-MacOSX-arm64.sh'
PREFIX=/usr/local/Caskroom/miniforge/base
Unpacking payload ...
Extracting ""pycparser-2.20-pyh9f0ad1d_2.tar.bz2""
Extracting ""pyopenssl-20.0.1-pyhd8ed1ab_0.tar.bz2""
Extracting ""python_abi-3.9-2_cp39.tar.bz2""
Extracting ""pysocks-1.7.1-py39h2804cbe_3.tar.bz2""
Extracting ""urllib3-1.26.6-pyhd8ed1ab_0.tar.bz2""
Extracting ""six-1.16.0-pyh6c4a22f_0.tar.bz2""
Extracting ""tzdata-2021a-he74cb21_1.tar.bz2""
Extracting ""yaml-0.2.5-h642e427_0.tar.bz2""
Extracting ""sqlite-3.36.0-h72a2b83_0.tar.bz2""
Extracting ""xz-5.2.5-h642e427_1.tar.bz2""
Extracting ""ca-certificates-2021.5.30-h4653dfc_0.tar.bz2""
Extracting ""setuptools-49.6.0-py39h2804cbe_3.tar.bz2""
Extracting ""cryptography-3.4.7-py39h73257c9_0.tar.bz2""
Extracting ""colorama-0.4.4-pyh9f0ad1d_0.tar.bz2""
Extracting ""tqdm-4.62.0-pyhd8ed1ab_0.tar.bz2""
Extracting ""cffi-1.14.6-py39hda8b47f_0.tar.bz2""
Extracting ""zlib-1.2.11-h31e879b_1009.tar.bz2""
Extracting ""idna-3.1-pyhd3deb0d_0.tar.bz2""
Extracting ""wheel-0.36.2-pyhd3deb0d_0.tar.bz2""
Extracting ""conda-package-handling-1.7.3-py39h5161555_0.tar.bz2""
Extracting ""chardet-4.0.0-py39h2804cbe_1.tar.bz2""
Extracting ""requests-2.26.0-pyhd8ed1ab_0.tar.bz2""
Extracting ""libffi-3.3-h9f76cd9_2.tar.bz2""
Extracting ""brotlipy-0.7.0-py39h5161555_1001.tar.bz2""
Extracting ""libcxx-12.0.1-h168391b_0.tar.bz2""
Extracting ""tk-8.6.10-hf7e6567_1.tar.bz2""
Extracting ""readline-8.1-hedafd6a_0.tar.bz2""
Extracting ""charset-normalizer-2.0.0-pyhd8ed1ab_0.tar.bz2""
Extracting ""openssl-1.1.1k-h27ca646_0.tar.bz2""
Extracting ""conda-4.10.3-py39h2804cbe_0.tar.bz2""
Extracting ""pycosat-0.6.3-py39h5161555_1006.tar.bz2""
Extracting ""pip-21.2.2-pyhd8ed1ab_0.tar.bz2""
Extracting ""ruamel_yaml-0.15.80-py39h5161555_1004.tar.bz2""
Extracting ""certifi-2021.5.30-py39h2804cbe_0.tar.bz2""
Extracting ""python-3.9.6-h54d631c_1_cpython.tar.bz2""
Extracting ""ncurses-6.2-h9aa5885_4.tar.bz2""

                                           __
          __  ______ ___  ____ _____ ___  / /_  ____ _
         / / / / __ `__ \/ __ `/ __ `__ \/ __ \/ __ `/
        / /_/ / / / / / / /_/ / / / / / / /_/ / /_/ /
       / .___/_/ /_/ /_/\__,_/_/ /_/ /_/_.___/\__,_/
      /_/


Transaction

  Prefix: /usr/local/Caskroom/miniforge/base

  Updating specs:

   - python==3.9.6=h54d631c_1_cpython
   - ca-certificates==2021.5.30=h4653dfc_0
   - libcxx==12.0.1=h168391b_0
   - ncurses==6.2=h9aa5885_4
   - tzdata==2021a=he74cb21_1
   - xz==5.2.5=h642e427_1
   - yaml==0.2.5=h642e427_0
   - zlib==1.2.11=h31e879b_1009
   - libffi==3.3=h9f76cd9_2
   - openssl==1.1.1k=h27ca646_0
   - readline==8.1=hedafd6a_0
   - tk==8.6.10=hf7e6567_1
   - sqlite==3.36.0=h72a2b83_0
   - charset-normalizer==2.0.0=pyhd8ed1ab_0
   - colorama==0.4.4=pyh9f0ad1d_0
   - idna==3.1=pyhd3deb0d_0
   - pycparser==2.20=pyh9f0ad1d_2
   - python_abi==3.9=2_cp39
   - six==1.16.0=pyh6c4a22f_0
   - wheel==0.36.2=pyhd3deb0d_0
   - certifi==2021.5.30=py39h2804cbe_0
   - cffi==1.14.6=py39hda8b47f_0
   - chardet==4.0.0=py39h2804cbe_1
   - pycosat==0.6.3=py39h5161555_1006
   - pysocks==1.7.1=py39h2804cbe_3
   - ruamel_yaml==0.15.80=py39h5161555_1004
   - tqdm==4.62.0=pyhd8ed1ab_0
   - brotlipy==0.7.0=py39h5161555_1001
   - conda-package-handling==1.7.3=py39h5161555_0
   - cryptography==3.4.7=py39h73257c9_0
   - setuptools==49.6.0=py39h2804cbe_3
   - pip==21.2.2=pyhd8ed1ab_0
   - pyopenssl==20.0.1=pyhd8ed1ab_0
   - urllib3==1.26.6=pyhd8ed1ab_0
   - requests==2.26.0=pyhd8ed1ab_0
   - conda==4.10.3=py39h2804cbe_0


  Package                   Version  Build               Channel                                                                         Size
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
  Install:
───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────

  brotlipy                    0.7.0  py39h5161555_1001   conda-forge/osx-arm64/brotlipy-0.7.0-py39h5161555_1001.tar.bz2                Cached
  ca-certificates         2021.5.30  h4653dfc_0          conda-forge/osx-arm64/ca-certificates-2021.5.30-h4653dfc_0.tar.bz2            Cached
  certifi                 2021.5.30  py39h2804cbe_0      conda-forge/osx-arm64/certifi-2021.5.30-py39h2804cbe_0.tar.bz2                Cached
  cffi                       1.14.6  py39hda8b47f_0      conda-forge/osx-arm64/cffi-1.14.6-py39hda8b47f_0.tar.bz2                      Cached
  chardet                     4.0.0  py39h2804cbe_1      conda-forge/osx-arm64/chardet-4.0.0-py39h2804cbe_1.tar.bz2                    Cached
  charset-normalizer          2.0.0  pyhd8ed1ab_0        conda-forge/noarch/charset-normalizer-2.0.0-pyhd8ed1ab_0.tar.bz2              Cached
  colorama                    0.4.4  pyh9f0ad1d_0        conda-forge/noarch/colorama-0.4.4-pyh9f0ad1d_0.tar.bz2                        Cached
  conda                      4.10.3  py39h2804cbe_0      conda-forge/osx-arm64/conda-4.10.3-py39h2804cbe_0.tar.bz2                     Cached
  conda-package-handling      1.7.3  py39h5161555_0      conda-forge/osx-arm64/conda-package-handling-1.7.3-py39h5161555_0.tar.bz2     Cached
  cryptography                3.4.7  py39h73257c9_0      conda-forge/osx-arm64/cryptography-3.4.7-py39h73257c9_0.tar.bz2               Cached
  idna                          3.1  pyhd3deb0d_0        conda-forge/noarch/idna-3.1-pyhd3deb0d_0.tar.bz2                              Cached
  libcxx                     12.0.1  h168391b_0          conda-forge/osx-arm64/libcxx-12.0.1-h168391b_0.tar.bz2                        Cached
  libffi                        3.3  h9f76cd9_2          conda-forge/osx-arm64/libffi-3.3-h9f76cd9_2.tar.bz2                           Cached
  ncurses                       6.2  h9aa5885_4          conda-forge/osx-arm64/ncurses-6.2-h9aa5885_4.tar.bz2                          Cached
  openssl                    1.1.1k  h27ca646_0          conda-forge/osx-arm64/openssl-1.1.1k-h27ca646_0.tar.bz2                       Cached
  pip                        21.2.2  pyhd8ed1ab_0        conda-forge/noarch/pip-21.2.2-pyhd8ed1ab_0.tar.bz2                            Cached
  pycosat                     0.6.3  py39h5161555_1006   conda-forge/osx-arm64/pycosat-0.6.3-py39h5161555_1006.tar.bz2                 Cached
  pycparser                    2.20  pyh9f0ad1d_2        conda-forge/noarch/pycparser-2.20-pyh9f0ad1d_2.tar.bz2                        Cached
  pyopenssl                  20.0.1  pyhd8ed1ab_0        conda-forge/noarch/pyopenssl-20.0.1-pyhd8ed1ab_0.tar.bz2                      Cached
  pysocks                     1.7.1  py39h2804cbe_3      conda-forge/osx-arm64/pysocks-1.7.1-py39h2804cbe_3.tar.bz2                    Cached
  python                      3.9.6  h54d631c_1_cpython  conda-forge/osx-arm64/python-3.9.6-h54d631c_1_cpython.tar.bz2                 Cached
  python_abi                    3.9  2_cp39              conda-forge/osx-arm64/python_abi-3.9-2_cp39.tar.bz2                           Cached
  readline                      8.1  hedafd6a_0          conda-forge/osx-arm64/readline-8.1-hedafd6a_0.tar.bz2                         Cached
  requests                   2.26.0  pyhd8ed1ab_0        conda-forge/noarch/requests-2.26.0-pyhd8ed1ab_0.tar.bz2                       Cached
  ruamel_yaml               0.15.80  py39h5161555_1004   conda-forge/osx-arm64/ruamel_yaml-0.15.80-py39h5161555_1004.tar.bz2           Cached
  setuptools                 49.6.0  py39h2804cbe_3      conda-forge/osx-arm64/setuptools-49.6.0-py39h2804cbe_3.tar.bz2                Cached
  six                        1.16.0  pyh6c4a22f_0        conda-forge/noarch/six-1.16.0-pyh6c4a22f_0.tar.bz2                            Cached
  sqlite                     3.36.0  h72a2b83_0          conda-forge/osx-arm64/sqlite-3.36.0-h72a2b83_0.tar.bz2                        Cached
  tk                         8.6.10  hf7e6567_1          conda-forge/osx-arm64/tk-8.6.10-hf7e6567_1.tar.bz2                            Cached
  tqdm                       4.62.0  pyhd8ed1ab_0        conda-forge/noarch/tqdm-4.62.0-pyhd8ed1ab_0.tar.bz2                           Cached
  tzdata                      2021a  he74cb21_1          conda-forge/noarch/tzdata-2021a-he74cb21_1.tar.bz2                            Cached
  urllib3                    1.26.6  pyhd8ed1ab_0        conda-forge/noarch/urllib3-1.26.6-pyhd8ed1ab_0.tar.bz2                        Cached
  wheel                      0.36.2  pyhd3deb0d_0        conda-forge/noarch/wheel-0.36.2-pyhd3deb0d_0.tar.bz2                          Cached
  xz                          5.2.5  h642e427_1          conda-forge/osx-arm64/xz-5.2.5-h642e427_1.tar.bz2                             Cached
  yaml                        0.2.5  h642e427_0          conda-forge/osx-arm64/yaml-0.2.5-h642e427_0.tar.bz2                           Cached
  zlib                       1.2.11  h31e879b_1009       conda-forge/osx-arm64/zlib-1.2.11-h31e879b_1009.tar.bz2                       Cached

  Summary:

  Install: 36 packages

  Total download: 0  B

───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────



Transaction starting
Linking ca-certificates-2021.5.30-h4653dfc_0
Linking libcxx-12.0.1-h168391b_0
Linking ncurses-6.2-h9aa5885_4
Linking tzdata-2021a-he74cb21_1
Linking xz-5.2.5-h642e427_1
Linking yaml-0.2.5-h642e427_0
Linking zlib-1.2.11-h31e879b_1009
Linking openssl-1.1.1k-h27ca646_0
Linking libffi-3.3-h9f76cd9_2
Linking readline-8.1-hedafd6a_0
Linking tk-8.6.10-hf7e6567_1
Linking sqlite-3.36.0-h72a2b83_0
Linking python-3.9.6-h54d631c_1_cpython
Linking wheel-0.36.2-pyhd3deb0d_0
Linking six-1.16.0-pyh6c4a22f_0
Linking python_abi-3.9-2_cp39
Linking pycparser-2.20-pyh9f0ad1d_2
Linking idna-3.1-pyhd3deb0d_0
Linking colorama-0.4.4-pyh9f0ad1d_0
Linking charset-normalizer-2.0.0-pyhd8ed1ab_0
Linking ruamel_yaml-0.15.80-py39h5161555_1004
Linking pysocks-1.7.1-py39h2804cbe_3
Linking pycosat-0.6.3-py39h5161555_1006
Linking chardet-4.0.0-py39h2804cbe_1
Linking certifi-2021.5.30-py39h2804cbe_0
Linking cffi-1.14.6-py39hda8b47f_0
Linking tqdm-4.62.0-pyhd8ed1ab_0
Linking setuptools-49.6.0-py39h2804cbe_3
Linking cryptography-3.4.7-py39h73257c9_0
Linking brotlipy-0.7.0-py39h5161555_1001
Linking conda-package-handling-1.7.3-py39h5161555_0
Linking pip-21.2.2-pyhd8ed1ab_0
Linking pyopenssl-20.0.1-pyhd8ed1ab_0
Linking urllib3-1.26.6-pyhd8ed1ab_0
Linking requests-2.26.0-pyhd8ed1ab_0
Linking conda-4.10.3-py39h2804cbe_0
Transaction finished
installation finished.
==> Linking Binary 'conda' to '/usr/local/bin/conda'
🍺  miniforge was successfully installed!

(base) Anshul@Anshuls-MacBook-Pro ~ % conda install -y jupyter

Collecting package metadata (current_repodata.json): done
Solving environment: done

# All requested packages already installed.

```
</details>

From there, I tried to set up an environment, where things started to go wrong. 

<details open>
<summary>I had a problem installing dependencies from a file called `tensorflow-apple-metal.yml` with this content:</summary>
<br>

```
name: tensorflow
 
dependencies:
    - python=3.9
    - pip>=19.0
    - jupyter
    - apple::tensorflow-deps
    - scikit-learn
    - scipy
    - pandas
    - pandas-datareader
    - matplotlib
    - pillow
    - tqdm
    - requests
    - h5py
    - pyyaml
    - flask
    - boto3
    - pip:
        - tensorflow-macos
        - tensorflow-metal
        - bayesian-optimization
        - gym
        - kaggle
```

</details>


This was installed in the `ML` directory (from the guide I linked above) and I ran the following code afterwards:

```
(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow

Collecting package metadata (repodata.json): done
Solving environment: failed

ResolvePackageNotFound: 
  - apple::tensorflow-deps
```

After some googling with this error, I moved `- apple::tensorflow-deps`  below `pip`, and reran this line of code. It installed all the dependencies and displayed *another* error at the bottom: 
<details>
<summary>Here's what my terminal displayed (very long, scroll to bottom of output)</summary>
<br>

```
(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow
Collecting package metadata (repodata.json): done
Solving environment: failed

ResolvePackageNotFound: 
  - apple::tensorflow-deps

(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow
Collecting package metadata (repodata.json): done
Solving environment: done

Downloading and Extracting Packages
scikit-learn-0.24.2  | 5.0 MB    | ################################################################################################################################################################################################################################### | 100% 
pillow-8.3.1         | 602 KB    | ################################################################################################################################################################################################################################### | 100% 
numpy-1.20.3         | 23 KB     | ################################################################################################################################################################################################################################### | 100% 
jupyter-1.0.0        | 8 KB      | ################################################################################################################################################################################################################################### | 100% 
pyzmq-20.0.0         | 405 KB    | ################################################################################################################################################################################################################################### | 100% 
packaging-21.0       | 36 KB     | ################################################################################################################################################################################################################################### | 100% 
brotlipy-0.7.0       | 333 KB    | ################################################################################################################################################################################################################################### | 100% 
pyrsistent-0.18.0    | 89 KB     | ################################################################################################################################################################################################################################### | 100% 
scipy-1.6.2          | 14.7 MB   | ################################################################################################################################################################################################################################### | 100% 
hdf5-1.10.6          | 3.0 MB    | ################################################################################################################################################################################################################################### | 100% 
jupyter_core-4.7.1   | 68 KB     | ################################################################################################################################################################################################################################### | 100% 
pandas-datareader-0. | 71 KB     | ################################################################################################################################################################################################################################### | 100% 
setuptools-52.0.0    | 724 KB    | ################################################################################################################################################################################################################################### | 100% 
prometheus_client-0. | 47 KB     | ################################################################################################################################################################################################################################### | 100% 
pyqt-5.9.2           | 3.7 MB    | ################################################################################################################################################################################################################################### | 100% 
pysocks-1.7.1        | 31 KB     | ################################################################################################################################################################################################################################### | 100% 
ipykernel-5.3.4      | 180 KB    | ################################################################################################################################################################################################################################### | 100% 
lz4-c-1.9.3          | 140 KB    | ################################################################################################################################################################################################################################### | 100% 
libxml2-2.9.12       | 1.1 MB    | ################################################################################################################################################################################################################################### | 100% 
cryptography-3.4.7   | 693 KB    | ################################################################################################################################################################################################################################### | 100% 
intel-openmp-2021.3. | 950 KB    | ################################################################################################################################################################################################################################### | 100% 
widgetsnbextension-3 | 863 KB    | ################################################################################################################################################################################################################################### | 100% 
terminado-0.9.4      | 25 KB     | ################################################################################################################################################################################################################################### | 100% 
attrs-21.2.0         | 46 KB     | ################################################################################################################################################################################################################################### | 100% 
botocore-1.20.109    | 3.8 MB    | ################################################################################################################################################################################################################################### | 100% 
six-1.16.0           | 18 KB     | ################################################################################################################################################################################################################################### | 100% 
h5py-3.2.1           | 946 KB    | ################################################################################################################################################################################################################################### | 100% 
boto3-1.17.109       | 70 KB     | ################################################################################################################################################################################################################################### | 100% 
pygments-2.9.0       | 721 KB    | ################################################################################################################################################################################################################################### | 100% 
markupsafe-2.0.1     | 20 KB     | ################################################################################################################################################################################################################################### | 100% 
bottleneck-1.3.2     | 111 KB    | ################################################################################################################################################################################################################################### | 100% 
mistune-0.8.4        | 57 KB     | ################################################################################################################################################################################################################################### | 100% 
pyyaml-5.4.1         | 170 KB    | ################################################################################################################################################################################################################################### | 100% 
pandocfilters-1.4.3  | 14 KB     | ################################################################################################################################################################################################################################### | 100% 
chardet-4.0.0        | 195 KB    | ################################################################################################################################################################################################################################### | 100% 
bleach-4.0.0         | 113 KB    | ################################################################################################################################################################################################################################### | 100% 
click-8.0.1          | 79 KB     | ################################################################################################################################################################################################################################### | 100% 
s3transfer-0.4.2     | 62 KB     | ################################################################################################################################################################################################################################### | 100% 
zstd-1.4.9           | 476 KB    | ################################################################################################################################################################################################################################### | 100% 
parso-0.8.2          | 69 KB     | ################################################################################################################################################################################################################################### | 100% 
brotli-1.0.9         | 398 KB    | ################################################################################################################################################################################################################################### | 100% 
mkl_fft-1.3.0        | 167 KB    | ################################################################################################################################################################################################################################### | 100% 
testpath-0.5.0       | 81 KB     | ################################################################################################################################################################################################################################### | 100% 
webencodings-0.5.1   | 20 KB     | ################################################################################################################################################################################################################################### | 100% 
numexpr-2.7.3        | 124 KB    | ################################################################################################################################################################################################################################### | 100% 
certifi-2021.5.30    | 138 KB    | ################################################################################################################################################################################################################################### | 100% 
zipp-3.5.0           | 13 KB     | ################################################################################################################################################################################################################################### | 100% 
pip-21.2.2           | 1.8 MB    | ################################################################################################################################################################################################################################### | 100% 
mkl-2021.3.0         | 100.4 MB  | ################################################################################################################################################################################################################################### | 100% 
tzdata-2021a         | 108 KB    | ################################################################################################################################################################################################################################### | 100% 
sqlite-3.36.0        | 1.1 MB    | ################################################################################################################################################################################################################################### | 100% 
mkl_random-1.2.2     | 285 KB    | ################################################################################################################################################################################################################################### | 100% 
cycler-0.10.0        | 16 KB     | ################################################################################################################################################################################################################################### | 100% 
matplotlib-3.4.2     | 26 KB     | ################################################################################################################################################################################################################################### | 100% 
ca-certificates-2021 | 113 KB    | ################################################################################################################################################################################################################################### | 100% 
cached-property-1.5. | 11 KB     | ################################################################################################################################################################################################################################### | 100% 
threadpoolctl-2.2.0  | 16 KB     | ################################################################################################################################################################################################################################### | 100% 
numpy-base-1.20.3    | 4.3 MB    | ################################################################################################################################################################################################################################### | 100% 
itsdangerous-2.0.1   | 18 KB     | ################################################################################################################################################################################################################################### | 100% 
python-3.9.6         | 9.7 MB    | ################################################################################################################################################################################################################################### | 100% 
nbconvert-6.1.0      | 484 KB    | ################################################################################################################################################################################################################################### | 100% 
tornado-6.1          | 587 KB    | ################################################################################################################################################################################################################################### | 100% 
mkl-service-2.4.0    | 45 KB     | ################################################################################################################################################################################################################################### | 100% 
munkres-1.1.4        | 13 KB     | ################################################################################################################################################################################################################################### | 100% 
matplotlib-inline-0. | 12 KB     | ################################################################################################################################################################################################################################### | 100% 
jinja2-3.0.1         | 110 KB    | ################################################################################################################################################################################################################################### | 100% 
jedi-0.18.0          | 909 KB    | ################################################################################################################################################################################################################################### | 100% 
lxml-4.6.3           | 1.2 MB    | ################################################################################################################################################################################################################################### | 100% 
pandas-1.3.1         | 9.2 MB    | ################################################################################################################################################################################################################################### | 100% 
fonttools-4.25.0     | 632 KB    | ################################################################################################################################################################################################################################### | 100% 
tqdm-4.62.0          | 83 KB     | ################################################################################################################################################################################################################################### | 100% 
matplotlib-base-3.4. | 5.6 MB    | ################################################################################################################################################################################################################################### | 100% 
sip-4.19.13          | 243 KB    | ################################################################################################################################################################################################################################### | 100% 
cffi-1.14.6          | 215 KB    | ################################################################################################################################################################################################################################### | 100% 
openjpeg-2.3.0       | 281 KB    | ################################################################################################################################################################################################################################### | 100% 
python-dateutil-2.8. | 233 KB    | ################################################################################################################################################################################################################################### | 100% 
qtconsole-5.1.0      | 98 KB     | ################################################################################################################################################################################################################################### | 100% 
notebook-6.4.1       | 4.1 MB    | ################################################################################################################################################################################################################################### | 100% 
importlib-metadata-3 | 33 KB     | ################################################################################################################################################################################################################################### | 100% 
jmespath-0.10.0      | 23 KB     | ################################################################################################################################################################################################################################### | 100% 
urllib3-1.26.6       | 112 KB    | ################################################################################################################################################################################################################################### | 100% 
decorator-5.0.9      | 12 KB     | ################################################################################################################################################################################################################################### | 100% 
entrypoints-0.3      | 12 KB     | ################################################################################################################################################################################################################################### | 100% 
appnope-0.1.2        | 10 KB     | ################################################################################################################################################################################################################################### | 100% 
ipython-7.26.0       | 996 KB    | ################################################################################################################################################################################################################################### | 100% 
argon2-cffi-20.1.0   | 44 KB     | ################################################################################################################################################################################################################################### | 100% 
kiwisolver-1.3.1     | 53 KB     | ################################################################################################################################################################################################################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: | 

    Installed package of scikit-learn can be accelerated using scikit-learn-intelex.
    More details are available here: https://intel.github.io/scikit-learn-intelex

    For example:

        $ conda install scikit-learn-intelex
        $ python -m sklearnex my_application.py

    

done
Installing pip dependencies: / Ran pip subprocess with arguments:
['/opt/anaconda3/envs/tensorflow/bin/python', '-m', 'pip', 'install', '-U', '-r', '/Users/Anshul/Documents/ML/condaenv.u702ztn8.requirements.txt']
Pip subprocess output:

Pip subprocess error:
  ERROR: Invalid requirement: 'apple::tensorflow-deps' (from line 6 of /Users/Anshul/Documents/ML/condaenv.u702ztn8.requirements.txt)

failed

CondaEnvException: Pip failed
```
</details>
<br>

After installing this, I ignored the error and went along with the rest of the installation process, and had a few *more* errors along the way. Here's my terminal input and output directly after the terminal output from above:
<br>
```
(base) Anshul@Anshuls-MacBook-Pro ML % conda env create -f tensorflow-apple-metal.yml -n tensorflow

CondaValueError: prefix already exists: /opt/anaconda3/envs/tensorflow

(base) Anshul@Anshuls-MacBook-Pro ML % conda activate tensorflow
(tensorflow) Anshul@Anshuls-MacBook-Pro ML % conda install nb_conda
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: / 
Found conflicts! Looking for incompatible packages.
This can take several minutes.  Press CTRL-C to abort.
failed                                                                                                                                                                                                                                                                        

UnsatisfiableError: The following specifications were found
to be incompatible with the existing python installation in your environment:

Specifications:

  - nb_conda -> python[version='>=2.7,<2.8.0a0|>=3.6,<3.7.0a0|>=3.7,<3.8.0a0|>=3.8,<3.9.0a0|>=3.5,<3.6.0a0']

Your python: python=3.9

If python is on the left-most side of the chain, that's the version you've asked for.
When python appears to the right, that indicates that the thing on the left is somehow
not available for the python version you are constrained to. Note that conda will not
change your python version to a different minor version unless you explicitly specify
that.



(tensorflow) Anshul@Anshuls-MacBook-Pro ML % python -m ipykernel install --user --name tensorflow --display-name ""Python 3.9 (tensorflow)""

Installed kernelspec tensorflow in /Users/Anshul/Library/Jupyter/kernels/tensorflow
(tensorflow) Anshul@Anshuls-MacBook-Pro ML % jupyter notebook
```

Jupyter Notebook is able to run, but once I create a new tensorflow notebook and run `import tensorflow`, I get the error `ModuleNotFoundError: No module named 'tensorflow'`. 

I've spent half the day trying to set up Tensorflow on my M1 Mac but keep falling into loops of errors, hence I spent over an hour writing this issue. Anything I seem to alter always causes another issue, and it's a little frustrating given that I haven't been able to even start using ML on my local machine yet. Any help at all would be really appreciated. Thanks!

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Attached a [txt file](https://github.com/tensorflow/tensorflow/files/6959610/pain.txt)."
51402,Gather not working as expected in TFLite,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
In TFLite, gather over a tensor of string types fails.

**Describe the expected behavior**
I expect it to behave in the same way gather over integer types does

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

names = tf.keras.Input(shape=(2,), dtype=tf.string)
model = tf.keras.Model(
    inputs=names,
    outputs=tf.gather(names, tf.constant([0])),
)

model.save('./export')
converter = tf.lite.TFLiteConverter.from_saved_model('./export')
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

interpreter = tf.lite.Interpreter(model_path='model.tflite')
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
interpreter.set_tensor(input_details[0]['index'], np.array([[1, 2]], dtype=np.string))
interpreter.invoke()
interpreter.get_tensor(output_details[0]['index'])
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-19-533b631ac475> in <module>
     15 
     16 interpreter = tf.lite.Interpreter(model_path='model.tflite')
---> 17 interpreter.allocate_tensors()
     18 input_details = interpreter.get_input_details()
     19 output_details = interpreter.get_output_details()

/code/venvs/venv/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)
    406   def allocate_tensors(self):
    407     self._ensure_safe()
--> 408     return self._interpreter.AllocateTensors()
    409 
    410   def _safe_to_run(self):

RuntimeError: tensorflow/lite/kernels/gather.cc:76 NumDimensions(input) != 1 (2 != 1)Node number 0 (GATHER) failed to prepare.
```

Changing the types from `string` to `int64` returns `array([[1, 2]])`, though I don't totally understand why it doesn't return `array([1, 2])`
"
51401,AttributeError: type object 'IteratorBase' has no attribute 'from_structure',"ｔｅｎｓｏｒｆｌｏｗ　２．５

I've issued this https://github.com/tensorflow/tensorflow/issues/50871. However, there's no reply at all. May it has been forgotten, so I have to raise this issue again.

```
import tensorflow as tf

training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random.uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
    # Initialize an iterator over the training dataset.
    sess.run(training_init_op)
    for _ in range(100):
        sess.run(next_element)

    # Initialize an iterator over the validation dataset.
    sess.run(validation_init_op)
    for _ in range(50):
        sess.run(next_element)`

```"
51400,Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_LAUNCH_FAILED,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Conda
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1.168/7.6.5
- GPU model and memory: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Can't complete any TensorFlow Operations (i.e. import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000]))))

**Describe the expected behavior**
Complete TensorFlow Operations

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import os
os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'
import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Logs:
```
(base) user@computer:~$ python
Python 3.8.8 (default, Apr 13 2021, 19:58:26) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import os
>>> os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'
>>> import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))
2021-08-09 18:25:50.895134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-08-09 18:25:51.967116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2021-08-09 18:25:52.035250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-08-09 18:25:52.036032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: 
pciBusID: 0000:06:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-08-09 18:25:52.037043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: 
pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-08-09 18:25:52.037996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 3 with properties: 
pciBusID: 0000:0a:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2021-08-09 18:25:52.038016: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2021-08-09 18:25:52.039398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2021-08-09 18:25:52.039431: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2021-08-09 18:25:52.040687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2021-08-09 18:25:52.040882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2021-08-09 18:25:52.042260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2021-08-09 18:25:52.043012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2021-08-09 18:25:52.045963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2021-08-09 18:25:52.052758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2, 3
2021-08-09 18:25:52.053048: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-09 18:25:52.072766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3597710000 Hz
2021-08-09 18:25:52.073339: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5618cc45fbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-08-09 18:25:52.073366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-08-09 18:26:22.377801: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
Aborted (core dumped)
```

Anaconda Package List:
```
_ipyw_jlab_nb_ext_conf    0.1.0                    py38_0  
_libgcc_mutex             0.1                        main  
_tflow_select             2.1.0                       gpu  
absl-py                   0.13.0           py38h06a4308_0  
alabaster                 0.7.12             pyhd3eb1b0_0  
anaconda                  2021.05                  py38_0  
anaconda-client           1.7.2                    py38_0  
anaconda-navigator        2.0.3                    py38_0  
anaconda-project          0.9.1              pyhd3eb1b0_1  
anyio                     2.2.0            py38h06a4308_1  
appdirs                   1.4.4                      py_0  
argh                      0.26.2                   py38_0  
argon2-cffi               20.1.0           py38h27cfd23_1  
asn1crypto                1.4.0                      py_0  
astor                     0.8.1            py38h06a4308_0  
astroid                   2.5              py38h06a4308_1  
astropy                   4.2.1            py38h27cfd23_1  
astunparse                1.6.3                      py_0  
async_generator           1.10               pyhd3eb1b0_0  
atomicwrites              1.4.0                      py_0  
attrs                     20.3.0             pyhd3eb1b0_0  
autopep8                  1.5.6              pyhd3eb1b0_0  
babel                     2.9.0              pyhd3eb1b0_0  
backcall                  0.2.0              pyhd3eb1b0_0  
backports                 1.0                pyhd3eb1b0_2  
backports.functools_lru_cache 1.6.4              pyhd3eb1b0_0  
backports.shutil_get_terminal_size 1.0.0              pyhd3eb1b0_3  
backports.tempfile        1.0                pyhd3eb1b0_1  
backports.weakref         1.0.post1                  py_1  
beautifulsoup4            4.9.3              pyha847dfd_0  
bitarray                  2.1.0            py38h27cfd23_1  
bkcharts                  0.2                      py38_0  
black                     19.10b0                    py_0  
blas                      1.0                         mkl  
bleach                    3.3.0              pyhd3eb1b0_0  
blinker                   1.4              py38h06a4308_0  
blosc                     1.21.0               h8c45485_0  
bokeh                     2.3.2            py38h06a4308_0  
boto                      2.49.0                   py38_0  
bottleneck                1.3.2            py38heb32a55_1  
brotlipy                  0.7.0           py38h27cfd23_1003  
bzip2                     1.0.8                h7b6447c_0  
c-ares                    1.17.1               h27cfd23_0  
ca-certificates           2021.4.13            h06a4308_1  
cachetools                4.2.2              pyhd3eb1b0_0  
cairo                     1.16.0               hf32fb01_1  
certifi                   2020.12.5        py38h06a4308_0  
cffi                      1.14.5           py38h261ae71_0  
chardet                   4.0.0           py38h06a4308_1003  
click                     7.1.2              pyhd3eb1b0_0  
cloudpickle               1.6.0                      py_0  
clyent                    1.2.2                    py38_1  
colorama                  0.4.4              pyhd3eb1b0_0  
conda                     4.10.3           py38h06a4308_0  
conda-build               3.21.4           py38h06a4308_0  
conda-content-trust       0.1.1              pyhd3eb1b0_0  
conda-env                 2.6.0                         1  
conda-package-handling    1.7.3            py38h27cfd23_1  
conda-repo-cli            1.0.4              pyhd3eb1b0_0  
conda-token               0.3.0              pyhd3eb1b0_0  
conda-verify              3.4.2                      py_1  
contextlib2               0.6.0.post1                py_0  
coverage                  5.5              py38h27cfd23_2  
cryptography              3.4.7            py38hd23ed53_0  
cudatoolkit               10.1.243             h6bb024c_0  
cudnn                     7.6.5                cuda10.1_0  
cupti                     10.1.168                      0  
curl                      7.71.1               hbc83047_1  
cycler                    0.10.0                   py38_0  
cython                    0.29.23          py38h2531618_0  
cytoolz                   0.11.0           py38h7b6447c_0  
dask                      2021.4.0           pyhd3eb1b0_0  
dask-core                 2021.4.0           pyhd3eb1b0_0  
dataclasses               0.8                pyh6d0b6a4_7  
dbus                      1.13.18              hb2f20db_0  
decorator                 5.0.6              pyhd3eb1b0_0  
defusedxml                0.7.1              pyhd3eb1b0_0  
diff-match-patch          20200713                   py_0  
distributed               2021.4.1         py38h06a4308_0  
docutils                  0.17.1           py38h06a4308_1  
entrypoints               0.3                      py38_0  
et_xmlfile                1.0.1                   py_1001  
expat                     2.3.0                h2531618_2  
fastcache                 1.1.0            py38h7b6447c_0  
filelock                  3.0.12             pyhd3eb1b0_1  
flake8                    3.9.0              pyhd3eb1b0_0  
flask                     1.1.2              pyhd3eb1b0_0  
fontconfig                2.13.1               h6c09931_0  
freetype                  2.10.4               h5ab3b9f_0  
fribidi                   1.0.10               h7b6447c_0  
fsspec                    0.9.0              pyhd3eb1b0_0  
future                    0.18.2                   py38_1  
gast                      0.4.0                      py_0  
get_terminal_size         1.0.0                haa9412d_0  
gevent                    21.1.2           py38h27cfd23_1  
glib                      2.68.1               h36276a3_0  
glob2                     0.7                pyhd3eb1b0_0  
gmp                       6.2.1                h2531618_2  
gmpy2                     2.0.8            py38hd5f6e3b_3  
google-auth               1.21.3                     py_0  
google-auth-oauthlib      0.4.4              pyhd3eb1b0_0  
google-pasta              0.2.0                      py_0  
gperftools                2.7                  h767d802_2    conda-forge
graphite2                 1.3.14               h23475e2_0  
greenlet                  1.0.0            py38h2531618_2  
grpcio                    1.36.1           py38h2157cd5_1  
gst-plugins-base          1.14.0               h8213a91_2  
gstreamer                 1.14.0               h28cd5cc_2  
h5py                      2.10.0           py38h7918eee_0  
harfbuzz                  2.8.0                h6f93f22_0  
hdf5                      1.10.4               hb1b8bf9_0  
heapdict                  1.0.1                      py_0  
html5lib                  1.1                        py_0  
huggingface_hub           0.0.8                      py_0    huggingface
icu                       58.2                 he6710b0_3  
idna                      2.10               pyhd3eb1b0_0  
imageio                   2.9.0              pyhd3eb1b0_0  
imagesize                 1.2.0              pyhd3eb1b0_0  
importlib-metadata        3.10.0           py38h06a4308_0  
importlib_metadata        3.10.0               hd3eb1b0_0  
iniconfig                 1.1.1              pyhd3eb1b0_0  
intel-openmp              2021.2.0           h06a4308_610  
intervaltree              3.1.0                      py_0  
ipykernel                 5.3.4            py38h5ca1d4c_0  
ipython                   7.22.0           py38hb070fc8_0  
ipython_genutils          0.2.0              pyhd3eb1b0_1  
ipywidgets                7.6.3              pyhd3eb1b0_1  
isort                     5.8.0              pyhd3eb1b0_0  
itsdangerous              1.1.0              pyhd3eb1b0_0  
jbig                      2.1                  hdba287a_0  
jdcal                     1.4.1                      py_0  
jedi                      0.17.2           py38h06a4308_1  
jeepney                   0.6.0              pyhd3eb1b0_0  
jinja2                    2.11.3             pyhd3eb1b0_0  
joblib                    1.0.1              pyhd3eb1b0_0  
jpeg                      9b                   h024ee3a_2  
json5                     0.9.5                      py_0  
jsonschema                3.2.0                      py_2  
jupyter                   1.0.0                    py38_7  
jupyter-packaging         0.7.12             pyhd3eb1b0_0  
jupyter_client            6.1.12             pyhd3eb1b0_0  
jupyter_console           6.4.0              pyhd3eb1b0_0  
jupyter_core              4.7.1            py38h06a4308_0  
jupyter_server            1.4.1            py38h06a4308_0  
jupyterlab                3.0.14             pyhd3eb1b0_1  
jupyterlab_pygments       0.1.2                      py_0  
jupyterlab_server         2.4.0              pyhd3eb1b0_0  
jupyterlab_widgets        1.0.0              pyhd3eb1b0_1  
keras-preprocessing       1.1.2              pyhd3eb1b0_0  
keyring                   22.3.0           py38h06a4308_0  
kiwisolver                1.3.1            py38h2531618_0  
krb5                      1.18.2               h173b8e3_0  
lazy-object-proxy         1.6.0            py38h27cfd23_0  
lcms2                     2.12                 h3be6417_0  
ld_impl_linux-64          2.33.1               h53a641e_7  
libarchive                3.4.2                h62408e4_0  
libcurl                   7.71.1               h20c2e04_1  
libedit                   3.1.20210216         h27cfd23_1  
libev                     4.33                 h7b6447c_0  
libffi                    3.3                  he6710b0_2  
libgcc-ng                 9.1.0                hdf63c60_0  
libgfortran-ng            7.3.0                hdf63c60_0  
liblief                   0.10.1               he6710b0_0  
libllvm10                 10.0.1               hbcb73fb_5  
libpng                    1.6.37               hbc83047_0  
libprotobuf               3.17.2               h4ff587b_1  
libsodium                 1.0.18               h7b6447c_0  
libspatialindex           1.9.3                h2531618_0  
libssh2                   1.9.0                h1ba5d50_1  
libstdcxx-ng              9.1.0                hdf63c60_0  
libtiff                   4.2.0                h85742a9_0  
libtool                   2.4.6             h7b6447c_1005  
libuuid                   1.0.3                h1bed415_2  
libuv                     1.40.0               h7b6447c_0  
libwebp-base              1.2.0                h27cfd23_0  
libxcb                    1.14                 h7b6447c_0  
libxml2                   2.9.10               hb55368b_3  
libxslt                   1.1.34               hc22bd24_0  
llvmlite                  0.36.0           py38h612dafd_4  
locket                    0.2.1            py38h06a4308_1  
lxml                      4.6.3            py38h9120a33_0  
lz4-c                     1.9.3                h2531618_0  
lzo                       2.10                 h7b6447c_2  
markdown                  3.3.4            py38h06a4308_0  
markupsafe                1.1.1            py38h7b6447c_0  
matplotlib                3.3.4            py38h06a4308_0  
matplotlib-base           3.3.4            py38h62a2d02_0  
mccabe                    0.6.1                    py38_1  
mistune                   0.8.4           py38h7b6447c_1000  
mkl                       2021.2.0           h06a4308_296  
mkl-service               2.3.0            py38h27cfd23_1  
mkl_fft                   1.3.0            py38h42c9631_2  
mkl_random                1.2.1            py38ha9443f7_2  
mock                      4.0.3              pyhd3eb1b0_0  
more-itertools            8.7.0              pyhd3eb1b0_0  
mpc                       1.1.0                h10f8cd9_1  
mpfr                      4.0.2                hb69a4c5_1  
mpmath                    1.2.1            py38h06a4308_0  
msgpack-python            1.0.2            py38hff7bd54_1  
multipledispatch          0.6.0                    py38_0  
mypy_extensions           0.4.3                    py38_0  
navigator-updater         0.2.1                    py38_0  
nbclassic                 0.2.6              pyhd3eb1b0_0  
nbclient                  0.5.3              pyhd3eb1b0_0  
nbconvert                 6.0.7                    py38_0  
nbformat                  5.1.3              pyhd3eb1b0_0  
ncurses                   6.2                  he6710b0_1  
nest-asyncio              1.5.1              pyhd3eb1b0_0  
networkx                  2.5                        py_0  
nltk                      3.6.1              pyhd3eb1b0_0  
nose                      1.3.7           pyhd3eb1b0_1006  
notebook                  6.3.0            py38h06a4308_0  
numba                     0.53.1           py38ha9443f7_0  
numexpr                   2.7.3            py38h22e1b3c_1  
numpy                     1.20.1           py38h93e21f0_0  
numpy-base                1.20.1           py38h7d8b39e_0  
numpydoc                  1.1.0              pyhd3eb1b0_1  
oauthlib                  3.1.1              pyhd3eb1b0_0  
olefile                   0.46                       py_0  
openpyxl                  3.0.7              pyhd3eb1b0_0  
openssl                   1.1.1k               h27cfd23_0  
opt_einsum                3.3.0              pyhd3eb1b0_1  
packaging                 20.9               pyhd3eb1b0_0  
pandas                    1.2.4            py38h2531618_0  
pandoc                    2.12                 h06a4308_0  
pandocfilters             1.4.3            py38h06a4308_1  
pango                     1.45.3               hd140c19_0  
parso                     0.7.0                      py_0  
partd                     1.2.0              pyhd3eb1b0_0  
patchelf                  0.12                 h2531618_1  
path                      15.1.2           py38h06a4308_0  
path.py                   12.5.0                        0  
pathlib2                  2.3.5            py38h06a4308_2  
pathspec                  0.7.0                      py_0  
patsy                     0.5.1                    py38_0  
pcre                      8.44                 he6710b0_0  
pep8                      1.7.1                    py38_0  
perl                      5.26.2               h14c3975_0  
pexpect                   4.8.0              pyhd3eb1b0_3  
pickleshare               0.7.5           pyhd3eb1b0_1003  
pillow                    8.2.0            py38he98fc37_0  
pip                       21.0.1           py38h06a4308_0  
pixman                    0.40.0               h7b6447c_0  
pkginfo                   1.7.0            py38h06a4308_0  
pluggy                    0.13.1           py38h06a4308_0  
ply                       3.11                     py38_0  
prometheus_client         0.10.1             pyhd3eb1b0_0  
prompt-toolkit            3.0.17             pyh06a4308_0  
prompt_toolkit            3.0.17               hd3eb1b0_0  
protobuf                  3.17.2           py38h295c915_0  
psutil                    5.8.0            py38h27cfd23_1  
ptyprocess                0.7.0              pyhd3eb1b0_2  
py                        1.10.0             pyhd3eb1b0_0  
py-lief                   0.10.1           py38h403a769_0  
pyasn1                    0.4.8                      py_0  
pyasn1-modules            0.2.8                      py_0  
pycodestyle               2.6.0              pyhd3eb1b0_0  
pycosat                   0.6.3            py38h7b6447c_1  
pycparser                 2.20                       py_2  
pycurl                    7.43.0.6         py38h1ba5d50_0  
pydocstyle                6.0.0              pyhd3eb1b0_0  
pyerfa                    1.7.3            py38h27cfd23_0  
pyflakes                  2.2.0              pyhd3eb1b0_0  
pygments                  2.8.1              pyhd3eb1b0_0  
pyjwt                     2.1.0            py38h06a4308_0  
pylint                    2.7.4            py38h06a4308_1  
pyls-black                0.4.6                hd3eb1b0_0  
pyls-spyder               0.3.2              pyhd3eb1b0_0  
pyodbc                    4.0.30           py38he6710b0_0  
pyopenssl                 20.0.1             pyhd3eb1b0_1  
pyparsing                 2.4.7              pyhd3eb1b0_0  
pyqt                      5.9.2            py38h05f1152_4  
pyrsistent                0.17.3           py38h7b6447c_0  
pysocks                   1.7.1            py38h06a4308_0  
pytables                  3.6.1            py38h9fd0a39_0  
pytest                    6.2.3            py38h06a4308_2  
python                    3.8.8                hdb3f193_5  
python-dateutil           2.8.1              pyhd3eb1b0_0  
python-flatbuffers        1.12               pyhd3eb1b0_0  
python-jsonrpc-server     0.4.0                      py_0  
python-language-server    0.36.2             pyhd3eb1b0_0  
python-libarchive-c       2.9                pyhd3eb1b0_1  
python_abi                3.8                      1_cp38    huggingface
pytz                      2021.1             pyhd3eb1b0_0  
pywavelets                1.1.1            py38h7b6447c_2  
pyxdg                     0.27               pyhd3eb1b0_0  
pyyaml                    5.4.1            py38h27cfd23_1  
pyzmq                     20.0.0           py38h2531618_1  
qdarkstyle                2.8.1                      py_0  
qt                        5.9.7                h5867ecd_1  
qtawesome                 1.0.2              pyhd3eb1b0_0  
qtconsole                 5.0.3              pyhd3eb1b0_0  
qtpy                      1.9.0                      py_0  
readline                  8.1                  h27cfd23_0  
regex                     2021.4.4         py38h27cfd23_0  
requests                  2.25.1             pyhd3eb1b0_0  
requests-oauthlib         1.3.0                      py_0  
ripgrep                   12.1.1                        0  
rope                      0.18.0                     py_0  
rsa                       4.7.2              pyhd3eb1b0_1  
rtree                     0.9.7            py38h06a4308_1  
ruamel_yaml               0.15.100         py38h27cfd23_0  
sacremoses                master                     py_0    huggingface
scikit-image              0.18.1           py38ha9443f7_0  
scikit-learn              0.24.1           py38ha9443f7_0  
scipy                     1.6.2            py38had2a1c9_1  
seaborn                   0.11.1             pyhd3eb1b0_0  
secretstorage             3.3.1            py38h06a4308_0  
send2trash                1.5.0              pyhd3eb1b0_1  
sentencepiece             0.1.91           py38hbf85e49_3    conda-forge
setuptools                52.0.0           py38h06a4308_0  
simplegeneric             0.8.1                    py38_2  
singledispatch            3.6.1           pyhd3eb1b0_1001  
sip                       4.19.13          py38he6710b0_0  
six                       1.15.0           py38h06a4308_0  
sniffio                   1.2.0            py38h06a4308_1  
snowballstemmer           2.1.0              pyhd3eb1b0_0  
sortedcollections         2.1.0              pyhd3eb1b0_0  
sortedcontainers          2.3.0              pyhd3eb1b0_0  
soupsieve                 2.2.1              pyhd3eb1b0_0  
sphinx                    4.0.1              pyhd3eb1b0_0  
sphinxcontrib             1.0                      py38_1  
sphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0  
sphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0  
sphinxcontrib-htmlhelp    1.0.3              pyhd3eb1b0_0  
sphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0  
sphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0  
sphinxcontrib-serializinghtml 1.1.4              pyhd3eb1b0_0  
sphinxcontrib-websupport  1.2.4                      py_0  
spyder                    4.2.5            py38h06a4308_0  
spyder-kernels            1.10.2           py38h06a4308_0  
sqlalchemy                1.4.15           py38h27cfd23_0  
sqlite                    3.35.4               hdfb4753_0  
statsmodels               0.12.2           py38h27cfd23_0  
sympy                     1.8              py38h06a4308_0  
tbb                       2020.3               hfd86e86_0  
tblib                     1.7.0                      py_0  
tensorboard               2.4.0              pyhc547734_0  
tensorboard-plugin-wit    1.6.0                      py_0  
tensorflow                2.4.1           gpu_py38h8a7d6ce_0  
tensorflow-base           2.4.1           gpu_py38h29c2da4_0  
tensorflow-estimator      2.4.1              pyheb71bc4_0  
tensorflow-gpu            2.4.1                h30adc30_0  
termcolor                 1.1.0            py38h06a4308_1  
terminado                 0.9.4            py38h06a4308_0  
testpath                  0.4.4              pyhd3eb1b0_0  
textdistance              4.2.1              pyhd3eb1b0_0  
threadpoolctl             2.1.0              pyh5ca1d4c_0  
three-merge               0.1.1              pyhd3eb1b0_0  
tifffile                  2020.10.1        py38hdd07704_2  
tk                        8.6.10               hbc83047_0  
tokenizers                0.10.3                   py38_0    huggingface
toml                      0.10.2             pyhd3eb1b0_0  
toolz                     0.11.1             pyhd3eb1b0_0  
tornado                   6.1              py38h27cfd23_0  
tqdm                      4.59.0             pyhd3eb1b0_1  
traitlets                 5.0.5              pyhd3eb1b0_0  
transformers              4.8.1                      py_0    huggingface
typed-ast                 1.4.2            py38h27cfd23_1  
typing_extensions         3.7.4.3            pyha847dfd_0  
ujson                     4.0.2            py38h2531618_0  
unicodecsv                0.14.1                   py38_0  
unixodbc                  2.3.9                h7b6447c_0  
urllib3                   1.26.4             pyhd3eb1b0_0  
watchdog                  1.0.2            py38h06a4308_1  
wcwidth                   0.2.5                      py_0  
webencodings              0.5.1                    py38_1  
werkzeug                  1.0.1              pyhd3eb1b0_0  
wheel                     0.36.2             pyhd3eb1b0_0  
widgetsnbextension        3.5.1                    py38_0  
wrapt                     1.12.1           py38h7b6447c_1  
wurlitzer                 2.1.0            py38h06a4308_0  
xlrd                      2.0.1              pyhd3eb1b0_0  
xlsxwriter                1.3.8              pyhd3eb1b0_0  
xlwt                      1.3.0                    py38_0  
xmltodict                 0.12.0                     py_0  
xz                        5.2.5                h7b6447c_0  
yaml                      0.2.5                h7b6447c_0  
yapf                      0.31.0             pyhd3eb1b0_0  
zeromq                    4.3.4                h2531618_0  
zict                      2.0.0              pyhd3eb1b0_0  
zipp                      3.4.1              pyhd3eb1b0_0  
zlib                      1.2.11               h7b6447c_3  
zope                      1.0                      py38_1  
zope.event                4.5.0                    py38_0  
zope.interface            5.3.0            py38h27cfd23_0  
zstd                      1.4.5                h9ceee32_0
```

"
51399,setting learning rate with `tk.backend.set_value` fails with `tf.keras.optimizers.schedules`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): '2.5.0'
- Python version: '3.8.10'

**Describe the current behavior**

Check the code snippet with two cases below

**Describe the expected behavior**

Both the cases should succeed.
Currently, when `learning_rate` is not a schedule it works.

**Standalone code to reproduce the issue**

```python
import tensorflow.keras as tk

# [1] this case works
_o = tk.optimizers.Adam(learning_rate=3.44)
tk.backend.set_value(_o.learning_rate, 0.01)

# [2] but when using learning rate sheculer it fails
_o = tk.optimizers.Adam(learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(0.1, 1000, 0.96))
tk.backend.set_value(_o.learning_rate, 0.01)
```
Fails with below error
```txt
Traceback (most recent call last):
  File ""C:\Python38\lib\site-packages\IPython\core\interactiveshell.py"", line 3441, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-85-b93ddba04c22>"", line 3, in <module>
    tk.backend.set_value(_o.learning_rate, 0.01)
  File ""C:\Python38\lib\site-packages\tensorflow\python\keras\backend.py"", line 3769, in set_value
    value = np.asarray(value, dtype=dtype(x))
  File ""C:\Python38\lib\site-packages\tensorflow\python\util\dispatch.py"", line 206, in wrapper
    return target(*args, **kwargs)
  File ""C:\Python38\lib\site-packages\tensorflow\python\keras\backend.py"", line 1516, in dtype
    return x.dtype.base_dtype.name
AttributeError: 'ExponentialDecay' object has no attribute 'dtype'
```

"
51395,[AutoML] [Tensorflow Lite] Export for TensorFlow Lite is broken for confidence score,"**System information**
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.9.5

**Describe the current behavior**
I trained a model on a dataset via AutoML Vision and exported models[ using the UI.](https://cloud.google.com/vision/automl/object-detection/docs/export-edge)  I've used AutoML in the past and the models have always worked well.

The .tflite version has bounding boxes and class names that are perfectly correct, but the confidence scores are wrong.

Specifically, the .tflite seems to cap its confidence score at 50%. It never goes higher than 50%.

Given the same input image, the top 4 confidence scores are as follows:
for .tflite `0.5, 0.0429, 0.0273, .002343`
for tf js `0.9975, 0.02638, 0.0182, 0.00969`

**Describe the expected behavior**
The top confidence score should not be 0.5 and should instead be around 0.99 in the tflite

According to Netron, the TF run time for the TFLite was 2.5.0. For the TF JS, the model.json indicates that it was generated by 2.7.0 (the brand new release). I don't have any obvious way to select what runtime I want TFLite to be exported in.

**Standalone code to reproduce the issue**
I used basic code to test the TF JS
```
<!---- python -m SimpleHTTPServer 8000 ---->

<script src=""https://unpkg.com/@tensorflow/tfjs""></script>
<script src=""https://unpkg.com/@tensorflow/tfjs-automl""></script>
<img id=""salad"" crossorigin=""anonymous"" src=""test.jpeg"">
<script>
async function run() {
  const model = await tf.automl.loadObjectDetection('model.json');
  const img = document.getElementById('salad');
const options = {score: 0.005, iou: 0.5, topk: 5};
  const predictions = await model.detect(img, options); // , options
  console.log(predictions);
  // Show the resulting object on the page.
  const pre = document.createElement('pre');
  pre.textContent = JSON.stringify(predictions, null, 2);
  document.body.append(pre);
}
run();
</script>
```

And the Tensorflow Lite tester:
```
import numpy as np
import tensorflow as tf
import cv2

img = cv2.imread(""test.jpeg"")
new_img = cv2.resize(img, (320,320))

# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""model.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the model on random input data.
interpreter.set_tensor(input_details[0]['index'], [new_img])

interpreter.invoke()

# Show the scores
scores = interpreter.get_tensor(output_details[2]['index'])
print(scores)
```


Couple of questions:
1. What would a capped confidence of 50% be a symptom of? (Something weird with quantization?)
2. Should I just multiple the confidence score by 2 or is that completely wrong?
3. Is this the right place to post about AutoML bugs?
"
51394,memory allocation exceeds 10 of free system memory,"tensorflow2.5
ubuntu 18.10
memory 16gb

I've added the swap memory up to 8 gb, but still showing the warning of that message. In the meaning time, I find the swap allocation is almost 0. 
What happens, the tensorflow cannot use the swap? 
Which kind of memory is not enough, is it gpu memory or just physical memory?
Also I'd like to ask what happens if I continue training ignoring that warning message, the precision being lost, or other effects? 
Why the training could still go on if the training result is not correct?"
51393,Slowdown of `tf.scan` operation in TF 2.5,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave Version 10.14.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.7.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**

There seems to be a considerable slowdown whenever a `tf.scan` operation is used inside the loss function of a model architecture and a learnable parameter (`self.transition_param` below) of the model architecture is part of the `tf.scan` op. Here's a code snippet to reproduce this:

```
import tensorflow as tf
import tensorflow_addons as tfa
from tqdm import tqdm
import numpy as np


def gen_batches(num_batches, batch_size, units):

    for _ in range(num_batches):
        x = np.random.random((batch_size, 20, units))
        y = np.random.randint(1, units, size=(batch_size, 20))
        yield x, y


class MyModel(tf.keras.models.Model):

    def __init__(self, units):
        super().__init__()

        self._tf_layers = {}

        self.units = units

        self.transition_param = self.add_weight(name=""transition_param"", shape=(units, units))

        self.optimizer = tf.keras.optimizers.Adam()
        self._training = False

    def _loss_fn_with_scan(self, inputs, transition_params):

        first_input = tf.slice(inputs, [0, 0, 0], [-1, 1, -1])
        first_input = tf.squeeze(first_input, [1])

        rest_of_input = tf.slice(inputs, [0, 1, 0], [-1, -1, -1])

        rest_of_input = tf.transpose(rest_of_input, [1, 0, 2])
        transition_params = tf.expand_dims(transition_params, 0)

        def _scan_fn(_state, _inputs):
            _state = tf.expand_dims(_state, 2)
            transition_scores = _state + transition_params
            new_alphas = _inputs + tf.reduce_logsumexp(transition_scores, [1])
            return new_alphas

        all_alphas = tf.transpose(tf.scan(_scan_fn, rest_of_input, first_input), [1, 0, 2])
        # add first state for sequences of length 1
        all_alphas = tf.concat([tf.expand_dims(first_input, 1), all_alphas], 1)

        return all_alphas

    def _loss(self, x, y):

        logits = tf.cast(x, dtype=tf.float32)

        loss = self._loss_fn_with_scan(logits, self.transition_param)

        return tf.reduce_mean(loss)

    @tf.function
    def train_on_batch(self, *args):
        with tf.GradientTape(persistent=True) as tape:
            loss = self._loss(*args)
        grads = tape.gradient(loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))
        return loss

    def train(self, epochs, batch_size, num_batches):

        data_generator_iter = gen_batches(num_batches, batch_size, self.units)

        sample_x, sample_y = next(data_generator_iter)

        self.train_on_batch(sample_x, sample_y)

        self._training = True

        progress_bar = tqdm(range(epochs), desc=""Epochs"")

        for epoch in progress_bar:
            for batch_x, batch_y in data_generator_iter:
                loss = self.train_on_batch(batch_x, batch_y)

            progress_bar.update(1)
            progress_bar.set_postfix({""loss"": f""{loss.numpy():.3f}""})


num_batches = 5000
batch_size = 32
units = 64
epochs = 100

model = MyModel(units)
model.train(epochs, batch_size, num_batches)
```

The same code takes  ~ 3 mins, 16 seconds on TF 2.3 . However, it takes ~ 4 mins and 1 second on TF 2.5 .

The above code is a stripped down version of a model architecture which uses transformers + CRF layer. The `_loss_fn_with_scan` is taken from [`crf_log_norm` function](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/text/crf.py#L157) of tensorflow-addons package but as the snippet shows, the problem is already visible without the CRF bits of the code and just using `tf.scan` as part of the loss function (`tf.scan` is part of tensorflow repo, hence the issue seems appropriate here). On large datasets, the slowdown is considerably large. For example, with TF 2.3 it took 1 hour 20 mins to complete the training and with TF 2.5 it takes close to 3 hours to complete the training which is a considerable increase and a big blocker for us to upgrade to TF 2.5.

**Describe the expected behavior**

Training times should be comparable across TF 2.3 and TF 2.5 .

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): maybe
- Briefly describe your candidate solution(if contributing): I am not familiar with the internals of `tf.scan` op. If there's some help available, we could give it a try.

**Standalone code to reproduce the issue**
A snippet is available above."
51390,version tag mismatch github: v2.5.0 python: 2.5.1,if you build from source from github tag v2.5.0 it produces a module file that's 2.5.1
51389,Android Studio CPU Profiler,"Hello!

I have a model built with tensorflow and exported to tensorflow lite and integrated to Android Studio.  I want to profile it and hence i follow the steps [] (https://www.tensorflow.org/lite/performance/measurement#android_studio_cpu_profiler) in the section of Android Studio CPU Profiler.  However, in the end, I see no thread like the one called ""recognizeImage()"" in the example and I am not able to see the ""per-op"" profile as in the example.

What do I need to implement to visualize the per-op results there?

Thank you!"
51388,"can not open include file,   无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): source
- TensorFlow version:1.2.0
- Python version:3.5.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): CMake 3.8.12
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: disable
- GPU model and memory: disable



**Describe the problem**
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.cc)
  table.cc
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\format.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\buffered_inputstream.cc)
  table_builder.cc
  two_level_iterator.cc
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\gtl\array_slice_internal.h(89): error C2064: 项不会计算为接受 0 个参数的函数 (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\histogram\histogram.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\block.cc)
  zlib_inputstream.cc
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\inputbuffer.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\threadpool.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\block_builder.cc)
  zlib_outputbuffer.cc
  jpeg_handle.cc
  jpeg_mem.cc
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\iterator.cc)
  collection_registry.cc
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\record_reader.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\inputstream_interface.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\record_writer.cc)
  distribution_sampler.cc
  simple_philox.cc
  weighted_picker.cc
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\random_inputstream.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\snappy\snappy_outputbuffer.cc)
f:\temp\tensorflow-1.2.0\tensorflow\core\lib\core\status.h(22): fatal error C1083: 无法打开包括文件: “tensorflow/core/lib/core/error_codes.pb.h”: No such file or directory (编译源文件 F:\temp\tensorflow-1.2.0\tensorflow\core\lib\io\path.cc)
  base64.cc
  proto_text_util.cc
  str_util.cc




**Provide the exact sequence of commands / steps that you executed before running into the problem**
when i use cmake to compile tensorflow from source code, raise up error.
if anyone occur the same error

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
51385,Mixed precision not working with stateful LSTM/GRU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (Colab and own machine)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not tested
- TensorFlow installed from (source or binary): pip from a conda env
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.11
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2
- GPU model and memory: Tested with Tesla T4 (Colab) and GeForce RTX 3090 (24GB RAM)

**Describe the current behavior**

It seems it is not possible to use stateful RNNs (LSTM, GRU) with mixed precision. Trying to run the following on Colab (Tesla T4):

```
import tensorflow as tf
tf.keras.mixed_precision.set_global_policy('mixed_float16')

data = tf.random.uniform((1, 64, 16), minval=0, maxval=1, dtype=tf.float16)
rnn = tf.keras.layers.GRU(1024, return_sequences=True, stateful=True)

rnn(data)
```

I get this error:

```
---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

<ipython-input-5-48878f0a1437> in <module>()
----> 1 rnn(data)

11 frames

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)
    666 
    667     if initial_state is None and constants is None:
--> 668       return super(RNN, self).__call__(inputs, **kwargs)
    669 
    670     # If any of `initial_state` or `constants` are specified and are Keras

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
   1028         with autocast_variable.enable_auto_cast_variables(
   1029             self._compute_dtype_object):
-> 1030           outputs = call_fn(inputs, *args, **kwargs)
   1031 
   1032         if self._activity_regularizer:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in call(self, inputs, mask, training, initial_state)
    456     else:
    457       last_output, outputs, runtime, states = self._defun_gru_call(
--> 458           inputs, initial_state, training, mask, row_lengths)
    459 
    460     if self.stateful:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in _defun_gru_call(self, inputs, initial_state, training, mask, sequence_lengths)
    527         # Under eager context, check the device placement and prefer the
    528         if can_use_gpu:
--> 529           last_output, outputs, new_h, runtime = gpu_gru(**gpu_gru_kwargs)
    530         else:
    531           last_output, outputs, new_h, runtime = standard_gru(

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py in gpu_gru(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)
    690     outputs, h, _, _ = gen_cudnn_rnn_ops.CudnnRNN(
    691         input=inputs, input_h=init_h, input_c=0, params=params,
--> 692         is_training=True, rnn_mode='gru')
    693 
    694   last_output = outputs[-1]

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_export.py in wrapper(*args, **kwargs)
    402           'Please pass these args as kwargs instead.'
    403           .format(f=f.__name__, kwargs=f_argspec.args))
--> 404     return f(**kwargs)
    405 
    406   return tf_decorator.make_decorator(f, wrapper, decorator_argspec=f_argspec)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)
    101           input_mode=input_mode, direction=direction, dropout=dropout,
    102           seed=seed, seed2=seed2, is_training=is_training, name=name,
--> 103           ctx=_ctx)
    104     except _core._SymbolicException:
    105       pass  # Add nodes to the TensorFlow graph.

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_cudnn_rnn_ops.py in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)
    171     is_training = True
    172   is_training = _execute.make_bool(is_training, ""is_training"")
--> 173   _attr_T, _inputs_T = _execute.args_to_matching_eager([input, input_h, input_c, params], ctx, [_dtypes.half, _dtypes.float32, _dtypes.float64, ])
    174   (input, input_h, input_c, params) = _inputs_T
    175   _inputs_flat = [input, input_h, input_c, params]

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in args_to_matching_eager(l, ctx, allowed_dtypes, default_dtype)
    278         dtype = tensor.dtype
    279   else:
--> 280     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]
    281 
    282   # TODO(slebedev): consider removing this as it leaks a Keras concept.

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in <listcomp>(.0)
    278         dtype = tensor.dtype
    279   else:
--> 280     ret = [ops.convert_to_tensor(t, dtype, ctx=ctx) for t in l]
    281 
    282   # TODO(slebedev): consider removing this as it leaks a Keras concept.

/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)
    161         with Trace(trace_name, **trace_kwargs):
    162           return func(*args, **kwargs)
--> 163       return func(*args, **kwargs)
    164 
    165     return wrapped

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1533       raise ValueError(
   1534           ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
-> 1535           (dtype.name, value.dtype.name, value))
   1536     return value
   1537 

ValueError: Tensor conversion requested dtype float16 for Tensor with dtype float32: <tf.Tensor: shape=(1, 1, 1024), dtype=float32, numpy=array([[[0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>
```

Perhaps this is something to do with the dtype of the initial state - the last `ValueError` seems to be printing that tensor (hence the zeroes), with `dtype=float32`. Even if I explicitly set the initial state with a float16 tensor, however, the issue persists.

It makes no difference if I run an LSTM or GRU layer, same error.

I also ran this code on my own Ubuntu machine with a GeForce RTX 3090 (24GB RAM) and got the following:

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute MatMul as input #1(zero-based) was expected to be a float tensor but is a half tensor [Op:MatMul]
```

**Describe the expected behavior**

Without `stateful=True` the code runs without a problem, returning a tensor with shape `(1, 64, 1024)` and `dtype=float16`.

Mixed precision is surely expected to work with stateful RNN layers. The documentation doesn't seem to indicate otherwise, unless I'm missing something.
"
51380,Exception Error while converting Keras LSTM model to TFlite model ,"I have trained an LSTM model that takes in sensor values from a smartphone using Keras and currently am trying to convert the model into TFLite format to deploy it on Android Studio. However, I am facing this issue. I am relatively new to all this, therefore any pointers, suggestions and even criticism to improve my code will be very useful. The error code is too long therefore I have to snip it a little, please refer to the Google Colab file attached to see the full error

### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): Tensorflow 2.3.0

### Command used to run the converter

```
# Convert the model.

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model.
with open('driver_profiler_deploy.tflite', 'wb') as f:
    f.write(tflite_model)

```

#### The output after executing the conversion line

```
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
C:\Anaconda\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    195     try:
--> 196       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
    197                                                  toco_flags_str, input_data_str,

C:\Anaconda\lib\site-packages\tensorflow\lite\python\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     31   """"""Wraps TocoConvert with lazy loader.""""""
---> 32   return _pywrap_toco_api.TocoConvert(
     33       model_flags_str,

Exception: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at ""sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975"") at ""StatefulPartitionedCall@__inference_signature_wrapper_292250"") at ""StatefulPartitionedCall"")): We cannot duplicate the value since it's not constant.

<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(callsite(unknown at ""sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975"") at ""StatefulPartitionedCall@__inference_signature_wrapper_292250"") at ""StatefulPartitionedCall"")): see current operation: %4 = ""tfl.unidirectional_sequence_lstm""(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>
<unknown>:0: error: Failed to duplicate values for the stateful op

<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x50x6xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<[5.58075495E-4, 0.0313672647, -0.0188098513, -0.0246837344]> : tensor<4xf32>} : () -> tensor<4xf32>
  %cst_0 = ""std.constant""() {value = dense<[0.0168908536, 0.0328395516, 0.032890223, 0.0250963103, 0.0189044718, -0.0114660431, 0.0205141585, 0.0246794671, 0.0165602472, 0.0507745668, -0.00160693936, 0.0168250985, 0.0210511424, 0.0273013972, 0.0362471119, 0.0202392936, 0.0296635088, 0.0094857458, 0.0339091942, 0.0257274546, 0.0100004124, -0.0119953547, 0.0321875811, 0.0217365436, 0.0301411357, 0.0284080133, -0.00616158592, 0.0177836455, 0.037834093, 0.0353285074, 0.0446266644, 0.02094361]> : tensor<32xf32>} : () -> tensor<32xf32>
  %cst_1 = ""std.constant""() {value = dense<[-1, 1600]> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_2 = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_3 = ""std.constant""() {value = dense<32> : tensor<i32>} : () -> tensor<i32>
  %cst_4 = ""std.constant""() {value} : () -> none
  %cst_5 = ""std.constant""() {value = dense<""0x507631BD189A80BCD5C2733ED4E290BC50CED43C3A5D883D59216B3D5C8655BE8DA77EBD0730CE3D28808CBC9849F7BDB4B8583E83AFDA3D253A9FBD61E09CBDE40B5DBE664A90BD1FEA963C8C7182BDCB83E93DD8643CBED633A7BDF8BDD63C5D85133DECE2E1BC32DDC13D878B92BD967B4BBEA4FC79BD4EAA463E394DBCBD123B213E5A4FEB3DFE63213DAA4C1BBDC5BDEE59D73D424DE8BD130735BD1E818ABDEF9E433D5A7F68BE8131F93AB20927BB599D563D932DC63D205D933BF7C3D4BD3BEE20BEA67AD1BC""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_6 = ""std.constant""() {value = dense<""0xC5098CBD408DDBBC314E433ECD6BDA3D6FC376BDE191E8BD0C83AA3C26A7D03CB6A3F83D69AC083ED3E450BD7C1A2ABDD5399BBD5B4856BC54154CBE3610BABD3294B3BD1893033E362EEDBDEF55183ED97FD3BD265B0DBD122FBF3A4B74C16BD246F16BE1D03DFBC""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_7 = ""std.constant""() {value = dense<""0x43512EBE2D7D3FBDC919BFBD6E77B93DE12A51BD7C780BBE2DA4A73CC8923D3D2B013A3C11E5A8BD9CED16BEA75EE2BC3943B0BB7EB687BDE02343BDDDCD46BD84D79ABDAB07FC3CDA7143BC824AE3BD2F1275BD5D24B8BA56A2363E5751AC3CDE06223E7679FFBD83C7B5BD""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_8 = ""std.constant""() {value = dense<""0xC1CE5CBC2598F43D11156ABC8639173E5D49453DECB4033E396DAF3D9020C33DFDB9353E89364A3E59B29DBC2AF5A9BD3E71513EABB5893BC79D0BBD62D7CD38CB94EABD31909E3D675939BED9DA9B3D65B9AFBD7D48733D56C0CA3CD6A9173EA0BDE33509BEA77AB0BD456201BE240DB4BE5E4C2CBEF8D79B3DFE3DAEBDB0D999BB4E39663D6196E23C2AD2463C8697C73D0963033E5964F0BDFEDAA43B121F233E""> : tensor<32x6xf32>} : () -> tensor<32x6xf32>
  %cst_14 = ""std.constant""() {value = dense<""0x09496D3D8CCDE5BD2FAEF73D18E2D6BDFE7238BEBC7B4ABE780F26BD53138B3EF7C62DBEF485CF3DBB8291BB9FEF023EDD5F5BBE7B0C25B96605E13D19AB7CBD0C6EDC3D042BC7BDE0458D3DE12FE7BD9B5A833DF7275A3E6C28D1BC9C83E53D87FBED28192BDE1B22E3E2CA9363EE19F3B3E""> : tensor<32x6xf32>} : () -> tensor<32x6xf32>
  %cst_16 = ""std.constant""() {value = dense<""0x231CB5BD1AE52D3EF6D2A7BD26C717BE2297C6BDEB7C47BD2CCF28BDBB5E0ABD75BC53BE884B1DBC63C86E3D1A4536BE4C5E253D22A573BE96AB413E2D9815BE74AEC0BD1E1673BCBE5805BD43E6A6BC995C223EF62F4ABE98F60A3E3219893D53D4E970ABE586DC4BC4847A73D8FCC253EEDCB55BE1F14E33D08BDCFBD8FD334BB512333BEB17B19BE14E8113E0ADA6B3D0A82593E1E270D3E5B538B3DC98F93BDE0B5F23A9E5FF5BA""> : tensor<32x6xf32>} : () -> tensor<32x6xf32>
  %cst_17 = ""std.constant""() {value = dense<""0xC45CFBBC2D98813CD0AE393D99C27A3DF3AD7B3DA82134BCEE687FBB4B4E5FBDBEED0EBD8AFC8DBC3FEFE23CFF39F7BB5234EFBC7CC681BC741B0B3DEA3601BDE4EA72BDB121D23B301740BD4CE70C3D423C45BC57F0513C25B331BD0D05B93C3C04CBBB062967BCBAE113BDE44B993DE177D4BC7145563B0A8E44BDC3B33D3D89B0A0BCA187EBBC3F5A973DD2F6D7BCE9B07D0713C4D7258BD7C6E1C3D872B93BD48C7813D""> : tensor<32x1600xf32>} : () -> tensor<32x1600xf32>
  %cst_18 = ""std.constant""() {value = dense<""0xBEBAAFBEC3EB073E7179C43E0D4656BDD887BCBEDD0FA7BEFC851DBC5A6F9B3E1410183E0722133E5FE27DBE4CB3BD74173EDF66BCBEBAA2B13C""> : tensor<4x32xf32>} : () -> tensor<4x32xf32>
  %cst_19 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_20 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %0 = ""tfl.shape""(%arg0) : (tensor<?x50x6xf32>) -> tensor<3xi32>
  %1 = ""tfl.strided_slice""(%0, %cst_19, %cst_20, %cst_20) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>
  %2 = ""tfl.pack""(%1, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>
  %3 = ""tfl.fill""(%2, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x32xf32>
  %4 = ""tfl.unidirectional_sequence_lstm""(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>
  %5 = ""tfl.reshape""(%4, %cst_1) : (tensor<?x50x32xf32>, tensor<2xi32>) -> tensor<?x1600xf32>
  %6 = ""tfl.fully_connected""(%5, %cst_17, %cst_0) {fused_activation_function = ""RELU"", keep_num_dims = false, weights_format = ""DEFAULT""} : (tensor<?x1600xf32>, tensor<32x1600xf32>, tensor<32xf32>) -> tensor<?x32xf32>
  %7 = ""tfl.fully_connected""(%6, %cst_18, %cst) {fused_activation_function = ""NONE"", keep_num_dims = false, weights_format = ""DEFAULT""} : (tensor<?x32xf32>, tensor<4x32xf32>, tensor<4xf32>) -> tensor<?x4xf32>
  %8 = ""tfl.softmax""(%7) {beta = 1.000000e+00 : f32} : (tensor<?x4xf32>) -> tensor<?x4xf32>
  ""std.return""(%8) : (tensor<?x4xf32>) -> ()
}) {arg0 = {tf_saved_model.index_path = [""LSTM_1st_layer_input""]}, result0 = {tf_saved_model.index_path = [""Dense_Output_Layer""]}, sym_name = ""serving_default"", tf.entry_function = {control_outputs = """", inputs = ""serving_default_LSTM_1st_layer_input:0"", outputs = ""StatefulPartitionedCall:0""}, tf_saved_model.exported_names = [""serving_default""], type = (tensor<?x50x6xf32>) -> tensor<?x4xf32>} : () -> ()


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-514-df6454e45435> in <module>
      1 # Convert the model.
      2 converter = tf.lite.TFLiteConverter.from_keras_model(model)
----> 3 tflite_model = converter.convert()
      4 
      5 # Save the model.

C:\Anaconda\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    785         Invalid quantization parameters.
    786     """"""
--> 787     saved_model_convert_result = self._convert_as_saved_model()
    788     if saved_model_convert_result:
    789       return saved_model_convert_result

C:\Anaconda\lib\site-packages\tensorflow\lite\python\lite.py in _convert_as_saved_model(self)
    767         self._trackable_obj = _load(self.saved_model_dir,
    768                                     self._saved_model_tags)
--> 769         return super(TFLiteKerasModelConverterV2,
    770                      self).convert(meta_graph.graph_def, input_tensors,
    771                                    output_tensors)

C:\Anaconda\lib\site-packages\tensorflow\lite\python\lite.py in convert(self, graph_def, input_tensors, output_tensors)
    627 
    628     # Converts model.
--> 629     result = _toco_convert_impl(
    630         input_data=graph_def,
    631         input_tensors=input_tensors,

C:\Anaconda\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    567       input_tensors, output_tensors, *args, **kwargs)
    568   debug_info_str = debug_info.SerializeToString() if debug_info else None
--> 569   data = toco_convert_protos(
    570       model_flags.SerializeToString(),
    571       toco_flags.SerializeToString(),

C:\Anaconda\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    200       return model_str
    201     except Exception as e:
--> 202       raise ConverterError(str(e))
    203 
    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at ""sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975"") at ""StatefulPartitionedCall@__inference_signature_wrapper_292250"") at ""StatefulPartitionedCall"")): We cannot duplicate the value since it's not constant.

<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(callsite(unknown at ""sequential_16/LSTM_1st_layer/PartitionedCall@__inference__wrapped_model_288975"") at ""StatefulPartitionedCall@__inference_signature_wrapper_292250"") at ""StatefulPartitionedCall"")): see current operation: %4 = ""tfl.unidirectional_sequence_lstm""(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>
<unknown>:0: error: Failed to duplicate values for the stateful op

<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x50x6xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<[5.58075495E-4, 0.0313672647, -0.0188098513, -0.0246837344]> : tensor<4xf32>} : () -> tensor<4xf32>
  %cst_0 = ""std.constant""() {value = dense<[0.0168908536, 0.0328395516, 0.032890223, 0.0250963103, 0.0189044718, -0.0114660431, 0.0205141585, 0.0246794671, 0.0165602472, 0.0507745668, -0.00160693936, 0.0168250985, 0.0210511424, 0.0273013972, 0.0362471119, 0.0202392936, 0.0296635088, 0.0094857458, 0.0339091942, 0.0257274546, 0.0100004124, -0.0119953547, 0.0321875811, 0.0217365436, 0.0301411357, 0.0284080133, -0.00616158592, 0.0177836455, 0.037834093, 0.0353285074, 0.0446266644, 0.02094361]> : tensor<32xf32>} : () -> tensor<32xf32>
  %cst_1 = ""std.constant""() {value = dense<[-1, 1600]> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_2 = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %cst_3 = ""std.constant""() {value = dense<32> : tensor<i32>} : () -> tensor<i32>
  %cst_4 = ""std.constant""() {value} : () -> none
  %cst_5 = ""std.constant""() {value = dense<""0x507631BD189A80BCD5C2733ED4E290BC50CED43C3A5D883D59216B3D5C8655BE8DA77EBD0730CE3D28808CBC9849F7BDB4B8583E83AFDA3D253A9FBD61E09CBDE40B5DBE664A90BD1FEA963C8C7182BDCB83E93DD8643CBED633A7BDF8BDD68A5BDEE59D73D424DE8BD130735BD1E818ABDEF9E433D5A7F68BE8131F93AB20927BB599D563D932DC63D205D933BF7C3D4BD3BEE20BEA67AD1BC""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_6 = ""std.constant""() {value = dense<""0xC5098CBD408DDBBC314E433ECD6BDA3D6FC376BDE191E8BD0C83AA3C26A7D03CB6A3F83D69AC083ED3E450BD7C1A2ABDD5399BBD5B4856BC54154CBE3610BABD3294B3BD1893033E362EEDBDEF55183ED97FD3BD265B0DBD122FBF3A4B74C16BD246F16BE1D03DFBC""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_7 = ""std.constant""() {value = dense<""0x43512EBE2D7D3FBDC919BFBD6E77B93DE12A51BD7C780BBE2DA4A73CC8923D3D2B013A3C11E5A8BD9CED16BEA75EE2BC3943B0BB7EB687BDE02343BDDDCD46BD84D79ABDAB07FC3CDA7143BC824AE3BD2F1275BD5D24B8BA56A2363E5751AC223E7679FFBD83C7B5BD""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_8 = ""std.constant""() {value = dense<""0xC1CE5CBC2598F43D11156ABC8639173E5D49453DECB4033E396DAF3D9020C33DFDB9353E89364A3E59B29DBC2AF5A9BD3E71513EABB5893BC79D0BBD62D7CD38CB94EABD31909E3D675939BED9DA9B3D65B9AFBD7D48733D56C0CA3CD6A9173E850162BDB7A7BDBDC2D5A53ED25AABBD816643BE480A193E1D20483D01327C3D3217353DECB9F1BCDCE961BD68D9123DC73D523975BDA28AF23BDD3CDB3D76CF45BA4C7C413D9243173D1C4A59BC7409C43CC452D9BD6DAA9D3D72594ABCC7C8023D124DD9BD8BE4E73D91EDF73CA46340BD5525DFBD96A31CBD7AC41F3E0A9989BD48A4ACBB7CC85F3ECA2F3A3C224824BE2AE865BD""> : tensor<32x32xf32>} : () -> tensor<32x32xf32>
  %cst_9 = ""std.constant""() {value = dense<[0.0144452555, 0.0439436212, 0.0415196344, 0.0175064709, 0.0429508053, 0.0735509619, 0.0491249301, 0.0418154374, 0.0602816083, 0.045234289, 5.909860e-02, 0.0427618176, 0.0817241296, 0.0802346095, 0.0551247187, 0.0658099055, 0.0615411662, 0.00372897903, 0.0607171729, 0.0572465882, 0.0421632193, 0.0733279287, 0.031675335, 0.0185546968, 0.0603379421, 0.051861681, 3.635350e-02, 0.0380876064, 0.0809857174, 0.0439099669, 0.0539641976, 0.0418169759]> : tensor<32xf32>} : () -> tensor<32xf32>
  %cst_10 = ""std.constant""() {value = dense<[1.00700974, 1.04556596, 1.03545511, 1.0162183, 1.0175035, 1.08579636, 1.01043904, 1.04590869, 1.04253387, 1.03596485, 1.05140936, 1.03108668, 1.07964396, 1.0831908, 1.09043574, 1.02333474, 1.04881787, 1.0237242, 1.05353069, 1.04014802, 1.05490816, 1.05565023, 1.01534796, 1.03404355, 1.07461286, 1.03379011, 1.05220687, 1.02958488, 1.082533, 1.06203258, 1.0333389, 1.02156973]> : tensor<32xf32>} : () -> tensor<32xf32>
  %cst_11 = ""std.constant""() {value = dense<[-0.0155429579, -0.0149332602, -2.810480e-03, -0.00695943832, -0.0290646255, 2.06409313E-5, 0.00824266858, 0.00734761823, 0.00945399608, 0.023697529, -0.0115692951, 0.00534931803, 0.00947638787, 0.0181952436, -0.0154710943, 0.00264836196, -0.00150267023, -0.00198521675, 0.0417954363, -0.00790990796, -0.00273986137, -0.0116288625, 0.00412545074, -0.0379990861, -0.0182854049, 0.0314916559, -0.0511364788, 0.0203785244, -0.0182113275, 0.0208651014, -0.0222315397, -0.00638690404]> : tensor<32xf32>} : () -> tensor<32xf32>
  %cst_12 = ""std.constant""() {value = dense<[0.0499719679, 0.0823660269, 0.0490536653, 0.0406278074, 0.058024019, 0.117005043, 0.0509332679, 0.0851290673, 0.0671336576, 0.0613935478, 0.0641625077, 0.0680163354, 0.0695394427, 0.0915709212, 0.110055275, 0.070103921, 0.06133404, 0.0508842357, 0.046390295, 0.0355754569, 0.0540821813, 0.0656848847, 0.0382119045, 0.0256700907, 0.101019681, 0.0558630377, 0.0504671149, 0.0564667471, 0.0997239723, 0.0563018657, 0.0500954203, 0.0496940762]> : tensor<32xf32>} : () -> tensor<32xf32>
  %cst_13 = ""std.constant""() {value = dense<""0x4C871E3EB55234BEC30F2C3EA52355BEA740A9BDC5CAF1BD945A6EBE1DC3983EB2D134BE0DD3223EC5BDBA3B2640433DF943B53DCEDB0ABE4BA540BE8E390BBE255A293E0814F2BDD4D06D3EEDFA733EFB04E93DA09EAABCEDAD30BE878FDFBDEA0BDE33509BEA77AB0BD456201BE240DB4BE5E4C2CBEF8D79B3DFE3DAEBDB0D999BB4E39663D6196E23C2AD2463C8697C73D0963033E5964F0BDFEDAA43B121F233E""> : tensor<32x6xf32>} : () -> tensor<32x6xf32>
  %cst_14 = ""std.constant""() {value = dense<""0x09496D3D8CCDE5BD2FAEF73D18E2D6BDFE7238BEBC7B4ABE780F26BD53138B3EF7C62DBEF485CF3DBB8291BB9FEF023EDD5F5BBE7B0C25B96605E13D19AB7CBD0C6EDC3D042BC7BDE0458D3DE12FE7BD9B5A833DF7275A3E6C28D1BC9C83E53DE5271EBEC92DD83DB4A2293EB5FE95BDAE0320BE540E1A3E675613BDA1C8FBBDDE2238BE12F041BE2F79F3BCD72E763E4C2435BE9A99BCBC2733143E164F0CBE8885403E507772BD3EF096BCFAC4AA3DED5D3A3E99651E3D4C83FCBDBC70EABD696F2B3E6FDBC63DBC94673E1F0F443EC01AB9BDAFBE143E2A8CD73DC0B9983E3617E53D74624F3EEB0AEF3D80D662BE5EA33E3EEE5EEC3D74574EBE5BCE11BD361D623D34BC04BEC5BD31BE97741B3E5026853E1B9D903E063017BDCA732BBD41773A3EB1CA46BD8D0D183DAA92993E8EE6F6BB4FA8BFBD9A69713D6E0E60BE21E7403E142D8BBDFA882FBE9D5A453EBF89DF3C3706913DA1FB0D3E87B6FEBA0750153EBBB29EBCD6670BBED47462BE9F74193DA0C8973C98053DBEA83E0FBE1A551EBDC1F7D1BD8BB506BE36C3B13CEDB45B3DDE6F013DFE0E03BE89958B3E2DF4023ED028B2BC1F81F53DE07F3EBDE31E083E65F363BE003E8BBE36F76D3DBFE0093E5FAA36BE357D263D2D1D273ED077FE3C5D1AC1BDB53F883C4B41B33BF79A1E3E16BE2D3D762DC93D37D1A6BB882A323EF27FF9BDF36D5C3EEBFDF3BC8A1332BDBBE96D3E96218FBBF9D4B7BC6E52F13DE6587BBDD7DE93BDF160F03D857E47BE220E56BDACB9C2BD9D954BBEB19639BEA6A392BD6B2F843ED49711BEBCDF77BD0C94F0BDEFE2A8BC5ACFA43EF6C9103EC7590BBB46CE25BDB2631CBE96D44EBB455582BD7C936A3E5694B8BD90C781BD3919203E2A63963DA66219BE4CA96CBD4CF5FFBD773316BD34FD253EB2784B3E7B1AAC3C552D99BD3835BABD9577AABC4C373CBE319F553DDEEA38BDF95A1A3EFEEEDB3DB797293EEB6C483E78F534BEFA08C9BD94CC8EBDE3B21BBC1C4EC83DFB3532BE91DC42BE9B96ED3DF6D530BD1E7252BE24151E3D727B87BDB81556BEEBC3373D13725CBEFAF3AD3D""> : tensor<32x6xf32>} : () -> tensor<32x6xf32>
  %cst_15 = ""std.constant""() {value = dense<""0xF8B4BE3D58147DBDC2B66DBE2EC7E9BCED1EDB3DCCBBD53D82A42E3D45B729BED0EA3E3E91EB7CBE2493CE3BE1023C41BC123E5C257DBE9C4658BD8E9AF2BDA150FF3D8C60003EE52216BD34F4DABD8C0714BE7C7D3F3D5CEBA53D3B81183DB7B1AABC88E11D3EA4F11C3C4174FDBD4F59D93BC8CB0A3DF1FCE03DFE20B93CF983113DEAA44EBEF8EE9EBD3505DDBDE494C13DB75EC6BDD7CCABBC62775C3E0E02463E3D77A3BD9E72DABD4E0BC8BB52051ABD7431D1BD3AA0903BCD2B28BEEB9AB73D4E970ABE586DC4BC4847A73D8FCC253EEDCB55BE1F14E33D08BDCFBD8FD334BB512333BEB17B19BE14E8113E0ADA6B3D0A82593E1E270D3E5B538B3DC98F93BDE0B5F23A9E5FF5BA""> : tensor<32x6xf32>} : () -> tensor<32x6xf32>
  %cst_17 = ""std.constant""() {value = dense<""0xC45CFBBC2D98813CD0AE393D99C27A3DF3AD7B3DA82134BCEE687FBB4B4E5FBDBEED0EBD8AFC8DBC3FEFE23CFF39F7BB5234EFBC7CC681BC741B0B3DEA3601BDE4EA72BDB121D23B301740BD4CE70C3D423C45BC57F0513C25B331BD0D05B93CBC3650BD9EB9073DE01A753C525381BDD17FD43A81FC7EBCD93D8B3C31BB3B3C7AB2AE3C4F07973D8A74903D2E087B3D203F2C3DA5D72B3D72E66EBC3264183D9C606F3C05A26A3DCE36903CAD21083BC911F3BC96D6FCBBBFD3A03C9B311A3DDC3E57B5635BD73552739A5CAF43CDB17233DBAAE27BCC90C183DD151083DFCC32FBDA29B11BD8605363DE97A51BC9DAAC33CEE03193B6C83CC3CB3808ABD269D143DEDF90E3DEB7BF43CDE7691BDE609D3BA429F11BD46DE4EBC4950583D9C2AA0BCFE4673BD7BDC21BC9FBC0E7D873C2A33333D8B734A3DE0E60B3D40C5BB3D19FC94BD1E4499BB90CA15BD3BB38F3D14FA54BD362E193DFE3BC33C4905373C1F90393DEDAE09BCB567053CD00553BC0BA1293C78C770BC1FE7F23CBD25E2BC35263D3DCC4910BDD87B323DF762533D860BA4BC91F7EFB93D55E83B50FA883A1DDE483B351A073D7BD408BD16B455BD4D63983BC79B06BDE7BB773DBC516EBB1AF827BD03190BBD9514B6BB3D3F9C3D1F873BBDC856B1BC2D56153D5ADF98BC467F193CE6CDCCBCA3C312BD2BC75C3B13E4E6BF4E3C6CE763BDDA6F38BDDD5D53BD9E664F3DF9AE11BD0D98443D5AC8E8BCE741C53BC924083D3E23813DDCBA623C2ECA9FBCD6469ABBD5AEA1BA7257043C9766A93C447A993A719FE5BAED58A93BA21597BD2C02C13B92E608BBA55196BD3502DE3BA8""> : tensor<32x1600xf32>} : () -> tensor<32x1600xf32>
  %cst_18 = ""std.constant""() {value = dense<""0xBEBAAFBEC3EB073E7179C43E0D4656BDD887BCBEDD0FA7BEFC851DBC5A6F9B3E1410183E0722133E5FE27DBE4CB3BBBDD8156EBEE919BB3E3B93E8BE9B5326BEAE8C7A3EE3C0A33E8FF0A73EF50D063EFBFF313C162261BE20DC383E832209BE79FCB63D0AE3DABE482082BE883185BE3CECA53DE08D863EAFCB2B3EA29FD33E2502093ECE2A0BBEBBADAB3D490FB43E8AD0D93ED74173EDF66BCBEBAA2B13C""> : tensor<4x32xf32>} : () -> tensor<4x32xf32>
  %cst_19 = ""std.constant""() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>
  %cst_20 = ""std.constant""() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>
  %0 = ""tfl.shape""(%arg0) : (tensor<?x50x6xf32>) -> tensor<3xi32>
  %1 = ""tfl.strided_slice""(%0, %cst_19, %cst_20, %cst_20) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>
  %2 = ""tfl.pack""(%1, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>
  %3 = ""tfl.fill""(%2, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x32xf32>
  %4 = ""tfl.unidirectional_sequence_lstm""(%arg0, %cst_13, %cst_14, %cst_15, %cst_16, %cst_5, %cst_6, %cst_7, %cst_8, %cst_4, %cst_4, %cst_4, %cst_9, %cst_10, %cst_11, %cst_12, %cst_4, %cst_4, %3, %3, %cst_4, %cst_4, %cst_4, %cst_4) {cell_clip = 1.000000e+01 : f32, fused_activation_function = ""TANH"", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x50x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x6xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, tensor<32x32xf32>, none, none, none, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, tensor<32xf32>, none, none, tensor<?x32xf32>, tensor<?x32xf32>, none, none, none, none) -> tensor<?x50x32xf32>
  %5 = ""tfl.reshape""(%4, %cst_1) : (tensor<?x50x32xf32>, tensor<2xi32>) -> tensor<?x1600xf32>
  %6 = ""tfl.fully_connected""(%5, %cst_17, %cst_0) {fused_activation_function = ""RELU"", keep_num_dims = false, weights_format = ""DEFAULT""} : (tensor<?x1600xf32>, tensor<32x1600xf32>, tensor<32xf32>) -> tensor<?x32xf32>
  %7 = ""tfl.fully_connected""(%6, %cst_18, %cst) {fused_activation_function = ""NONE"", keep_num_dims = false, weights_format = ""DEFAULT""} : (tensor<?x32xf32>, tensor<4x32xf32>, tensor<4xf32>) -> tensor<?x4xf32>
  %8 = ""tfl.softmax""(%7) {beta = 1.000000e+00 : f32} : (tensor<?x4xf32>) -> tensor<?x4xf32>
  ""std.return""(%8) : (tensor<?x4xf32>) -> ()
}) {arg0 = {tf_saved_model.index_path = [""LSTM_1st_layer_input""]}, result0 = {tf_saved_model.index_path = [""Dense_Output_Layer""]}, sym_name = ""serving_default"", tf.entry_function = {control_outputs = """", inputs = ""serving_default_LSTM_1st_layer_input:0"", outputs = ""StatefulPartitionedCall:0""}, tf_saved_model.exported_names = [""serving_default""], type = (tensor<?x50x6xf32>) -> tensor<?x4xf32>} : () -> ()

```

### Architecture of LSTM Model
```
Layer (type)                 Output Shape              Param #   
=================================================================
LSTM_1st_layer (LSTM)        (None, 50, 32)            4992      
_________________________________________________________________
Dropout_1 (Dropout)          (None, 50, 32)            0         
_________________________________________________________________
Flatten_2nd_layer (Flatten)  (None, 1600)              0         
_________________________________________________________________
Dropout_2 (Dropout)          (None, 1600)              0         
_________________________________________________________________
Dense_3rd_layer (Dense)      (None, 32)                51232     
_________________________________________________________________
Dropout_3 (Dropout)          (None, 32)                0         
_________________________________________________________________
Dense_Output_Layer (Dense)   (None, 4)                 132       
=================================================================
Total params: 56,356
Trainable params: 56,356
Non-trainable params: 0
```

### 4. Google Colab file for your reference.

https://github.com/Kimidoge/DriveProfiler-LSTM/blob/main/Driver_Classifier_using_LSTM_(Main).ipynb




"
51379,InputSpec missing float64 support and wrong error message,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5

**Describe the current behavior**
The [InputSpec](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputSpec?hl=ja) seems to have an issue when the dtype argument is set to float64. In this case an error is produced that doesn't make much sense: `ValueError: Input 0 of layer sequential is incompatible with the layer: expected dtype=float64, found dtype=<dtype: 'float32'`; (and strangely, the opposite error (`expected dtype=float32, found dtype=<dtype: 'float64')` occurs, when only the dtype is set to float32).
The issue is illustrated in the following example with a simple custom layer. 


**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
tf.keras.backend.set_floatx('float64')
class TempLayer(tf.keras.layers.Activation):
    def __init__(self):
        super(keras.layers.Activation, self).__init__()
        self.input_spec = keras.layers.InputSpec(dtype='float64',shape=(1,1))#float32/float also does not work
    def call(self, input_1, training=False):
        return input_1
        
model = keras.Sequential([TempLayer()])
x = tf.constant([[1.4392]])
print (np.array2string(model.predict(x,steps=1), separator=', '))
```"
51378,transfer learning model based on universal sentence encoder cannot save to tf model for tensorflow serving,"The model is created using the following codes,

    model = tf.keras.models.Sequential()

    model.add(hub.KerasLayer(""https://tfhub.dev/google/universal-sentence-encoder/4"", input_shape=[], output_shape=[512], dtype=tf.string, trainable=False))

    model.add(tf.keras.layers.Dense(10, activation='relu'))
    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))

    model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

......
    model.fit(X_train, Y_train, epochs=1, validation_data=(X_test, Y_test))
    model.save(model_save_loc)
......

I tried tensorflow 2.5.0 and 2.2.0. Both gave me the following exception when I saved the model after fully training it, (model training works perfectly)

Traceback (most recent call last):
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py"", line 277, in __del__
    self._destroy_resource()
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 889, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 924, in _call
    results = self._stateful_fn(*args, **kwds)
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3022, in __call__
    filtered_flat_args) = self._maybe_define_function(args, kwargs)
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3279, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/feng/workspace/venv3.8/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
AttributeError: 'NoneType' object has no attribute '__wrapped__'
"
51377,InputSpec argument ignored ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0
- Python version: 3.8.5

**Describe the current behavior**
The `ndim` argument of the [InputSpec](https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputSpec?hl=ja) of a layer seems to be ignored when the `shape` argument is set. The issue is illustrated in the following example with a simple custom layer. 

**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

class TempLayer(tf.keras.layers.Activation):
    def __init__(self):
        super(keras.layers.Activation, self).__init__()
        self.input_spec = keras.layers.InputSpec(ndim=5, shape=(1,2))
    def call(self, input_1, training=False):
        return input_1
        
model = keras.Sequential([TempLayer()])
x = tf.constant([[1.4392, 1.9206]])
print (np.array2string(model.predict(x,steps=1), separator=', '))
```
"
51376,ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.,"I'm Trying to write my own RandomHSV custom layer to create faster augmentations to images (and later on just remove it from the model).
the code is as follows:
```

class RandomHSV(Layer):
    """"""Adding Random Noise to HSV image. output is RGB
  Input shape:
    Arbitrary.
  Output shape:
    Same as input.
  Arguments:
    hsv_max_amp: list or tuple of the maximum amplitudes of the noise in range of [0, 1]
    name: A string, the name of the layer.
    NOTE: MAKE SURE INPUTS LAYERS HAS THE BATCH SIZE FIGURED BEFORE USING THIS LAYER.
  """"""

    def __init__(self, hsv_max_amp=(0, 0, 0), batch_size=None, name=None, **kwargs):
        super(RandomHSV, self).__init__(name=name, **kwargs)
        # self.rand_generator = tf.random.Generator.from_seed(seed=int(time.time()))
        self.hsv_max_amp = np.array(list(hsv_max_amp), dtype='float32')

    def build(self, input_shape):
        # self.batch_size = input_shape[0]
        super(RandomHSV, self).build(input_shape)  # Be sure to call this at the end

    def call(self, inputs, training=True, **kwargs):
        def hsv_noise():
            hsv = tf.image.rgb_to_hsv(inputs)
            # the random noise is a random matrix in shape (batch_size, img_w, img_h, depth)
            # after creating the random matrix, multiply it (element wise) by the self.hsv_max_amp.
            # that gets multiplied by random enabler (np.random.randint(0, 2, 3) -> 3 items, 0 or 1)
            # then removing an offset.
            random_noise = (np.random.ranf(inputs.shape) * (
                    np.random.random(1) * self.hsv_max_amp * np.random.randint(0, 2, 3)) - self.hsv_max_amp / 2) * 2
            # those lines will cut any number which goes above 1 or goes below 0 (round it to 1 or 0 respectively).
            hsv = tf.minimum(1., tf.maximum(0., tf.add(hsv, random_noise)))
            batch = tf.image.hsv_to_rgb(hsv)
            batch.set_shape(inputs.shape)
            return batch

        # applying hsv_noise if Training. if Testing then just passing batch forward unchanged
        return control_flow_util.smart_cond(pred=training, true_fn=hsv_noise, false_fn=lambda: inputs)

    def compute_output_shape(self, input_shape):
        return input_shape

    def get_config(self):
        config = {
            'hsv_max_amp': self.hsv_max_amp,
            'batch_size': self.batch_size
        }
        base_config = super(RandomHSV, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))
```

When the whole model is built (or trying to build it self), I get the error:
```
TypeError: 'NoneType' object cannot be interpreted as an integer
```
or when I use the ```tf.random.Generator()``` class:
```
ValueError: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.
```
this is because I don't tell the model's Inputs layers the batch size before I run it.
I tried to figure out how to work around it, but the only solution is to let the model know the batch size (```Input(batch_size=BATCH_SIZE)``` layer is mandatory)
on other layers (such as Dense, Conv2D and so on...) its not mandatory to name the batch_size. Is there any idea how could I do it on my layer too?"
51375,trainable_variables being empty in tf2.5,"tf2.5
```

initial = tf.random.normal(shape=[2, 5], mean=0, stddev=0.05, dtype=tf.dtypes.float64)
initial = tf.Variable(initial, name='eeeeeee', trainable=True)

print(tf.compat.v1.trainable_variables())
```

In tf2.5, the above output is [ ], but in tf1.13, it has variables `[<tf.Variable 'eeeeeee:0' shape=(2, 5) dtype=float64_ref>]`. Why?"
51358,How to interpret the model analysis report of TensorFlow2,"2021-08-07 22:21:14.783664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-08-07 22:21:14.783849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-08-07 22:21:14.783983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7077 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
2021-08-07 22:21:14.790480: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 216 nodes (198), 329 edges (310), time = 3.612ms.
  function_optimizer: function_optimizer did nothing. time = 0.07ms.
How should we understand these two times（time = 3.612ms and time = 0.07ms）?"
51357,"tf.get_logger().setLevel(""ERROR"")  dose not work","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
windows10 
tensorflow 2.5.0

i run the following code:
`import tensorflow as tf

tf.get_logger().setLevel(""ERROR"") 

def f():
    a = tf.constant([[10,10],[11.,1.]])
    x = tf.constant([[1.,0.],[0.,1.]])
    b = tf.Variable(12.)
    y = tf.matmul(a, x) + b
    print(""PRINT: "", y)
    tf.print(""TF-PRINT: "", y)
    return y
f()`

it is supposed to show noly the logs of level error, but the logs of info level still show up as following:
`2021-08-07 21:38:07.489566: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
2021-08-07 21:38:09.872614: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll
2021-08-07 21:38:10.474791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX150 computeCapability: 6.1
coreClock: 1.0375GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s
2021-08-07 21:38:10.475740: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
2021-08-07 21:38:10.494343: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll
2021-08-07 21:38:10.494809: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll
2021-08-07 21:38:10.503734: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll
2021-08-07 21:38:10.505973: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll
2021-08-07 21:38:10.510533: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll
2021-08-07 21:38:10.517252: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll
2021-08-07 21:38:10.520018: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll
2021-08-07 21:38:10.521771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-08-07 21:38:10.523332: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-07 21:38:10.524939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: NVIDIA GeForce MX150 computeCapability: 6.1
coreClock: 1.0375GHz coreCount: 3 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 37.33GiB/s
2021-08-07 21:38:10.525938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-08-07 21:38:11.193205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-08-07 21:38:11.193561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2021-08-07 21:38:11.193780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
2021-08-07 21:38:11.194437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1332 MB memory) -> physical GPU (device: 0, name: 
NVIDIA GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1)
2021-08-07 21:38:11.273136: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll
2021-08-07 21:38:11.820818: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll
PRINT:  tf.Tensor(
[[22. 22.]
 [23. 13.]], shape=(2, 2), dtype=float32)
TF-PRINT:  [[22 22]
 [23 13]]`

**Describe the expected behavior**


**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51356,ERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: none),"System information: 

Windows 10
Python 3.6.13
Pip-Version: 21.2.3.
Would like to install tensorflow 1.15

Hey, 
i would like to install tensorflow 1.15. 
I am setting up a virtual environment for this and typing the following (The variable OUTPUT_FOLDER is defined above).

pip3 install virtualenv 
python3 -m virtualenv $OUTPUT_FOLDER/venv
source $OUTPUT_FOLDER/venv/bin/activate
pip3 install --pre ""tensorflow==1.15.*""

The folders are created, but installing tensorflow gives the error message in the title: 
ERROR: Could not find a version that satisfies the requirement tensorflow==1.15.* (from versions: none)
ERROR: No matching distribution found for tensorflow==1.15.*
 
Can somebody help me?

Thanks!
Hinnerk8"
51354,Out-of-memory error in eager mode loop,"Following code gives an out-of-memory error when running in tensorflow-2.5. The code itself does not do anything useful it is just meant to highlight what I believe is a problem.

For the small problem (i.e. ```b, a, c = 1, 1000, 5 # small problem```) the program completes. For the large problem (i.e. ```b, a, c = 1, 10000, 5 # large problem```) the program runs out of memory.

My expectation would have been that in eager mode allocated tensors have the lifetime of one iteration, while it seems more memory is being allocated with each iteration. Similar code with identical parameters runs in Pytorch.

Am I wrong in my expectation or is this a bug? If I am wrong how could I do this in Tensorflow?

```python
import tensorflow as tf

from tensorflow.keras.losses import Loss

class EagerOom(Loss):

    def __init__(self):
        super(EagerOom, self).__init__()

    def __call__(self, targets, logits):
        logits = tf.reshape(logits, [-1])
        targets = tf.reshape(targets, [-1])
        return self.inner(targets, logits)


    @tf.custom_gradient
    def inner(self, targets, logits):

        g_logits = tf.zeros_like(logits)

        for idx in range(len(targets)):
            print(f""idx: {idx}"")
            g_logits_upd = logits - logits[idx]
            g_logits += g_logits_upd
        
        loss = tf.reduce_mean(targets * logits)

        def grad_fn(upstream):
            g_targets = tf.zeros_like(targets)
            return g_targets, g_logits

        return loss, grad_fn



def main():
    tf.random.set_seed(0)
    # b, a, c = 1, 1000, 5 # small problem
    b, a, c = 1, 10000, 5 # large problem
    logits = tf.random.normal((b, a, c))
    targets = tf.random.uniform((b, a), 0, c + 1, dtype=tf.int32)
    targets = tf.one_hot(targets, depth=c, axis=-1)
    loss_fn = EagerOom()
    with tf.GradientTape(persistent=True) as tape:
        tape.watch(logits)
        loss = loss_fn(targets, logits)
    print(""Done."")


if __name__ == '__main__':
    main()
```
"
51352,Is it possible to compile tflite-runtime python wheel on m1 mac (arm64)?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Big Sur version 11.4
- TensorFlow installed from (source or binary): source 
- TensorFlow version: v2.6.0, v2.5.0
- Python version: 3.8.10
- Bazel version (if compiling from source): 4.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.5 (clang-1205.0.22.11)
- CUDA/cuDNN version: - 
- GPU model and memory:	
```
16 GB, Type:	LPDDR4
Chipset Model:	Apple M1
  Type:	GPU
  Bus:	Built-In
  Total Number of Cores:	8
  Vendor:	Apple (0x106b)
  Metal Family:	Supported, Metal GPUFamily Apple 7 
```



**Describe the problem**
I tried several following ways of tflite-runtime compilation to python wheel:

`sh build_pip_package_with_cmake.sh native`

getting:
```
CMake Error at /opt/homebrew/Cellar/cmake/3.21.1/share/cmake/Modules/CMakeTestCCompiler.cmake:69 (message):
  The C compiler

    ""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc""

  is not able to compile a simple test program.

  It fails with the following output:

    Change Dir: /Users/koubadom/Projects/tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/cmake_build/CMakeFiles/CMakeTmp

    Run Build Command(s):/usr/bin/make -f Makefile cmTC_4563f/fast && /Applications/Xcode.app/Contents/Developer/usr/bin/make  -f CMakeFiles/cmTC_4563f.dir/build.make CMakeFiles/cmTC_4563f.dir/build
    Building C object CMakeFiles/cmTC_4563f.dir/testCCompiler.c.o
    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc   -march=native -I/Users/koubadom/miniforge3/include/python3.8 -I/Users/koubadom/miniforge3/lib/python3.8/site-packages/pybind11/include  -arch arm64 -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX11.3.sdk -MD -MT CMakeFiles/cmTC_4563f.dir/testCCompiler.c.o -MF CMakeFiles/cmTC_4563f.dir/testCCompiler.c.o.d -o CMakeFiles/cmTC_4563f.dir/testCCompiler.c.o -c /Users/koubadom/Projects/tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/cmake_build/CMakeFiles/CMakeTmp/testCCompiler.c
    clang: error: the clang compiler does not support '-march=native'
    make[1]: *** [CMakeFiles/cmTC_4563f.dir/testCCompiler.c.o] Error 1
    make: *** [cmTC_4563f/fast] Error 2





  CMake will not be able to correctly generate this project.
Call Stack (most recent call first):
  CMakeLists.txt:40 (project)
```

`sh build_pip_package_with_cmake.sh arm64`

```
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make[3]: *** [_pywrap_tensorflow_interpreter_wrapper.dylib] Error 1
make[2]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/all] Error 2
make[1]: *** [CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2
make: *** [_pywrap_tensorflow_interpreter_wrapper] Error 2
```
`sh build_pip_package.sh`

```
ld: symbol(s) not found for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [/Users/koubadom/Projects/tensorflow/tensorflow/lite/tools/make/gen/osx_arm64/bin/benchmark_model_performance_options] Error 1
Traceback (most recent call last):
```

`sh build_pip_package_with_bazel.sh`

```
/private/var/tmp/_bazel_koubadom/4a39adbd2fff0dadf31cbeb460f8aca3/external/io_bazel_rules_go/go/private/sdk.bzl:53:35: in <toplevel>
ERROR: Analysis of target '//tensorflow/lite/python/interpreter_wrapper:_pywrap_tensorflow_interpreter_wrapper' failed; build aborted: Configuration Error: Invalid python library path: /usr/lib/python3/dist-packages
```
(I know this looks like some env var is badly set, but I tried everything what come to my mind.) I modified version of bazel in .bazelversion to match 4.1.0.

`tensorflow/tools/ci_build/ci_build.sh PI-PYTHON38 \
  tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh`

```
 I got multiple errors especially with `ModuleNotFoundError: No module named 'pybind11'` and bazel version, I do know why, pybind11 is not there, I am sure it is on my local machine, how not in container.
```



All attempts I did on git checkout v2.5.0 and everything is run under arm (not in Rosetta). Is here anybody who was successful doing this obscure task? I might made a lot of mistakes but I am trying hard... If somebody can give me a hint or compiled version for arm without any advice, I am ok with that :D. I would appreciate any version on my platform. 

Thanks a lot. "
51351,TypeError: Cannot convert a symbolic Keras input/output to a numpy array by using a custom layer,"**System information**
* OS Platform and Distribution: Linux Ubuntu 20.10
* TensorFlow installation: pip package
* Tensorflow version: 2.6.0rc1
* Python version: 3.8

I created a Keras custom layer which implements a custom causal Conv1D. To do it, I simply used the classes Conv and Conv1D (they are in tensorflow/python/keras/layers/convolutional.py) and modified Conv. I'll show you how I use this layer with a very silly example dataset, which is characterized by only two training samples (given an ordered sequence of numbers as a training sample, the model should predict its next sequence: for example, if I've [0, 1, 2] the output will be [3, 4, 5]). However I get the following error:

   ```
 Traceback (most recent call last):
File ""model.py"", line 406, in <module>
model = build_model(x_train, y_train)
File ""model.py"", line 373, in build_model
r=Myconv1D(filters=1,kernel_size=3,padding='causal',dilation_rate=1,use_bias=False,name=""MyConv"")(inp)
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1057, in __call__
outputs = call_fn(inputs, *args, **kwargs)
File ""model.py"", line 181, in call
z[0,4+i,0].assign(inputs[0,i,0])  
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py"", line 1235, in assign
return var._strided_slice_assign(
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py"", line 1392, in   
_strided_slice_assign
value=ops.convert_to_tensor(value, dtype=self.dtype),
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py"", line 163, in wrapped
return func(*args, **kwargs)
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1566, in convert_to_tensor
ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 346, in    
 _constant_tensor_conversion_function
return constant(v, dtype=dtype, name=name)
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 271, in constant
return _constant_impl(value, dtype, shape, name, verify_shape=False,
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 283, in    
_constant_impl
return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 308, in   
_constant_eager_impl
t = convert_to_eager_tensor(value, ctx, dtype)
File ""/home/es/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py"", line 106, in    
convert_to_eager_tensor
return ops.EagerTensor(value, ctx.device_name, dtype)
File ""/home/es/venv/lib/python3.8/site-packages/keras/engine/keras_tensor.py"", line 244, in __array__
raise TypeError(
TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a     
symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF    
API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the     
Functional Model.

```

I attached the example code used to train the model:
[model.zip](https://github.com/tensorflow/tensorflow/files/6946190/model.zip)
"
51350,TensorArray Can't be used for tf.concat?,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf2.3
- Python version: python 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 7.5
- CUDA/cuDNN version: 10.1
- GPU model and memory: None

**Describe the current behavior**
I want to use model.fit but in my model definition, I use python list and for loop. So I want to change it by using TensorArray.
but I have tf.concat after for loop. So I test following code to see if it works:
```python
a = tf.ones([2,3])
b = [a] * 2

ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
ta = ta.write(0, a)
ta = ta.write(1, a)
ta = ta.stack()

d1 = tf.concat(b, axis=1)
print(""d1:"", d1)

d2 = tf.concat(ta, axis=1)
print(""d1:"", d2)

But  I get these results:  
------------------------------------------------
d1: tf.Tensor(
[[1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1.]], shape=(2, 6), dtype=float32)

d1: tf.Tensor(
[[[1. 1. 1.]
  [1. 1. 1.]]

 [[1. 1. 1.]
  [1. 1. 1.]]], shape=(2, 2, 3), dtype=float32)
------------------------------------------------
**Describe the expected behavior**
I want TensorArray have the same shape as result of ""d1"", but nothing changed. It's a bug?
d1: tf.Tensor(
[[1. 1. 1. 1. 1. 1.]
 [1. 1. 1. 1. 1. 1.]], shape=(2, 6), dtype=float32)

IF not bug, please tell me how to change TensorArray shape with tf.concat? Thanks
```
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
"
51349,type dependent output,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 5.8.14-arch1-1
- TensorFlow installed from (source or binary): via pip
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.8.6



**Describe the current behavior**
Output is type dependent
**Describe the expected behavior**
It should not be type dependent

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? ?
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
```
import tensorflow as tf
print(tf.range(21.70725420531782, 42.707254205317824,dtype=tf.float64))
print(tf.range(21.70725420531782, 42.707254205317824,dtype=tf.float32))
```"
51348,[GPU DELEGATE] [2.5.0] Failed to apply delegate: TfLiteGpuDelegate Init: MUL: Expected a 3D tensor of shape HxWxC or a 4D tensor of shape 1xHxWxC but got 12x4,"System information

OS Platform and Distribution: Android all possible versions
TensorFlow version : 2.5.0
Describe the current behavior
Gpu delegate failed to initialize with model

java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: MUL: Expected a 3D tensor of shape HxWxC or a 4D tensor of shape 1xHxWxC but got 12x4 TfLiteGpuDelegate Prepare: delegate is not initialized Node number 243 (TfLiteGpuDelegateV2) failed to prepare.

implementation(""org.tensorflow:tensorflow-lite:2.5.0"")
implementation(""org.tensorflow:tensorflow-lite-gpu:2.5.0"")
"
51347,save_model and export categorical_column_with_vocabulary_file,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file?hl=zh_cn

## Description of issue (what needs changing):
when i used tf.feature_column.categorical_column_with_vocabulary_file(""column"",""/tmp/vocab.txt"") to build a keras model, training is ok but when use tf.save_model.save(my_keras_model, ""/target/""), my vocabulary file did no export to ""/target/assets/"" path.  So if I load this model again and do predict, model still read the origin path(""/tmp/vocab.txt""), I want to know how to make sure the model does not depend on original files and can be moved to another path.

I tried this doc but not works(https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/saved_model/Asset?hl=zh_cn)

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

tf.__version__ = 2.4.0

### Parameters defined
code1:
```python
sex = tf.keras.Input(shape=(1,), name=""sex"", dtype=tf.string)
x = tf.feature_column.categorical_with_vocabulary_file(""sex"",""./sex.txt"", num_oov_bucuckets=5)
x = tf.keras.layers.DenseFeatures([tf.feature_column.embedding_column(x, 2)])
out = x({""sex"",sex})
model = tf.keras.Model(inputs=sex, outputs=out)
tf.save_model.save(model, ""./no_assets_model"")
```

code2:
```python
sex = tf.keras.Input(shape=(1,), name=""sex"", dtype=tf.string)
x = tf.feature_column.categorical_with_vocabulary_file(""sex"",""./sex.txt"")
x = tf.keras.layers.DenseFeatures([tf.feature_column.embedding_column(x, 2)])
out = x({""sex"",sex})
model = tf.keras.Model(inputs=sex, outputs=out)
tf.save_model.save(model, ""./has_assets_model"")
```
seems param 'num_oov_bucuckets' must not be 0, or asset file will not be exported

### Returns defined

Are return values defined?

### Raises listed and defined

https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises
No error, No warning

### Usage example

Is there a usage example?

yes, in https://www.tensorflow.org/tutorials/structured_data/feature_columns

### Request visuals, if applicable

No

### Submit a pull request?

No
"
51346,tf.data.Iterator:  TypeError: object() takes no parameters,"tf 2.5
[tf.data.Iterator](https://tensorflow.google.cn/api_docs/python/tf/data/Iterator?hl=en)

```
dataset = tf.data.Dataset.range(10)
iterator = tf.data.Iterator(dataset)
print(iterator.get_next())
```

```
Traceback (most recent call last):
  File ""test6.py"", line 32, in <module>
    iterator = tf.data.Iterator(dataset)
TypeError: object() takes no parameters
```
"
51344,Possible bug with session handle as feed dict input,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0
- Python version:Python 3.8.5 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0 (nvcr.io/nvidia/tensorflow:21.03-tf2-py3)
- GPU model and memory: TeslaT4

```
$ python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
2021-08-06 02:34:51.763077: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
unknown 2.4.0
```


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Below is the minimum reproduce code snippet derived from 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/v1_compat_tests/session_ops_test.py#L249

```python
""""""Tests for tensorflow.ops.session_ops.""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.framework import constant_op
from tensorflow.python.framework import ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import session_ops
from tensorflow.core.protobuf import rewriter_config_pb2
import tensorflow as tf
import sys
import time

tf.debugging.set_log_device_placement(True)

def testFeedOneHandleDirectly():
  config = tf.compat.v1.ConfigProto()
  config.graph_options.optimizer_options.opt_level = -1
  config.allow_soft_placement = True
  config.graph_options.rewrite_options.constant_folding = (
      rewriter_config_pb2.RewriterConfig.OFF)
  config.graph_options.rewrite_options.pin_to_host_optimization = (
      rewriter_config_pb2.RewriterConfig.OFF)
  with tf.compat.v1.Session(config=config) as sess:

    a = constant_op.constant(10.0)
    b = constant_op.constant(5.0)
    c = math_ops.multiply(a, b)
    d = math_ops.multiply(c, c)

    h_c = sess.run(session_ops.get_session_handle(c))
    print(sess.run(d, feed_dict={c: h_c}))
    #print(""result = %f "" % d.eval())


testFeedOneHandleDirectly()

```

Run  with command 
```
python handle_test.py
```
or
```
TF_CPP_MIN_VLOG_LEVEL=2 python handle_test.py 2>&1 | tee log.txt
```


**Describe the current behavior**
d = c * c = (a * b) * (a * b) = (10 * 5) * (10 * 5) = 2500.00
If you run above script on cpu or gpu you'll get the correct result, but it seems there is something fishy underneath.

We are running tensorflow unit tests on our asic chip to verify our chip works properly on tensorflow and we failed on this test
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/v1_compat_tests/session_ops_test.py#L249

The error was related to memory copy between CPU and device. 
We found a peculiar CopyCPUTensorToGPU call which invoked
  Stream &ThenMemcpy(DeviceMemoryBase *gpu_dst, const void *host_src,  uint64 size);
The fishy part is that both gpu_dst and host_src are device pointers, which later triggered an error in our driver.

Then we tried the same piece of code on GPU and surprisingly on GPU it has exactly the same issue. But the funny part is it seems nvidia cuda driver silently handled the wrong memory copy call. If you pass two device pointers to cuMemcpyHtoDAsync it just does a silent D2D copy and reports nothing. But on our platform it is illegal to call H2D memcpy interface with two device pointers.

```
I tensorflow/core/common_runtime/gpu/gpu_util.cc:303] CopyCPUTensorToGPU                                                                                                                            
I tensorflow/stream_executor/stream.cc:1543] [stream=0x2c48a6e0,impl=0x2c489490] Called Stream::ThenWaitFor(other=0x61ba9a0)
I tensorflow/stream_executor/stream.cc:4655] [stream=0x2c48a6e0,impl=0x2c489490] Called Stream::ThenMemcpy(gpu_dst=0x7f6860000800, host_src=0x7f6860000700, size=4)
```

**Describe the expected behavior**

When call CopyCPUTensorToGPU it should have a device pointer as dest address and a host address as source address.
It seems to me the there is something flaky with the session handle mechanism.
the **h_c** got a session(resource) handle and corresponding resource is on devices. and when you pass h_c to feed dict it always assume the feed is on host and tries to send it to device again.
```
sess.run(d, feed_dict={c: h_c})
```

https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No, I'm not sure how to fix it
- Briefly describe your candidate solution(if contributing):


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

[log.txt.gz](https://github.com/tensorflow/tensorflow/files/6942630/log.txt.gz)"
51340,TF1.13.1 how to shiled tensorflow device mapping information?,"i don't want to print the device mapping information in my console when i am training my model, i tried some methods, which only can shiled the tensorflow warning information. How should i do to shiled device mapping and the first warning?
![image](https://user-images.githubusercontent.com/52489106/128446262-5779c7bc-450b-4eab-9dd4-efd770401d1b.png)
![image](https://user-images.githubusercontent.com/52489106/128446278-17fe472b-93e4-4b8f-974c-783255eb3bad.png)


"
51335,Error while using fit_generator on TimeseriesGenerator,"For the record, last May when using this code, it was fine when compiling, but this month, an error appears when running the program which has not changed at all.

The code I use
```python
model_forecast = tf.keras.models.Sequential([
  tf.keras.layers.LSTM(32, activation='relu', return_sequences=True, input_shape=(look_back, 1)),
  tf.keras.layers.GlobalMaxPooling1D(),
  tf.keras.layers.Dropout(0.25),
  tf.keras.layers.Dense(1)
])
optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
model_forecast.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=[""mae""])
model_forecast.fit_generator(train_gen, epochs=10, verbose=1)
```

The error I get
```python
ValueError                                Traceback (most recent call last)
<ipython-input-12-66f244cb1c54> in <module>()
      1 optimizer = tf.keras.optimizers.SGD(lr=1.0000e-04, momentum=0.9)
      2 model_forecast.compile(loss=tf.keras.losses.Huber(), optimizer=optimizer, metrics=[""mae""])
----> 3 model_forecast.fit_generator(train_gen, epochs=10, verbose=1)

4 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1955         use_multiprocessing=use_multiprocessing,
   1956         shuffle=shuffle,
-> 1957         initial_epoch=initial_epoch)
   1958 
   1959   def evaluate_generator(self,

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1145           use_multiprocessing=use_multiprocessing,
   1146           model=self,
-> 1147           steps_per_execution=self._steps_per_execution)
   1148 
   1149       # Container that configures and calls `tf.keras.Callback`s.

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py in get_data_handler(*args, **kwargs)
   1362   if getattr(kwargs[""model""], ""_cluster_coordinator"", None):
   1363     return _ClusterCoordinatorDataHandler(*args, **kwargs)
-> 1364   return DataHandler(*args, **kwargs)
   1365 
   1366 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)
   1150       self._steps_per_execution_value = steps_per_execution.numpy().item()
   1151 
-> 1152     adapter_cls = select_data_adapter(x, y)
   1153     self._verify_data_adapter_compatibility(adapter_cls)
   1154     self._adapter = adapter_cls(

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/data_adapter.py in select_data_adapter(x, y)
    992         ""Failed to find data adapter that can handle ""
    993         ""input: {}, {}"".format(
--> 994             _type_name(x), _type_name(y)))
    995   elif len(adapter_cls) > 1:
    996     raise RuntimeError(

ValueError: Failed to find data adapter that can handle input: <class 'keras.preprocessing.sequence.TimeseriesGenerator'>, <class 'NoneType'>
```

Need help :)"
51277, ValueError: Input 0 of node model/x/ was passed float from model/x/resource:0 incompatible with expected resource ,"### 1. System information

- OS Platform and Distribution: Linux Ubuntu 20.10
- TensorFlow installation: pip package 
- Tensorflow version: 2.4.1
- Python version: 3.8

### 2. Code

I created a Keras custom layer which implements a custom causal Conv1D. To do it, I simply used the classes Conv and Conv1D (they are in tensorflow/python/keras/layers/convolutional.py) and modified Conv. I'll show you how I use this layer with a very silly example dataset, which is characterized by only two training samples (given an ordered sequence of numbers as a training sample, the model should predict its next sequence: for example, if I've [0, 1, 2] the output will be [3, 4, 5]). However I get the following warnings and errors (I read similar problems, but this seems a little bit different):

    Epoch 1/10
    WARNING:tensorflow:Gradients do not exist for variables ['MyConv/kernel:0'] when minimizing the loss.
    WARNING:tensorflow:Gradients do not exist for variables ['MyConv/kernel:0'] when minimizing the loss.
    2/2 [==============================] - 1s 1ms/step - loss: 113.0949 - accuracy: 1.0000
    Epoch 2/10
    2/2 [==============================] - 0s 1ms/step - loss: 117.4004 - accuracy: 1.0000
    Epoch 3/10
    2/2 [==============================] - 0s 1ms/step - loss: 124.0515 - accuracy: 1.0000
    Epoch 4/10
    2/2 [==============================] - 0s 994us/step - loss: 132.9754 - accuracy: 1.0000
    Epoch 5/10
    2/2 [==============================] - 0s 1ms/step - loss: 154.4105 - accuracy: 1.0000
    Epoch 6/10
    2/2 [==============================] - 0s 4ms/step - loss: 157.2047 - accuracy: 1.0000
    Epoch 7/10
    2/2 [==============================] - 0s 981us/step - loss: 184.0751 - accuracy: 1.0000
    Epoch 8/10
    2/2 [==============================] - 0s 902us/step - loss: 201.2888 - accuracy: 1.0000
    Epoch 9/10
    2/2 [==============================] - 0s 888us/step - loss: 219.6019 - accuracy: 1.0000
    Epoch 10/10
    2/2 [==============================] - 0s 5ms/step - loss: 238.6077 - accuracy: 1.0000

    ValueError: Input 0 of node model/MyConv/model/MyConv/strided_slice/_assign was passed float from 
    model/MyConv/ReadVariableOp/resource:0 incompatible with expected resource.

I attached the example code used to train the model:
[model.zip](https://github.com/tensorflow/tensorflow/files/6941085/model.zip)
"
51276,TFLite GPU Delegate with OpenGL wrong output,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Dragonboard 845c (db845c)
- TensorFlow installed from (source or binary): Yes
- TensorFlow version (use command below): 2.4.2
- Python version:
- Bazel version (if compiling from source): 4.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


I am running a tflite ssd mobilenet face detection model on CPU and the results are correct but when I delegate to GPU using code below I get wrong results ( score is max): 
```
const TfLiteGpuDelegateOptionsV2 options = {
            .is_precision_loss_allowed = 1, // FP16
            .inference_preference = TFLITE_GPU_INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER,
            .inference_priority1 = TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY,
            .inference_priority2 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO,
            .inference_priority3 = TFLITE_GPU_INFERENCE_PRIORITY_AUTO,
            .experimental_flags = TFLITE_GPU_EXPERIMENTAL_FLAGS_GL_ONLY,
        };

        TfLiteDelegate *delegate = TfLiteGpuDelegateV2Create(&options);
        if (m_interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk)
        {
            std::cerr << ""Failed to modify graph with delegate"" << std::endl;
            exit(0);
        }
``` 

I have tried more than 3 models and the results are the same, on CPU is working correctly but on gpu no detection or output is trash. 

> NOTE: I have Dragonboard 845 running latest Android 11 (flashed from master branch) and it currently supports only OpenGL.

Output when delegating: 

```
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: Following operations are not supported by GPU delegate:
CUSTOM TFLite_Detection_PostProcess: TFLite_Detection_PostProcess
98 operations will run on the GPU, and the remaining 1 operations will run on the CPU.
INFO: Replacing 98 node(s) with delegate (TfLiteGpuDelegateV2) node, yielding 2 partitions.
INFO: Initialized OpenGL-based API.
INFO: Created 1 GPU delegate kernels.
```

**Describe the expected behavior**
Model should have same results when delegating on GPU using OpenGL only.

> For reference I will upload tflite model also.
[face_ssd_mobilenet_v2.tflite.zip](https://github.com/tensorflow/tensorflow/files/6940801/face_ssd_mobilenet_v2.tflite.zip)

"
51247,"VAE model causes ""tensorflow:Gradients do not exist for variables"" error","I am constructing a Variational Auto-Encoder (VAE) model in Tensorflow 2.15.0, but when I go to fit it, I get the ""tensorflow:Gradients do not exist for variables"" for the variables in the decoder part of the VAE.

Here is the code for the encoder:
```
    encoder = Sequential( [
                           
        Conv2D( filters = 32, kernel_size = ( 4, 4 ), strides = ( 2, 2 ), padding = ""same"", activation = ""relu"",
                input_shape = INPUT_IMAGE_SHAPE, name = ""encoder_conv2d_0"" ),
        BatchNormalization( name = ""encoder_batchnorm_0""),
        Conv2D( filters = 64, kernel_size = ( 4, 4 ), strides = ( 2, 2 ), padding = ""same"", activation = ""relu"", name = ""encoder_conv2d_1"" ),
        BatchNormalization(  name = ""encoder_batchnorm_1"" ),
        Flatten( name = ""encoder_flatten""),
        Dense( tfpl.MultivariateNormalTriL.params_size( latent_dim ), name = ""encoder_dense"" ),
        tfpl.MultivariateNormalTriL( latent_dim, activity_regularizer = kl_regularizer, dtype = tf.float64, name = ""encoder_outdist"" )


    ], name = ""encoder"" )
```
and for the decoder:
```
    decoder = Sequential( [
        
        Dense( units = 9 * 9 * 64, activation = ""relu"", input_shape = ( latent_dim, ), name = ""decoder_dense"" ),
        Reshape( ( 9, 9, 64 ) , name = ""decoder.reshape"" ),
        UpSampling2D( size = ( 2, 2 ), name = ""decoder_upsampl_0"" ),      # ### 18 x 18 x 32
        Conv2D( filters = 128, kernel_size = ( 3, 3 ), padding = ""same"", activation = ""relu"", name = ""decoder_conv2D_0"" ),
        UpSampling2D( size = ( 2, 2 ), name = ""decoder_upsampl_1"" ),  # ### 36 x 36 x 16
        Conv2D( filters = 128, kernel_size = ( 3, 3 ), padding = ""same"", activation = ""relu"", name = ""decoder_conv2D_1"" ),
        Conv2D( filters = 3, kernel_size = ( 3, 3 ), padding = ""same"", name = ""decoder_conv2D_2"" ),
        Flatten( name = ""decoder_flatten"" ),
        tfpl.IndependentBernoulli( event_shape = INPUT_IMAGE_SHAPE, name = ""decoder_outdist"" )
        
    ], name = ""decoder"" )
```
Here are the model summaries for the encoder and decoder:
```
Model: ""encoder""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoder_conv2d_0 (Conv2D)    (None, 18, 18, 32)        1568      
_________________________________________________________________
encoder_batchnorm_0 (BatchNo (None, 18, 18, 32)        128       
_________________________________________________________________
encoder_conv2d_1 (Conv2D)    (None, 9, 9, 64)          32832     
_________________________________________________________________
encoder_batchnorm_1 (BatchNo (None, 9, 9, 64)          256       
_________________________________________________________________
encoder_flatten (Flatten)    (None, 5184)              0         
_________________________________________________________________
encoder_dense (Dense)        (None, 5)                 25925     
_________________________________________________________________
encoder_outdist (Multivariat multiple                  0         
=================================================================
Total params: 60,709
Trainable params: 60,517
Non-trainable params: 192
_________________________________________________________________

 None
Model: ""decoder""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
decoder_dense (Dense)        (None, 5184)              15552     
_________________________________________________________________
decoder.reshape (Reshape)    (None, 9, 9, 64)          0         
_________________________________________________________________
decoder_upsampl_0 (UpSamplin (None, 18, 18, 64)        0         
_________________________________________________________________
decoder_conv2D_0 (Conv2D)    (None, 18, 18, 128)       73856     
_________________________________________________________________
decoder_upsampl_1 (UpSamplin (None, 36, 36, 128)       0         
_________________________________________________________________
decoder_conv2D_1 (Conv2D)    (None, 36, 36, 128)       147584    
_________________________________________________________________
decoder_conv2D_2 (Conv2D)    (None, 36, 36, 3)         3459      
_________________________________________________________________
decoder_flatten (Flatten)    (None, 3888)              0         
_________________________________________________________________
decoder_outdist (Independent multiple                  0         
=================================================================
Total params: 240,451
Trainable params: 240,451
Non-trainable params: 0
```
Here is the probabilistic loss function:
```
@tf.function
def reconstruction_loss(batch_of_images, decoding_dist):
    """"""
    This function should compute and return the average expected reconstruction loss,
    as defined above.
    The function takes batch_of_images (Tensor containing a batch of input images to
    the encoder) and decoding_dist (output distribution of decoder after passing the 
    image batch through the encoder and decoder) as arguments.
    The function should return the scalar average expected reconstruction loss.
    """"""
    batch_loss = decoding_dist.log_prob( batch_of_images )
    loss = - tf.math.reduce_sum( batch_loss ) / batch_of_images.shape[ 0 ]
    return loss
```
Here is how the encoder and decoder are connected for model-fitting:
```
vae = Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[ 0 ]) )

optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)
vae.compile(optimizer=optimizer, loss=reconstruction_loss)
```
and here is how the fitting is done:
```
history = vae.fit( x = train_dataset, validation_data = test_dataset, epochs = 50, verbose = True )
```
Finally, here are the error messages I'm getting from the fitting step:
```
Epoch 1/50
WARNING:tensorflow:Gradients do not exist for variables ['decoder_dense/kernel:0', 'decoder_dense/bias:0', 'decoder_conv2D_0/kernel:0', 'decoder_conv2D_0/bias:0', 'decoder_conv2D_1/kernel:0', 'decoder_conv2D_1/bias:0', 'decoder_conv2D_2/kernel:0', 'decoder_conv2D_2/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['decoder_dense/kernel:0', 'decoder_dense/bias:0', 'decoder_conv2D_0/kernel:0', 'decoder_conv2D_0/bias:0', 'decoder_conv2D_1/kernel:0', 'decoder_conv2D_1/bias:0', 'decoder_conv2D_2/kernel:0', 'decoder_conv2D_2/bias:0'] when minimizing the loss.
40/40 [==============================] - 4s 29ms/step - loss: 0.1177 - val_loss: 0.0263
Epoch 2/50
40/40 [==============================] - 0s 10ms/step - loss: 0.0406 - val_loss: 0.0381
...
```

"
51246,Windows fatal exception: access violation (Ran out of memory),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow-gpu (tried with pip install tensorflow as well in a seperate env)
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.x
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA Toolkit 11.4/ 8.1.0
- GPU model and memory:  Quadro P400, 2 GB GDDR5

**Current behavior**

I am using tensorflow object detection model EfficientDet D0 512x512 (efficientdet_d0_coco17_tpu-32.
When I start training the model on my custom data set, in fact data set of very small size i.e. 24 training Images, 10 test images (2481 x 1754). On CPU the model trainings runs smoothly but on GPU with batch_size =4, it says Ran out of memory and get an error - Windows fatal exception: access violation. I am providing the trace below. Howerver with batch_size =2 it works and start to train (thought it says Ran out of memory) there is no performance improvement at at all.

**Train Command**
python model_main_tf2.py --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir=training --alsologtostderr

**Log**
(mtp4.0) D:\work\research\object_detection>python model_main_tf2.py --pipeline_config_path=training/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir=training --alsologtostderr
2021-08-04 16:38:02.878487: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
2021-08-04 16:38:05.547332: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll
2021-08-04 16:38:05.569978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P400 computeCapability: 6.1
coreClock: 1.2525GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 29.88GiB/s
2021-08-04 16:38:05.575388: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll
2021-08-04 16:38:05.585010: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll
2021-08-04 16:38:05.588056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll
2021-08-04 16:38:05.594726: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll
2021-08-04 16:38:05.600703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll
2021-08-04 16:38:05.604537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll
2021-08-04 16:38:05.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll
2021-08-04 16:38:05.611666: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll
2021-08-04 16:38:05.614167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-08-04 16:38:05.616318: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-04 16:38:05.624039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: Quadro P400 computeCapability: 6.1
coreClock: 1.2525GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 29.88GiB/s
2021-08-04 16:38:05.632019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-08-04 16:38:06.097245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-08-04 16:38:06.101126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
2021-08-04 16:38:06.103109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
2021-08-04 16:38:06.105264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1334 MB memory) -> physical GPU (device: 0, name: Quadro P400, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.
W0804 16:38:06.108209  4804 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0804 16:38:06.171064  4804 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: None
I0804 16:38:06.171064  4804 config_util.py:552] Maybe overwriting train_steps: None
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0804 16:38:06.171064  4804 config_util.py:552] Maybe overwriting use_bfloat16: False
I0804 16:38:06.171064  4804 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0
I0804 16:38:06.171064  4804 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64
I0804 16:38:06.171064  4804 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3
I0804 16:38:06.186730  4804 efficientnet_model.py:147] round_filter input=32 output=32
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.202276  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.202276  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.202276  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.202276  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.202276  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.202276  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.217941  4804 efficientnet_model.py:147] round_filter input=32 output=32
I0804 16:38:06.217941  4804 efficientnet_model.py:147] round_filter input=16 output=16
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.217941  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.217941  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.217941  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.217941  4804 cross_device_ops.py:619] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0804 16:38:06.280382  4804 efficientnet_model.py:147] round_filter input=16 output=16
I0804 16:38:06.280382  4804 efficientnet_model.py:147] round_filter input=24 output=24
I0804 16:38:06.451971  4804 efficientnet_model.py:147] round_filter input=24 output=24
I0804 16:38:06.451971  4804 efficientnet_model.py:147] round_filter input=40 output=40
I0804 16:38:06.639441  4804 efficientnet_model.py:147] round_filter input=40 output=40
I0804 16:38:06.639441  4804 efficientnet_model.py:147] round_filter input=80 output=80
I0804 16:38:06.905066  4804 efficientnet_model.py:147] round_filter input=80 output=80
I0804 16:38:06.905066  4804 efficientnet_model.py:147] round_filter input=112 output=112
I0804 16:38:07.170690  4804 efficientnet_model.py:147] round_filter input=112 output=112
I0804 16:38:07.170690  4804 efficientnet_model.py:147] round_filter input=192 output=192
I0804 16:38:07.530065  4804 efficientnet_model.py:147] round_filter input=192 output=192
I0804 16:38:07.530065  4804 efficientnet_model.py:147] round_filter input=320 output=320
I0804 16:38:07.608386  4804 efficientnet_model.py:147] round_filter input=1280 output=1280
I0804 16:38:07.655260  4804 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
WARNING:tensorflow:From D:\work\research\object_detection\object_detection\model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W0804 16:38:07.686819  4804 deprecation.py:330] From D:\work\research\object_detection\object_detection\model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
INFO:tensorflow:Reading unweighted datasets: ['train.record']
I0804 16:38:07.686819  4804 dataset_builder.py:163] Reading unweighted datasets: ['train.record']
INFO:tensorflow:Reading record datasets for input file: ['train.record']
I0804 16:38:07.686819  4804 dataset_builder.py:80] Reading record datasets for input file: ['train.record']
INFO:tensorflow:Number of filenames to read: 1
I0804 16:38:07.686819  4804 dataset_builder.py:81] Number of filenames to read: 1
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0804 16:38:07.686819  4804 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From D:\work\research\object_detection\object_detection\builders\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
W0804 16:38:07.702328  4804 deprecation.py:330] From D:\work\research\object_detection\object_detection\builders\dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.
WARNING:tensorflow:From D:\work\research\object_detection\object_detection\builders\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0804 16:38:07.718009  4804 deprecation.py:330] From D:\work\research\object_detection\object_detection\builders\dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\util\dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0804 16:38:12.967560  4804 deprecation.py:330] From C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\util\dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\autograph\impl\api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0804 16:38:16.201879  4804 deprecation.py:330] From C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\autograph\impl\api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2021-08-04 16:38:18.121582: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\keras\backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '
2021-08-04 16:38:38.140804: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll
2021-08-04 16:38:38.566078: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202
2021-08-04 16:38:39.300264: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll
2021-08-04 16:38:39.676574: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll
WARNING:tensorflow:From C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\util\deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0804 16:38:46.389341 13492 deprecation.py:528] From C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\util\deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
W0804 16:38:51.420594 13492 utils.py:78] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
W0804 16:38:59.345944  6216 utils.py:78] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
W0804 16:39:06.404875 19920 utils.py:78] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
W0804 16:39:14.076793 11208 utils.py:78] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.
2021-08-04 16:39:46.100920: W tensorflow/core/common_runtime/bfc_allocator.cc:456] Allocator (GPU_0_bfc) ran out of memory trying to allocate 512.0KiB (rounded to 524288)requested by op while/body/_1/EfficientDet-D0/bifpn/node_19/3_dn_lvl_5/combine/stack
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation.
Current allocation summary follows.
Current allocation summary follows.
2021-08-04 16:39:46.131517: I tensorflow/core/common_runtime/bfc_allocator.cc:991] BFCAllocator dump for GPU_0_bfc
2021-08-04 16:39:46.137256: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (256):   Total Chunks: 1011, Chunks in use: 1009. 252.8KiB allocated for chunks. 252.3KiB in use in bin. 138.5KiB client-requested in use in bin.
2021-08-04 16:39:46.147828: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (512):   Total Chunks: 169, Chunks in use: 169. 104.8KiB allocated for chunks. 104.8KiB in use in bin. 85.7KiB client-requested in use in bin.
2021-08-04 16:39:46.153697: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (1024):  Total Chunks: 80, Chunks in use: 80. 90.5KiB allocated for chunks. 90.5KiB in use in bin. 82.4KiB client-requested in use in bin.
2021-08-04 16:39:46.164655: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (2048):  Total Chunks: 255, Chunks in use: 255. 627.5KiB allocated for chunks. 627.5KiB in use in bin. 596.0KiB client-requested in use in bin.
2021-08-04 16:39:46.169814: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (4096):  Total Chunks: 100, Chunks in use: 100. 478.3KiB allocated for chunks. 478.3KiB in use in bin. 453.2KiB client-requested in use in bin.
2021-08-04 16:39:46.177073: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (8192):  Total Chunks: 53, Chunks in use: 52. 586.8KiB allocated for chunks. 573.3KiB in use in bin. 541.9KiB client-requested in use in bin.
2021-08-04 16:39:46.180967: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (16384):         Total Chunks: 119, Chunks in use: 119. 2.10MiB allocated for chunks. 2.10MiB in use in bin. 1.98MiB client-requested in use in bin.
2021-08-04 16:39:46.184395: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (32768):         Total Chunks: 43, Chunks in use: 43. 1.61MiB allocated for chunks. 1.61MiB in use in bin. 1.56MiB client-requested in use in bin.
2021-08-04 16:39:46.190071: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (65536):         Total Chunks: 64, Chunks in use: 63. 4.74MiB allocated for chunks. 4.68MiB in use in bin. 4.55MiB client-requested in use in bin.
2021-08-04 16:39:46.194824: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (131072):        Total Chunks: 71, Chunks in use: 71. 13.26MiB allocated for chunks. 13.26MiB in use in bin. 12.77MiB client-requested in use in bin.
2021-08-04 16:39:46.199623: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (262144):        Total Chunks: 49, Chunks in use: 47. 15.13MiB allocated for chunks. 14.40MiB in use in bin. 13.50MiB client-requested in use in bin.
2021-08-04 16:39:46.209243: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (524288):        Total Chunks: 38, Chunks in use: 38. 30.54MiB allocated for chunks. 30.54MiB in use in bin. 30.16MiB client-requested in use in bin.
2021-08-04 16:39:46.215150: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (1048576):       Total Chunks: 32, Chunks in use: 32. 38.25MiB allocated for chunks. 38.25MiB in use in bin. 35.31MiB client-requested in use in bin.
2021-08-04 16:39:46.222745: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (2097152):       Total Chunks: 11, Chunks in use: 11. 30.79MiB allocated for chunks. 30.79MiB in use in bin. 28.67MiB client-requested in use in bin.
2021-08-04 16:39:46.226251: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (4194304):       Total Chunks: 50, Chunks in use: 50. 269.38MiB allocated for chunks. 269.38MiB in use in bin. 266.63MiB client-requested in use in bin.
2021-08-04 16:39:46.230039: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (8388608):       Total Chunks: 20, Chunks in use: 20. 237.00MiB allocated for chunks. 237.00MiB in use in bin. 237.00MiB client-requested in use in bin.
2021-08-04 16:39:46.237180: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (16777216):      Total Chunks: 4, Chunks in use: 4. 77.46MiB allocated for chunks. 77.46MiB in use in bin. 77.46MiB client-requested in use in bin.
2021-08-04 16:39:46.242508: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (33554432):      Total Chunks: 9, Chunks in use: 9. 324.36MiB allocated for chunks. 324.36MiB in use in bin. 312.00MiB client-requested in use in bin.
2021-08-04 16:39:46.247344: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (67108864):      Total Chunks: 3, Chunks in use: 3. 288.00MiB allocated for chunks. 288.00MiB in use in bin. 288.00MiB client-requested in use in bin.
2021-08-04 16:39:46.256827: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (134217728):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-08-04 16:39:46.261713: I tensorflow/core/common_runtime/bfc_allocator.cc:998] Bin (268435456):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-08-04 16:39:46.268859: I tensorflow/core/common_runtime/bfc_allocator.cc:1014] Bin for 512.0KiB was 512.0KiB, Chunk State:
2021-08-04 16:39:46.272614: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] Next region of size 1399566592
2021-08-04 16:39:46.275718: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600000 of size 1280 by op ScratchBuffer action_count 2716826279889 step 0 next 1
2021-08-04 16:39:46.278526: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600500 of size 256 by op AssignVariableOp action_count 2716826279890 step 0 next 2
2021-08-04 16:39:46.283215: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600600 of size 256 by op AssignVariableOp action_count 2716826279891 step 0 next 3
2021-08-04 16:39:46.286097: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600700 of size 256 by op Fill action_count 2716826279899 step 0 next 9
2021-08-04 16:39:46.288766: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600800 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_0/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289676 step 13097390214773393689 next 10
2021-08-04 16:39:46.293877: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600900 of size 256 by op Fill action_count 2716826279901 step 0 next 11
2021-08-04 16:39:46.302344: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600a00 of size 256 by op AssignVariableOp action_count 2716826286748 step 0 next 12
2021-08-04 16:39:46.306855: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600b00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_0/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289677 step 13097390214773393689 next 13
2021-08-04 16:39:46.316281: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600c00 of size 256 by op AssignVariableOp action_count 2716826286756 step 0 next 14
2021-08-04 16:39:46.320640: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600d00 of size 256 by op AssignVariableOp action_count 2716826287062 step 0 next 21
2021-08-04 16:39:46.326373: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600e00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/se_reduce_conv2d/Conv2D action_count 2716826289738 step 13097390214773393689 next 31
2021-08-04 16:39:46.333115: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01600f00 of size 256 by op AssignVariableOp action_count 2716826287228 step 0 next 32
2021-08-04 16:39:46.336008: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601000 of size 256 by op Mul action_count 2716826279940 step 0 next 34
2021-08-04 16:39:46.338706: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601100 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289727 step 13097390214773393689 next 33
2021-08-04 16:39:46.348401: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601300 of size 512 by op AssignVariableOp action_count 2716826287298 step 0 next 4
2021-08-04 16:39:46.352560: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601500 of size 256 by op Mul action_count 2716826279893 step 0 next 5
2021-08-04 16:39:46.357169: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601600 of size 256 by op Mul action_count 2716826279906 step 0 next 15
2021-08-04 16:39:46.364688: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601700 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_0/block_0/se_reduce_conv2d/Conv2D action_count 2716826289688 step 13097390214773393689 next 17
2021-08-04 16:39:46.369412: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601800 of size 256 by op AssignVariableOp action_count 2716826286984 step 0 next 18
2021-08-04 16:39:46.373292: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601900 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_0/block_0/se_reduce_activation/Sigmoid action_count 2716826289691 step 13097390214773393689 next 19
2021-08-04 16:39:46.383148: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601a00 of size 256 by op AssignVariableOp action_count 2716826286992 step 0 next 20
2021-08-04 16:39:46.386012: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601b00 of size 256 by op Mul action_count 2716826279916 step 0 next 16
2021-08-04 16:39:46.388666: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601c00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/se_reduce_conv2d/Conv2D action_count 2716826289845 step 13097390214773393689 next 71
2021-08-04 16:39:46.397111: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01601d00 of size 768 by op AssignVariableOp action_count 2716826286956 step 0 next 56
2021-08-04 16:39:46.400718: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01602000 of size 1024 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289834 step 13097390214773393689 next 6
2021-08-04 16:39:46.407997: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01602400 of size 256 by op Add action_count 2716826279895 step 0 next 7
2021-08-04 16:39:46.415018: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01602500 of size 3584 by op AssignVariableOp action_count 2716826286754 step 0 next 8
2021-08-04 16:39:46.419945: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603300 of size 1024 by op AssignVariableOp action_count 2716826287044 step 0 next 22
2021-08-04 16:39:46.428485: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603700 of size 256 by op Mul action_count 2716826279923 step 0 next 23
2021-08-04 16:39:46.433226: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603800 of size 256 by op AssignVariableOp action_count 2716826287104 step 0 next 26
2021-08-04 16:39:46.439954: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603900 of size 256 by op Mul action_count 2716826279930 step 0 next 28
2021-08-04 16:39:46.444866: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603a00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/se_reduce_activation/Sigmoid action_count 2716826289741 step 13097390214773393689 next 27
2021-08-04 16:39:46.451619: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603b00 of size 256 by op AssignVariableOp action_count 2716826287192 step 0 next 24
2021-08-04 16:39:46.458690: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603c00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/se_reduce_conv2d/Conv2D action_count 2716826290074 step 13097390214773393689 next 1938
2021-08-04 16:39:46.464077: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01603e00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/se_reduce_activation/Sigmoid action_count 2716826290079 step 13097390214773393689 next 25
2021-08-04 16:39:46.473297: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604000 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289728 step 13097390214773393689 next 37
2021-08-04 16:39:46.481130: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604200 of size 256 by op AssignVariableOp action_count 2716826287314 step 0 next 186
2021-08-04 16:39:46.487564: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604300 of size 256 by op GeneratorDataset action_count 2716826287370 step 0 next 38
2021-08-04 16:39:46.491523: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604400 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/se_reduce_activation/mul action_count 2716826289742 step 13097390214773393689 next 1849
2021-08-04 16:39:46.496941: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604500 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/project_bn/FusedBatchNormV3 action_count 2716826289754 step 13097390214773393689 next 39
2021-08-04 16:39:46.505425: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604600 of size 512 by op AssignVariableOp action_count 2716826286804 step 0 next 41
2021-08-04 16:39:46.508399: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604800 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/project_bn/FusedBatchNormV3 action_count 2716826289755 step 13097390214773393689 next 1533
2021-08-04 16:39:46.512927: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604900 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_0/project_bn/FusedBatchNormV3 action_count 2716826289756 step 13097390214773393689 next 42
2021-08-04 16:39:46.520974: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604a00 of size 256 by op AssignVariableOp action_count 2716826286840 step 0 next 304
2021-08-04 16:39:46.524039: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604b00 of size 256 by op AssignVariableOp action_count 2716826286858 step 0 next 43
2021-08-04 16:39:46.527369: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604c00 of size 256 by op Mul action_count 2716826279959 step 0 next 45
2021-08-04 16:39:46.532977: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604d00 of size 256 by op AssignVariableOp action_count 2716826286882 step 0 next 44
2021-08-04 16:39:46.538076: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604e00 of size 256 by op AssignVariableOp action_count 2716826286906 step 0 next 445
2021-08-04 16:39:46.542759: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01604f00 of size 256 by op AssignVariableOp action_count 2716826286908 step 0 next 29
2021-08-04 16:39:46.549087: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605000 of size 256 by op AssignVariableOp action_count 2716826287144 step 0 next 158
2021-08-04 16:39:46.554801: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605100 of size 512 by op AssignVariableOp action_count 2716826287154 step 0 next 172
2021-08-04 16:39:46.558538: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605300 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/se_reduce_conv2d/Conv2D action_count 2716826290128 step 13097390214773393689 next 174
2021-08-04 16:39:46.567874: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605500 of size 256 by op AssignVariableOp action_count 2716826287182 step 0 next 152
2021-08-04 16:39:46.570896: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605600 of size 256 by op AssignVariableOp action_count 2716826287190 step 0 next 190
2021-08-04 16:39:46.574473: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605700 of size 256 by op AssignVariableOp action_count 2716826287268 step 0 next 30
2021-08-04 16:39:46.580559: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605800 of size 256 by op Mul action_count 2716826279972 step 0 next 50
2021-08-04 16:39:46.585985: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605900 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/se_reduce_conv2d/Conv2D action_count 2716826289790 step 13097390214773393689 next 1863
2021-08-04 16:39:46.597928: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605a00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/se_reduce_activation/Sigmoid action_count 2716826289795 step 13097390214773393689 next 53
2021-08-04 16:39:46.602854: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605b00 of size 256 by op AssignVariableOp action_count 2716826286936 step 0 next 61
2021-08-04 16:39:46.605779: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605c00 of size 256 by op AssignVariableOp action_count 2716826286946 step 0 next 55
2021-08-04 16:39:46.611818: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605d00 of size 256 by op Mul action_count 2716826279982 step 0 next 48
2021-08-04 16:39:46.616830: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01605e00 of size 768 by op AssignVariableOp action_count 2716826286926 step 0 next 52
2021-08-04 16:39:46.620852: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01606100 of size 768 by op AssignVariableOp action_count 2716826286928 step 0 next 46
2021-08-04 16:39:46.627621: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01606400 of size 1536 by op AssignVariableOp action_count 2716826286892 step 0 next 47
2021-08-04 16:39:46.630859: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01606a00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826289779 step 13097390214773393689 next 58
2021-08-04 16:39:46.635964: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01606d00 of size 768 by op AssignVariableOp action_count 2716826286918 step 0 next 59
2021-08-04 16:39:46.642975: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01607000 of size 1024 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826289780 step 13097390214773393689 next 40
2021-08-04 16:39:46.651899: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01607400 of size 5120 by op AssignVariableOp action_count 2716826286760 step 0 next 35
2021-08-04 16:39:46.657741: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01608800 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/se_reduce_activation/mul action_count 2716826290242 step 13097390214773393689 next 1980
2021-08-04 16:39:46.663281: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01608a00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/project_bn/FusedBatchNormV3 action_count 2716826290254 step 13097390214773393689 next 1983
2021-08-04 16:39:46.673954: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01608c00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/project_bn/FusedBatchNormV3 action_count 2716826290255 step 13097390214773393689 next 1984
2021-08-04 16:39:46.680298: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01608e00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/project_bn/FusedBatchNormV3 action_count 2716826290256 step 13097390214773393689 next 1985
2021-08-04 16:39:46.684631: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609000 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/project_bn/FusedBatchNormV3 action_count 2716826290257 step 13097390214773393689 next 193
2021-08-04 16:39:46.694109: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609300 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290277 step 13097390214773393689 next 1991
2021-08-04 16:39:46.700756: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609400 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290278 step 13097390214773393689 next 1992
2021-08-04 16:39:46.712220: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609500 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290279 step 13097390214773393689 next 1993
2021-08-04 16:39:46.724294: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609600 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290280 step 13097390214773393689 next 239
2021-08-04 16:39:46.729530: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609700 of size 512 by op AssignVariableOp action_count 2716826287296 step 0 next 240
2021-08-04 16:39:46.732579: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609900 of size 768 by op AssignVariableOp action_count 2716826287324 step 0 next 231
2021-08-04 16:39:46.737812: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609c00 of size 256 by op Cast action_count 2716826287374 step 0 next 782
2021-08-04 16:39:46.740688: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609d00 of size 256 by op Cast action_count 2716826287377 step 0 next 781
2021-08-04 16:39:46.743738: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609e00 of size 256 by op Cast action_count 2716826287380 step 0 next 780
2021-08-04 16:39:46.746750: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01609f00 of size 256 by op Fill action_count 2716826287388 step 0 next 36
2021-08-04 16:39:46.753408: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160a000 of size 3584 by op AssignVariableOp action_count 2716826286938 step 0 next 65
2021-08-04 16:39:46.758960: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160ae00 of size 6144 by op AssignVariableOp action_count 2716826286976 step 0 next 72
2021-08-04 16:39:46.766549: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160c600 of size 256 by op AssignVariableOp action_count 2716826286948 step 0 next 75
2021-08-04 16:39:46.771934: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160c700 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/se_reduce_activation/Sigmoid action_count 2716826289850 step 13097390214773393689 next 76
2021-08-04 16:39:46.776674: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160c800 of size 1024 by op AssignVariableOp action_count 2716826286968 step 0 next 78
2021-08-04 16:39:46.781765: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160cc00 of size 768 by op AssignVariableOp action_count 2716826286958 step 0 next 66
2021-08-04 16:39:46.784998: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160cf00 of size 256 by op Mul action_count 2716826280001 step 0 next 67
2021-08-04 16:39:46.787797: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d000 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/se_reduce_activation/mul action_count 2716826289851 step 13097390214773393689 next 1878
2021-08-04 16:39:46.793557: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d100 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/project_bn/FusedBatchNormV3 action_count 2716826289863 step 13097390214773393689 next 1881
2021-08-04 16:39:46.805580: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d200 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/project_bn/FusedBatchNormV3 action_count 2716826289864 step 13097390214773393689 next 86
2021-08-04 16:39:46.813549: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d300 of size 256 by op AssignVariableOp action_count 2716826286974 step 0 next 77
2021-08-04 16:39:46.817411: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d400 of size 256 by op AssignVariableOp action_count 2716826286982 step 0 next 83
2021-08-04 16:39:46.822376: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d500 of size 256 by op AssignVariableOp action_count 2716826286994 step 0 next 87
2021-08-04 16:39:46.825691: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d600 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/project_bn/FusedBatchNormV3 action_count 2716826289916 step 13097390214773393689 next 1895
2021-08-04 16:39:46.831990: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d700 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/project_bn/FusedBatchNormV3 action_count 2716826289917 step 13097390214773393689 next 1896
2021-08-04 16:39:46.836719: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d800 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/project_bn/FusedBatchNormV3 action_count 2716826289918 step 13097390214773393689 next 1897
2021-08-04 16:39:46.841925: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160d900 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/project_bn/FusedBatchNormV3 action_count 2716826289919 step 13097390214773393689 next 107
2021-08-04 16:39:46.854595: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160da00 of size 1024 by op AssignVariableOp action_count 2716826287014 step 0 next 108
2021-08-04 16:39:46.860578: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160de00 of size 1280 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/expand_bn/FusedBatchNormV3 action_count 2716826289936 step 13097390214773393689 next 115
2021-08-04 16:39:46.865883: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160e300 of size 1280 by op AssignVariableOp action_count 2716826287040 step 0 next 51
2021-08-04 16:39:46.870426: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0160e800 of size 9984 by op AssignVariableOp action_count 2716826286924 step 0 next 60
2021-08-04 16:39:46.873716: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01610f00 of size 3584 by op AssignVariableOp action_count 2716826286942 step 0 next 68
2021-08-04 16:39:46.881091: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01611d00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289833 step 13097390214773393689 next 80
2021-08-04 16:39:46.885413: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612000 of size 768 by op AssignVariableOp action_count 2716826286966 step 0 next 81
2021-08-04 16:39:46.888260: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612300 of size 256 by op Mul action_count 2716826280032 step 0 next 82
2021-08-04 16:39:46.895927: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612400 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/project_bn/FusedBatchNormV3 action_count 2716826289865 step 13097390214773393689 next 1882
2021-08-04 16:39:46.901987: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612500 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/project_bn/FusedBatchNormV3 action_count 2716826289866 step 13097390214773393689 next 1883
2021-08-04 16:39:46.912151: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612600 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/se_reduce_conv2d/Conv2D action_count 2716826289898 step 13097390214773393689 next 85
2021-08-04 16:39:46.916724: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612700 of size 1024 by op AssignVariableOp action_count 2716826286978 step 0 next 70
2021-08-04 16:39:46.919930: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01612b00 of size 19712 by op AssignVariableOp action_count 2716826286964 step 0 next 57
2021-08-04 16:39:46.928019: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01617800 of size 9728 by op AssignVariableOp action_count 2716826287052 step 0 next 114
2021-08-04 16:39:46.931780: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01619e00 of size 9984 by op AssignVariableOp action_count 2716826287064 step 0 next 132
2021-08-04 16:39:46.934909: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161c500 of size 512 by op AssignVariableOp action_count 2716826287072 step 0 next 131
2021-08-04 16:39:46.940311: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161c700 of size 512 by op AssignVariableOp action_count 2716826287074 step 0 next 133
2021-08-04 16:39:46.944970: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161c900 of size 256 by op Mul action_count 2716826280135 step 0 next 134
2021-08-04 16:39:46.949606: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161ca00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/se_reduce_conv2d/Conv2D action_count 2716826290020 step 13097390214773393689 next 1922
2021-08-04 16:39:46.956316: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161cc00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/se_reduce_activation/Sigmoid action_count 2716826290025 step 13097390214773393689 next 138
2021-08-04 16:39:46.961896: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161ce00 of size 256 by op AssignVariableOp action_count 2716826287090 step 0 next 130
2021-08-04 16:39:46.965888: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161cf00 of size 768 by op AssignVariableOp action_count 2716826287114 step 0 next 140
2021-08-04 16:39:46.975873: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161d200 of size 256 by op Mul action_count 2716826280145 step 0 next 142
2021-08-04 16:39:46.979865: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161d300 of size 2048 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826290009 step 13097390214773393689 next 141
2021-08-04 16:39:46.988868: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161db00 of size 2304 by op AssignVariableOp action_count 2716826287084 step 0 next 73
2021-08-04 16:39:46.992264: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0161e400 of size 13824 by op AssignVariableOp action_count 2716826286954 step 0 next 74
2021-08-04 16:39:46.995598: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01621a00 of size 14848 by op AssignVariableOp action_count 2716826287022 step 0 next 92
2021-08-04 16:39:47.000568: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625400 of size 256 by op Mul action_count 2716826280054 step 0 next 93
2021-08-04 16:39:47.004477: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625500 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/se_reduce_activation/Sigmoid action_count 2716826289903 step 13097390214773393689 next 1891
2021-08-04 16:39:47.009032: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625600 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/se_reduce_activation/mul action_count 2716826289904 step 13097390214773393689 next 97
2021-08-04 16:39:47.013823: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625700 of size 256 by op AssignVariableOp action_count 2716826287020 step 0 next 69
2021-08-04 16:39:47.020545: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625800 of size 256 by op AssignVariableOp action_count 2716826287030 step 0 next 99
2021-08-04 16:39:47.025901: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625900 of size 256 by op Mul action_count 2716826280064 step 0 next 101
2021-08-04 16:39:47.032280: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625a00 of size 1024 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826289887 step 13097390214773393689 next 88
2021-08-04 16:39:47.040446: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01625e00 of size 3584 by op AssignVariableOp action_count 2716826286980 step 0 next 89
2021-08-04 16:39:47.043380: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01626c00 of size 1024 by op AssignVariableOp action_count 2716826287004 step 0 next 100
2021-08-04 16:39:47.050426: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01627000 of size 1024 by op while/body/_1/EfficientDet-D0/model/stack_2/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826289888 step 13097390214773393689 next 104
2021-08-04 16:39:47.058640: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01627400 of size 9728 by op AssignVariableOp action_count 2716826287026 step 0 next 113
2021-08-04 16:39:47.064565: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01629a00 of size 1024 by op AssignVariableOp action_count 2716826287066 step 0 next 106
2021-08-04 16:39:47.069684: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01629e00 of size 10752 by op AssignVariableOp action_count 2716826287068 step 0 next 116
2021-08-04 16:39:47.073119: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162c800 of size 256 by op AssignVariableOp action_count 2716826287032 step 0 next 119
2021-08-04 16:39:47.076029: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162c900 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/input_0_up_lvl_3/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826289944 step 13097390214773393689 next 120
2021-08-04 16:39:47.083647: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162ca00 of size 256 by op AssignVariableOp action_count 2716826287038 step 0 next 121
2021-08-04 16:39:47.087073: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162cb00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/input_0_up_lvl_3/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826289945 step 13097390214773393689 next 1901
2021-08-04 16:39:47.096013: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162cc00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/input_0_up_lvl_3/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826289946 step 13097390214773393689 next 1902
2021-08-04 16:39:47.106302: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162cd00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/input_0_up_lvl_3/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826289947 step 13097390214773393689 next 1903
2021-08-04 16:39:47.115883: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162ce00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/se_reduce_conv2d/Conv2D action_count 2716826289967 step 13097390214773393689 next 122
2021-08-04 16:39:47.121834: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162cf00 of size 1024 by op AssignVariableOp action_count 2716826287046 step 0 next 124
2021-08-04 16:39:47.128332: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162d300 of size 1024 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826289956 step 13097390214773393689 next 125
2021-08-04 16:39:47.133709: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162d700 of size 1024 by op AssignVariableOp action_count 2716826287054 step 0 next 126
2021-08-04 16:39:47.136485: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162db00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/project_bn/FusedBatchNormV3 action_count 2716826289985 step 13097390214773393689 next 1911
2021-08-04 16:39:47.145663: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162dd00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/project_bn/FusedBatchNormV3 action_count 2716826289986 step 13097390214773393689 next 128
2021-08-04 16:39:47.151460: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162df00 of size 1024 by op AssignVariableOp action_count 2716826287056 step 0 next 129
2021-08-04 16:39:47.158726: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162e300 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/project_bn/FusedBatchNormV3 action_count 2716826289987 step 13097390214773393689 next 1912
2021-08-04 16:39:47.163070: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162e500 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/project_bn/FusedBatchNormV3 action_count 2716826289988 step 13097390214773393689 next 110
2021-08-04 16:39:47.167387: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162e800 of size 256 by op Mul action_count 2716826280083 step 0 next 111
2021-08-04 16:39:47.170202: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162e900 of size 2048 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826290010 step 13097390214773393689 next 145
2021-08-04 16:39:47.181709: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162f100 of size 1024 by op AssignVariableOp action_count 2716826287092 step 0 next 127
2021-08-04 16:39:47.185877: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162f500 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/project_bn/FusedBatchNormV3 action_count 2716826290041 step 13097390214773393689 next 1927
2021-08-04 16:39:47.196275: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0162f700 of size 2560 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/expand_bn/FusedBatchNormV3 action_count 2716826290052 step 13097390214773393689 next 147
2021-08-04 16:39:47.204635: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01630100 of size 2048 by op AssignVariableOp action_count 2716826287098 step 0 next 150
2021-08-04 16:39:47.209789: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01630900 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/se_reduce_activation/mul action_count 2716826290026 step 13097390214773393689 next 1923
2021-08-04 16:39:47.215607: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01630b00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/project_bn/FusedBatchNormV3 action_count 2716826290038 step 13097390214773393689 next 1924
2021-08-04 16:39:47.225074: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01630d00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/project_bn/FusedBatchNormV3 action_count 2716826290039 step 13097390214773393689 next 1926
2021-08-04 16:39:47.236710: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01630f00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_1/project_bn/FusedBatchNormV3 action_count 2716826290040 step 13097390214773393689 next 151
2021-08-04 16:39:47.240961: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01631100 of size 2816 by op AssignVariableOp action_count 2716826287108 step 0 next 94
2021-08-04 16:39:47.244363: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01631c00 of size 2048 by op AssignVariableOp action_count 2716826287082 step 0 next 139
2021-08-04 16:39:47.247820: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01632400 of size 30720 by op AssignVariableOp action_count 2716826287094 step 0 next 112
2021-08-04 16:39:47.256718: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01639c00 of size 256 by op Mul action_count 2716826280164 step 0 next 153
2021-08-04 16:39:47.261872: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01639d00 of size 2816 by op AssignVariableOp action_count 2716826287124 step 0 next 159
2021-08-04 16:39:47.267491: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0163a800 of size 512 by op AssignVariableOp action_count 2716826287116 step 0 next 160
2021-08-04 16:39:47.272639: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0163aa00 of size 3072 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/depthwise_bn/FusedBatchNormV3 action_count 2716826290064 step 13097390214773393689 next 164
2021-08-04 16:39:47.279675: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0163b600 of size 2048 by op AssignVariableOp action_count 2716826287126 step 0 next 165
2021-08-04 16:39:47.286766: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0163be00 of size 2048 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/depthwise_bn/FusedBatchNormV3 action_count 2716826290063 step 13097390214773393689 next 166
2021-08-04 16:39:47.291802: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0163c600 of size 3584 by op AssignVariableOp action_count 2716826287134 step 0 next 105
2021-08-04 16:39:47.294635: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0163d400 of size 52736 by op AssignVariableOp action_count 2716826287110 step 0 next 102
2021-08-04 16:39:47.301388: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0164a200 of size 38400 by op AssignVariableOp action_count 2716826287010 step 0 next 103
2021-08-04 16:39:47.306379: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01653800 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/se_reduce_activation/mul action_count 2716826290080 step 13097390214773393689 next 1939
2021-08-04 16:39:47.314017: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01653a00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/project_bn/FusedBatchNormV3 action_count 2716826290092 step 13097390214773393689 next 1934
2021-08-04 16:39:47.319239: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01653c00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/project_bn/FusedBatchNormV3 action_count 2716826290093 step 13097390214773393689 next 1940
2021-08-04 16:39:47.324201: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01653e00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/project_bn/FusedBatchNormV3 action_count 2716826290094 step 13097390214773393689 next 168
2021-08-04 16:39:47.334820: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01654000 of size 2048 by op AssignVariableOp action_count 2716826287136 step 0 next 169
2021-08-04 16:39:47.338793: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01654800 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_3/block_2/project_bn/FusedBatchNormV3 action_count 2716826290095 step 13097390214773393689 next 1941
2021-08-04 16:39:47.347458: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01654a00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/se_reduce_activation/mul action_count 2716826290134 step 13097390214773393689 next 1951
2021-08-04 16:39:47.352580: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01654c00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/project_bn/FusedBatchNormV3 action_count 2716826290146 step 13097390214773393689 next 1954
2021-08-04 16:39:47.356863: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01654e00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/project_bn/FusedBatchNormV3 action_count 2716826290147 step 13097390214773393689 next 170
2021-08-04 16:39:47.364598: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01655000 of size 2048 by op AssignVariableOp action_count 2716826287142 step 0 next 171
2021-08-04 16:39:47.368619: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01655800 of size 2816 by op AssignVariableOp action_count 2716826287164 step 0 next 178
2021-08-04 16:39:47.372591: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01656300 of size 512 by op AssignVariableOp action_count 2716826287156 step 0 next 179
2021-08-04 16:39:47.381969: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01656500 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/se_reduce_activation/Sigmoid action_count 2716826290133 step 13097390214773393689 next 180
2021-08-04 16:39:47.388563: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01656700 of size 4608 by op AssignVariableOp action_count 2716826287334 step 0 next 216
2021-08-04 16:39:47.395588: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01657900 of size 5120 by op AssignVariableOp action_count 2716826287354 step 0 next 346
2021-08-04 16:39:47.399784: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01658d00 of size 512 by op Fill action_count 2716826287395 step 0 next 775
2021-08-04 16:39:47.403625: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01658f00 of size 2304 by op Fill action_count 2716826287396 step 0 next 774
2021-08-04 16:39:47.410267: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01659800 of size 256 by op Fill action_count 2716826287398 step 0 next 772
2021-08-04 16:39:47.413056: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01659900 of size 256 by op Fill action_count 2716826287399 step 0 next 357
2021-08-04 16:39:47.415794: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01659a00 of size 256 by op Fill action_count 2716826287400 step 0 next 773
2021-08-04 16:39:47.418530: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01659b00 of size 2304 by op Fill action_count 2716826287401 step 0 next 771
2021-08-04 16:39:47.425954: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165a400 of size 256 by op Fill action_count 2716826287403 step 0 next 769
2021-08-04 16:39:47.430022: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165a500 of size 256 by op Fill action_count 2716826287404 step 0 next 768
2021-08-04 16:39:47.434262: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165a600 of size 256 by op Fill action_count 2716826287405 step 0 next 767
2021-08-04 16:39:47.440416: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165a700 of size 2304 by op Fill action_count 2716826287406 step 0 next 766
2021-08-04 16:39:47.444081: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b000 of size 256 by op Fill action_count 2716826287408 step 0 next 764
2021-08-04 16:39:47.447050: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b100 of size 256 by op Fill action_count 2716826287409 step 0 next 763
2021-08-04 16:39:47.449988: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b200 of size 256 by op Fill action_count 2716826287410 step 0 next 762
2021-08-04 16:39:47.457313: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b300 of size 256 by op Fill action_count 2716826287411 step 0 next 761
2021-08-04 16:39:47.461527: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b400 of size 256 by op Fill action_count 2716826287412 step 0 next 760
2021-08-04 16:39:47.465337: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b500 of size 256 by op Fill action_count 2716826287413 step 0 next 755
2021-08-04 16:39:47.472776: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b600 of size 256 by op Fill action_count 2716826287414 step 0 next 756
2021-08-04 16:39:47.476638: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b700 of size 256 by op Fill action_count 2716826287415 step 0 next 757
2021-08-04 16:39:47.480371: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b800 of size 256 by op Fill action_count 2716826287416 step 0 next 758
2021-08-04 16:39:47.485667: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165b900 of size 256 by op Fill action_count 2716826287417 step 0 next 759
2021-08-04 16:39:47.489414: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165ba00 of size 256 by op Fill action_count 2716826287418 step 0 next 366
2021-08-04 16:39:47.492355: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165bb00 of size 256 by op Fill action_count 2716826287419 step 0 next 367
2021-08-04 16:39:47.495480: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165bc00 of size 256 by op Fill action_count 2716826287420 step 0 next 368
2021-08-04 16:39:47.498484: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165bd00 of size 256 by op Fill action_count 2716826287421 step 0 next 369
2021-08-04 16:39:47.507276: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165be00 of size 256 by op Fill action_count 2716826287422 step 0 next 365
2021-08-04 16:39:47.512362: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165bf00 of size 256 by op Fill action_count 2716826287423 step 0 next 148
2021-08-04 16:39:47.518120: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165c000 of size 2048 by op AssignVariableOp action_count 2716826287096 step 0 next 84
2021-08-04 16:39:47.521355: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165c800 of size 2048 by op AssignVariableOp action_count 2716826287148 step 0 next 154
2021-08-04 16:39:47.524715: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165d000 of size 2048 by op AssignVariableOp action_count 2716826287166 step 0 next 167
2021-08-04 16:39:47.527978: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165d800 of size 2048 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826290117 step 13097390214773393689 next 1948
2021-08-04 16:39:47.537868: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165e000 of size 2048 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826290118 step 13097390214773393689 next 149
2021-08-04 16:39:47.543929: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165e800 of size 2048 by op AssignVariableOp action_count 2716826287174 step 0 next 183
2021-08-04 16:39:47.549124: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165f000 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/project_bn/FusedBatchNormV3 action_count 2716826290148 step 13097390214773393689 next 1955
2021-08-04 16:39:47.554320: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165f200 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_0/project_bn/FusedBatchNormV3 action_count 2716826290149 step 13097390214773393689 next 1956
2021-08-04 16:39:47.559105: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165f400 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/se_reduce_activation/mul action_count 2716826290187 step 13097390214773393689 next 1967
2021-08-04 16:39:47.569351: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165f600 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/project_bn/FusedBatchNormV3 action_count 2716826290199 step 13097390214773393689 next 185
2021-08-04 16:39:47.576067: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0165f800 of size 2816 by op AssignVariableOp action_count 2716826287210 step 0 next 602
2021-08-04 16:39:47.583180: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01660300 of size 6400 by op AssignVariableOp action_count 2716826287246 step 0 next 187
2021-08-04 16:39:47.587485: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01661c00 of size 2048 by op AssignVariableOp action_count 2716826287176 step 0 next 188
2021-08-04 16:39:47.590551: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01662400 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/project_bn/FusedBatchNormV3 action_count 2716826290200 step 13097390214773393689 next 1970
2021-08-04 16:39:47.600452: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01662600 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/project_bn/FusedBatchNormV3 action_count 2716826290201 step 13097390214773393689 next 1971
2021-08-04 16:39:47.606378: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01662800 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/project_bn/FusedBatchNormV3 action_count 2716826290202 step 13097390214773393689 next 1972
2021-08-04 16:39:47.616536: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01662a00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/se_reduce_conv2d/Conv2D action_count 2716826290236 step 13097390214773393689 next 189
2021-08-04 16:39:47.620995: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01662c00 of size 2304 by op AssignVariableOp action_count 2716826287186 step 0 next 191
2021-08-04 16:39:47.625958: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01663500 of size 512 by op AssignVariableOp action_count 2716826287200 step 0 next 146
2021-08-04 16:39:47.628990: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01663700 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/se_reduce_activation/Sigmoid action_count 2716826290241 step 13097390214773393689 next 218
2021-08-04 16:39:47.633616: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01663900 of size 512 by op AssignVariableOp action_count 2716826287278 step 0 next 232
2021-08-04 16:39:47.636859: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01663b00 of size 512 by op AssignVariableOp action_count 2716826287280 step 0 next 194
2021-08-04 16:39:47.642345: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01663d00 of size 256 by op Mul action_count 2716826280255 step 0 next 195
2021-08-04 16:39:47.646385: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01663e00 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/se_reduce_conv2d/Conv2D action_count 2716826290181 step 13097390214773393689 next 198
2021-08-04 16:39:47.652162: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01664000 of size 512 by op AssignVariableOp action_count 2716826287202 step 0 next 199
2021-08-04 16:39:47.660708: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01664200 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/se_reduce_activation/Sigmoid action_count 2716826290186 step 13097390214773393689 next 200
2021-08-04 16:39:47.668840: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01664400 of size 512 by op AssignVariableOp action_count 2716826287238 step 0 next 201
2021-08-04 16:39:47.673940: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01664600 of size 256 by op Mul action_count 2716826280265 step 0 next 203
2021-08-04 16:39:47.678303: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01664700 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826290169 step 13097390214773393689 next 202
2021-08-04 16:39:47.683333: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01665200 of size 4608 by op AssignVariableOp action_count 2716826287212 step 0 next 117
2021-08-04 16:39:47.686297: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01666400 of size 38400 by op AssignVariableOp action_count 2716826287042 step 0 next 118
2021-08-04 16:39:47.693369: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0166fa00 of size 38400 by op AssignVariableOp action_count 2716826287106 step 0 next 123
2021-08-04 16:39:47.696929: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01679000 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_4/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826290170 step 13097390214773393689 next 206
2021-08-04 16:39:47.701323: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01679b00 of size 2816 by op AssignVariableOp action_count 2716826287220 step 0 next 207
2021-08-04 16:39:47.708149: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167a600 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/expand_bn/FusedBatchNormV3 action_count 2716826290213 step 13097390214773393689 next 210
2021-08-04 16:39:47.713756: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167b100 of size 2816 by op AssignVariableOp action_count 2716826287222 step 0 next 211
2021-08-04 16:39:47.720348: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167bc00 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/expand_bn/FusedBatchNormV3 action_count 2716826290214 step 13097390214773393689 next 212
2021-08-04 16:39:47.724521: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167c700 of size 2816 by op AssignVariableOp action_count 2716826287232 step 0 next 213
2021-08-04 16:39:47.727256: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167d200 of size 256 by op Mul action_count 2716826280284 step 0 next 214
2021-08-04 16:39:47.729867: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167d300 of size 3584 by op AssignVariableOp action_count 2716826287250 step 0 next 219
2021-08-04 16:39:47.737934: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167e100 of size 512 by op AssignVariableOp action_count 2716826287240 step 0 next 221
2021-08-04 16:39:47.741309: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167e300 of size 3840 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/depthwise_bn/FusedBatchNormV3 action_count 2716826290225 step 13097390214773393689 next 224
2021-08-04 16:39:47.745466: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167f200 of size 2816 by op AssignVariableOp action_count 2716826287252 step 0 next 226
2021-08-04 16:39:47.748243: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0167fd00 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_4/block_2/depthwise_bn/FusedBatchNormV3 action_count 2716826290224 step 13097390214773393689 next 227
2021-08-04 16:39:47.758642: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01680800 of size 2816 by op AssignVariableOp action_count 2716826287260 step 0 next 228
2021-08-04 16:39:47.767859: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01681300 of size 20736 by op Fill action_count 2716826287394 step 0 next 776
2021-08-04 16:39:47.772299: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01686400 of size 22528 by op Fill action_count 2716826287397 step 0 next 135
2021-08-04 16:39:47.775542: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0168bc00 of size 153600 by op AssignVariableOp action_count 2716826287112 step 0 next 156
2021-08-04 16:39:47.778356: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016b1400 of size 75264 by op AssignVariableOp action_count 2716826287234 step 0 next 215
2021-08-04 16:39:47.784721: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016c3a00 of size 75264 by op AssignVariableOp action_count 2716826287270 step 0 next 217
2021-08-04 16:39:47.789881: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6000 of size 256 by op AssignVariableOp action_count 2716826286366 step 0 next 404
2021-08-04 16:39:47.795577: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290601 step 13097390214773393689 next 405
2021-08-04 16:39:47.802039: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6200 of size 256 by op AssignVariableOp action_count 2716826286372 step 0 next 406
2021-08-04 16:39:47.805254: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6300 of size 256 by op AssignVariableOp action_count 2716826286326 step 0 next 407
2021-08-04 16:39:47.808454: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6400 of size 256 by op AssignVariableOp action_count 2716826286384 step 0 next 420
2021-08-04 16:39:47.813831: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6500 of size 256 by op AssignVariableOp action_count 2716826286328 step 0 next 421
2021-08-04 16:39:47.818529: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6600 of size 256 by op AssignVariableOp action_count 2716826286396 step 0 next 434
2021-08-04 16:39:47.822089: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6700 of size 256 by op AssignVariableOp action_count 2716826286330 step 0 next 435
2021-08-04 16:39:47.824916: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6800 of size 256 by op AssignVariableOp action_count 2716826286408 step 0 next 448
2021-08-04 16:39:47.830183: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6900 of size 256 by op AssignVariableOp action_count 2716826286332 step 0 next 449
2021-08-04 16:39:47.832994: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6a00 of size 256 by op AssignVariableOp action_count 2716826286708 step 0 next 450
2021-08-04 16:39:47.835784: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6b00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_08/1_up_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290856 step 13097390214773393689 next 453
2021-08-04 16:39:47.841481: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6c00 of size 256 by op AssignVariableOp action_count 2716826286710 step 0 next 454
2021-08-04 16:39:47.850060: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6d00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_08/1_up_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290857 step 13097390214773393689 next 455
2021-08-04 16:39:47.857088: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6e00 of size 256 by op AssignVariableOp action_count 2716826286716 step 0 next 456
2021-08-04 16:39:47.864235: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d6f00 of size 256 by op AssignVariableOp action_count 2716826286334 step 0 next 457
2021-08-04 16:39:47.868783: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7000 of size 256 by op AssignVariableOp action_count 2716826286722 step 0 next 460
2021-08-04 16:39:47.872780: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_09/1_up_lvl_7/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290888 step 13097390214773393689 next 395
2021-08-04 16:39:47.880140: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7200 of size 2560 by op AssignVariableOp action_count 2716826286662 step 0 next 411
2021-08-04 16:39:47.883069: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7c00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290760 step 13097390214773393689 next 412
2021-08-04 16:39:47.887396: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7d00 of size 256 by op AssignVariableOp action_count 2716826286668 step 0 next 413
2021-08-04 16:39:47.895364: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7e00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290761 step 13097390214773393689 next 414
2021-08-04 16:39:47.901816: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d7f00 of size 256 by op AssignVariableOp action_count 2716826286674 step 0 next 415
2021-08-04 16:39:47.908308: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8000 of size 256 by op AssignVariableOp action_count 2716826286376 step 0 next 417
2021-08-04 16:39:47.914513: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8100 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/se_reduce_activation/Sigmoid action_count 2716826289972 step 13097390214773393689 next 418
2021-08-04 16:39:47.920356: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8200 of size 256 by op AssignVariableOp action_count 2716826286378 step 0 next 419
2021-08-04 16:39:47.925054: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8300 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_3/block_0/se_reduce_activation/mul action_count 2716826289973 step 13097390214773393689 next 408
2021-08-04 16:39:47.929335: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8400 of size 2560 by op AssignVariableOp action_count 2716826286676 step 0 next 424
2021-08-04 16:39:47.932578: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8e00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290791 step 13097390214773393689 next 425
2021-08-04 16:39:47.941589: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d8f00 of size 256 by op AssignVariableOp action_count 2716826286682 step 0 next 426
2021-08-04 16:39:47.945803: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9000 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290792 step 13097390214773393689 next 427
2021-08-04 16:39:47.955227: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9100 of size 256 by op AssignVariableOp action_count 2716826286688 step 0 next 428
2021-08-04 16:39:47.960308: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9200 of size 256 by op AssignVariableOp action_count 2716826286388 step 0 next 431
2021-08-04 16:39:47.965687: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9300 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290602 step 13097390214773393689 next 432
2021-08-04 16:39:47.975500: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9400 of size 256 by op AssignVariableOp action_count 2716826286390 step 0 next 433
2021-08-04 16:39:47.978581: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9500 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290603 step 13097390214773393689 next 422
2021-08-04 16:39:47.987396: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016d9600 of size 2560 by op AssignVariableOp action_count 2716826286690 step 0 next 375
2021-08-04 16:39:47.991227: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016da000 of size 16384 by op AssignVariableOp action_count 2716826286566 step 0 next 376
2021-08-04 16:39:47.995113: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de000 of size 256 by op AssignVariableOp action_count 2716826286694 step 0 next 439
2021-08-04 16:39:48.002158: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290824 step 13097390214773393689 next 440
2021-08-04 16:39:48.007647: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de200 of size 256 by op AssignVariableOp action_count 2716826286696 step 0 next 441
2021-08-04 16:39:48.010655: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de300 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290825 step 13097390214773393689 next 442
2021-08-04 16:39:48.020129: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de400 of size 256 by op AssignVariableOp action_count 2716826286702 step 0 next 443
2021-08-04 16:39:48.023998: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de500 of size 256 by op AssignVariableOp action_count 2716826286400 step 0 next 444
2021-08-04 16:39:48.029042: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de600 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_00/0_up_lvl_6/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290626 step 13097390214773393689 next 446
2021-08-04 16:39:48.040055: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de700 of size 256 by op AssignVariableOp action_count 2716826286402 step 0 next 447
2021-08-04 16:39:48.045166: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de800 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_00/0_up_lvl_6/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290627 step 13097390214773393689 next 436
2021-08-04 16:39:48.052437: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016de900 of size 2304 by op AssignVariableOp action_count 2716826286704 step 0 next 437
2021-08-04 16:39:48.055711: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df200 of size 256 by op AssignVariableOp action_count 2716826286414 step 0 next 474
2021-08-04 16:39:48.058759: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df300 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_11/2_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290947 step 13097390214773393689 next 475
2021-08-04 16:39:48.068707: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df400 of size 256 by op AssignVariableOp action_count 2716826286416 step 0 next 476
2021-08-04 16:39:48.072643: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df500 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_11/2_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290948 step 13097390214773393689 next 477
2021-08-04 16:39:48.081186: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df600 of size 256 by op AssignVariableOp action_count 2716826286422 step 0 next 478
2021-08-04 16:39:48.086046: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df700 of size 256 by op AssignVariableOp action_count 2716826286292 step 0 next 479
2021-08-04 16:39:48.089916: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df800 of size 256 by op AssignVariableOp action_count 2716826286470 step 0 next 507
2021-08-04 16:39:48.096537: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016df900 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_15/2_up_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291076 step 13097390214773393689 next 508
2021-08-04 16:39:48.103995: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016dfa00 of size 256 by op AssignVariableOp action_count 2716826286472 step 0 next 509
2021-08-04 16:39:48.107849: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016dfb00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_15/2_up_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291077 step 13097390214773393689 next 510
2021-08-04 16:39:48.116040: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016dfc00 of size 256 by op AssignVariableOp action_count 2716826286478 step 0 next 511
2021-08-04 16:39:48.118903: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016dfd00 of size 256 by op AssignVariableOp action_count 2716826286300 step 0 next 512
2021-08-04 16:39:48.121648: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016dfe00 of size 256 by op AssignVariableOp action_count 2716826286484 step 0 next 516
2021-08-04 16:39:48.128697: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016dff00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_16/2_up_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291108 step 13097390214773393689 next 517
2021-08-04 16:39:48.133429: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e0000 of size 256 by op AssignVariableOp action_count 2716826286486 step 0 next 518
2021-08-04 16:39:48.136102: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e0100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_16/2_up_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291109 step 13097390214773393689 next 519
2021-08-04 16:39:48.144937: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e0200 of size 256 by op AssignVariableOp action_count 2716826286492 step 0 next 520
2021-08-04 16:39:48.148726: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e0300 of size 256 by op AssignVariableOp action_count 2716826286302 step 0 next 451
2021-08-04 16:39:48.153159: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e0400 of size 2304 by op AssignVariableOp action_count 2716826286718 step 0 next 452
2021-08-04 16:39:48.159598: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e0d00 of size 3072 by op AssignVariableOp action_count 2716826286732 step 0 next 463
2021-08-04 16:39:48.162873: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1900 of size 256 by op AssignVariableOp action_count 2716826286336 step 0 next 464
2021-08-04 16:39:48.165528: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1a00 of size 256 by op AssignVariableOp action_count 2716826286736 step 0 next 467
2021-08-04 16:39:48.168194: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1b00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_10/2_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290917 step 13097390214773393689 next 468
2021-08-04 16:39:48.177350: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1c00 of size 256 by op AssignVariableOp action_count 2716826286738 step 0 next 469
2021-08-04 16:39:48.182011: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1d00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_10/2_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290918 step 13097390214773393689 next 470
2021-08-04 16:39:48.192298: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1e00 of size 256 by op AssignVariableOp action_count 2716826286746 step 0 next 471
2021-08-04 16:39:48.195557: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e1f00 of size 256 by op AssignVariableOp action_count 2716826286290 step 0 next 394
2021-08-04 16:39:48.198334: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e2000 of size 30720 by op AssignVariableOp action_count 2716826286664 step 0 next 143
2021-08-04 16:39:48.201140: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c016e9800 of size 153600 by op AssignVariableOp action_count 2716826287122 step 0 next 144
2021-08-04 16:39:48.208372: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0170f000 of size 38400 by op AssignVariableOp action_count 2716826287150 step 0 next 173
2021-08-04 16:39:48.211815: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01718600 of size 38400 by op AssignVariableOp action_count 2716826287184 step 0 next 175
2021-08-04 16:39:48.214558: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01721c00 of size 38400 by op AssignVariableOp action_count 2716826287188 step 0 next 192
2021-08-04 16:39:48.217278: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172b200 of size 2816 by op AssignVariableOp action_count 2716826287262 step 0 next 229
2021-08-04 16:39:48.224323: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172bd00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290290 step 13097390214773393689 next 1988
2021-08-04 16:39:48.231650: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172be00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290291 step 13097390214773393689 next 235
2021-08-04 16:39:48.241985: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172bf00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290292 step 13097390214773393689 next 1986
2021-08-04 16:39:48.253439: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172c000 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/input_0_up_lvl_4/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290293 step 13097390214773393689 next 1990
2021-08-04 16:39:48.260996: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172c100 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/se_reduce_conv2d/Conv2D action_count 2716826290324 step 13097390214773393689 next 2000
2021-08-04 16:39:48.269629: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172c300 of size 512 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/se_reduce_activation/Sigmoid action_count 2716826290329 step 13097390214773393689 next 2001
2021-08-04 16:39:48.278570: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172c500 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/se_reduce_activation/mul action_count 2716826290330 step 13097390214773393689 next 230
2021-08-04 16:39:48.287881: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172c800 of size 3072 by op AssignVariableOp action_count 2716826287272 step 0 next 233
2021-08-04 16:39:48.290805: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172d400 of size 4864 by op AssignVariableOp action_count 2716826287288 step 0 next 241
2021-08-04 16:39:48.293560: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172e700 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826290314 step 13097390214773393689 next 243
2021-08-04 16:39:48.303458: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172f200 of size 2816 by op AssignVariableOp action_count 2716826287290 step 0 next 244
2021-08-04 16:39:48.307689: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0172fd00 of size 2816 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826290315 step 13097390214773393689 next 245
2021-08-04 16:39:48.315237: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01730800 of size 2816 by op AssignVariableOp action_count 2716826287306 step 0 next 246
2021-08-04 16:39:48.319704: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01731300 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/project_bn/FusedBatchNormV3 action_count 2716826290343 step 13097390214773393689 next 2004
2021-08-04 16:39:48.325727: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01731600 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/project_bn/FusedBatchNormV3 action_count 2716826290344 step 13097390214773393689 next 2005
2021-08-04 16:39:48.331947: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01731900 of size 1280 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/project_bn/FusedBatchNormV3 action_count 2716826290345 step 13097390214773393689 next 247
2021-08-04 16:39:48.336225: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01731e00 of size 2816 by op AssignVariableOp action_count 2716826287308 step 0 next 248
2021-08-04 16:39:48.339109: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01732900 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_0/project_bn/FusedBatchNormV3 action_count 2716826290346 step 13097390214773393689 next 2006
2021-08-04 16:39:48.349706: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01732c00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/se_reduce_activation/mul action_count 2716826290384 step 13097390214773393689 next 2016
2021-08-04 16:39:48.357208: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01732f00 of size 1280 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/project_bn/FusedBatchNormV3 action_count 2716826290398 step 13097390214773393689 next 249
2021-08-04 16:39:48.366039: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01733400 of size 5120 by op AssignVariableOp action_count 2716826287318 step 0 next 157
2021-08-04 16:39:48.369319: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01734800 of size 17408 by op AssignVariableOp action_count 2716826287132 step 0 next 162
2021-08-04 16:39:48.372276: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01738c00 of size 38400 by op AssignVariableOp action_count 2716826287146 step 0 next 161
2021-08-04 16:39:48.378989: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01742200 of size 251392 by op AssignVariableOp action_count 2716826287152 step 0 next 163
2021-08-04 16:39:48.382060: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0177f800 of size 75264 by op AssignVariableOp action_count 2716826287316 step 0 next 197
2021-08-04 16:39:48.384988: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01791e00 of size 256 by op Fill action_count 2716826287442 step 0 next 893
2021-08-04 16:39:48.387717: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01791f00 of size 256 by op Fill action_count 2716826287443 step 0 next 908
2021-08-04 16:39:48.395448: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01792000 of size 256 by op Fill action_count 2716826287444 step 0 next 826
2021-08-04 16:39:48.399397: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01792100 of size 2304 by op Fill action_count 2716826287445 step 0 next 901
2021-08-04 16:39:48.403271: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01792a00 of size 16384 by op Fill action_count 2716826287446 step 0 next 998
2021-08-04 16:39:48.412443: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01796a00 of size 256 by op Fill action_count 2716826287447 step 0 next 829
2021-08-04 16:39:48.415601: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01796b00 of size 256 by op Fill action_count 2716826287448 step 0 next 819
2021-08-04 16:39:48.418506: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01796c00 of size 256 by op Fill action_count 2716826287449 step 0 next 827
2021-08-04 16:39:48.423179: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01796d00 of size 256 by op Fill action_count 2716826287450 step 0 next 909
2021-08-04 16:39:48.426227: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01796e00 of size 256 by op Fill action_count 2716826287451 step 0 next 986
2021-08-04 16:39:48.429174: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01796f00 of size 256 by op Fill action_count 2716826287452 step 0 next 987
2021-08-04 16:39:48.432824: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797000 of size 256 by op Fill action_count 2716826287453 step 0 next 918
2021-08-04 16:39:48.439569: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797100 of size 256 by op Fill action_count 2716826287454 step 0 next 985
2021-08-04 16:39:48.446198: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797200 of size 256 by op Fill action_count 2716826287455 step 0 next 825
2021-08-04 16:39:48.450588: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797300 of size 256 by op Fill action_count 2716826287456 step 0 next 806
2021-08-04 16:39:48.458960: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797400 of size 256 by op Fill action_count 2716826287457 step 0 next 983
2021-08-04 16:39:48.463398: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797500 of size 256 by op Fill action_count 2716826287458 step 0 next 915
2021-08-04 16:39:48.467153: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797600 of size 256 by op Fill action_count 2716826287459 step 0 next 913
2021-08-04 16:39:48.473623: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797700 of size 256 by op Fill action_count 2716826287460 step 0 next 835
2021-08-04 16:39:48.476747: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797800 of size 256 by op Fill action_count 2716826287461 step 0 next 821
2021-08-04 16:39:48.479627: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797900 of size 256 by op Fill action_count 2716826287462 step 0 next 828
2021-08-04 16:39:48.482322: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797a00 of size 256 by op Fill action_count 2716826287463 step 0 next 973
2021-08-04 16:39:48.489196: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797b00 of size 256 by op Fill action_count 2716826287464 step 0 next 837
2021-08-04 16:39:48.492629: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797c00 of size 256 by op Fill action_count 2716826287465 step 0 next 810
2021-08-04 16:39:48.495334: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797d00 of size 256 by op Fill action_count 2716826287466 step 0 next 836
2021-08-04 16:39:48.498096: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797e00 of size 256 by op Fill action_count 2716826287467 step 0 next 995
2021-08-04 16:39:48.505754: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01797f00 of size 256 by op Fill action_count 2716826287468 step 0 next 818
2021-08-04 16:39:48.511625: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01798000 of size 256 by op Fill action_count 2716826287469 step 0 next 820
2021-08-04 16:39:48.518415: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01798100 of size 256 by op Fill action_count 2716826287470 step 0 next 1023
2021-08-04 16:39:48.522538: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01798200 of size 256 by op Fill action_count 2716826287471 step 0 next 907
2021-08-04 16:39:48.525298: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01798300 of size 256 by op Fill action_count 2716826287472 step 0 next 882
2021-08-04 16:39:48.527981: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01798400 of size 256 by op Fill action_count 2716826287473 step 0 next 902
2021-08-04 16:39:48.533979: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01798500 of size 3584 by op Fill action_count 2716826287474 step 0 next 832
2021-08-04 16:39:48.539972: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01799300 of size 256 by op Fill action_count 2716826287475 step 0 next 900
2021-08-04 16:39:48.544082: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01799400 of size 256 by op Fill action_count 2716826287476 step 0 next 897
2021-08-04 16:39:48.551965: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01799500 of size 1280 by op Fill action_count 2716826287477 step 0 next 896
2021-08-04 16:39:48.555007: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01799a00 of size 256 by op Fill action_count 2716826287478 step 0 next 977
2021-08-04 16:39:48.558104: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01799b00 of size 256 by op Fill action_count 2716826287479 step 0 next 824
2021-08-04 16:39:48.563426: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01799c00 of size 1024 by op Fill action_count 2716826287480 step 0 next 884
2021-08-04 16:39:48.566728: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179a000 of size 256 by op Fill action_count 2716826287481 step 0 next 831
2021-08-04 16:39:48.569443: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179a100 of size 1024 by op Fill action_count 2716826287482 step 0 next 823
2021-08-04 16:39:48.572466: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179a500 of size 256 by op Fill action_count 2716826287483 step 0 next 863
2021-08-04 16:39:48.575327: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179a600 of size 2048 by op Fill action_count 2716826287484 step 0 next 894
2021-08-04 16:39:48.583081: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179ae00 of size 256 by op Fill action_count 2716826287485 step 0 next 976
2021-08-04 16:39:48.587836: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179af00 of size 256 by op Fill action_count 2716826287486 step 0 next 888
2021-08-04 16:39:48.596022: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179b000 of size 6144 by op Fill action_count 2716826287487 step 0 next 916
2021-08-04 16:39:48.599794: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179c800 of size 512 by op Fill action_count 2716826287488 step 0 next 881
2021-08-04 16:39:48.603730: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179ca00 of size 512 by op Fill action_count 2716826287489 step 0 next 804
2021-08-04 16:39:48.606447: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179cc00 of size 3584 by op Fill action_count 2716826287490 step 0 next 850
2021-08-04 16:39:48.613968: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179da00 of size 512 by op Fill action_count 2716826287491 step 0 next 789
2021-08-04 16:39:48.616619: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179dc00 of size 512 by op Fill action_count 2716826287492 step 0 next 1069
2021-08-04 16:39:48.619291: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179de00 of size 1536 by op Fill action_count 2716826287493 step 0 next 853
2021-08-04 16:39:48.621879: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179e400 of size 256 by op Fill action_count 2716826287494 step 0 next 861
2021-08-04 16:39:48.629156: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179e500 of size 1536 by op Fill action_count 2716826287495 step 0 next 910
2021-08-04 16:39:48.633716: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179eb00 of size 512 by op Fill action_count 2716826287496 step 0 next 834
2021-08-04 16:39:48.636939: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0179ed00 of size 9216 by op Fill action_count 2716826287497 step 0 next 842
2021-08-04 16:39:48.644394: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017a1100 of size 256 by op Fill action_count 2716826287498 step 0 next 802
2021-08-04 16:39:48.648124: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017a1200 of size 256 by op Fill action_count 2716826287499 step 0 next 996
2021-08-04 16:39:48.651572: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017a1300 of size 15616 by op Fill action_count 2716826287500 step 0 next 176
2021-08-04 16:39:48.658538: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017a5000 of size 153600 by op AssignVariableOp action_count 2716826287162 step 0 next 177
2021-08-04 16:39:48.662885: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017ca800 of size 48128 by op AssignVariableOp action_count 2716826287172 step 0 next 184
2021-08-04 16:39:48.666059: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017d6400 of size 105472 by op AssignVariableOp action_count 2716826287218 step 0 next 182
2021-08-04 16:39:48.668919: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f0000 of size 256 by op Cast action_count 2716826287386 step 0 next 779
2021-08-04 16:39:48.673397: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f0100 of size 256 by op AssignVariableOp action_count 2716826287389 step 0 next 778
2021-08-04 16:39:48.676268: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f0200 of size 2560 by op Fill action_count 2716826287390 step 0 next 254
2021-08-04 16:39:48.678872: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f0c00 of size 256 by op Mul action_count 2716826280375 step 0 next 256
2021-08-04 16:39:48.682128: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f0d00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/se_reduce_conv2d/Conv2D action_count 2716826290378 step 13097390214773393689 next 255
2021-08-04 16:39:48.693634: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1000 of size 768 by op AssignVariableOp action_count 2716826287326 step 0 next 259
2021-08-04 16:39:48.697670: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1300 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/se_reduce_activation/Sigmoid action_count 2716826290383 step 13097390214773393689 next 260
2021-08-04 16:39:48.705020: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1600 of size 256 by op AssignAddVariableOp action_count 2716826287371 step 0 next 354
2021-08-04 16:39:48.708158: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1700 of size 256 by op AssignAddVariableOp action_count 2716826287372 step 0 next 353
2021-08-04 16:39:48.710980: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1800 of size 256 by op Cast action_count 2716826287383 step 0 next 261
2021-08-04 16:39:48.713576: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1900 of size 256 by op Mul action_count 2716826280385 step 0 next 262
2021-08-04 16:39:48.716155: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f1a00 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826290368 step 13097390214773393689 next 265
2021-08-04 16:39:48.724944: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f2c00 of size 4608 by op AssignVariableOp action_count 2716826287336 step 0 next 266
2021-08-04 16:39:48.728454: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f3e00 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/depthwise_bn/FusedBatchNormV3 action_count 2716826290369 step 13097390214773393689 next 267
2021-08-04 16:39:48.732698: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f5000 of size 4608 by op AssignVariableOp action_count 2716826287344 step 0 next 268
2021-08-04 16:39:48.739654: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f6200 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/project_bn/FusedBatchNormV3 action_count 2716826290399 step 13097390214773393689 next 2019
2021-08-04 16:39:48.747009: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f6500 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/project_bn/FusedBatchNormV3 action_count 2716826290400 step 13097390214773393689 next 2020
2021-08-04 16:39:48.755367: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f6800 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_1/project_bn/FusedBatchNormV3 action_count 2716826290401 step 13097390214773393689 next 2021
2021-08-04 16:39:48.759576: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f6b00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/se_reduce_activation/Sigmoid action_count 2716826290441 step 13097390214773393689 next 2029
2021-08-04 16:39:48.763724: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f6e00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/se_reduce_activation/mul action_count 2716826290442 step 13097390214773393689 next 2031
2021-08-04 16:39:48.772800: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f7100 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/project_bn/FusedBatchNormV3 action_count 2716826290457 step 13097390214773393689 next 269
2021-08-04 16:39:48.777147: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f7400 of size 4608 by op AssignVariableOp action_count 2716826287346 step 0 next 271
2021-08-04 16:39:48.782266: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f8600 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/expand_bn/FusedBatchNormV3 action_count 2716826290412 step 13097390214773393689 next 272
2021-08-04 16:39:48.789936: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017f9800 of size 4608 by op AssignVariableOp action_count 2716826287362 step 0 next 273
2021-08-04 16:39:48.793312: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017faa00 of size 256 by op Mul action_count 2716826280404 step 0 next 274
2021-08-04 16:39:48.798438: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017fab00 of size 5632 by op AssignVariableOp action_count 2716826286776 step 0 next 282
2021-08-04 16:39:48.801884: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017fc100 of size 768 by op AssignVariableOp action_count 2716826286768 step 0 next 283
2021-08-04 16:39:48.804623: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017fc400 of size 6144 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/depthwise_bn/FusedBatchNormV3 action_count 2716826290425 step 13097390214773393689 next 287
2021-08-04 16:39:48.808838: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017fdc00 of size 4608 by op AssignVariableOp action_count 2716826286778 step 0 next 288
2021-08-04 16:39:48.817331: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017fee00 of size 768 by op AssignVariableOp action_count 2716826286850 step 0 next 286
2021-08-04 16:39:48.822538: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017ff100 of size 1536 by op AssignVariableOp action_count 2716826286860 step 0 next 314
2021-08-04 16:39:48.828684: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017ff700 of size 1536 by op AssignVariableOp action_count 2716826286902 step 0 next 313
2021-08-04 16:39:48.832816: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017ffd00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/project_bn/FusedBatchNormV3 action_count 2716826289809 step 13097390214773393689 next 1868
2021-08-04 16:39:48.840522: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017ffe00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/project_bn/FusedBatchNormV3 action_count 2716826289810 step 13097390214773393689 next 1869
2021-08-04 16:39:48.850544: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c017fff00 of size 256 by op while/body/_1/EfficientDet-D0/model/stack_1/block_1/project_bn/FusedBatchNormV3 action_count 2716826289811 step 13097390214773393689 next 1870
2021-08-04 16:39:48.855463: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01800000 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_2/block_0/expand_bn/FusedBatchNormV3 action_count 2716826289822 step 13097390214773393689 next 63
2021-08-04 16:39:48.864352: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01800300 of size 1024 by op AssignVariableOp action_count 2716826286940 step 0 next 208
2021-08-04 16:39:48.868929: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01800700 of size 67328 by op AssignVariableOp action_count 2716826287258 step 0 next 209
2021-08-04 16:39:48.873104: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01810e00 of size 80384 by op AssignVariableOp action_count 2716826287274 step 0 next 196
2021-08-04 16:39:48.879396: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01824800 of size 75264 by op AssignVariableOp action_count 2716826287230 step 0 next 783
2021-08-04 16:39:48.883682: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01836e00 of size 67328 by op AssignVariableOp action_count 2716826287304 step 0 next 238
2021-08-04 16:39:48.886429: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01847500 of size 222976 by op AssignVariableOp action_count 2716826287342 step 0 next 234
2021-08-04 16:39:48.893634: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0187dc00 of size 115200 by op AssignVariableOp action_count 2716826286830 step 0 next 290
2021-08-04 16:39:48.896907: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01899e00 of size 9216 by op AssignVariableOp action_count 2716826286904 step 0 next 305
2021-08-04 16:39:48.900400: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0189c200 of size 13824 by op AssignVariableOp action_count 2716826286914 step 0 next 54
2021-08-04 16:39:48.903200: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0189f800 of size 18432 by op AssignVariableOp action_count 2716826286944 step 0 next 328
2021-08-04 16:39:48.908571: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018a4000 of size 256 by op Sub action_count 2716826280554 step 0 next 351
2021-08-04 16:39:48.912861: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018a4100 of size 256 by op Sub action_count 2716826280555 step 0 next 352
2021-08-04 16:39:48.916398: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018a4200 of size 256 by op Fill action_count 2716826287392 step 0 next 777
2021-08-04 16:39:48.920403: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018a4300 of size 3840 by op Fill action_count 2716826287393 step 0 next 350
2021-08-04 16:39:48.928020: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018a5200 of size 256 by op Mul action_count 2716826280633 step 0 next 355
2021-08-04 16:39:48.931656: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018a5300 of size 38912 by op AssignVariableOp action_count 2716826286362 step 0 next 382
2021-08-04 16:39:48.935342: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018aeb00 of size 256 by op AssignVariableOp action_count 2716826286342 step 0 next 381
2021-08-04 16:39:48.944504: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018aec00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_02/1_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290667 step 13097390214773393689 next 380
2021-08-04 16:39:48.950891: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018aed00 of size 2304 by op AssignVariableOp action_count 2716826286410 step 0 next 601
2021-08-04 16:39:48.957324: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018af600 of size 3328 by op AssignVariableOp action_count 2716826286438 step 0 next 371
2021-08-04 16:39:48.960728: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0300 of size 256 by op AssignVariableOp action_count 2716826286554 step 0 next 372
2021-08-04 16:39:48.964216: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0400 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290698 step 13097390214773393689 next 374
2021-08-04 16:39:48.973459: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0500 of size 256 by op AssignVariableOp action_count 2716826286556 step 0 next 373
2021-08-04 16:39:48.976648: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0600 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290699 step 13097390214773393689 next 385
2021-08-04 16:39:48.981676: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0700 of size 256 by op AssignVariableOp action_count 2716826286562 step 0 next 386
2021-08-04 16:39:48.989174: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0800 of size 256 by op AssignVariableOp action_count 2716826286352 step 0 next 388
2021-08-04 16:39:48.994015: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0900 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290616 step 13097390214773393689 next 389
2021-08-04 16:39:49.007484: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0a00 of size 256 by op AssignVariableOp action_count 2716826286354 step 0 next 390
2021-08-04 16:39:49.010602: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0b00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290617 step 13097390214773393689 next 391
2021-08-04 16:39:49.019411: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0c00 of size 256 by op AssignVariableOp action_count 2716826286360 step 0 next 392
2021-08-04 16:39:49.023663: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0d00 of size 256 by op AssignVariableOp action_count 2716826286324 step 0 next 393
2021-08-04 16:39:49.032356: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0e00 of size 256 by op AssignVariableOp action_count 2716826286652 step 0 next 397
2021-08-04 16:39:49.037316: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b0f00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290728 step 13097390214773393689 next 398
2021-08-04 16:39:49.043079: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1000 of size 256 by op AssignVariableOp action_count 2716826286654 step 0 next 399
2021-08-04 16:39:49.049981: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290729 step 13097390214773393689 next 400
2021-08-04 16:39:49.056482: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1200 of size 256 by op AssignVariableOp action_count 2716826286660 step 0 next 401
2021-08-04 16:39:49.059745: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1300 of size 256 by op AssignVariableOp action_count 2716826286364 step 0 next 402
2021-08-04 16:39:49.066268: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1400 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290604 step 13097390214773393689 next 378
2021-08-04 16:39:49.071651: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1500 of size 2304 by op AssignVariableOp action_count 2716826286564 step 0 next 377
2021-08-04 16:39:49.074853: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b1e00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/se_reduce_conv2d/Conv2D action_count 2716826290436 step 13097390214773393689 next 279
2021-08-04 16:39:49.084087: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b2100 of size 256 by op AssignVariableOp action_count 2716826286794 step 0 next 285
2021-08-04 16:39:49.088636: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b2200 of size 512 by op AssignVariableOp action_count 2716826286802 step 0 next 277
2021-08-04 16:39:49.092027: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b2400 of size 768 by op AssignVariableOp action_count 2716826286812 step 0 next 466
2021-08-04 16:39:49.098402: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b2700 of size 2560 by op AssignVariableOp action_count 2716826286424 step 0 next 483
2021-08-04 16:39:49.101375: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_12/2_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290979 step 13097390214773393689 next 484
2021-08-04 16:39:49.105870: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3200 of size 256 by op AssignVariableOp action_count 2716826286430 step 0 next 485
2021-08-04 16:39:49.111150: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3300 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_12/2_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290980 step 13097390214773393689 next 486
2021-08-04 16:39:49.118676: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3400 of size 256 by op AssignVariableOp action_count 2716826286436 step 0 next 487
2021-08-04 16:39:49.122081: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3500 of size 256 by op AssignVariableOp action_count 2716826286294 step 0 next 488
2021-08-04 16:39:49.128987: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3600 of size 256 by op AssignVariableOp action_count 2716826286442 step 0 next 492
2021-08-04 16:39:49.133196: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3700 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_13/2_dn_lvl_3/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291010 step 13097390214773393689 next 493
2021-08-04 16:39:49.142873: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3800 of size 256 by op AssignVariableOp action_count 2716826286444 step 0 next 480
2021-08-04 16:39:49.147052: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3900 of size 256 by op AssignVariableOp action_count 2716826286428 step 0 next 473
2021-08-04 16:39:49.150579: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3a00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_13/2_dn_lvl_3/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291011 step 13097390214773393689 next 481
2021-08-04 16:39:49.161640: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3b00 of size 256 by op AssignVariableOp action_count 2716826286450 step 0 next 494
2021-08-04 16:39:49.165825: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3c00 of size 256 by op AssignVariableOp action_count 2716826286666 step 0 next 410
2021-08-04 16:39:49.173301: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3d00 of size 256 by op AssignVariableOp action_count 2716826286680 step 0 next 409
2021-08-04 16:39:49.176322: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3e00 of size 256 by op AssignVariableOp action_count 2716826286724 step 0 next 459
2021-08-04 16:39:49.179232: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b3f00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_09/1_up_lvl_7/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290889 step 13097390214773393689 next 461
2021-08-04 16:39:49.184238: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4000 of size 256 by op AssignVariableOp action_count 2716826286730 step 0 next 462
2021-08-04 16:39:49.189419: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4100 of size 768 by op AssignVariableOp action_count 2716826286766 step 0 next 495
2021-08-04 16:39:49.194422: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4400 of size 256 by op AssignVariableOp action_count 2716826286296 step 0 next 496
2021-08-04 16:39:49.198362: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4500 of size 256 by op AssignVariableOp action_count 2716826286456 step 0 next 500
2021-08-04 16:39:49.204928: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4600 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_14/2_up_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291040 step 13097390214773393689 next 501
2021-08-04 16:39:49.214049: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4700 of size 256 by op AssignVariableOp action_count 2716826286458 step 0 next 502
2021-08-04 16:39:49.220477: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4800 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_14/2_up_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826291041 step 13097390214773393689 next 503
2021-08-04 16:39:49.228422: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4900 of size 256 by op AssignVariableOp action_count 2716826286464 step 0 next 504
2021-08-04 16:39:49.231642: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4a00 of size 256 by op AssignVariableOp action_count 2716826286298 step 0 next 489
2021-08-04 16:39:49.240025: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b4b00 of size 2304 by op AssignVariableOp action_count 2716826286452 step 0 next 490
2021-08-04 16:39:49.244058: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5400 of size 256 by op Sub action_count 2716826281147 step 0 next 628
2021-08-04 16:39:49.247827: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5500 of size 256 by op Sub action_count 2716826281148 step 0 next 629
2021-08-04 16:39:49.255179: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5600 of size 256 by op Fill action_count 2716826281195 step 0 next 645
2021-08-04 16:39:49.259803: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5700 of size 256 by op Fill action_count 2716826281196 step 0 next 646
2021-08-04 16:39:49.263610: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5800 of size 256 by op Fill action_count 2716826281197 step 0 next 647
2021-08-04 16:39:49.269871: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5900 of size 256 by op Fill action_count 2716826281198 step 0 next 648
2021-08-04 16:39:49.274838: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5a00 of size 256 by op Fill action_count 2716826281211 step 0 next 651
2021-08-04 16:39:49.279174: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5b00 of size 256 by op Fill action_count 2716826281212 step 0 next 652
2021-08-04 16:39:49.288386: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5c00 of size 256 by op Fill action_count 2716826281213 step 0 next 653
2021-08-04 16:39:49.291503: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5d00 of size 256 by op Fill action_count 2716826281214 step 0 next 654
2021-08-04 16:39:49.294293: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5e00 of size 256 by op Fill action_count 2716826281215 step 0 next 655
2021-08-04 16:39:49.300754: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b5f00 of size 256 by op Sub action_count 2716826281224 step 0 next 270
2021-08-04 16:39:49.305267: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b6000 of size 768 by op Fill action_count 2716826287501 step 0 next 811
2021-08-04 16:39:49.309758: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b6300 of size 768 by op Fill action_count 2716826287502 step 0 next 812
2021-08-04 16:39:49.317594: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b6600 of size 5376 by op Fill action_count 2716826287503 step 0 next 807
2021-08-04 16:39:49.321743: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b7b00 of size 768 by op Fill action_count 2716826287504 step 0 next 800
2021-08-04 16:39:49.324990: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b7e00 of size 768 by op Fill action_count 2716826287505 step 0 next 980
2021-08-04 16:39:49.331818: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b8100 of size 3584 by op Fill action_count 2716826287506 step 0 next 911
2021-08-04 16:39:49.336825: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b8f00 of size 256 by op Fill action_count 2716826287507 step 0 next 982
2021-08-04 16:39:49.342086: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b9000 of size 3584 by op Fill action_count 2716826287508 step 0 next 914
2021-08-04 16:39:49.347658: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018b9e00 of size 768 by op Fill action_count 2716826287509 step 0 next 864
2021-08-04 16:39:49.350972: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018ba100 of size 13824 by op Fill action_count 2716826287510 step 0 next 805
2021-08-04 16:39:49.353720: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018bd700 of size 256 by op Fill action_count 2716826287511 step 0 next 968
2021-08-04 16:39:49.356437: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018bd800 of size 256 by op Fill action_count 2716826287512 step 0 next 1068
2021-08-04 16:39:49.364120: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018bd900 of size 13824 by op Fill action_count 2716826287513 step 0 next 984
2021-08-04 16:39:49.368470: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c0f00 of size 768 by op Fill action_count 2716826287514 step 0 next 1066
2021-08-04 16:39:49.371623: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c1200 of size 768 by op Fill action_count 2716826287515 step 0 next 972
2021-08-04 16:39:49.377015: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c1500 of size 14592 by op Fill action_count 2716826287516 step 0 next 912
2021-08-04 16:39:49.379808: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c4e00 of size 768 by op Fill action_count 2716826287517 step 0 next 975
2021-08-04 16:39:49.382820: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c5100 of size 768 by op Fill action_count 2716826287518 step 0 next 969
2021-08-04 16:39:49.385811: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c5400 of size 3584 by op Fill action_count 2716826287519 step 0 next 979
2021-08-04 16:39:49.388899: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c6200 of size 256 by op Fill action_count 2716826287520 step 0 next 964
2021-08-04 16:39:49.397679: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c6300 of size 3584 by op Fill action_count 2716826287521 step 0 next 785
2021-08-04 16:39:49.402143: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c7100 of size 768 by op Fill action_count 2716826287522 step 0 next 787
2021-08-04 16:39:49.408657: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018c7400 of size 23040 by op Fill action_count 2716826287523 step 0 next 1020
2021-08-04 16:39:49.413457: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018cce00 of size 256 by op Fill action_count 2716826287524 step 0 next 1067
2021-08-04 16:39:49.419303: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018ccf00 of size 256 by op Fill action_count 2716826287525 step 0 next 1065
2021-08-04 16:39:49.424746: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018cd000 of size 38400 by op Fill action_count 2716826287526 step 0 next 965
2021-08-04 16:39:49.427945: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018d6600 of size 1024 by op Fill action_count 2716826287527 step 0 next 813
2021-08-04 16:39:49.430866: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018d6a00 of size 1024 by op Fill action_count 2716826287528 step 0 next 971
2021-08-04 16:39:49.433602: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018d6e00 of size 24064 by op Fill action_count 2716826287529 step 0 next 967
2021-08-04 16:39:49.439529: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018dcc00 of size 1024 by op Fill action_count 2716826287530 step 0 next 1027
2021-08-04 16:39:49.443904: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018dd000 of size 1024 by op Fill action_count 2716826287531 step 0 next 814
2021-08-04 16:39:49.448147: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018dd400 of size 9728 by op Fill action_count 2716826287532 step 0 next 798
2021-08-04 16:39:49.451650: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018dfa00 of size 256 by op Fill action_count 2716826287533 step 0 next 966
2021-08-04 16:39:49.457319: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018dfb00 of size 9728 by op Fill action_count 2716826287534 step 0 next 1026
2021-08-04 16:39:49.460441: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018e2100 of size 1024 by op Fill action_count 2716826287535 step 0 next 981
2021-08-04 16:39:49.463160: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018e2500 of size 39680 by op Fill action_count 2716826287536 step 0 next 204
2021-08-04 16:39:49.465964: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c018ec000 of size 301056 by op AssignVariableOp action_count 2716826287236 step 0 next 205
2021-08-04 16:39:49.473220: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01935800 of size 301056 by op AssignVariableOp action_count 2716826287248 step 0 next 220
2021-08-04 16:39:49.476637: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c0197f000 of size 301056 by op AssignVariableOp action_count 2716826287276 step 0 next 225
2021-08-04 16:39:49.479525: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019c8800 of size 4608 by op AssignVariableOp action_count 2716826286786 step 0 next 289
2021-08-04 16:39:49.482328: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019c9a00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/project_bn/FusedBatchNormV3 action_count 2716826290458 step 13097390214773393689 next 2035
2021-08-04 16:39:49.491725: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019c9d00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/project_bn/FusedBatchNormV3 action_count 2716826290459 step 13097390214773393689 next 2036
2021-08-04 16:39:49.498549: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ca000 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_2/project_bn/FusedBatchNormV3 action_count 2716826290460 step 13097390214773393689 next 2037
2021-08-04 16:39:49.505498: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ca300 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/se_reduce_activation/Sigmoid action_count 2716826290503 step 13097390214773393689 next 2046
2021-08-04 16:39:49.510153: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ca600 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/se_reduce_activation/mul action_count 2716826290504 step 13097390214773393689 next 2048
2021-08-04 16:39:49.514235: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ca900 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/project_bn/FusedBatchNormV3 action_count 2716826290519 step 13097390214773393689 next 291
2021-08-04 16:39:49.524416: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019cac00 of size 4608 by op AssignVariableOp action_count 2716826286788 step 0 next 292
2021-08-04 16:39:49.527536: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019cbe00 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/expand_bn/FusedBatchNormV3 action_count 2716826290474 step 13097390214773393689 next 293
2021-08-04 16:39:49.537571: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019cd000 of size 4864 by op AssignVariableOp action_count 2716826286798 step 0 next 296
2021-08-04 16:39:49.540679: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ce300 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/se_reduce_conv2d/Conv2D action_count 2716826290498 step 13097390214773393689 next 298
2021-08-04 16:39:49.548279: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ce600 of size 4608 by op AssignVariableOp action_count 2716826286822 step 0 next 301
2021-08-04 16:39:49.551311: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019cf800 of size 768 by op AssignVariableOp action_count 2716826286814 step 0 next 302
2021-08-04 16:39:49.554443: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019cfb00 of size 6144 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/depthwise_bn/FusedBatchNormV3 action_count 2716826290488 step 13097390214773393689 next 306
2021-08-04 16:39:49.559323: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d1300 of size 4608 by op AssignVariableOp action_count 2716826286824 step 0 next 307
2021-08-04 16:39:49.567280: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d2500 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/depthwise_bn/FusedBatchNormV3 action_count 2716826290487 step 13097390214773393689 next 308
2021-08-04 16:39:49.574171: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d3700 of size 4608 by op AssignVariableOp action_count 2716826286832 step 0 next 309
2021-08-04 16:39:49.580055: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d4900 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/project_bn/FusedBatchNormV3 action_count 2716826290520 step 13097390214773393689 next 2054
2021-08-04 16:39:49.586624: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d4c00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/project_bn/FusedBatchNormV3 action_count 2716826290521 step 13097390214773393689 next 2055
2021-08-04 16:39:49.599237: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d4f00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_5/block_3/project_bn/FusedBatchNormV3 action_count 2716826290522 step 13097390214773393689 next 2056
2021-08-04 16:39:49.604041: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d5200 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/se_reduce_activation/Sigmoid action_count 2716826290563 step 13097390214773393689 next 2066
2021-08-04 16:39:49.611109: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d5500 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/se_reduce_activation/mul action_count 2716826290564 step 13097390214773393689 next 2068
2021-08-04 16:39:49.620699: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d5800 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290618 step 13097390214773393689 next 2077
2021-08-04 16:39:49.631529: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d5900 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290619 step 13097390214773393689 next 2079
2021-08-04 16:39:49.637158: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d5a00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_00/0_up_lvl_6/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290628 step 13097390214773393689 next 310
2021-08-04 16:39:49.645546: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d5b00 of size 4608 by op AssignVariableOp action_count 2716826286834 step 0 next 311
2021-08-04 16:39:49.648324: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d6d00 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/expand_bn/FusedBatchNormV3 action_count 2716826290534 step 13097390214773393689 next 312
2021-08-04 16:39:49.653488: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d7f00 of size 4864 by op AssignVariableOp action_count 2716826286844 step 0 next 315
2021-08-04 16:39:49.661833: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019d9200 of size 7168 by op AssignVariableOp action_count 2716826286864 step 0 next 250
2021-08-04 16:39:49.664732: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019dae00 of size 75264 by op AssignVariableOp action_count 2716826287320 step 0 next 251
2021-08-04 16:39:49.667509: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ed400 of size 16384 by op Fill action_count 2716826287402 step 0 next 770
2021-08-04 16:39:49.670132: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f1400 of size 16384 by op Fill action_count 2716826287407 step 0 next 765
2021-08-04 16:39:49.677616: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5400 of size 256 by op Fill action_count 2716826287424 step 0 next 359
2021-08-04 16:39:49.683936: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5500 of size 256 by op Fill action_count 2716826287425 step 0 next 360
2021-08-04 16:39:49.690112: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5600 of size 256 by op Fill action_count 2716826287426 step 0 next 362
2021-08-04 16:39:49.693551: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5700 of size 256 by op Fill action_count 2716826287427 step 0 next 363
2021-08-04 16:39:49.696144: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5800 of size 256 by op Fill action_count 2716826287428 step 0 next 361
2021-08-04 16:39:49.698764: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5900 of size 256 by op Fill action_count 2716826287429 step 0 next 356
2021-08-04 16:39:49.701331: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5a00 of size 256 by op Fill action_count 2716826287430 step 0 next 358
2021-08-04 16:39:49.709788: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5b00 of size 256 by op Fill action_count 2716826287431 step 0 next 790
2021-08-04 16:39:49.713649: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5c00 of size 256 by op Fill action_count 2716826287432 step 0 next 867
2021-08-04 16:39:49.716474: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5d00 of size 256 by op Fill action_count 2716826287433 step 0 next 865
2021-08-04 16:39:49.722780: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5e00 of size 256 by op Fill action_count 2716826287434 step 0 next 808
2021-08-04 16:39:49.725473: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f5f00 of size 2304 by op Fill action_count 2716826287435 step 0 next 917
2021-08-04 16:39:49.728337: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019f6800 of size 16384 by op Fill action_count 2716826287436 step 0 next 801
2021-08-04 16:39:49.730967: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019fa800 of size 256 by op Fill action_count 2716826287437 step 0 next 851
2021-08-04 16:39:49.735771: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019fa900 of size 256 by op Fill action_count 2716826287438 step 0 next 883
2021-08-04 16:39:49.738919: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019faa00 of size 256 by op Fill action_count 2716826287439 step 0 next 889
2021-08-04 16:39:49.741473: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019fab00 of size 2304 by op Fill action_count 2716826287440 step 0 next 1024
2021-08-04 16:39:49.744107: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019fb400 of size 17920 by op Fill action_count 2716826287441 step 0 next 253
2021-08-04 16:39:49.746901: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ffa00 of size 768 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/se_reduce_conv2d/Conv2D action_count 2716826290558 step 13097390214773393689 next 319
2021-08-04 16:39:49.757691: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c019ffd00 of size 768 by op AssignVariableOp action_count 2716826286852 step 0 next 320
2021-08-04 16:39:49.761476: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a00000 of size 6144 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826290547 step 13097390214773393689 next 324
2021-08-04 16:39:49.770110: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a01800 of size 4608 by op AssignVariableOp action_count 2716826286866 step 0 next 325
2021-08-04 16:39:49.774972: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a02a00 of size 4608 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/depthwise_bn/FusedBatchNormV3 action_count 2716826290546 step 13097390214773393689 next 326
2021-08-04 16:39:49.785343: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a03c00 of size 4608 by op AssignVariableOp action_count 2716826286874 step 0 next 327
2021-08-04 16:39:49.788568: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a04e00 of size 1280 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/project_bn/FusedBatchNormV3 action_count 2716826290578 step 13097390214773393689 next 2069
2021-08-04 16:39:49.793322: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a05300 of size 1280 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/project_bn/FusedBatchNormV3 action_count 2716826290579 step 13097390214773393689 next 2072
2021-08-04 16:39:49.802655: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a05800 of size 2048 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/project_bn/FusedBatchNormV3 action_count 2716826290580 step 13097390214773393689 next 329
2021-08-04 16:39:49.809242: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a06000 of size 4608 by op AssignVariableOp action_count 2716826286876 step 0 next 330
2021-08-04 16:39:49.815828: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07200 of size 1280 by op while/body/_1/EfficientDet-D0/model/stack_6/block_0/project_bn/FusedBatchNormV3 action_count 2716826290581 step 13097390214773393689 next 2073
2021-08-04 16:39:49.820479: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07700 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290794 step 13097390214773393689 next 2111
2021-08-04 16:39:49.825299: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07800 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290826 step 13097390214773393689 next 2117
2021-08-04 16:39:49.834930: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07900 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_07/1_up_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290827 step 13097390214773393689 next 2118
2021-08-04 16:39:49.841129: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07a00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_08/1_up_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290858 step 13097390214773393689 next 2121
2021-08-04 16:39:49.848489: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07b00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_08/1_up_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290859 step 13097390214773393689 next 2122
2021-08-04 16:39:49.853368: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07c00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_09/1_up_lvl_7/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290890 step 13097390214773393689 next 2125
2021-08-04 16:39:49.862369: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07d00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_09/1_up_lvl_7/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290891 step 13097390214773393689 next 2126
2021-08-04 16:39:49.869568: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07e00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_10/2_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290919 step 13097390214773393689 next 2131
2021-08-04 16:39:49.876673: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a07f00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_10/2_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290920 step 13097390214773393689 next 2132
2021-08-04 16:39:49.881825: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a08000 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_11/2_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290949 step 13097390214773393689 next 2137
2021-08-04 16:39:49.887733: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a08100 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_11/2_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290950 step 13097390214773393689 next 2138
2021-08-04 16:39:49.897262: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a08200 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_12/2_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290981 step 13097390214773393689 next 2146
2021-08-04 16:39:49.901714: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a08300 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_12/2_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290982 step 13097390214773393689 next 331
2021-08-04 16:39:49.909652: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a08400 of size 4864 by op AssignVariableOp action_count 2716826286886 step 0 next 334
2021-08-04 16:39:49.914446: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a09700 of size 1280 by op AssignVariableOp action_count 2716826286934 step 0 next 64
2021-08-04 16:39:49.924077: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a09c00 of size 1024 by op AssignVariableOp action_count 2716826287002 step 0 next 79
2021-08-04 16:39:49.930019: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0a000 of size 1024 by op AssignVariableOp action_count 2716826287012 step 0 next 91
2021-08-04 16:39:49.932834: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0a400 of size 1280 by op AssignVariableOp action_count 2716826287024 step 0 next 336
2021-08-04 16:39:49.935650: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0a900 of size 256 by op Mul action_count 2716826280534 step 0 next 338
2021-08-04 16:39:49.942645: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0aa00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_00/0_up_lvl_6/input_0_up_lvl_5/1x1_pre_sample/batchnorm/FusedBatchNormV3 action_count 2716826290629 step 13097390214773393689 next 2078
2021-08-04 16:39:49.950614: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0ab00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_02/1_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290669 step 13097390214773393689 next 2091
2021-08-04 16:39:49.960351: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0ac00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_02/1_dn_lvl_6/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290670 step 13097390214773393689 next 2092
2021-08-04 16:39:49.964827: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0ad00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290700 step 13097390214773393689 next 2095
2021-08-04 16:39:49.973458: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0ae00 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_03/1_dn_lvl_5/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290701 step 13097390214773393689 next 337
2021-08-04 16:39:49.981554: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0af00 of size 1280 by op AssignVariableOp action_count 2716826286894 step 0 next 341
2021-08-04 16:39:49.986627: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0b400 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290730 step 13097390214773393689 next 2100
2021-08-04 16:39:49.993265: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0b500 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_04/1_dn_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290731 step 13097390214773393689 next 2101
2021-08-04 16:39:50.003681: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0b600 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290762 step 13097390214773393689 next 2107
2021-08-04 16:39:50.011023: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0b700 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_05/1_dn_lvl_3/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290763 step 13097390214773393689 next 2108
2021-08-04 16:39:50.020253: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0b800 of size 256 by op while/body/_1/EfficientDet-D0/bifpn/node_06/1_up_lvl_4/post_combine/batchnorm/FusedBatchNormV3 action_count 2716826290793 step 13097390214773393689 next 342
2021-08-04 16:39:50.028628: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0b900 of size 512 by op AssignVariableOp action_count 2716826286900 step 0 next 339
2021-08-04 16:39:50.037040: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0bb00 of size 768 by op AssignVariableOp action_count 2716826286916 step 0 next 343
2021-08-04 16:39:50.041779: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0be00 of size 256 by op Mul action_count 2716826280544 step 0 next 344
2021-08-04 16:39:50.045381: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0bf00 of size 5120 by op AssignVariableOp action_count 2716826287358 step 0 next 347
2021-08-04 16:39:50.054061: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0d300 of size 5120 by op AssignVariableOp action_count 2716826287356 step 0 next 348
2021-08-04 16:39:50.058361: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0e700 of size 5120 by op AssignVariableOp action_count 2716826287360 step 0 next 349
2021-08-04 16:39:50.064753: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a0fb00 of size 9472 by op Fill action_count 2716826287391 step 0 next 236
2021-08-04 16:39:50.068003: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a12000 of size 301056 by op AssignVariableOp action_count 2716826287286 step 0 next 237
2021-08-04 16:39:50.071110: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a5b800 of size 256 by op Fill action_count 2716826287537 step 0 next 978
2021-08-04 16:39:50.073787: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a5b900 of size 256 by op Fill action_count 2716826287538 step 0 next 974
2021-08-04 16:39:50.076471: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a5ba00 of size 38400 by op Fill action_count 2716826287539 step 0 next 970
2021-08-04 16:39:50.084225: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a65000 of size 1024 by op Fill action_count 2716826287540 step 0 next 1029
2021-08-04 16:39:50.089329: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a65400 of size 1024 by op Fill action_count 2716826287541 step 0 next 1013
2021-08-04 16:39:50.096991: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a65800 of size 8704 by op Fill action_count 2716826287542 step 0 next 799
2021-08-04 16:39:50.101496: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a67a00 of size 1024 by op Fill action_count 2716826287543 step 0 next 797
2021-08-04 16:39:50.105661: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a67e00 of size 1024 by op Fill action_count 2716826287544 step 0 next 791
2021-08-04 16:39:50.110315: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a68200 of size 9728 by op Fill action_count 2716826287545 step 0 next 792
2021-08-04 16:39:50.112976: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a6a800 of size 256 by op Fill action_count 2716826287546 step 0 next 1007
2021-08-04 16:39:50.115573: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a6a900 of size 9728 by op Fill action_count 2716826287547 step 0 next 1012
2021-08-04 16:39:50.118215: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a6cf00 of size 1024 by op Fill action_count 2716826287548 step 0 next 1006
2021-08-04 16:39:50.121263: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a6d300 of size 76800 by op Fill action_count 2716826287549 step 0 next 1016
2021-08-04 16:39:50.128837: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a7ff00 of size 512 by op Fill action_count 2716826287550 step 0 next 1019
2021-08-04 16:39:50.133669: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a80100 of size 512 by op Fill action_count 2716826287551 step 0 next 992
2021-08-04 16:39:50.137859: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a80300 of size 2048 by op Fill action_count 2716826287553 step 0 next 840
2021-08-04 16:39:50.144618: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a80b00 of size 2048 by op Fill action_count 2716826287554 step 0 next 1070
2021-08-04 16:39:50.147624: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a81300 of size 17408 by op Fill action_count 2716826287555 step 0 next 1075
2021-08-04 16:39:50.150265: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a85700 of size 2048 by op Fill action_count 2716826287556 step 0 next 862
2021-08-04 16:39:50.152848: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a85f00 of size 2048 by op Fill action_count 2716826287557 step 0 next 870
2021-08-04 16:39:50.158867: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a86700 of size 38400 by op Fill action_count 2716826287558 step 0 next 871
2021-08-04 16:39:50.163421: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a8fd00 of size 256 by op Fill action_count 2716826287559 step 0 next 875
2021-08-04 16:39:50.166695: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a8fe00 of size 38400 by op Fill action_count 2716826287560 step 0 next 876
2021-08-04 16:39:50.169295: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a99400 of size 2048 by op Fill action_count 2716826287561 step 0 next 841
2021-08-04 16:39:50.175692: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a99c00 of size 512 by op Fill action_count 2716826287563 step 0 next 1045
2021-08-04 16:39:50.180015: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a99e00 of size 512 by op Fill action_count 2716826287564 step 0 next 845
2021-08-04 16:39:50.184366: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a9a000 of size 2048 by op Fill action_count 2716826287566 step 0 next 849
2021-08-04 16:39:50.188896: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a9a800 of size 2048 by op Fill action_count 2716826287567 step 0 next 1046
2021-08-04 16:39:50.191572: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a9b000 of size 17408 by op Fill action_count 2716826287568 step 0 next 844
2021-08-04 16:39:50.194153: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a9f400 of size 2048 by op Fill action_count 2716826287569 step 0 next 859
2021-08-04 16:39:50.196931: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01a9fc00 of size 2048 by op Fill action_count 2716826287570 step 0 next 860
2021-08-04 16:39:50.199519: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa0400 of size 256 by op Fill action_count 2716826287572 step 0 next 874
2021-08-04 16:39:50.206668: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa0500 of size 2048 by op Fill action_count 2716826287574 step 0 next 890
2021-08-04 16:39:50.210947: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa0d00 of size 512 by op Fill action_count 2716826287576 step 0 next 1057
2021-08-04 16:39:50.214300: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa0f00 of size 512 by op Fill action_count 2716826287577 step 0 next 1059
2021-08-04 16:39:50.216893: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa1100 of size 2048 by op Fill action_count 2716826287579 step 0 next 1062
2021-08-04 16:39:50.224421: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa1900 of size 2048 by op Fill action_count 2716826287580 step 0 next 1008
2021-08-04 16:39:50.230671: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa2100 of size 2048 by op Fill action_count 2716826287582 step 0 next 1033
2021-08-04 16:39:50.235275: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa2900 of size 2048 by op Fill action_count 2716826287583 step 0 next 1034
2021-08-04 16:39:50.238394: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa3100 of size 256 by op Fill action_count 2716826287585 step 0 next 1041
2021-08-04 16:39:50.240994: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa3200 of size 2048 by op Fill action_count 2716826287587 step 0 next 838
2021-08-04 16:39:50.243608: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa3a00 of size 512 by op Fill action_count 2716826287589 step 0 next 839
2021-08-04 16:39:50.246177: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa3c00 of size 512 by op Fill action_count 2716826287590 step 0 next 1058
2021-08-04 16:39:50.252728: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa3e00 of size 4608 by op Fill action_count 2716826287592 step 0 next 242
2021-08-04 16:39:50.258163: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01aa5000 of size 1032192 by op AssignVariableOp action_count 2716826286764 step 0 next 257
2021-08-04 16:39:50.262785: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01ba1000 of size 153600 by op Fill action_count 2716826287552 step 0 next 1044
2021-08-04 16:39:50.268396: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01bc6800 of size 153600 by op Fill action_count 2716826287562 step 0 next 830
2021-08-04 16:39:50.271674: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01bec000 of size 208896 by op Fill action_count 2716826287565 step 0 next 258
2021-08-04 16:39:50.276525: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01c1f000 of size 26624 by op AssignVariableOp action_count 2716826286678 step 0 next 416
2021-08-04 16:39:50.283410: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01c25800 of size 16384 by op AssignVariableOp action_count 2716826286692 step 0 next 423
2021-08-04 16:39:50.287815: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01c29800 of size 16384 by op AssignVariableOp action_count 2716826286706 step 0 next 438
2021-08-04 16:39:50.291052: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01c2d800 of size 2304 by op Add action_count 2716826281167 step 0 next 635
2021-08-04 16:39:50.293641: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01c2e100 of size 2304 by op Add action_count 2716826281184 step 0 next 643
2021-08-04 16:39:50.300554: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] InUse at c01c2ea00 of size 256 by op Sub action_count 2716826281225 step 0 next 658
Windows fatal exception: access violation

Thread 0x00004aac (most recent call first):
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\pool.py"", line 576 in _handle_results
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 892 in run
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 954 in _bootstrap_inner
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 912 in _bootstrap

Thread 0x00001274 (most recent call first):
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\pool.py"", line 528 in _handle_tasks
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 892 in run
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 954 in _bootstrap_inner
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 912 in _bootstrap

Thread 0x00003f0c (most recent call first):
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\connection.py"", line 816 in _exhaustive_wait
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\connection.py"", line 884 in wait
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\pool.py"", line 499 in _wait_for_updates
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\pool.py"", line 519 in _handle_workers
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 892 in run
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 954 in _bootstrap_inner
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 912 in _bootstrap

Thread 0x00001694 (most recent call first):
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\multiprocessing\pool.py"", line 114 in worker
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 892 in run
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 954 in _bootstrap_inner
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\threading.py"", line 912 in _bootstrap

Thread 0x000012c4 (most recent call first):
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\eager\execute.py"", line 59 in quick_execute
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\eager\function.py"", line 591 in call
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\eager\function.py"", line 1960 in _call_flat
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\eager\function.py"", line 3023 in __call__
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\eager\def_function.py"", line 950 in _call
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\eager\def_function.py"", line 889 in __call__
  File ""D:\work\research\object_detection\object_detection\model_lib_v2.py"", line 678 in train_loop
  File ""D:\work\research\object_detection\model_main_tf2.py"", line 106 in main
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\absl\app.py"", line 251 in _run_main
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\absl\app.py"", line 303 in run
  File ""C:\ProgramData\Anaconda3\envs\mtp4.0\lib\site-packages\tensorflow\python\platform\app.py"", line 40 in run
  File ""D:\work\research\object_detection\model_main_tf2.py"", line 115 in <module>

Is there any problem with the GPU specification? or Additional tensorflow configurations are required? "
51245,Can tensorflow.js decode MP4 video?,"Can tensorflow.js decode MP4 video?
"
51244,tf.function block thread,"I tried to run this code in multiprocess by `multiprocessing.Process`:

```python
@tf.function
def get_action(self, obs):
    mu, sigma = self.Model(obs)

    dist = tfp.distributions.Normal(mu, sigma)
    action = tf.squeeze(dist.sample(), axis=0)
    prob = tf.squeeze(dist.prob(action), axis=0)

    return action, prob
```

the tf.function would block the thread."
51243,kears.Model memory leak and tf.funtion block the thread,"I tried to run Keras Model by multiprocessing.Process for RL, it has some problems. The code as belows:

```python
def get_action(self, obs):
    mu, sigma = self.Model(obs)

    dist = tfp.distributions.Normal(mu, sigma)
    action = tf.squeeze(dist.sample(), axis=0)
    prob = tf.squeeze(dist.prob(action), axis=0)

    return action, prob
```

This code will cause memory leak,but it can work in multiprocess. Then I add `tf.function` decorator, it can run in single process, and has no more memory leak,. However, I when I try to run in multiprocess, this function will block the thread.

"
51242,TypeError: Input 'y' of 'Sub' Op has type int32 that does not match type float32 of argument 'x'.,"**System information**
- Have I written custom code: [posted below]
- Done on Google Colab using TF 2.5

I have done with building model but these some problem when training.  The errors are not clear enough I have no idea about which causes these errors.

Traceback is:
```
Epoch 1/5
/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:376: UserWarning: CRF decoding models have serialization issues in TF >=2.5 . Please see isse #2476
  return py_builtins.overload_of(f)(*args)
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-27-1b7e06547f26> in <module>()
      1 history = MODEL.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS,
----> 2                     validation_split=0.1, verbose=2)

9 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    984           except Exception as e:  # pylint:disable=broad-except
    985             if hasattr(e, ""ag_error_metadata""):
--> 986               raise e.ag_error_metadata.to_exception(e)
    987             else:
    988               raise

TypeError: in user code:

    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:855 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.7/dist-packages/keras/losses.py:142 __call__  *
        losses = call_fn(y_true, y_pred)
    <ipython-input-25-f9adc600d49b>:7 call  *
        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1250 binary_op_wrapper
        raise e
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:1234 binary_op_wrapper
        return func(x, y, name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py:548 subtract
        return gen_math_ops.sub(x, y, name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py:10562 sub
        ""Sub"", x=x, y=y, name=name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:558 _apply_op_helper
        inferred_from[input_arg.type_attr]))

    TypeError: Input 'y' of 'Sub' Op has type int32 that does not match type float32 of argument 'x'.
```
Link to colab: https://colab.research.google.com/drive/1eRN8yxM4TyQ7JmO-hxjM76dIQz2_Hpga?usp=sharing
Link to dataset: https://drive.google.com/file/d/1cVRPolctpCgcQontLDm8OmNHUMBM1KSp/view?usp=sharing

Please help me with fixing this bug."
51241,Inconsistent eager/tf.function behavior for rank 0 shape in tf.reshape,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8

**Describe the current behavior**

The eager version of `tf.reshape` takes a rank 0 tensor as a shape parameter while the jitted (`tf.function` decorated) does not.

**Describe the expected behavior**

It should be consistent, either fail in both or allow in both. To be consistent with other methods, I think it should fail in both.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): maybe
- Briefly describe your candidate solution(if contributing): raise an error, such as done in other methods like `tf.random.uniform`

**Standalone code to reproduce the issue**
[executable example here](https://colab.research.google.com/drive/15wQJVDzEHc5puK6twrV9HzxcdWZWZPtC?usp=sharing)

```
import tensorflow as tf

def func():
    return tf.reshape([[42]], 1)


func_jit = tf.function(func=func)

func()  # works
func_jit()  # fails
```"
51240,the calculation results of matmul OP are inconsistent,"I was running the following code, the results were supposed to be the same but they did not.

```python
def run_matmul_test():
    a = tf.random.normal([2452,2992], dtype=tf.float16)
    a_b = tf.random.normal([2992], dtype=tf.float16)

    b = tf.random.normal([1, 2452], dtype=tf.float16)
    c = tf.repeat(b, 8, 0)

    out1_1 = tf.matmul(b, a)
    out1 = tf.nn.bias_add(out1_1, a_b)

    out2_1 = tf.matmul(c, a)
    out2  = tf.nn.bias_add(out2_1, a_b)


    with tf.Session() as sess:
        a_out,b_out = sess.run([out1, out2])

        print(a_out[0] - b_out[0])
        print((a_out[0] - b_out[0]).max())
        print((a_out - b_out[1]).max())
        print((a_out - b_out[2]).max())
        print((a_out - b_out[3]).max())
```

Result for 1 test run.

```
[-0.01563 -0.0742   0.1289  ... -0.1406  -0.0625   0.02344]
0.625
0.625
0.625
0.625
```"
51239,Make some of the private members of MicroInterpreter protected so derived classes can access them,"I would like some of the members of the MicroInterpreter class to be protected rather than private as I would like to write a derived class that has access to the allocations with graph_. In the past we(Xmos) had a derived class of the MicroInterpreter that implemented timing hooks (function calls that profiled the execution time of each operator) by patching the registrations, maybe there is a better way of doing this? Thanks"
51238,"In ResNet50, It is unequal to actual structure of library in the keras.applications.Resnet50","As you know, in the CNN, only layers of Convolution, BatchNormalization and Dense have weights. And Usually, they are constructed by this way. Input - Conv - BN - ReLU - Conv - BN - ReLU ... - Dense. But, As you can see, below the structure remain unusual.


![image](https://user-images.githubusercontent.com/83423286/128308372-357e542a-7197-46cc-9fce-536c7331bdce.png)


```
conv2_block1_0_conv/kernel:0
conv2_block1_0_conv/bias:0
conv2_block1_3_conv/kernel:0
conv2_block1_3_conv/bias:0
conv2_block1_1_bn/gamma:0
conv2_block1_1_bn/beta:0
conv2_block1_1_bn/moving_mean:0
conv2_block1_1_bn/moving_variance:0
conv2_block1_3_bn/gamma:0
conv2_block1_3_bn/beta:0
conv2_block1_3_bn/moving_mean:0
conv2_block1_3_bn/moving_variance:0
```
You can find this result by:

```
model = tf.keras.application.ResNet50()
#The unusual phenomenon begins with index 18.
model.weights[18]
```
_I recommend that you use debugging mode in your IDE. Then you'll find it easier._

In the below lines, the ResNet50 has stack_fn function for creating layers

```
def ResNet50():
.
.
  def stack_fn(x):
    x = stack1(x, 64, 3, stride1=1, name='conv2')
    x = stack1(x, 128, 4, name='conv3')
    x = stack1(x, 256, 6, name='conv4')
    return stack1(x, 512, 3, name='conv5')
.
.

```
In the below codes, the stack1 is for simplifying repeated residential blocks.

```
def stack1(x, filters, blocks, stride1=2, name=None):


  x = block1(x, filters, stride=stride1, name=name + '_block1')
  for i in range(2, blocks + 1):
    x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i))
  return x
```

In the below structure, the block1 is Residential layers in ResNet50.

```
def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):

  bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1

  if conv_shortcut:
    shortcut = layers.Conv2D(
        4 * filters, 1, strides=stride, name=name + '_0_conv')(x)
    shortcut = layers.BatchNormalization(
        axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut) 
  else:
    shortcut = x

  x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)
  x = layers.BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)
  x = layers.Activation('relu', name=name + '_1_relu')(x)

  x = layers.Conv2D(
      filters, kernel_size, padding='SAME', name=name + '_2_conv')(x)
  x = layers.BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)
  x = layers.Activation('relu', name=name + '_2_relu')(x)

  x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)
  x = layers.BatchNormalization(
      axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)

  x = layers.Add(name=name + '_add')([shortcut, x]) 
  x = layers.Activation('relu', name=name + '_out')(x)
  return x
```
My problem is why are the model instance different from the actual structures?"
51237,Training weak learners in using video or image dataset on TensorFlow,"Hi I have a problem statement where I have to train an action recognizer using videos.
but due to non availability of good dataset there is a slight misclassification.
Is there any setting or function where I can train the misclassified or weak learners by assigning them more weights.
Its sounds similar like Xgboost but I want something which can work on Deeplearning frame works and on Image and Video data set

Thanks."
51236,How can I use multi_gpu in tf.keras?,"How can I use multi_gpu in tf.keras?
WARNING:tensorflow:From train_conv.py:214: multi_gpu_model (from tensorflow.python.keras.utils.multi_gpu_utils) is deprecated and will be removed after 2020-04-01."
51234,Tensorflow tf.map_fn over ragged tensor fails with object of type 'RaggedTensor' has no len,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (both RHEL 7 Power PC and Ubuntu 21.04 with Intel)

- TensorFlow installed from (source or binary): conda install tensorflow
- TensorFlow version (use command below): Tested on 2.4.1 and 2.5.0
- Python version: 3.7.10
- CUDA/cuDNN version: cudatoolkit 10.1.243 (Intel) and 10.2 (PowerPC)
- GPU model and memory: 2080TI (Intel) and A100 (PowerPC)

```
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)
> ""
2021-08-04 23:57:32.182116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
unknown 2.4.1
```

**Describe the current behavior**

https://stackoverflow.com/questions/68658093/tensorflow-tf-map-fn-over-ragged-tensor-fails-with-object-of-type-raggedtensor
This Tensorflow doc gives this example of using tf.map_fn on ragged tensors which works for Tensorflow 2.4.1 and above:

```
digits = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])
print(tf.map_fn(tf.math.square, digits))
```
However the following example results in error ""object of type 'RaggedTensor' has no len"" when run in Tensorflow 2.4.1 or Tensorflow 2.5:

```
import tensorflow as tf

X=tf.ragged.constant([[1.,2.],[3.,4.,5.]], dtype=tf.float32)

@tf.function
def powerX(i):
    global X
    return X**i

Y = tf.map_fn(powerX, tf.range(3, dtype=tf.float32))
```

**Describe the expected behavior**

It should return a ragged tensor.   

**Standalone code to reproduce the issue**

```
import tensorflow as tf

X=tf.ragged.constant([[1.,2.],[3.,4.,5.]], dtype=tf.float32)

@tf.function
def powerX(i):
    global X
    return X**i

Y = tf.map_fn(powerX, tf.range(3, dtype=tf.float32))
```
"
51233,tensorflow saved model to tf dialect mlir,"May I know command available in tensorflow to convert saved_model.pb to model_tf_dialect.mlir?


Thanks
"
51226,No performance improvement when I change prefetch() to prefetch_to_device(),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos 
- TensorFlow installed from (source or binary): source 
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6.8
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): devtools gcc 9.3.0
- CUDA/cuDNN version: 11.2
- GPU model and memory:  single card 40536MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
bash: v1.15.4-830-g656e13f8ba: command not found(custom version)

I decode the features in the CPU and run the model in the GPU, so I need to synchronize the movement of the features from the CPU to the GPU. I found from the timeline that it took a long time to move the features. like:
![image](https://user-images.githubusercontent.com/33950866/128280087-279bb510-73f5-431b-8474-3935083a52bf.png)

 so, I would like to async memcpyH2D features by ```prefetch_to_device```, then I get a new timeline:
![image](https://user-images.githubusercontent.com/33950866/128280627-469e6a7b-b1a1-4a5b-b879-bb0aa26b7373.png)

From the timeline point of view, I expect to improve performance by more than 30%.
I successfully async memcpyH2D, but global_steps/s is same as sync memcpyH2D. I have no idea about this. please help~
"
51209,"Can Mask_rcnn being converted into fully integer quantized TF Lite model?  Got error: Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select  TF Select ops: CropAndResize during converting.","### 1. System information

- OS Platform and Distribution:  Linux Ubuntu 18.04
- TensorFlow installation: pip package
- TensorFlow library version: 2.7.0-dev20210804

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option B: provide a link to a custom end-to-end colab


Please see code to reproduce the issue in Colab [here](https://colab.research.google.com/drive/1cHh5BYiKkm1At6eStDQnwcg9xDK5E3Ci#scrollTo=bXcd5l9x6A07)

Pretrained mask_rcnn model is downloaded from: [link](https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1)

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
ConverterError: <unknown>:0: error: loc(callsite(callsite(""CropAndResize/CropAndResize@__inference___call___39142"" at ""StatefulPartitionedCall@__inference_signature_wrapper_44195"") at ""StatefulPartitionedCall"")): 'tf.CropAndResize' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(""CropAndResize/CropAndResize@__inference___call___39142"" at ""StatefulPartitionedCall@__inference_signature_wrapper_44195"") at ""StatefulPartitionedCall"")): Error code: ERROR_NEEDS_FLEX_OPS
<unknown>:0: error: loc(callsite(callsite(""CropAndResize_1/CropAndResize@__inference___call___39142"" at ""StatefulPartitionedCall@__inference_signature_wrapper_44195"") at ""StatefulPartitionedCall"")): 'tf.CropAndResize' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: note: loc(callsite(callsite(""CropAndResize_1/CropAndResize@__inference___call___39142"" at ""StatefulPartitionedCall@__inference_signature_wrapper_44195"") at ""StatefulPartitionedCall"")): Error code: ERROR_NEEDS_FLEX_OPS
<unknown>:0: error: failed while converting: 'main': 
Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select 
TF Select ops: CropAndResize
Details:
	tf.CropAndResize(tensor<1x64x64x1088xf32>, tensor<?x4xf32>, tensor<100xi32>, tensor<2xi32>) -> (tensor<100x17x17x1088xf32>) : {T = f32, device = """", extrapolation_value = 0.000000e+00 : f32, method = ""bilinear""}
	tf.CropAndResize(tensor<1x64x64x1088xf32>, tensor<?x4xf32>, tensor<300xi32>, tensor<2xi32>) -> (tensor<300x17x17x1088xf32>) : {T = f32, device = """", extrapolation_value = 0.000000e+00 : f32, method = ""bilinear""}
```
"
51201,"Error : Value for attr 'data_format' of """", when calling TF_AddGradients with FusedBatchNormV3 operator","Hello, I'm very happy to see that FusedBatchNormV3 is now included in backprop.
Unfortunately, when I call TF_AddGradients with a TF_Graph containing a FusedBatchNormV3 operator, I get an error with a blank data_format attribute.

This is probably due to the fact that the default values are not reflected when registering FusedBatchNormGradV3.

**System information**
Windows 10 x64
No custom code
binary From [https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.6.0.zip](https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.6.0.zip)
TensorFlow Version 2.6.0
C API 
On CPU"
51180,[CoreML Delegate] validator error: Padding type for the pooling layer 'PoolingLayerBuilder (MEAN)_2' is not set.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX Big Sur
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone XS
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8
- Bazel version (if compiling from source): 3.7.2

**Describe the current behavior**
I have used Google AutoML Vision to create object detection models in the past. Previously the models that were generated were all TOCO converted on runtime 1.15. Recently, AutoML has been generating object detection models that are MLIR converted on TF runtime 2.5. All models are in TensorFlow Lite format.

My previous object detection models run without any issues with the CoreML Delegate. The new object detection models run on CPU but throw an error when using the CoreML delegate. It's the same Object Detection sample code running for both - older model the CoreML works, newer one does not work.

The specific error is `Error compiling model Error reading protobuf spec. validator error: Padding type for the pooling layer 'PoolingLayerBuilder (MEAN)_2' is not set.`

**Describe the expected behavior**
CoreML Delegate should create an ML model without any errors.

**Other info / logs** 
I attempted to solve the problem by explicitly setting padding to SAME for kTfLiteBuiltInMean operation as follows. It appeared to work, the error was gone and the delegate was initialized. However, with that one small change it also seemed to crash every now and then with BAD_EXC_ACCESS error. 

I made this PR today but closed it once I noticed the crashes.
https://github.com/tensorflow/tensorflow/pull/51174/commits/602cd90c1d55bc205c4230060c4423af4cdf82fd

Pooling Layer Params specification:
https://apple.github.io/coremltools/mlmodel/Format/NeuralNetwork.html#poolinglayerparams

I am building the CoreML framework locally by running this in `tensorflow/tensorflow/lite` and testing on an iPhoneX (I am making sure to Clean the Build Folder between tests)
```
 bazel build -c opt --config=ios_fat //tensorflow/lite/ios:TensorFlowLiteCCoreML_framework
tflite_ios_framework(
    name = ""TensorFlowLiteCCoreML_framework"",
    hdrs = [
        "":coreml_delegate.h"",
    ],
    allowlist_symbols_file = "":allowlist_TensorFlowLiteCCoreML.txt"",
    bundle_name = ""TensorFlowLiteCCoreML"",
    minimum_os_version = TFL_MINIMUM_OS_VERSION,
    deps = [
        ""//tensorflow/lite/delegates/coreml:coreml_delegate"",
    ],
)
```


Questions:
1. Was my approach correct to explicitly set the padding or is there something else at play here?
2. What else can I try to get CoreML working and fix this error?
"
51179,Inference is slower on Densenet121 when using XLA ,"Hi,

When running the Densenet121 model using **XLA** on Imagenet dataset, the inference is about 5-7 seconds slower than normal on GPU.

**Environment**:
Tensorflow 2.5.0
keras-nightly==2.5.0.dev2021032900
Python 3.7
OS: Ubuntu 18.04
CUDA 11.1
GPUs: 8 Nvidia GA100

**Current behaviour**:
Running inference using Densenet121 without XLA takes ~14s on 10000 images
Running inference using Densenet121 with XLA takes ~20s on 10000 images

**Expected behaviour**:
Times should be similar or XLA should be faster!

My code is currently quite complex. If needed, I can try to provide a simplified version. Please let me know if you need any additional information.





"
51178,&TfLiteTensor->Data not 16-Byte Aligned,"### 1. System information

- OS Platform and Di_pywrap_toco_apistribution (e.g., Linux Ubuntu 16.04): LINUX UBUNTU 20.04
- TensorFlow installation (pip package or built from source):  PIP PACKAGE
- TensorFlow library (version, if pip package or github SHA, if built from source): PIP PACKAGE

### 2. Code
I think the code will not help, as the conversion process is working but I have questions about the resulting model file.
I have attached a zip:
[model.zip](https://github.com/tensorflow/tensorflow/files/6934441/model.zip)


### 3. Failure after conversion
I am working on a proof of concept, and I am making changes to the TFLite codebase. 
Although the model file is 16-byte aligned, some of the tensor data is not. 
For example:
my input->data.f has an address of 0x..........0 (16 byte aligned)
my bias->data.f has an address of 0x...........8 (8 byte aligned)

While this can still work, the hardware optimization I am trying to implement works better if the data is 16-byte aligned. The only option I see is to specifically treat the first two floats (8 bytes), and then use full optimization for the rest of the data.

SO, my question is whether there is some option somewhere during conversion to align the the data within each tensor! I assume there would be some option to have it pad the data structures in the flatbuffer model with a few zeros before beginning the float data array.

The only posts I have seen regarding memory alignment are for TensorflowLite Micro, which isn't really an option for me.

### 5. (optional) Any other info / logs
If there is no option in the converter to achieve what I want, I suppose I can make the changes myself when the memory is allocated in TFlite, but I could use a nudge in the right direction. My assumption is that the model is parsed somewhere, and I would like to add some instruction to make sure the TfLiteTensor->data is properly aligned. Do you know where the easiest place to make that change would be?

Thanks!"
51149,Cloud TPU Memory Leak causing OOM Error ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): n1-standard-2 VM on GKE; Container-Optimized OS with Docker (cos) 
- TensorFlow installed from (source or binary): binary (pip command) 
- TensorFlow version (use command below): 2.3.0 
- Python version: 3.6 
- Bazel version (if compiling from source): None 
- GCC/Compiler version (if compiling from source): None 
- CUDA/cuDNN version: None 
- GPU model and memory: None (v2.8 preemptible TPU with GKE) 

**Describe the current behavior**
I am performing large-scale hyperparameter optimization using Cloud TPUs on GKE. Unfortunately, I keep encountering a memory leak that causes the TPUs to return an OOM after training several networks. Initially, I thought this issue was due to the buildup of old models, so I tried methods such as tf.backend.clear_session(), del model, and gc.collect(). Those methods fixed a memory leak that had been happening with the controller CPU, but the memory leak persists on the TPU worker node. Occasionally, I instead get an ""Unavailable: Socket Closed"" error. To fix these issues, I tried solutions suggested by other posts, such as typecasting my data to float32, not caching my dataset into memory, using a smaller mini-batch size, and using from_logits in my cost function. Unfortunately, those solutions have not helped.  I have not encountered these problems with either a CPU/GPU/Colab TPU. 

**Describe the expected behavior**
Same as CPU/GPU/Colab TPU (no memory leak) 

**Standalone code to reproduce the issue**
The issue does not occur on Colab, but here is a [link](https://colab.research.google.com/drive/1tjPh6-UQuEtFKNQcJfaVA3vQ0eIV5SG_?usp=sharing) to code that reproduces the issue on GCP.

**Other info / logs** 
Log trace: 
[TPU_Traceback.txt](https://github.com/tensorflow/tensorflow/files/6932886/TPU_Traceback.txt)

"
51148,The model won't download,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
51146,Google Developers Certification Plugin,"The Google Developers Certification Plugin is not available on Android Studio Arctic Fox 2020.3.1
![dd](https://user-images.githubusercontent.com/40315618/128174071-8755f5fb-5161-4991-9151-df731784dda8.PNG)
"
51145,Performance regression: Tensorflow 2.5.0,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Centos 7**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.5.0**
- Python version: 3.8.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I observed significant performance regression (+20% latency) using TF 2.5.0 compared to TF 2.3.0 on CPU.
One op to highlight is `sparse_tensor_dense_matmul `.
The cause could be Eigen or change of this kernel.

**Describe the expected behavior**
Performance on parity with TF 2.3.0.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1gNaQsRZzhmKYFQGMxOO9vzSR6AFpVMci?usp=sharing
"
51143,tf.saved_model.save fails when there is tf.reshape in tf.keras.Model call method,"**Current behavior**
tf.saved_model.save fails to save tf.keras.Model if there is tf.reshape operation in Model call method.

I have debugged it and I found that during saving the Model, SimpleModel.call is called twice. The first time everything is fine and **batch_size = 1,** but in the second call **batch_size = None** and this is why it fails.

**Expected behavior**
Model should be saved as Savedmodel

**Tested with**
TF 2.4.1 and TF 2.5 installed by PIP
Windows 10
Ubuntu 18.04
Nvidia GPU

**Example code for easy reproduction**
```
import tensorflow as tf

class SampleModel(tf.keras.Model):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        self.dense_1 = tf.keras.layers.Dense(
            units=10,
            activation=tf.nn.relu
        )

    def call(self, inputs, **kwargs):
        batch_size, height, width, filters = inputs.get_shape().as_list()
        x = tf.reshape(inputs, [batch_size, height * width * filters])
        x = self.dense_1(x)

        return x

def get_model():
    input_shape = (10, 10, 3)
    input = tf.keras.layers.Input(shape=input_shape, batch_size=1)

    x =  tf.keras.layers.Conv2D(
        filters=10,
        kernel_size=3
    )(input)

    sample_model = SampleModel()
    output = sample_model(x)
    model = tf.keras.Model(inputs=input, outputs=output)

    return model

if __name__ == ""__main__"":
    model = get_model()

    tf.saved_model.save(
        obj=model,
        export_dir=""./savemodel_test""
    )


```"
51142,"Tensorflow 2.x, Unable to debug a tensorflow projects, can only print tensor.shape but not get values of the tensor","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51141,Failed precondition: Could not find variable bias_w. This could mean that the variable has been deleted.,"tf2.5

```
import tensorflow as tf

def weightVariables(shape, name):
    initial = tf.random.truncated_normal(shape=shape, mean=0, stddev=0.05, dtype=tf.dtypes.float64)
    return tf.Variable(initial, name=name)

c_proto = tf.compat.v1.ConfigProto()
c_proto.gpu_options.allow_growth = True

with tf.compat.v1.Session(config=c_proto) as sess:
    sess.run(tf.compat.v1.global_variables_initializer())

    while True:
        biasWeight = weightVariables([10], name='bias_w')
        print(sess.run(biasWeight))

```


```
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) Failed precondition: Could not find variable bias_w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Container localhost does not exist. (Could not find resource: localhost/bias_w)
         [[node bias_w/Read/ReadVariableOp (defined at test5.py:42) ]]
  (1) Failed precondition: Could not find variable bias_w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Container localhost does not exist. (Could not find resource: localhost/bias_w)
         [[node bias_w/Read/ReadVariableOp (defined at test5.py:42) ]]
         [[bias_w/Read/ReadVariableOp/_1]]

```"
51139,KeyError: u'SelectV2',"**I trained one model using tf 1.13, but when i load the model , the KeyError: u'SelectV2' occured , is there anything wrong with the procedure?**

File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/predictor/predictor_factories.py"", line 153, in from_saved_model
    config=config)
  File ""/usr/lib/python2.7/site-packages/tensorflow/contrib/predictor/saved_model_predictor.py"", line 153, in __init__
    loader.load(self._session, tags.split(','), export_dir)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py"", line 197, in load
    return loader.load(sess, tags, import_scope, **saver_kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py"", line 350, in load
    **saver_kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/saved_model/loader_impl.py"", line 278, in load_graph
    meta_graph_def, import_scope=import_scope, **saver_kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1696, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/meta_graph.py"", line 806, in import_scoped_meta_graph_with_return_elements
    return_elements=return_elements)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 488, in new_func
    return func(*args, **kwargs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 391, in import_graph_def
    _RemoveDefaultAttrs(op_dict, producer_op_list, graph_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 158, in _RemoveDefaultAttrs
    op_def = op_dict[node.op]
KeyError: u'SelectV2'"
51137,TFLite conversion notebook will no longer install dependencies,"## URL(s) with the issue:

Doc Link: https://github.com/tensorflow/examples/blob/master/lite/examples/gesture_classification/ml/README.md

Notebook link (also on doc page): 
https://github.com/tensorflow/examples/blob/master/lite/examples/gesture_classification/ml/tensorflowjs_to_tflite_colab_notebook.ipynb

## Description of issue (what needs changing):

Updated notebook that will install the dependencies, and run successfully to convert a Tf 1.x model to a TFLite model. 

### Clear description

Following the steps for the TFLite example project you are recommended to use a python notebook (linked above). I have used it many times before, however it has recently stopped working. I was using it on Collab as per the instructions. 


### Usage example

The following command: `!pip3 install tensorflow==1.14.0 keras==2.2.4 tensorflowjs==0.6.4 --force-reinstall`

Results in: 

```
ERROR: Cannot install keras==2.2.4 and tensorflowjs==0.6.4 because these package versions have conflicting dependencies.

The conflict is caused by:
    The user requested keras==2.2.4
    tensorflowjs 0.6.4 depends on keras==2.2.2

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

```
"
51135,Documentation link broken at projector.tensorflow.org,"## URL(s) with the issue:
https://projector.tensorflow.org/

## Description of the issue (what needs changing):

The question mark icon in the top right of navbar is supposed to be a hyperlink to the documentation.
The icon is a hyperlink to https://www.tensorflow.org/get_started/embedding_viz , which is broken.
"
51134,TFLite fails to convert when the Model has regex_split_with_offsets,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

```
def tokenize(self, x):
    x = tf_text.case_fold_utf8(x)
    x = tf_text.normalize_utf8(x, ""NFD"")
    x = tf.strings.regex_replace(x, r""\p{Mn}"", """")
    x = tf.strings.regex_replace(x, r""\p{Cc}|\p{Cf}"", "" "")
    x,_ ,_ = tf_text.regex_split_with_offsets(
        x, self._delim_regex_pattern, self._keep_delim_regex_pattern,
        ""BasicTokenizer"")
    return x
```
Testing with a simpler delim and keep_delim inputs will also result in the conversion error.
The full model is in the following colab gist.
#### Reference To [TensorFlow Model, and tflite conversion Colab] [Colab gist](https://colab.research.google.com/drive/1JRSaXPEy7_osjKj-JnYoYNo5pPhvbal3?usp=sharing)

In the gist, the model is shown to work before and after saving to SavedModel. 
The code attempts to convert to tflite from SavedModel. 

### 3. Failure during conversion
TFLite Fails to convert when model contains regex_split_with_offsets ops. 
tensorflow_text is imported, 
Select Ops flex option is enabled. such as:
`
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS
]`

In the example, there are other tf_text ops before problematic regex_split_with_offsets. 
When commenting away the line with tf_text.regex_split_with_offsets, it will convert successfully. 

### 4. (optional) Any other info / logs
The error prompt says the  ""Graph does not contain node: "". Full trace logs is available below and in the gist.

```
 ---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    293                                                  debug_info_str,
--> 294                                                  enable_mlir_converter)
    295       return model_str

4 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     37       debug_info_str,
---> 38       enable_mlir_converter)
     39 

Exception: Graph does not contain node: 

During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-82-51fa59e54032> in <module>()
      5   tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
      6 ]
----> 7 tflite_model = converter.convert()
      8 with open(tfLite_filepath, 'wb') as f:
      9   f.write(tflite_model)

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py in convert(self)
    911     converter_kwargs.update(quant_mode.converter_flags())
    912 
--> 913     result = _convert_saved_model(**converter_kwargs)
    914     if self.experimental_new_quantizer:
    915       calibrate_and_quantize, flags = quant_mode.quantizer_flags(

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in convert_saved_model(saved_model_dir, saved_model_version, saved_model_tags, saved_model_exported_names, **kwargs)
    725       None,  # input_data, unused
    726       None,  # debug_info_str, unused
--> 727       enable_mlir_converter=True)
    728   return data
    729 

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    295       return model_str
    296     except Exception as e:
--> 297       raise ConverterError(str(e))
    298 
    299   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: Graph does not contain node: 

```"
51131,"recompute_grad + keras: ""TypeError: Cannot convert a symbolic Keras input/output to a numpy array.""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro, Version 21H1
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.9.0

**Describe the current behavior**
tf.recompute_grad does not accept tf.keras.layers objects.
Instead, I get: ""TypeError: Cannot convert a symbolic Keras input/output to a numpy array.""

**Describe the expected behavior**
The API documentation explicitly mentions tf.keras.layers objects.
Also, according to several comments on GitHub, it should work with keras layers.

**Contributing**

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Input
from tensorflow.keras.models import Model

def block(x):
    x = Conv2D(filters = 32, kernel_size = (3, 3))(x)
    x = Conv2D(filters = 32, kernel_size = (3, 3))(x)
    return x
block = tf.recompute_grad(block)

input = Input(shape = (128, 128, 3))
block_1 = block(input)
block_2 = block(block_1)
model = Model(input, block_2)
```

**Other info / logs**

> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> <ipython-input-15-d90add487c0c> in <module>
>      10 
>      11 input = Input(shape = (128, 128, 3))
> ---> 12 block_1 = block(input)
>      13 block_2 = block(block_1)
>      14 model = Model(input, block_2)
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\ops\custom_gradient.py in __call__(self, *a, **k)
>     259 
>     260   def __call__(self, *a, **k):
> --> 261     return self._d(self._f, a, k)
>     262 
>     263 
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\ops\custom_gradient.py in decorated(wrapped, args, kwargs)
>     213 
>     214     if context.executing_eagerly():
> --> 215       return _eager_mode_decorator(wrapped, args, kwargs)
>     216     else:
>     217       return _graph_mode_decorator(wrapped, args, kwargs)
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\ops\custom_gradient.py in _eager_mode_decorator(f, args, kwargs)
>     456   flat_result = nest.flatten(result)
>     457   # TODO(apassos) consider removing the identity below.
> --> 458   flat_result = [gen_array_ops.identity(x) for x in flat_result]
>     459 
>     460   input_tensors = [ops.convert_to_tensor(x) for x
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\ops\custom_gradient.py in <listcomp>(.0)
>     456   flat_result = nest.flatten(result)
>     457   # TODO(apassos) consider removing the identity below.
> --> 458   flat_result = [gen_array_ops.identity(x) for x in flat_result]
>     459 
>     460   input_tensors = [ops.convert_to_tensor(x) for x
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\ops\gen_array_ops.py in identity(input, name)
>    3954       pass
>    3955     try:
> -> 3956       return identity_eager_fallback(
>    3957           input, name=name, ctx=_ctx)
>    3958     except _core._SymbolicException:
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\ops\gen_array_ops.py in identity_eager_fallback(input, name, ctx)
>    3974 
>    3975 def identity_eager_fallback(input, name, ctx):
> -> 3976   _attr_T, (input,) = _execute.args_to_matching_eager([input], ctx, [])
>    3977   _inputs_flat = [input]
>    3978   _attrs = (""T"", _attr_T)
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\eager\execute.py in args_to_matching_eager(l, ctx, allowed_dtypes, default_dtype)
>     271 
>     272       if tensor is None:
> --> 273         tensor = ops.convert_to_tensor(
>     274             t, dtype, preferred_dtype=default_dtype, ctx=ctx)
>     275 
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\profiler\trace.py in wrapped(*args, **kwargs)
>     161         with Trace(trace_name, **trace_kwargs):
>     162           return func(*args, **kwargs)
> --> 163       return func(*args, **kwargs)
>     164 
>     165     return wrapped
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\framework\ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
>    1564 
>    1565     if ret is None:
> -> 1566       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
>    1567 
>    1568     if ret is NotImplemented:
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
>     337                                          as_ref=False):
>     338   _ = as_ref
> --> 339   return constant(v, dtype=dtype, name=name)
>     340 
>     341 
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\framework\constant_op.py in constant(value, dtype, shape, name)
>     262     ValueError: if called on a symbolic tensor.
>     263   """"""
> --> 264   return _constant_impl(value, dtype, shape, name, verify_shape=False,
>     265                         allow_broadcast=True)
>     266 
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
>     274       with trace.Trace(""tf.constant""):
>     275         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
> --> 276     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
>     277 
>     278   g = ops.get_default_graph()
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\framework\constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
>     299 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
>     300   """"""Implementation of eager constant.""""""
> --> 301   t = convert_to_eager_tensor(value, ctx, dtype)
>     302   if shape is None:
>     303     return t
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\framework\constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
>      96       dtype = dtypes.as_dtype(dtype).as_datatype_enum
>      97   ctx.ensure_initialized()
> ---> 98   return ops.EagerTensor(value, ctx.device_name, dtype)
>      99 
>     100 
> 
> ~\.conda\envs\histology\lib\site-packages\tensorflow\python\keras\engine\keras_tensor.py in __array__(self)
>     252 
>     253   def __array__(self):
> --> 254     raise TypeError(
>     255         'Cannot convert a symbolic Keras input/output to a numpy array. '
>     256         'This error may indicate that you\'re trying to pass a symbolic value '
> 
> TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.
"
51127,No information in official doc regarding implementation of class_weight in customized model.fit() method,"Hi,
I have customized the standard model.fit() method based on the help/steps described in the official [page](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). Now, I would like to use the class_weight in this customized function but I do not see any help regarding class_weight implementation in official [page](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#supporting_sample_weight_class_weight) under the heading [Supporting sample_weight & class_weight](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit#supporting_sample_weight_class_weight). Kindly help me to understand how to implement class_weight in this case?


Best Regards"
51126,Question: Can we get all the intermidiate tensors when using gpu(opencl) delegate??,"Hi guys, i wanna ask if there is any method that we can get the intermidiate tensors on gpu(opencl) delegate.   Which means, when delegate invoke is finished , all the intermidiate tensors' cl_mem are NAIVE stored and we can WRITE into a cpu ptr which is hold by TfliteTensor form the marched tensor id on CPU.   

I see there is TensorTieFactory for subgraph global input & output's conversion. However I'm not really clear some details. 
Could you help me ? Thanks a lot.!


"
51125,WARNING:tensorflow:AutoGraph could not transform <function> ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, following this tutorial: https://www.tensorflow.org/text/tutorials/text_generation
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary (via pip)
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.10
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.4
- GPU model and memory: NVIDIA RTX A4000, 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Tensorflow throws a warning when mapping a function to a dataset. The stacktrace told me to report this (see full stack trace below):


```
WARNING: AutoGraph could not transform <function split_input_target at 0x7f24c012aa60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of <function split_input_target at 0x7f24c012aa60>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```

**Describe the expected behavior**

No warning

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No

**Standalone code to reproduce the issue**

Code taken from [tutorial](https://www.tensorflow.org/text/tutorials/text_generation):
```python
import tensorflow as tf
from tensorflow.keras.layers.experimental import preprocessing

import numpy as np
import os
import time

path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')

with open(path_to_file, 'rb') as f:
    text = f.read().decode(encoding='utf-8')

vocab = sorted(set(text))

# process the text

example_texts = ['abcdefg', 'xyz']
# unicode_split = tokenizer, split by unicode character
chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')

# StringLookup maps strings to integers, vocab list is single chars
ids_from_chars = preprocessing.StringLookup(
            vocabulary=list(vocab), mask_token=None)

ids = ids_from_chars(chars)

# inverted operation

chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(
    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)

chars = chars_from_ids(ids)
# tf & numpy way of joining a list:
tf.strings.reduce_join(chars, axis=-1).numpy()

def text_from_ids(ids):
  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)


# create training dataset

all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))

ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)

for ids in ids_dataset.take(10):
    print(chars_from_ids(ids).numpy().decode('utf-8'))

seq_length = 100
examples_per_epoch = len(text) // (seq_length+1)

sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)

for seq in sequences.take(5):
  print(text_from_ids(seq).numpy())

# create input and label pairs
# input: current character
# label: next character

def split_input_target(sequence):
    input_text = sequence[:-1]
    target_text = sequence[1:]
    return input_text, target_text

split_input_target(list(""Tensorflow""))

dataset = sequences.map(split_input_target)
```



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


Full error:

```
INFO:tensorflow:Converted call: <function split_input_target at 0x7f24c012aa60>
    args: (<tf.Tensor 'args_0:0' shape=(101,) dtype=int64>,)
    kwargs: {}

Converted call: <function split_input_target at 0x7f24c012aa60>
    args: (<tf.Tensor 'args_0:0' shape=(101,) dtype=int64>,)
    kwargs: {}

INFO:tensorflow:Not allowed: <method-wrapper '__call__' of function object at 0x7f24c012aa60>: default rule
Not allowed: <method-wrapper '__call__' of function object at 0x7f24c012aa60>: default rule
INFO:tensorflow:Not allowed: <function split_input_target at 0x7f24c012aa60>: default rule
Not allowed: <function split_input_target at 0x7f24c012aa60>: default rule
INFO:tensorflow:<function split_input_target at 0x7f24c012aa60> is not cached for subkey ConversionOptions[{}]
<function split_input_target at 0x7f24c012aa60> is not cached for subkey ConversionOptions[{}]
INFO:tensorflow:Error transforming entity <function split_input_target at 0x7f24c012aa60>
Traceback (most recent call last):
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/parser.py"", line 154, in parse_entity
    original_source = inspect_utils.getimmediatesource(entity)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py"", line 151, in getimmediatesource
    lines, lnum = inspect.findsource(obj)
  File ""/usr/lib/python3.8/inspect.py"", line 798, in findsource
    raise OSError('could not get source code')
OSError: could not get source code

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 432, in converted_call
    converted_f = _convert_actual(target_entity, program_ctx)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 274, in _convert_actual
    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 286, in transform
    return self.transform_function(obj, user_context)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 470, in transform_function
    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 346, in transform_function
    node, source = parser.parse_entity(fn, future_features=future_features)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/parser.py"", line 156, in parse_entity
    raise ValueError(
ValueError: Unable to locate the source code of <function split_input_target at 0x7f24c012aa60>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
Error transforming entity <function split_input_target at 0x7f24c012aa60>
Traceback (most recent call last):
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/parser.py"", line 154, in parse_entity
    original_source = inspect_utils.getimmediatesource(entity)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/inspect_utils.py"", line 151, in getimmediatesource
    lines, lnum = inspect.findsource(obj)
  File ""/usr/lib/python3.8/inspect.py"", line 798, in findsource
    raise OSError('could not get source code')
OSError: could not get source code

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 432, in converted_call
    converted_f = _convert_actual(target_entity, program_ctx)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 274, in _convert_actual
    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 286, in transform
    return self.transform_function(obj, user_context)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 470, in transform_function
    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 346, in transform_function
    node, source = parser.parse_entity(fn, future_features=future_features)
  File ""/redacted//.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/parser.py"", line 156, in parse_entity
    raise ValueError(
ValueError: Unable to locate the source code of <function split_input_target at 0x7f24c012aa60>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
WARNING:tensorflow:AutoGraph could not transform <function split_input_target at 0x7f24c012aa60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of <function split_input_target at 0x7f24c012aa60>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function split_input_target at 0x7f24c012aa60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of <function split_input_target at 0x7f24c012aa60>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```
"
51124,Upgrade Sqlite3 to fix CVE-2021-20227,sqlite 3.34.0
51123,"Need help: How to build tensorflow-lite with ""Pyro"" version of Yocto, for ARM platform","Hi,

I need to build tensorflow-lite on ""Pyro"" version of Yocto for one of my Projects, for ARM platform
Can someone point me to fetch the ""*.bb"" file for the same ? Or the steps to build the same from scratch ?

Thanking in advance"
51122,Issue with tf.nn.conv2d restarting kernel,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10

- TensorFlow installed from (source or binary):
Pip install

- TensorFlow version (use command below):
v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0

- Python version:
3.8

- CUDA/cuDNN version:
CUDA 11.2; cuDNN 8.2

- GPU model and memory:
Nvdia RTX 3060Ti 8GB

**Describe the current behavior**
I am running the exmple script found on the tf.nn.conv2d documentaion page (found here: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)

Upon running the final line in spyder the kernel immediately restarts with no error message displayed

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import numpy as np

x_in = np.array([[
  [[2], [1], [2], [0], [1]],
  [[1], [3], [2], [2], [3]],
  [[1], [1], [3], [3], [0]],
  [[2], [2], [0], [1], [1]],
  [[0], [0], [3], [1], [2]], ]])
kernel_in = np.array([
 [ [[2, 0.1]], [[3, 0.2]] ],
 [ [[0, 0.3]],[[1, 0.4]] ], ])
x = tf.constant(x_in, dtype=tf.float32)
kernel = tf.constant(kernel_in, dtype=tf.float32)
tf.nn.conv2d(x, kernel, strides=[1, 1, 1, 1], padding='VALID')
```
"
51121,FAILED: Build did NOT complete successfully,"**System information**

- OS Platform and Distribution: 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.2
- Python version: 3.8.10
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 10.2 / 8.2.2
- GPU model and memory: Quadro K2000M / 2GB

**Configure**

`cat .tf_configure.bazelrc`

```
build --action_env PYTHON_BIN_PATH=""/usr/bin/python3""
build --action_env PYTHON_LIB_PATH=""/usr/lib/python3/dist-packages""
build --python_path=""/usr/bin/python3""
build --config=tensorrt
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-10.2""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""3.0""
build --action_env LD_LIBRARY_PATH=""/usr/local/cuda-10.2/lib64:/usr/local/lib""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-9""
build --config=cuda
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-Wno-sign-compare
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
```

**Build a TensorFlow package builder with GPU support:**

bazel build --config=cuda [--config=option] //tensorflow/tools/pip_package:build_pip_package

The error:

```
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=190
INFO: Reading rc options for 'build' from /home/kevin/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/kevin/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true
INFO: Reading rc options for 'build' from /home/kevin/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=tensorrt --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-10.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.0 --action_env LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:/usr/local/lib --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 --config=cuda
INFO: Found applicable config definition build:short_logs in file /home/kevin/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/kevin/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:tensorrt in file /home/kevin/tensorflow/.bazelrc: --repo_env TF_NEED_TENSORRT=1
INFO: Found applicable config definition build:cuda in file /home/kevin/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:cuda in file /home/kevin/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:linux in file /home/kevin/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/kevin/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/toolchains/archive/d781e89e2ee797ea7afd0c8391e761616fc5d50d.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/cdf6d36e9a5c07770160ebac25b153481c37a247.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
DEBUG: /home/kevin/.cache/bazel/_bazel_kevin/34b262a4f3c2d5656d47ec6453465346/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:10: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
ERROR: Skipping '[--config=option]': no such target '//:[--config=option]': target '[--config=option]' not declared in package '' defined by /home/kevin/tensorflow/BUILD
ERROR: no such target '//:[--config=option]': target '[--config=option]' not declared in package '' defined by /home/kevin/tensorflow/BUILD
INFO: Elapsed time: 0.089s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```

I see URLs not available and return 404.

http://mirror.tensorflow.org/github.com/tensorflow/toolchains/archive/d781e89e2ee797ea7afd0c8391e761616fc5d50d.tar.gz
http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/cdf6d36e9a5c07770160ebac25b153481c37a247.tar.gz
"
51120,ValueError(Missing predictions) in tf.estimator,"I defined the two spec for eval and prediction with tf.estimator, My goal is to get **predictions**'s content, like[1,1,1], not printed like ""Tensor(shape=(),dtype=float32)""
- here is the code
```python
def model_fn():
    ...
    predictions = tf.argmax(logits,axis=-1,name=""pred_node"") 
    pred = {'pred':prediction}
    acc = tf.metrics.accuracy(labels,predictions)
    eval_metrics={""acc"":acc}
    if mode == tf.estimator.ModeKeys.EVAL:
        eval_spec = tf.estimator.EstimatorSpec(
            mode=mode,
            loss=total_loss,
            eval_metrics=eval_metrics,
            scaffold_fn=scaffold_fn
        )
    if mode == tf.estimator.ModeKeys.PREDICT:
        eval_spec = tf.estimator.EstimatorSpec(
            mode=mode,
            predictions=pred
        )
    return eval_spec
```
and when do eval mode using `estimator.eval()`, it can print the content of *eval_metrics*,acc(0.966) however, when i use `estimator.predict()`, raised ValueError(Missing predictions).

I also tried these ways to get tensor predictions:
- using session to `session.run(predictions)`, and `tf.print(predictions)`, failed
- restore model.ckpt to model.pb to `tf.get_default_graph.get_tensor_by_name()`,I got all of argmax nodes' output, Then i found the node that calculates `predictions` not in the graph ????

Finally I found in [estimator source code](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/model_fn.py) that:
```python
Raises:
    ValueError: If:
      - predictions is None and we are in predict mode.
      - predictions `Tensor` is not in default_graph or else it is a dict of
        `Tensor` where at least one is not in default_graph.
    TypeError:  If predictions is not a `Tensor` or dict of `Tensor`.
  """"""
```
but i got acc(0.996969907284) using predictions, which means this tensor is not NONE. So it must be the second cause, **not in default_graph**, the same as my second try.

So how should I deal with this? how to add this argmax node to graph?

Thanks in advance for answering."
51119,"cpu gpu delegate in ios get the different result, cpu's is right but gpu's is wrong","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos big sur 11.4 20f71
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iphone xr
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): a4dfb8d1a71385bd6d122e4f27f86dcebb96712d (tag: v2.5.0)
- Python version: 3.8.2
- Bazel version (if compiling from source): bazel-4.0.0
- GCC/Compiler version (if compiling from source): (clang-1205.0.22.11)
- CUDA/cuDNN version: NO
- GPU model and memory: reference iphone xr configuration 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
git checkout v2.5.0
tensorflow/lite/tools/make/build_ios_universal_lib.sh
change the pod file below
platform :ios, '12.0'
inhibit_all_warnings!

target 'tflite_simple_example'
       pod 'TensorFlowLiteObjC', '2.5.0'

modify ../tensorflow/tensorflow/lite/examples/ios/simple project to load my tflite model , feed the same input
and then run in cpu and gpu mode. 
but the result has a big big difference
[bisenetv3_fp32_224.tflite.zip](https://github.com/tensorflow/tensorflow/files/6929310/bisenetv3_fp32_224.tflite.zip)

here is the run debug info

> 2021-08-03 14:52:45.587249+0800 tflite_simple_example[4144:2858180] input data len 150528
tflite_simple_example was compiled with optimization - stepping may behave oddly; variables may not be available.
2021-08-03 14:53:02.632412+0800 tflite_simple_example[4144:2858180] Initialized TensorFlow Lite runtime.
2021-08-03 14:53:02.651308+0800 tflite_simple_example[4144:2858180] Created TensorFlow Lite delegate for Metal.
2021-08-03 14:53:02.652346+0800 tflite_simple_example[4144:2858180] Metal GPU Frame Capture Enabled
2021-08-03 14:53:02.653172+0800 tflite_simple_example[4144:2858180] Metal API Validation Enabled
=== Pre-invoke Interpreter State ===
Interpreter has 1 subgraphs.

-----------Subgraph-0 has 249 tensors and 102 nodes------------
Inputs: [0]
Outputs: [226]

Tensor  ID Name                      Type            AllocType                Size
Tensor   0 input_1                   kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,224,224,3]
Tensor   1 bi_se_net_v3_tf/Resize... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   2 bi_se_net_v3_tf/Resize... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   3 bi_se_net_v3_tf/Resize... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   4 bi_se_net_v3_tf/bga_la... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   5 bi_se_net_v3_tf/mul/y;... kTfLiteFloat32  kTfLiteMmapRo              12B ( 0.0 MB) [1,1,1,3]
Tensor   6 bi_se_net_v3_tf/segmen... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   7 bi_se_net_v3_tf/segmen... kTfLiteInt32    kTfLiteMmapRo              32B ( 0.0 MB) [4,2]
Tensor   8 bi_se_net_v3_tf/sub/y;... kTfLiteFloat32  kTfLiteMmapRo              12B ( 0.0 MB) [1,1,1,3]
Tensor   9 unknown_266               kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  10 unknown_268               kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  11 unknown_270               kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  12 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  13 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  14 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  15 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  16 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  17 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  18 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  19 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  20 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  21 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  22 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  23 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  24 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  25 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  26 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  27 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  28 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  29 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  30 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  31 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  32 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  33 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  34 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  35 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  36 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  37 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  38 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  39 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  40 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  41 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  42 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  43 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              32B ( 0.0 MB) [8]
Tensor  44 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  45 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  46 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  47 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             384B ( 0.0 MB) [96]
Tensor  48 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             384B ( 0.0 MB) [96]
Tensor  49 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             384B ( 0.0 MB) [96]
Tensor  50 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  51 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  52 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  53 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo            3456B ( 0.0 MB) [32,3,3,3]
Tensor  54 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1728B ( 0.0 MB) [16,3,3,3]
Tensor  55 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [8,1,1,16]
Tensor  56 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            4608B ( 0.0 MB) [16,3,3,8]
Tensor  57 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           18432B ( 0.0 MB) [16,3,3,32]
Tensor  58 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6144B ( 0.0 MB) [96,1,1,16]
Tensor  59 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           12288B ( 0.0 MB) [32,1,1,96]
Tensor  60 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo           73728B ( 0.1 MB) [64,3,3,32]
Tensor  61 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            2048B ( 0.0 MB) [32,1,1,16]
Tensor  62 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  63 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  64 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  65 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          294912B ( 0.3 MB) [128,3,3,64]
Tensor  66 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  67 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  68 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo           65536B ( 0.1 MB) [128,1,1,128]
Tensor  69 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  70 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           24576B ( 0.0 MB) [192,1,1,32]
Tensor  71 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           24576B ( 0.0 MB) [32,1,1,192]
Tensor  72 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           24576B ( 0.0 MB) [192,1,1,32]
Tensor  73 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           49152B ( 0.0 MB) [64,1,1,192]
Tensor  74 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            8192B ( 0.0 MB) [64,1,1,32]
Tensor  75 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           98304B ( 0.1 MB) [384,1,1,64]
Tensor  76 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           98304B ( 0.1 MB) [64,1,1,384]
Tensor  77 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           98304B ( 0.1 MB) [384,1,1,64]
Tensor  78 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          196608B ( 0.2 MB) [128,1,1,384]
Tensor  79 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           32768B ( 0.0 MB) [128,1,1,64]
Tensor  80 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [768,1,1,128]
Tensor  81 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [128,1,1,768]
Tensor  82 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [768,1,1,128]
Tensor  83 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [128,1,1,768]
Tensor  84 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [768,1,1,128]
Tensor  85 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [128,1,1,768]
Tensor  86 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           65536B ( 0.1 MB) [128,1,1,128]
Tensor  87 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  88 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  89 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo           65536B ( 0.1 MB) [128,1,1,128]
Tensor  90 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  91 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo          294912B ( 0.3 MB) [64,3,3,128]
Tensor  92 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  93 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo           73728B ( 0.1 MB) [32,3,3,64]
Tensor  94 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo            1152B ( 0.0 MB) [1,3,3,32]
Tensor  95 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3456B ( 0.0 MB) [1,3,3,96]
Tensor  96 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3456B ( 0.0 MB) [1,3,3,96]
Tensor  97 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  98 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             576B ( 0.0 MB) [1,3,3,16]
Tensor  99 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor 100 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo            4608B ( 0.0 MB) [1,3,3,128]
Tensor 101 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 102 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6912B ( 0.0 MB) [1,3,3,192]
Tensor 103 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor 104 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6912B ( 0.0 MB) [1,3,3,192]
Tensor 105 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6912B ( 0.0 MB) [1,3,3,192]
Tensor 106 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor 107 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1152B ( 0.0 MB) [1,3,3,32]
Tensor 108 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor 109 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           13824B ( 0.0 MB) [1,3,3,384]
Tensor 110 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor 111 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           13824B ( 0.0 MB) [1,3,3,384]
Tensor 112 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           13824B ( 0.0 MB) [1,3,3,384]
Tensor 113 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 114 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            2304B ( 0.0 MB) [1,3,3,64]
Tensor 115 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 116 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           27648B ( 0.0 MB) [1,3,3,768]
Tensor 117 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 118 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           27648B ( 0.0 MB) [1,3,3,768]
Tensor 119 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 120 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           27648B ( 0.0 MB) [1,3,3,768]
Tensor 121 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 122 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 123 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo            4608B ( 0.0 MB) [1,3,3,128]
Tensor 124 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 125 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo               4B ( 0.0 MB) [1]
Tensor 126 bi_se_net_v3_tf/sub;St... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,224,224,3]
Tensor 127 bi_se_net_v3_tf/mul;St... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,224,224,3]
Tensor 128 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         612912B ( 0.6 MB) [1,226,226,3]
Tensor 129 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw        1605632B ( 1.5 MB) [1,112,112,32]
Tensor 130 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,112,112,16]
Tensor 131 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         831744B ( 0.8 MB) [1,114,114,16]
Tensor 132 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,56,56,16]
Tensor 133 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,112,112,8]
Tensor 134 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         415872B ( 0.4 MB) [1,114,114,8]
Tensor 135 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,56,56,16]
Tensor 136 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,56,56,32]
Tensor 137 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,56,56,16]
Tensor 138 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         215296B ( 0.2 MB) [1,58,58,16]
Tensor 139 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw        1204224B ( 1.1 MB) [1,56,56,96]
Tensor 140 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw        1291776B ( 1.2 MB) [1,58,58,96]
Tensor 141 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,28,28,96]
Tensor 142 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,28,28,96]
Tensor 143 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 144 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw        3211264B ( 3.1 MB) [1,112,112,64]
Tensor 145 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw        3326976B ( 3.2 MB) [1,114,114,64]
Tensor 146 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,28,28,16]
Tensor 147 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 148 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 149 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 150 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 151 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 152 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         861184B ( 0.8 MB) [1,58,58,64]
Tensor 153 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 154 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 155 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 156 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 157 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 158 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         460800B ( 0.4 MB) [1,30,30,128]
Tensor 159 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,14,14,128]
Tensor 160 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         131072B ( 0.1 MB) [1,16,16,128]
Tensor 161 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 162 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,28,28,192]
Tensor 163 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,28,28,192]
Tensor 164 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 165 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 166 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,28,28,192]
Tensor 167 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         691200B ( 0.7 MB) [1,30,30,192]
Tensor 168 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,14,14,192]
Tensor 169 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,14,14,192]
Tensor 170 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 171 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         115200B ( 0.1 MB) [1,30,30,32]
Tensor 172 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,14,14,32]
Tensor 173 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 174 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 175 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,14,14,384]
Tensor 176 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,14,14,384]
Tensor 177 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 178 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 179 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,14,14,384]
Tensor 180 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         393216B ( 0.4 MB) [1,16,16,384]
Tensor 181 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          75264B ( 0.1 MB) [1,7,7,384]
Tensor 182 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          75264B ( 0.1 MB) [1,7,7,384]
Tensor 183 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 184 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          65536B ( 0.1 MB) [1,16,16,64]
Tensor 185 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          12544B ( 0.0 MB) [1,7,7,64]
Tensor 186 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 187 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 188 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 189 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 190 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 191 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 192 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 193 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 194 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 195 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 196 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 197 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 198 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 199 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 200 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 201 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 202 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 203 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 204 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 205 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 206 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 207 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 208 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 209 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 210 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 211 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 212 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 213 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 214 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 215 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 216 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 217 bi_se_net_v3_tf/re_lu_... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,28,28,64]
Tensor 218 bi_se_net_v3_tf/Resize... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 219 bi_se_net_v3_tf/add;St... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 220 bi_se_net_v3_tf/re_lu_... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 221 bi_se_net_v3_tf/Resize... kTfLiteFloat32  kTfLiteArenaRw        3211264B ( 3.1 MB) [1,112,112,64]
Tensor 222 bi_se_net_v3_tf/add_1;... kTfLiteFloat32  kTfLiteArenaRw        3211264B ( 3.1 MB) [1,112,112,64]
Tensor 223 bi_se_net_v3_tf/re_lu_... kTfLiteFloat32  kTfLiteArenaRw        1605632B ( 1.5 MB) [1,112,112,32]
Tensor 224 bi_se_net_v3_tf/Resize... kTfLiteFloat32  kTfLiteArenaRw        6422528B ( 6.1 MB) [1,224,224,32]
Tensor 225 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,224,224,1]
Tensor 226 Identity                  kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,224,224,1]
Tensor 227 (nil)                     kTfLiteInt32    kTfLiteArenaRw             16B ( 0.0 MB) [4]
Tensor 228 (nil)                     kTfLiteInt32    kTfLiteArenaRw              8B ( 0.0 MB) [2]
Tensor 229 (nil)                     kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [128]
Tensor 230 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        1354752B ( 1.3 MB) [1,112,112,27]
Tensor 231 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        1354752B ( 1.3 MB) [1,112,112,27]
Tensor 232 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         903168B ( 0.9 MB) [1,56,56,72]
Tensor 233 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,56,56,288]
Tensor 234 (nil)                     kTfLiteFloat32  kTfLiteArenaRw       14450688B (13.8 MB) [1,112,112,288]
Tensor 235 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 236 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 237 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 238 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        1806336B ( 1.7 MB) [1,28,28,576]
Tensor 239 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 240 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 241 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         903168B ( 0.9 MB) [1,14,14,1152]
Tensor 242 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         225792B ( 0.2 MB) [1,7,7,1152]
Tensor 243 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         225792B ( 0.2 MB) [1,7,7,1152]
Tensor 244 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 245 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 246 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 247 (nil)                     kTfLiteFloat32  kTfLiteArenaRw       28901376B (27.6 MB) [1,112,112,576]
Tensor 248 (nil)                     kTfLiteFloat32  kTfLiteArenaRw       57802752B (55.1 MB) [1,224,224,288]

kTfLiteArenaRw Info: 
Tensor 0 has the max size 602112 bytes (0.6 MB).
This memory arena is estimated as[0x109820000, 0x10975c000), taking 0.8 MB.

kTfLiteArenaRwPersistent Info: not holding any allocation.

Node   0 Operator Builtin Code  41 SUB
  Input Tensors:[0,8]
  Output Tensors:[126]
Node   1 Operator Builtin Code  18 MUL
  Input Tensors:[126,5]
  Output Tensors:[127]
Node   2 Operator Builtin Code  34 PAD
  Input Tensors:[127,7]
  Output Tensors:[128]
Node   3 Operator Builtin Code   3 CONV_2D
  Input Tensors:[128,53,12]
  Output Tensors:[129]
  Temporary Tensors:[230]
Node   4 Operator Builtin Code   3 CONV_2D
  Input Tensors:[128,54,42]
  Output Tensors:[130]
  Temporary Tensors:[231]
Node   5 Operator Builtin Code  34 PAD
  Input Tensors:[130,7]
  Output Tensors:[131]
Node   6 Operator Builtin Code  17 MAX_POOL_2D
  Input Tensors:[131]
  Output Tensors:[132]
Node   7 Operator Builtin Code   3 CONV_2D
  Input Tensors:[130,55,43]
  Output Tensors:[133]
Node   8 Operator Builtin Code  34 PAD
  Input Tensors:[133,7]
  Output Tensors:[134]
Node   9 Operator Builtin Code   3 CONV_2D
  Input Tensors:[134,56,45]
  Output Tensors:[135]
  Temporary Tensors:[232]
Node  10 Operator Builtin Code   2 CONCATENATION
  Input Tensors:[135,132]
  Output Tensors:[136]
Node  11 Operator Builtin Code   3 CONV_2D
  Input Tensors:[136,57,46]
  Output Tensors:[137]
  Temporary Tensors:[233]
Node  12 Operator Builtin Code  34 PAD
  Input Tensors:[137,7]
  Output Tensors:[138]
Node  13 Operator Builtin Code   3 CONV_2D
  Input Tensors:[137,58,47]
  Output Tensors:[139]
Node  14 Operator Builtin Code  34 PAD
  Input Tensors:[139,7]
  Output Tensors:[140]
Node  15 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[140,95,48]
  Output Tensors:[141]
Node  16 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[141,96,49]
  Output Tensors:[142]
Node  17 Operator Builtin Code   3 CONV_2D
  Input Tensors:[142,59,97]
  Output Tensors:[143]
Node  18 Operator Builtin Code   3 CONV_2D
  Input Tensors:[129,60,44]
  Output Tensors:[144]
  Temporary Tensors:[234]
Node  19 Operator Builtin Code  34 PAD
  Input Tensors:[144,7]
  Output Tensors:[145]
Node  20 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[138,98,50]
  Output Tensors:[146]
Node  21 Operator Builtin Code   3 CONV_2D
  Input Tensors:[146,61,99]
  Output Tensors:[147]
Node  22 Operator Builtin Code   0 ADD
  Input Tensors:[143,147]
  Output Tensors:[148]
Node  23 Operator Builtin Code   3 CONV_2D
  Input Tensors:[145,62,13]
  Output Tensors:[149]
  Temporary Tensors:[235]
Node  24 Operator Builtin Code   3 CONV_2D
  Input Tensors:[149,63,20]
  Output Tensors:[150]
  Temporary Tensors:[236]
Node  25 Operator Builtin Code   3 CONV_2D
  Input Tensors:[150,64,28]
  Output Tensors:[151]
  Temporary Tensors:[237]
Node  26 Operator Builtin Code  34 PAD
  Input Tensors:[151,7]
  Output Tensors:[152]
Node  27 Operator Builtin Code   3 CONV_2D
  Input Tensors:[152,65,37]
  Output Tensors:[153]
  Temporary Tensors:[238]
Node  28 Operator Builtin Code   3 CONV_2D
  Input Tensors:[153,66,40]
  Output Tensors:[154]
  Temporary Tensors:[239]
Node  29 Operator Builtin Code   3 CONV_2D
  Input Tensors:[154,67,41]
  Output Tensors:[155]
  Temporary Tensors:[240]
Node  30 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[155,100,36]
  Output Tensors:[156]
Node  31 Operator Builtin Code   3 CONV_2D
  Input Tensors:[156,68,124]
  Output Tensors:[157]
Node  32 Operator Builtin Code  34 PAD
  Input Tensors:[155,7]
  Output Tensors:[158]
Node  33 Operator Builtin Code   3 CONV_2D
  Input Tensors:[158,69,101]
  Output Tensors:[159]
  Temporary Tensors:[241]
Node  34 Operator Builtin Code  34 PAD
  Input Tensors:[159,7]
  Output Tensors:[160]
Node  35 Operator Builtin Code   1 AVERAGE_POOL_2D
  Input Tensors:[160]
  Output Tensors:[161]
Node  36 Operator Builtin Code   3 CONV_2D
  Input Tensors:[148,70,51]
  Output Tensors:[162]
Node  37 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[162,102,52]
  Output Tensors:[163]
Node  38 Operator Builtin Code   3 CONV_2D
  Input Tensors:[163,71,103]
  Output Tensors:[164]
Node  39 Operator Builtin Code   0 ADD
  Input Tensors:[164,148]
  Output Tensors:[165]
Node  40 Operator Builtin Code   3 CONV_2D
  Input Tensors:[165,72,14]
  Output Tensors:[166]
Node  41 Operator Builtin Code  34 PAD
  Input Tensors:[166,7]
  Output Tensors:[167]
Node  42 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[167,104,15]
  Output Tensors:[168]
Node  43 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[168,105,16]
  Output Tensors:[169]
Node  44 Operator Builtin Code   3 CONV_2D
  Input Tensors:[169,73,106]
  Output Tensors:[170]
Node  45 Operator Builtin Code  34 PAD
  Input Tensors:[165,7]
  Output Tensors:[171]
Node  46 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[171,107,17]
  Output Tensors:[172]
Node  47 Operator Builtin Code   3 CONV_2D
  Input Tensors:[172,74,108]
  Output Tensors:[173]
Node  48 Operator Builtin Code   0 ADD
  Input Tensors:[170,173]
  Output Tensors:[174]
Node  49 Operator Builtin Code   3 CONV_2D
  Input Tensors:[174,75,18]
  Output Tensors:[175]
Node  50 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[175,109,19]
  Output Tensors:[176]
Node  51 Operator Builtin Code   3 CONV_2D
  Input Tensors:[176,76,110]
  Output Tensors:[177]
Node  52 Operator Builtin Code   0 ADD
  Input Tensors:[177,174]
  Output Tensors:[178]
Node  53 Operator Builtin Code   3 CONV_2D
  Input Tensors:[178,77,21]
  Output Tensors:[179]
Node  54 Operator Builtin Code  34 PAD
  Input Tensors:[179,7]
  Output Tensors:[180]
Node  55 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[180,111,22]
  Output Tensors:[181]
Node  56 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[181,112,23]
  Output Tensors:[182]
Node  57 Operator Builtin Code   3 CONV_2D
  Input Tensors:[182,78,113]
  Output Tensors:[183]
Node  58 Operator Builtin Code  34 PAD
  Input Tensors:[178,7]
  Output Tensors:[184]
Node  59 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[184,114,24]
  Output Tensors:[185]
Node  60 Operator Builtin Code   3 CONV_2D
  Input Tensors:[185,79,115]
  Output Tensors:[186]
Node  61 Operator Builtin Code   0 ADD
  Input Tensors:[183,186]
  Output Tensors:[187]
Node  62 Operator Builtin Code   3 CONV_2D
  Input Tensors:[187,80,25]
  Output Tensors:[188]
Node  63 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[188,116,26]
  Output Tensors:[189]
Node  64 Operator Builtin Code   3 CONV_2D
  Input Tensors:[189,81,117]
  Output Tensors:[190]
Node  65 Operator Builtin Code   0 ADD
  Input Tensors:[190,187]
  Output Tensors:[191]
Node  66 Operator Builtin Code   3 CONV_2D
  Input Tensors:[191,82,27]
  Output Tensors:[192]
Node  67 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[192,118,29]
  Output Tensors:[193]
Node  68 Operator Builtin Code   3 CONV_2D
  Input Tensors:[193,83,119]
  Output Tensors:[194]
Node  69 Operator Builtin Code   0 ADD
  Input Tensors:[194,191]
  Output Tensors:[195]
Node  70 Operator Builtin Code   3 CONV_2D
  Input Tensors:[195,84,30]
  Output Tensors:[196]
Node  71 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[196,120,31]
  Output Tensors:[197]
Node  72 Operator Builtin Code   3 CONV_2D
  Input Tensors:[197,85,121]
  Output Tensors:[198]
Node  73 Operator Builtin Code   0 ADD
  Input Tensors:[198,195]
  Output Tensors:[199]
Node  74 Operator Builtin Code  40 MEAN
  Input Tensors:[199,6]
  Output Tensors:[200]
  Temporary Tensors:[227,228,229]
Node  75 Operator Builtin Code  18 MUL
  Input Tensors:[200,32]
  Output Tensors:[201]
Node  76 Operator Builtin Code   0 ADD
  Input Tensors:[201,33]
  Output Tensors:[202]
Node  77 Operator Builtin Code   3 CONV_2D
  Input Tensors:[202,86,34]
  Output Tensors:[203]
Node  78 Operator Builtin Code   0 ADD
  Input Tensors:[203,199]
  Output Tensors:[204]
Node  79 Operator Builtin Code   3 CONV_2D
  Input Tensors:[204,87,35]
  Output Tensors:[205]
  Temporary Tensors:[242]
Node  80 Operator Builtin Code   3 CONV_2D
  Input Tensors:[205,88,122]
  Output Tensors:[206]
  Temporary Tensors:[243]
Node  81 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[206,4]
  Output Tensors:[207]
Node  82 Operator Builtin Code  14 LOGISTIC
  Input Tensors:[207]
  Output Tensors:[208]
Node  83 Operator Builtin Code  18 MUL
  Input Tensors:[157,208]
  Output Tensors:[209]
Node  84 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[205,123,38]
  Output Tensors:[210]
Node  85 Operator Builtin Code   3 CONV_2D
  Input Tensors:[210,89,124]
  Output Tensors:[211]
Node  86 Operator Builtin Code  14 LOGISTIC
  Input Tensors:[211]
  Output Tensors:[212]
Node  87 Operator Builtin Code  18 MUL
  Input Tensors:[161,212]
  Output Tensors:[213]
Node  88 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[213,4]
  Output Tensors:[214]
Node  89 Operator Builtin Code   0 ADD
  Input Tensors:[209,214]
  Output Tensors:[215]
Node  90 Operator Builtin Code   3 CONV_2D
  Input Tensors:[215,90,39]
  Output Tensors:[216]
  Temporary Tensors:[244]
Node  91 Operator Builtin Code   3 CONV_2D
  Input Tensors:[216,91,9]
  Output Tensors:[217]
  Temporary Tensors:[245]
Node  92 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[217,1]
  Output Tensors:[218]
Node  93 Operator Builtin Code   0 ADD
  Input Tensors:[218,151]
  Output Tensors:[219]
Node  94 Operator Builtin Code   3 CONV_2D
  Input Tensors:[219,92,10]
  Output Tensors:[220]
  Temporary Tensors:[246]
Node  95 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[220,2]
  Output Tensors:[221]
Node  96 Operator Builtin Code   0 ADD
  Input Tensors:[221,144]
  Output Tensors:[222]
Node  97 Operator Builtin Code   3 CONV_2D
  Input Tensors:[222,93,11]
  Output Tensors:[223]
  Temporary Tensors:[247]
Node  98 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[223,3]
  Output Tensors:[224]
Node  99 Operator Builtin Code   3 CONV_2D
  Input Tensors:[224,94,125]
  Output Tensors:[225]
  Temporary Tensors:[248]
Node 100 Operator Builtin Code  14 LOGISTIC
  Input Tensors:[225]
  Output Tensors:[226]
Node 101 Operator Custom Name TfLiteMetalDelegate
  Input Tensors:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125]
  Output Tensors:[226]
--------------Subgraph-0 dump has completed--------------

2021-08-03 14:53:03.492138+0800 tflite_simple_example[4144:2858180] model load and init time 17904 ms


=== Post-invoke Interpreter State Time 39 ===
Interpreter has 1 subgraphs.

-----------Subgraph-0 has 249 tensors and 102 nodes------------
Inputs: [0]
Outputs: [226]

Tensor  ID Name                      Type            AllocType                Size
Tensor   0 input_1                   kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,224,224,3]
Tensor   1 bi_se_net_v3_tf/Resize... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   2 bi_se_net_v3_tf/Resize... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   3 bi_se_net_v3_tf/Resize... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   4 bi_se_net_v3_tf/bga_la... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   5 bi_se_net_v3_tf/mul/y;... kTfLiteFloat32  kTfLiteMmapRo              12B ( 0.0 MB) [1,1,1,3]
Tensor   6 bi_se_net_v3_tf/segmen... kTfLiteInt32    kTfLiteMmapRo               8B ( 0.0 MB) [2]
Tensor   7 bi_se_net_v3_tf/segmen... kTfLiteInt32    kTfLiteMmapRo              32B ( 0.0 MB) [4,2]
Tensor   8 bi_se_net_v3_tf/sub/y;... kTfLiteFloat32  kTfLiteMmapRo              12B ( 0.0 MB) [1,1,1,3]
Tensor   9 unknown_266               kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  10 unknown_268               kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  11 unknown_270               kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  12 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  13 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  14 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  15 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  16 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  17 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  18 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  19 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  20 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  21 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  22 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  23 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1536B ( 0.0 MB) [384]
Tensor  24 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  25 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  26 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  27 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  28 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  29 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  30 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  31 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3072B ( 0.0 MB) [768]
Tensor  32 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  33 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  34 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  35 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  36 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  37 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  38 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  39 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  40 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  41 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor  42 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  43 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              32B ( 0.0 MB) [8]
Tensor  44 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor  45 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  46 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  47 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             384B ( 0.0 MB) [96]
Tensor  48 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             384B ( 0.0 MB) [96]
Tensor  49 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             384B ( 0.0 MB) [96]
Tensor  50 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo              64B ( 0.0 MB) [16]
Tensor  51 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  52 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             768B ( 0.0 MB) [192]
Tensor  53 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo            3456B ( 0.0 MB) [32,3,3,3]
Tensor  54 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1728B ( 0.0 MB) [16,3,3,3]
Tensor  55 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [8,1,1,16]
Tensor  56 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            4608B ( 0.0 MB) [16,3,3,8]
Tensor  57 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           18432B ( 0.0 MB) [16,3,3,32]
Tensor  58 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6144B ( 0.0 MB) [96,1,1,16]
Tensor  59 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           12288B ( 0.0 MB) [32,1,1,96]
Tensor  60 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo           73728B ( 0.1 MB) [64,3,3,32]
Tensor  61 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            2048B ( 0.0 MB) [32,1,1,16]
Tensor  62 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  63 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  64 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  65 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          294912B ( 0.3 MB) [128,3,3,64]
Tensor  66 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  67 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  68 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo           65536B ( 0.1 MB) [128,1,1,128]
Tensor  69 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  70 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           24576B ( 0.0 MB) [192,1,1,32]
Tensor  71 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           24576B ( 0.0 MB) [32,1,1,192]
Tensor  72 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           24576B ( 0.0 MB) [192,1,1,32]
Tensor  73 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           49152B ( 0.0 MB) [64,1,1,192]
Tensor  74 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            8192B ( 0.0 MB) [64,1,1,32]
Tensor  75 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           98304B ( 0.1 MB) [384,1,1,64]
Tensor  76 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           98304B ( 0.1 MB) [64,1,1,384]
Tensor  77 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           98304B ( 0.1 MB) [384,1,1,64]
Tensor  78 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          196608B ( 0.2 MB) [128,1,1,384]
Tensor  79 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           32768B ( 0.0 MB) [128,1,1,64]
Tensor  80 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [768,1,1,128]
Tensor  81 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [128,1,1,768]
Tensor  82 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [768,1,1,128]
Tensor  83 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [128,1,1,768]
Tensor  84 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [768,1,1,128]
Tensor  85 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          393216B ( 0.4 MB) [128,1,1,768]
Tensor  86 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           65536B ( 0.1 MB) [128,1,1,128]
Tensor  87 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  88 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  89 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo           65536B ( 0.1 MB) [128,1,1,128]
Tensor  90 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo          589824B ( 0.6 MB) [128,3,3,128]
Tensor  91 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo          294912B ( 0.3 MB) [64,3,3,128]
Tensor  92 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo          147456B ( 0.1 MB) [64,3,3,64]
Tensor  93 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo           73728B ( 0.1 MB) [32,3,3,64]
Tensor  94 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo            1152B ( 0.0 MB) [1,3,3,32]
Tensor  95 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3456B ( 0.0 MB) [1,3,3,96]
Tensor  96 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            3456B ( 0.0 MB) [1,3,3,96]
Tensor  97 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor  98 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             576B ( 0.0 MB) [1,3,3,16]
Tensor  99 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor 100 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo            4608B ( 0.0 MB) [1,3,3,128]
Tensor 101 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 102 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6912B ( 0.0 MB) [1,3,3,192]
Tensor 103 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             128B ( 0.0 MB) [32]
Tensor 104 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6912B ( 0.0 MB) [1,3,3,192]
Tensor 105 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            6912B ( 0.0 MB) [1,3,3,192]
Tensor 106 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor 107 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            1152B ( 0.0 MB) [1,3,3,32]
Tensor 108 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor 109 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           13824B ( 0.0 MB) [1,3,3,384]
Tensor 110 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             256B ( 0.0 MB) [64]
Tensor 111 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           13824B ( 0.0 MB) [1,3,3,384]
Tensor 112 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           13824B ( 0.0 MB) [1,3,3,384]
Tensor 113 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 114 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo            2304B ( 0.0 MB) [1,3,3,64]
Tensor 115 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 116 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           27648B ( 0.0 MB) [1,3,3,768]
Tensor 117 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 118 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           27648B ( 0.0 MB) [1,3,3,768]
Tensor 119 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 120 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo           27648B ( 0.0 MB) [1,3,3,768]
Tensor 121 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 122 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 123 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo            4608B ( 0.0 MB) [1,3,3,128]
Tensor 124 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteMmapRo             512B ( 0.0 MB) [128]
Tensor 125 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteMmapRo               4B ( 0.0 MB) [1]
Tensor 126 bi_se_net_v3_tf/sub;St... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,224,224,3]
Tensor 127 bi_se_net_v3_tf/mul;St... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,224,224,3]
Tensor 128 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         612912B ( 0.6 MB) [1,226,226,3]
Tensor 129 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw        1605632B ( 1.5 MB) [1,112,112,32]
Tensor 130 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,112,112,16]
Tensor 131 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         831744B ( 0.8 MB) [1,114,114,16]
Tensor 132 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,56,56,16]
Tensor 133 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,112,112,8]
Tensor 134 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         415872B ( 0.4 MB) [1,114,114,8]
Tensor 135 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,56,56,16]
Tensor 136 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,56,56,32]
Tensor 137 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,56,56,16]
Tensor 138 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         215296B ( 0.2 MB) [1,58,58,16]
Tensor 139 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw        1204224B ( 1.1 MB) [1,56,56,96]
Tensor 140 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw        1291776B ( 1.2 MB) [1,58,58,96]
Tensor 141 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,28,28,96]
Tensor 142 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,28,28,96]
Tensor 143 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 144 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw        3211264B ( 3.1 MB) [1,112,112,64]
Tensor 145 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw        3326976B ( 3.2 MB) [1,114,114,64]
Tensor 146 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,28,28,16]
Tensor 147 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 148 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 149 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 150 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 151 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 152 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         861184B ( 0.8 MB) [1,58,58,64]
Tensor 153 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 154 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 155 bi_se_net_v3_tf/detail... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 156 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 157 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 158 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         460800B ( 0.4 MB) [1,30,30,128]
Tensor 159 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,14,14,128]
Tensor 160 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         131072B ( 0.1 MB) [1,16,16,128]
Tensor 161 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 162 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,28,28,192]
Tensor 163 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,28,28,192]
Tensor 164 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 165 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         100352B ( 0.1 MB) [1,28,28,32]
Tensor 166 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         602112B ( 0.6 MB) [1,28,28,192]
Tensor 167 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         691200B ( 0.7 MB) [1,30,30,192]
Tensor 168 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,14,14,192]
Tensor 169 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,14,14,192]
Tensor 170 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 171 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         115200B ( 0.1 MB) [1,30,30,32]
Tensor 172 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,14,14,32]
Tensor 173 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 174 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 175 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,14,14,384]
Tensor 176 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,14,14,384]
Tensor 177 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 178 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          50176B ( 0.0 MB) [1,14,14,64]
Tensor 179 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         301056B ( 0.3 MB) [1,14,14,384]
Tensor 180 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         393216B ( 0.4 MB) [1,16,16,384]
Tensor 181 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          75264B ( 0.1 MB) [1,7,7,384]
Tensor 182 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          75264B ( 0.1 MB) [1,7,7,384]
Tensor 183 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 184 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          65536B ( 0.1 MB) [1,16,16,64]
Tensor 185 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          12544B ( 0.0 MB) [1,7,7,64]
Tensor 186 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 187 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 188 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 189 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 190 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 191 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 192 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 193 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 194 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 195 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 196 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 197 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw         150528B ( 0.1 MB) [1,7,7,768]
Tensor 198 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 199 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 200 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 201 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 202 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 203 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [1,1,1,128]
Tensor 204 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 205 bi_se_net_v3_tf/segmen... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 206 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 207 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 208 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 209 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 210 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 211 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 212 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 213 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw          25088B ( 0.0 MB) [1,7,7,128]
Tensor 214 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 215 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 216 bi_se_net_v3_tf/bga_la... kTfLiteFloat32  kTfLiteArenaRw         401408B ( 0.4 MB) [1,28,28,128]
Tensor 217 bi_se_net_v3_tf/re_lu_... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,28,28,64]
Tensor 218 bi_se_net_v3_tf/Resize... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 219 bi_se_net_v3_tf/add;St... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 220 bi_se_net_v3_tf/re_lu_... kTfLiteFloat32  kTfLiteArenaRw         802816B ( 0.8 MB) [1,56,56,64]
Tensor 221 bi_se_net_v3_tf/Resize... kTfLiteFloat32  kTfLiteArenaRw        3211264B ( 3.1 MB) [1,112,112,64]
Tensor 222 bi_se_net_v3_tf/add_1;... kTfLiteFloat32  kTfLiteArenaRw        3211264B ( 3.1 MB) [1,112,112,64]
Tensor 223 bi_se_net_v3_tf/re_lu_... kTfLiteFloat32  kTfLiteArenaRw        1605632B ( 1.5 MB) [1,112,112,32]
Tensor 224 bi_se_net_v3_tf/Resize... kTfLiteFloat32  kTfLiteArenaRw        6422528B ( 6.1 MB) [1,224,224,32]
Tensor 225 bi_se_net_v3_tf/conv2d... kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,224,224,1]
Tensor 226 Identity                  kTfLiteFloat32  kTfLiteArenaRw         200704B ( 0.2 MB) [1,224,224,1]
Tensor 227 (nil)                     kTfLiteInt32    kTfLiteArenaRw             16B ( 0.0 MB) [4]
Tensor 228 (nil)                     kTfLiteInt32    kTfLiteArenaRw              8B ( 0.0 MB) [2]
Tensor 229 (nil)                     kTfLiteFloat32  kTfLiteArenaRw            512B ( 0.0 MB) [128]
Tensor 230 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        1354752B ( 1.3 MB) [1,112,112,27]
Tensor 231 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        1354752B ( 1.3 MB) [1,112,112,27]
Tensor 232 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         903168B ( 0.9 MB) [1,56,56,72]
Tensor 233 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,56,56,288]
Tensor 234 (nil)                     kTfLiteFloat32  kTfLiteArenaRw       14450688B (13.8 MB) [1,112,112,288]
Tensor 235 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 236 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 237 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 238 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        1806336B ( 1.7 MB) [1,28,28,576]
Tensor 239 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 240 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 241 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         903168B ( 0.9 MB) [1,14,14,1152]
Tensor 242 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         225792B ( 0.2 MB) [1,7,7,1152]
Tensor 243 (nil)                     kTfLiteFloat32  kTfLiteArenaRw         225792B ( 0.2 MB) [1,7,7,1152]
Tensor 244 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 245 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        3612672B ( 3.4 MB) [1,28,28,1152]
Tensor 246 (nil)                     kTfLiteFloat32  kTfLiteArenaRw        7225344B ( 6.9 MB) [1,56,56,576]
Tensor 247 (nil)                     kTfLiteFloat32  kTfLiteArenaRw       28901376B (27.6 MB) [1,112,112,576]
Tensor 248 (nil)                     kTfLiteFloat32  kTfLiteArenaRw       57802752B (55.1 MB) [1,224,224,288]

kTfLiteArenaRw Info: 
Tensor 0 has the max size 602112 bytes (0.6 MB).
This memory arena is estimated as[0x109820000, 0x10975c000), taking 0.8 MB.

kTfLiteArenaRwPersistent Info: not holding any allocation.

Node   0 Operator Builtin Code  41 SUB
  Input Tensors:[0,8]
  Output Tensors:[126]
Node   1 Operator Builtin Code  18 MUL
  Input Tensors:[126,5]
  Output Tensors:[127]
Node   2 Operator Builtin Code  34 PAD
  Input Tensors:[127,7]
  Output Tensors:[128]
Node   3 Operator Builtin Code   3 CONV_2D
  Input Tensors:[128,53,12]
  Output Tensors:[129]
  Temporary Tensors:[230]
Node   4 Operator Builtin Code   3 CONV_2D
  Input Tensors:[128,54,42]
  Output Tensors:[130]
  Temporary Tensors:[231]
Node   5 Operator Builtin Code  34 PAD
  Input Tensors:[130,7]
  Output Tensors:[131]
Node   6 Operator Builtin Code  17 MAX_POOL_2D
  Input Tensors:[131]
  Output Tensors:[132]
Node   7 Operator Builtin Code   3 CONV_2D
  Input Tensors:[130,55,43]
  Output Tensors:[133]
Node   8 Operator Builtin Code  34 PAD
  Input Tensors:[133,7]
  Output Tensors:[134]
Node   9 Operator Builtin Code   3 CONV_2D
  Input Tensors:[134,56,45]
  Output Tensors:[135]
  Temporary Tensors:[232]
Node  10 Operator Builtin Code   2 CONCATENATION
  Input Tensors:[135,132]
  Output Tensors:[136]
Node  11 Operator Builtin Code   3 CONV_2D
  Input Tensors:[136,57,46]
  Output Tensors:[137]
  Temporary Tensors:[233]
Node  12 Operator Builtin Code  34 PAD
  Input Tensors:[137,7]
  Output Tensors:[138]
Node  13 Operator Builtin Code   3 CONV_2D
  Input Tensors:[137,58,47]
  Output Tensors:[139]
Node  14 Operator Builtin Code  34 PAD
  Input Tensors:[139,7]
  Output Tensors:[140]
Node  15 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[140,95,48]
  Output Tensors:[141]
Node  16 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[141,96,49]
  Output Tensors:[142]
Node  17 Operator Builtin Code   3 CONV_2D
  Input Tensors:[142,59,97]
  Output Tensors:[143]
Node  18 Operator Builtin Code   3 CONV_2D
  Input Tensors:[129,60,44]
  Output Tensors:[144]
  Temporary Tensors:[234]
Node  19 Operator Builtin Code  34 PAD
  Input Tensors:[144,7]
  Output Tensors:[145]
Node  20 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[138,98,50]
  Output Tensors:[146]
Node  21 Operator Builtin Code   3 CONV_2D
  Input Tensors:[146,61,99]
  Output Tensors:[147]
Node  22 Operator Builtin Code   0 ADD
  Input Tensors:[143,147]
  Output Tensors:[148]
Node  23 Operator Builtin Code   3 CONV_2D
  Input Tensors:[145,62,13]
  Output Tensors:[149]
  Temporary Tensors:[235]
Node  24 Operator Builtin Code   3 CONV_2D
  Input Tensors:[149,63,20]
  Output Tensors:[150]
  Temporary Tensors:[236]
Node  25 Operator Builtin Code   3 CONV_2D
  Input Tensors:[150,64,28]
  Output Tensors:[151]
  Temporary Tensors:[237]
Node  26 Operator Builtin Code  34 PAD
  Input Tensors:[151,7]
  Output Tensors:[152]
Node  27 Operator Builtin Code   3 CONV_2D
  Input Tensors:[152,65,37]
  Output Tensors:[153]
  Temporary Tensors:[238]
Node  28 Operator Builtin Code   3 CONV_2D
  Input Tensors:[153,66,40]
  Output Tensors:[154]
  Temporary Tensors:[239]
Node  29 Operator Builtin Code   3 CONV_2D
  Input Tensors:[154,67,41]
  Output Tensors:[155]
  Temporary Tensors:[240]
Node  30 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[155,100,36]
  Output Tensors:[156]
Node  31 Operator Builtin Code   3 CONV_2D
  Input Tensors:[156,68,124]
  Output Tensors:[157]
Node  32 Operator Builtin Code  34 PAD
  Input Tensors:[155,7]
  Output Tensors:[158]
Node  33 Operator Builtin Code   3 CONV_2D
  Input Tensors:[158,69,101]
  Output Tensors:[159]
  Temporary Tensors:[241]
Node  34 Operator Builtin Code  34 PAD
  Input Tensors:[159,7]
  Output Tensors:[160]
Node  35 Operator Builtin Code   1 AVERAGE_POOL_2D
  Input Tensors:[160]
  Output Tensors:[161]
Node  36 Operator Builtin Code   3 CONV_2D
  Input Tensors:[148,70,51]
  Output Tensors:[162]
Node  37 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[162,102,52]
  Output Tensors:[163]
Node  38 Operator Builtin Code   3 CONV_2D
  Input Tensors:[163,71,103]
  Output Tensors:[164]
Node  39 Operator Builtin Code   0 ADD
  Input Tensors:[164,148]
  Output Tensors:[165]
Node  40 Operator Builtin Code   3 CONV_2D
  Input Tensors:[165,72,14]
  Output Tensors:[166]
Node  41 Operator Builtin Code  34 PAD
  Input Tensors:[166,7]
  Output Tensors:[167]
Node  42 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[167,104,15]
  Output Tensors:[168]
Node  43 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[168,105,16]
  Output Tensors:[169]
Node  44 Operator Builtin Code   3 CONV_2D
  Input Tensors:[169,73,106]
  Output Tensors:[170]
Node  45 Operator Builtin Code  34 PAD
  Input Tensors:[165,7]
  Output Tensors:[171]
Node  46 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[171,107,17]
  Output Tensors:[172]
Node  47 Operator Builtin Code   3 CONV_2D
  Input Tensors:[172,74,108]
  Output Tensors:[173]
Node  48 Operator Builtin Code   0 ADD
  Input Tensors:[170,173]
  Output Tensors:[174]
Node  49 Operator Builtin Code   3 CONV_2D
  Input Tensors:[174,75,18]
  Output Tensors:[175]
Node  50 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[175,109,19]
  Output Tensors:[176]
Node  51 Operator Builtin Code   3 CONV_2D
  Input Tensors:[176,76,110]
  Output Tensors:[177]
Node  52 Operator Builtin Code   0 ADD
  Input Tensors:[177,174]
  Output Tensors:[178]
Node  53 Operator Builtin Code   3 CONV_2D
  Input Tensors:[178,77,21]
  Output Tensors:[179]
Node  54 Operator Builtin Code  34 PAD
  Input Tensors:[179,7]
  Output Tensors:[180]
Node  55 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[180,111,22]
  Output Tensors:[181]
Node  56 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[181,112,23]
  Output Tensors:[182]
Node  57 Operator Builtin Code   3 CONV_2D
  Input Tensors:[182,78,113]
  Output Tensors:[183]
Node  58 Operator Builtin Code  34 PAD
  Input Tensors:[178,7]
  Output Tensors:[184]
Node  59 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[184,114,24]
  Output Tensors:[185]
Node  60 Operator Builtin Code   3 CONV_2D
  Input Tensors:[185,79,115]
  Output Tensors:[186]
Node  61 Operator Builtin Code   0 ADD
  Input Tensors:[183,186]
  Output Tensors:[187]
Node  62 Operator Builtin Code   3 CONV_2D
  Input Tensors:[187,80,25]
  Output Tensors:[188]
Node  63 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[188,116,26]
  Output Tensors:[189]
Node  64 Operator Builtin Code   3 CONV_2D
  Input Tensors:[189,81,117]
  Output Tensors:[190]
Node  65 Operator Builtin Code   0 ADD
  Input Tensors:[190,187]
  Output Tensors:[191]
Node  66 Operator Builtin Code   3 CONV_2D
  Input Tensors:[191,82,27]
  Output Tensors:[192]
Node  67 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[192,118,29]
  Output Tensors:[193]
Node  68 Operator Builtin Code   3 CONV_2D
  Input Tensors:[193,83,119]
  Output Tensors:[194]
Node  69 Operator Builtin Code   0 ADD
  Input Tensors:[194,191]
  Output Tensors:[195]
Node  70 Operator Builtin Code   3 CONV_2D
  Input Tensors:[195,84,30]
  Output Tensors:[196]
Node  71 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[196,120,31]
  Output Tensors:[197]
Node  72 Operator Builtin Code   3 CONV_2D
  Input Tensors:[197,85,121]
  Output Tensors:[198]
Node  73 Operator Builtin Code   0 ADD
  Input Tensors:[198,195]
  Output Tensors:[199]
Node  74 Operator Builtin Code  40 MEAN
  Input Tensors:[199,6]
  Output Tensors:[200]
  Temporary Tensors:[227,228,229]
Node  75 Operator Builtin Code  18 MUL
  Input Tensors:[200,32]
  Output Tensors:[201]
Node  76 Operator Builtin Code   0 ADD
  Input Tensors:[201,33]
  Output Tensors:[202]
Node  77 Operator Builtin Code   3 CONV_2D
  Input Tensors:[202,86,34]
  Output Tensors:[203]
Node  78 Operator Builtin Code   0 ADD
  Input Tensors:[203,199]
  Output Tensors:[204]
Node  79 Operator Builtin Code   3 CONV_2D
  Input Tensors:[204,87,35]
  Output Tensors:[205]
  Temporary Tensors:[242]
Node  80 Operator Builtin Code   3 CONV_2D
  Input Tensors:[205,88,122]
  Output Tensors:[206]
  Temporary Tensors:[243]
Node  81 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[206,4]
  Output Tensors:[207]
Node  82 Operator Builtin Code  14 LOGISTIC
  Input Tensors:[207]
  Output Tensors:[208]
Node  83 Operator Builtin Code  18 MUL
  Input Tensors:[157,208]
  Output Tensors:[209]
Node  84 Operator Builtin Code   4 DEPTHWISE_CONV_2D
  Input Tensors:[205,123,38]
  Output Tensors:[210]
Node  85 Operator Builtin Code   3 CONV_2D
  Input Tensors:[210,89,124]
  Output Tensors:[211]
Node  86 Operator Builtin Code  14 LOGISTIC
  Input Tensors:[211]
  Output Tensors:[212]
Node  87 Operator Builtin Code  18 MUL
  Input Tensors:[161,212]
  Output Tensors:[213]
Node  88 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[213,4]
  Output Tensors:[214]
Node  89 Operator Builtin Code   0 ADD
  Input Tensors:[209,214]
  Output Tensors:[215]
Node  90 Operator Builtin Code   3 CONV_2D
  Input Tensors:[215,90,39]
  Output Tensors:[216]
  Temporary Tensors:[244]
Node  91 Operator Builtin Code   3 CONV_2D
  Input Tensors:[216,91,9]
  Output Tensors:[217]
  Temporary Tensors:[245]
Node  92 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[217,1]
  Output Tensors:[218]
Node  93 Operator Builtin Code   0 ADD
  Input Tensors:[218,151]
  Output Tensors:[219]
Node  94 Operator Builtin Code   3 CONV_2D
  Input Tensors:[219,92,10]
  Output Tensors:[220]
  Temporary Tensors:[246]
Node  95 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[220,2]
  Output Tensors:[221]
Node  96 Operator Builtin Code   0 ADD
  Input Tensors:[221,144]
  Output Tensors:[222]
Node  97 Operator Builtin Code   3 CONV_2D
  Input Tensors:[222,93,11]
  Output Tensors:[223]
  Temporary Tensors:[247]
Node  98 Operator Builtin Code  23 RESIZE_BILINEAR
  Input Tensors:[223,3]
  Output Tensors:[224]
Node  99 Operator Builtin Code   3 CONV_2D
  Input Tensors:[224,94,125]
  Output Tensors:[225]
  Temporary Tensors:[248]
Node 100 Operator Builtin Code  14 LOGISTIC
  Input Tensors:[225]
  Output Tensors:[226]
Node 101 Operator Custom Name TfLiteMetalDelegate
  Input Tensors:[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125]
  Output Tensors:[226]
--------------Subgraph-0 dump has completed--------------

**Describe the expected behavior**
CPU GPU delegate has the same output
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51115,TFLite flex delegate on x86_64 failed to link,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: 3.8.10
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 4.1.0
- GCC/Compiler version (if compiling from source): 11.1.0
- CUDA/cuDNN version: 11.4
- GPU model and memory: RTX 2080Ti 11GB



**Describe the problem**

I am trying to compile the C++ API of flex delegate on x86_64 desktop but failed due to link errors (see below). But if i compile the same target with option `--config=android_arm64` everything runs smoothly. I am wondering if the C++ API of flex delegate is supported and if it is how to avoid the link errors. The log file is attached below. Please kindly check it. Thanks!

Compiling

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel build --compilation_mode=opt --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 --experimental_ui_max_stdouterr_bytes=1073741819 -- //tensorflow/lite/delegates/flex:libtensorflowlite_flex.so`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[tflite_flex.log](https://github.com/tensorflow/tensorflow/files/6919287/tflite_flex.log)
"
51099,"2.6.0rc1 regression: isinstance(layer, Layer) no longer works. Affects: `keras.layers.Wrapper`","Hello,
  One of the CI tests in the [R interface to keras](https://github.com/rstudio/keras) surfaced this regression in 2.6.0rc1: 
  `tf.keras.layers.Wrapper` seemingly doesn't work the way it used to.
  
Specifically, this assertion is being raised where it wasn't before:

https://github.com/tensorflow/tensorflow/blob/8406c010e1793f458a9fd5d73404c1a93689bcfc/tensorflow/python/keras/layers/wrappers.py#L50


Tracking this down, it seems this is a minimal example in the change in behavior:
```python
import tensorflow as tf

from tensorflow.python.keras.engine.base_layer import Layer
layer = tf.keras.layers.Dense(1)

isinstance(layer, Layer) # True with 2.5.0, False with 2.6.0rc1
```
    
"
51098,AttributeError: '_UserObject' object has no attribute 'add_slot' ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below):v2.6.0-rc1-12-gb61c987109e 2.6.0-rc1
- Python version:3.8.5 
- Bazel version (if compiling from source):3.7.2
- GCC/Compiler version (if compiling from source):7.5.0 
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
git checkout r2.6
build the source (CPU only), install, generate mnist model, then try to convert it, has issue.

1. install
sudo apt install python3-dev python3-pip
pip install -U --user pip numpy wheel
pip install -U --user keras_preprocessing --no-deps

bazel build //tensorflow/tools/pip_package:build_pip_package
./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
pip install /tmp/tensorflow_pkg/tensorflow-2.6.0rc1-cp38-cp38-linux_x86_64.whl

pip install tensorflow-model-optimization

2. generate model: refer to below code
3. convert:
bazel-bin/tensorflow/lite/python/tflite_convert --saved_model_dir mnist_qat_notdocker/float_model/ --output_file oo

error message:
...
  File ""/home/tensorflow2/tensorflow/bazel-bin/tensorflow/lite/python/tflite_convert.runfiles/org_tensorflow/tensorflow/python/saved_model/load.py"", line 448, in _load_nodes
    slot_variable = optimizer_object.add_slot(
AttributeError: '_UserObject' object has no attribute 'add_slot'

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

import tempfile
import os

import tensorflow as tf
from tensorflow import keras

# Load MNIST dataset
mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture.
model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(
  train_images,
  train_labels,
  epochs=1,
  validation_split=0.1,
)

model.save('mnist_qat_notdocker/float_model')

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51097,Parameter description generating weirdly in `tf.keras.metrics.AUC`,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/metrics/AUC

## Description of issue (what needs changing):

The description for `num_labels` is generating weirdly:
![Screen Shot 2021-08-02 at 9 30 05 AM](https://user-images.githubusercontent.com/29757116/127869653-5cc9728d-9c29-4de2-9c85-f8452fb1eaa1.png)
"
51096,Can't save custom layers to .h5 file !,"<em>Can't save custom layers to .h5 file !</em>

**Can't save !**
I use tensorflow 2.4.1, this code works very well, but it can't save to .h5 file. I have tried Sequential() method, but it not working. I want to ask which approch should I adopt it. I have add get_config params, and which not working in my network that is very puzzle me. I don't know what cause this problem, can somebody tell me, thank you very much.
Please note that `tf.keras` code was moved entirely to
```
class MultiSpectralAttentionLayer(layers.Layer):
def __init__(self, reduction=16, freq_sel_method='top16'):
    super(MultiSpectralAttentionLayer, self).__init__()
    self.reduction = 16
    self.freq_sel_method = freq_sel_method

def build(self, input_shape):
    _, h, w, c = input_shape
    self.channel = int(c)
    self.reduction = self.reduction
    self.fc1 = layers.Dense(self.channel / self.reduction, use_bias=True, activation='relu')
    self.fc2 = layers.Dense(self.channel, use_bias=True, activation='sigmoid')
    self.reshapeTensor = tf.keras.layers.Reshape((1, 1, c))
    self.mapper_x, self.mapper_y = self.get_freq_indices(self.freq_sel_method)
    self.dynamic_weight = tf.Variable(self.get_dct_filter(h, w, self.mapper_x, self.mapper_y, channel=c))
    self.mapper_x = [temp_x * (h // 7) for temp_x in self.mapper_x]
    self.mapper_y = [temp_y * (2 // 7) for temp_y in self.mapper_y]

    super().build(input_shape)

def get_freq_indices(self, methods):
    assert methods in ['top1', 'top2', 'top4', 'top8', 'top16', 'top32',
                       'bot1', 'bot2', 'bot4', 'bot8', 'bot16', 'bot32',
                       'low1', 'low2', 'low4', 'low8', 'low16', 'low32']
    num_freq = int(methods[3:])

    if 'top' in methods:
        all_top_indices_x = [0, 0, 6, 0, 0, 1, 1, 4, 5, 1, 3, 0, 0, 0, 3, 2, 4, 6, 3, 5, 5, 2, 6, 5, 5, 3, 3, 4, 2,
                             2,
                             6, 1]
        all_top_indices_y = [0, 1, 0, 5, 2, 0, 2, 0, 0, 6, 0, 4, 6, 3, 5, 2, 6, 3, 3, 3, 5, 1, 1, 2, 4, 2, 1, 1, 3,
                             0,
                             5, 3]
        mapper_x = all_top_indices_x[:num_freq]
        mapper_y = all_top_indices_y[:num_freq]

    elif 'low' in methods:
        all_low_indices_x = [0, 0, 1, 1, 0, 2, 2, 1, 2, 0, 3, 4, 0, 1, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 1,
                             2,
                             3, 4]

        all_low_indices_y = [0, 1, 0, 1, 2, 0, 1, 2, 2, 3, 0, 0, 4, 3, 1, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6,
                             5,
                             4, 3]

        mapper_x = all_low_indices_x[:num_freq]
        mapper_y = all_low_indices_y[:num_freq]

    elif 'bot' in methods:
        all_bot_indices_x = [6, 1, 3, 3, 2, 4, 1, 2, 4, 4, 5, 1, 4, 6, 2, 5, 6, 1, 6, 2, 2, 4, 3, 3, 5, 5, 6, 2, 5,
                             5,
                             3, 6]
        all_bot_indices_y = [6, 4, 4, 6, 6, 3, 1, 4, 4, 5, 6, 5, 2, 2, 5, 1, 4, 3, 5, 0, 3, 1, 1, 2, 4, 2, 1, 1, 5,
                             3,
                             3, 3]
        mapper_x = all_bot_indices_x[:num_freq]
        mapper_y = all_bot_indices_y[:num_freq]
    else:
        raise NotImplementedError
    return mapper_x, mapper_y

def get_dct_filter(self, tile_size_x, tile_size_y, mapper_x, mapper_y, channel):
    dct_numpy_filter = np.zeros(shape=(tile_size_y, tile_size_x, channel), dtype=np.float32)
    c_part = channel // len(mapper_x)

    for i, (u_x, u_y) in enumerate(zip(mapper_x, mapper_y)):
        for t_x in range(tile_size_x):
            for t_y in range(tile_size_y):
                dct_numpy_filter[t_y, t_x, i * c_part: (i + 1) * c_part] = self.build_filter(t_x, u_x, tile_size_x) * \
                                                                           self.build_filter(t_y, u_y, tile_size_y)
    return dct_numpy_filter


def build_filter(self, pos, frequency, POS):
    result = np.cos(np.pi * frequency * (pos + 0.5) / POS) / np.sqrt(POS)
    if frequency == 0:
        return result
    else:
        return result * np.sqrt(2)


def get_config(self):
    base_config = super(MultiSpectralAttentionLayer, self).get_config()
    config = {
        ""reduction"": self.reduction,
        ""freq_sel_method"": self.freq_sel_method,
    }
    return dict(list(base_config.items()) + list(config.items()))


@tf.function
def call(self, inputs, training=None):
    x = inputs * self.dynamic_weight
    result = tf.math.reduce_sum(x, axis=[1, 2], keepdims=True)
    x = self.fc1(result)
    x = self.fc2(x)
    x = self.reshapeTensor(x)
    return inputs * x
```

**I use the following code to inference images, but it not working.**

```
    def load_trained_model():
    _custom_objects = {
    ""SeBlock"" : SeBlock,
    ""MultiSpectralAttentionLayer"": MultiSpectralAttentionLayer,
}
    model_name = r""F:\log\ablation\model.01-3.4231-1.h5""  
    function_model = load_model(model_name, custom_objects=_custom_objects)
    print('model load success')
    return function_model
```

The error message is "" init() got an unexpected keyword argument 'name' "". I have assigned names to this custom layers each times.

The code is re-implement FcaNet -->**https://github.com/cfzd/FcaNet/blob/aa5fb63505575bb4e4e094613565379c3f6ada33/model/layer.py#L29**.
"
51093,Conv2DTranspose in Hexagon delegate crash,"**System information**

* Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
MacOS, Ubuntu...
* TensorFlow installed from (source or binary):
source
* Tensorflow version (commit SHA if source):
Tag v2.5.0
* Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
Android

**Describe the problem**

When I run my tflite quantized model on my mobile device's DSP, I get a crash:

`ERROR: Bias/channel scales number mismatch for bias tensor: model/conv2d_3/BiasAdd;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d_3/Conv2D`
`Segmentation fault`

The crash occurs in Hexagon delegate, in the recently added code related to Transposed Convolution with bias.
The crash does NOT occur if I set use_bias=False to Conv2DTranspose

The error log comes from the ProcessPerChannelQuantizedBias() method in conv_2d_helpers.cc file.

See attached a small sample code that creates a model reproducing the crash.

[model.zip](https://github.com/tensorflow/tensorflow/files/6916360/model.zip)

`inputs = keras.layers.Input(shape=(128, 128, 1))`
`x = keras.layers.Conv2D(96, kernel_size=2, strides=2, padding='valid')(inputs)`
`x = keras.layers.Conv2D(96, kernel_size=2, strides=2, padding='valid')(x)`
`x = keras.layers.Conv2D(96, kernel_size=2, strides=2, padding='valid')(x)`
`x = keras.layers.Conv2D(96, kernel_size=2, strides=2, padding='valid')(x)`
`outputs = keras.layers.Conv2DTranspose(16, kernel_size=2, strides=2, use_bias=True)(x)`
`model = keras.Model(inputs=inputs, outputs=outputs)`

The crash can be easily reproduced with the benchmark tool:

`> benchmark_model --graph=model.tflite --input_layer=normalized_input_image_tensor --input_layer_shape=1,128,128,1 --warmup_runs=100 --num_runs=1000 --run_delay=0 --num_threads=4 --use_hexagon=true --enable_op_profiling=false`

`STARTING!`
`Log parameter values verbosely: [0]`
`Min num runs: [1000]`
`Inter-run delay (seconds): [0]`
`Num threads: [4]`
`Min warmup runs: [100]`
`Graph: [model.tflite]`
`Input layers: [normalized_input_image_tensor]`
`Input shapes: [1,128,128,1]`
`Enable op profiling: [0]`
`#threads used for CPU inference: [4]`
`Use Hexagon: [1]`
`Loaded model model.tflite`
`INFO: Initialized TensorFlow Lite runtime.`
`INFO: TfLiteHexagonDelegate delegate: 5 nodes delegated out of 5 nodes with 1 partitions.`

`ERROR: Bias/channel scales number mismatch for bias tensor: 
model/conv2d_3/BiasAdd;model/conv2d/BiasAdd/ReadVariableOp/resource;model/conv2d_3/Conv2D`
`Segmentation fault`
"
51092,Sparse matmul and element-wise multiply,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tf2.5
- Are you willing to contribute it (Yes/No): yes



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?** No

**Who will benefit with this feature?** Users who need sparse calculation, but with limited memory resources and so big the dimension of data.

**Any Other info.**

1. If `a` is a sparse column vector`(n*1)`, then how to get the result of `a matmul a.T`, which is also the sparse matrix with dense_shape `(n*n)` but unable to be stored in the memory? 
2. If A and B are both the sparse matrix with dense_shape of `(n*n)`,  then how to calculate the result of `A multiply B`(element-wise), and how to calculate `A matmul B`, the result of which are both sparse matrix with dense shape` (n*n)`? 


"
51091,How to collect code coverage of C++ code when running Python tests?,"I am trying to figure out the way to get the code coverage of C++ code for tests written in Python. I know that `coverage` is the package to measure code coverage of Python code for tests that run in Python.
Also, it appears to me that `bazel` is the build system for C++ projects, and `bazel coverage` can collect the C++ code coverage for C++ tests.

If there is anything wrong with my previous findings, please feel free to point out!

I am currently looking for the way to collect the code coverage of C++ when running Python code. Is there any potential ways? Thanks!"
51090,Single scalar ground truth for a batch?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
When calling `model.fit(X)` where `X` is a generator giving the input and ground truth of batches, the ground truth has to be a vector (otherwise it emits error). However, in some case, I want to train a model with a single scalar ground truth for a batch. I would like to aggregate the prediction of the batch into a single scalar and compare it with the single scalar ground truth.  

**Will this change the current api? How?**
It would make the API more permissible. `fit()` would allow the ground truth for a batch to be a single scalar.

**Who will benefit with this feature?**
Those want to train a model with a single scalar ground truth for a batch. 

**Any Other info.**
I don't see why this is not allowed. The ground truth is only used in loss calculation, and it should be fine to be a single scalar as long as the user loss function can handle that.
Currently I simply zero-pad `y_true` into a vector and only use `y_true[0]` in loss calculation."
51089,16x8 quantization mode & TFLite Micro,"### 1. System information

- OS Platform Ubuntu 20.04
- TensorFlow installation : pip package
- TensorFlow library 2.5.0

Hi, 
I'm using 16x8 experimental quantization on my model.
I convert my model after I follow instructions on the tflite 16x8 info page, i also set:
converter_fp.inference_input_type = tf.int16
converter_fp.inference_output_type = tf.int16

When I invoke the converted model from Jupyter Notebook everything works fine.

When I transfer the converted model to TFLite Micro then I get the following error:
../src/tensorflow/lite/micro/kernels/fully_connected.cc Hybrid models are not supported on TFLite Micro.
input->type is kTfLiteInt16
filter->type is kTfLiteInt8

Is there a way to make this work? And if not, when is this functionality expected to be available on TFLite Micro?

Thanks and Best Regards,
Alex
"
51088,RTX30 series: unsupported compute compability for CUDA 9.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Ubuntu 20.04
- TensorFlow installed from: source 
- TensorFlow version: 1.10
- Python version: 3.6
- Installed using virtualenv? pip? conda?: building, not installed yet
- Bazel version: 0.15
- GCC/Compiler version (if compiling from source): 4.8
- CUDA/cuDNN version: 9.0/7.1.2
- GPU model and memory: RTX3060*4, 64GB



**Describe the problem**

I'm trying to build TensorFlow 1.10 from source, with compute compatibility of 3060 assigned. The building process failed at : 
```
ERROR: /home/yulab/packages_software/tensorflow-r1.10/tensorflow/core/kernels/BUILD:3699:1:error while parsing .d file: /home/yulab/.cache/bazel/_bazel_yulab/0ab03e3c981f656d0173f64ae90fcc89/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/core/kernals/_objs/batch_space_ops_gpu/tensorflow/core/kernels/spacetobatch_functor_gpu.cu.pic.d (No such file or directory)
nvcc fatal: unsupported GPU architecture 'compute_86'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```
I manually assigned compute compatibility of 3060 in compile options,  but seems CUDA 9.0 does not support it. And I can't update TF to 2.x as  my application specified TF 1.10. 
Can this error be fixed by changing parameters? Or I have to give up GPU support?
"
51086,Does TFLite Support conv + LSTM ?,"https://github.com/tensorflow/tensorflow/issues/49381 - 

I have raised the above issue for getting data formats,

Here, it is mentioned that N, S, D is only supported format in tflite .

Need, confirmation whether conv + lstm is supported or not in TFLite ?

Using TFLite version 2.4.1."
51084,Cannot split windowed data when batching is used in tf.data.Dataset,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- I have written custom code 
- Linux 20.04
- TensorFlow installed from binary
- TensorFlow version: 2.3/2.4/2.5
- Python version: 3.7.5
- CUDA/cuDNN version: 11.0
- GPU model and memory: NVIDIA RTX 2080/11GB

**Describe the current behavior**

train_dataset = tf.data.Dataset.from_tensor_slices((x, y)).window(2, 1, True).shuffle(buffer_size=tr_s).batch(batch_size)

for x in train_dataset_dataset.take(1):
    a, b = x
    c, d = tf.split(list(a), num_or_size_splits=2, axis=0)

For the above described code, I cannot split up the windowed data. However, when I do not use batching, I can split the windowed data. I get the following error in various flavours when I attempt to do so:

TypeError: '_NestedVariant' object is not iterable

**Describe the expected behavior**

I expect to be able to split up the data, when windowed data is batched

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**

funda = tf.data.Dataset.range(7).window(2, 1, True).batch(1)

for x in funda.take(1):
    a, b = x
    c, d = tf.split(list(a), num_or_size_splits=2, axis=0)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51083,tf.io.read_file memory leackage,"Hello all!


If've found the mem leackage bug in tf.io.read_file  function during my inference testing;

**Describe the current behavior**

This code eats over 30 Gb memory when I read 10000 jpeg images from local nvme drive. And the library does not release memory for data that is not in use anymore. The process eats all available RAM during the intensive file io and then got killed by the OS kernel.

When I changed   string  ""img_string = tf.io.read_file(fpath)""  on  ""img_string = open(fpath, 'rb').read()"" (and remove tf.function decorator) the leackage has gone. 

When i try to read the same images again in the same session, there is no leackage (memory consumption stops on the prevoius value). 

**Describe the expected behavior**
Library should release memory for not used data. I expected some kind of garbage collection. Or, if there is a caching under the hood, I expect to have an option to turn it off.  In current sutuation it is impossible to use this function in inference for intence io operations. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): the code is based on tf 2.5 documentation, tf.io module.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): built from sources
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.8.10
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)
- CUDA/cuDNN version: CUDA Version: 11.2 / CUDNN 8.0.5.39
- GPU model and memory: NVIDIA RTX3080TI 12Gb, NVIDIA RTX2070 8Gb

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
@tf.function
def read_jpg(fpath):
        img_string = tf.io.read_file(fpath)       
        img_tensor = tf.io.decode_jpeg(img_string)      
        return img_tensor

*in cycle of 10000 image reading eats over 30 Gb of RAM

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
There is no logs. The memory leackage was detected in htop utillite.
"
51082,"NotImplementedError: Cannot convert a symbolic Tensor (digit_capsule_layer_2/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported","tensorflow - 2.5.0
numpy - 1.21.1
python - 3.8 
CUDA - 11.2
CuDNN - 8.1

Many other issues related to it suggested downgrading the NumPy version to 1.19.5, after downgrading the NumPy version, unfortunately, it still doesn't work. 
"
51081,dnn implementation Error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code:
- System: Windows 10
- TensorFlow installed from (source or binary): Described below
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 11.2 / cuDNN 8.1 
- GPU model and memory: NVIDIA GeForce RTX 2080 Ti

**Describe the current behavior**
I am getting an error..
UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]
after I installed tensorflow-text and no matter what I do i cant get rid of it. 
Here is exactly what happened...



## FIRST INSTALLATION

In Anaconda Navigator under Environment install
	-keras = 2.4.3
	-keras-gpu= 2.4.3

tried running program (code below) got the following error. 
NotImplementedError: Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported

In Anaconda Navigator under Environment downgrade Numpy 1.2 with...
	-numpy = 1.19.2
	-numpy-base = 1.19.2

ran program and it WORKED

In Anaconda Prompt i did
    conda install pandas
    conda install matplotlib
ran PROGRAM in jupyter notebook; still works

In Anaconda Prompt i did
    pip install tensorflow_hub and got the following error when trying to import in temp file. 
    ImportError: cannot import name 'parameter_server_strategy_v2' from 'tensorflow.python.distribute' 
    (C:\Users\shapi\Anaconda3\envs\temp1\lib\site-packages\tensorflow\python\distribute\__init__.py)
    pip uninstall tensorflow_hub
    conda install tensorflow-hub
ran PROGRAM in jupyter notebook; still works

In Anaconda Prompt i did
     python -c ""import tensorflow as tf;print(tf.__version__)""
     2.5.0
     pip install --user tensorflow_text==2.5.0

TRIED TO RUN PROGRAM AND GOT ERROR
UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]

## Shutdown computer and Tried to make a new environment.

in Navigator create conda environment python == 3.8
In Anaconda Navigator under Environment install
	-keras = 2.4.3
	-keras-gpu= 2.4.3
In Anaconda Navigator under Environment downgrade
	-numpy = 1.19.2
	-numpy-base = 1.19.2
In Anaconda Prompt
conda install tensorflow-hub
python -c ""import tensorflow as tf;print(tf.__version__)""
2.5.0
TRIED TO RUN PROGRAM AND GOT ERROR
UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]

The problem is at this point the PROGRAM worked fine in the first installation. I have checked my path variables and they didn't change. I tried adding allow_growth = TRUE and that didn't help. I am completely stuck I have no idea what happened and why even a regular installation wont work anymore. 


## PROGRAM 

```
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
import time
from tensorflow import keras

physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)

def build_model1():
    macro_data = tf.keras.Input(shape=(None, 3)) 
    
    whole_seq_output, final_memory_state, final_carry_state = layers.LSTM(16,
                                                                          dropout=.95,
                                                                          input_shape=(None,3),
                                                                          return_sequences=True, 
                                                                          return_state=True)(macro_data)   
    
    SDF_Network = tf.keras.Model(
                            inputs=[macro_data],
                            outputs=[whole_seq_output],
                            name=""SDF_Network""
                            )         
    
    return SDF_Network

temp = np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]])
SDF_Network = build_model1()
SDF_Network([temp])
```

## Full Error

```
UnknownError                              Traceback (most recent call last)
<ipython-input-4-da1b52ecaec0> in <module>
      1 import numpy as np
      2 SDF_Network = build_model1()
----> 3 SDF_Network([temp])

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\engine\base_layer.py in __call__(self, *args, **kwargs)
   1028         with autocast_variable.enable_auto_cast_variables(
   1029             self._compute_dtype_object):
-> 1030           outputs = call_fn(inputs, *args, **kwargs)
   1031 
   1032         if self._activity_regularizer:

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\engine\functional.py in call(self, inputs, training, mask)
    418         a list of tensors if there are more than one outputs.
    419     """"""
--> 420     return self._run_internal_graph(
    421         inputs, training=training, mask=mask)
    422 

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\engine\functional.py in _run_internal_graph(self, inputs, training, mask)
    554 
    555         args, kwargs = node.map_arguments(tensor_dict)
--> 556         outputs = node.layer(*args, **kwargs)
    557 
    558         # Update tensor_dict.

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\layers\recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)
    666 
    667     if initial_state is None and constants is None:
--> 668       return super(RNN, self).__call__(inputs, **kwargs)
    669 
    670     # If any of `initial_state` or `constants` are specified and are Keras

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\engine\base_layer.py in __call__(self, *args, **kwargs)
   1028         with autocast_variable.enable_auto_cast_variables(
   1029             self._compute_dtype_object):
-> 1030           outputs = call_fn(inputs, *args, **kwargs)
   1031 
   1032         if self._activity_regularizer:

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\layers\recurrent_v2.py in call(self, inputs, mask, training, initial_state)
   1257           # GPU implementation when GPU is available.
   1258           if can_use_gpu:
-> 1259             last_output, outputs, new_h, new_c, runtime = gpu_lstm(
   1260                 **gpu_lstm_kwargs)
   1261           else:

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\keras\layers\recurrent_v2.py in gpu_lstm(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)
   1509       # Reverse axis 0 since the input is already convert to time major.
   1510       inputs = array_ops.reverse(inputs, axis=[0])
-> 1511     outputs, h, c, _ = gen_cudnn_rnn_ops.CudnnRNN(
   1512         input=inputs, input_h=init_h, input_c=init_c, params=params,
   1513         is_training=True, rnn_mode='lstm')

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\util\tf_export.py in wrapper(*args, **kwargs)
    402           'Please pass these args as kwargs instead.'
    403           .format(f=f.__name__, kwargs=f_argspec.args))
--> 404     return f(**kwargs)
    405 
    406   return tf_decorator.make_decorator(f, wrapper, decorator_argspec=f_argspec)

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\ops\gen_cudnn_rnn_ops.py in cudnn_rnn(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)
     96       pass
     97     try:
---> 98       return cudnn_rnn_eager_fallback(
     99           input, input_h, input_c, params, rnn_mode=rnn_mode,
    100           input_mode=input_mode, direction=direction, dropout=dropout,

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\ops\gen_cudnn_rnn_ops.py in cudnn_rnn_eager_fallback(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)
    176   ""direction"", direction, ""dropout"", dropout, ""seed"", seed, ""seed2"", seed2,
    177   ""is_training"", is_training)
--> 178   _result = _execute.execute(b""CudnnRNN"", 4, inputs=_inputs_flat,
    179                              attrs=_attrs, ctx=ctx, name=name)
    180   if _execute.must_record_gradient():

~\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     57   try:
     58     ctx.ensure_initialized()
---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:

UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]
```"
51080,Op type not registered 'NormalizeUTF8' in binary running  when reload model ,"tf version: 2.4.1

```
def get_model_bert(num_classes):

    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string) # shape=(None,) dtype=string

    encoder = hub.KerasLayer(""./resource/albert_en_base_2"", trainable=True)

    encoder_inputs = preprocessor_layer(text_input)
    outputs = encoder(encoder_inputs)
    embed = outputs[""pooled_output""]  

    if num_classes == 2:
        out = layers.Dense(1, activation='sigmoid')(embed)
        model = tf.keras.Model(inputs=text_input, outputs=out)
        model.compile(Adam(lr=2e-5), ""binary_crossentropy"", metrics=[""binary_accuracy""])
    else:
        out = layers.Dense(num_classes, activation=""softmax"")(embed)
        model = tf.keras.Model(inputs=text_input, outputs=out)
        model.compile(Adam(lr=2e-5), ""sparse_categorical_crossentropy"", metrics=[""acc""])
    return model

model = get_model_bert(2)
model.save('tttmodel').
```  


> 2021-08-01 03:46:36.957767: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
> WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 85). These functions will not be directly callable after loading.
> WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 85). These functions will not be directly callable after loading.
> INFO:tensorflow:Assets written to: tttmodel/assets
> INFO:tensorflow:Assets written to: tttmodel/assets

Then I tried reload it from disk:

`model = tf.keras.models.load_model('tttmodel')`

The error:



> ----> 1 model = tf.keras.models.load_model('tttmodel')
> 
> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)
>     210       if isinstance(filepath, six.string_types):
>     211         loader_impl.parse_saved_model(filepath)
> --> 212         return saved_model_load.load(filepath, compile, options)
>     213 
>     214   raise IOError(
> 
> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/load.py in load(path, compile, options)
>     142   for node_id, loaded_node in keras_loader.loaded_nodes.items():
>     143     nodes_to_load[keras_loader.get_path(node_id)] = loaded_node
> --> 144   loaded = tf_load.load_partial(path, nodes_to_load, options=options)
>     145 
>     146   # Finalize the loaded layers and remove the extra tracked dependencies.
> 
> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_partial(export_dir, filters, tags, options)
>     763     A dictionary mapping node paths from the filter to loaded objects.
>     764   """"""
> --> 765   return load_internal(export_dir, tags, options, filters=filters)
>     766 
>     767 
> 
> /workspace/user-workspace/conda-34805-py37/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, options, loader_cls, filters)
>     891       except errors.NotFoundError as err:
>     892         raise FileNotFoundError(
> --> 893             str(err) + ""\n If trying to load on a different device from the ""
>     894             ""computational device, consider using setting the ""
>     895             ""`experimental_io_device` option on tf.saved_model.LoadOptions ""
> 
> FileNotFoundError: Op type not registered 'NormalizeUTF8' in binary running on jp-34805-jjj. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
>  If trying to load on a different device from the computational device, consider using setting the `experimental_io_device` option on tf.saved_model.LoadOptions to the io_device such as '/job:localhost'.



Any solution ?"
51078,cannot use tf.keras.preprocessing.image.random_channel_shift or apply_channel_shift with tf.data.Dataset functions like image_dataset_from_directory or tensor_slices.,"I am using tensorflow 2.5, i cannot use apply_channel_shift or [random_channel_shift](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/random_channel_shift) with tf.data.Dataset it raises the following error:
tensor object has no attribute ""ndim"".
 can any one please write a sample code for me ? 
i am using .map function for apply agumentation on tf.data Dataset. many thanks.
"
51077,tf.math.confusion_matrix InvalidArgumentError about incompatible shapes,"I need to train a model using a custom score that is computed using TP, TN, FP, FN (values from confusion matrix). This is my custom metric:
```
class MyScore(Metric):
  def __init__(self, name='my_score', **kwargs):
    super().__init__(name=name, **kwargs)
    self.cost = self.add_weight(name='cost', initializer='zeros')
    self.misprediction_cost = self.add_weight(name='misprediction_cost', initializer='zeros')
    self.weighted_samples = self.add_weight(name='weighted_samples', initializer='zeros')
    self.score = self.add_weight(name='score', initializer='zeros')
    self.tp = self.add_weight(name='tp', initializer='zeros')
    self.tn = self.add_weight(name='tn', initializer='zeros')
    self.fp = self.add_weight(name='fp', initializer='zeros')
    self.fn = self.add_weight(name='fn', initializer='zeros')
  
  def update_state(self, y_true, y_pred, sample_weight=None):
    matrix = tf.math.confusion_matrix(y_true, y_pred)
    self.tp += matrix[0][0]
    self.tn += matrix[0][1]
    self.fp += matrix[1][0]
    self.fn += matrix[1][1]
    self.cost.assign((self.tn + self.fp)/(self.tp + self.fn))
    self.misprediction_cost.assign(self.fn * self.cost + self.fp)
    self.weighted_samples.assign(self.tn + self.fp + self.cost * (self.tp + self.fn))
    self.score.assign(1.0 - self.misprediction_cost / self.weighted_samples)

  def result(self):
    return self.score

  def reset_state(self):
    self.tp.assign(0)
    self.tf.assign(0)
    self.fp.assign(0)
    self.fn.assign(0)
    self.cost.assign(0.0)
    self.misprediction_cost.assign(0.0)
    self.weighted_samples.assign(0.0)
    self.score.assign(0.0)
```
But confusion_matrix() fails on its last line:
 ```
/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: 
tensorflow.python.framework.errors_impl.InvalidArgumentError: in user code:

    <ipython-input-17-ad2031fe9bf3>:20 update_state  *
        matrix = tf.math.confusion_matrix(y_true, y_pred)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206 wrapper  **
        return target(*args, **kwargs)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/confusion_matrix.py:198 confusion_matrix
        shape=math_ops.cast(shape, dtypes.int64))
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py:8997 scatter_nd
        _ops.raise_from_not_ok_status(e, name)
    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:6897 raise_from_not_ok_status
        six.raise_from(core._status_to_exception(e.code, message), None)
    <string>:3 raise_from
        

    InvalidArgumentError: Dimensions [0,2) of indices[shape=[512,2,1]] must match dimensions [0,2) of updates[shape=[512,1]] [Op:ScatterNd]
```
But if i add a debug `print(y_true.shape, y_pred.shape)` into `update_state()` i get `(512, 1) (512, 1)`!"
51076,__iter__() is only supported inside of tf.function or when eager execution is enabled,"**System information**
- Tensorflow version: 2.2.0 
- Python version: 3.8.6

![image](https://user-images.githubusercontent.com/36669308/127742743-1fcc6fe6-24a3-40cc-9433-0d244fb54276.png)

It working in tensorflow 1.10.1 and python 3.6.5, but not 2.2.0
How can anyone resolve it, please?
Thanks"
51075,Linux setup guide update for Ubuntu 20.04 ,"## URL(s) with the issue:

https://www.tensorflow.org/install/gpu#install_cuda_with_apt

## Description of issue (what needs changing):

Ubuntu 20.04 installation guide for new CUDA and CUDnn versions.

### Clear description

Since new LTS released by Ubuntu, maybe CUDA installation can be updated.

### Correct links

None

### Parameters defined

None

### Returns defined

None

### Raises listed and defined

None

### Usage example

None

### Request visuals, if applicable

None

### Submit a pull request?

None
"
51074,tf.spars.sparsee_dense_matmul supports multiplication of batches of data in a sparse tensor with a dense tensor,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):  tf 2.5
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?** No.

**Who will benefit with this feature?** The user who needs the sparse matrix multiplication of batches of data

As said in the manual script, `tf.spars.sparsee_dense_matmul`  only support `Multiply SparseTensor (or dense Matrix) (of rank 2)
`. Currently I have batches of data stored in a sparse tensor, then how should I do the multiplication? Any suggestions?"
51073,INFO:tensorflow:Assets written to: C:\Users\TFLab\AppData\Local\Temp\tmpdw25wybi\assets,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installation (pip package or built from source):
- TensorFlow library (version, if pip package or github SHA, if built from source):

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/gist/ymodak/e96a4270b953201d5362c61c1e8b78aa/tensorflow-datasets.ipynb?authuser=1): Demonstrate how to build your TF model.
2)  Reference [TensorFlow Lite Model Colab](https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).

```
(You can paste links or attach files by dragging & dropping them below)
- Provide links to your updated versions of the above two colab notebooks.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
(You can paste links or attach files by dragging & dropping them below)
- Include code to invoke the TFLite Converter Python API and the errors.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
51072,Can sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix be used in the graph mode?,"tensorflow 2.5

When I run `sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix` this function in the graph mode, it gives out the error of `    ValueError: Invalid rank: -1.  Expected a known rank of either 2 or 3. for '{{node SparseTensorToCSRSparseMatrix}} = SparseTensorToCSRSparseMatrix[T=DT_DOUBLE](SparseConcat_4, SparseConcat_4:1, SparseConcat_4:2)' with input shapes: [?,?], [?], [?].`It seems that this function cannot recognize the rank of csr matrix. However, if I run the function not in the graph mode, it works well without any debug. Why? 
 "
51071,Add version to Zenodo,"I need to cite a specific version of TensorFlow in a paper -- Any chance you could add 2.3.1 to https://zenodo.org/record/4724125?

EDIT: this is no bug -- please change to Feature Request/Other Issues."
51070,Index out of bounds error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 20

- TensorFlow installed from (source or binary):
Binary

**Describe the current behavior**

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 19, in run_odt_and_draw_results
IndexError: index 12 is out of bounds for axis 0 with size 5
```

**Describe the expected behavior**

Was expecting arrays of bounding box values and so forth, as per the model inputs and outputs

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
```python
import cv2
from PIL import Image
import wget
import numpy as np
import os
from tflite_model_maker.config import ExportFormat
from tflite_model_maker import model_spec
from tflite_model_maker import object_detector
import tensorflow as tf
assert tf.__version__.startswith('2')
tf.get_logger().setLevel('ERROR')
from absl import logging
logging.set_verbosity(logging.ERROR)
spec = model_spec.get('efficientdet_lite0')
train_data, validation_data, test_data = object_detector.DataLoader.from_csv('gs://cloud-ml-data/img/openimage/csv/salads_ml_use.csv')
model = object_detector.create(train_data, model_spec=spec, batch_size=8, train_whole_model=True, validation_data=validation_data)
model.evaluate(test_data)
model.export(export_dir='/media/nvme')
model.evaluate_tflite('/media/nvme/model.tflite', test_data)
model_path = ""/media/nvme/model.tflite""

classes = [""???""] * model.model_spec.config.num_classes
label_map = model.model_spec.config.label_map
for label_id, label_name in label_map.as_dict().items():
    classes[label_id - 1] = label_name

# Define a list of colors for visualization
COLORS = np.random.randint(0, 255, size=(len(classes), 3), dtype=np.uint8)


def preprocess_image(image_path, input_size):
    """"""Preprocess the input image to feed to the TFLite model""""""
    img = tf.io.read_file(image_path)
    img = tf.io.decode_image(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.uint8)
    original_image = img
    resized_img = tf.image.resize(img, input_size)
    resized_img = resized_img[tf.newaxis, :]
    return resized_img, original_image


def set_input_tensor(interpreter, image):
    """"""Set the input tensor.""""""
    tensor_index = interpreter.get_input_details()[0][""index""]
    input_tensor = interpreter.tensor(tensor_index)()[0]
    input_tensor[:, :] = image


def get_output_tensor(interpreter, index):
    """"""Retur the output tensor at the given index.""""""
    output_details = interpreter.get_output_details()[index]
    tensor = np.squeeze(interpreter.get_tensor(output_details[""index""]))
    return tensor


def detect_objects(interpreter, image, threshold):
    set_input_tensor(interpreter, image)
    interpreter.invoke()
    boxes = get_output_tensor(interpreter, 0)
    classes = get_output_tensor(interpreter, 1)
    scores = get_output_tensor(interpreter, 2)
    count = int(get_output_tensor(interpreter, 3))
    results = []
    for i in range(count):
        if scores[i] >= threshold:
            result = {
                ""bounding_box"": boxes[i],
                ""class_id"": classes[i],
                ""score"": scores[i],
            }
            results.append(result)
    return results

def run_odt_and_draw_results(image_path, interpreter, threshold=0.5):
    _, input_height, input_width, _ = interpreter.get_input_details()[0][""shape""]
    preprocessed_image, original_image = preprocess_image(
        image_path, (input_height, input_width)
    )
    results = detect_objects(interpreter, preprocessed_image, threshold=threshold)
    original_image_np = original_image.numpy().astype(np.uint8)
    for obj in results:
        ymin, xmin, ymax, xmax = obj[""bounding_box""]
        xmin = int(xmin * original_image_np.shape[1])
        print(""xmin plus: "")
        print(original_image_np.shape[1])
        xmax = int(xmax * original_image_np.shape[1])
        ymin = int(ymin * original_image_np.shape[0])
        print(""ymin plus: "")
        print(original_image_np.shape[0])
        ymax = int(ymax * original_image_np.shape[0])
        class_id = int(obj[""class_id""])
        color = [int(c) for c in COLORS[class_id]]
        cv2.rectangle(original_image_np, (xmin, ymin), (xmax, ymax), color, 2)
        y = ymin - 15 if ymin - 15 > 15 else ymin + 15
        label = ""{}: {:.0f}%"".format(classes[class_id], obj[""score""] * 100)
        cv2.putText(
            original_image_np, label, (xmin, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2
        )
    original_uint8 = original_image_np.astype(np.uint8)
    return original_uint8

INPUT_IMAGE_URL = ""https://storage.googleapis.com/cloud-ml-data/img/openimage/3/2520/3916261642_0a504acd60_o.jpg""

DETECTION_THRESHOLD = 0.3

TEMP_FILE = '/media/nvme/image.png'

# Download image and save to above location as a 512 x 512 input

interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

detection_result_image = run_odt_and_draw_results(
	TEMP_FILE,
    interpreter,
    threshold=DETECTION_THRESHOLD
)
```"
51052,issue with running forward passes using saved model format converted from a checkpoint ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I used a script in tf object detection API V2
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tried TF 2.3, 2.4, 2.5, 2.6,0-rc0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2
- GPU model and memory: RTX 3080 Max-Q 8 GIG

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I fine tuned faster_rcnn_resnet50_keras model from the TF object detection API on my own dataset and I used a script (exporter_main_v2) under `models/research/object_detection/` to convert one of my checkpoints to a saved model format to serve in a Golang application. I can load the saved model files in Golang using TF Golang client but when I do a forward pass I get the following error:
```
2021-07-30 15:45:06.876593: I tensorflow/cc/saved_model/loader.cc:303] SavedModel load for tags { serve }; Status: success: OK. Took 1198184 microseconds.
{""severity"":""info"",""timestamp"":""2021-07-30T15:45:07.743500777Z"",""caller"":""/go/src/bitbucket.org/ehsai/doc-structure/internal/classifier/object_detection_init.go:30"",""message"":""Loading Tensorflow Model labels: /go/src/bitbucket.org/ehsai/doc-structure/models/classifiers/document_structure/object_detection/v14""}
2021-07-30 15:45:21.226358: E tensorflow/core/framework/tensor.cc:555] Could not decode variant with type_name: ""tensorflow::TensorList"".  Perhaps you forgot to register a decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?
2021-07-30 15:45:21.226403: W tensorflow/core/framework/op_kernel.cc:1744] OP_REQUIRES failed at constant_op.cc:82 : Invalid argument: Cannot parse tensor from tensor_proto.
2021-07-30 15:45:21.255391: E tensorflow/core/framework/tensor.cc:555] Could not decode variant with type_name: ""tensorflow::TensorList"".  Perhaps you forgot to register a decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?
2021-07-30 15:45:21.255454: W tensorflow/core/framework/op_kernel.cc:1744] OP_REQUIRES failed at constant_op.cc:82 : Invalid argument: Cannot parse tensor from proto: dtype: DT_VARIANT
tensor_shape {
}
variant_val {
  type_name: ""tensorflow::TensorList""
  metadata: ""\001\000\001\377\377\377\377\377\377\377\377\377\001\030\001""
}

{""severity"":""error"",""timestamp"":""2021-07-30T15:45:21.265370446Z"",""caller"":""/go/src/bitbucket.org/ehsai/doc-structure/internal/classifier/object_detection_run.go:135"",""message"":""An error occurred during forwad pass, err=Cannot parse tensor from proto: dtype: DT_VARIANT\ntensor_shape {\n}\nvariant_val {\n  type_name: \""tensorflow::TensorList\""\n  metadata: \""\\001\\000\\001\\377\\377\\377\\377\\377\\377\\377\\377\\377\\001\\030\\001\""\n}\n\n\t [[{{node StatefulPartitionedCall/StatefulPartitionedCall/map/TensorArrayV2_1/_0__cf__4}}]]""}
    suite.go:63: test panicked: runtime error: index out of range [2] with length 0
        goroutine 158 [running]:
        runtime/debug.Stack(0xc001f95710, 0x9f4bc0, 0xc0000fa000)
                /usr/local/go/src/runtime/debug/stack.go:24 +0x9f
        github.com/stretchr/testify/suite.failOnPanic(0xc000d03e00)
                /go/pkg/mod/github.com/stretchr/testify@v1.7.0/suite/suite.go:63 +0x57
        panic(0x9f4bc0, 0xc0000fa000)
                /usr/local/go/src/runtime/panic.go:969 +0x175
        bitbucket.org/ehsai/doc-structure/internal/classifier.(*objectDetectionModelSuite).Test_modelOutputsShape(0xc0043c60a0)
                /go/src/bitbucket.org/ehsai/doc-structure/internal/classifier/object_detection_test.go:146 +0xb45
        reflect.Value.call(0xc00440b620, 0xc004408550, 0x13, 0xa376d8, 0x4, 0xc000325e30, 0x1, 0x1, 0xc000325cf8, 0x41142a, ...)
                /usr/local/go/src/reflect/value.go:475 +0x8c7
        reflect.Value.Call(0xc00440b620, 0xc004408550, 0x13, 0xc000325e30, 0x1, 0x1, 0x24, 0xcf345, 0x519dc4)
                /usr/local/go/src/reflect/value.go:336 +0xb9
        github.com/stretchr/testify/suite.Run.func1(0xc000d03e00)
                /go/pkg/mod/github.com/stretchr/testify@v1.7.0/suite/suite.go:158 +0x379
        testing.tRunner(0xc000d03e00, 0xc004155cb0)
                /usr/local/go/src/testing/testing.go:1127 +0xef
        created by testing.(*T).Run
```
When I tried to load the saved model files in Python using tf.saved_model.load() I had no problem, I could load the model and run a forward pass and I got the exact same predictions using the checkpoint and the saved model filed so this happens only when I load the model in Golang.

What's wired is that when I loaded the saved model files  provided in the object detection model zoo (Pre trained model done by internal people in TF team I guess) I was able to run forward passes in Golang so I think there must be something wrong with the conversion script.  
**Describe the expected behavior**

I expect to load the saved model files and perform forward passes, I have done this before using TF object detection V1 so this issue happened when I started using TF objection deection V2 to fine a pre trained model on my dataset.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

step 1: You need to download a pre trained model from  the object detection model zoo (any model) https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md
and then you need to use the checkpoint and convert it to a saved model format using the following code:
```
import tensorflow as tf
from PIL import Image, ImageDraw, ImageFont
from six import BytesIO
import numpy as np
from object_detection.utils import label_map_util
from object_detection.utils import config_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder
from object_detection.exporter_lib_v2 import export_inference_graph
import os
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format
    
pipeline_config_path = path to the pipeline config file available in the downlaoded model folder
pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
with tf.io.gfile.GFile(pipeline_config_path, 'r') as f:
    text_format.Merge(f.read(), pipeline_config)
model_dir =  path to the checkpoint in the downlaoded model
saved_model_path = a path to save exported saved model files

export_inference_graph(""image_tensor"", pipeline_config, model_dir,  saved_model_path)
```

Running the above code generates a folder called saved_model in the saved_model_path directory. You need to load the model in Golang and run a forward pass. Here is the  code to do that. 

step 2:
```
package main

import (
	""bytes""
	""fmt""
	""image""
	""image/png""
	""os""

	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	tf_op ""github.com/tensorflow/tensorflow/tensorflow/go/op""
)

func main() {

	tags := []string{""serve""}

	imagePath := ""Path to a png image to feed to the model""

	modelDir := ""Path to a directory that has saved model files""
	tensorflowModel, err := tf.LoadSavedModel(modelDir, tags, nil)
	if err != nil {
		os.Exit(1)
	}

	imageBytes, err := generateByteArrayFromPngFile(imagePath)
	if err != nil {
		os.Exit(1)
	}

	tensor, err := tf.NewTensor(string(imageBytes))
	if err != nil {
		os.Exit(1)
	}

	// Prepare image for forward pass
	scope := tf_op.NewScope()
	// @ts-ignore
	input := tf_op.Placeholder(scope, tf.String)
	out := tf_op.ExpandDims(scope,
		tf_op.DecodePng(scope, input, tf_op.DecodePngChannels(3)),
		tf_op.Const(scope.SubScope(""make_batch""), int32(0)))

	outs, err := runScope(scope, map[tf.Output]*tf.Tensor{input: tensor}, []tf.Output{out})
	if err != nil {
		os.Exit(1)
	}

	modelOutputs, err := tensorflowModel.Session.Run(
		map[tf.Output]*tf.Tensor{
			tensorflowModel.Graph.Operation(""serving_default_input_tensor"").Output(0): outs[0],
		},
		[]tf.Output{
			// scores
			tensorflowModel.Graph.Operation(""StatefulPartitionedCall"").Output(4),
			// classes
			tensorflowModel.Graph.Operation(""StatefulPartitionedCall"").Output(2),
			// bounding boxes
			tensorflowModel.Graph.Operation(""StatefulPartitionedCall"").Output(1),
		},
		nil)

	if err != nil {
		os.Exit(1)
	}

	fmt.Println(modelOutputs)

}

func runScope(s *tf_op.Scope, inputs map[tf.Output]*tf.Tensor, outputs []tf.Output) ([]*tf.Tensor, error) {
	graph, err := s.Finalize()
	if err != nil {
		return nil, err
	}

	session, err := tf.NewSession(graph, nil)
	if err != nil {
		return nil, err
	}
	defer session.Close()
	return session.Run(inputs, outputs, nil)
}

func generateByteArrayFromPngFile(filePath string) ([]byte, error) {
	existingImageFile, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer existingImageFile.Close()

	imageData, imageType, err := image.Decode(existingImageFile)
	if err != nil {
		return nil, err
	}
	if imageType != ""png"" {
		return nil, err
	}

	pngBytesBuffer := new(bytes.Buffer)
	png.Encode(pngBytesBuffer, imageData)

	return pngBytesBuffer.Bytes(), nil
}

```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
51051,"Traing is very slow when add a custom layers. I found this tensor ops  run on cpu not on gpu,I don't konw why?","tensorFlow version (use command below): tensorflow 2.4
Python version: 3.7.9
CUDA/cuDNN version: 10.1

Traing is very slow when add a custom layers. I found this tensor ops  run on cpu not on gpu,I don't konw why?

**L2 = RuleLayer(100,420,4, 3, name='ruleLayer')(L1)**

```
class RuleLayer(keras.layers.Layer):
    def __init__(self,batch_size,time_steps, n_input, n_memb, **kwargs):
        super(RuleLayer, self).__init__( **kwargs)
        self.ts = time_steps
        self.n = n_input
        self.m = n_memb
        self.batch_size = batch_size

    def build(self, batch_input_shape):
        #self.batch_size = batch_input_shape[0]
        # self.batch_size = tf.shape(batch_input_shape)[0]
        super(RuleLayer, self).build(batch_input_shape)  # Be sure to call this at the end
        
    def call(self, input_):
        #for d in range(1,self.n):
            
        CP_batch = []
        # a tensor object is not assignable*, so you cannot use it on the left-hand side of an assignment.
        # build a Python list of tensors, and tf.stack() them together at the end of the loop:
        for batch in range(self.batch_size):            
            CP = []
            for ts in range(0,self.ts):
                cp = input_[batch,ts,:,0]
                c_shape = [1]
                xd_shape = [self.m]
                
                for d in range(1,self.n):
                    # append shape indizes
                    c_shape.insert(0,self.m)
                    xd_shape.insert(0,1)
                    # get cartesian product for each dimension
                    #xd = tf.reshape(input_[batch,ts,:,d], (xd_shape))
                    #c = tf.reshape(cp,(c_shape))
                    #cp = tf.matmul(c , xd)                    
                    cp = tf.matmul( tf.reshape(cp,(c_shape)) , tf.reshape(input_[batch,ts,:,d], (xd_shape)))                    
                    tf.print(""Is there a GPU available: ""),
                    tf.print(tf.config.list_physical_devices(""GPU""))
                    tf.print(""Is the Tensor on GPU #0:  ""),
                    tf.print(cp.device.endswith('GPU:0'))
                    
                flat_cp = tf.reshape(cp,(1, self.m**self.n))
                CP.append(flat_cp)
            CP = tf.reshape(CP,(1, self.ts,self.m**self.n))
            CP_batch.append(CP)

        return tf.reshape(tf.stack(CP_batch), (self.batch_size,self.ts, self.m**self.n))

    def compute_output_shape(self, batch_input_shape):
        if self.n == 1:
            return tf.TensorShape([self.batch_size, self.ts,self.m])
        else:
            return tf.TensorShape([self.batch_size, self.ts,self.m** self.n])
    
    def get_config(self):
        config = {
            'time_steps':  self.ts,
            'n_input': self.n,
            'n_memb': self.m,
            'batch_size':self.batch_size
        }
        base_config = super(RuleLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

```

It tooks me almost 2 hours/epoch on my computer .
Epoch 1/150
Is there a GPU available: 
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Is the Tensor on GPU #0:  
False
Is there a GPU available: 
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Is the Tensor on GPU #0:  
False
Is there a GPU available: 
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Is the Tensor on GPU #0:  
False
Is there a GPU available: 
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Is the Tensor on GPU #0:  
False
Is there a GPU available: 
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
Is the Tensor on GPU #0:  
False
"
51049,using `tf.image.*` module for one channel or more than three channel? ,"**Basic info**

- TensorFlow 2.4
- Colab / Kaggle Platform 

## Question

In `tf`, we have this module [`tf.image`](https://www.tensorflow.org/api_docs/python/tf/image) to perform various image processing operations. If I'm not mistaken, most of the operations require an RGB image, e.g (`h, w, channel == 3`). However, for a reason, I need them to work on one channel (`h, w, channel == 1`) or more than three-channel (`h, w, channel > 3`); basically for a 3D model (..medical imaging). 

## Description 

Let's say, a 3d data set where each sample contains 100 sequences of frames and so technically for a sample, the shape would be (`h, w, 100`). Now, from these 100 frames 5of a sample, there are 4 modalities, and we pick 5 frames for each of these 4 modalities and end up the data set the shape of (`h, w, 20`). 

Now, from this point, we need to do data augmentation with the data set the shape of (`h, w, 20`). In summary

```
(1st modalities): h, w, 5   <- same augmentations through all 5 channel 
(2nd modalities): h, w, 5   <- same augmentations through all 5 channel 
(3rd modalities): h, w, 5   <- same augmentations through all 5 channel 
(4th modalities): h, w, 5   <- same augmentations through all 5 channel 
```

**How can we apply augmentation on each modality with this shape (`h, w, 5`)?**

---

However, if we take only 1 frame from these 4 modalities, then in order to perform `tf.image.*` operation on these frames, there is a dirty approach. So, if we have some like as follows: 

```
(1st modalities): h, w, 1   <- same augmentations through all channel 
(2nd modalities): h, w, 1   <- same augmentations through all channel 
(3rd modalities): h, w, 1   <- same augmentations through all channel 
(4th modalities): h, w, 1   <- same augmentations through all channel 
```

then we can do something like below, for example: 

```python
# split them first 
split_img <- tf.split(h, w, 4)

aug_img = [] # will contain augmented image 

for i, frame in enumerate(split_img): # iterate each of the frame 
   print(frame.shape) # h, w, 1  

   # repeat 3 times to make fake rgb type. 
   img = tf.repeat(frame, repeats=3, axis=-1)
   print(img.shape) # h, w, 3

   # data augmentaiton with tf.image.* module 
   # seed ensure same augmentation for 
   # particular modality 
   img = tf.image.stateless_random_*(img , seed=(i, 2))
   print(img.shape) # h, w, 3
   
   # split the rgb and go back to previous state 
   img, _, _ = tf.split(img, 3, axis=-1)
   print(img.shape) # h, w, 1
 
   # appending augmented image 
   aug_img.append(img)

# lastly concate all augmented modalites 
img = tf.concat(aug_img, axis=-1)
print(img.shape) # h, w, 4
```



"
51048,Two python versions install tf in one system one succeeds while the other fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.5.1804 (Core)
- TensorFlow version:1.14.0
- Python version: python3.6.8 and python3.7.9
- Installed using virtualenv? pip? conda?: pip




**Describe the problem**
I have python3.6 installed by yum earlier and install tensorflow through pip successfully. Then I compile a python3.7 and also install same version tensorflow by pip but it failed, the error as follows:
```
ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)
```
Any idea on why this happens?


**Any other info / logs**
```
[root@localhost lib]# python3.6
Python 3.6.8 (default, Nov 16 2020, 16:55:22)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/usr/local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
```


```
[root@localhost lib]# /root/python379tgz/Python-3.7.9-compiled/bin/python3.7
Python 3.7.9 (default, Jul 30 2021, 12:33:12)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/root/python379tgz/Python-3.7.9-compiled/lib/python3.7/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by /root/python379tgz/Python-3.7.9-compiled/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so)


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.```"
51047,Inception_v4 can not node in the pb file,"HI,all

* convert tensorflow model inceptionV4 to onnx format, ``Error`` in ``tensorflow_core/python/framework/graph_util_impl.py""``
* the model url (https://storage.googleapis.com/download.tensorflow.org/models/inception_v4_2016_09_09_frozen.pb.tar.gz)
* I can find the node named ``graph/InceptionV4/Logits/Predictions`` by the scripts
```
import tensorflow as tf
from tensorflow.python.platform import gfile
import os
 
model_dir = '/home/yons/workspace/models/tf1/inception_v4'
model_name = 'inception_v4_2016_09_09_frozen.pb'
 
# 读取并创建一个图graph来存放Google训练好的Inception_v4模型（函数）
def create_graph():
    with gfile.GFile(os.path.join(
            model_dir, model_name), 'rb') as f:
        # 使用tf.GraphDef()定义一个空的Graph
        graph_def = tf.compat.v1.GraphDef()
        graph_def.ParseFromString(f.read())
        # Imports the graph from graph_def into the current default Graph.
        tf.import_graph_def(graph_def, name='graph')
 
# 创建graph
create_graph()
 
tensor_name_list = [tensor.name for tensor in tf.compat.v1.get_default_graph().as_graph_def().node]
result_file = os.path.join(model_dir, 'result.txt') 
with open(result_file, 'w+') as f:
    for tensor_name in tensor_name_list:
        f.write(tensor_name+'\n')

```

# Error
```
2021-07-30 16:41:47,830 - WARNING - From /home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.

Traceback (most recent call last):
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tf2onnx/convert.py"", line 605, in <module>
    main()
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tf2onnx/convert.py"", line 213, in main
    graph_def, inputs, outputs = tf_loader.from_graphdef(args.graphdef, args.inputs, args.outputs)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tf2onnx/tf_loader.py"", line 315, in from_graphdef
    frozen_graph = freeze_session(sess, input_names=input_names, output_names=output_names)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tf2onnx/tf_loader.py"", line 262, in freeze_session
    graph_def = convert_variables_to_constants(sess, graph_def, output_node_names)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py"", line 277, in convert_variables_to_constants
    inference_graph = extract_sub_graph(input_graph_def, output_node_names)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py"", line 197, in extract_sub_graph
    _assert_nodes_are_present(name_to_node, dest_nodes)
  File ""/home/yons/workspace/anaconda3/envs/nx_cross_compilers/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py"", line 152, in _assert_nodes_are_present
    assert d in name_to_node, ""%s is not in graph"" % d
AssertionError: graph/InceptionV4/Logits/Predictions is not in graph
```



**System information**
- OS Platform and Distribution ( Linux Ubuntu 18.04):
Ubuntu18.04
python 3.7.10
tensorflow-estimator 1.15.1 (binary)
tensorflow-gpu 1.15.5(binary)
onnx 1.6.0
onnxruntime 1.3.0
tf2onnx 1.9.1


"
51046,Release candidate 2.6.0rc1 is not built with HDFS support anymore?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
binary from pip
- TensorFlow version:
2.6.0rc1
- Python version:
3.7.10
- Installed using virtualenv? pip? conda?:
pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the problem**

I installed the release candidate 2.6.0rc1 and tried to read files from HDFS and it failed complaining that hdfs is an unknown filesystem scheme. I have seen this problem before when working TensorFlow builds that were not built with HDFS support.

All previous TF 2.* versions including release candidates that I've tested is built with HDFS support and looking at the release notes I'm none the wiser as it does not mention that HDFS support is being dropped from the pip wheel.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
import tensorflow as tf
tf.io.gfile.glob(""hdfs://localhost:8020/data"")
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-6-3127c92cb05e> in <module>
----> 1 tf.io.gfile.glob(""hdfs://localhost:8020/data"")

/srv/hops/anaconda/envs/theenv/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py in get_matching_files_v2(pattern)
    441         compat.as_str_any(matching_filename)
    442         for matching_filename in _pywrap_file_io.GetMatchingFiles(
--> 443             compat.as_bytes(pattern))
    444     ]
    445   else:

UnimplementedError: File system scheme 'hdfs' not implemented (file: 'hdfs://localhost:8020/data')
```
"
51043,bug in rsqrt,"---------------------------------------------------------------------------part 1-----------------------------------------------------------------
**my code:**
````
import tensorflow as tf
import os
import numpy as np
np.set_printoptions(threshold=np.inf)

def test():
    with tf.device(""/device:CPU:0""):
    # with tf.device('/gpu:1'):
        a=tf.constant([1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38])
        b = tf.rsqrt(a)
    return b

if __name__=='__main__':
    with tf.Session() as sess:
        print(sess.run(test()))
````

**expect the right result:**
_[9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18, 9.223371843921341e+18]_

in the env: **tensorflow== 1.14.0  python=3.6.8**
get the wrong result:
[1.383168e+19 1.383168e+19 1.383168e+19 1.383168e+19 1.383168e+19
 1.383168e+19 1.383168e+19 1.383168e+19 9.223372e+18]


in the env: **tensorflow== 1.14.0  python=3.6.8**
get the wrong result:
_[1.383168e+19 1.383168e+19 1.383168e+19 1.383168e+19 1.383168e+19
 1.383168e+19 1.383168e+19 1.383168e+19 9.223372e+18]_

in the env: **tensorflow== 1.14.0  python=2.7.18**
get the wrong result:
_[         inf          inf          inf          inf          inf
          inf          inf          inf 9.223372e+18]_

note:if I use the gpu device, also get the wrong result
----------------------------------------------------------------------part 2-----------------------------------------------------------------
**my code2:**
````
import tensorflow as tf
import os
import numpy as np
np.set_printoptions(threshold=np.inf)
import math

os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""
def test():
    a=tf.constant([1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38,1.1754944e-38])
    b = tf.math.rsqrt(a)
    print(b)
    return
    
if __name__=='__main__':
    test()
````

in the env: **tensorflow== 2.4.0  python=3.8.5**
get the wrong result:
_[1.383168e+19 1.383168e+19 1.383168e+19 1.383168e+19 1.383168e+19
 1.383168e+19 1.383168e+19 1.383168e+19 9.223372e+18]_

in the same env **tensorflow== 2.4.0  python=3.8.5** if I use GPU, I mean os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""
get the right result:
[9.223372e+18 9.223372e+18 9.223372e+18 9.223372e+18 9.223372e+18
 9.223372e+18 9.223372e+18 9.223372e+18 9.223372e+18]


----------------------------------------------------------------------part 3-----------------------------------------------------------------
note:
1、the small shape tend to get the right result
2、similarity bug also in tf.floor

"
51041,"Does the ""p"" in ""pfor"" stand for ""print"" or something?",https://github.com/tensorflow/tensorflow/blob/bfb74e15879212c3e4573fb83cd87358e964b4be/tensorflow/python/ops/parallel_for/pfor.py#L924
51040,Bash Bad address if CUDA on None Standard Path,"This is a jax build. See next comment for tensorflow reproduce.

**System information**
- OS Platform and Distribution: Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version:  https://github.com/tensorflow/tensorflow/archive/8cc3ffa8d8e4dd659c1534849cf5984ef4ec3532.tar.gz
- Python version: python 3.8 and 3.9 via miniconda
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

This following error occurs if you use CUDA located in non standard path location, that is,
if I use `C:/CUDA/v10.1` instead of `C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1`, a bad address error will be as following:

```
     _   _  __  __
    | | / \ \ \/ /
 _  | |/ _ \ \  /
| |_| / ___ \/  \
 \___/_/   \/_/\_\


Starting local Bazel server and connecting to it...
Bazel binary path: C:\tools\bazelisk\bazel.EXE
Python binary path: C:/Users/cloud/Miniconda3/envs/py38/python.exe
Python version: 3.8
NumPy version: 1.17.3
ciPy version: 1.5.4MKL-DNN enabled: yes
Target CPU: AMD64
Target CPU features: release
CUDA enabled: yes
CUDA toolkit path: C:/CUDA/v10.1
CUDNN library path: C:/CUDA/v10.1
CUDA compute capabilities: 6.1,7.0,7.5
CUDA version: 10.1
CUDNN version: 7.6.5
NCCL enabled: yes
TPU enabled: no
ROCm enabled: no

Building XLA and installing it in the jaxlib source tree...
C:\tools\bazelisk\bazel.EXE run --verbose_failures=true --config=short_logs --config=mkl_open_source_only --config=cuda --define=xla_python_enable_gpu=true :build_wheel -- --output_path=D:\jax\dist --cpu=AMD64
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'run' from d:\jax\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  Inherited 'build' options: --python_path=C:/Users/cloud/Miniconda3/envs/py38/python.exe
INFO: Reading rc options for 'run' from d:\jax\.bazelrc:
  Inherited 'build' options: --repo_env PYTHON_BIN_PATH=C:/Users/cloud/Miniconda3/envs/py38/python.exe --action_env=PYENV_ROOT --python_path=C:/Users/cloud/Miniconda3/envs/py38/python.exe --repo_env TF_NEED_CUDA=1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1,7.0,7.5 --repo_env TF_NEED_ROCM=0 --action_env TF_ROCM_AMDGPU_TARGETS=gfx803,gfx900,gfx906,gfx1010 -c opt --apple_platform_type=macos --macos_minimum_os=10.9 --announce_rc --define open_source_build=true --define=no_aws_support=true --define=no_gcp_support=true --define=no_hdfs_support=true --define=no_kafka_support=true --define=no_ignite_support=true --define=grpc_no_ares=true --spawn_strategy=standalone --strategy=Genrule=standalone --enable_platform_specific_config --action_env CUDA_TOOLKIT_PATH=C:/CUDA/v10.1 --action_env CUDNN_INSTALL_PATH=C:/CUDA/v10.1 --action_env TF_CUDA_PATHS=C:/CUDA/v10.1,C:/CUDA/v10.1 --action_env TF_CUDA_VERSION=10.1 --action_env TF_CUDNN_VERSION=7.6.5 --distinct_host_configuration=false
INFO: Found applicable config definition build:short_logs in file d:\jax\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:mkl_open_source_only in file d:\jax\.bazelrc: --define=tensorflow_mkldnn_contraction_kernel=1
INFO: Found applicable config definition build:cuda in file d:\jax\.bazelrc: --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:windows in file d:\jax\.bazelrc: --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/Zc:preprocessor --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true
INFO: Analyzed target //build:build_wheel (183 packages loaded, 15537 targets configured).
INFO: Found 1 target...
ERROR: C:/users/cloud/_bazel_cloud/hwk42b7s/external/llvm-project/llvm/BUILD:60:18: Executing genrule @llvm-project//llvm:abi_breaking_gen failed (Exit 126): bash.exe failed: error executing command
  cd C:/users/cloud/_bazel_cloud/hwk42b7s/execroot/__main__
  SET CUDA_TOOLKIT_PATH=C:/CUDA/v10.1
    SET CUDNN_INSTALL_PATH=C:/CUDA/v10.1
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\windows;C:\windows\System32;C:\windows\System32\WindowsPowerShell\v1.0
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF_CUDA_COMPUTE_CAPABILITIES=6.1,7.0,7.5
    SET TF_CUDA_PATHS=C:/CUDA/v10.1,C:/CUDA/v10.1
    SET TF_CUDA_VERSION=10.1
    SET TF_CUDNN_VERSION=7.6.5
    SET TF_ROCM_AMDGPU_TARGETS=gfx803,gfx900,gfx906,gfx1010
  C:/msys64/usr/bin/bash.exe -c source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/x64_windows-opt/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars.exe ""ENABLE_BACKTRACES=1"" ""LLVM_BINDIR=/dev/null"" ""LLVM_DISABLE_ABI_BREAKING_CHECKS_ENFORCING=0"" ""LLVM_ENABLE_ABI_BREAKING_CHECKS=0"" ""LLVM_ENABLE_THREADS=1"" ""LLVM_ENABLE_ZLIB=1"" ""LLVM_HAS_ATOMICS=1"" ""LLVM_INCLUDEDIR=/dev/null"" ""LLVM_INFODIR=/dev/null"" ""LLVM_MANDIR=/dev/null"" ""LLVM_NATIVE_TARGET=1"" ""LLVM_NATIVE_TARGETINFO=1"" ""LLVM_NATIVE_TARGETMC=1"" ""LLVM_NATIVE_ASMPRINTER=1"" ""LLVM_NATIVE_ASMPARSER=1"" ""LLVM_NATIVE_DISASSEMBLER=1"" ""LLVM_PREFIX=/dev/null"" ""LLVM_VERSION_MAJOR=0"" ""LLVM_VERSION_MINOR=0"" ""LLVM_VERSION_PATCH=0"" ""PACKAGE_NAME=llvm"" ""PACKAGE_STRING=llvm tensorflow-trunk"" ""PACKAGE_VERSION=tensorflow-trunk"" ""RETSIGTYPE=void"" ""LLVM_HOST_TRIPLE=x86_64-pc-win32"" ""LLVM_DEFAULT_TARGET_TRIPLE=x86_64-pc-win32"" ""LLVM_NATIVE_ARCH=X86"" ""HAVE_ERRNO_H=1"" ""HAVE_EXECINFO_H=1"" ""HAVE_FCNTL_H=1"" ""HAVE_FENV_H=1"" ""HAVE_INTTYPES_H=1"" ""HAVE_MALLOC_H=1"" ""HAVE_SIGNAL_H=1"" ""HAVE_STDINT_H=1"" ""HAVE_SYS_STAT_H=1"" ""HAVE_SYS_TYPES_H=1"" ""HAVE_ZLIB_H=1"" ""BACKTRACE_HEADER=execinfo.h"" ""HAVE_GETCWD=1"" ""HAVE_INT64_T=1"" ""HAVE_STRERROR=1"" ""HAVE_STRTOLL=1"" ""HAVE_SYSCONF=1"" ""HAVE_UINT64_T=1"" ""HAVE__CHSIZE_S=1"" ""HAVE___CHKSTK=1"" ""stricmp=_stricmp"" ""strdup=_strdup"" ""LTDL_SHLIB_EXT=.dll""< external/llvm-project/llvm/include/llvm/Config/abi-breaking.h.cmake > bazel-out/x64_windows-opt/bin/external/llvm-project/llvm/include/llvm/Config/abi-breaking.h
Execution platform: @local_execution_config_platform//:platform
/usr/bin/bash: line 1: bazel-out/x64_windows-opt/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars.exe: Bad address
Target //build:build_wheel failed to build
INFO: Elapsed time: 23.877s, Critical Path: 4.59s
INFO: 27 processes: 15 internal, 12 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
b''
Traceback (most recent call last):
  File "".\build\build.py"", line 603, in <module>
    main()
  File "".\build\build.py"", line 598, in main
    shell(command)
  File "".\build\build.py"", line 52, in shell
    output = subprocess.check_output(cmd)
  File ""C:\Users\cloud\Miniconda3\envs\py38\lib\subprocess.py"", line 415, in check_output
    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,
  File ""C:\Users\cloud\Miniconda3\envs\py38\lib\subprocess.py"", line 516, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '['C:\\tools\\bazelisk\\bazel.EXE', 'run', '--verbose_failures=true', '--config=short_logs', '--config=mkl_open_source_only', '--config=cuda', '--define=xla_python_enable_gpu=true', ':build_wheel', '--', '--output_path=D:\\jax\\dist', '--cpu=AMD64']' returned non-zero exit status 1.
```

**other info**
#42819, #46118, #41850 and #39680 should all be due to the same reason."
51038,"Autograph set_verbosity doc example shows using integer values for env vars, but only strings can be used","## URL(s) with the issue:    
https://www.tensorflow.org/api_docs/python/tf/autograph/set_verbosity

## Description of issue (what needs changing):

The documentation usage description for setting verbosity through environment variables uses an integer value, however this is not possible as environment variables must be strings. In the current state the following code example is provided:

```py
import os
import tensorflow as tf

os.environ['AUTOGRAPH_VERBOSITY'] = 5
# Verbosity is now 5

tf.autograph.set_verbosity(0)
# Verbosity is now 0

os.environ['AUTOGRAPH_VERBOSITY'] = 1
# No effect, because set_verbosity was already called.
```

However it should actually be:

```py
import os
import tensorflow as tf

os.environ['AUTOGRAPH_VERBOSITY'] = '5'
# Verbosity is now 5

tf.autograph.set_verbosity(0)
# Verbosity is now 0

os.environ['AUTOGRAPH_VERBOSITY'] = '1'
# No effect, because set_verbosity was already called.
```"
51031,Installation of tflite-model-maker 0.3.2. takes forever,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Windows 10 Enterprise
- TensorFlow installed from (source or binary): from PyPi
- TensorFlow version: 2.5.0
- Python version: 3.6.8 and 3.8.8
- Installed using virtualenv? pip? conda?:  using pip in venv
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 11.2, cuDNN 8.1.0
- GPU model and memory: NVIDIA GeForce RTX 2070 with Max-Q Design 8gb



**Describe the problem**
Installation of tflite-model-maker 0.3.2. takes forever.
Attached log demonstrates situation for a 10+ minutes of installation. I will attach fuller log in the comments.
It downloads 17 versions of scipy package, 10+ versions of scikit-learn, 3 versions of tensorflow (although 2.5.0 version is already installed) and so on.
I tried installation of tflite-model-maker 0.3.2 few times, but couldn't make it. 
Installed nightly version, but I question its quality and stability - that's why I've decided to create an issue. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tflite-model-maker==0.3.2


**Any other info / logs**
[pip install tflite-model-maker.txt](https://github.com/tensorflow/tensorflow/files/6900929/pip.install.tflite-model-maker.txt)
"
51030,TfLite python delegate support for RB5 robotics platform,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
Robotics RB5 Platform
Linux qrb5165-rb5 4.19.125 aarch64 GNU/Linux
CPU: Qualcomm QRB5165
RAM: 8GB
- TensorFlow version (you are using):
- Python 3.6.9
- python3-tflite-runtime (2.5.0.post1)
- hexagon_nn_skel_v1.20.0.1
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
Currently it works on cpu cores, I would like to delegate it to libhexagon_nn_skel.so.
When I run:
`tflite.load_delegate('libhexagon_nn_skel.so')`
It returns:
`OSError: libhexagon_nn_skel.so: wrong ELF class: ELFCLASS32`
Same with v65 and v66
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Everyone using RB5 platform with python, and likely oyher sililar Qualcomm products
**Any Other info.**
"
51029,Query About tflite interpreter usage,"Is it possible to provide input/output memory (pointer) for running inference..
[](https://www.tensorflow.org/lite/api_docs/cc/class/tflite/interpreter)

From the snippet below
```
  // Allocate tensor buffers.
  TFLITE_MINIMAL_CHECK(interpreter->AllocateTensors() == kTfLiteOk);
  printf(""=== Pre-invoke Interpreter State ===\n"");
  tflite::PrintInterpreterState(interpreter.get());

  // Fill input buffers
  // TODO(user): Insert code to fill input tensors.
  // Note: The buffer of the input tensor with index `i` of type T can
  // be accessed with `T* input = interpreter->typed_input_tensor<T>(i);`

  // Run inference
  TFLITE_MINIMAL_CHECK(interpreter->Invoke() == kTfLiteOk);
```
1) Does `AllocateTensors()` create memory for input & intermediate & output layers?
2) How can I provide my buffer memory pointer (virtual mem) directly so to avoid setting the memory content.


Regards,
Harsh"
51027,Worse predict result from keras h5 model convert to tensorflow frozen pb model,"Hi everyone,
I have try to convert my keras h5 model to tensorflow frozen pb model.
I want to use this pb model in Microsoft ML.net to classify images.
I successfully convert the model to frozen pb, but I get the worse predict result than h5 model.
Some classes can predict well like original model, some classes will get the bad result.
Anyone try this before? Please help me, THX!!"
51026,TensorFlow Lite C API full example,Is there any example fully in C language using Tensorflow Lite C API? More specifically for image classification or object detection? I have not been able to find any TensorFlow example in C.
51025,"Could provide the different platforms compiled release file, as widows lib and  in(cpu gpu) and linux .so?","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
50993,fake quant in tflite ignores the num_bits that is passed,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0

### 2. Code

``` python
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf

keras = tf.keras
layers = tf.keras.layers

input_shape = (1, 1000)
inputs = layers.Input(shape=input_shape)
outputs = tf.quantization.fake_quant_with_min_max_args(inputs=inputs, num_bits=2, min=-2, max=2)
model = keras.Model(inputs=inputs, outputs=outputs)


def convert_to_tflite(model):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    tflite_model = converter.convert()
    return tflite_model


def infer(tflite_model, img):
    interpreter = tf.lite.Interpreter(model_content=tflite_model)
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()[0]
    interpreter.set_tensor(input_details[""index""], img)
    interpreter.invoke()
    output_details = interpreter.get_output_details()[0]
    output = interpreter.get_tensor(output_details[""index""])[0]
    return output


img = np.sort(np.random.random((1,)+input_shape).astype(np.float32) * 5 - 2.5)
tflite_model = convert_to_tflite(model)
tf_output = model.predict(img)
tflite_output = infer(tflite_model, img)

fig, axs = plt.subplots(2)
fig.suptitle('FakeQuant TFLite vs TF')

x = img.flatten()
axs[0].plot(x, tflite_output.flatten())
axs[1].plot(x, tf_output.flatten())
plt.show()
```


### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:
When quantizing using fake quant with less than 8 bits, it seems to actually quantize the input with 8 bits anyway.
In Tensorflow it seems to work, but not in TFLite.

### 5. (optional) Any other info / logs
Here for example is a plot of quantizing a tensor using 2 bits. The upper subplot is the output of TFLite, while the bottom subplot is the output of Tensorflow.


![fq_issue](https://user-images.githubusercontent.com/44209964/127321225-4b2181bc-a822-40d4-bebc-3557a3deb8c7.png)
"
50992,reduce_sum in tflite outputs is incorrect,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

``` python
import tensorflow as tf
import numpy as np


keras = tf.keras
layers = keras.layers


def infer(tflite_model, img):
    interpreter = tf.lite.Interpreter(model_content=tflite_model)
    interpreter.allocate_tensors()
    input_details = interpreter.get_input_details()[0]
    interpreter.set_tensor(input_details[""index""], img)
    interpreter.invoke()
    output_details = interpreter.get_output_details()[0]
    output = interpreter.get_tensor(output_details[""index""])
    return output

def convert_to_tflite(model):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.experimental_new_converter = True
    tflite_model = converter.convert()
    return tflite_model


# Image to test
np.random.seed(1)
input_shape = (12, 14, 18)
img = np.random.random((1,)+input_shape).astype(np.float32) * 7.0 - 3.5

# Create a model
i = layers.Input(shape=input_shape)
x = tf.quantization.fake_quant_with_min_max_args(i, min=0.0, max=3.984375)
x = tf.reduce_sum(x, axis=None)
x = tf.quantization.fake_quant_with_min_max_args(x, min=-4.0, max=3.96875)
model = keras.models.Model(inputs=i, outputs=x)


tf_output = model.predict(img)
tflite_model = convert_to_tflite(model)
tflite_output = infer(tflite_model, img)

print(f'Tensorflow output: {tf_output}, TFLite output: {tflite_output}, ')

```


### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:
I get a huge difference between the TF model and the TFLite model:
Tensorflow output: 3.96875, TFLite output: -2.78125, 

The Tensorflow model gives completely different results than the TFLite model. Furthermore, before the reduce_sum, I quantize the tensor using only positive values, so it does not make sense that the output of the model is negative (which is what I get).

"
50990,Help Me 😅,"Can Anyone tell me why is this happening? I am new to Python so it might be a silly issue 😅
![dfhdfhdtr](https://user-images.githubusercontent.com/70793550/127268620-ba792466-e339-4231-95a3-d66d4fed52b5.JPG)
"
50989,Failed when upgrading grpc to 1.36.0,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):  2.4.2
- Are you willing to contribute it (Yes/No): Yes, but no idea how get it work.


I try to upgrade grpc to 1.36 to use feature `grpc::experimental::TlsServerAuthorizationCheckConfig>` for client-side custom certificate verification.  Updates of workload.bzl: 
```
+++ b/tensorflow/workspace.bzl
@@ -650,8 +650,8 @@ def tf_repositories(path_prefix = """", tf_repo_name = """"):
     # WARNING: make sure ncteisen@ and vpai@ are cc-ed on any CL to change the below rule
     tf_http_archive(
         name = ""com_github_grpc_grpc"",
-        sha256 = ""b956598d8cbe168b5ee717b5dafa56563eb5201a947856a6688bbeac9cac4e1f"",
-        strip_prefix = ""grpc-b54a5b338637f92bfcf4b0bc05e0f57a5fd8fadd"",
+        sha256 = ""019822cb6f1a339658fc620a54af9b710c39b540ae90e14c3babd6b16fb45b0f"",
+        strip_prefix = ""grpc-736e3758351ced3cd842bad3ba4e2540f01bbc48"",
         system_build_file = clean_dep(""//third_party/systemlibs:grpc.BUILD""),
         patch_file = clean_dep(""//third_party/grpc:generate_cc_env_fix.patch""),
         system_link_files = {
@@ -664,8 +664,8 @@ def tf_repositories(path_prefix = """", tf_repo_name = """"):
             ""//third_party/systemlibs:grpc.bazel.protobuf.bzl"": ""bazel/protobuf.bzl"",
         },
         urls = [
-            ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/grpc/grpc/archive/b54a5b338637f92bfcf4b0bc05e0f57a5fd8fadd.tar.gz"",
-            ""https://github.com/grpc/grpc/archive/b54a5b338637f92bfcf4b0bc05e0f57a5fd8fadd.tar.gz"",
+            ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/grpc/grpc/archive/736e3758351ced3cd842bad3ba4e2540f01bbc48.tar.gz"",
+            ""https://github.com/grpc/grpc/archive/736e3758351ced3cd842bad3ba4e2540f01bbc48.tar.gz"",
```

but got errors as below:
```
ERROR: /root/.cache/bazel/_bazel_root/b2ed5105b9fe9c49ec55af56657398dc/external/upb/bazel/upb_proto_library.bzl:257:29: aspect() got unexpected keyword argument 'incompatible_use_toolchain_transition'
ERROR: /tf/src/tensorflow/tools/pip_package/BUILD:175:1: error loading package '@com_github_grpc_grpc//': in /root/.cache/bazel/_bazel_root/b2ed5105b9fe9c49ec55af56657398dc/external/com_github_grpc_grpc/bazel/grpc_build_system.bzl: Extension file 'bazel/upb_proto_library.bzl' has errors and referenced by '//tensorflow/tools/pip_package:licenses'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: error loading package '@com_github_grpc_grpc//': in /root/.cache/bazel/_bazel_root/b2ed5105b9fe9c49ec55af56657398dc/external/com_github_grpc_grpc/bazel/grpc_build_system.bzl: Extension file 'bazel/upb_proto_library.bzl' has errors
INFO: Elapsed time: 1.187s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (29 packages loaded, 12 targets configured)
    currently loading: @com_google_protobuf// ... (2 packages)
    Fetching @rules_java; fetching
    Fetching @go_sdk; fetching
```
Could you give me some tips for debugging and upgrade?

Thanks!
"
50988,How to convert model trained with tensorflow object detection api to tflite model that supported by Android GPU,"I train a ssd_resnet50 with tensorflow object detection api. Then export and convert the model. The tflite model has lots of nodes like while, gather that that are not supported by tflite GPU. However ssd_mobile model with similar framework on tensorflow hub can ran on android gpu.
Did I forget some operations? How to remove nodes not supported by android gpu in model conversion."
50982,Why is <normalizing flow>.prob() failing for me?,"I am building a Normalizing Flow (concatenation of Distribution and chain of Bijectors) in Tensorflow. Here is the code for the (single-link) chain of Bijectors:

```
class Flow( tfb.Bijector ):

    def __init__( self, theta, a, **kwargs ):
        tfb.Bijector.__init__( self, forward_min_event_ndims = 0, **kwargs )
        bijectors = [ tfb.Tanh() ]
        self.chain = tfb.Chain( bijectors = bijectors )

    def _forward( self, z ):
        return self.chain( z )

    def _inverse( self, x ):
        result = self.chain.inverse( x ) 
        return result

    def _forward_log_det_jacobian( self, z ):
        return self.chain._forward_log_det_jacobian( z, event_ndims = 2 )
```
Here is the code I use to test the Flow:

```
Z = tf.convert_to_tensor( [ [ [ 0.1, 0.2 ], [ 0.3, 0.4 ], [ 0.5, 0.6 ] ], 
                            [ [ 0.8, 0.7 ], [ 0.6, 0.5 ], [ 0.4, 0.3 ] ],
                            [ [ 0.4, 0.7 ], [ 0.2, 0.1 ], [ 0.8, 0.0 ] ] ] )
print( ""Z"", Z )
nf = Flow( 1., 2. )  # ### theta, a 
bd = tfd.MultivariateNormalDiag( loc=[0.,0.], scale_diag=[1.,1.] )
td = tfd.TransformedDistribution( bd, nf )
td.log_prob( Z )
```
The last statement fails with the following stack trace:
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-53-de138696ce92> in <module>()
     24 bd = tfd.MultivariateNormalDiag( loc=[0.,0], scale_diag=[1.,1.] )
     25 td = tfd.TransformedDistribution( bd, nf )
---> 26 td.prob( Z )

12 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py in prob(self, value, name, **kwargs)
   1322         values of type `self.dtype`.
   1323     """"""
-> 1324     return self._call_prob(value, name, **kwargs)
   1325 
   1326   def _call_unnormalized_log_prob(self, value, name, **kwargs):

/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/distribution.py in _call_prob(self, value, name, **kwargs)
   1304     with self._name_and_control_scope(name, value, kwargs):
   1305       if hasattr(self, '_prob'):
-> 1306         return self._prob(value, **kwargs)
   1307       if hasattr(self, '_log_prob'):
   1308         return tf.exp(self._log_prob(value, **kwargs))

/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/distributions/transformed_distribution.py in _prob(self, y, **kwargs)
    371         )
    372     ildj = self.bijector.inverse_log_det_jacobian(
--> 373         y, event_ndims=event_ndims, **bijector_kwargs)
    374     if self.bijector._is_injective:  # pylint: disable=protected-access
    375       base_prob = self.distribution.prob(x, **distribution_kwargs)

/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/bijector.py in inverse_log_det_jacobian(self, y, event_ndims, name, **kwargs)
   1318       ValueError: if the value of `event_ndims` is not valid for this bijector.
   1319     """"""
-> 1320     return self._call_inverse_log_det_jacobian(y, event_ndims, name, **kwargs)
   1321 
   1322   def _call_forward_log_det_jacobian(self, x, event_ndims, name, **kwargs):

/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/bijector.py in _call_inverse_log_det_jacobian(self, y, event_ndims, name, **kwargs)
   1274               'is implemented. One or the other is required.')
   1275 
-> 1276         return self._reduce_jacobian_det_over_shape(ildj, reduce_shape)
   1277 
   1278   def inverse_log_det_jacobian(self,

/usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/bijectors/bijector.py in _reduce_jacobian_det_over_shape(self, unreduced, reduce_shape)
   1531     ones = tf.ones(reduce_shape, unreduced.dtype)
   1532     reduce_dims = ps.range(-ps.size(reduce_shape), 0)
-> 1533     return tf.reduce_sum(ones * unreduced, axis=reduce_dims)
   1534 
   1535   def _parameter_control_dependencies(self, is_init):

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
   1232         #   r_binary_op_wrapper use different force_same_dtype values.
   1233         x, y = maybe_promote_tensors(x, y, force_same_dtype=False)
-> 1234         return func(x, y, name=name)
   1235       except (TypeError, ValueError) as e:
   1236         # Even if dispatching the op failed, the RHS may be a tensor aware

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in _mul_dispatch(x, y, name)
   1573     return sparse_tensor.SparseTensor(y.indices, new_vals, y.dense_shape)
   1574   else:
-> 1575     return multiply(x, y, name=name)
   1576 
   1577 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    204     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    205     try:
--> 206       return target(*args, **kwargs)
    207     except (TypeError, ValueError):
    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in multiply(x, y, name)
    528   """"""
    529 
--> 530   return gen_math_ops.mul(x, y, name)
    531 
    532 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py in mul(x, y, name)
   6238       return _result
   6239     except _core._NotOkStatusException as e:
-> 6240       _ops.raise_from_not_ok_status(e, name)
   6241     except _core._FallbackException:
   6242       pass

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6895   message = e.message + ("" name: "" + name if name is not None else """")
   6896   # pylint: disable=protected-access
-> 6897   six.raise_from(core._status_to_exception(e.code, message), None)
   6898   # pylint: enable=protected-access
   6899 

/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: required broadcastable shapes at loc(unknown) [Op:Mul]
```
I do not understand the error message, nor how to correct it.   Please help"
50981,XLA Optimizer Mixed Precision Support,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

I used autoclustering with optimization level 2.
```
export TF_DUMP_GRAPH_PREFIX=""./xla_hlo""
export TF_XLA_FLAGS=""--tf_xla_clustering_debug --tf_xla_auto_jit=2""
export XLA_FLAGS=""--xla_dump_hlo_as_dot --xla_dump_to=./xla_hlo""
```

I found that when I have the `DynamicLossScale` in mixed-precision setting, the graph for loss scaling is appended to the original graph containing forward and backward propagations,  
and the remaining part of the optimizer is emitted as a separate graph.

So, my questions is

Why does the `DynamicScaleLoss` generate separated graphs in XLA?

**Will this change the current api? How?**
The API should not be changed because already full precision training is supported.

**Who will benefit with this feature?**
Anyone who wants to analyze the XLA HLO graph for their accelerator.

**Any Other info.**"
50980,XLA compilation error for TPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04 (GCP Cloud TPU VM)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): default cloud TPU VM installation
- TensorFlow version (use command below): unknown 2.6.0
- Python version: 3.8.10
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version: no
- GPU model and memory: TPU

**Describe the current behavior**
Model compilation for TPU fails with logs:
```
2021-07-27 14:46:12.541836: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(7086181526061168380), session_name()
2021-07-27 14:46:14.141350: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:66] TpuCompileOp was cancelled. Sleeping for 300 seconds to give time for TPUCompileOp to finished.
2021-07-27 14:46:17.250612: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:175] Compilation of 7086181526061168380 with session name  took 4.708620071s and failed
2021-07-27 14:46:17.250711: F tensorflow/core/tpu/kernels/tpu_program_group.cc:86] Check failed: xla_tpu_programs.size() > 0 (0 vs. 0)
```

**Describe the expected behavior**
The model compiles or at least a meaningful error message with a cause is printed.

**Standalone code to reproduce the issue**

The code ran was this: https://github.com/TensorSpeech/TensorFlowASR/blob/main/examples/conformer/train.py

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Full log: https://gist.github.com/lamyiowce/2e9c0adc3c9c52b4785c63898c0a6b43"
50979,FunctionalPreprocessingStage incompatible with some keras preprocessing layers,"**Describe the current behavior**

[FunctionalPreprocessingStage](https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/layers/preprocessing/preprocessing_stage.py#L98-L133) provides a Functional like interface for connecting up multiple keras preprocessing layers, and adapting them all with a single call. If I understand the intended use correctly, you must first call the instances of the various preprocessing layers in order to connect them up into a DAG, wrap the inputs & outputs with FunctionalPreprocessingStage and then call adapt on that. However, some of the preprocessing layers throw an error if you call them before they have been adapted (eg. [IndexLookup](https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/layers/preprocessing/index_lookup.py#L599-L602) which is also used by other related classes like StringLookup, although this was not the case in [v2.4.0](https://github.com/tensorflow/tensorflow/blob/582c8d236cb079023657287c318ff26adb239002/tensorflow/python/keras/layers/preprocessing/index_lookup.py#L370-L373)).

**Describe the expected behavior**

All Keras preprocessing layers should be compatible with FunctionalPreprocessingStage.

Minimal reproducible example:

```python
# Expected usage
input_layer = tf.keras.Input(name='scalar_string', shape=(1,), dtype=tf.string)
lookup_layer = tf.keras.layers.experimental.preprocessing.StringLookup(num_oov_indices=1, name=""scalar_string_idx"")
output_layer = lookup_layer(input_layer) # this actually raises a ValueError
fps = preprocessing_stage.FunctionalPreprocessingStage(input_layer, output_layer)
fps.adapt(tf.constant([['testing'], ['one'], ['two'], ['three']]))
```"
50978,RuntimeError: Attempting to capture an EagerTensor without building a function.,"**tensorflow 2.5**


Adding the code of 
```
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
```
indeed solves the problem. But it maynot be what I want. Because in the function of `dense_tensor_to_sparse_tensor` , I indeed need the eager execution of `tensor.numpy()`, which means I should not disable the v2 behaviour. So is this the internal bug of tf 2.5. Any suggestion of how to modify this piece of code?


### source code

```

import tensorflow as tf
import numpy as np
# import tensorflow.compat.v1 as tf
# tf.disable_v2_behavior()


from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops


a_indices = np.array([[0, 0], [2, 3], [2, 4], [3, 0]])
a_values = np.array([1.0, 5.0, -1.0, -2.0], np.float32)
a_dense_shape = [4, 5]

a_st = tf.sparse.SparseTensor(a_indices, a_values, a_dense_shape)

def dense_tensor_to_sparse_tensor(tensor):

    col = tensor.shape.as_list()[0]
    print(col)

    x = np.arange(col)
    y = np.zeros(1)
    xi, yi = np.meshgrid(x, y)
    sparse_tensor = tf.sparse.SparseTensor(indices=np.array(np.vstack([xi.ravel(), yi.ravel()]).T),
                                           values=tensor.numpy(),
                                           dense_shape=[col, 1])
    return sparse_tensor


b_indices = np.array([[0,0], [1,0], [2,0], [3,0],[4,0]])
# b_indices = np.array([[0,0], [0,1], [0,2], [0,3],[0,4]])
b_values = np.array([2.0, 7.0, 8.0,9.0,10.0], np.float32)
b_dense_shape = [5,1]

B = tf.constant([2.0, 7.0, 8.0,9.0,10.0])
B_sparse = dense_tensor_to_sparse_tensor(B)
print(B_sparse.indices, B_sparse.values, B_sparse.dense_shape)

with tf.compat.v1.Session() as sess:
    # Define (COO format) Sparse Tensors over Numpy arrays
    a_st = tf.sparse.SparseTensor(a_indices, a_values, a_dense_shape)
    # b_st = tf.sparse.SparseTensor(b_indices, b_values, b_dense_shape)
    b_st = B_sparse

    # Convert SparseTensors to CSR SparseMatrix
    a_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
        a_st.indices, a_st.values, a_st.dense_shape)
    b_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(
        b_st.indices, b_st.values, b_st.dense_shape)

    # Compute the CSR SparseMatrix matrix multiplication
    c_sm = sparse_csr_matrix_ops.sparse_matrix_sparse_mat_mul(
        a=a_sm, b=b_sm, type=tf.float32)

    # Convert the CSR SparseMatrix product to a dense Tensor
    c_sm_dense = sparse_csr_matrix_ops.csr_sparse_matrix_to_dense(
        c_sm, tf.float32)
    # Evaluate the dense Tensor value
    c_sm_dense_value = sess.run(c_sm_dense)
    print(c_sm_dense_value)
    # print(sess.run(a_st))

```

### **error  message:**
```


Traceback (most recent call last):
  File ""test3.py"", line 92, in <module>
    b_st.indices, b_st.values, b_st.dense_shape)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/ops/linalg/sparse/gen_sparse_csr_matrix_ops.py"", line 1332, in sparse_tensor_to_csr_sparse_matrix
    dense_shape=dense_shape, name=name)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 522, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/profiler/trace.py"", line 163, in wrapped
    return func(*args, **kwargs)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1525, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.

```"
50977,Issue with saving trained model of module TensorFlow Recommenders (tfrs),"Hi,

I'm currently working on a model of module TensorFlow Recommenders (tfrs):

https://www.tensorflow.org/recommenders/examples/quickstart?hl=en

I want to save the model after builting, compling and fitting it, and load it for prediction, but it doesn't work with functions .save() from tf.saved_model and .save_model() from tf.keras.models. I'll appriciate it if someone share any expiriences about it.  Thanks :)

"
50975,failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal,"Hello,

I am trying to train a neural network with multiple GPUs on multiple nodes, I have a .pbs script which starts, for each node/worker, the following program:

```
import os
import sys
import json
import time
import tensorflow as tf


per_worker_batch_size = 256
hosts = sys.argv[1].split(',')
task_id = int(sys.argv[2])
num_workers = len(hosts)
tab = []
for host in hosts:
    tab.append(str(host)+"":2222"")
cluster = tf.train.ClusterSpec({'worker': tab})
cluster_resolver = tf.distribute.cluster_resolver.SimpleClusterResolver(cluster,
                                         task_type='worker', task_id=task_id,
                                         num_accelerators={'GPU': 0})
data_options = tf.data.Options()
data_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
options = tf.distribute.experimental.CommunicationOptions(implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)
strategy = tf.distribute.MultiWorkerMirroredStrategy(cluster_resolver=cluster_resolver, communication_options=options)       
global_batch_size = per_worker_batch_size * num_workers

from Controller import *
from Utils import *
import numpy as np

def main():

    with strategy.scope():
        model = get_compiled_cnn_model()


    X = np.random.rand(10000,8,900)
    y = np.random.choice(2, 10000)
    y = keras.utils.to_categorical(y, num_classes=2)
    
    
    epochs_=5
    history = train_child(X, y, model, global_batch_size, epochs_, data_options, callbacks=[])



    
def get_compiled_cnn_model():

    outputs = []
    input_shape = (8, 900, 1)
    inputs = keras.Input(shape=(8, 900))
    x = layers.Reshape((8,900,1))(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Conv2D(10, (2, 10), padding=""same"", activation='relu')(x)
    outputs.append(x)

    x = layers.Flatten()(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dropout(0.25)(x)
    x = layers.Dense(10)(x)
    x = layers.Dropout(.25)(x)

    outputss = layers.Dense(2, activation='softmax')(x)
    model = keras.Model(inputs=inputs, outputs=outputss)
    loss = keras.losses.CategoricalCrossentropy()
    model.compile(loss=loss, optimizer=keras.optimizers.Adam(1e-3), metrics=[""accuracy""])

    return model



def train_child(X, y, model, batch_size, epochs_child, options, callbacks):

    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, shuffle=True)
    train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))
    val_data = tf.data.Dataset.from_tensor_slices((X_val, y_val))

    train_data = train_data.batch(batch_size)
    val_data = val_data.batch(batch_size)
    train_data = train_data.with_options(options)
    val_data = val_data.with_options(options)

    call = None

    if(len(callbacks)>0):
        call = callbacks
    history = model.fit(
            train_data,
            validation_data=val_data,
            epochs=epochs_child,
            batch_size=batch_size,
            callbacks=call,
            verbose=1,
        )
    return history     

    
if __name__ == ""__main__"":

    main()
```

The following error appear when running the script:

> F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal


This code is working on 1 node with mutiple GPUs but it is not working on multiple nodes.


Also here is the content of the yml file from the conda env I am using (called TestPythonGPU):
```

name: TestPythonGPU
channels:
  - anaconda
  - conda-forge
  - defaults
dependencies:
  - _libgcc_mutex=0.1=main
  - _openmp_mutex=4.5=1_gnu
  - _tflow_select=2.1.0=gpu
  - absl-py=0.13.0=py38h06a4308_0
  - aiohttp=3.7.4=py38h27cfd23_1
  - astor=0.8.1=py38h06a4308_0
  - astunparse=1.6.3=py_0
  - async-timeout=3.0.1=py38h06a4308_0
  - attrs=21.2.0=pyhd3eb1b0_0
  - blas=1.0=openblas
  - blinker=1.4=py38h06a4308_0
  - brotlipy=0.7.0=py38h27cfd23_1003
  - c-ares=1.17.1=h27cfd23_0
  - ca-certificates=2021.7.5=h06a4308_1
  - cachetools=4.2.2=pyhd3eb1b0_0
  - cairo=1.14.12=h8948797_3
  - certifi=2021.5.30=py38h06a4308_0
  - cffi=1.14.5=py38h261ae71_0
  - chardet=3.0.4=py38h06a4308_1003
  - click=8.0.1=pyhd3eb1b0_0
  - colorama=0.4.4=pyhd3eb1b0_0
  - coverage=5.5=py38h27cfd23_2
  - cryptography=3.4.7=py38hd23ed53_0
  - cudatoolkit=10.1.243=h6bb024c_0
  - cudnn=7.6.5=cuda10.1_0
  - cupti=10.1.168=0
  - cycler=0.10.0=py38_0
  - cython=0.29.23=py38h2531618_0
  - dbus=1.13.18=hb2f20db_0
  - expat=2.4.1=h2531618_2
  - fontconfig=2.13.1=h6c09931_0
  - freetype=2.10.4=h5ab3b9f_0
  - fribidi=1.0.10=h7b6447c_0
  - future=0.18.2=py38_1
  - gast=0.4.0=py_0
  - glib=2.56.2=hd408876_0
  - google-auth=1.32.0=pyhd3eb1b0_0
  - google-auth-oauthlib=0.4.4=pyhd3eb1b0_0
  - google-pasta=0.2.0=py_0
  - graphite2=1.3.14=h23475e2_0
  - graphviz=2.40.1=h21bd128_2
  - grpcio=1.38.1=py38hdd6454d_0
  - gst-plugins-base=1.14.0=hbbd80ab_1
  - gstreamer=1.14.0=hb31296c_0
  - h5py=2.10.0=nompi_py38h9915d05_106
  - harfbuzz=1.8.8=hffaf4a1_0
  - hdf5=1.10.6=hb1b8bf9_0
  - icu=58.2=he6710b0_3
  - idna=2.10=pyhd3eb1b0_0
  - importlib-metadata=3.10.0=py38h06a4308_0
  - intel-openmp=2021.2.0=h06a4308_610
  - joblib=1.0.1=pyhd3eb1b0_0
  - jpeg=9b=h024ee3a_2
  - keras=2.4.3=0
  - keras-base=2.4.3=py_0
  - keras-preprocessing=1.1.2=pyhd3eb1b0_0
  - keras-tuner=1.0.1=py_0
  - kiwisolver=1.3.1=py38h2531618_0
  - lcms2=2.12=h3be6417_0
  - ld_impl_linux-64=2.35.1=h7274673_9
  - libffi=3.3=he6710b0_2
  - libgcc-ng=9.3.0=h5101ec6_17
  - libgfortran-ng=7.5.0=ha8ba4b0_17
  - libgfortran4=7.5.0=ha8ba4b0_17
  - libgomp=9.3.0=h5101ec6_17
  - libopenblas=0.3.13=h4367d64_0
  - libpng=1.6.37=hbc83047_0
  - libprotobuf=3.14.0=h8c45485_0
  - libstdcxx-ng=9.3.0=hd4cf53a_17
  - libtiff=4.2.0=h85742a9_0
  - libuuid=1.0.3=h1bed415_2
  - libwebp-base=1.2.0=h27cfd23_0
  - libxcb=1.14=h7b6447c_0
  - libxml2=2.9.12=h03d6c58_0
  - lz4-c=1.9.3=h2531618_0
  - markdown=3.3.4=py38h06a4308_0
  - matplotlib=3.3.4=py38h578d9bd_0
  - matplotlib-base=3.3.4=py38h62a2d02_0
  - mkl=2021.2.0=h06a4308_296
  - mkl-service=2.3.0=py38h27cfd23_1
  - multidict=5.1.0=py38h27cfd23_2
  - ncurses=6.2=he6710b0_1
  - numpy=1.19.1=py38h30dfecb_0
  - numpy-base=1.19.1=py38h75fe3a5_0
  - oauthlib=3.1.0=py_0
  - olefile=0.46=py_0
  - openblas=0.3.4=h9ac9557_1000
  - openssl=1.1.1k=h27cfd23_0
  - opt_einsum=3.3.0=pyhd3eb1b0_1
  - pandas=1.1.3=py38he6710b0_0
  - pango=1.42.4=h049681c_0
  - pcre=8.45=h295c915_0
  - pillow=8.2.0=py38he98fc37_0
  - pip=21.1.3=py38h06a4308_0
  - pixman=0.40.0=h7b6447c_0
  - protobuf=3.14.0=py38h2531618_1
  - pyasn1=0.4.8=py_0
  - pyasn1-modules=0.2.8=py_0
  - pycparser=2.20=py_2
  - pydot=1.4.1=py38_0
  - pyjwt=1.7.1=py38_0
  - pyopenssl=20.0.1=pyhd3eb1b0_1
  - pyparsing=2.4.7=pyhd3eb1b0_0
  - pyqt=5.9.2=py38h05f1152_4
  - pysocks=1.7.1=py38h06a4308_0
  - python=3.8.10=h12debd9_8
  - python-dateutil=2.8.1=pyhd3eb1b0_0
  - python-flatbuffers=2.0=pyhd8ed1ab_0
  - python_abi=3.8=1_cp38
  - pytz=2021.1=pyhd3eb1b0_0
  - pyyaml=5.4.1=py38h27cfd23_1
  - qt=5.9.7=h5867ecd_1
  - readline=8.1=h27cfd23_0
  - requests=2.25.1=pyhd3eb1b0_0
  - requests-oauthlib=1.3.0=py_0
  - rsa=4.7.2=pyhd3eb1b0_1
  - scikit-learn=0.24.1=py38ha9443f7_0
  - scipy=1.6.2=py38hf56f3a7_1
  - setuptools=52.0.0=py38h06a4308_0
  - sip=4.19.13=py38he6710b0_0
  - six=1.16.0=pyh6c4a22f_0
  - sqlite=3.36.0=hc218d9a_0
  - tabulate=0.8.9=py38h06a4308_0
  - tensorboard=2.4.0=pyhc547734_0
  - tensorboard-plugin-wit=1.8.0=pyh44b312d_0
  - tensorflow=2.4.1=gpu_py38h8a7d6ce_0
  - tensorflow-base=2.4.1=gpu_py38h29c2da4_0
  - tensorflow-estimator=2.5.0=pyh81a9013_1
  - tensorflow-gpu=2.4.1=h30adc30_0
  - termcolor=1.1.0=py38h06a4308_1
  - terminaltables=3.1.0=py_0
  - threadpoolctl=2.1.0=pyh5ca1d4c_0
  - tk=8.6.10=hbc83047_0
  - tornado=6.1=py38h27cfd23_0
  - tqdm=4.61.2=pyhd3eb1b0_1
  - typing-extensions=3.10.0.0=hd8ed1ab_0
  - typing_extensions=3.10.0.0=pyha770c72_0
  - urllib3=1.26.6=pyhd3eb1b0_1
  - werkzeug=1.0.1=pyhd3eb1b0_0
  - wheel=0.36.2=pyhd3eb1b0_0
  - wrapt=1.12.1=py38h7b6447c_1
  - xz=5.2.5=h7b6447c_0
  - yaml=0.2.5=h7b6447c_0
  - yarl=1.6.3=py38h27cfd23_0
  - zipp=3.5.0=pyhd3eb1b0_0
  - zlib=1.2.11=h7b6447c_3
  - zstd=1.4.9=haebb681_0
prefix: /data/leuven/339/vsc33965/miniconda3/envs/TestPythonGPU

```



Thank you for your support

Aymeric
"
50974,"None of the Demo Edge TPU Models Work - “Module Provided has model identifier 'l><b', should be 'TFL3'”","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10

- TensorFlow installed from (source or binary):
Tensorflow 2.5

- Python version:
Python 3.8
- Installed using virtualenv? pip? conda?:
pip


****Describe the problem****

Using a Coral Devboard, and trying to run the `detect.py` file from https://github.com/google-coral/pycoral/blob/master/examples/detect_image.py with the models on the https://coral.ai/models/object-detection/ page. Tried `ssd mobilenetv2` and `EfficientDet Lite`, both get the same error:

```
Traceback (most recent call last):
  File ""detect.py"", line 108, in <module>
    main()
  File ""detect.py"", line 73, in main
    interpreter = make_interpreter(args.model)
  File ""/usr/lib/python3/dist-packages/pycoral/utils/edgetpu.py"", line 93, in make_interpreter
    model_path=model_path_or_content, experimental_delegates=delegates)
  File ""/usr/lib/python3/dist-packages/tflite_runtime/interpreter.py"", line 351, in __init__
    experimental_preserve_all_tensors))
ValueError: Model provided has model identifier 'l><b', should be 'TFL3'
```

Not sure what the problem is, since both get the exact same error. Help is appreciated!


**Provide the exact sequence of commands / steps that you executed before running into the problem**
I ran the command `python3 detect.py -m efficientdet_lite3_512_ptq_edgetpu.tflite -i parking.jpg -l coco_labels.txt -o result.jpg`
"
50973,Documentation: old installation requirements,"Hi,

on the [page with installation instructions](https://www.tensorflow.org/install?hl=en), the listed requirements have not been updated: it lists Python 3.6–3.8 explicitly.

According to the [pip installation guide](https://www.tensorflow.org/install/pip), Python 3.9 is a valid requirement.

I suggest updating the page.

Best regards
Thomas"
50971,Keras.io XRay TPU example fails on 2.6.0-rc1,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: none
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.6.0-rc1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Current Colab (July 27, 2021)
- GPU model and memory: TPU, 8 core, Colab standard

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Example fails in model.fit()

**Describe the expected behavior**
Complete notebook finishes in Colab with TPU, standard memory size

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Open this example in Colab. Set runtime to TPU with standard size memory. 

https://keras.io/examples/vision/xray_classification_with_tpus/

Install Tensorflow 2.6.0-rc1 at beginning:
!pip uninstall -y tensorflow
!pip install -q tensorflow-2.6.0-rc1

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Run entire notebook via F9. You will eventually receive this stack trace in model.fit(), before finishing any epochs:

```
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-38-2dcbec06520a> in <module>()
      1 with strategy.scope():
----> 2     model = build_model()
      3 
      4     METRICS = [
      5         tf.keras.metrics.BinaryAccuracy(),

26 frames
<ipython-input-34-b10aa2c50d05> in build_model()
      3     inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
      4     x = preprocessing.Rescaling(1.0 / 255)(inputs)
----> 5     x = layers.Conv2D(16, 3, activation=""relu"", padding=""same"")(x)
      6     x = layers.Conv2D(16, 3, activation=""relu"", padding=""same"")(x)
      7     x = layers.MaxPool2D()(x)

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    975     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):
    976       return self._functional_construction_call(inputs, args, kwargs,
--> 977                                                 input_list)
    978 
    979     # Maintains info about the `Layer.call` stack.

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
   1113       # Check input assumptions set after layer building, e.g. input shape.
   1114       outputs = self._keras_tensor_symbolic_call(
-> 1115           inputs, input_masks, args, kwargs)
   1116 
   1117       if outputs is None:

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)
    846       return tf.nest.map_structure(keras_tensor.KerasTensor, output_signature)
    847     else:
--> 848       return self._infer_output_signature(inputs, args, kwargs, input_masks)
    849 
    850   def _infer_output_signature(self, inputs, args, kwargs, input_masks):

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)
    884           # overridden).
    885           # TODO(kaftan): do we maybe_build here, or have we already done it?
--> 886           self._maybe_build(inputs)
    887           inputs = self._maybe_cast_inputs(inputs)
    888           outputs = call_fn(inputs, *args, **kwargs)

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _maybe_build(self, inputs)
   2657         # operations.
   2658         with tf_utils.maybe_init_scope(self):
-> 2659           self.build(input_shapes)  # pylint:disable=not-callable
   2660       # We must set also ensure that the layer is marked as built, and the build
   2661       # shape is stored since user defined build functions may not be calling

/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional.py in build(self, input_shape)
    202         constraint=self.kernel_constraint,
    203         trainable=True,
--> 204         dtype=self.dtype)
    205     if self.use_bias:
    206       self.bias = self.add_weight(

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)
    661         synchronization=synchronization,
    662         aggregation=aggregation,
--> 663         caching_device=caching_device)
    664     if regularizer is not None:
    665       # TODO(fchollet): in the future, this should be handled at the

/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)
    816         dtype=dtype,
    817         initializer=initializer,
--> 818         **kwargs_for_getter)
    819 
    820     # If we set an initializer and the variable processed it, tracking will not

/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)
    127       synchronization=synchronization,
    128       aggregation=aggregation,
--> 129       shape=variable_shape if variable_shape else None)
    130 
    131 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)
    264   def __call__(cls, *args, **kwargs):
    265     if cls is VariableV1:
--> 266       return cls._variable_v1_call(*args, **kwargs)
    267     elif cls is Variable:
    268       return cls._variable_v2_call(*args, **kwargs)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)
    225         synchronization=synchronization,
    226         aggregation=aggregation,
--> 227         shape=shape)
    228 
    229   def _variable_v2_call(cls,

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py in getter(**kwargs)
     65 
     66   def getter(**kwargs):
---> 67     return captured_getter(captured_previous, **kwargs)
     68 
     69   return getter

/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py in creator_with_resource_vars(next_creator, **kwargs)
   2125         checkpoint_restore_uid = None
   2126 
-> 2127       created = self._create_variable(next_creator, **kwargs)
   2128 
   2129       if checkpoint_restore_uid is not None:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _create_variable(self, next_creator, **kwargs)
   1167         self._container_strategy(), _real_mirrored_creator,
   1168         distribute_utils.TPU_VARIABLE_CLASS_MAPPING,
-> 1169         distribute_utils.TPU_VARIABLE_POLICY_MAPPING, **kwargs)
   1170 
   1171   def _gather_to_implementation(self, value, destinations, axis, options):

/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_utils.py in create_mirrored_variable(strategy, real_mirrored_creator, class_mapping, policy_mapping, **kwargs)
    306   # here.
    307   with tape.stop_recording():
--> 308     value_list = real_mirrored_creator(**kwargs)
    309     # MirroredVariable is recreated during saved_model loading, and its
    310     # component variables (value_list) will have None initializer. We

/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _real_mirrored_creator(**kwargs)
   1146             with maybe_init_scope():
   1147               initial_value = initial_value() if callable(
-> 1148                   initial_value) else initial_value
   1149 
   1150           if i > 0:

/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py in __call__(self, shape, dtype, **kwargs)
    515     else:
    516       limit = math.sqrt(3.0 * scale)
--> 517       return self._random_generator.random_uniform(shape, -limit, limit, dtype)
    518 
    519   def get_config(self):

/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py in random_uniform(self, shape, minval, maxval, dtype)
    971       op = tf.random.uniform
    972     return op(
--> 973         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)
    974 
    975   def truncated_normal(self, shape, mean, stddev, dtype):

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    204     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    205     try:
--> 206       return target(*args, **kwargs)
    207     except (TypeError, ValueError):
    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/random_ops.py in random_uniform(shape, minval, maxval, dtype, seed, name)
    313           result = math_ops.multiply(result, maxval)
    314       else:
--> 315         result = math_ops.add(result * (maxval - minval), minval, name=name)
    316     # TODO(b/132092188): C++ shape inference inside functional ops does not
    317     # cross FuncGraph boundaries since that information is only available in

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
   1365         #   r_binary_op_wrapper use different force_same_dtype values.
   1366         x, y = maybe_promote_tensors(x, y, force_same_dtype=False)
-> 1367         return func(x, y, name=name)
   1368       except (TypeError, ValueError) as e:
   1369         # Even if dispatching the op failed, the RHS may be a tensor aware

/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    204     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    205     try:
--> 206       return target(*args, **kwargs)
    207     except (TypeError, ValueError):
    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py in subtract(x, y, name)
    546 @dispatch.add_dispatch_support
    547 def subtract(x, y, name=None):
--> 548   return gen_math_ops.sub(x, y, name)
    549 
    550 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py in sub(x, y, name)
  10642       return _result
  10643     except _core._NotOkStatusException as e:
> 10644       _ops.raise_from_not_ok_status(e, name)
  10645     except _core._FallbackException:
  10646       pass

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6939   message = e.message + ("" name: "" + name if name is not None else """")
   6940   # pylint: disable=protected-access
-> 6941   six.raise_from(core._status_to_exception(e.code, message), None)
   6942   # pylint: enable=protected-access
   6943 

/usr/local/lib/python3.7/dist-packages/six.py in raise_from(value, from_value)

NotFoundError: '_EagerConst' is neither a type of a primitive operation nor a name of a function registered in binary running on n-d02110c1-w-0. Make sure the operation or function is registered in the binary running in this process. [Op:Sub]
```"
50970,Node number 106 (FlexTensorScatterUpdate) failed to prepare.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- TensorFlow installed from (source or binary):source  ,pip install tensorflow-gpu==2.5.0
- TensorFlow version (or github SHA if from source):2.5.0


**Provide the text output from tflite_convert**

```
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
Model: ""model_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_images (InputLayer)    [(1, 128, 128, 3)]        0         
_________________________________________________________________
face_detetor_1 (FaceDetetor) (None, 1, 17)             101390    
=================================================================
Total params: 101,390
Trainable params: 101,390
Non-trainable params: 0
_________________________________________________________________
```

**Standalone code to reproduce the issue** 

[colab](https://colab.research.google.com/drive/1T9kF-dn4WeH1ndN19ao5Hj0SV9Kuutrr?usp=sharing) 
[blazeface_tf.h5](https://drive.google.com/file/d/1yKLW5F7-6x9ylH65MgVxH5N5oQJgK8wq/view?usp=sharing)

**Any other info / logs**
I use this [codes](https://colab.research.google.com/drive/1T9kF-dn4WeH1ndN19ao5Hj0SV9Kuutrr?usp=sharing)  to  add some postprocess layer since I need to use NMS op after the origin model.After add postprocess layer and convert keras model to savedmodel, I convert the savedmodel to tf-lite model and there is a correct result. Then I need to depoly the tf-lite model in Android, I got an error when loading the tf-lite model:
```
try {
      detector =
          TFLiteObjectDetectionAPIModel.create(
              getAssets(),
              TF_OD_API_MODEL_FILE,
              TF_OD_API_LABELS_FILE,
              TF_OD_API_INPUT_SIZE,
              TF_OD_API_IS_QUANTIZED);
      cropSize = TF_OD_API_INPUT_SIZE;
    } catch (final IOException e) {
      e.printStackTrace();
      LOGGER.e(e, ""Exception initializing classifier!"");
      Toast toast =
          Toast.makeText(
              getApplicationContext(), ""Classifier could not be initialized"", Toast.LENGTH_SHORT);
      toast.show();
      finish();
    }
```
log
```
I/tflite: Initialized TensorFlow Lite runtime.
E/tensorflow: CameraActivity: Exception!
    java.lang.RuntimeException: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
    Node number 106 (FlexTensorScatterUpdate) failed to prepare.
    
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:129)
        at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:122)
        at org.tensorflow.lite.examples.detection.CameraActivity.onPreviewFrame(CameraActivity.java:200)
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1264)
        at android.os.Handler.dispatchMessage(Handler.java:110)
        at android.os.Looper.loop(Looper.java:219)
        at android.app.ActivityThread.main(ActivityThread.java:8393)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:513)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1055)
     Caused by: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
    Node number 106 (FlexTensorScatterUpdate) failed to prepare.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:87)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:266)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:251)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:127)
        	... 9 more
```
 
Thank you for your reply!

"
50968,At Chrome run Tensorflow.js.,"Use the square layer tf.layers.conv2d, This file prompts a run error.

webgl_util.js

Error: Failed to compile fragment shader."
50967,protobuf error while saving the model ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Ubuntu 16.04.7 LTS
- TensorFlow installed from: conda
-  TensorFlow version: 1.15.0
- Python version: 3.6.13 from Anaconda
- GPU: Quadro P6000 (Memory 24.5GB)

I am trying to adopt the pixelcnn++ code available at https://github.com/openai/pixel-cnn. Initiallly with tensorflow version 1.10.0 it was working fine. Later I updated the code with an addition of incorporating ` tf.compat.v1.extract_image_patches` and run it using tensorflow version 1.15.0 (as ` tf.compat.v1.extract_image_patches` is nor compatible with tensorflow 1.10.0). 

While saving the model after every 1000 iterations with: 
`saver.save(sess, args.save_dir + '/best_params_' + args.data_set + '.ckpt') `      
error occurs:
```
[libprotobuf ERROR google/protobuf/wire_format_lite.cc:577] String field 'tensorflow.TensorShapeProto.Dim.name' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. 
Traceback (most recent call last):
  File ""train_pxpp_softmax_random_patch_extraction.py"", line 325, in <module>
    saver.save(sess, args.save_dir + '/best_params_' + args.data_set + '.ckpt')
  File ""/home/nisar/anaconda3/envs/pixelcnn/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py"", line 1203, in save
    save_debug_info=save_debug_info)
  File ""/home/nisar/anaconda3/envs/pixelcnn/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py"", line 1246, in export_meta_graph
    graph_def=ops.get_default_graph().as_graph_def(add_shapes=True),
  File ""/home/nisar/anaconda3/envs/pixelcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3238, in as_graph_def
    result, _ = self._as_graph_def(from_version, add_shapes)
  File ""/home/nisar/anaconda3/envs/pixelcnn/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3166, in _as_graph_def
    graph.ParseFromString(compat.as_bytes(data))
google.protobuf.message.DecodeError: Error parsing message
```
Though it saves the model succesffuly at iteration 0. I also tried to save the model after every 500 iterations and it works fine for 0 and 500 but same error occurs at 1000 iteration. Following is the complete updated pixelcnn++ code with additions:
"
50966,The max version of bazel supported by tensorflow should be increased to 4.1.0 or higher,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Windows 10 21H1
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 2.4

**Describe the problem**
I'm a member of Microsoft VCPKG team, we recently upgraded the version of bazel used in vcpkg to 4.1.0, then tensorflow build failed with following error:
```
You have bazel 4.1.0 installed.
Please downgrade your bazel installation to version 3.99.0 or lower to build TensorFlow! To downgrade: download the installer for the old version (from https://github.com/bazelbuild/bazel/releases) then run the installer.
```
This issue is due to the fact that tensorflow has set the maximum supported version of bazel to 3.99.0 on line 53 of the https://github.com/tensorflow/tensorflow/blob/master/configure.py file.

For fixing this issue, the max version of bazel supported by tensorflow should be increased to 4.1.0 or higher.

**Any other info / logs**
I have tested that tensorflow could installed successfully when using bazel 4.1.0.
"
50965,Tensorflow Lite Model Maker cannot train EfficientDet-Lite using Cloud TPU,"**System information**
- Have I written custom code: minimally modified stock example
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab Pro w/TPU
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5

**Describe the current behavior**

Attempting to use a CloudTPU for training results in the following error:
```
INFO:absl:Using /tmp/tfhub_modules to cache modules.
INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/efficientdet/lite0/feature-vector/1'.
INFO:absl:Downloaded https://tfhub.dev/tensorflow/efficientdet/lite0/feature-vector/1, Total size: 29.61MB
INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/efficientdet/lite0/feature-vector/1'.
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-9-fb7d2e23be2c> in <module>()
----> 1 model = object_detector.create(train_data, model_spec=spec, batch_size=8, epochs=4, train_whole_model=True, validation_data=validation_data)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in shape(self)
   1196         # `_tensor_shape` is declared and defined in the definition of
   1197         # `EagerTensor`, in C.
-> 1198         self._tensor_shape = tensor_shape.TensorShape(self._shape_tuple())
   1199       except core._NotOkStatusException as e:
   1200         six.raise_from(core._status_to_exception(e.code, e.message), None)

InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /tmp/tfhub_modules/0771ebbebbfa831cd20c20680920ec4ad9deb2bd/variables/variables: Unimplemented: File system scheme '[local]' not implemented (file: '/tmp/tfhub_modules/0771ebbebbfa831cd20c20680920ec4ad9deb2bd/variables/variables')
```

**Standalone code to reproduce the issue**

See: https://gist.github.com/tve/615f4b51fa88dc643358176c86d6537e
Use the ""open in colab"" button and run it to get the error (or just read the results in the gist).
The original tutorial is https://www.tensorflow.org/lite/tutorials/model_maker_object_detection
I added:
- `tpu = tf.distribute.cluster_resolver.TPUClusterResolver()`

and I changed:
- from `spec = model_spec.get('efficientdet_lite0')`
- to `spec = object_detector_spec.efficientdet_lite0_spec(strategy='tpu', tpu=tpu.master(), debug=True)`

It's quite possible that I'm missing some magic, but I cannot find any tutorial or example that shows the use of model maker to train an object detection model using cloud TPU..."
50964,SparseCategoricalCrossentropy and Mixed Precision Training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  Binary
- TensorFlow version (use command below): v2.5.0-0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2
- GPU model and memory: A6000

**Describe the current behavior**

`sparse_categorical_crossentropy` in `losses.py` performs an unnecessary [cast](https://github.com/tensorflow/tensorflow/blob/8c541bab667488249a34404170985dff8a9bab56/tensorflow/python/keras/losses.py#L1751) of `y_true` to `y_pred.dtype` since it's then [cast](https://github.com/keras-team/keras/blob/d3688b72924a4235598f0f80038de8c897f44799/keras/backend.py#L4952) to `int64` in `sparse_categorical_crossentropy` in `keras.backend.py`.

This seems to be the same code as in `categorical_crossentropy`, but causes issues with sparse, especially with mixed precision training and float16 as the loss in precision causes incorrect encodings or labels outside the domain resulting in incorrect or `nan` loss. With float16, issues start with a couple thousand labels and a couple hundred labels with bfloat16.

**Describe the expected behavior**

Cast to `y_pred.dtype` should be skipped.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): 
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1oRbNOnCo1i2HcXD2V4_-D1Bz2EVxiT65

"
50963,bug,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50960,"""ValueError: Cannot take the length of Shape with unknown rank"" or ""InvalidArgumentError: Length for attr 'output_shapes' of 0 must be at least minimum 1"" using tf.data.Dataset tensors","Hello I'm new to machine learning and for my project I need to load training set and validation set from disk into a tf.data.Dataset since they are too big to fit in memory.

running the code in google colab using gpu or in my local machine with tf 2.5.0 i get the following problems:

first I just load the datasets reading the tf record

```
#reading training and validation dataset
def read_tfrecord(example):
  tfrecord_format = (
      {
          ""x"": tf.io.FixedLenFeature([], tf.string),
          ""y"": tf.io.FixedLenFeature([], tf.string),
      }
  )
  example = tf.io.parse_single_example(example, tfrecord_format)
  x = tf.io.parse_tensor(example['x'], out_type=tf.float32)
  y = tf.io.parse_tensor(example['y'], out_type=tf.double)
    

  return x,y

batch_size = 32

filename = ""training.tfrecord""
training_dataset = tf.data.TFRecordDataset(filename).map(read_tfrecord)
training_dataset = training_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)

filename = ""validation.tfrecord""
validation_dataset = tf.data.TFRecordDataset(filename).map(read_tfrecord)
validation_dataset = validation_dataset.batch(batch_size)


model.fit(training_dataset,
          validation_data=validation_dataset,
          epochs=35,
          verbose=1)
```

and then I get the error ` ValueError: Cannot take the length of Shape with unknown rank
`
So as suggested on this thread https://github.com/tensorflow/tensorflow/issues/24520 I set set_shape on read_tfrecord method 

```
def read_tfrecord(example):
  tfrecord_format = (
      {
          ""x"": tf.io.FixedLenFeature([], tf.string),
          ""y"": tf.io.FixedLenFeature([], tf.string),
      }
  )
  example = tf.io.parse_single_example(example, tfrecord_format)
  x = tf.io.parse_tensor(example['x'], out_type=tf.float32)
  y = tf.io.parse_tensor(example['y'], out_type=tf.double)
    
  x = x.set_shape((None, None, None))
  y = y.set_shape((None, None)

  return x,y
```

So I get the error
`InvalidArgumentError: Length for attr 'output_shapes' of 0 must be at least minimum 1`

Any suggestion?"
50959,Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.6.13
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2 8.1
- GPU model and memory: RTX 2080 Ti

**Describe the current behavior**
TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(""Placeholder_1:0"", shape=(None, 2), dtype=int64), values=Tensor(""Placeholder:0"", shape=(None,), dtype=float32), dense_shape=Tensor(""PlaceholderWithDefault:0"", shape=(2,), dtype=int64)). Consider casting elements to a supported type.

**Describe the expected behavior**
The same results as dense tensor.

We encounter this issue when we try to use sparse tensors in keras. We checked ReLU and BatchNormalization layer and we met this error. From the document ""Working with sparse tensors"", ""The tf.keras API natively supports sparse tensors without any expensive casting or conversion ops"". But we found a similar issue 25980 which meets a similar error but it's about dropout layer. I checked dropout layer and confirmed it is fixed in tf2.5, but other layers may still have bugs.

So my question is, is it safe to assume all tf.keras apis work with sparse tensors?

**Standalone code to reproduce the issue**
import tensorflow as tf
input = tf.keras.layers.Input(shape=(4), sparse=True)
output = tf.keras.layers.ReLU()(input)
\# output = tf.keras.layers.BatchNormalization()(input)
model = tf.keras.Model(inputs=[input], outputs=[output])
print(model(np.array([[1, 0, 1, 0]])))
"
50958,Code not visible in dark theme in the Tensorflow documentation,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (WSL2)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached. <br>
This is the currently output shown in tensorflow documentation :  https://www.tensorflow.org/api_docs/python/tf/keras/Model <br>
![image](https://user-images.githubusercontent.com/47894634/127043452-73d5c066-007e-4833-8cfe-7abdf6fee682.png)
"
50957,resize_tensor_input does not change shape in tflite interpreter for efficientdet models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04 LTS
- TensorFlow installed from (source or binary): conda tf
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.8


**Describe the current behavior**
I am trying to modify the batch size of a tflite efficientdet model following this [official tf guide](https://colab.research.google.com/github/frogermcs/TFLite-Tester/blob/master/notebooks/Testing_TFLite_model.ipynb#scrollTo=VXX8lJkPRYFq)
However I cannot modify the output shapes.

I download the model from the [TF hub](https://tfhub.dev/tensorflow/lite-model/efficientdet/lite2/detection/default/1) and load them into `model_path`.

```python
tflite_interpreter = tf.lite.Interpreter(model_path, num_threads=1)
input_details = tflite_interpreter.get_input_details()
output_details = tflite_interpreter.get_output_details()
```

Then just to be sure that everything works fine, I set `batch_size=1` which is the default:
```python
batch_size = 1
# tflite_interpreter.resize_tensor_input(output_details[0]['index'], (batch_size, 25, 4,))
# tflite_interpreter.resize_tensor_input(output_details[1]['index'], (batch_size, 25,))
# tflite_interpreter.resize_tensor_input(output_details[2]['index'], (batch_size, 25,))
# tflite_interpreter.resize_tensor_input(output_details[3]['index'], (batch_size,))
tflite_interpreter.resize_tensor_input(input_details[0]['index'], (batch_size, model_res, model_res, 3))
tflite_interpreter.allocate_tensors()

# print(input_details)
for od in tflite_interpreter.get_input_details():
    print(""\n"".join(""{}\t{}"".format(k, v) for k, v in od.items()))
    print('___')
# output details
for od in tflite_interpreter.get_output_details():
    print(""\n"".join(""{}\t{}"".format(k, v) for k, v in od.items()))
    print('___')
```
I obtain the following output
```
name	serving_default_images:0
index	0
shape	[  1 448 448   3]
shape_signature	[  1 448 448   3]
dtype	<class 'numpy.uint8'>
quantization	(0.0078125, 127)
quantization_parameters	{'scales': array([0.0078125], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:3
index	782
shape	[ 1 25  4]
shape_signature	[ 1 25  4]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:2
index	783
shape	[ 1 25]
shape_signature	[ 1 25]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:1
index	784
shape	[ 1 25]
shape_signature	[ 1 25]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:0
index	785
shape	[1]
shape_signature	[1]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
```
so far so good... I kwow that tflite efficient det produces a max of 25 outputs.

Now I try to change the batch size. The input shape changes (now batch size is 4) but nothing changes for the output details.

```python
batch_size = 4

tflite_interpreter = tf.lite.Interpreter(model_path, num_threads=1)
tflite_interpreter.resize_tensor_input(input_details[0]['index'], (batch_size, model_res, model_res, 3))
tflite_interpreter.resize_tensor_input(output_details[0]['index'], (batch_size, 25, 4,))
tflite_interpreter.resize_tensor_input(output_details[1]['index'], (batch_size, 25,))
tflite_interpreter.resize_tensor_input(output_details[2]['index'], (batch_size, 25,))
tflite_interpreter.resize_tensor_input(output_details[3]['index'], (batch_size,))
tflite_interpreter.allocate_tensors()

# print(input_details)
for od in tflite_interpreter.get_input_details():
    print(""\n"".join(""{}\t{}"".format(k, v) for k, v in od.items()))
    print('___')
# output details
for od in tflite_interpreter.get_output_details():
    print(""\n"".join(""{}\t{}"".format(k, v) for k, v in od.items()))
    print('___')
```
```
name	serving_default_images:0
index	0
shape	[  4 448 448   3]
shape_signature	[  4 448 448   3]
dtype	<class 'numpy.uint8'>
quantization	(0.0078125, 127)
quantization_parameters	{'scales': array([0.0078125], dtype=float32), 'zero_points': array([127], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:3
index	782
shape	[ 1 25  4]
shape_signature	[ 1 25  4]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:2
index	783
shape	[ 1 25]
shape_signature	[ 1 25]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:1
index	784
shape	[ 1 25]
shape_signature	[ 1 25]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
name	StatefulPartitionedCall:0
index	785
shape	[1]
shape_signature	[1]
dtype	<class 'numpy.float32'>
quantization	(0.0, 0)
quantization_parameters	{'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}
sparsity_parameters	{}
___
```

I tried this approach with different versions of the efficientdet model (0, 1, 2, 3, 4) changing their respectively  input resolutions accordingly, and still have the same problem.

**Describe the expected behavior**
I expect that the output shape is 4 as I set.

"
50956,Reading TFRecords from S3 with a window shift leads to a large performance degradation,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): tried both types
- TensorFlow version (use command below): 2.4.2
- Python version: 3.8.0
- Bazel version (if compiling from source): 4.1.0
- GCC/Compiler version (if compiling from source): 7.5.0

**Describe the current behavior**
I have a list of filenames of TFRecords that are stored on S3. Each TFRecord contains a list of frames stored in a type: `tf.io.FixedLenFeature((), tf.string)`. If I want to select every 100th frame from a TFRecord, TFRecordDataset downloads the whole file and then select required frames. 

I'm running p3dn.24xlarge that have 100Gb network bandwidth (EC2 and S3 on the same region + VPC).

`iftop` shows average bandwidth around 20Gb and 25 threads (probably, because of this hard limitation: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system.cc#L69 )

Increasing `num_parallel_calls` don't have any affect.

```python
dl = tf.data.TFRecordDataset.from_tensor_slices(filenames)
dl = dl.interleave(
    lambda y: tf.data.TFRecordDataset(y).window(size=1, shift=100, stride=5, drop_remainder=True).flat_map(lambda x: x.batch(1)), 
num_parallel_calls=10)

```
**Describe the expected behavior**
I would've expect any of the two following cases:
* TFRecordDataset downloads only selected frames
* TFRecordDataset scales up to 100Gb of network bandwidth
"
50955,Could not find the DLL(s) 'msvcp140.dll or msvcp140_1.dll',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0
- Python version: 3.8.10
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Intel(R) Iris(R) Plus Graphics


**Describe the problem**

`import tensorflow `
yields

`ImportError: Could not find the DLL(s) 'msvcp140.dll or msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading ""Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019"" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads`

even when I have both `msvcp140.dll` and `msvcp140_1.dll` installed and they are both placed in the directory specified by %PATH% environment variable

```
C:\Users\Rostyslav>where msvcp140.dll
C:\Program Files\Java\jdk-16\bin\msvcp140.dll
C:\Windows\System32\msvcp140.dll
C:\Users\Rostyslav\AppData\Local\Programs\Python\Python39\msvcp140.dll <-- HERE
C:\Users\Rostyslav\AppData\Local\Programs\MiKTeX\miktex\bin\x64\msvcp140.dll
```

Path environment variable looks like this:

![image](https://user-images.githubusercontent.com/49762976/127005254-b1c797c5-ec19-43c5-bb81-564ae13230ab.png)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

in cmd prompt I run `python run_model.py --train --save`, which is a script from github repository that can be found 
[here](https://machine-reasoning-ufrgs.github.io/GNN-GCP/)
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I also tried to get more information about the problem, so I modified tensorflow's `self_check.py`. In `preload_check` in the `except OSError:` handler I added a line `import traceback; traceback.print_exc()`

The whole traceback is
```(base) PS C:\Users\Rostyslav\git\gnn-gcp> python run_model.py --train --save
Traceback (most recent call last):
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\platform\self_check.py"", line 50, in preload_check
    ctypes.WinDLL(dll_name)
  File ""C:\Users\Rostyslav\anaconda3\lib\ctypes\__init__.py"", line 381, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 87] The parameter is incorrect
Traceback (most recent call last):
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\platform\self_check.py"", line 50, in preload_check
    ctypes.WinDLL(dll_name)
  File ""C:\Users\Rostyslav\anaconda3\lib\ctypes\__init__.py"", line 381, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 87] The parameter is incorrect
Traceback (most recent call last):
  File ""run_model.py"", line 6, in <module>
    import tensorflow as tf
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    self_check.preload_check()
  File ""C:\Users\Rostyslav\anaconda3\lib\site-packages\tensorflow\python\platform\self_check.py"", line 55, in preload_check
    raise ImportError(
ImportError: Could not find the DLL(s) 'msvcp140.dll or msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading ""Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019"" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads```
"
50953,Identifying the type of input ,"

Creating a generalized application that can accept both sequence inputs and non-sequence inputs.
To check whether its sequence input or non-sequence input, have written c++ API to get this information.

Need confirmation regarding checking whether it's RNN input or not? 
`    int t_size1 = this->interpreter->tensors_size();
    for (int i = 0; i < t_size1; i++) {
        if (this->interpreter->tensor(i)->name != nullptr) {
            if ((std::string(this->interpreter->tensor(i)->name)
                     .compare(""tfl.unidirectional_sequence_lstm"") == 0) ||
                (std::string(this->interpreter->tensor(i)->name).compare(""tfl.lstm"") == 0) ||
                (std::string(this->interpreter->tensor(i)->name).compare(""tfl.basic_lstm"") == 0) ||
                (std::string(this->interpreter->tensor(i)->name)
                     .compare(""tfl.unidirectional_sequence_rnn "") == 0)) {
                *isRNNType = true;
                break;
            }
        }
    }`"
50952,Unexpected warning when using tf.data.Dataset.cache(filename),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0 and 2.7.0.dev20210725
- Python version: 3.9.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v1.12.1-60944-g65153d2677e 2.7.0-dev20210725

**Describe the current behavior**
When tf.data.Dataset is cached into a file there is a warning
```
W tensorflow/core/kernels/data/cache_dataset_ops.cc:233] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
```
Eventhough dataset is fully read.

**Describe the expected behavior**
There should be no warning when dataset is fully read.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import os
import tensorflow as tf

os.system('rm -f /tmp/foo*')

def gen():
    for i in range(5):
        yield i

dataset = tf.data.Dataset.from_generator(gen, output_signature=tf.TensorSpec(shape=(), dtype=tf.int32))
dataset = dataset.cache('/tmp/foo')
# dataset = dataset.take(3).cache('/tmp/foo').repeat(2)

for x in dataset:
    print(x)
```

Even if `take.cache.repeat` is used just like the warning suggests, it doesn't help

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Output of the script above:
```
tf.Tensor(0, shape=(), dtype=int32)
tf.Tensor(1, shape=(), dtype=int32)
tf.Tensor(2, shape=(), dtype=int32)
tf.Tensor(3, shape=(), dtype=int32)
tf.Tensor(4, shape=(), dtype=int32)
2021-07-26 13:35:10.940312: W tensorflow/core/kernels/data/cache_dataset_ops.cc:233] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
```

Running this script under `strace` shows that a shard file is removed just before it's existence is checked:
```
[pid   910] stat(""/tmp/foo_0.index"", {st_mode=S_IFREG|0644, st_size=201, ...}) = 0
[pid   910] openat(AT_FDCWD, ""/tmp/foo_0.index"", O_RDONLY) = 4
[pid   910] pread64(4, ""y\10\206\1\16\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0""..., 48, 153) = 48
[pid   910] pread64(4, ""\0\1\2!\0t\0\0\0\0\1\0\0\0\0t\214P\20"", 19, 134) = 19
[pid   910] pread64(4, ""\0\0\6\10\1\32\2\10\1\0\t\v      0_0\10\3\22\0(\0045\246{\21:""..., 121, 0) = 121
[pid   910] close(4)                    = 0
[pid   910] rename(""/tmp/foo_0.data-00000-of-00001"", ""/tmp/foo.data-00000-of-00001"") = 0
[pid   910] openat(AT_FDCWD, ""/tmp/foo.index"", O_WRONLY|O_CREAT|O_TRUNC, 0666) = 4
[pid   910] fstat(4, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0
[pid   910] write(4, ""\0\0\6\10\1\32\2\10\1\0\t\v      0_0\10\3\22\0(\0045\246{\21:""..., 201) = 201
[pid   910] close(4)                    = 0
[pid   910] unlink(""/tmp/foo_0.index"")  = 0
[pid   910] unlink(""/tmp/foo_0.lockfile"") = 0
[pid   910] access(""/tmp/foo.index"", F_OK) = 0
[pid   910] access(""/tmp/foo_0.index"", F_OK) = -1 ENOENT (No such file or directory)
[pid   910] stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=127, ...}) = 0
[pid   910] write(2, ""2021-07-26 13:17:56.497443: W te""..., 4242021-07-26 13:17:56.497443: W tensorflow/core/kernels/data/cache_dataset_ops.cc:233] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
) = 424
```"
50951,smaller model runs slower than a larger one when compiled for edgetpu,"**System information**-
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: coral usb edgetpu
- TensorFlow version (use command below): v1.12.1-49562-gee58e600bfc 2.5.0-dev20210125
- Python version: 3.7

**Describe the current behavior**
So I have two models (U-nets) that are nearly identical except one of them uses fewer filters in some of the convolutional layers which makes that network strictly smaller, and when running the tflite version of the models the smaller one is indeed faster than the larger one, however when compiled and run on the edgetpu the smaller network runs slower than the larger network.

**Describe the expected behavior**
performance gain form tflite should be the same on the edgetpu

**Standalone code to reproduce the issue**
https://drive.google.com/drive/folders/1-u9GpNwRdbCAxtaMuAdDZazMWqeMIt_n?usp=sharing

**Other info / logs**
I already made an issue at the google coral edgetpu page seen [here](https://github.com/google-coral/edgetpu/issues/424#issue-949588585), they said the issue was with interpreter.invoke() in the script ../lib/python3.8/site-packages/tflite_runtime/interpreter.py and that I should contact the tensorflow team.
"
50950,cl.exe failed during building tensorflow from source,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: master branch
- Python version: 3.8,6
- Installed using virtualenv? pip? conda?: bazel
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): VS2019
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the problem**
The build works for most of the time but at the end it crashes into a c++ compilation error (cl.exe) and gives unknown option error for optimization flags

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
python ./configure.py
bazel --output_user_root=C:\tfb build --config=opt --jobs=3 //tensorflow/tools/pip_package:build_pip_package
```
I didnt checkout to any branch as i had problems with r2.5 and r2.4 and had to limit jobs to 3 due to ram constraint.
I put y for this question `` Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: `` and gave `` --copt=-march=native `` as the optimization flag.

**Any other info / logs**
```
ERROR: C:/tensorflow/tensorflow/python/util/BUILD:632:27: C++ compilation of rule '//tensorflow/python/util:fast_module_type.so' failed (Exit 2): cl.exe failed: error executing command
  cd C:/tfb/xv6zejqw/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30037\include;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\cppwinrt
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30037\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\Tools\devinit;C:\Program Files (x86)\Windows Kits\10\bin\10.0.19041.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/python.exe
    SET PYTHON_LIB_PATH=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\SUNDAR~1\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TMP=C:\Users\SUNDAR~1\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio/2019/BuildTools/VC/Tools/MSVC/14.29.30037/bin/HostX64/x64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/pybind11 /Ibazel-out/x64_windows-opt/bin/external/pybind11 /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/pybind11/_virtual_includes/pybind11 /Ithird_party/eigen3/mkl_include /Ibazel-out/x64_windows-opt/bin/third_party/eigen3/mkl_include /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/pybind11/include /Ibazel-out/x64_windows-opt/bin/external/pybind11/include /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions --copt=-march=native /std:c++14 -fno-strict-aliasing -fexceptions /Fobazel-out/x64_windows-opt/bin/tensorflow/python/util/_objs/fast_module_type.so/fast_module_type.obj /c tensorflow/python/util/fast_module_type.cc
Execution platform: @local_execution_config_platform//:platform
cl : Command line warning D9035 : option 'experimental:preprocessor' has been deprecated and will be removed in a future release
cl : Command line warning D9036 : use 'Zc:preprocessor' instead of 'experimental:preprocessor'
cl : Command line warning D9002 : ignoring unknown option '--copt=-march=native'
cl : Command line warning D9002 : ignoring unknown option '-fno-strict-aliasing'
cl : Command line warning D9002 : ignoring unknown option '-fexceptions'
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30037\include\complex(675): error C2039: 'copysign': is not a member of '`global namespace''
C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30037\include\complex(675): error C3861: 'copysign': identifier not found
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 5030.345s, Critical Path: 387.99s
INFO: 8960 processes: 2679 internal, 6281 local.
FAILED: Build did NOT complete successfully
```
I have tried the same build with the following optimization flags 

- ``-march=native``
- ``-mavx -mavx2 -msse4.2 -mfma`` (suggested on stackoverflow)
- ``--copt=-mavx --copt=-mavx2 --copt=-msse4.2 --copt=-mfma``

However I get the same error (`` cl : Command line warning D9002 : ignoring unknown option `` for each flag)
How do i compile tensorflow with avx2 and sse4.2 without the unknown option error?"
50948,import tensorflow get a bug,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip install tensorflow-gpu 2.5.0
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:cuda 11.4 
- cudnn :libcudnn8_8.2.1.32-1+cuda11.3_amd64.deb
libcudnn8-dev_8.2.1.32-1+cuda11.3_amd64.deb
libcudnn8-samples_8.2.1.32-1+cuda11.3_amd64.deb

- GPU model and memory:nvidia 2080s 8g 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When I upgraded tensorflow in the virtual environment anaconda, there was a bug that couldn't run. I don't know what the problem is. I have reinstalled the driver and CUDA cudnn, but it still doesn't work. There should be no mistake in installing the three files of cudnn. It seems that it reads tensorflow directly from the virtual environment rather than the absolute path. I don't know what the problem is. It should be a tensorflow bug. In addition, my soft link settings are as follows:


export PATH=$PATH:/usr/local/cuda-11.4/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.4/lib64
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.4/extras/CUPTI/lib64









2021-07-26 19:11:29.807559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
Traceback (most recent call last):
  File ""/home/zy/Project_save/stock_hht_pred/code/online_prediction_market.py"", line 8, in <module>
    import tensorflow as tf
  File ""/home/zy/.local/lib/python3.6/site-packages/tensorflow/__init__.py"", line 444, in <module>
    _ll.load_library(_main_dir)
  File ""/home/zy/.local/lib/python3.6/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library
    py_tf.TF_LoadLibrary(lib)
tensorflow.python.framework.errors_impl.NotFoundError: /home/zy/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb


**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50946,Build TensorFlow Lite for Android and reduce binary size to use with C API ,"Hello, 

I would like to build TensorFlow Lite for Android reducing the binary size. I want to optimize its size based on the operations used by my model. Then, I want to use the generated `.so` for `arm64-v8a` and `armeabi-v7a` in JNI with C API.

I am able to build TensorFlow Lite for Android as described in [Build Android](https://www.tensorflow.org/lite/guide/build_android#build_and_install) and use it in my Android Studio project. However, the binary files are too big for my application. In order to reduce the binary size, I followed the instructions described in [Reduce Binary Size](https://www.tensorflow.org/lite/guide/reduce_binary_size), but as stated in [Known Limitations](https://www.tensorflow.org/lite/guide/reduce_binary_size#known_issueslimitations) it does not support C API. The generated `.aar` does not contain the C headers and when I try to use the `.so` files in my Android Studio project, none of the C functions are available.

Is there any other way to reduce TensorFlow Lite binary size to be used in JNI with C API?

Thanks."
50945,Can't save the LSTM model. (AttributeError: 'CuDNNLSTM' object has no attribute 'unroll'),"Hey,

I'm trying to build a `LSTM` model with CuDNN and this is the model I'm using.

```
model = Sequential()
model.add(CuDNNLSTM(256, input_shape=(train_x.shape[1:]), return_sequences=True))
model.add(Dropout(0.2))

model.add(CuDNNLSTM(256, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1))
model.add(Activation(""tanh""))

# Compile the model.
model.compile(loss=""mse"", optimizer=""rmsprop"", metrics=[""accuracy""])
print(""Compiled!"")

# Train the model.
model.fit(train_x, train_y, epochs=epoch, batch_size=512, validation_split=0.05)
```

But when I try to save the model with  `model.save(...)` I get this error.

```
Traceback (most recent call last):
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\save.py"", line 150, in save_model
    saved_model_save.save(model, filepath, overwrite, include_optimizer,
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\save.py"", line 90, in save
    saved_nodes, node_paths = save_lib.save_and_return_nodes(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1103, in save_and_return_nodes
    _build_meta_graph(obj, signatures, options, meta_graph_def,
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1290, in _build_meta_graph
    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def,
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1207, in _build_meta_graph_impl
    signatures = signature_serialization.find_function_to_export(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\saved_model\signature_serialization.py"", line 99, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\saved_model\save.py"", line 154, in list_functions
    obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\engine\training.py"", line 2688, in _list_functions_for_serialization
    functions = super(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\engine\base_layer.py"", line 2992, in _list_functions_for_serialization
    return (self._trackable_saved_model_saver
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\base_serialization.py"", line 93, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\layer_serialization.py"", line 73, in functions_to_serialize
    return (self._get_serialized_attributes(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\layer_serialization.py"", line 89, in _get_serialized_attributes
    object_dict, function_dict = self._get_serialized_attributes_internal(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\model_serialization.py"", line 53, in _get_serialized_attributes_internal
    super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\layer_serialization.py"", line 99, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\save_impl.py"", line 149, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\save_impl.py"", line 279, in _replace_child_layer_functions
    child_layer._trackable_saved_model_saver._get_serialized_attributes(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\layer_serialization.py"", line 89, in _get_serialized_attributes
    object_dict, function_dict = self._get_serialized_attributes_internal(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\layer_serialization.py"", line 151, in _get_serialized_attributes_internal
    super(RNNSavedModelSaver, self)._get_serialized_attributes_internal(
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\layer_serialization.py"", line 99, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\save_impl.py"", line 156, in wrap_layer_functions
    call_collection = LayerCallCollection(layer)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\save_impl.py"", line 406, in __init__
    self._input_signature = self._generate_input_signature(layer)
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\saving\saved_model\save_impl.py"", line 431, in _generate_input_signature
    layer._use_input_spec_as_call_signature):  # pylint: disable=protected-access
  File ""C:\Users\User\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\layers\recurrent.py"", line 437, in _use_input_spec_as_call_signature
    if self.unroll:
AttributeError: 'CuDNNLSTM' object has no attribute 'unroll'
python-BaseException
```
"
50944,Problems on TensorFlow-ROCm installation,"Hi,

My PC has AMD CPU(Ryzen 5900X) and an AMD graphic card(RX6800XT). The operating system is openSUSE Tumbleweed(20210726). I want to use my GPU to do some scientific computation by tensorflow-rocm. 

I add the repository resource via: `sudo zypper addrepo --no-gpgcheck http://repo.radeon.com/rocm/zyp/zypper/ rocm`
But I don't know which are the necessary packages for the ROCm.
And I find that:

Some packages can be installed directly.
`rock-dkms`
`rocm-gdb`: requires me to install python36 (My OS has python38 installed)
`rocminfo`
`rocm-opencl`
`rocm-opencl-devel`
`rocm-device-libs`
`hsakmt-roct`
`hipify-clang`
...

Some packages cannot be installed with dependencies problems.
`rocm-dkms` 
`rocm-dev`
`rccl`
`rocm-libs`
`hip-samples`
...

I'm new to computational science, could you tell me the minimal installation of ROCm environment(Could let me use tensorflow-rocm) requires me to install which packages from the [official repo](http://repo.radeon.com/rocm/zyp/zypper/)?
I just want to use [tensorflow-rocm](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream).

I would appreciate it if you can respond to me.
 

"
50943,Error build: target 'cuda/bin/nvcc' not declared in package,"Above error when building from source with GPU on Ubuntu 18.04.

To reproduce:

```
 git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
./configure # all defaults except for CUDA: y
bazel build --copt=-march=native --config=nonccl --config=cuda //tensorflow/tools/pip_package:build_pip_package
```
OS: Ubuntu 18.04
Python 3.9.6: Anaconda managed environment
GPU: NVIDIA 1080 Ti
CUDA: V11.2.152
bazel 3.7.2

Full stacktrace:
```
bazel build --copt=-march=native --config=nonccl --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --explain=file.txt --verbose_failures 2>&1 | tee bazel.log
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=0 --terminal_columns=80
INFO: Reading rc options for 'build' from /home/sergey/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/sergey/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true
INFO: Reading rc options for 'build' from /home/sergey/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/sergey/anaconda3/bin/python3 --action_env PYTHON_LIB_PATH=/home/sergey/anaconda3/lib/python3.9/site-packages --python_path=/home/sergey/anaconda3/bin/python3 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --action_env LD_LIBRARY_PATH=/home/sergey/hadoop/lib/native/:/usr/lib/x86_64-linux-gnu/:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 --config=cuda
INFO: Found applicable config definition build:short_logs in file /home/sergey/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/sergey/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda in file /home/sergey/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:nonccl in file /home/sergey/tensorflow/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:cuda in file /home/sergey/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:linux in file /home/sergey/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false
INFO: Found applicable config definition build:dynamic_kernels in file /home/sergey/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: /home/sergey/.cache/bazel/_bazel_sergey/3b767bf3a32053879a4e137b3de41895/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.
DEBUG: /home/sergey/.cache/bazel/_bazel_sergey/3b767bf3a32053879a4e137b3de41895/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:10:
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
Loading:  (1 packages loaded)
Loading: 1 packages loaded
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (2 packages loaded, 0 targets configured)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (57 packages loaded, 17 targets configured)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (227 packages loaded, 3960 targets configured)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (246 packages loaded, 3960 targets configured)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (248 packages loaded, 3960 targets configured)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (249 packages loaded, 3960 targets configured)
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /home/sergey/tensorflow/WORKSPACE:23:14: in <toplevel>
  /home/sergey/tensorflow/tensorflow/workspace0.bzl:108:34: in workspace
  /home/sergey/.cache/bazel/_bazel_sergey/3b767bf3a32053879a4e137b3de41895/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /home/sergey/.cache/bazel/_bazel_sergey/3b767bf3a32053879a4e137b3de41895/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (332 packages loaded, 5329 targets configured)
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (427 packages loaded, 13775 targets configured)
ERROR: /home/sergey/.cache/bazel/_bazel_sergey/3b767bf3a32053879a4e137b3de41895/external/rules_cuda/cuda/BUILD:128:20: every rule of type cuda_toolchain_info implicitly depends upon the target '@local_cuda//:cuda/bin/nvcc', but this target could not be found because of: no such target '@local_cuda//:cuda/bin/nvcc': target 'cuda/bin/nvcc' not declared in package '' (did you mean 'cuda/bin/h5cc'?) defined by /home/sergey/.cache/bazel/_bazel_sergey/3b767bf3a32053879a4e137b3de41895/external/local_cuda/BUILD
INFO: Repository eigen_archive instantiated at:
  /home/sergey/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:1091:28: in workspace
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:61:11: in _initialize_third_party
  /home/sergey/tensorflow/third_party/eigen3/workspace.bzl:12:20: in repo
  /home/sergey/tensorflow/third_party/repo.bzl:113:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/sergey/tensorflow/third_party/repo.bzl:66:35: in <toplevel>
INFO: Repository org_sqlite instantiated at:
  /home/sergey/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:1098:21: in workspace
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:347:20: in _tf_repositories
  /home/sergey/tensorflow/third_party/repo.bzl:113:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/sergey/tensorflow/third_party/repo.bzl:66:35: in <toplevel>
INFO: Repository llvm-project instantiated at:
  /home/sergey/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:1098:21: in workspace
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:657:9: in _tf_repositories
  /home/sergey/tensorflow/third_party/llvm/workspace.bzl:10:20: in repo
  /home/sergey/tensorflow/third_party/repo.bzl:113:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/sergey/tensorflow/third_party/repo.bzl:66:35: in <toplevel>
INFO: Repository cudnn_frontend_archive instantiated at:
  /home/sergey/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:1098:21: in workspace
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:158:20: in _tf_repositories
  /home/sergey/tensorflow/third_party/repo.bzl:113:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/sergey/tensorflow/third_party/repo.bzl:66:35: in <toplevel>
Analyzing: target //tensorflow/tools/pip_package:build_pip_package (427 packages loaded, 13776 targets configured)
INFO: Repository mkl_dnn_v1 instantiated at:
  /home/sergey/tensorflow/WORKSPACE:15:14: in <toplevel>
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:1098:21: in workspace
  /home/sergey/tensorflow/tensorflow/workspace2.bzl:181:20: in _tf_repositories
  /home/sergey/tensorflow/third_party/repo.bzl:113:21: in tf_http_archive
Repository rule _tf_http_archive defined at:
  /home/sergey/tensorflow/third_party/repo.bzl:66:35: in <toplevel>
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed
INFO: Elapsed time: 13.023s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (427 packages loaded, 13776 targets configured)
FAILED: Build did NOT complete successfully (427 packages loaded, 13776 targets configured)
```
Tensorflow 2.5.0 builds though on the same machine."
50942,TFLite Conversion Error: Element Shape Required to be 1D,"### 1. System information

- Windows 10 PC, TensorFlow version 2.5.0

### 2. Code

```
import tensorflow as tf
import model as modellib
import coco
import os 
import sys

# Enable eager execution
tf.compat.v1.enable_eager_execution()

class InferenceConfig(coco.CocoConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
config = InferenceConfig()
model = modellib.MaskRCNN(mode=""inference"", model_dir='logs', config=config)
model.load_weights('mask_rcnn_coco.h5', by_name=True)
model = model.keras_model

tf.saved_model.save(model, ""tflite"")

# Preparing before conversion - making the representative dataset
ROOT_DIR = os.path.abspath(""../"")
CARS = os.path.join(ROOT_DIR, 'Mask_RCNN\\mrcnn\\smallCar')

IMAGE_SIZE = 224
datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

def representative_data_gen():
    dataset_list = tf.data.Dataset.list_files(CARS)
    for i in range(100):
        image = next(iter(dataset_list))
        image = tf.io.read_file(image)
        image = tf.io.decode_jpeg(image, channels=3)
        image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
        image = tf.cast(image / 255., tf.float32)
        image = tf.expand_dims(image, 0)
        yield [image]


converter = tf.lite.TFLiteConverter.from_keras_model(model)
# This enables quantization
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# This sets the representative dataset for quantization
converter.representative_dataset = representative_data_gen
# This ensures that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.
converter.target_spec.supported_types = [tf.int8]
# These set the input and output tensors to uint8 (added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model = converter.convert()

with open('modelQuantized.tflite', 'wb') as f:
  f.write(tflite_model)
```

### 3. Failure after conversion
I get the following error for the `tflite_model = converter.convert()` line:

`error: 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass`,

FULL:

```
loc(callsite(""mask_rcnn/mrcnn_detection/map/TensorArrayV2_1""(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py"":535:0) at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py"":602:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\model.py"":774:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\model.py"":839:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\utils.py"":820:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\model.py"":837:0 at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py"":645:0 at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py"":1030:0 at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py"":556:0 at ""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py"":420:0)))))))))): error: 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
loc(callsite(""mask_rcnn/mrcnn_detection/map/TensorArrayV2_1""(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py"":535:0) at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py"":602:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\model.py"":774:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\model.py"":839:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\utils.py"":820:0 at callsite(""d:\\Mask_RCNN\\mrcnn\\model.py"":837:0 at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py"":645:0 at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py"":1030:0 at callsite(""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py"":556:0 at ""C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py"":420:0)))))))))): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\tensorflow\lite\python\convert.py"", line 291, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""C:\Python39\lib\site-packages\tensorflow\lite\python\wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:535:0: error: 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:602:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:774:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:839:0: note: called from
d:\Mask_RCNN\mrcnn\utils.py:820:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:837:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\autograph\impl\api.py:645:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1030:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:556:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:420:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:535:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:602:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:774:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:839:0: note: called from
d:\Mask_RCNN\mrcnn\utils.py:820:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:837:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\autograph\impl\api.py:645:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1030:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:556:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:420:0: note: called from


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""d:\Mask_RCNN\mrcnn\convertQuantize.py"", line 53, in <module>
    tflite_model = converter.convert()
  File ""C:\Python39\lib\site-packages\tensorflow\lite\python\lite.py"", line 1057, in convert
    result = super(TFLiteKerasModelConverterV2,
  File ""C:\Python39\lib\site-packages\tensorflow\lite\python\lite.py"", line 782, in convert
    result = _toco_convert_impl(
  File ""C:\Python39\lib\site-packages\tensorflow\lite\python\convert.py"", line 698, in toco_convert_impl
    data = toco_convert_protos(
  File ""C:\Python39\lib\site-packages\tensorflow\lite\python\convert.py"", line 297, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:535:0: error: 'tf.TensorListReserve' op requires element_shape to be 1D tensor during TF Lite transformation pass
C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:602:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:774:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:839:0: note: called from
d:\Mask_RCNN\mrcnn\utils.py:820:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:837:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\autograph\impl\api.py:645:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1030:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:556:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:420:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:535:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
C:\Python39\lib\site-packages\tensorflow\python\util\deprecation.py:602:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:774:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:839:0: note: called from
d:\Mask_RCNN\mrcnn\utils.py:820:0: note: called from
d:\Mask_RCNN\mrcnn\model.py:837:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\autograph\impl\api.py:645:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1030:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:556:0: note: called from
C:\Python39\lib\site-packages\tensorflow\python\keras\engine\functional.py:420:0: note: called from
```

Not sure what the error is, or how to fix it. Any help is appreciated!
"
50941,Where is convert_all_kernels_in_model in tensorflow 2.5.0?,"I can't import `convert_all_kernels_in_model` from `tensorflow.keras.utils` in `tf 2.5.0`

```python
from tensorflow.keras.utils import convert_all_kernels_in_model
```

I get this error:

```bash
ImportError: cannot import name 'convert_all_kernels_in_model' from 'tensorflow.keras.utils' ...
```

I have an old code written in `tf 2.3.0` and I need to port it to `tf 2.5.0`.  

Where did that function go? "
50940,Build TensorFlowLite C API with GPU delegate with CMake,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: nightly
- Python version: 3.6
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): N/A, using CMake 3.20
- GCC/Compiler version (if compiling from source): GCC 8.2
- CUDA/cuDNN version: CUDA 11.1, cuDNN 8
- GPU model and memory: GTX 1650


**Describe the problem**
I am trying to build the C API for Tensorflow Lite, with GPU delegate enabled, and using CMake. The resulting `libtensorflowlite_c.so` does not have GPU delegate symbols.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I basically followed https://www.tensorflow.org/lite/guide/build_cmake#build_tensorflow_lite_c_library . With the only difference that I added `-DTFLITE_ENABLE_GPU=ON` in the CMake config step. From what I gathered from `tensorflow/lite/c/CMakeLists.txt`, we build `libtensorflow-lite.a` (C++ API, static) first, and bake this into `libtensorflowlite_c.so`. The GPU delegate symbols can be found inside `libtensorflow-lite.a`, but are stripped away from `libtensorflowlite_c.so`. I found a workaround which consists of changing:
```
target_link_libraries(tensorflowlite_c
  tensorflow-lite
)
```
to
```
target_link_libraries(tensorflowlite_c
  -Wl,--whole-archive
  tensorflow-lite
  -Wl,--no-whole-archive
)
```
inside `tensorflow/lite/c/CMakeLists.txt` and removing `${TFLITE_C_SRCS}` from the list of source files associated to the `tensorflow-lite` target inside `tensorflow/lite/CMakeLists.txt`. This latter step is necessary because both `tensorflowlite_c` and `tensorflow-lite` targets include this same set of source files and will lead to a linker multiple-definition error.

Is there better way to achieve this without having to patch the CMake files on my end? Can we add better support for delegates for the CMake workflow?


"
50939,implement reduce for the bitwise operations. ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4, 2.5. 
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently, there is no tf.reduce_xor (or any reduction or any other bitwise op). There is the tf.bitwise package for bitwise ops, but they only operate on two inputs. 


**Will this change the current api? How?**

No, this would be an additional api. 

**Who will benefit with this feature?**

As more preprocessing operations are pushed into the graph-mode model rather than in tf.data.Dataset.map layers, we need to do more preprocessing work in the graph (though preprocessing does not need to be differentiable). For example, I am attempting to implement a message digest algorithm that is invariant to the ordering of the images in a batch. The basic algo would be to implement a message digest for each image in a mini batch, then xor them together with a tf.bitwise.reduce_xor() function. Without reduce, I'd have to rely on tf.scan and tf.bitwise.bitwise_xor. 

**Any Other info.**
"
50938,Performance issue on Macbook Pro M1,"**System information**
- Script can be found below
- MacBook Pro M1 (Mac OS Big Sir (11.5))
- TensorFlow installed from (source)
- TensorFlow version (2.5 version) with Metal Support
- Python version: 3.9
- GPU model and memory: MacBook Pro M1 and 16 GB

Steps needed for installing Tensorflow with metal support.
https://developer.apple.com/metal/tensorflow-plugin/

I am trying to train a model on Macbook Pro M1, but the performance is so bad and the train doesn't work properly. It takes a ridiculously long time just for a single epoch. 

Code needed for reproducing this behavior.
`
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.layers import Embedding, Dense, LSTM
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Model configuration
additional_metrics = ['accuracy']
batch_size = 128
embedding_output_dims = 15
loss_function = BinaryCrossentropy()
max_sequence_length = 300
num_distinct_words = 5000
number_of_epochs = 5
optimizer = Adam()
validation_split = 0.20
verbosity_mode = 1

# Disable eager execution
tf.compat.v1.disable_eager_execution()

# Load dataset
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_distinct_words)
print(x_train.shape)
print(x_test.shape)

# Pad all sequences
padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>
padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length, value = 0.0) # 0.0 because it corresponds with <PAD>

# Define the Keras model
model = Sequential()
model.add(Embedding(num_distinct_words, embedding_output_dims, input_length=max_sequence_length))
model.add(LSTM(10))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer=optimizer, loss=loss_function, metrics=additional_metrics)

# Give a summary
model.summary()

# Train the model
history = model.fit(padded_inputs, y_train, batch_size=batch_size, epochs=number_of_epochs, verbose=verbosity_mode, validation_split=validation_split)

# Test the model after training
test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)
print(f'Test results - Loss: {test_results[0]} - Accuracy: {100*test_results[1]}%')

`

"
50937,validation_split for tensorflow.dataset,"ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>]

I believe there is explicitly no support to divide a tensorflow dataset  into train and validation on the go while calling model.fit. Would be really helpful if this feature can be added.
**System information**
- TensorFlow version (you are using): 2.5
- Are you willing to contribute it (Yes/No): Yes


"
50935,2.5.0 tf_to_kernel is not compatible with msvc /Ob3,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 20H2
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.5.0
- Python version: 3.8 (anaconda 2021.05)
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): msvc 19.28.29910 (Visual Studio 2019 v16.9.0)
- CUDA/cuDNN version: 11.3.0_465.89/8.2.0.53
- GPU model and memory: RTX 3090 24GB

**Describe the problem**

If the Ob3 parameter is specified during compilation, the compilation will fail.
The error occurs in tf_to_kernel.exe.
2.4.0 is fine with Ob3.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
C:\Users\User\Source\Repos\tensorflow>python ./configure.py
You have bazel 3.7.2 installed.
Please specify the location of python. [Default is C:\Users\User\anaconda3\python.exe]:
Found possible Python library paths:
  C:\Users\User\anaconda3\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\User\anaconda3\lib\site-packages]
Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.
Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.
Found CUDA 11.3 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3/include
Found cuDNN 8 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.3/include
Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]:
 compute_35

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:
/MP /cgthreads8 /Qpar /fp:fast -Ob3

Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: n
Not overriding eigen strong inline, some compilations could take more than 20 mins.
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.
Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).
        --config=monolithic     # Config for mostly static monolithic build.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v1             # Build with TensorFlow 1 API instead of TF 2 API.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=nogcp          # Disable GCP support.
        --config=nonccl         # Disable NVIDIA NCCL support.
C:\Users\User\Source\Repos\tensorflow>bazel build --config=opt --incompatible_strict_action_env=false --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
```
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR: tensorflow/tensorflow/core/kernels/mlir_generated/BUILD:871:23: compile tensorflow/core/kernels/mlir_generated/***.o failed (Exit -1073741819): tf_to_kernel.exe failed: error executing command
  cd execroot/org_tensorflow
bazel-out/x64_windows-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel.exe --tile_sizes=1024 --arch=compute_35 --input=bazel-out/x64_windows-opt/bin/tensorflow/core/kernels/mlir_generated/***.mlir --output=bazel-out/x64_windows-opt/bin/tensorflow/core/kernels/mlir_generated/***.o --enable_ftz=False --cpu_codegen=False
```"
50933,'tf.MLCConv2D' op is neither a custom op nor a flex op,"### 1. System information

- OS Platform and Distribution: Mac OS 11.4 (Hardware: Mac Mini M1)
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.0rc0
- Python version: 3.8.10

### 2. Description of problem

I am using TFLite with the code from this repo (https://github.com/hunglc007/tensorflow-yolov4-tflite) to save on inference time. When I try to quantize weights into float 16, this is the error that appears:

`
 'tf.MLCConv2D' op is neither a custom op nor a flex op
`

### 3. Code

This error was surfaced through the following actions:
Download this repo: https://github.com/hunglc007/tensorflow-yolov4-tflite

Run the following commands inside that repo:
```
python save_model.py --weights ./data/yolov4.weights --output ./checkpoints/yolov4-416 --input_size 416 --model yolov4 
python save_model.py --weights ./data/yolov4.weights --output ./checkpoints/yolov4-416 --input_size 416 --model yolov4 --framework tflite
python convert_tflite.py --weights ./checkpoints/yolov4-416 --output ./checkpoints/yolov4-416.tflite
```
On the third command, the error will show up. 

### 5. (optional) Any other info / logs
Here is the info that was emitted along with the error:
```
@Amols-Mac-mini-2 tensorflow-yolov4-tflite-master % python convert_tflite.py --weights ./checkpoints/yolov4-416 --output ./checkpoints/yolov4-416.tflite
2021-06-30 06:06:32.420247: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.
2021-06-30 06:06:32.420283: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.
2021-06-30 06:06:32.420288: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:325] Ignored change_concat_input_ranges.
2021-06-30 06:06:32.420843: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ./checkpoints/yolov4-416
2021-06-30 06:06:32.469275: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2021-06-30 06:06:32.469304: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ./checkpoints/yolov4-416
2021-06-30 06:06:32.614124: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2021-06-30 06:06:32.661105: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
2021-06-30 06:06:32.694735: W tensorflow/core/platform/profile_utils/cpu_utils.cc:126] Failed to get CPU frequency: 0 Hz
2021-06-30 06:06:33.529179: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ./checkpoints/yolov4-416
2021-06-30 06:06:33.717920: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 1297076 microseconds.
2021-06-30 06:06:34.386654: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
loc(callsite(callsite(""model/conv2d/Conv2D@__inference__wrapped_model_11175"" at ""StatefulPartitionedCall@__inference_signature_wrapper_47226"") at ""StatefulPartitionedCall"")): error: 'tf.MLCConv2D' op is neither a custom op nor a flex op
[~1000 similar lines to above omitted for brevity]
<unknown>:0: error: loc(callsite(callsite(""model/conv2d_109/Conv2D@__inference__wrapped_model_11175"" at ""StatefulPartitionedCall@__inference_signature_wrapper_47226"") at ""StatefulPartitionedCall"")): 'tf.MLCConv2D' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: loc(callsite(callsite(""model/conv2d_109/Conv2D@__inference__wrapped_model_11175"" at ""StatefulPartitionedCall@__inference_signature_wrapper_47226"") at ""StatefulPartitionedCall"")): 'tf.MLCConv2D' op is neither a custom op nor a flex op
<unknown>:0: note: loc(""StatefulPartitionedCall""): called from
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
        tf.MLCConv2D {T = f32, data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], num_args = 0 : i64, padding = ""SAME"", strides = [1, 1, 1, 1], transpose = false, use_cudnn_on_gpu = true}
        tf.MLCConv2D {T = f32, data_format = ""NHWC"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], num_args = 0 : i64, padding = ""VALID"", strides = [1, 2, 2, 1], transpose = false, use_cudnn_on_gpu = true}
```"
50928,ValueError: Could not find matching function to call loaded from the SavedModel,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

[https://github.com/webster1309/colab/blob/main/tlex.ipynb]
"
50927,Export Graph gradient API on Windows,"**System information**
- TensorFlow version: 2.5
- Are you willing to contribute it: Probably


**Describe the feature and the current behavior/state.**

Similar to #41904, there are symbols missing when using the graph gradient API from C++.  We (SIG JVM) are running into this when trying to add custom gradient support.

Symbols:
```
jnitensorflow.obj : error LNK2001: unresolved external symbol ""class tensorflow::Status __cdecl tensorflow::StatusFromTF_Status(struct TF_Status const *)"" (?StatusFromTF_Status@tensorflow@@YA?AVStatus@1@PEBUTF_Status@@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: static class tensorflow::ops::GradOpRegistry * __cdecl tensorflow::ops::GradOpRegistry::Global(void)"" (?Global@GradOpRegistry@ops@tensorflow@@SAPEAV123@XZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Status __cdecl tensorflow::ops::GradOpRegistry::Lookup(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class tensorflow::Status (__cdecl**)(class tensorflow::Scope const &,class tensorflow::Operation const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > *))const "" (?Lookup@GradOpRegistry@ops@tensorflow@@QEBA?AVStatus@3@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@PEAP6A?AV43@AEBVScope@3@AEBVOperation@3@AEBV?$vector@VOutput@tensorflow@@V?$allocator@VOutput@tensorflow@@@std@@@6@PEAV96@@Z@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: bool __cdecl tensorflow::ops::GradOpRegistry::Register(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class tensorflow::Status (__cdecl*)(class tensorflow::Scope const &,class tensorflow::Operation const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > const &,class std::vector<class tensorflow::Output,class std::allocator<class tensorflow::Output> > *))"" (?Register@GradOpRegistry@ops@tensorflow@@QEAA_NAEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@P6A?AVStatus@3@AEBVScope@3@AEBVOperation@3@AEBV?$vector@VOutput@tensorflow@@V?$allocator@VOutput@tensorflow@@@std@@@5@PEAV95@@Z@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: __cdecl tensorflow::Operation::Operation(class tensorflow::Node *)"" (??0Operation@tensorflow@@QEAA@PEAVNode@1@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Graph * __cdecl tensorflow::Scope::graph(void)const "" (?graph@Scope@tensorflow@@QEBAPEAVGraph@2@XZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: bool __cdecl tensorflow::Scope::ok(void)const "" (?ok@Scope@tensorflow@@QEBA_NXZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: void __cdecl tensorflow::Scope::UpdateBuilder(class tensorflow::NodeBuilder *)const "" (?UpdateBuilder@Scope@tensorflow@@QEBAXPEAVNodeBuilder@2@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > __cdecl tensorflow::Scope::GetUniqueNameForOp(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?GetUniqueNameForOp@Scope@tensorflow@@QEBA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBV34@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope __cdecl tensorflow::Scope::ExitOnError(void)const "" (?ExitOnError@Scope@tensorflow@@QEBA?AV12@XZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope __cdecl tensorflow::Scope::WithDevice(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?WithDevice@Scope@tensorflow@@QEBA?AV12@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope __cdecl tensorflow::Scope::WithNoControlDependencies(void)const "" (?WithNoControlDependencies@Scope@tensorflow@@QEBA?AV12@XZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope __cdecl tensorflow::Scope::WithControlDependencies(class absl::lts_2020_09_23::Span<class tensorflow::Operation const > const &)const "" (?WithControlDependencies@Scope@tensorflow@@QEBA?AV12@AEBV?$Span@$$CBVOperation@tensorflow@@@lts_2020_09_23@absl@@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope __cdecl tensorflow::Scope::WithControlDependencies(class tensorflow::Output const &)const "" (?WithControlDependencies@Scope@tensorflow@@QEBA?AV12@AEBVOutput@2@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope __cdecl tensorflow::Scope::NewSubScope(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &)const "" (?NewSubScope@Scope@tensorflow@@QEBA?AV12@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: static class tensorflow::Scope __cdecl tensorflow::Scope::NewRootScope(void)"" (?NewRootScope@Scope@tensorflow@@SA?AV12@XZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: class tensorflow::Scope & __cdecl tensorflow::Scope::operator=(class tensorflow::Scope const &)"" (??4Scope@tensorflow@@QEAAAEAV01@AEBV01@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: __cdecl tensorflow::Scope::~Scope(void)"" (??1Scope@tensorflow@@QEAA@XZ)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""public: __cdecl tensorflow::Scope::Scope(class tensorflow::Scope const &)"" (??0Scope@tensorflow@@QEAA@AEBV01@@Z)
jnitensorflow.obj : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::Set_TF_Status_from_Status(struct TF_Status *,class tensorflow::Status const &)"" (?Set_TF_Status_from_Status@tensorflow@@YAXPEAUTF_Status@@AEBVStatus@1@@Z)

```

It seems like there's three parts:
* Exporting `Scope`
* Exporting [Set_TF_Status_from_Status](https://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/tensorflow/c/tf_status_helper.h#L25)
* Exporting `GradOpRegistry`

**Will this change the current api? How?**
It will add additional exported symbols.

**Who will benefit with this feature?**
Anyone trying to use the custom gradient API from Windows.

**Any Other info.**
If it's as simple as adding `TF_CAPI_EXPORT` to `Set_TF_Status_from_Status` and adding scope and gradient targets to `tf_custom_op_library_additional_deps_impl`, I can make a PR, but I'm not sure of the proper place to add scope and gradient and whether you are far enough from the symbol limit to allow you to."
50926,Segmentation fault when using NCCL in MultiWorkerMirroredStrategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.9
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.6
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 10.2.0
- CUDA/cuDNN version: 11.1.1
- GPU model and memory: A100

**Describe the current behavior**

When running the distributed training with MultiWorkerMirroredStrategy and NCCL the application will crash during a NCCL reduction operation due to a bug in TF.

**Standalone code to reproduce the issue**

Similar to #50853 run the following on at least 2 nodes with at least 2 GPUs: 

```
import tensorflow as tf
from mpi_cluster_resolver import MPIClusterResolver

resolver = MPIClusterResolver()
communication = tf.distribute.experimental.CollectiveCommunication.NCCL
options = tf.distribute.experimental.CommunicationOptions(implementation=communication)
strategy = tf.distribute.MultiWorkerMirroredStrategy(communication_options=options, cluster_resolver=resolver)

with strategy.scope():
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
    x_train = x_train / 255.0
    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(128)

    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(10),
    ])

    model.compile(
        optimizer=tf.keras.optimizers.SGD(),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=['accuracy'])

is_master = resolver.task_id == 0
verbose = 2 if is_master else 0
model.fit(train_data.repeat(), epochs=1, steps_per_epoch=10, verbose=verbose)
```

With 
[mpi_cluster_resolver.py.txt](https://github.com/tensorflow/tensorflow/files/6823734/mpi_cluster_resolver.py.txt)

**Other info / logs**

I was able to collect the following backtrace:
```
   #0  tensorflow::NcclCommunicator::Enqueue(std::shared_ptr<tensorflow::CollectiveContext>, std::function<void (tensorflow::Status const&)>) (this=0x1ebf9260, 
std::shared_ptr<tensorflow::CollectiveContext> (use count 5, weak count 0) = {...}, done=...) at tensorflow/core/nccl/collective_communicator.cc:78
#1  0x00002aaacc95de30 in tensorflow::NcclReducer::Run(std::function<void (tensorflow::Status const&)>) ()
   from <prefix>/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00002aaaeb699dc0 in std::_Function_handler<void (), tensorflow::BaseCollectiveExecutor::ExecuteAsync(tensorflow::OpKernelContext*, tensorflow::CollectiveParams const*, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void (tensorflow::Status const&)>)::{lambda()#3}>::_M_invoke(std::_Any_data const&) ()
   from <prefix>/tensorflow/python/../libtensorflow_framework.so.2
#3  0x00002aaaeb2cdbf6 in std::function<void ()>::operator()() const ()
   from <prefix>/tensorflow/python/../libtensorflow_framework.so.2
#4  0x00002aaaeb9350a9 in tensorflow::UnboundedWorkQueue::PooledThreadFunc() ()
   from <prefix>/tensorflow/python/../libtensorflow_framework.so.2
#5  0x00002aaaeb935164 in std::_Function_handler<void (), tensorflow::UnboundedWorkQueue::Schedule(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from <prefix>/tensorflow/python/../libtensorflow_framework.so.2
#6  0x00002aaaeb2cdbf6 in std::function<void ()>::operator()() const ()
   from <prefix>/tensorflow/python/../libtensorflow_framework.so.2
#7  0x00002aaaeb93c799 in tensorflow::(anonymous namespace)::PThread::ThreadFn(void*) ()
   from <prefix>/tensorflow/python/../libtensorflow_framework.so.2
#8  0x00002aaaab7deea5 in start_thread () from /lib64/libpthread.so.0
#9  0x00002aaaabcf496d in clone () from /lib64/libc.so.6
```

Further debugging led me to https://github.com/tensorflow/tensorflow/blob/98765aab1af708f8663fb983aca75115d70da8df/tensorflow/core/nccl/collective_communicator.cc#L89 which calls effectively `col_ctx->op_ctx->device()->tensorflow_gpu_device_info()` which returns `nullptr` which is then returned an dereferenced in `col_ctx->op_ctx->op_device_context()->stream()` which obviously segfaults.
Some further debugging examining `col_ctx->op_ctx->device()->name()` shows that in the case of the crash `/job:worker/replica:0/task:1/device:CPU:0` or `/job:worker/replica:0/task:0/device:CPU:0` is used (both of the 2 nodes crash), so a CPU device ends up there which of course does not have a GPU info set."
50925,Error in saving model: TypeError: No conversion path for dtype: dtype('<U30'),"<em>I am building a new model based an existed model. However, I found that I could not save the new model</em>

**Important Notice**

I have an existed model which was built based on VGG16 (namely, 'base_network' in the following picture). Now, I am building a new model based on the existed model (namely, 'model' in the following picture). However, the existed model could be saved using the keras.models.save, but the new model could not.

For simplicity, the code is as follows,

<img width=""414"" alt=""微信截图_20210723233351"" src=""https://user-images.githubusercontent.com/24711658/126806731-1f1828be-fcf2-4d0d-bc18-1ec57be44189.png"">

As you can see, the first base_network.save('out.h5') works. the base_network can be saved. However, when it comes to model.save('out2.h5'), problems occur.

I do not know why. the base_network and model looks the same in these codes. Could anyone help me? thanks.

<img width=""688"" alt=""20210723234456"" src=""https://user-images.githubusercontent.com/24711658/126807518-c2160c9e-47f7-42a0-976c-afad5ac294ff.png"">

Here, I also uploaded the summary information.
<img width=""618"" alt=""20210723234641"" src=""https://user-images.githubusercontent.com/24711658/126807803-5b111478-2d82-4349-8fe4-e8bf3a2a11a3.png"">
<img width=""588"" alt=""20210723234659"" src=""https://user-images.githubusercontent.com/24711658/126807810-74a744bc-e363-4c64-939b-4ca167ff4852.png"">




"
50924,Building TF.Lite benchmark tool with TF.text ops support,"Does anyone have an example of re-building a TF.Lite binary with support for tensorflow-text operations?

I have a TF.Lite model which includes [USE-multilingual](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3), which uses several Sentencepiece ops from tensorflow-text. After reading https://github.com/tensorflow/hub/issues/463 and a few others, I was able to successfully covert the model, and it returns results during inference as expected when using the TF.Lite Interpreter.

I'd like to run the TF.Lite native benchmark tool against this model as well, but doing so requires building the tool from source with tensorflow-text ops. Thus far, I haven't been able to build a working version of the tool for my model. A few things I've tried are listed below, any help would be much appreciated. Thanks!

**Attempt 1: Include tensorflow-text as an external repository and target tensorflow_text:ops_lib**

My first attempt was to build `tensorflow_text:ops_lib` directly into the tool from source, which seems to be the more Bazel-appropriate way to tackle the problem. The diff below shows my most recent attempt to build the benchmark tool in this manner.

<details><summary>Diff</summary><p>

```diff
diff --git a/tensorflow/BUILD b/tensorflow/BUILD
index 3ef74d742ef..c653a384c69 100644
--- a/tensorflow/BUILD
+++ b/tensorflow/BUILD
@@ -38,7 +38,7 @@ load(
 load(""@bazel_skylib//:bzl_library.bzl"", ""bzl_library"")
 
 package(
-    default_visibility = ["":internal""],
+    default_visibility = [""//visibility:public""],
     licenses = [""notice""],  # Apache 2.0
 )
 
diff --git a/tensorflow/lite/c/BUILD b/tensorflow/lite/c/BUILD
index 3119cf30557..3b7ff060518 100644
--- a/tensorflow/lite/c/BUILD
+++ b/tensorflow/lite/c/BUILD
@@ -38,6 +38,8 @@ tflite_cc_shared_object(
         "":c_api_experimental"",
         "":exported_symbols.lds"",
         "":version_script.lds"",
+        ""//tensorflow/lite/delegates/flex:delegate"",
+        ""@org_tensorflow_text//tensorflow_text:ops_lib"",
     ],
 )
 
diff --git a/tensorflow/lite/tools/benchmark/BUILD b/tensorflow/lite/tools/benchmark/BUILD
index 815efb776e9..0793db4a417 100644
--- a/tensorflow/lite/tools/benchmark/BUILD
+++ b/tensorflow/lite/tools/benchmark/BUILD
@@ -24,9 +24,12 @@ cc_library(
     deps = [
         "":benchmark_tflite_model_lib"",
         ""//tensorflow/lite/tools:logging"",
+        ""//tensorflow/lite/delegates/flex:delegate"",
+        ""@org_tensorflow_text//tensorflow_text:ops_lib"",
     ],
 )
 
+
 cc_binary(
     name = ""benchmark_model"",
     copts = common_copts,
diff --git a/tensorflow/workspace0.bzl b/tensorflow/workspace0.bzl
index 22374bc1297..f8483aa2f53 100644
--- a/tensorflow/workspace0.bzl
+++ b/tensorflow/workspace0.bzl
@@ -102,6 +102,38 @@ def workspace():
         ],
     )
 
+    # TF.text repo
+    http_archive(
+        name = ""org_tensorflow_text"",
+        sha256 = ""d82856dc04c04bbce347f72d0ad7df59bb6b26b7030f96f25f036cfe8a138312"",
+        strip_prefix = ""text-2.5.0"",
+        urls = [
+            ""https://github.com/tensorflow/text/archive/v2.5.0.zip"",
+        ],
+        patches = [""@//third_party/tf_text:tftext10.patch""],
+        patch_args = [""-p1""],
+    )
+
+    # TF.text dependencies
+    http_archive(
+        name = ""com_google_sentencepiece"",
+        strip_prefix = ""sentencepiece-1.0.0"",
+        sha256 = ""c05901f30a1d0ed64cbcf40eba08e48894e1b0e985777217b7c9036cac631346"",
+        urls = [
+            ""https://github.com/google/sentencepiece/archive/1.0.0.zip"",
+        ],
+    )
+
+    http_archive(
+        name = ""com_google_glog"",
+        sha256 = ""1ee310e5d0a19b9d584a855000434bb724aa744745d5b8ab1855c85bff8a8e21"",
+        strip_prefix = ""glog-028d37889a1e80e8a07da1b8945ac706259e5fd8"",
+        urls = [
+            ""https://mirror.bazel.build/github.com/google/glog/archive/028d37889a1e80e8a07da1b8945ac706259e5fd8.tar.gz"",
+            ""https://github.com/google/glog/archive/028d37889a1e80e8a07da1b8945ac706259e5fd8.tar.gz"",
+        ],
+    )
+
     bazel_toolchains_repositories()
 
     # Use `swift_rules_dependencies` to fetch the toolchains. With the
@@ -117,6 +149,7 @@ def workspace():
     grpc_extra_deps()
     config_googleapis()
 
+
 # Alias so it can be loaded without assigning to a different symbol to prevent
 # shadowing previous loads and trigger a buildifier warning.
 tf_workspace0 = workspace
diff --git a/third_party/eigen3/BUILD b/third_party/eigen3/BUILD
index e2253e18f8a..c0802240b4b 100644
--- a/third_party/eigen3/BUILD
+++ b/third_party/eigen3/BUILD
@@ -47,7 +47,7 @@ filegroup(
         [""**/*""],
         exclude = [""**/OWNERS""],
     ),
-    visibility = [""//tensorflow:__subpackages__""],
+    visibility = [""//visibility:public""],
 )
 
 filegroup(
@@ -74,4 +74,5 @@ genrule(
     done
     """""",
     tags = [""manual""],
+    visibility = [""//visibility:public""],
 )
diff --git a/third_party/icu/BUILD.bazel b/third_party/icu/BUILD.bazel
index 14cadffc841..691585ce5ba 100644
--- a/third_party/icu/BUILD.bazel
+++ b/third_party/icu/BUILD.bazel
@@ -19,6 +19,16 @@ cc_library(
     ],
 )
 
+alias(
+    name = ""nfkc"",
+    actual = "":common"",
+)
+
+alias(
+    name = ""nfkc_cf"",
+    actual = "":common"",
+)
+
 cc_library(
     name = ""common"",
     hdrs = glob([""icu4c/source/common/unicode/*.h""]),
diff --git a/third_party/tf_text/tftext10.patch b/third_party/tf_text/tftext10.patch
new file mode 100644
index 00000000000..cd313cd3ad3
--- /dev/null
+++ b/third_party/tf_text/tftext10.patch
@@ -0,0 +1,29 @@
+diff --git a/tensorflow_text/tftext.bzl b/tensorflow_text/tftext.bzl
+index 7f703b3..b840c0f 100644
+--- a/tensorflow_text/tftext.bzl
++++ b/tensorflow_text/tftext.bzl
+@@ -93,8 +93,8 @@ def tf_deps(deps = []):
+             ""@org_tensorflow//tensorflow/core:portable_tensorflow_lib_lite"",
+         ],
+         ""//conditions:default"": [
+-            ""@local_config_tf//:libtensorflow_framework"",
+-            ""@local_config_tf//:tf_header_lib"",
++            ""@org_tensorflow//tensorflow:libtensorflow_framework_import_lib"",
++            #""@org_tensorflow//tensorflow/c:headers"",
+         ] + deps + oss_deps,
+     })
+ 
+diff --git a/third_party/sentencepiece/processor.patch b/third_party/sentencepiece/processor.patch
+index 5fa1b84..c5a7358 100644
+--- a/third_party/sentencepiece/processor.patch
++++ b/third_party/sentencepiece/processor.patch
+@@ -22,8 +22,7 @@ index b4298d2..7ce779f 100644
+ +              ""@org_tensorflow//tensorflow/core:tflite_portable_logging"",
+ +            ],
+ +            ""//conditions:default"": [
+-+              ""@local_config_tf//:libtensorflow_framework"",
+-+              ""@local_config_tf//:tf_header_lib"",
+++              ""@org_tensorflow//tensorflow:libtensorflow_framework_import_lib"",
+ +              ""@com_google_absl//absl/functional:function_ref"",
+ +              ""@com_google_absl//absl/strings:cord"",
+ +            ],
```

</p></details>

This build fails with a number of different dependency path/access errors, depending on Bazel build order. Typically, it either can't find an `Eigen` header or a `Protobuf` header when starting from tensorflow-text source (this is what led me to attempt changing some of the rule visibilities, but with no luck). I've included a couple of these error messages for reference.

<details><summary>Example 1</summary><p>

ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/b813f517b143a3c1665dd902035fe00f/external/org_tensorflow_text/tensorflow_text/core/kernels/BUILD:355:23: C++ compilation of rule '@org_tensorflow_text//tensorflow_text/core/kernels:sentencepiece_kernels' failed (Exit 1): gcc failed: error executing command 
  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/b813f517b143a3c1665dd902035fe00f/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \
    LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib: \
    PATH=/home/ubuntu/.cache/bazelisk/downloads/bazelbuild/bazel-3.7.2-linux-x86_64/bin:/usr/local/cuda:/home/ubuntu/src/tensorflow/.venv/bin:/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/home/ubuntu/anaconda3/condabin:/home/ubuntu/.dl_binaries/bin:/usr/local/cuda/bin:/opt/aws/neuron/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/ubuntu/src/tensorflow/.venv/bin/python3 \
    PYTHON_LIB_PATH=/home/ubuntu/src/tensorflow/.venv/lib/python3.6/site-packages \
    TF2_BEHAVIOR=1 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/org_tensorflow_text/tensorflow_text/core/kernels/_objs/sentencepiece_kernels/sentencepiece_kernels.d '-frandom-seed=bazel-out/k8-opt/bin/external/org_tensorflow_text/tensorflow_text/core/kernels/_objs/sentencepiece_kernels/sentencepiece_kernels.o' -iquote external/org_tensorflow_text -iquote bazel-out/k8-opt/bin/external/org_tensorflow_text -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/com_google_sentencepiece -iquote bazel-out/k8-opt/bin/external/com_google_sentencepiece -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/com_github_gflags_gflags -iquote bazel-out/k8-opt/bin/external/com_github_gflags_gflags -iquote external/com_google_glog -iquote bazel-out/k8-opt/bin/external/com_google_glog -iquote external/com_google_googletest -iquote bazel-out/k8-opt/bin/external/com_google_googletest -iquote . -iquote bazel-out/k8-opt/bin -Ibazel-out/k8-opt/bin/external/com_google_glog/_virtual_includes/glog -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/com_github_gflags_gflags/include -isystem bazel-out/k8-opt/bin/external/com_github_gflags_gflags/include -isystem external/com_google_googletest/googlemock -isystem bazel-out/k8-opt/bin/external/com_google_googletest/googlemock -isystem external/com_google_googletest/googlemock/include -isystem bazel-out/k8-opt/bin/external/com_google_googletest/googlemock/include -isystem external/com_google_googletest/googletest -isystem bazel-out/k8-opt/bin/external/com_google_googletest/googletest -isystem external/com_google_googletest/googletest/include -isystem bazel-out/k8-opt/bin/external/com_google_googletest/googletest/include -w -DAUTOLOAD_DYNAMIC_KERNELS '-std=c++14' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/org_tensorflow_text/tensorflow_text/core/kernels/sentencepiece_kernels.cc -o bazel-out/k8-opt/bin/external/org_tensorflow_text/tensorflow_text/core/kernels/_objs/sentencepiece_kernels/sentencepiece_kernels.o)
Execution platform: @local_execution_config_platform//:platform
In file included from ./tensorflow/core/framework/bounds_check.h:21,
                 from external/org_tensorflow_text/tensorflow_text/core/kernels/sentencepiece_kernels.cc:25:
./third_party/eigen3/Eigen/Core:1:10: fatal error: Eigen/Core: No such file or directory
 #include ""Eigen/Core""
          ^~~~~~~~~~~~
compilation terminated. 

</p></details>

<details><summary>Example 2</summary><p>

ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/b813f517b143a3c1665dd902035fe00f/external/org_tensorflow_text/tensorflow_text/BUILD:1162:19: C++ compilation of rule '@org_tensorflow_text//tensorflow_text:wordpiece_tokenizer_cc' failed (Exit 1): gcc failed: error executing command 
  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/b813f517b143a3c1665dd902035fe00f/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/opt/amazon/efa/lib:/opt/amazon/openmpi/lib:/usr/local/lib:/usr/lib: \
    PATH=/home/ubuntu/.cache/bazelisk/downloads/bazelbuild/bazel-3.7.2-linux-x86_64/bin:/home/ubuntu/src/tensorflow/.venv/bin:/opt/amazon/openmpi/bin/:/opt/amazon/efa/bin/:/home/ubuntu/anaconda3/condabin:/home/ubuntu/.dl_binaries/bin:/usr/local/cuda/bin:/opt/aws/neuron/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/ubuntu/src/tensorflow/.venv/bin/python \
    PYTHON_LIB_PATH=/home/ubuntu/src/tensorflow/.venv/lib/python3.6/site-packages \
    TF2_BEHAVIOR=1 \
  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/org_tensorflow_text/tensorflow_text/_objs/wordpiece_tokenizer_cc/wordpiece_op.pic.d '-frandom-seed=bazel-out/k8-opt/bin/external/org_tensorflow_text/tensorflow_text/_objs/wordpiece_tokenizer_cc/wordpiece_op.pic.o' -fPIC -iquote external/org_tensorflow_text -iquote bazel-out/k8-opt/bin/external/org_tensorflow_text -iquote external/icu -iquote bazel-out/k8-opt/bin/external/icu -iquote . -iquote bazel-out/k8-opt/bin -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -isystem external/icu/icu4c/source/common -isystem bazel-out/k8-opt/bin/external/icu/icu4c/source/common -w -DAUTOLOAD_DYNAMIC_KERNELS '-std=c++14' -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/org_tensorflow_text/tensorflow_text/core/ops/wordpiece_op.cc -o bazel-out/k8-opt/bin/external/org_tensorflow_text/tensorflow_text/_objs/wordpiece_tokenizer_cc/wordpiece_op.pic.o)
Execution platform: @local_execution_config_platform//:platform
In file included from ./tensorflow/core/framework/op_def_builder.h:24,
                 from ./tensorflow/core/framework/op.h:23,
                 from external/org_tensorflow_text/tensorflow_text/core/ops/wordpiece_op.cc:15:
bazel-out/k8-opt/bin/tensorflow/core/framework/op_def.pb.h:10:10: fatal error: google/protobuf/port_def.inc: No such file or directory
 #include <google/protobuf/port_def.inc>
          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.

</p></details>

**Attempt 2: Compile tensorflow-text ops separately and link library**

I was able to compile tensorflow-text with `linkstatic=1` and `linkshared=True`, hoping this would give me the best chance at a usable library (based on the `linkshared` description in the [Bazel `cc_binary` docs](https://docs.bazel.build/versions/main/be/c-cpp.html#cc_binary)). However, when I try to link this in `tensorflow/lite/tools/benchmark:benchmark_model`, the build completes, but gives the following runtime error:
```
ubuntu@ip-10-22-3-51:~/src/tensorflow$ bazel-bin/tensorflow/lite/tools/benchmark/benchmark_model --help
bazel-bin/tensorflow/lite/tools/benchmark/benchmark_model: error while loading shared libraries: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory
```

When I try to link that library as well (which doesn't make much sense to include in a separate TF build, admittedly), I get the following runtime crash:
```
ubuntu@ip-10-22-3-51:~/src/tensorflow$ bazel-bin/tensorflow/lite/tools/benchmark/benchmark_model --help
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
```

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: checked out from v2.5.0
- Python version: 3.6.3
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 3.7.2 (via Bazelisk)
- GCC/Compiler version (if compiling from source): gcc 8.4.0
- CUDA/cuDNN version: CUDA Version 10.0.130/cuDNN 7.5
- GPU model and memory: NVIDIA GV100GL Tesla V100 SXM2 (16GB)
"
50922,SECURITY.md,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**
[SECURITY.md](https://github.com/tensorflow/tensorflow/files/6868801/SECURITY.md)

**Any Other info.**
"
50921,AttributeError: 'NoneType' object has no attribute 'PluginAssets',"tensorflow 2.5

**This problem occurs when I'm using the tensorboard to do the profiling.**

The code is as follows.

```
import tensorflow as tf
import datetime

# The function to be traced.
@tf.function
def my_func(x, y):
  # A simple hand-rolled layer.
  return tf.nn.relu(tf.matmul(x, y))

# Set up logging.
stamp = datetime.datetime.now().strftime(""%Y%m%d-%H%M%S"")
logdir = 'logs/func/%s' % stamp
writer = tf.summary.create_file_writer(logdir)

# Sample data for your function.
x = tf.random.uniform((3, 3))
y = tf.random.uniform((3, 3))

# Bracket the function call with
# tf.summary.trace_on() and tf.summary.trace_export().
tf.summary.trace_on(graph=True, profiler=True)
# Call only one tf.function when tracing.
z = my_func(x, y)
with writer.as_default():
  tf.summary.trace_export(
      name=""my_func_trace"",
      step=0,
      profiler_outdir=logdir)
```

**It produces no error when running this code, seeing from the output.**

sjtusmartboy@sjtusmartboy-ThinkPad-X230:~/opt/Projects/RandLA-Net$ python test3.py 
```
2021-07-23 19:41:34.589229: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-23 19:41:36.138644: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-07-23 19:41:36.170275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.171081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1
coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s
2021-07-23 19:41:36.171145: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-23 19:41:36.176195: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-07-23 19:41:36.176262: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-07-23 19:41:36.178526: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-07-23 19:41:36.178833: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-07-23 19:41:36.179436: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2021-07-23 19:41:36.180522: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-07-23 19:41:36.180748: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-07-23 19:41:36.180909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.181553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.182112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-07-23 19:41:36.183934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.184486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1
coreClock: 1.835GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s
2021-07-23 19:41:36.184588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.185197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.185693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-07-23 19:41:36.185742: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-23 19:41:36.773690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-23 19:41:36.773748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2021-07-23 19:41:36.773763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N 
2021-07-23 19:41:36.773975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.774569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.775196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-07-23 19:41:36.775721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6857 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1263: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.start` instead.
2021-07-23 19:41:36.884168: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.
2021-07-23 19:41:36.884221: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.
2021-07-23 19:41:36.884273: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs
2021-07-23 19:41:36.885256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcupti.so.11.2
2021-07-23 19:41:37.125954: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-07-23 19:41:37.126748: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2793545000 Hz
2021-07-23 19:41:37.141797: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-07-23 19:41:37.573205: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
WARNING:tensorflow:From /home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1319: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
2021-07-23 19:41:37.576615: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.
2021-07-23 19:41:37.576966: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed
2021-07-23 19:41:37.607794: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 11 callback api events and 145 activity events. 
2021-07-23 19:41:37.608909: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.
WARNING:tensorflow:From /home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1319: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.
WARNING:tensorflow:From /home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/eager/profiler.py:151: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.
```

**However, when I type the tensorboard command, `tensorboard --logdir logs/func`, and open the tensorboard webpage, it gives out the following error.**

```
2021-07-23 19:42:10.506328: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0

NOTE: Using experimental fast data loading logic. To disable, pass
    ""--load_fast=false"" and report issues on GitHub. More details:
    https://github.com/tensorflow/tensorboard/issues/4784

Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all
TensorBoard 2.5.0 at http://localhost:6006/ (Press CTRL+C to quit)
Exception in thread DynamicProfilePluginIsActiveThread:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorboard_plugin_profile/profile_plugin.py"", line 311, in compute_is_active
    self._is_active = any(self.generate_run_to_tools())
  File ""/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorboard_plugin_profile/profile_plugin.py"", line 693, in generate_run_to_tools
    plugin_assets = self.multiplexer.PluginAssets(PLUGIN_NAME)
AttributeError: 'NoneType' object has no attribute 'PluginAssets'


```

"
50920,XNNPACK enable cross-compilation failure using Bazel on r2.6 armhf or v2.6.0-rc1 armhf TensorFlow Lite pip,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 (HostPC), Ubuntu 16.04 (Docker)
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.6, v2.6.0-rc1
- Python version: 3.7 (Docker)
- Bazel version (if compiling from source): 3.7.2 (Docker)

**Describe the problem**
When I apply the changes [#50893](https://github.com/tensorflow/tensorflow/pull/50893) (Related issues #50826), the build with XNNPACK enabled on **`aarch64`** succeeds, but when I enable XNNPACK on **`armhf`**, I get XNNPACK build errors. This error is a result of a problem with the source of XNNPACK that was discovered as a result of #50826 being resolved by commit #50893.
```bash
SUBCOMMAND: # @XNNPACK//:neondot_ukernels [action 'Compiling XNNPACK/src/qs8-gemm/gen/4x8c4-minmax-fp32-neondot.c', configuration: 2e7b4c6d74b28315d87b125d5d5ce89c3c9e63c1078a7d749a0d0caf18244a66, execution platform: @local_execution_config_platform//:platform]
(cd /home/xxxxx/work/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /home/xxxxx/work/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/armhf_linux_toolchain/bin/arm-linux-gnueabihf-gcc -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/armhf-opt/bin/external/XNNPACK/_objs/neondot_ukernels/0/4x8c4-minmax-fp32-neondot.pic.d '-frandom-seed=bazel-out/armhf-opt/bin/external/XNNPACK/_objs/neondot_ukernels/0/4x8c4-minmax-fp32-neondot.pic.o' -fPIC -DPTHREADPOOL_NO_DEPRECATED_API -iquote external/XNNPACK -iquote bazel-out/armhf-opt/bin/external/XNNPACK -iquote external/FP16 -iquote bazel-out/armhf-opt/bin/external/FP16 -iquote external/pthreadpool -iquote bazel-out/armhf-opt/bin/external/pthreadpool -iquote external/FXdiv -iquote bazel-out/armhf-opt/bin/external/FXdiv -iquote external/cpuinfo -iquote bazel-out/armhf-opt/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/armhf-opt/bin/external/clog -Ibazel-out/armhf-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/armhf-opt/bin/external/pthreadpool/_virtual_includes/pthreadpool -Ibazel-out/armhf-opt/bin/external/FXdiv/_virtual_includes/FXdiv -Ibazel-out/armhf-opt/bin/external/cpuinfo/_virtual_includes/cpuinfo -Ibazel-out/armhf-opt/bin/external/clog/_virtual_includes/clog -isystem external/XNNPACK/include -isystem bazel-out/armhf-opt/bin/external/XNNPACK/include -isystem external/XNNPACK/src -isystem bazel-out/armhf-opt/bin/external/XNNPACK/src -isystem external/FP16/include -isystem bazel-out/armhf-opt/bin/external/FP16/include -isystem external/pthreadpool/include -isystem bazel-out/armhf-opt/bin/external/pthreadpool/include -isystem external/FXdiv/include -isystem bazel-out/armhf-opt/bin/external/FXdiv/include -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=armv7-a' '-mfpu=neon-vfpv4' -O3 -fno-tree-pre -fpermissive -Iinclude -Isrc -marm '-march=armv8.2-a+dotprod' '-mfpu=neon-fp-armv8' '-std=c99' -O2 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c external/XNNPACK/src/qs8-gemm/gen/4x8c4-minmax-fp32-neondot.c -o bazel-out/armhf-opt/bin/external/XNNPACK/_objs/neondot_ukernels/0/4x8c4-minmax-fp32-neondot.pic.o)
ERROR: /home/xxxxx/work/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/XNNPACK/BUILD.bazel:4507:19: C++ compilation of rule '@XNNPACK//:neondot_ukernels' failed (Exit 1): arm-linux-gnueabihf-gcc failed: error executing command 
  (cd /home/xxxxx/work/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /home/xxxxx/work/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/armhf_linux_toolchain/bin/arm-linux-gnueabihf-gcc -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/armhf-opt/bin/external/XNNPACK/_objs/neondot_ukernels/0/1x8c4-minmax-fp32-neondot.pic.d '-frandom-seed=bazel-out/armhf-opt/bin/external/XNNPACK/_objs/neondot_ukernels/0/1x8c4-minmax-fp32-neondot.pic.o' -fPIC -DPTHREADPOOL_NO_DEPRECATED_API -iquote external/XNNPACK -iquote bazel-out/armhf-opt/bin/external/XNNPACK -iquote external/FP16 -iquote bazel-out/armhf-opt/bin/external/FP16 -iquote external/pthreadpool -iquote bazel-out/armhf-opt/bin/external/pthreadpool -iquote external/FXdiv -iquote bazel-out/armhf-opt/bin/external/FXdiv -iquote external/cpuinfo -iquote bazel-out/armhf-opt/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/armhf-opt/bin/external/clog -Ibazel-out/armhf-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/armhf-opt/bin/external/pthreadpool/_virtual_includes/pthreadpool -Ibazel-out/armhf-opt/bin/external/FXdiv/_virtual_includes/FXdiv -Ibazel-out/armhf-opt/bin/external/cpuinfo/_virtual_includes/cpuinfo -Ibazel-out/armhf-opt/bin/external/clog/_virtual_includes/clog -isystem external/XNNPACK/include -isystem bazel-out/armhf-opt/bin/external/XNNPACK/include -isystem external/XNNPACK/src -isystem bazel-out/armhf-opt/bin/external/XNNPACK/src -isystem external/FP16/include -isystem bazel-out/armhf-opt/bin/external/FP16/include -isystem external/pthreadpool/include -isystem bazel-out/armhf-opt/bin/external/pthreadpool/include -isystem external/FXdiv/include -isystem bazel-out/armhf-opt/bin/external/FXdiv/include -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=armv7-a' '-mfpu=neon-vfpv4' -O3 -fno-tree-pre -fpermissive -Iinclude -Isrc -marm '-march=armv8.2-a+dotprod' '-mfpu=neon-fp-armv8' '-std=c99' -O2 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c external/XNNPACK/src/qs8-gemm/gen/1x8c4-minmax-fp32-neondot.c -o bazel-out/armhf-opt/bin/external/XNNPACK/_objs/neondot_ukernels/0/1x8c4-minmax-fp32-neondot.pic.o)
Execution platform: @local_execution_config_platform//:platform
external/XNNPACK/src/qs8-gemm/gen/1x8c4-minmax-fp32-neondot.c: In function 'xnn_qs8_gemm_minmax_fp32_ukernel_1x8c4__neondot':
external/XNNPACK/src/qs8-gemm/gen/1x8c4-minmax-fp32-neondot.c:93:16: error: incompatible types when assigning to type 'int32x4_t' from type 'int'
     vacc0x0123 = vcvtnq_s32_f32(vproduct0x0123);
                ^
external/XNNPACK/src/qs8-gemm/gen/1x8c4-minmax-fp32-neondot.c:94:16: error: incompatible types when assigning to type 'int32x4_t' from type 'int'
     vacc0x4567 = vcvtnq_s32_f32(vproduct0x4567);
                ^
Target //tensorflow/lite/python/interpreter_wrapper:_pywrap_tensorflow_interpreter_wrapper failed to build
INFO: Elapsed time: 1268.607s, Critical Path: 183.02s
INFO: 9070 processes: 1642 internal, 7428 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```bash
$ git clone -b r2.6 https://github.com/tensorflow/tensorflow.git
$ cd tensorflow
```
Edit `tensorflow/tensorflow/.bazelrc`
```
# TFLite build configs for generic embedded Linux
build:elinux --crosstool_top=@local_config_embedded_arm//:toolchain
build:elinux --host_crosstool_top=@bazel_tools//tools/cpp:toolchain
build:elinux_aarch64 --config=elinux
build:elinux_aarch64 --cpu=aarch64
build:elinux_aarch64 --distinct_host_configuration=true
build:elinux_armhf --config=elinux
build:elinux_armhf --cpu=armhf
build:elinux_armhf --distinct_host_configuration=true
```
Added FlexDelegate and XNNPACK as build options.
Edit `tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh`
```sh
# Build python interpreter_wrapper.
cd ""${BUILD_DIR}""
case ""${TENSORFLOW_TARGET}"" in
  armhf)
    BAZEL_FLAGS=""--config=elinux_armhf
      --copt=-march=armv7-a --copt=-mfpu=neon-vfpv4
      --copt=-O3 --copt=-fno-tree-pre --copt=-fpermissive
      --define tensorflow_mkldnn_contraction_kernel=0
      --define=raspberry_pi_with_neon=true
      --define=tflite_pip_with_flex=true
      --define=tflite_with_xnnpack=true""
    ;;
  aarch64)
    BAZEL_FLAGS=""--config=elinux_aarch64
      --define tensorflow_mkldnn_contraction_kernel=0
      --define=tflite_pip_with_flex=true
      --define=tflite_with_xnnpack=true
      --copt=-O3""
    ;;
  native)
    BAZEL_FLAGS=""--copt=-O3 --copt=-march=native
      --define=tflite_pip_with_flex=true
      --define=tflite_with_xnnpack=true""
    ;;
  *)
    BAZEL_FLAGS=""--copt=-O3
      --define=tflite_pip_with_flex=true
      --define=tflite_with_xnnpack=true""
    ;;
esac
```
Building **`armhf`** with cross-compilation.
```bash
sudo CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3.7 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7"" \
  tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
  tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf
```

**Any other info / logs**
I found that if I change the commit hash of XNNPACK as follows, the build finishes successfully on both armhf and aarch64. I don't know if this will help, but I have issued a pull request. https://github.com/tensorflow/tensorflow/pull/50923

XNNPACK https://github.com/google/XNNPACK/commit/476eb84d6a8e6f8249d5584d30759c6fbdbf791d

Edit `tensorflow/workspace2.bzl`

**From:**
```bzl
    tf_http_archive(
        name = ""XNNPACK"",
        sha256 = ""7320355409ae5dd2c8600cafbd07b56c379cd13666a7c971ffd3a01025c0f63e"",
        strip_prefix = ""XNNPACK-56b78a03e359ac04a3ba758596cd28b198a8000f"",
        urls = [
            ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/56b78a03e359ac04a3ba758596cd28b198a8000f.zip"",
            ""https://github.com/google/XNNPACK/archive/56b78a03e359ac04a3ba758596cd28b198a8000f.zip"",
        ],
    )
```

**To:**
```bzl
    tf_http_archive(
        name = ""XNNPACK"",
        sha256 = ""e1fee5a16e4a06d3bd77ab33cf87b1c6d826715906248a308ab790486198d3c9"",
        strip_prefix = ""XNNPACK-476eb84d6a8e6f8249d5584d30759c6fbdbf791d"",
        urls = [
            ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/476eb84d6a8e6f8249d5584d30759c6fbdbf791d.zip"",
            ""https://github.com/google/XNNPACK/archive/476eb84d6a8e6f8249d5584d30759c6fbdbf791d.zip"",
        ],
    )
```"
50919,Are these two lines of code okay? It may cause compilation errors,"https://github.com/tensorflow/tensorflow/blob/b61c987109eaad755c2b36ba51a0b233d54d4e57/tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/fusion_utils.cc#L203
https://github.com/tensorflow/tensorflow/blob/b61c987109eaad755c2b36ba51a0b233d54d4e57/tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/fusion_utils.cc#L204
@wyzero 

tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/fusion_utils.cc:203:27: error: 'class mlir::Operation' has no member named 'region'
   for (Operation& op : op.region().getBlocks().front()) {
"
50918,TensorFlow Import Error,"### System information
Intel 8th gen i7 with integrated graphics

using stock script, import tensorflow as tf caused failure

WIndows 10
Tensorflow installed from pip, version 2.0.0 (also tried 2.5.0, same error)
Python Version 3.7.9
No CUDA and GPU

Exact command to reproduce: import tensorflow as tf


### Describe the problem
There is a problem to import tensorflow 2.0.0 using Python 3.7. Installation appears to have worked on pip with all the requirements satisfied, but the import command results in an OSError: [WinError 126]. **Any help is greatly appreciated, thank you so much in advance**

### Source code / logs
Source Code: ``` import tensorflow as tf```
Error: 
```
C:\Users\steven.f>python3
Python 3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 16:30:00) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 959, in _find_and_load_unlocked
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.7_3.7.2544.0_x64__qbz5n2kfra8p0\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\__init__.py"", line 83, in <module>
    from tensorflow.python import keras
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\__init__.py"", line 26, in <module>
    from tensorflow.python.keras import activations
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\__init__.py"", line 26, in <module>
    from tensorflow.python.keras import activations
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\activations.py"", line 23, in <module>
    from tensorflow.python.keras.utils.generic_utils import deserialize_keras_object
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\utils\__init__.py"", line 38, in <module>
    from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\utils\multi_gpu_utils.py"", line 22, in <module>
    from tensorflow.python.keras.engine.training import Model
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\engine\training.py"", line 47, in <module>
    from tensorflow.python.keras.engine import training_arrays
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\tensorflow_core\python\keras\engine\training_arrays.py"", line 41, in <module>
    from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\scipy\__init__.py"", line 136, in <module>
    from . import _distributor_init
  File ""C:\Users\steven.f\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\LocalCache\local-packages\Python37\site-packages\scipy\_distributor_init.py"", line 61, in <module>
    WinDLL(os.path.abspath(filename))
  File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.7_3.7.2544.0_x64__qbz5n2kfra8p0\lib\ctypes\__init__.py"", line 364, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 126] The specified module could not be found
```
"
50915,loading a keras model on raspberry pi,"```
Traceback (most recent call last):
  File ""/home/pi/Desktop/testting/client.py"", line 21, in <module>
    modelLSTM = load_model('/home/pi/Desktop/ANN_model.keras')
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 168, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 263, in deserialize_keras_object
    config, module_objects, custom_objects, printable_module_name)
  File ""/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py"", line 234, in class_and_config_for_serialized_keras_object
    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
ValueError: Unknown layer: Functional
```

> I get this error when running a client code from the socket communication module. The role of the client is to receive inputs from the server code in a NumPy array format fed to a saved Keras model where I saved first on my laptop and transferred to my raspberry pi. so a brief:

`import tensorflow as tf
from random import randint
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow import keras
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Activation, Dense, Input
from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Nadam, Ftrl
from tensorflow.keras.metrics import categorical_crossentropy, mean_squared_error
from tensorflow.keras.models import model_from_json
import pandas as pd
import numpy as np
import xlrd
import matplotlib.pyplot as plt
import openpyxl
from math import sqrt
import sklearn



train_inputs = []
train_outputs = []
test_inputs = []
test_outputs = []
test_time = []

train_inputs = np.array(train_inputs)
train_outputs = np.array(train_outputs)
test_inputs = np.array(test_inputs)
test_outputs = np.array(test_outputs)
test_time = np.array(test_time)

output = pd.read_excel(r'K:\BachelorThesis\Data\Training_data\Mix_Data_outputs.xlsx')
train_outputs = output.to_numpy()
#print(type(train_outputs[-1][0]))

input = pd.read_excel(r'K:\BachelorThesis\Data\Training_data\Mix_Data_inputs.xlsx')
train_inputs = input.to_numpy()
#print(type(train_inputs[-1][0]))

temp_output = pd.read_excel(r'K:\BachelorThesis\Data\TestingData\Mix_Data_outputs.xlsx')
test_outputs = temp_output.to_numpy()
#print(type(train_outputs[-1][0]))

temp_input = pd.read_excel(r'K:\BachelorThesis\Data\TestingData\Mix_Data_inputs.xlsx')
test_inputs = temp_input.to_numpy()
#print(type(train_inputs[-1][0]))

time = pd.read_excel(r'K:\BachelorThesis\Data\TestingData\Nuneaton_RDE_Track\DataNuneaton_time.xlsx')
test_time = time.to_numpy()

scaler_i = MinMaxScaler()
scaler_o = MinMaxScaler()
scaler_i.fit(train_inputs)
normalized_inputs = scaler_i.transform(train_inputs)
scaler_o.fit(train_outputs)
normalized_outputs = scaler_o.transform(train_outputs)


tf.random.set_seed(16)

layer1 = Input(shape = (8, ))
layer2 = Dense(2048, activation='tanh')(layer1)
layer3 = Dense(1024, activation='tanh')(layer2)
layer4 = Dense(512, activation='tanh')(layer3)
layer5 = Dense(512, activation='tanh')(layer4)
layer6 = Dense(256, activation='tanh')(layer5)
layer7 = Dense(256, activation='tanh')(layer6)
layer8 = Dense(512, activation='tanh')(layer7)
layer9 = Dense(512, activation='tanh')(layer8)
layer10 = Dense(1024, activation='tanh')(layer9)
layer11 = Dense(2048, activation='tanh')(layer10)
output = Dense(8, )(layer11)
model = Model(inputs = layer1, outputs = output)

model.compile(optimizer=Adam(learning_rate=0.0001), loss='mse', metrics=['mean_squared_error'])

history = model.fit(x=normalized_inputs, y=normalized_outputs, validation_split=0.3, epochs=30, verbose=2)#, batch_size = 400, validation_batch_size= 100)

history.history.keys()

plt.plot(history.history['loss'])
plt.plot(history.history['mean_squared_error'])
plt.title('training')
plt.ylabel('loss & mse')
plt.xlabel('epochs')
plt.legend(['loss','mse'],loc='upper left')
plt.show()

plt.plot(history.history['val_loss'])
plt.plot(history.history['val_mean_squared_error'])
plt.title('validation')
plt.ylabel('val_loss & val_mse')
plt.xlabel('epochs')
plt.legend(['val_loss','val_mse'],loc='upper left')
plt.show()

scaler_ti = MinMaxScaler()
scaler_to = MinMaxScaler()
scaler_ti.fit(test_inputs)
normalized_test_inputs = scaler_ti.transform(test_inputs)
scaler_to.fit(test_outputs)
normalized_test_outputs = scaler_to.transform(test_outputs)

model.evaluate(normalized_test_inputs, normalized_test_outputs)

prediction = model.predict(normalized_test_inputs)
inverse = scaler_to.inverse_transform(prediction)

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,0])
ax.plot(test_time, test_outputs[:,0], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,1])
ax.plot(test_time, test_outputs[:,1], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,2])
ax.plot(test_time, test_outputs[:,2], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,3])
ax.plot(test_time, test_outputs[:,3], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,4])
ax.plot(test_time, test_outputs[:,4], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,5])
ax.plot(test_time, test_outputs[:,5], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,6])
ax.plot(test_time, test_outputs[:,6], linestyle = 'dashed')
plt.show()

fig, ax = plt.subplots(figsize=(30,10))
ax.plot(test_time, inverse[:,7])
ax.plot(test_time, test_outputs[:,7], linestyle = 'dashed')
plt.show()

model.save('K:\BachelorThesis\code testing\TireForces.LSTM\ANN_model.keras')

#model_json = model.to_json()
#with open(""K:\BachelorThesis\code testing\tireForcesANN/modelANN.json"", ""w"") as json_file:
 #   json_file.write(model_json)
# serialize weights to HDF5
#model.save_weights(""K:\BachelorThesis\code testing\tireForcesANN/modelANN.h5"")
#print(""Saved model to disk"")`

> This code on my laptop was used to train a model and save it in my laptop then the saved model was transferred using WinSCP to my raspberry pi.

`import socket
import numpy as np
import pandas as pd
import sklearn
from sklearn.preprocessing import MinMaxScaler

scaler_ti = MinMaxScaler()
test_inputs = []
test_inputs = np.array(test_inputs)
temp_in = pd.read_excel(r'K:\BachelorThesis\Data\TestingData\Mix_Data_inputs.xlsx')
test_inputs = temp_in.to_numpy()
rows = test_inputs.shape[0]
scaler_ti.fit(test_inputs)
normalized_test_inputs = scaler_ti.transform(test_inputs)


s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
host = ''
port = 62402
s.bind((host,port))
s.listen(5)

while True:
    
    clientsocket, address = s.accept()
    print(f""connection from {address} has been established!"")
    strg = test_inputs
    temp = strg.tobytes()
    clientsocket.send(temp)
    clientsocket.close()
        

`

> This code is the server code on my laptop to feed the client code with the inputs.

`import socket
import numpy as np
#import pandas as pd
#import sklearn
#from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import load_model
import tensorflow as tf
from random import randint
import h5py
#import argparse

#ap = argparse.ArgumentParser()
#ap.add_argument(""-d"", ""--dataset"", required=True,
	#help=""path to input dataset"")
#ap.add_argument(""-m"", ""--LSTM_model.h5"", required=True, help=""/home/pi/Desktop"")
#args = vars(ap.parse_args())

i = 0
final = []
final = np.array(final)
modelLSTM = load_model('/home/pi/Desktop/ANN_model.keras')
#json_file = open('LSTM_model.json', 'r')
#loaded_model_json = json_file.read()
#json_file.close()
#loaded_model = model_from_json(loaded_model_json)

s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
host = '192.168.1.24'
port = 62402
s.connect((host, port))

while True:
    if i in range(65533):
        i = i + 1
        msg = s.recv(64)
        out = np.frombuffer(msg)
        #out = out.reshape(1,8)
        #out = out.reshape(1,1,8)
        #prediction = modelLSTM.predict(out)
        #inverse = scaler_ti.inverse_transform(prediction.reshape(1,8))
        #print(prediction)
        #print(inverse)
        #final = np.vstack(inverse) 
        print(out)
        if len(msg) <= 0:
            break
#print (final)

`

> This code is the client code on my raspberry pi where I get the error every time I run. 

"
50897,Predict data from a collection to determine a single object with the most used data.,"**System information**
- Linux Ubuntu 16.04
- TensorFlow Lite JS

**Description** 
I need to start from a set of objects, define a single object, with the most used data among the javascript object collection informed.

**Example of set of objects:**
```javascript
[{
    name: ""Pedro"",
    product: ""Caneta""
}, {
    name: ""Ana"",
    product: ""Caderno""
}, {
    name: ""Maria"",
    product: ""Boracha""
}, {
    name: ""Pedro"",
    product: ""Caneta""
}, {
    name: ""Pedro"",
    product: ""Caneta""
}]
```

**Single object with the most used values in the above collections:**
```javascript
{
    name: ""Pedro"",
    product: ""Caneta""
}
```

That's what I need, based on the javascript collections array you can see that the most used information for the fields (name and product), were `name: ""Pedro""` and `product: ""Caneta""`.
That kind of analysis I need.

What function or how could I do this using tensorflow javascript, if you have any examples I'm very grateful, because I'm new to this."
50896,Could not find org.tensorflow:tensorflow-lite-support:0.1.0-rc1,"Hello everybody :)

I am converting a transformer model for text classification to TFLite. Conversion works. When I integrate it in the Android Studio template for text classification ([https://www.tensorflow.org/lite/examples/text_classification/overview](url)) I use lib_interpreter and obtain the following error:

Execution failed for task ':app:checkInterpreterDebugAarMetadata'.
> Could not resolve all files for configuration ':app:interpreterDebugRuntimeClasspath'.
   > Could not find org.tensorflow:tensorflow-lite-support:0.1.0-rc1.
     Searched in the following locations:
       - https://dl.google.com/dl/android/maven2/org/tensorflow/tensorflow-lite-support/0.1.0-rc1/tensorflow-lite-support-0.1.0-rc1.pom
       - https://repo.maven.apache.org/maven2/org/tensorflow/tensorflow-lite-support/0.1.0-rc1/tensorflow-lite-support-0.1.0-rc1.pom
       - http://oss.sonatype.org/content/repositories/snapshots/org/tensorflow/tensorflow-lite-support/0.1.0-rc1/tensorflow-lite-support-0.1.0-rc1.pom
     Required by:
         project :app > project :lib_interpreter

I would like to know if this is a problem related to the conversion of the model or what is going on here. Thank you very much! "
50894,WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FE83356310> and will run it as-is.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 20H2 19042.985
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):Binary (Anconda + Tensorflow.org + Nvidia-CUDA)
- TensorFlow version (use command below):2.4.0
- Python version:3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.0
- GPU model and memory: GeForce GTX 1650 computeCapability: 7.5  4098 Mib

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**CMD Runtime Log
2021-07-22 15:36:43.493521: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-07-22 15:36:44.947073: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-07-22 15:36:44.953523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2021-07-22 15:36:45.498789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5
coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 178.84GiB/s
2021-07-22 15:36:45.507262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-07-22 15:36:45.517511: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-07-22 15:36:45.521634: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-07-22 15:36:45.530173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-07-22 15:36:45.537579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-07-22 15:36:45.550524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-07-22 15:36:45.559310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-07-22 15:36:45.565102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-07-22 15:36:45.568619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
Found 28709 images belonging to 7 classes.
Found 7178 images belonging to 7 classes.
2021-07-22 15:36:46.904080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-22 15:36:46.916424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 computeCapability: 7.5
coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 178.84GiB/s
2021-07-22 15:36:46.925351: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2021-07-22 15:36:46.929340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-07-22 15:36:46.933846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-07-22 15:36:46.940659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2021-07-22 15:36:46.944810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2021-07-22 15:36:46.949295: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2021-07-22 15:36:46.954932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2021-07-22 15:36:46.958866: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-07-22 15:36:46.963356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2021-07-22 15:36:47.561268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-22 15:36:47.566554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2021-07-22 15:36:47.582880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2021-07-22 15:36:47.586730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2907 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)
2021-07-22 15:36:47.596419: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2021-07-22 15:36:50.406265: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001FA29D673A0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unable to locate the source code of <function Model.make_predict_function.<locals>.predict_function at 0x000001FA29D673A0>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2021-07-22 15:36:50.483496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2021-07-22 15:36:51.687993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2021-07-22 15:36:51.696841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2021-07-22 15:36:54.689521: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2021-07-22 15:36:54.823788: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0"
50892,Tensorflow could not build with `config=asan`  flag,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary): source
TensorFlow version: master
Python version: 3.8.8
Installed using virtualenv? pip? conda?: cinda
Bazel version (if compiling from source): 3.7.2
GCC/Compiler version (if compiling from source): clang-11
CUDA/cuDNN version: CUDA 11.3, CuDNN 8
GPU model and memory: GTX 1080 Ti


**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

I am trying to build TF with Address Sanitizer enabled. 

TF could not built with the flag `--config asan`.

I tried to use the following command:

```Batch
CC=/usr/lib/llvm-11/bin/clang TMP=~/tmp bazel build --config asan --config=dbg --per_file_copt=//tensorflow/core/grappler/./.*\.cc@-g //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```
and it failed with the following

```Log
tensorflow git:(master) ✗ CC=/usr/lib/llvm-11/bin/clang TMP=~/tmp bazel build --config asan --config=dbg --per_file_copt=//tensorflow/core/grappler/./.*\.cc@-g //tensorflow/tools/pip_package:build_pip_package --verbose_failures
WARNING: The following configs were expanded more than once: [cuda_clang, cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=149
INFO: Reading rc options for 'build' from /home/user/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/user/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true
INFO: Reading rc options for 'build' from /home/user/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/user/anaconda3/envs/tfenv/bin/python3 --action_env PYTHON_LIB_PATH=/home/user/anaconda3/envs/tfenv/lib/python3.8/site-packages --python_path=/home/user/anaconda3/envs/tfenv/bin/python3 --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.3 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1,6.1,6.1,6.1 --action_env LD_LIBRARY_PATH=/usr/local/cuda-11.3/lib64 --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/lib/llvm-11/bin/clang --config=cuda_clang
INFO: Reading rc options for 'build' from /home/user/tensorflow/.bazelrc:
  'build' options: --verbose_failures
INFO: Found applicable config definition build:short_logs in file /home/user/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/user/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda_clang in file /home/user/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang
INFO: Found applicable config definition build:cuda in file /home/user/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:cuda_clang in file /home/user/tensorflow/.bazelrc: --config=cuda --repo_env TF_CUDA_CLANG=1 --@local_config_cuda//:cuda_compiler=clang
INFO: Found applicable config definition build:cuda in file /home/user/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:asan in file /home/user/tensorflow/.bazelrc: --strip=never --copt -fsanitize=address --copt -DADDRESS_SANITIZER --copt -g --copt -O3 --copt -fno-omit-frame-pointer --linkopt -fsanitize=address
INFO: Found applicable config definition build:dbg in file /home/user/tensorflow/.bazelrc: -c dbg --per_file_copt=+.*,-tensorflow.*@-g0 --per_file_copt=+tensorflow/core/kernels.*@-g0 --cxxopt -DTF_LITE_DISABLE_X86_NEON --copt -DDEBUG_BUILD
INFO: Found applicable config definition build:linux in file /home/user/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/user/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/toolchains/archive/d781e89e2ee797ea7afd0c8391e761616fc5d50d.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
WARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/c362c993e4cca885ba6afef155d864a2dfd21f85.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/bcf6f641acdbeb208ea07a9e8ded37cd5b796d26.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: /home/user/.cache/bazel/_bazel_user/7562dd0a46bcb6cada6ae19650738275/external/highwayhash/BUILD.bazel:23:11: undeclared inclusion(s) in rule '@highwayhash//:arch_specific':
this rule is missing dependency declarations for the following files included by 'highwayhash/highwayhash/arch_specific.cc':
  '/usr/lib/llvm-11/lib/clang/11.1.0/share/asan_blacklist.txt'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 0.680s, Critical Path: 0.40s
INFO: 17 processes: 17 internal.
FAILED: Build did NOT complete successfully
```

Also tried the command of `--copt -fsanitize=address --linkopt -fsanitize=address`:

```Batch
 CC=/usr/lib/llvm-11/bin/clang TMP=~/tmp bazel build --copt -fsanitize=address --linkopt -fsanitize=address --config=dbg --per_file_copt=//tensorflow/core/grappler/./.*\.cc@-g //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```

and get the similar error.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


```Batch
$env
USER=user
LOGNAME=user
HOME=/home/user
PATH=/home/user/bin:/usr/local/cuda-11.3/bin:/home/user/anaconda3/envs/tfenv/bin:/home/user/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
SHELL=/usr/bin/zsh
TERM=xterm-256color
XDG_SESSION_ID=99
XDG_RUNTIME_DIR=/run/user/1000
DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/1000/bus
XDG_SESSION_TYPE=tty
XDG_SESSION_CLASS=user
MOTD_SHOWN=pam
LANG=en_US.UTF-8
LC_NUMERIC=zh_CN.UTF-8
LC_TIME=zh_CN.UTF-8
LC_MONETARY=zh_CN.UTF-8
LC_PAPER=zh_CN.UTF-8
LC_NAME=zh_CN.UTF-8
LC_ADDRESS=zh_CN.UTF-8
LC_TELEPHONE=zh_CN.UTF-8
LC_MEASUREMENT=zh_CN.UTF-8
LC_IDENTIFICATION=zh_CN.UTF-8
SSH_CLIENT=10.249.174.114 49269 22
SSH_CONNECTION=10.249.174.114 49269 10.239.44.39 22
SSH_TTY=/dev/pts/3
SHLVL=1
PWD=/home/user/tensorflow
OLDPWD=/home/user
ZSH=/home/user/.oh-my-zsh
PAGER=less
LESS=-R
LSCOLORS=Gxfxcxdxbxegedabagacad
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
LD_PRELOAD=/home/user/anaconda3/envs/dlrm/lib/libiomp5.so
CONDA_EXE=/home/user/anaconda3/bin/conda
_CE_M=
_CE_CONDA=
CONDA_PYTHON_EXE=/home/user/anaconda3/bin/python
CONDA_SHLVL=2
CONDA_PREFIX=/home/user/anaconda3/envs/tfenv
CONDA_DEFAULT_ENV=tfenv
CONDA_PROMPT_MODIFIER=(tfenv)
LD_LIBRARY_PATH=/usr/local/cuda-11.3/lib64
CONDA_PREFIX_1=/home/user/anaconda3
_=/usr/bin/env
```
"
50890,converting tensorflow model to mlir,"I saved tf model using model.save().Then I tried to convert it to mlir using tensorflow/bazel-bin/tensorflow/compiler/mlir/tf-mlir-translate --graphdef-to-mlir /data/aruna/tf_models/saved_model.pb -o /data/aruna/tf_models/convolution.mlir  but I am getting error as  tensorflow/compiler/mlir/tensorflow/translate/tf_mlir_translate.cc:163] SavedModel import failed: Failed precondition: Could not restore saved variable: Adam/conv2d/kernel/m
Am I giving correct flag to convert tf to mlir?"
50889,48584629.0这个浮点数数据类型转换精度丢失,"tf.cast(48584629.0,tf.float64)  转换后变成48584628"
50888,"tf.cast(48584629,tf.float32) 精度丢失","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50887,MacOS failure to compile dylib with metal delegate,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur (11.4)
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0
- Python version: Python 3.9.1
- Bazel version (if compiling from source): bazel 3.7.2-homebrew
- GCC/Compiler version (if compiling from source): clang version 11.0.0

**Describe the problem**
Building the default bazel target is fine and generates a dylib but when I add the metal delegate target to the file _tensorflow/lite/BUILD_:

```
tflite_cc_shared_object(
    name = ""tensorflowlite"",
    # Until we have more granular symbol export for the C++ API on Windows,
    # export all symbols.
    features = [""windows_export_all_symbols""],
    linkopts = select({
        ""//tensorflow:macos"": [
            ""-Wl,-exported_symbols_list,$(location //tensorflow/lite:tflite_exported_symbols.lds)"",
        ],
        ""//tensorflow:windows"": [],
        ""//conditions:default"": [
            ""-Wl,-z,defs"",
            ""-Wl,--version-script,$(location //tensorflow/lite:tflite_version_script.lds)"",
        ],
    }),
    per_os_targets = True,
    deps = [
        "":framework"",
        "":tflite_exported_symbols.lds"",
        "":tflite_version_script.lds"",
        ""//tensorflow/lite/tools/evaluation:utils"",
        ""//tensorflow/lite/delegates/gpu:metal_delegate"",      # adding this makes it fail
        ""//tensorflow/lite/kernels:builtin_ops_all_linked"",
    ],
)
```

It fails and gives me 

```
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=183
INFO: Reading rc options for 'build' from /Users/me/Repositories/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/me/Repositories/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /Users/me/Repositories/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 --action_env PYTHON_LIB_PATH=/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages --python_path=/Library/Frameworks/Python.framework/Versions/3.8/bin/python3
INFO: Found applicable config definition build:short_logs in file /Users/me/Repositories/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/me/Repositories/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:macos in file /Users/me/Repositories/tensorflow/.bazelrc: --apple_platform_type=macos --copt=-DGRPC_BAZEL_BUILD --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
ERROR: /private/var/tmp/_bazel_me/a01251391e7b28e63e36a7eb9c920e09/external/cpuinfo/BUILD.bazel:96:11: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:linux_arm
 @cpuinfo//:linux_armhf
 @cpuinfo//:linux_armv7a
 @cpuinfo//:linux_armeabi
 @cpuinfo//:linux_aarch64
 @cpuinfo//:linux_mips64
 @cpuinfo//:linux_riscv64
 @cpuinfo//:linux_s390x
 @cpuinfo//:macos_x86_64
 @cpuinfo//:macos_arm64
 @cpuinfo//:windows_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:tvos_x86_64
 @cpuinfo//:tvos_arm64
ERROR: Analysis of target '//tensorflow/lite:tensorflowlite' failed; build aborted: /private/var/tmp/_bazel_me/a01251391e7b28e63e36a7eb9c920e09/external/cpuinfo/BUILD.bazel:96:11: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:linux_arm
 @cpuinfo//:linux_armhf
 @cpuinfo//:linux_armv7a
 @cpuinfo//:linux_armeabi
 @cpuinfo//:linux_aarch64
 @cpuinfo//:linux_mips64
 @cpuinfo//:linux_riscv64
 @cpuinfo//:linux_s390x
 @cpuinfo//:macos_x86_64
 @cpuinfo//:macos_arm64
 @cpuinfo//:windows_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:tvos_x86_64
 @cpuinfo//:tvos_arm64
INFO: Elapsed time: 0.104s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 526 targets configured)
```
I assume when adding the metal delegate it changes the select cpu type (im not familiar with bazel enough to know).  Unless there is a better way of adding the metal target.

I also tried to add a target myself such as 

```
macos_dylib (
  name = ""tensorflowlite2"",
    minimum_os_version = ""10.12"",
  deps = [  
        ""//tensorflow/lite/kernels:builtin_ops_all_linked"",
        ""//tensorflow/lite/tools/evaluation:utils"",
        ""//tensorflow/lite/delegates/gpu:metal_delegate"",
],
)
```

First I had to change the cpu_info target to darwin_x86_64 (https://github.com/tensorflow/tensorflow/issues/41039) then I assume because of the CPU name change, when linking NNAPI it tries to build with `-lrt `which is not supported by MacOS and it will fail. Removing that flag (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/nnapi/BUILD#L38) I was able to build finally. I assume this is not the way I am supposed to do it but for some reason i had no issues with Android and iOS but MacOS has issues.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Building with option 1
1.  Clone and checkout **v2.5.0** branch (though I am sure this will fail on all branches and master)
2. Modify the BUILD file **tensorflow/lite/BUILD** and add `""//tensorflow/lite/delegates/gpu:metal_delegate""` (location =`https://github.com/tensorflow/tensorflow/blob/v2.5.0/tensorflow/lite/BUILD#L907`)
3.  Run the command  `bazel build -c opt --copt -Os  --cxxopt=-std=c++14 --apple_platform_type=macos //tensorflow/lite:tensorflowlite`

Building option 2
1. Clone and checkout **v2.5.0** branch (though I am sure this will fail on all branches and master)
2. Modify the BUILD file **tensorflow/lite/BUILD** and add
```
macos_dylib (
  name = ""tensorflowlite2"",
    minimum_os_version = ""10.12"",
  deps = [  
        ""//tensorflow/lite/kernels:builtin_ops_all_linked"",
        ""//tensorflow/lite/tools/evaluation:utils"",
        ""//tensorflow/lite/delegates/gpu:metal_delegate"",
],
)
```
3.  Run the command  `bazel build -c opt --copt -Os  --cxxopt=-std=c++14 --apple_platform_type=macos //tensorflow/tensorflowlite2`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
50886,[Question] TfLiteTensor is supposed to be deleted/released with TfLiteTensorFree?,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): from source
- TensorFlow version (use command below): master branch
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**TfLiteTensor is supposed to be deleted/released with TfLiteTensorFree?**
I found the function TfLiteTensorFree and TfLiteTensorReset in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/c/common.h#L608 ,  however, it is not clarified in the documentation and not seen in examples that TfLiteTensor(s) are supposed to be freed.

**Describe the expected behavior**
Clarify whether TfLiteTensor(s) are supposed to be freed.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50885,TF -> TFLite conversion error: could not rewrite use of immutable bound input,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**
- TensorFlow installation (pip package or built from source): **pip package**
- TensorFlow library (version, if pip package or github SHA, if built from source): **2.5.0**

### 2. Code

The model I'm trying to convert is a FasterRCNN model with an AlexNet backbone trained using PyTorch. From what I've gathered, the only way I could do this is by going from Torch -> ONNX -> Tensorflow -> TFLite. The conversion from Torch to ONNX succeeds but there's a couple of errors I encountered when converting from ONNX -> Tensorflow and subsequently from Tensorflow to TFLite. 

**Error 1:**  Resize coordinate_transformation_mode=pytorch_half_pixel is not supported in Tensorflow. (solved but may be related)

This is an error on the ONNX -> TF conversion side which I solved by modifying the transforms in the Torch model to include an `align_corners=True` argument in the interpolation call:

```
def ObjDetModel():
  
    # Define backbone
    backbone = torchvision.models.alexnet(pretrained=True).features
    backbone.out_channels = 256

    # Define anchor generator
    anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),
                           aspect_ratios=((0.5, 1.0, 2.0),))

    # Define ROI pooler
    roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],
                                        output_size=7,
                                        sampling_ratio=2)

    # put the pieces together inside a FasterRCNN model
    model = FasterRCNN(backbone,
                      num_classes=2,
                      rpn_anchor_generator=anchor_generator,
                      box_roi_pool=roi_pooler)

    min_size=800
    max_size=1333
    image_mean = [0.485, 0.456, 0.406]
    image_std = [0.229, 0.224, 0.225]


    # Change the transform op through subclassing the original transform class
    transform = ModifiedRCNNTransform(min_size, max_size, image_mean, image_std)
    model.transform = transform

    return model

@torch.jit.unused
def _get_shape_onnx(image):
    # type: (Tensor) -> Tensor
    from torch.onnx import operators
    return operators.shape_as_tensor(image)[-2:]

@torch.jit.unused
def _fake_cast_onnx(v):
    # type: (Tensor) -> float
    # ONNX requires a tensor but here we fake its type for JIT.
    return v

def _resize_image_and_masks(image: Tensor, 
                            self_min_size: float, 
                            self_max_size: float,
                            target: Optional[Dict[str, Tensor]] = None,
                            fixed_size: Optional[Tuple[int, int]] = None,
                            ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:
    if torchvision._is_tracing():
        im_shape = _get_shape_onnx(image)
    else:
        im_shape = torch.tensor(image.shape[-2:])

    size: Optional[List[int]] = None
    scale_factor: Optional[float] = None
    recompute_scale_factor: Optional[bool] = None

    if fixed_size is not None:
        size = [fixed_size[1], fixed_size[0]]
    else:
        min_size = torch.min(im_shape).to(dtype=torch.float32)
        max_size = torch.max(im_shape).to(dtype=torch.float32)
        scale = torch.min(self_min_size / min_size, self_max_size / max_size)

        if torchvision._is_tracing():
            scale_factor = _fake_cast_onnx(scale)
        else:
            scale_factor = scale.item()
        recompute_scale_factor = True

    # Had to add align_corners=True to make the conversion work
    image = torch.nn.functional.interpolate(image[None], size=size, scale_factor=scale_factor, mode='bilinear',
                                            recompute_scale_factor=recompute_scale_factor, align_corners=True)[0]

    if target is None:
        return image, target

    if ""masks"" in target:
        mask = target[""masks""]
        mask = torch.nn.functional.interpolate(mask[:, None].float(), size=size, scale_factor=scale_factor,
                                               recompute_scale_factor=recompute_scale_factor)[:, 0].byte()
        target[""masks""] = mask

    return image, target


def resize_boxes(boxes, original_size, new_size):
    # type: (Tensor, List[int], List[int]) -> Tensor
    ratios = [
        torch.tensor(s, dtype=torch.float32, device=boxes.device) /
        torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)
        for s, s_orig in zip(new_size, original_size)
    ]
    ratio_height, ratio_width = ratios
    xmin, ymin, xmax, ymax = boxes.unbind(1)

    xmin = xmin * ratio_width
    xmax = xmax * ratio_width
    ymin = ymin * ratio_height
    ymax = ymax * ratio_height
    return torch.stack((xmin, ymin, xmax, ymax), dim=1)

# Subclass the original GeneralizedRCNNTransform object and overwrite the resize method
class ModifiedRCNNTransform(GeneralizedRCNNTransform):
   """"""docstring for ModifiedRCNNTransform""""""
    def __init__(self, min_size, max_size, image_mean, image_std):
        super(ModifiedRCNNTransform, self).__init__(min_size, max_size, image_mean, image_std)
        
    def resize(self,
               image: Tensor,
               target: Optional[Dict[str, Tensor]] = None,
               ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:

        h, w = image.shape[-2:]

        if self.training:
            size = float(self.torch_choice(self.min_size))
        else:
            # FIXME assume for now that testing uses the largest scale
            size = float(self.min_size[-1])
        image, target = _resize_image_and_masks(image, size, float(self.max_size), target, self.fixed_size)
Error 2:
        if target is None:
            return image, target

        bbox = target[""boxes""]
        bbox = resize_boxes(bbox, (h, w), image.shape[-2:])
        target[""boxes""] = bbox

        if ""keypoints"" in target:
            keypoints = target[""keypoints""]
            keypoints = resize_keypoints(keypoints, (h, w), image.shape[-2:])
            target[""keypoints""] = keypoints
        return image, target
```

It is a very janky fix but it works (at least for the Torch -> ONNX -> Tensorflow conversion)

**Error 2:** 
2021-07-21 17:15:33.799749: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: ./saved_models/tf_model
2021-07-21 17:15:33.854208: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }
2021-07-21 17:15:33.854259: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: ./saved_models/tf_model
2021-07-21 17:15:33.961926: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
2021-07-21 17:15:34.185671: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ./saved_models/tf_model
2021-07-21 17:15:34.399376: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 599629 microseconds.
2021-07-21 17:15:35.011283: I tensorflow/compiler/mlir/tensorflow/translate/import_model.cc:1856] Unmodelled op type `CropAndResize` is not stateful but will be treated as such conservatively

Exception: <unknown>:0: error: loc(callsite(callsite(""onnx_tf_prefix_If_600@__inference___call___7107"" at ""StatefulPartitionedCall@__inference_signature_wrapper_7170"") at ""StatefulPartitionedCall"")): could not rewrite use of immutable bound input

The way I'm converting the model is very simple:

```
def TensorflowToTFLite(self, tf_path, tflite_path):

        print(""Converting from Tensorflow to TFLite"")
        # make a converter object from the saved tensorflow file
        print(""Initializing TFLite converter"")
        converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)

        converter.optimizations = [tf.lite.Optimize.DEFAULT]

        # tell converter which type of optimization techniques to use
        if self.full_quantize:
            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
            converter.representative_dataset = self.representative_dataset
            converter.inference_input_type = tf.uint8
            converter.inference_output_type = tf.uint8  

        else:
            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                                   tf.lite.OpsSet.SELECT_TF_OPS]
        
        try:
            print(""Converting to TFLite model"")
            tf_lite_model = converter.convert()

            print(""Saving TFLite Model..."")
            with open(tflite_path, 'wb') as f:
                f.write(tf_lite_model)

        except Exception as e:
            sys.exit(f""Tensorflow to TFLite conversion failed! Exception: {e}"")
```

Regardless of whether or not I am full quantizing, I encounter the error. For the life of me, I could not figure out why this is happening. If anyone could point me in the right direction, that would be great. Here's a [link](https://drive.google.com/drive/folders/1bZ4pGbsEOwmB4fxvUPFpain_NPnV_rmk?usp=sharing) to the models and the MLIR reproducer.

Thanks so much!"
50883,tf.math.sign() gives inconsistent output for the same input values for small complex numbers,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: X
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.6.12
- Bazel version (if compiling from source): X
- GCC/Compiler version (if compiling from source): X
- CUDA/cuDNN version: X
- GPU model and memory: X

**Describe the current behavior**
The function `tf.math.sign()` gives inconsistent results for `tf.complex64` values with small magnitudes.  When passing `tf.math.sign()` two slices of the same Tensor, one of which wholly includes the elements of the other, the same numerical inputs result in different values.

Referencing the code example below:
tf.math.sign(z[23:26]) -> [1.+0.j, 1.+0.j, 1.+0.j]
tf.math.sign(z[23:27]) -> [nan+nanj, nan+nanj, nan+nanj, nan+nanj]

I've also demonstrated this behavior when using the docker image `tensorflow/tensorflow:2.5.0`

**Describe the expected behavior**
Referencing the code example below:
tf.math.sign(z[23:26]) -> [1.+0.j, 1.+0.j, 1.+0.j]
tf.math.sign(z[23:27]) -> [1.+0.j, 1.+0.j, 1.+0.j, 1.+0.j (or some other value)]

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
print(tf.__version__)
x = tf.constant([10 ** -n for n in range(47)], dtype=tf.float32)
z = tf.complex(x, 0.0)

q0 = tf.math.sign(z[23:26])  # result: [1.+0.j, 1.+0.j, 1.+0.j]
q1 = tf.math.sign(z[23:27])  # result: [nan+nanj, nan+nanj, nan+nanj, nan+nanj]
```"
50881,model.evaluate() does not yield the same accuracy as computing it manually using a for-loop,"Apologies in advance if this is the wrong place for this discussion. I suspect the `model.evaluate()` behavior I identify below is a feature, not a bug, but would like to better understand it if so.

After following the transfer learning tutorial on [Tensorflow's site][1], I have a question about how `model.evaluate()` works in comparison to calculating accuracy by hand.

At the very end, after fine-tuning, in the Evaluation and prediction section, we use `model.evaluate()` to calculate the accuracy on the test set as follows:
```
loss, accuracy = model.evaluate(test_dataset)
print('Test accuracy :', accuracy)
6/6 [==============================] - 2s 217ms/step - loss: 0.0516 - accuracy: 0.9740
Test accuracy : 0.9739583134651184
```

Next, we generate predictions manually from one batch of images from the test set as part of a visualization exercise:
```
# Apply a sigmoid since our model returns logits
predictions = tf.nn.sigmoid(predictions)
predictions = tf.where(predictions < 0.5, 0, 1)
```
However, it's also possible to extend this functionality to calculate predictions across the entire test set and compare them to the actual values to yield an average accuracy:
```
all_acc=tf.zeros([], tf.int32) #initialize array to hold all accuracy indicators (single element)
for image_batch, label_batch in test_dataset.as_numpy_iterator():
    predictions = model.predict_on_batch(image_batch).flatten() #run batch through model and return logits
    predictions = tf.nn.sigmoid(predictions) #apply sigmoid activation function to transform logits to [0,1]
    predictions = tf.where(predictions < 0.5, 0, 1) #round down or up accordingly since it's a binary classifier
    accuracy = tf.where(tf.equal(predictions,label_batch),1,0) #correct is 1 and incorrect is 0
    all_acc = tf.experimental.numpy.append(all_acc, accuracy)
all_acc = all_acc[1:]  #drop first placeholder element
avg_acc = tf.reduce_mean(tf.dtypes.cast(all_acc, tf.float16)) 
print('My Accuracy:', avg_acc.numpy()) 
My Accuracy: 0.974
```

Now, if `model.evaluate()` generates predictions by applying a sigmoid to the logit model outputs and using a threshold of 0.5 like the tutorial suggests, my manually-calculated accuracy should equal the accuracy output of Tensorflow's `model.evaluate()` function. This is indeed the case for the tutorial. My Accuracy: 0.974 = accuracy from `model.evaluate()` function. However, when I try this same code with a model trained using the same convolutional base as the tutorial, but different Gabor images (not cats & dogs like the tutorial), my accuracy no longer equals the `model.evaluate()` accuracy:
```
current_set = set17 #define set to process. 
all_acc=tf.zeros([], tf.float64) #initialize array to hold all accuracy indicators (single element)
loss, acc = model.evaluate(current_set) #now test the model's performance on the test set
for image_batch, label_batch in current_set.as_numpy_iterator():
    predictions = model.predict_on_batch(image_batch).flatten() #run batch through model and return logits
    predictions = tf.nn.sigmoid(predictions) #apply sigmoid activation function to transform logits to [0,1]
    predictions = tf.where(predictions < 0.5, 0, 1) #round down or up accordingly since it's a binary classifier
    accuracy = tf.where(tf.equal(predictions,label_batch),1,0) #correct is 1 and incorrect is 0
    all_acc = tf.experimental.numpy.append(all_acc, accuracy)
all_acc = all_acc[1:]  #drop first placeholder element
avg_acc = tf.reduce_mean(all_acc)
print('My Accuracy:', avg_acc.numpy()) 
print('Tf Accuracy:', acc) 
My Accuracy: 0.832
Tf Accuracy: 0.675000011920929
```
Does anyone know why there would be a discrepancy? Does the model.evaluate() *not* use a sigmoid? Or does it use a different threshold than 0.5? Or perhaps it's something else I'm not considering? Please note, my new model was trained using Gabor images, which are different than the cats and dogs from the tutorial, but the code was the same. 

Thank you in advance for any insight!


  [1]: https://www.tensorflow.org/tutorials/images/transfer_learning


"
50880,"ModuleNotFoundError: No module named 'TensorFlow'  File ""<string>"", line 1, in <module>","**System information**
- OS Platform and Distribution : Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): $ pip install --upgrade TensorFlow
- TensorFlow version: tensorflow 2.5.0
- Python version: 3.8.10
- Installed using virtualenv? pip? conda?:      venv
- using the following sequence 
- $ python3 -m venv venv
$ source venv/bin/activate
$ pip install --upgrade pip
$ pip install --upgrade TensorFlow
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc version 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04)
- CUDA/cuDNN version: /usr/local/cuda-11.0 installed using  https://github.com/tensorflow/tensorflow/issues/45930
- 
-  cuda had a problem. I fixed using  
- 1) find / -name 'libcudart.so.11.0'
/usr/local/cuda-11.0/targets/x86_64-linux/lib/libcudart.so.11.0
2) edit /etc/profile
$ sudo vim /etc/profile
3) append path to ""LD_LIBRARY_PATH"" in profile file
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.0/targets/x86_64-linux/lib
4) make environment file work
source /etc/profile
-
- GPU model and memory:
- Intel HD Graphics 4400
HP proBook 430 G2 HSTNN-C84C product:F6N65AV  
cpu i5-4210U 1.7GHz 
memory 4G main 
64bit OS
-
-
**Describe the problem**
@hp430:~/my_tensorflow$ python -c 'import TensorFlow as tf; print(tf.__version__)'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'TensorFlow'
-
Any help really helps. Thanks.
-
**Provide the exact sequence of commands / steps that you executed before running into the problem**
$python3 -v
$ sudo apt install python3-venv python3-dev
$ mkdir my_tensorflow 
$ cd my_tensorflow 
$ python3 -m venv venv
$ source venv/bin/activate
$ pip install --upgrade pip
$ pip install --upgrade TensorFlow
$ python -c 'import TensorFlow as tf; print(tf.__version__)'
-
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
(venv) @hp430:~/my_tensorflow$ pip debug --verbose
WARNING: This command is only meant for debugging. Do not use this with automation for parsing and getting 
these details, since the output and options of this command may change without notice.
pip version: pip 21.1.3 from /home/benh/my_tensorflow/venv/lib/python3.8/site-packages/pip (python 3.8)
sys.version: 3.8.10 (default, Jun  2 2021, 10:49:15)
[GCC 9.4.0]
sys.executable: /home/benh/my_tensorflow/venv/bin/python3
sys.getdefaultencoding: utf-8
sys.getfilesystemencoding: utf-8
locale.getpreferredencoding: UTF-8
sys.platform: linux
sys.implementation:
  name: cpython
'cert' config value: Not specified
REQUESTS_CA_BUNDLE: None
CURL_CA_BUNDLE: None
pip._vendor.certifi.where(): /home/benh/my_tensorflow/venv/lib/python3.8/site-packages/pip/_vendor/certifi/cacert.pem
pip._vendor.DEBUNDLED: False
vendored library versions:
  appdirs==1.4.4
  CacheControl==0.12.6
  colorama==0.4.4
  distlib==0.3.1
  distro==1.5.0 (Unable to locate actual module version, using vendor.txt specified version)
  html5lib==1.1
  msgpack==1.0.2 (Unable to locate actual module version, using vendor.txt specified version)
  packaging==20.9
  pep517==0.10.0
  progress==1.5
  pyparsing==2.4.7
  requests==2.25.1
  certifi==2020.12.05
  chardet==4.0.0
  idna==3.1
  urllib3==1.26.4
  resolvelib==0.7.0
  setuptools==44.0.0 (Unable to locate actual module version, using vendor.txt specified version)
  six==1.15.0
  tenacity==7.0.0 (Unable to locate actual module version, using vendor.txt specified version)
  toml==0.10.2
  webencodings==0.5.1 (Unable to locate actual module version, using vendor.txt specified version)
Compatible tags: 600
  cp38-cp38-manylinux_2_31_x86_64
  cp38-cp38-manylinux_2_30_x86_64
  cp38-cp38-manylinux_2_29_x86_64
  cp38-cp38-manylinux_2_28_x86_64
  cp38-cp38-manylinux_2_27_x86_64
  cp38-cp38-manylinux_2_26_x86_64
  cp38-cp38-manylinux_2_25_x86_64
  cp38-cp38-manylinux_2_24_x86_64
  cp38-cp38-manylinux_2_23_x86_64
  cp38-cp38-manylinux_2_22_x86_64
  cp38-cp38-manylinux_2_21_x86_64
  cp38-cp38-manylinux_2_20_x86_64
  cp38-cp38-manylinux_2_19_x86_64
  cp38-cp38-manylinux_2_18_x86_64
  cp38-cp38-manylinux_2_17_x86_64
  cp38-cp38-manylinux2014_x86_64
  cp38-cp38-manylinux_2_16_x86_64
  cp38-cp38-manylinux_2_15_x86_64
  cp38-cp38-manylinux_2_14_x86_64
  cp38-cp38-manylinux_2_13_x86_64
  cp38-cp38-manylinux_2_12_x86_64
  cp38-cp38-manylinux2010_x86_64
  cp38-cp38-manylinux_2_11_x86_64
  cp38-cp38-manylinux_2_10_x86_64
  cp38-cp38-manylinux_2_9_x86_64
  cp38-cp38-manylinux_2_8_x86_64
  cp38-cp38-manylinux_2_7_x86_64
  cp38-cp38-manylinux_2_6_x86_64
  cp38-cp38-manylinux_2_5_x86_64
  cp38-cp38-manylinux1_x86_64
  cp38-cp38-linux_x86_64
  cp38-abi3-manylinux_2_31_x86_64
  cp38-abi3-manylinux_2_30_x86_64
  cp38-abi3-manylinux_2_29_x86_64
  cp38-abi3-manylinux_2_28_x86_64
  cp38-abi3-manylinux_2_27_x86_64
  cp38-abi3-manylinux_2_26_x86_64
  cp38-abi3-manylinux_2_25_x86_64
  cp38-abi3-manylinux_2_24_x86_64
  cp38-abi3-manylinux_2_23_x86_64
  cp38-abi3-manylinux_2_22_x86_64
  cp38-abi3-manylinux_2_21_x86_64
  cp38-abi3-manylinux_2_20_x86_64
  cp38-abi3-manylinux_2_19_x86_64
  cp38-abi3-manylinux_2_18_x86_64
  cp38-abi3-manylinux_2_17_x86_64
  cp38-abi3-manylinux2014_x86_64
  cp38-abi3-manylinux_2_16_x86_64
  cp38-abi3-manylinux_2_15_x86_64
  cp38-abi3-manylinux_2_14_x86_64
  cp38-abi3-manylinux_2_13_x86_64
  cp38-abi3-manylinux_2_12_x86_64
  cp38-abi3-manylinux2010_x86_64
  cp38-abi3-manylinux_2_11_x86_64
  cp38-abi3-manylinux_2_10_x86_64
  cp38-abi3-manylinux_2_9_x86_64
  cp38-abi3-manylinux_2_8_x86_64
  cp38-abi3-manylinux_2_7_x86_64
  cp38-abi3-manylinux_2_6_x86_64
  cp38-abi3-manylinux_2_5_x86_64
  cp38-abi3-manylinux1_x86_64
  cp38-abi3-linux_x86_64
  cp38-none-manylinux_2_31_x86_64
  cp38-none-manylinux_2_30_x86_64
  cp38-none-manylinux_2_29_x86_64
  cp38-none-manylinux_2_28_x86_64
  cp38-none-manylinux_2_27_x86_64
  cp38-none-manylinux_2_26_x86_64
  cp38-none-manylinux_2_25_x86_64
  cp38-none-manylinux_2_24_x86_64
  cp38-none-manylinux_2_23_x86_64
  cp38-none-manylinux_2_22_x86_64
  cp38-none-manylinux_2_21_x86_64
  cp38-none-manylinux_2_20_x86_64
  cp38-none-manylinux_2_19_x86_64
  cp38-none-manylinux_2_18_x86_64
  cp38-none-manylinux_2_17_x86_64
  cp38-none-manylinux2014_x86_64
  cp38-none-manylinux_2_16_x86_64
  cp38-none-manylinux_2_15_x86_64
  cp38-none-manylinux_2_14_x86_64
  cp38-none-manylinux_2_13_x86_64
  cp38-none-manylinux_2_12_x86_64
  cp38-none-manylinux2010_x86_64
  cp38-none-manylinux_2_11_x86_64
  cp38-none-manylinux_2_10_x86_64
  cp38-none-manylinux_2_9_x86_64
  cp38-none-manylinux_2_8_x86_64
  cp38-none-manylinux_2_7_x86_64
  cp38-none-manylinux_2_6_x86_64
  cp38-none-manylinux_2_5_x86_64
  cp38-none-manylinux1_x86_64
  cp38-none-linux_x86_64
  cp37-abi3-manylinux_2_31_x86_64
  cp37-abi3-manylinux_2_30_x86_64
  cp37-abi3-manylinux_2_29_x86_64
  cp37-abi3-manylinux_2_28_x86_64
  cp37-abi3-manylinux_2_27_x86_64
  cp37-abi3-manylinux_2_26_x86_64
  cp37-abi3-manylinux_2_25_x86_64
  cp37-abi3-manylinux_2_24_x86_64
  cp37-abi3-manylinux_2_23_x86_64
  cp37-abi3-manylinux_2_22_x86_64
  cp37-abi3-manylinux_2_21_x86_64
  cp37-abi3-manylinux_2_20_x86_64
  cp37-abi3-manylinux_2_19_x86_64
  cp37-abi3-manylinux_2_18_x86_64
  cp37-abi3-manylinux_2_17_x86_64
  cp37-abi3-manylinux2014_x86_64
  cp37-abi3-manylinux_2_16_x86_64
  cp37-abi3-manylinux_2_15_x86_64
  cp37-abi3-manylinux_2_14_x86_64
  cp37-abi3-manylinux_2_13_x86_64
  cp37-abi3-manylinux_2_12_x86_64
  cp37-abi3-manylinux2010_x86_64
  cp37-abi3-manylinux_2_11_x86_64
  cp37-abi3-manylinux_2_10_x86_64
  cp37-abi3-manylinux_2_9_x86_64
  cp37-abi3-manylinux_2_8_x86_64
  cp37-abi3-manylinux_2_7_x86_64
  cp37-abi3-manylinux_2_6_x86_64
  cp37-abi3-manylinux_2_5_x86_64
  cp37-abi3-manylinux1_x86_64
  cp37-abi3-linux_x86_64
  cp36-abi3-manylinux_2_31_x86_64
  cp36-abi3-manylinux_2_30_x86_64
  cp36-abi3-manylinux_2_29_x86_64
  cp36-abi3-manylinux_2_28_x86_64
  cp36-abi3-manylinux_2_27_x86_64
  cp36-abi3-manylinux_2_26_x86_64
  cp36-abi3-manylinux_2_25_x86_64
  cp36-abi3-manylinux_2_24_x86_64
  cp36-abi3-manylinux_2_23_x86_64
  cp36-abi3-manylinux_2_22_x86_64
  cp36-abi3-manylinux_2_21_x86_64
  cp36-abi3-manylinux_2_20_x86_64
  cp36-abi3-manylinux_2_19_x86_64
  cp36-abi3-manylinux_2_18_x86_64
  cp36-abi3-manylinux_2_17_x86_64
  cp36-abi3-manylinux2014_x86_64
  cp36-abi3-manylinux_2_16_x86_64
  cp36-abi3-manylinux_2_15_x86_64
  cp36-abi3-manylinux_2_14_x86_64
  cp36-abi3-manylinux_2_13_x86_64
  cp36-abi3-manylinux_2_12_x86_64
  cp36-abi3-manylinux2010_x86_64
  cp36-abi3-manylinux_2_11_x86_64
  cp36-abi3-manylinux_2_10_x86_64
  cp36-abi3-manylinux_2_9_x86_64
  cp36-abi3-manylinux_2_8_x86_64
  cp36-abi3-manylinux_2_7_x86_64
  cp36-abi3-manylinux_2_6_x86_64
  cp36-abi3-manylinux_2_5_x86_64
  cp36-abi3-manylinux1_x86_64
  cp36-abi3-linux_x86_64
  cp35-abi3-manylinux_2_31_x86_64
  cp35-abi3-manylinux_2_30_x86_64
  cp35-abi3-manylinux_2_29_x86_64
  cp35-abi3-manylinux_2_28_x86_64
  cp35-abi3-manylinux_2_27_x86_64
  cp35-abi3-manylinux_2_26_x86_64
  cp35-abi3-manylinux_2_25_x86_64
  cp35-abi3-manylinux_2_24_x86_64
  cp35-abi3-manylinux_2_23_x86_64
  cp35-abi3-manylinux_2_22_x86_64
  cp35-abi3-manylinux_2_21_x86_64
  cp35-abi3-manylinux_2_20_x86_64
  cp35-abi3-manylinux_2_19_x86_64
  cp35-abi3-manylinux_2_18_x86_64
  cp35-abi3-manylinux_2_17_x86_64
  cp35-abi3-manylinux2014_x86_64
  cp35-abi3-manylinux_2_16_x86_64
  cp35-abi3-manylinux_2_15_x86_64
  cp35-abi3-manylinux_2_14_x86_64
  cp35-abi3-manylinux_2_13_x86_64
  cp35-abi3-manylinux_2_12_x86_64
  cp35-abi3-manylinux2010_x86_64
  cp35-abi3-manylinux_2_11_x86_64
  cp35-abi3-manylinux_2_10_x86_64
  cp35-abi3-manylinux_2_9_x86_64
  cp35-abi3-manylinux_2_8_x86_64
  cp35-abi3-manylinux_2_7_x86_64
  cp35-abi3-manylinux_2_6_x86_64
  cp35-abi3-manylinux_2_5_x86_64
  cp35-abi3-manylinux1_x86_64
  cp35-abi3-linux_x86_64
  cp34-abi3-manylinux_2_31_x86_64
  cp34-abi3-manylinux_2_30_x86_64
  cp34-abi3-manylinux_2_29_x86_64
  cp34-abi3-manylinux_2_28_x86_64
  cp34-abi3-manylinux_2_27_x86_64
  cp34-abi3-manylinux_2_26_x86_64
  cp34-abi3-manylinux_2_25_x86_64
  cp34-abi3-manylinux_2_24_x86_64
  cp34-abi3-manylinux_2_23_x86_64
  cp34-abi3-manylinux_2_22_x86_64
  cp34-abi3-manylinux_2_21_x86_64
  cp34-abi3-manylinux_2_20_x86_64
  cp34-abi3-manylinux_2_19_x86_64
  cp34-abi3-manylinux_2_18_x86_64
  cp34-abi3-manylinux_2_17_x86_64
  cp34-abi3-manylinux2014_x86_64
  cp34-abi3-manylinux_2_16_x86_64
  cp34-abi3-manylinux_2_15_x86_64
  cp34-abi3-manylinux_2_14_x86_64
  cp34-abi3-manylinux_2_13_x86_64
  cp34-abi3-manylinux_2_12_x86_64
  cp34-abi3-manylinux2010_x86_64
  cp34-abi3-manylinux_2_11_x86_64
  cp34-abi3-manylinux_2_10_x86_64
  cp34-abi3-manylinux_2_9_x86_64
  cp34-abi3-manylinux_2_8_x86_64
  cp34-abi3-manylinux_2_7_x86_64
  cp34-abi3-manylinux_2_6_x86_64
  cp34-abi3-manylinux_2_5_x86_64
  cp34-abi3-manylinux1_x86_64
  cp34-abi3-linux_x86_64
  cp33-abi3-manylinux_2_31_x86_64
  cp33-abi3-manylinux_2_30_x86_64
  cp33-abi3-manylinux_2_29_x86_64
  cp33-abi3-manylinux_2_28_x86_64
  cp33-abi3-manylinux_2_27_x86_64
  cp33-abi3-manylinux_2_26_x86_64
  cp33-abi3-manylinux_2_25_x86_64
  cp33-abi3-manylinux_2_24_x86_64
  cp33-abi3-manylinux_2_23_x86_64
  cp33-abi3-manylinux_2_22_x86_64
  cp33-abi3-manylinux_2_21_x86_64
  cp33-abi3-manylinux_2_20_x86_64
  cp33-abi3-manylinux_2_19_x86_64
  cp33-abi3-manylinux_2_18_x86_64
  cp33-abi3-manylinux_2_17_x86_64
  cp33-abi3-manylinux2014_x86_64
  cp33-abi3-manylinux_2_16_x86_64
  cp33-abi3-manylinux_2_15_x86_64
  cp33-abi3-manylinux_2_14_x86_64
  cp33-abi3-manylinux_2_13_x86_64
  cp33-abi3-manylinux_2_12_x86_64
  cp33-abi3-manylinux2010_x86_64
  cp33-abi3-manylinux_2_11_x86_64
  cp33-abi3-manylinux_2_10_x86_64
  cp33-abi3-manylinux_2_9_x86_64
  cp33-abi3-manylinux_2_8_x86_64
  cp33-abi3-manylinux_2_7_x86_64
  cp33-abi3-manylinux_2_6_x86_64
  cp33-abi3-manylinux_2_5_x86_64
  cp33-abi3-manylinux1_x86_64
  cp33-abi3-linux_x86_64
  cp32-abi3-manylinux_2_31_x86_64
  cp32-abi3-manylinux_2_30_x86_64
  cp32-abi3-manylinux_2_29_x86_64
  cp32-abi3-manylinux_2_28_x86_64
  cp32-abi3-manylinux_2_27_x86_64
  cp32-abi3-manylinux_2_26_x86_64
  cp32-abi3-manylinux_2_25_x86_64
  cp32-abi3-manylinux_2_24_x86_64
  cp32-abi3-manylinux_2_23_x86_64
  cp32-abi3-manylinux_2_22_x86_64
  cp32-abi3-manylinux_2_21_x86_64
  cp32-abi3-manylinux_2_20_x86_64
  cp32-abi3-manylinux_2_19_x86_64
  cp32-abi3-manylinux_2_18_x86_64
  cp32-abi3-manylinux_2_17_x86_64
  cp32-abi3-manylinux2014_x86_64
  cp32-abi3-manylinux_2_16_x86_64
  cp32-abi3-manylinux_2_15_x86_64
  cp32-abi3-manylinux_2_14_x86_64
  cp32-abi3-manylinux_2_13_x86_64
  cp32-abi3-manylinux_2_12_x86_64
  cp32-abi3-manylinux2010_x86_64
  cp32-abi3-manylinux_2_11_x86_64
  cp32-abi3-manylinux_2_10_x86_64
  cp32-abi3-manylinux_2_9_x86_64
  cp32-abi3-manylinux_2_8_x86_64
  cp32-abi3-manylinux_2_7_x86_64
  cp32-abi3-manylinux_2_6_x86_64
  cp32-abi3-manylinux_2_5_x86_64
  cp32-abi3-manylinux1_x86_64
  cp32-abi3-linux_x86_64
  py38-none-manylinux_2_31_x86_64
  py38-none-manylinux_2_30_x86_64
  py38-none-manylinux_2_29_x86_64
  py38-none-manylinux_2_28_x86_64
  py38-none-manylinux_2_27_x86_64
  py38-none-manylinux_2_26_x86_64
  py38-none-manylinux_2_25_x86_64
  py38-none-manylinux_2_24_x86_64
  py38-none-manylinux_2_23_x86_64
  py38-none-manylinux_2_22_x86_64
  py38-none-manylinux_2_21_x86_64
  py38-none-manylinux_2_20_x86_64
  py38-none-manylinux_2_19_x86_64
  py38-none-manylinux_2_18_x86_64
  py38-none-manylinux_2_17_x86_64
  py38-none-manylinux2014_x86_64
  py38-none-manylinux_2_16_x86_64
  py38-none-manylinux_2_15_x86_64
  py38-none-manylinux_2_14_x86_64
  py38-none-manylinux_2_13_x86_64
  py38-none-manylinux_2_12_x86_64
  py38-none-manylinux2010_x86_64
  py38-none-manylinux_2_11_x86_64
  py38-none-manylinux_2_10_x86_64
  py38-none-manylinux_2_9_x86_64
  py38-none-manylinux_2_8_x86_64
  py38-none-manylinux_2_7_x86_64
  py38-none-manylinux_2_6_x86_64
  py38-none-manylinux_2_5_x86_64
  py38-none-manylinux1_x86_64
  py38-none-linux_x86_64
  py3-none-manylinux_2_31_x86_64
  py3-none-manylinux_2_30_x86_64
  py3-none-manylinux_2_29_x86_64
  py3-none-manylinux_2_28_x86_64
  py3-none-manylinux_2_27_x86_64
  py3-none-manylinux_2_26_x86_64
  py3-none-manylinux_2_25_x86_64
  py3-none-manylinux_2_24_x86_64
  py3-none-manylinux_2_23_x86_64
  py3-none-manylinux_2_22_x86_64
  py3-none-manylinux_2_21_x86_64
  py3-none-manylinux_2_20_x86_64
  py3-none-manylinux_2_19_x86_64
  py3-none-manylinux_2_18_x86_64
  py3-none-manylinux_2_17_x86_64
  py3-none-manylinux2014_x86_64
  py3-none-manylinux_2_16_x86_64
  py3-none-manylinux_2_15_x86_64
  py3-none-manylinux_2_14_x86_64
  py3-none-manylinux_2_13_x86_64
  py3-none-manylinux_2_12_x86_64
  py3-none-manylinux2010_x86_64
  py3-none-manylinux_2_11_x86_64
  py3-none-manylinux_2_10_x86_64
  py3-none-manylinux_2_9_x86_64
  py3-none-manylinux_2_8_x86_64
  py3-none-manylinux_2_7_x86_64
  py3-none-manylinux_2_6_x86_64
  py3-none-manylinux_2_5_x86_64
  py3-none-manylinux1_x86_64
  py3-none-linux_x86_64
  py37-none-manylinux_2_31_x86_64
  py37-none-manylinux_2_30_x86_64
  py37-none-manylinux_2_29_x86_64
  py37-none-manylinux_2_28_x86_64
  py37-none-manylinux_2_27_x86_64
  py37-none-manylinux_2_26_x86_64
  py37-none-manylinux_2_25_x86_64
  py37-none-manylinux_2_24_x86_64
  py37-none-manylinux_2_23_x86_64
  py37-none-manylinux_2_22_x86_64
  py37-none-manylinux_2_21_x86_64
  py37-none-manylinux_2_20_x86_64
  py37-none-manylinux_2_19_x86_64
  py37-none-manylinux_2_18_x86_64
  py37-none-manylinux_2_17_x86_64
  py37-none-manylinux2014_x86_64
  py37-none-manylinux_2_16_x86_64
  py37-none-manylinux_2_15_x86_64
  py37-none-manylinux_2_14_x86_64
  py37-none-manylinux_2_13_x86_64
  py37-none-manylinux_2_12_x86_64
  py37-none-manylinux2010_x86_64
  py37-none-manylinux_2_11_x86_64
  py37-none-manylinux_2_10_x86_64
  py37-none-manylinux_2_9_x86_64
  py37-none-manylinux_2_8_x86_64
  py37-none-manylinux_2_7_x86_64
  py37-none-manylinux_2_6_x86_64
  py37-none-manylinux_2_5_x86_64
  py37-none-manylinux1_x86_64
  py37-none-linux_x86_64
  py36-none-manylinux_2_31_x86_64
  py36-none-manylinux_2_30_x86_64
  py36-none-manylinux_2_29_x86_64
  py36-none-manylinux_2_28_x86_64
  py36-none-manylinux_2_27_x86_64
  py36-none-manylinux_2_26_x86_64
  py36-none-manylinux_2_25_x86_64
  py36-none-manylinux_2_24_x86_64
  py36-none-manylinux_2_23_x86_64
  py36-none-manylinux_2_22_x86_64
  py36-none-manylinux_2_21_x86_64
  py36-none-manylinux_2_20_x86_64
  py36-none-manylinux_2_19_x86_64
  py36-none-manylinux_2_18_x86_64
  py36-none-manylinux_2_17_x86_64
  py36-none-manylinux2014_x86_64
  py36-none-manylinux_2_16_x86_64
  py36-none-manylinux_2_15_x86_64
  py36-none-manylinux_2_14_x86_64
  py36-none-manylinux_2_13_x86_64
  py36-none-manylinux_2_12_x86_64
  py36-none-manylinux2010_x86_64
  py36-none-manylinux_2_11_x86_64
  py36-none-manylinux_2_10_x86_64
  py36-none-manylinux_2_9_x86_64
  py36-none-manylinux_2_8_x86_64
  py36-none-manylinux_2_7_x86_64
  py36-none-manylinux_2_6_x86_64
  py36-none-manylinux_2_5_x86_64
  py36-none-manylinux1_x86_64
  py36-none-linux_x86_64
  py35-none-manylinux_2_31_x86_64
  py35-none-manylinux_2_30_x86_64
  py35-none-manylinux_2_29_x86_64
  py35-none-manylinux_2_28_x86_64
  py35-none-manylinux_2_27_x86_64
  py35-none-manylinux_2_26_x86_64
  py35-none-manylinux_2_25_x86_64
  py35-none-manylinux_2_24_x86_64
  py35-none-manylinux_2_23_x86_64
  py35-none-manylinux_2_22_x86_64
  py35-none-manylinux_2_21_x86_64
  py35-none-manylinux_2_20_x86_64
  py35-none-manylinux_2_19_x86_64
  py35-none-manylinux_2_18_x86_64
  py35-none-manylinux_2_17_x86_64
  py35-none-manylinux2014_x86_64
  py35-none-manylinux_2_16_x86_64
  py35-none-manylinux_2_15_x86_64
  py35-none-manylinux_2_14_x86_64
  py35-none-manylinux_2_13_x86_64
  py35-none-manylinux_2_12_x86_64
  py35-none-manylinux2010_x86_64
  py35-none-manylinux_2_11_x86_64
  py35-none-manylinux_2_10_x86_64
  py35-none-manylinux_2_9_x86_64
  py35-none-manylinux_2_8_x86_64
  py35-none-manylinux_2_7_x86_64
  py35-none-manylinux_2_6_x86_64
  py35-none-manylinux_2_5_x86_64
  py35-none-manylinux1_x86_64
  py35-none-linux_x86_64
  py34-none-manylinux_2_31_x86_64
  py34-none-manylinux_2_30_x86_64
  py34-none-manylinux_2_29_x86_64
  py34-none-manylinux_2_28_x86_64
  py34-none-manylinux_2_27_x86_64
  py34-none-manylinux_2_26_x86_64
  py34-none-manylinux_2_25_x86_64
  py34-none-manylinux_2_24_x86_64
  py34-none-manylinux_2_23_x86_64
  py34-none-manylinux_2_22_x86_64
  py34-none-manylinux_2_21_x86_64
  py34-none-manylinux_2_20_x86_64
  py34-none-manylinux_2_19_x86_64
  py34-none-manylinux_2_18_x86_64
  py34-none-manylinux_2_17_x86_64
  py34-none-manylinux2014_x86_64
  py34-none-manylinux_2_16_x86_64
  py34-none-manylinux_2_15_x86_64
  py34-none-manylinux_2_14_x86_64
  py34-none-manylinux_2_13_x86_64
  py34-none-manylinux_2_12_x86_64
  py34-none-manylinux2010_x86_64
  py34-none-manylinux_2_11_x86_64
  py34-none-manylinux_2_10_x86_64
  py34-none-manylinux_2_9_x86_64
  py34-none-manylinux_2_8_x86_64
  py34-none-manylinux_2_7_x86_64
  py34-none-manylinux_2_6_x86_64
  py34-none-manylinux_2_5_x86_64
  py34-none-manylinux1_x86_64
  py34-none-linux_x86_64
  py33-none-manylinux_2_31_x86_64
  py33-none-manylinux_2_30_x86_64
  py33-none-manylinux_2_29_x86_64
  py33-none-manylinux_2_28_x86_64
  py33-none-manylinux_2_27_x86_64
  py33-none-manylinux_2_26_x86_64
  py33-none-manylinux_2_25_x86_64
  py33-none-manylinux_2_24_x86_64
  py33-none-manylinux_2_23_x86_64
  py33-none-manylinux_2_22_x86_64
  py33-none-manylinux_2_21_x86_64
  py33-none-manylinux_2_20_x86_64
  py33-none-manylinux_2_19_x86_64
  py33-none-manylinux_2_18_x86_64
  py33-none-manylinux_2_17_x86_64
  py33-none-manylinux2014_x86_64
  py33-none-manylinux_2_16_x86_64
  py33-none-manylinux_2_15_x86_64
  py33-none-manylinux_2_14_x86_64
  py33-none-manylinux_2_13_x86_64
  py33-none-manylinux_2_12_x86_64
  py33-none-manylinux2010_x86_64
  py33-none-manylinux_2_11_x86_64
  py33-none-manylinux_2_10_x86_64
  py33-none-manylinux_2_9_x86_64
  py33-none-manylinux_2_8_x86_64
  py33-none-manylinux_2_7_x86_64
  py33-none-manylinux_2_6_x86_64
  py33-none-manylinux_2_5_x86_64
  py33-none-manylinux1_x86_64
  py33-none-linux_x86_64
  py32-none-manylinux_2_31_x86_64
  py32-none-manylinux_2_30_x86_64
  py32-none-manylinux_2_29_x86_64
  py32-none-manylinux_2_28_x86_64
  py32-none-manylinux_2_27_x86_64
  py32-none-manylinux_2_26_x86_64
  py32-none-manylinux_2_25_x86_64
  py32-none-manylinux_2_24_x86_64
  py32-none-manylinux_2_23_x86_64
  py32-none-manylinux_2_22_x86_64
  py32-none-manylinux_2_21_x86_64
  py32-none-manylinux_2_20_x86_64
  py32-none-manylinux_2_19_x86_64
  py32-none-manylinux_2_18_x86_64
  py32-none-manylinux_2_17_x86_64
  py32-none-manylinux2014_x86_64
  py32-none-manylinux_2_16_x86_64
  py32-none-manylinux_2_15_x86_64
  py32-none-manylinux_2_14_x86_64
  py32-none-manylinux_2_13_x86_64
  py32-none-manylinux_2_12_x86_64
  py32-none-manylinux2010_x86_64
  py32-none-manylinux_2_11_x86_64
  py32-none-manylinux_2_10_x86_64
  py32-none-manylinux_2_9_x86_64
  py32-none-manylinux_2_8_x86_64
  py32-none-manylinux_2_7_x86_64
  py32-none-manylinux_2_6_x86_64
  py32-none-manylinux_2_5_x86_64
  py32-none-manylinux1_x86_64
  py32-none-linux_x86_64
  py31-none-manylinux_2_31_x86_64
  py31-none-manylinux_2_30_x86_64
  py31-none-manylinux_2_29_x86_64
  py31-none-manylinux_2_28_x86_64
  py31-none-manylinux_2_27_x86_64
  py31-none-manylinux_2_26_x86_64
  py31-none-manylinux_2_25_x86_64
  py31-none-manylinux_2_24_x86_64
  py31-none-manylinux_2_23_x86_64
  py31-none-manylinux_2_22_x86_64
  py31-none-manylinux_2_21_x86_64
  py31-none-manylinux_2_20_x86_64
  py31-none-manylinux_2_19_x86_64
  py31-none-manylinux_2_18_x86_64
  py31-none-manylinux_2_17_x86_64
  py31-none-manylinux2014_x86_64
  py31-none-manylinux_2_16_x86_64
  py31-none-manylinux_2_15_x86_64
  py31-none-manylinux_2_14_x86_64
  py31-none-manylinux_2_13_x86_64
  py31-none-manylinux_2_12_x86_64
  py31-none-manylinux2010_x86_64
  py31-none-manylinux_2_11_x86_64
  py31-none-manylinux_2_10_x86_64
  py31-none-manylinux_2_9_x86_64
  py31-none-manylinux_2_8_x86_64
  py31-none-manylinux_2_7_x86_64
  py31-none-manylinux_2_6_x86_64
  py31-none-manylinux_2_5_x86_64
  py31-none-manylinux1_x86_64
  py31-none-linux_x86_64
  py30-none-manylinux_2_31_x86_64
  py30-none-manylinux_2_30_x86_64
  py30-none-manylinux_2_29_x86_64
  py30-none-manylinux_2_28_x86_64
  py30-none-manylinux_2_27_x86_64
  py30-none-manylinux_2_26_x86_64
  py30-none-manylinux_2_25_x86_64
  py30-none-manylinux_2_24_x86_64
  py30-none-manylinux_2_23_x86_64
  py30-none-manylinux_2_22_x86_64
  py30-none-manylinux_2_21_x86_64
  py30-none-manylinux_2_20_x86_64
  py30-none-manylinux_2_19_x86_64
  py30-none-manylinux_2_18_x86_64
  py30-none-manylinux_2_17_x86_64
  py30-none-manylinux2014_x86_64
  py30-none-manylinux_2_16_x86_64
  py30-none-manylinux_2_15_x86_64
  py30-none-manylinux_2_14_x86_64
  py30-none-manylinux_2_13_x86_64
  py30-none-manylinux_2_12_x86_64
  py30-none-manylinux2010_x86_64
  py30-none-manylinux_2_11_x86_64
  py30-none-manylinux_2_10_x86_64
  py30-none-manylinux_2_9_x86_64
  py30-none-manylinux_2_8_x86_64
  py30-none-manylinux_2_7_x86_64
  py30-none-manylinux_2_6_x86_64
  py30-none-manylinux_2_5_x86_64
  py30-none-manylinux1_x86_64
  py30-none-linux_x86_64
  cp38-none-any
  py38-none-any
  py3-none-any
  py37-none-any
  py36-none-any
  py35-none-any
  py34-none-any
  py33-none-any
  py32-none-any
  py31-none-any
  py30-none-any
==================
(venv) @hp430:~/my_tensorflow$ python -m pip --version and python -m pip install --upgrade pip && python 
-m pip install -vvv tensorflow && python -c ""import tensorflow""
pip 21.1.3 from /home/benh/my_tensorflow/venv/lib/python3.8/site-packages/pip (python 3.8)
Using pip 21.1.3 from /home/benh/my_tensorflow/venv/lib/python3.8/site-packages/pip (python 3.8)
Non-user install because user site-packages disabled
Created temporary directory: /tmp/pip-ephem-wheel-cache-xo6vdpue
Created temporary directory: /tmp/pip-req-tracker-5wc69qjc
Initialized build tracking at /tmp/pip-req-tracker-5wc69qjc
Created build tracker: /tmp/pip-req-tracker-5wc69qjc
Entered build tracker: /tmp/pip-req-tracker-5wc69qjc
Created temporary directory: /tmp/pip-install-__l3fu1x
Requirement already satisfied: tensorflow in ./venv/lib/python3.8/site-packages (2.5.0)
Requirement already satisfied: absl-py~=0.10 in ./venv/lib/python3.8/site-packages (from tensorflow) (0.13.0)
Requirement already satisfied: google-pasta~=0.2 in ./venv/lib/python3.8/site-packages (from tensorflow) 
(0.2.0)
Requirement already satisfied: gast==0.4.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)
Requirement already satisfied: typing-extensions~=3.7.4 in ./venv/lib/python3.8/site-packages (from 
tensorflow) (3.7.4.3)
Requirement already satisfied: six~=1.15.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.15.0)
Requirement already satisfied: h5py~=3.1.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (3.1.0)
Requirement already satisfied: wrapt~=1.12.1 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.12.1)
Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in ./venv/lib/python3.8/site-packages 
(from tensorflow) (2.5.0)
Requirement already satisfied: flatbuffers~=1.12.0 in ./venv/lib/python3.8/site-packages (from tensorflow) 
(1.12)
Requirement already satisfied: termcolor~=1.1.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.1.0)
Requirement already satisfied: grpcio~=1.34.0 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.34.1)
Requirement already satisfied: wheel~=0.35 in ./venv/lib/python3.8/site-packages (from tensorflow) (0.36.2)
Requirement already satisfied: opt-einsum~=3.3.0 in ./venv/lib/python3.8/site-packages (from tensorflow) 
(3.3.0)
Requirement already satisfied: protobuf>=3.9.2 in ./venv/lib/python3.8/site-packages (from tensorflow) (3.17.3)
Requirement already satisfied: astunparse~=1.6.3 in ./venv/lib/python3.8/site-packages (from tensorflow) 
(1.6.3)
Requirement already satisfied: tensorboard~=2.5 in ./venv/lib/python3.8/site-packages (from tensorflow) 
(2.5.0)
Requirement already satisfied: numpy~=1.19.2 in ./venv/lib/python3.8/site-packages (from tensorflow) (1.19.5)
Requirement already satisfied: keras-preprocessing~=1.1.2 in ./venv/lib/python3.8/site-packages (from 
tensorflow) (1.1.2)
Requirement already satisfied: keras-nightly~=2.5.0.dev in ./venv/lib/python3.8/site-packages (from tensorflow) 
(2.5.0.dev2021032900)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (0.4.4)
Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (2.26.0)
Requirement already satisfied: google-auth<2,>=1.6.3 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (1.33.1)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./venv/lib/python3.8/site-packages 
(from tensorboard~=2.5->tensorflow) (0.6.1)
Requirement already satisfied: werkzeug>=0.11.15 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (2.0.1)
Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (57.4.0)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (1.8.0)
Requirement already satisfied: markdown>=2.6.8 in ./venv/lib/python3.8/site-packages (from 
tensorboard~=2.5->tensorflow) (3.3.4)
Requirement already satisfied: rsa<5,>=3.1.4 in ./venv/lib/python3.8/site-packages (from google-
auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)
Requirement already satisfied: pyasn1-modules>=0.2.1 in ./venv/lib/python3.8/site-packages (from google-
auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)
Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./venv/lib/python3.8/site-packages (from google-
auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)
Requirement already satisfied: requests-oauthlib>=0.7.0 in ./venv/lib/python3.8/site-packages (from google-
auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./venv/lib/python3.8/site-packages (from pyasn1-
modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)
Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from 
requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.8/site-packages (from 
requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.6)
Requirement already satisfied: charset-normalizer~=2.0.0 in ./venv/lib/python3.8/site-packages (from 
requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.0.3)
Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests<3,>=2.21.0-
>tensorboard~=2.5->tensorflow) (3.2)
Requirement already satisfied: oauthlib>=3.0.0 in ./venv/lib/python3.8/site-packages (from requests-
oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)
Created temporary directory: /tmp/pip-unpack-kcbizxz6
Removed build tracker: '/tmp/pip-req-tracker-5wc69qjc'
2021-07-21 11:16:29.094300: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully 
opened dynamic library libcudart.so.11.0
(venv)  @hp430:~/my_tensorflow$
"
50873,MLIR tests fail to build with non-system gcc and later glibc,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RTHEL 8.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 10.3.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**
Running unit tests //tensorflow/core/kernels/... fails to build on a system with a later gcc and glibc as LD_LIBRARY_PATH is ignored so incorrect glibc is attempted to be used when executing tf_to_kernel binary.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
$ export PATH=/usr/local/bin:$PATH
$ export LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib
$ bazel test --flaky_test_attempts=3 --test_output=all --cache_test_results=no --remote_http_cache=""""  --remote_cache_proxy="""" --noremote_accept_cached --config=noaws --config=nogcp --config=nonccl --verbose_failures //tensorflow/core/kernels/...


**Any other info / logs**
================================================================================
ERROR: /home/builder/1/tensorflow_build/tensorflow-2.5.0/tensorflow/core/kernels/mlir_generated/BUILD:1071:19: compile tensorflow/core/kernels/mlir_generated/rsqrt_cpu_f64_f64_kernel_generator_kernel.o failed (Exit 1): tf_to_kernel failed: error executing command 
  (cd /home/builder/.cache/bazel/_bazel_builder/d307c59d5864ee3d13b4b70232d700ac/execroot/org_tensorflow && \
  exec env - \
  bazel-out/host/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel '--unroll_factors=4' '--tile_sizes=256' '--arch=' '--input=bazel-out/k8-opt/bin/tensorflow/core/kernels/mlir_generated/rsqrt_cpu_f64_f64.mlir' '--output=bazel-out/k8-opt/bin/tensorflow/core/kernels/mlir_generated/rsqrt_cpu_f64_f64_kernel_generator_kernel.o' '--enable_ftz=False' '--cpu_codegen=True')
Execution platform: @local_execution_config_platform//:platform
bazel-out/host/bin/tensorflow/compiler/mlir/tools/kernel_gen/tf_to_kernel: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.26' not found (required by /home/builder/.cache/bazel/_bazel_builder/d307c59d5864ee3d13b4b70232d700ac/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/compiler/mlir/tools/kernel_gen/../../../../../_solib_k8/_U_S_Stensorflow_Scompiler_Smlir_Stools_Skernel_Ugen_Ctf_Uto_Ukernel___Utensorflow/libtensorflow_framework.so.2)
INFO: Elapsed time: 6.145s, Critical Path: 2.14s
INFO: 10 processes: 4 internal, 6 local.
FAILED: Build did NOT complete successfully
"
50872,Tensorflow estimator returns the same answer,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- OS Platform: Ubuntu 18.04.5 LTS
- TensorFlow installed from pip3
- TensorFlow version (use command below): all versions 2.5+
- Python version: 3.6.9
- CUDA/cuDNN version:  11.2
- GPU model and memory: 3090, 2060

**Describe the current behavior**
I create a tf.keras model, train it and save it with model.save as keras model. After that I transform model to tf estimator with 
`tf.keras.estimator.model_to_estimator`, create input reciever and save estimator with it `estimator.export_saved_model(EXPORT_PATH, serving_input_receiver_fn = serving_fn)`
After that I load this 2 models in my jupyter notebook and send same pictures. From two same models in different formats I get different results. Moreover, model that were saved as estimator returns the same answer on all pictures, but the model in H5 format returns different answers.


**Describe the expected behavior**
Estimator and H5 model return the same answer. Estimator return different answers.

It works with all tested models and datasets (5 models and 3 datasets). I watched answers in tensorboard during training and they are normal. The problem starts when I create estimator. I can't avoid creating estimator because I need it for TF serving."
50871,AttributeError: type object 'IteratorBase' has no attribute 'from_structure',"ｔｅｎｓｏｒｆｌｏｗ　２．５
```

`
import tensorflow as tf

training_dataset = tf.data.Dataset.range(100).map(
    lambda x: x + tf.random.uniform([], -10, 10, tf.int64))
validation_dataset = tf.data.Dataset.range(50)

# A reinitializable iterator is defined by its structure. We could use the
# `output_types` and `output_shapes` properties of either `training_dataset`
# or `validation_dataset` here, because they are compatible.
iterator = tf.data.Iterator.from_structure(training_dataset.output_types,
                                           training_dataset.output_shapes)
next_element = iterator.get_next()

training_init_op = iterator.make_initializer(training_dataset)
validation_init_op = iterator.make_initializer(validation_dataset)

# Run 20 epochs in which the training dataset is traversed, followed by the
# validation dataset.
for _ in range(20):
    # Initialize an iterator over the training dataset.
    sess.run(training_init_op)
    for _ in range(100):
        sess.run(next_element)

    # Initialize an iterator over the validation dataset.
    sess.run(validation_init_op)
    for _ in range(50):
        sess.run(next_element)`
```"
50870,Clarity issues in the mixed-precision execution guide,"## URL(s) with the issue:

In particular this point: https://github.com/tensorflow/docs/blame/master/site/en/guide/mixed_precision.ipynb#L817

## Description of issue (what needs changing):

### Clear description

Given linked summary point:

>   If your model ends in softmax, make sure it is float32. And regardless of what your model ends in, make sure the output is float32.

How do exactly those sentences make sense together?

If ""output"" is a result of an arbitrary calculation then why mention specific softmax at all?
If ""output"" is a variable then it was mentioned before that all variables should be float32, and pointing at the end specifically doesn't make much sense either.

I find this part of the summary very confusing.

As a side note, if there was any reference to explain why despite float16 calculation it still makes sense to store the
output in float32 variables that would also be very useful. I.e., why it helps with numeric precision exactly?. I mean, low-resolution operation presumably results in a low-resolution result, therefore how is it not wasteful to store such result in a higher resolution ""container""? Clearly, it is not wasteful because ""everyone"" does it."
50869,copies data from gpu to cpu,"I learned that the GPU ops' running code is in` /lite/delegates/gpu/cl/api.cc`.The code for Run() is as follows:
```
absl::Status Run() override {
#ifdef CL_DELEGATE_ALLOW_GL
    if (gl_interop_fabric_) {
      RETURN_IF_ERROR(gl_interop_fabric_->Start());
    }
#endif
    for (const auto& input : inputs_) {
      RETURN_IF_ERROR(input->CopyFromExternalObject());
    }

    RETURN_IF_ERROR(RunWithoutExternalBufferCopy());

    bool has_async_copies = false;
    for (const auto& output : outputs_) {
      RETURN_IF_ERROR(output->CopyToExternalObject());
      if (output->def().external_def.object_def.object_type ==
          ObjectType::CPU_MEMORY) {
        has_async_copies = true;
      }ng 
    }
#ifdef CL_DELEGATE_ALLOW_GL
    if (gl_interop_fabric_) {
      RETURN_IF_ERROR(gl_interop_fabric_->Finish());
    }
#endif
    if (has_async_copies) {
      RETURN_IF_ERROR(queue_->WaitForCompletion());
    }
    return absl::OkStatus();
  }
```
I found that the outputs_ has only one element,and the elapsed time of CopyToExternalObject() depends on the number of ops running on the GPU.In other words,the more ops are deployed on GPU,the longer the time will be.
It doesn't make sense.Normally,we only need to copy the last op's data.I wonder why this is the case.
Thanks in advance!"
50860,Prediction depends on Batch size,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: https://colab.research.google.com/drive/1moHCzJlvoc4KXdOFpwQTqBaQLJ9paeHi?usp=sharing
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
-   **TensorFlow version (use command below)**: TF 2.5.1
-   **Python version**: 3.6
-   **GPU model and memory**: NVIDIA 3080 10GB

### Describe the problem

I have trained a model for semantic segmentation in Tensorflow. I want to run the predictions of a set of 64 new images (they are greyscale images, therefore the number of channels is 1). For this, I wrote two methods and compare the results (I initially expected that they would provide the same value):

Method A: Load all the images into a 4D array (NB_IMAGES, ROWS, COLS, 1). I run the prediction in the entire 4D array, i.e., all images at the same time (Batch size=64).

Method B: I run the predictions in each image separately. Each image is loaded as a 4D array of the shape (1, ROWS, COLS, 1). Batch size=1.

After running it in colab and displaying the prediction of the third class for the first image: 

```
Method A:
[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]

Method B
[[0.02932691 0.01693235 0.0095239  ... 0.33940026 0.14944448 0.1266723 ]
 [0.00729698 0.00919143 0.00475383 ... 0.21612257 0.05683496 0.05206718]
 [0.00214194 0.00178528 0.0010777  ... 0.35763222 0.11783648 0.05261206]
 ...
 [0.00742953 0.00188467 0.00282917 ... 0.04309301 0.01660612 0.01606987]
 [0.01856694 0.00265247 0.00360173 ... 0.03587637 0.01677576 0.02269481]
 [0.04196882 0.01845963 0.01436812 ... 0.07170304 0.09968089 0.16050124]]
```

However, as you can see in the colab attached, thre predictions differ greatly. 
I'm really lost about these differences in the predictions, considering that the model is the same, no batch_normalization was used and the data set is also the same. Does anybody know or have any experience regarding the effect of batch size and prediction?

### Source code / logs
https://colab.research.google.com/drive/1moHCzJlvoc4KXdOFpwQTqBaQLJ9paeHi?usp=sharing
"
50859,Bug with optimizer_v2.OptimizerV2.set_weights method ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 None
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux (Ubuntu/Debina)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- NA
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
- Python version: 2.4.1 & 2.4.x
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
11.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
2.4.1

**Describe the current behavior**
I am seeing an issue in setting Adam optimizer weights in Optimizer v2 implementation. Looking at the code here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adam.py#L154-L160, it seems to be able to set the weights the current optimizer must have been initialized and set the right size in terms of array length. If this assertion is correct setting weights `on_train_begin` or prior to the first gradient calculation is a bit too soon to set optimizers weights. 
In earlier versions, this was not a problem, and optimizer set_weights use to work at `on_train_begin`.  
I suspect this is a bug in how slots and weights are internally structured.

Code to reproduce the issue is here: 
https://gist.github.com/suneeta-mall/b6086a6b252075f48936a5f80f040b77
To run try:
```
python debug_optimizer_issue.py
```
& then try again:
```
python debug_optimizer_issue.py --start_epoch 2
```

The first run finishes and the second one, where its suppose to start from epoch 2,  fails with error as:
```
ValueError: You called `set_weights(weights)` on optimizer Adam with a  weight list of length 9, but the optimizer was expecting 0 weights. Provided weights: [120, array([[ 0.0000000e+00,  0.0000000e+00,  0.0...
```

I looked around in Adam V2 code to see if there are any other APIs that can help with creating slots etc but I didn't see any that does not require knowledge of internal implementation details (I think). 

As a crazy thought, I use array extension on actual weights to bypass the bug in set_weights like this:
```
model.optimizer.weights.extend(_ref_model.optimizer.get_weights())
```
This lets past the training regime, but the next model save errors into:
```
AttributeError: 'numpy.int64' object has no attribute 'name'
```

Worth noting, the same problem exists with SGD, which is met with the following related error:
```
ValueError: You called `set_weights(weights)` on optimizer SGD with a  weight list of length 1, but the optimizer was expecting 0 weights. Provided weights: [120]...
```

*Please note*: This code is written for TF2, and will not work as in TF1. Also, in earlier versions of TF 2.1 support for loading h5 weights in distributed scope was not there. In that case, a callback was necessary to set the weights, for more see here https://github.com/tensorflow/tensorflow/issues/30850. 


Also worth noting that, I appreciate that the instead of setting weights, I can just load the model like following:
```
        if args.start_epoch:
            model = load_model(f""model_{args.start_epoch}.h5"")
            # deduced_epoch = int(_ref_model.optimizer.iterations.numpy() // (len(train_images) / args.batch_size))
            # if deduced_epoch != args.start_epoch:
            #     raise ValueError()
            # model.set_weights(_ref_model.get_weights())
            # model.optimizer.set_weights(_ref_model.optimizer.get_weights())
```
and that works fine. But for the use case I have I need to set the weights and optimizer weights explicitly. 

**Describe the expected behavior**
I expect the set_weights to work naturally. 
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50857,Discrepancy between expected and tflite quantization parameters,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `no`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux Ubuntu 20.04`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `N/A`
- TensorFlow installed from (source or binary): `binary (pip package)`
- TensorFlow version (use command below): `2.5.0`
- Python version: `3.8.10`
- Bazel version (if compiling from source): `N/A`
- GCC/Compiler version (if compiling from source): `N/A`
- CUDA/cuDNN version: `N/A`
- GPU model and memory: `N/A  (using CPU)`

**Describe the current behavior**
Hi there! :wave: Thank's for the great work on Tensorflow, TFLite!

Unfortunately, I’m facing an issue where there seems to be a discrepancy between the quantization parameters recorded by a fully-quantized tflite model.

For an input `x` and kernel `w`, I manually compute `tf.matmul(x, w)` and then compute the scale/zero-point of the result.  These are the values I get:
```
Parameters from manual computation
Scale: 0.09185781291886871, Zero-point: -3.0351044277537085
````
but when I build the equivalent model in tflite, these are the scale/zp it calculates:
```
Parameters from tflite model
Scale: 0.09184519201517105, Zero-point: -3
```
I would expect them to be the same, but they are not. [Here is an example to reproduce the issue](https://colab.research.google.com/drive/1QjwtcNIBb-lqtuMod6tV233D4UFvQ0dS?usp=sharing).

This discrepancy is causing larger TFLite models to produce significantly different outputs than expected, when compounded across multiple layers. [Here is a demonstration of how these errors compound with more layers](https://colab.research.google.com/drive/1PJjr6EOGJXZ0dvaoGKSJaFzA4pIiv9xe?usp=sharing). 

**Describe the expected behavior**
I would expect the quantization parameters to be the same.

**[Contributing](https://www.tensorflow.org/community/contribute)**
- Do you want to contribute a PR? (yes/no): `no`
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**

[Link to Colab example](https://colab.research.google.com/drive/1QjwtcNIBb-lqtuMod6tV233D4UFvQ0dS?usp=sharing )
The model is 1 Flatten layer + 4 simple `Dense` layers with `use_bias=False`, on the `MNIST` dataset.

**Other info / logs** Include any logs or source code that would be helpful to diagnose the problem.

A visualization of the tflite model using `python -m tensorflow.lite.tools.visualize` and netron are attached.

![gist](https://user-images.githubusercontent.com/70828198/126397792-54a3f092-de97-41a0-9fdc-f4b9c2af563e.png)
![gist_netron](https://user-images.githubusercontent.com/70828198/126397793-c4b93dda-4aa2-4044-81d0-9b5912187f2c.png)"
50856,bug,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50854,Gradient not working with tf.math.angle,"I tried to create my own loss function that uses `tf.math.angle` in it. However, when I use this custom loss I get `None` gradients.
I created a minimum working example (link [here](https://colab.research.google.com/drive/1SkomH1STPtHX6GfB8RBDRuu-pK5VkTyk?usp=sharing)).

The expected behavior for this example would be the gradient to be zero as the loss is zero so there is no minimizing it.
Another note is that the loss would be zero for every real number which is what we are going to have using Tensorflow.

My motivation is because I work with complex numbers as you can see [here](https://github.com/NEGU93/cvnn). So this loss function will make sense on the complex domain as not every tensor will have the same angle.
This issue is related to [this](https://github.com/NEGU93/cvnn/issues/12).

"
50853,Crash/Force termination in distributed training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.9
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.6
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 10.2.0
- CUDA/cuDNN version: 11.1.1
- GPU model and memory: A100

**Describe the current behavior**

When running the distributed training, i.e. with MultiWorkerMirroredStrategy, the application runs through and then crashes with ""terminate called without an active exception""

**Standalone code to reproduce the issue**

Taken from #50790: 

```
import tensorflow as tf
from mpi_cluster_resolver import MPIClusterResolver

resolver = MPIClusterResolver()
strategy = tf.distribute.MultiWorkerMirroredStrategy(cluster_resolver=resolver)

with strategy.scope():
    (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()
    x_train = x_train / 255.0
    train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(128)

    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(10),
    ])

    model.compile(
        optimizer=tf.keras.optimizers.SGD(),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        metrics=['accuracy'])

is_master = resolver.task_id == 0
verbose = 2 if is_master else 0
model.fit(train_data.repeat(), epochs=1, steps_per_epoch=10, verbose=verbose)
```

With 
[mpi_cluster_resolver.py.txt](https://github.com/tensorflow/tensorflow/files/6823734/mpi_cluster_resolver.py.txt)

**Other info / logs**
I traced the crash to `TF_DeleteGraph` Python wrapper by following the stacktrace and inserting debug information: 
[tf.txt](https://github.com/tensorflow/tensorflow/files/6848724/tf.txt)

As you can see the code is called during runtime shutdown and ultimately reaches pybind11s `~gil_scoped_release` which calls `PyEval_RestoreThread`. This is documented as terminating when the runtime is finalized: https://docs.python.org/3/c-api/init.html#c.PyEval_RestoreThread

So to fix this either all threads created by TF must be collected and freed before python starts finalizing or the `pybind11::gil_scoped_release` must be removed from cleanup functions
See also https://github.com/pybind/pybind11/pull/2657"
50850,GazeML upgrade problem TF 1.4.0 to TF 2.5 (tf.contrib.layers.batch_norm),"ubnutu 20.04
Tensorflow 2.5

This is an open source GazeML from github. I am trying to modify this code to tensorflow 2.5 but have some problem in GazeML/src/models/elg.py 

  def _apply_bn(self, tensor):
        return tf.contrib.layers.batch_norm(
            tensor,
            scale=True,
            center=True,
            is_training=self.use_batch_statistics,
            trainable=True,
            data_format=self._data_format,
            updates_collections=None,
        )

AttributeError: module 'tensorflow.compat.v1' has no attribute 'contrib'

i tried 
def _apply_bn(self, tensor):
        return tf.keras.layers.LayerNormalization(
            tensor,
            scale=True,
            center=True,
            is_training=self.use_batch_statistics,
            trainable=True,
            data_format=self._data_format,
            updates_collections=None,
        )

 File ""/home/user/GazeML/src/models/elg.py"", line 178, in _apply_bn
    return tf.keras.layers.LayerNormalization( #tf.contrib.layers.batch_norm(
  File ""/home/user/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/normalization.py"", line 1119, in __init__
    super(LayerNormalization, self).__init__(**kwargs)
  File ""/home/user/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py"", line 522, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/user/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py"", line 159, in __init__
    generic_utils.validate_kwargs(kwargs, allowed_kwargs)
  File ""/home/user/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 1137, in validate_kwargs
    raise TypeError(error_message, kwarg)
TypeError: ('Keyword argument not understood:', 'is_training')
Exception ignored in: <function BaseModel.__del__ at 0x7f3a09e553a0>
Traceback (most recent call last):
  File ""/home/user/GazeML/src/core/model.py"", line 110, in __del__
  File ""/home/user/GazeML/src/core/data_source.py"", line 157, in cleanup
  File ""/home/user/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py"", line 967, in run
  File ""/home/user/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py"", line 1114, in _run
RuntimeError: Attempted to use a closed Session.

How do I modify this code?
Thank you guys!
"
50845,"InvalidArgumentError:  indices[0,2] = 2188 is not in [0, 2027)","Hi when I run the evaluation I get this error message, which I can't identify what is the issue.

***** train
WARNING:tensorflow:Model was constructed with shape (None, 5) for input KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=""created by layer 'embedding_input'""), but it was called on an input with incompatible shape (None, 10).
src=[déplacezvous sil vous plaît], target=[please move], predicted=[im relax]
src=[attrapezle], target=[grab him], predicted=[im me]
src=[tu peux y arriver], target=[you can do it], predicted=[in objected]
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-15-840ecd362078> in <module>()
     83 # test on some training sequences
     84 print('***** train')
---> 85 evaluate_model(model, eng_tokenizer, trainX, train)
     86 
     87 # test on some test sequences

8 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError:  indices[0,2] = 2188 is not in [0, 2027)
	 [[node sequential/embedding/embedding_lookup (defined at <ipython-input-15-840ecd362078>:32) ]] [Op:__inference_predict_function_24327]

Errors may have originated from an input operation.
Input Source operations connected to node sequential/embedding/embedding_lookup:
 sequential/embedding/embedding_lookup/23436 (defined at /usr/lib/python3.7/contextlib.py:112)

Function call stack:
predict_function
SEARCH STACK OVERFLOW"
50843,`case` and `cond` executes all the functions within,"Hi, I'm trying to execute some condition-dependent functions where each function needs to contract tensors differently depending on their shapes, for instance. However, I realised that `tf.cond` and `tf.case` are executing all functions regardless of the condition. Prepared the following code as an example;

```python
x = tf.ones((3,2,1))
y = tf.ones((1,2,3))
z = tf.ones((4,3,5))
k = tf.ones((3,5,5))

def a(t): 
    def exe():
        return tf.einsum(""ijk,lmi"", t, y)
    return exe

def b(t): 
    def exe():
        return tf.einsum(""ijk,ljm"", t, z)
    return exe

def d(t): 
    def exe():
        return tf.einsum(""ijk,klm"", t, z)
    return exe

c = tf.constant(1)

@tf.function
def f(t):
    y = tf.case([
        (tf.equal(tf.shape(t)[0], 3), a(t)),
        (tf.equal(tf.shape(t)[1], 3), b(t)),
    ], default=d, exclusive=True)
    return y

print(f(x))
```
When this code is executed without the decorator, I get the correct answer but with the decorator, all the conditions are executed. Hence in my particular case, since I'm doing different calculations depending on the tensor's shape, I get a multitude of errors. I've seen many such bug reports but haven't found a solution. Is there another way to do conditional execution that I'm not aware of where different functions can be executed depending on the condition?

Thanks

**System information**
- OS Platform and Distribution: MacOS 11.4
- TensorFlow installed from: PyPI
- TensorFlow version: 2.4.1
- TensorFlow Git version : v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.8.2"
50842,tensorflow does not recognize gpu,"**System information**
- OS Platform and Distribution : Linux Ubuntu 20.04.2 LTS
- TensorFlow version: tensorflow-gpu 2.5.0
- Python version: Python 3.8
- Installed using virtualenv? pip? conda?:  pycharm venv
- GPU model and memory: Nvidia TU102[TITANRTX]
- CUDA/cuDNN version: CUDA 10.1 / 11.1
![](https://i.imgur.com/KQOzYES.png)
![](https://i.imgur.com/DamemJ7.png)

**Describe the problem**
I ran my deep reinforcement learning code(tensorflow model) on CPU and the code worked.The output is below:
```
2021-07-18 15:40:19.039476: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-18 15:40:20.551477: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-07-18 15:40:20.584382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2021-07-18 15:40:20.584422: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-18 15:40:20.587696: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-07-18 15:40:20.587764: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-07-18 15:40:20.588983: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-07-18 15:40:20.589327: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-07-18 15:40:20.589548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64
2021-07-18 15:40:20.590170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-07-18 15:40:20.590293: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-07-18 15:40:20.590310: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2021-07-18 15:40:20.590571: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-18 15:40:20.591825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-07-18 15:40:20.591846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      
/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
 
```
But it required so much memory(nearly 100%).According to my cudnn and cuda version. I installed ```tensorflow-gpu 2.5.0```. 
I checked and ensured I had the lastest tensorflow gpu release installed.The command and output is below:
- command
```
import tensorflow as tf
print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU')))
```
- output
```
2021-07-18 15:46:34.898115: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-18 15:46:35.945751: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-07-18 15:46:35.975290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: TITAN RTX computeCapability: 7.5
coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s
2021-07-18 15:46:35.975330: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-18 15:46:35.978463: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-07-18 15:46:35.978520: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-07-18 15:46:35.979857: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-07-18 15:46:35.980175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-07-18 15:46:35.980391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64
2021-07-18 15:46:35.981033: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-07-18 15:46:35.981142: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-07-18 15:46:35.981158: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
Num GPUs Available:  0

```
I tried to install other tensorflow gpu version (2.4.0,2.3.0.....).The error is below:
```
(venv) wayne:~/PycharmProjects/stock_point_$ python train.py ^GSPC 10 1000
2021-07-18 15:50:49.752192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
Traceback (most recent call last):
  File ""train.py"", line 1, in <module>
    from agent.agent import Agent
  File ""/home/wayne/PycharmProjects/stock_point_/agent/agent.py"", line 1, in <module>
    import keras
  File ""/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/keras/__init__.py"", line 25, in <module>
    from keras import models
  File ""/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/keras/models.py"", line 19, in <module>
    from keras import backend
  File ""/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/keras/backend.py"", line 37, in <module>
    from tensorflow.python.eager.context import get_config
ImportError: cannot import name 'get_config' from 'tensorflow.python.eager.context' (/home/wayne/PycharmProjects/stock_point_/venv/lib/python3.8/site-packages/tensorflow/python/eager/context.py)

```

Could you help me solve this problem.Thanks in advance.
"
50841,tensorflow-serving-apt signature key expired,"### System information
- OS Platform and Distribution: Ubuntu 1804, Windows - Dockerfile, Google Cloud Build (Dockerfile)
- TensorFlow installed from (source or binary): apt

### Problem
tensorflow serving apt key is expired
[https://www.tensorflow.org/tfx/serving/setup#installation_2](https://www.tensorflow.org/tfx/serving/setup#installation_2)

**Command to run**
```bash
echo ""deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal"" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \
curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -
```

**Error**
GPG error: http://storage.googleapis.com/tensorflow-serving-apt stable InRelease: The following signatures were invalid: KEYEXPIRED...
"
50840,tensorflow.python.data.ops.dataset_ops.BatchDataset to HDF5,"Hello,
I need to load large image datasets (JPEG and other types) with tensorflow and then transform them to HDF5, I have loaded the dataset with the following code, but I don't know how to transform it to HDF5.**


img = tf.keras.preprocessing.image_dataset_from_directory(
    '/home/tiny-imagenet-200/train/',
    labels=""inferred"",
    label_mode=""int"",
    class_names=None,
    color_mode=""rgb"",
    batch_size=32,
    image_size=(256, 256),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation=""bilinear"",
    follow_links=False,
)

I tried to do it like it did in python, but it doesn't work:

for i in range(len(img)):
    Imagen = cv2.imread(img)
    Imagen = cv2.resize(Imagen, (224, 224), interpolation=cv2.INTER_CUBIC)
    Imagen = cv2.cvtColor(Imagen, cv2.COLOR_BGR2RGB)
*****************
The error:


typeError                                 Traceback (most recent call last)
<ipython-input-18-94fcf3e072ce> in <module>
 
---> 10     Imagen = cv2.imread(img)
     11     Imagen = cv2.resize(Imagen, (224, 224), interpolation=cv2.INTER_CUBIC)
     12     Imagen = cv2.cvtColor(Imagen, cv2.COLOR_BGR2RGB)

TypeError: Can't convert object of type 'tensorflow.python.framework.ops.EagerTensor' to 'str' for 'filename'

I guess it is because of the type of object it generates that it is: tensorflow.python.data.ops.dataset_ops.BatchDataset

Please I would appreciate if someone can help me to know how to transform this to HDF5. Thank you.

"
50838,TFLite convertion bug: NumDimensions(input) != 4 (3 != 4)Node number 0 (RESIZE_BILINEAR) failed to prepare.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.2
- Python version: 3.6.9

**Describe the current behavior**
I am trying to quantize the `tf.image.resize()` function to TFLite but the following error is raised:
```
RuntimeError: tensorflow/lite/kernels/resize_bilinear.cc:73 NumDimensions(input) != 4 (3 != 4)Node number 0 (RESIZE_BILINEAR) failed to prepare.
```

**Standalone code to reproduce the issue**
The code below leads to the error:
```
import tensorflow as tf

print(tf.version.VERSION)
inputs = tf.keras.Input(shape=(720, 1280, 3), batch_size=1)
outputs = tf.image.resize(inputs, (360, 640))
model = tf.keras.Model(inputs=inputs, outputs=outputs)
model.summary()


def representative_dataset_generator():
    for _ in range(20):
        image = tf.random.uniform(shape=(1, 720, 1280, 3), dtype=tf.float32)
        yield image


converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.representative_dataset = representative_dataset_generator
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.target_spec.supported_types = [tf.int8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model = converter.convert()
```
With TF 2.5.0, the error changes and becomes: 
```
ValueError: The inference_input_type and inference_output_type must be tf.float32.
```
as shown in [this google colab](https://colab.research.google.com/drive/14rgat_c4d4TWaF7Vmp7MnPczYbmDhv6R?usp=sharing). This is also a problem because I want to do full-integer quantization.

Since this operation has its [TFLite equivalent](https://tensorflow.google.cn/mlir/tfl_ops#tflresize_bilinear_tflresizebilinearop), I expect to be able to quantize it without a problem. 
Looking forward to hearing from you.
"
50837,'utf-8' codec can't decode byte 0xc1 in position 103: invalid start byte,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Geforce 3090

**Describe the current behavior**
 when loading pipeline.config, it cause error. 
config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)
even I installed tensorflow nightly version. but it is same. 

error is
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 103: invalid start byte


full log error is
UnicodeDecodeError                        Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_16452/1215164193.py in <module>
      1 print(""s"")
----> 2 config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)

c:\users\pedro\anaconda3\envs\tensorflow1\lib\site-packages\object_detection\utils\config_util.py in get_configs_from_pipeline_file(pipeline_config_path, config_override)
    138 
    139     print(""protto"")
--> 140     proto_str = f.read()
    141     print(proto_str)
    142     print(""proto"")

c:\users\pedro\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\lib\io\file_io.py in read(self, n)
    117       string if in string (regular) mode.
    118     """"""
--> 119     self._preread_check()
    120     if n == -1:
    121       length = self.size() - self.tell()

c:\users\pedro\anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\lib\io\file_io.py in _preread_check(self)
     80       print(self.__name)
     81       self._read_buf = _pywrap_file_io.BufferedInputStream(
---> 82           compat.path_to_str(self.__name), 1024 * 512)
     83 
     84   def _prewrite_check(self):

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 103: invalid start byte

"
50835,There should be No expansion ReLU on MobileNet v2 bottleneck,"I argue that this line should be removed:

https://github.com/tensorflow/tensorflow/blob/a4d25192f0340b7786760d57e6b5859e561d9b49/tensorflow/python/keras/applications/mobilenet_v2.py#L450

The code seems wrong vs. the [MobileNet v2 paper](https://arxiv.org/pdf/1801.04381.pdf), **which this code is supposed to faithfully implement**, for the following reasons:

The paper uses all of Figure 1 (read the caption), part D of Figure 2 (also read the caption), and part B of Figure 3 (also read the caption and check the parts that are annotated ReLU vs. those that aren't), as well as well as the last two paragraphs of Section 3.2 ""Linear Bottlenecks"" to argue _against_ having ReLU on the bottlenecks. One can specifically see that the _expansion_ layer in part D of Figure 2 is shown without ReLU, and the same setup is shown with part B of Figure 3, all of which matches perfectly with the description given in the last two paragraphs of the section.

Currently, it is like the entire point of a central section of the paper was missed or ignored."
50833,tensorflow estimator how to export sub-graph,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 19.04
- TensorFlow version (use command below): 1.14.1
- Python version: 3.7

```
        self.features = self._build_input_placeholder_for_serving(features)
        imei_embedding, user_inputs, item_inputs_a, item_inputs_b = self._build_input(self.features)
        self.labels = self.get_labels(labels)
        meta_embedding, meta_embedding_variables = self.build_meta_embedding_generator(imei_embedding, user_inputs)
        self.logits_a = self.build_graph([meta_embedding, user_inputs, item_inputs_a])
        self.cold_loss_a = self.cross_entropy_loss(self.labels['label_a'], self.logits_a)
        self.predictions = self.get_prediction(self.logits_a)
        cold_embedding_grads = tf.gradients(self.cold_loss_a, meta_embedding)[0]
        new_meta_embedding = meta_embedding - self.learning_rate_cold * cold_embedding_grads
        self.logits_b = self.build_graph([new_meta_embedding, user_inputs, item_inputs_b])
        self.cold_loss_b = self.cross_entropy_loss(self.labels['label_b'], self.logits_b)
        self.loss = self.cold_loss_a * self.alpha + self.cold_loss_b * (1 - self.alpha)
```
when i want to export the model, the error occurs:
```
  File ""/usr/local/lib/python3.6/dist-packages/apts/run_loop/run.py"", line 56, in run
    self.run_loop.run()
  File ""/usr/local/lib/python3.6/dist-packages/apts/run_loop/base_run_loop.py"", line 594, in run
    self.run_loop()
  File ""/usr/local/lib/python3.6/dist-packages/apts/run_loop/base_run_loop.py"", line 245, in run_loop
    self._export_and_upload_saved_model()
  File ""/usr/local/lib/python3.6/dist-packages/apts/run_loop/base_run_loop.py"", line 502, in _export_and_upload_saved_model
    export_path=os.path.join(self.model_dir, 'saved_model'))
  File ""/root/workspace/meta_embedding/utils/run_loop.py"", line 140, in export_and_upload_saved_model
    checkpoint_path=checkpoint_path)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 732, in export_saved_model
    strip_default_attrs=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 856, in _export_all_saved_models
    strip_default_attrs=strip_default_attrs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 929, in _add_meta_graph_for_mode
    config=self.config)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1146, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File ""/root/workspace/meta_embedding/model/meta_embedding_meta_generator.py"", line 51, in model_fn
    self.labels = self.get_labels(labels)
  File ""/root/workspace/meta_embedding/model/meta_embedding_meta_generator.py"", line 340, in get_labels
    _labels['label_a'] = labels[list(self.feature_config['label_name'])[0]]
TypeError: 'NoneType' object is not subscriptable

```
I guess it's because I compute the gradient with **loss_a** and then update **meta_embedding**. I only want to export the graph of **loss_a**. Are there any feasible solutions?"
50832,"tf.function runs correctly in eager mode, but breaks in graph mode","
### System information

= check python ===================================================
python version: 3.8.10
python branch: 
python build version: ('default', 'Jun  2 2021 10:49:15')
python compiler version: GCC 9.4.0
python implementation: CPython


== check os platform ===============================================

== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Copyright (C) 2019 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                         1.19.5
protobuf                      3.17.3
tensorflow                    2.5.0+nv
tensorflow-addons             0.13.1
tensorflow-datasets           3.2.1
tensorflow-dot-based-interact 0.0.1
tensorflow-estimator          2.5.0
tensorflow-metadata           1.1.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.5.0
tf.version.GIT_VERSION = unknown
tf.version.COMPILER_VERSION = 9.3.0

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/compat/lib.real:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
DYLD_LIBRARY_PATH is unset

== cuda libs  ===================================================
/usr/local/cuda-11.4/targets/x86_64-linux/lib/libcudart.so.11.4.43
/usr/local/cuda-11.4/targets/x86_64-linux/lib/libcudart_static.a

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.5.0+nv
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /usr/local/lib/python3.8/dist-packages
Required-by: tensorflow-dot-based-interact, nvtx-plugins

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 8, 10, 'final', 0)

== bazel version  ===============================================
Build label: 3.7.2
Build time: Thu Dec 17 16:57:23 2020 (1608224243)
Build timestamp: 1608224243
Build timestamp as int: 1608224243


### Describe the problem

When doing perf analysis of Tensorflow2 models, we want to breakdown the training flow into separate phases: forward, loss, backward, weight_update etc. The main idea to do the time breakdown is to run the flow in overall eager mode, but each phase is wrapped in tf.function API, so to run the phase in graph mode. We have an issue that a tf.function can run correctly under eager mode, but breaks in graph mode. 

I created a minimum tests to reproduce the issue pasted below.

in the direct test, we want to run optimizer.minimize in graph mode by wrapping with tf.function, when running the tf.function in eager mode throught setting tf.config.experimental_run_functions_eagerly(True), it works. 

But fails with if running the graph mode with below error: 

Traceback (most recent call last):
  File ""direct_test.py"", line 119, in <module>
    dummy_model.fit(dummy_data_generator,steps_per_epoch = 100)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py"", line 1183, in fit
    tmp_logs = self.train_function(iterator)
  File ""direct_test.py"", line 59, in train_function
    return step_function(self, iterator)
  File ""direct_test.py"", line 49, in step_function
    outputs = model.distribute_strategy.run(run_step, args=(data,))
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 1285, in run
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 2833, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py"", line 3608, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py"", line 597, in wrapper
    return func(*args, **kwargs)
  File ""direct_test.py"", line 41, in run_step
    outputs = model.train_step(data)
  File ""direct_test.py"", line 88, in train_step
    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 889, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 933, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 763, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 3050, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 3279, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py"", line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py"", line 986, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:530 minimize  *
        return self.apply_gradients(grads_and_vars, name=name)
    /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:630 apply_gradients  **
        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)
    /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/optimizer_v2/utils.py:75 filter_empty_gradients
        raise ValueError(""No gradients provided for any variable: %s."" %

    ValueError: No gradients provided for any variable: ['training_model/dense/kernel:0', 'training_model/dense/bias:0'].

2021-07-15 03:29:43.999375: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
         [[{{node PyFunc}}]]

### Source code / logs

[direct_test.txt](https://github.com/tensorflow/tensorflow/files/6838642/direct_test.txt)

"
50829,Error while building tensorflow from source.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), wuie only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Mac Os Big sur
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):Source
- TensorFlow version: r2.4 
- Python version:3.9
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):3.1.0
- GCC/Compiler version (if compiling from source):4.2.1
- CUDA/cuDNN version:NA
- GPU model and memory:NA



**Describe the problem**

i am following the steps from this link : https://www.tensorflow.org/install/source#macos_1, i am getting an error in the last step, where we install tensorflow wheel file generated through pip.

**Any other info / logs**

Building wheels for collected packages: grpcio, wrapt, termcolor, h5py
  Building wheel for grpcio (setup.py) ... /^[[error
  ERROR: Command errored out with exit status 1:
   command: /usr/local/opt/python@3.9/bin/python3.9 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'""'""'; __file__='""'""'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-wheel-x721u2p1
       cwd: /private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/
  Complete output (1640 lines):
  Found cython-generated files...
  running bdist_wheel
  running build
  running build_py
  running build_project_metadata
  creating python_build
  creating python_build/lib.macosx-10.14-x86_64-3.9
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_compression.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_channel.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_common.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_simple_stubs.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_plugin_wrapping.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_interceptor.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_grpcio_metadata.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_server.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_runtime_protos.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  copying src/python/grpcio/grpc/_auth.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/_server_adaptations.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/interfaces.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/_metadata.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/implementations.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  copying src/python/grpcio/grpc/beta/_client_adaptations.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/beta
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental
  copying src/python/grpcio/grpc/experimental/gevent.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental
  copying src/python/grpcio/grpc/experimental/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental
  copying src/python/grpcio/grpc/experimental/session_cache.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework
  copying src/python/grpcio/grpc/framework/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_base_server.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_metadata.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_typing.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_call.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_channel.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_base_channel.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_interceptor.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_server.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_base_call.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  copying src/python/grpcio/grpc/aio/_utils.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/aio
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython
  copying src/python/grpcio/grpc/_cython/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental/aio
  copying src/python/grpcio/grpc/experimental/aio/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/experimental/aio
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/callable_util.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/abandonment.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/stream.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/stream_util.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/future.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  copying src/python/grpcio/grpc/framework/foundation/logging_pool.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/foundation
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common
  copying src/python/grpcio/grpc/framework/common/style.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common
  copying src/python/grpcio/grpc/framework/common/cardinality.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common
  copying src/python/grpcio/grpc/framework/common/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/common
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces
  copying src/python/grpcio/grpc/framework/interfaces/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face
  copying src/python/grpcio/grpc/framework/interfaces/face/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face
  copying src/python/grpcio/grpc/framework/interfaces/face/utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face
  copying src/python/grpcio/grpc/framework/interfaces/face/face.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/face
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base
  copying src/python/grpcio/grpc/framework/interfaces/base/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base
  copying src/python/grpcio/grpc/framework/interfaces/base/utilities.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base
  copying src/python/grpcio/grpc/framework/interfaces/base/base.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/framework/interfaces/base
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_cygrpc
  copying src/python/grpcio/grpc/_cython/_cygrpc/__init__.py -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_cygrpc
  creating python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_credentials
  copying src/python/grpcio/grpc/_cython/_credentials/roots.pem -> python_build/lib.macosx-10.14-x86_64-3.9/grpc/_cython/_credentials
  running build_ext
  Found cython-generated files...
  building 'grpc._cython.cygrpc' extension
  creating python_build/temp.macosx-10.14-x86_64-3.9
  creating python_build/temp.macosx-10.14-x86_64-3.9/src
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/census
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/health
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/grpclb
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/pick_first
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/priority
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/round_robin
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/weighted_target
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/lb_policy/xds
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/dns
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/dns/c_ares
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/dns/native
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/fake
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/sockaddr
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_channel/resolver/xds
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/client_idle
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/deadline
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http/client
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http/message_compress
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/http/server
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/max_age
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/message_size
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/workarounds
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/alpn
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/client
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/client/insecure
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/client/secure
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/server
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/server/insecure
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/server/secure
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/chttp2/transport
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/transport/inproc
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/annotations
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/accesslog
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/accesslog/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/cluster
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/cluster/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/core
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/core/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/endpoint
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/endpoint/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/listener
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/listener/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/rbac
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/rbac/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/route
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/route/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/trace
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/config/trace/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters/network
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters/network/http_connection_manager
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/filters/network/http_connection_manager/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/transport_sockets
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/transport_sockets/tls
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/extensions/transport_sockets/tls/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/cluster
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/cluster/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/discovery
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/discovery/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/endpoint
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/endpoint/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/listener
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/listener/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/load_stats
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/load_stats/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/route
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/service/route/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/matcher
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/matcher/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/metadata
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/metadata/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/tracing
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/tracing/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/envoy/type/v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/gogoproto
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/api
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/api/expr
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/api/expr/v1alpha1
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/protobuf
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/google/rpc
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/gcp
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/health
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/health/v1
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/lb
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/src/proto/grpc/lb/v1
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/annotations
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/data
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/data/orca
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/udpa/data/orca/v1
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/upb-generated/validate
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/xds
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/avl
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/backoff
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/channel
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/compression
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/debug
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/gpr
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/gprpp
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/http
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/iomgr
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/iomgr/executor
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/iomgr/poller
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/json
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/profiling
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/authorization
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/context
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/alts
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/composite
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/fake
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/google_default
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/iam
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/jwt
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/local
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/oauth2
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/plugin
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/ssl
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/credentials/tls
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/alts
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/fake
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/local
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/ssl
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/security_connector/tls
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/transport
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/security/util
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/slice
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/surface
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/transport
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/lib/uri
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/plugin_registry
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/crypt
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/frame_protector
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/handshaker
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/alts/zero_copy_frame_protector
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/ssl
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/core/tsi/ssl/session_cache
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python/grpcio
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python/grpcio/grpc
  creating python_build/temp.macosx-10.14-x86_64-3.9/src/python/grpcio/grpc/_cython
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/base
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/base/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/container
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/container/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/debugging
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/debugging/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/hash
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/hash/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/numeric
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/status
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/strings
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/strings/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/strings/internal/str_format
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/synchronization
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/synchronization/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time/internal
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time/internal/cctz
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/time/internal/cctz/src
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/abseil-cpp/absl/types
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/address_sorting
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/chacha
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/cipher_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/fipsmodule
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/mac-x86_64/crypto/test
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/asn1
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/base64
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/bio
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/bn_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/buf
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/bytestring
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/chacha
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/cipher_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/cmac
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/conf
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/curve25519
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/dh
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/digest_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/dsa
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/ec_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/ecdh_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/ecdsa_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/engine
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/err
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/evp
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/fipsmodule
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/hkdf
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/hpke
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/hrss
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/lhash
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/obj
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pem
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pkcs7
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pkcs8
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/poly1305
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/pool
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/rand_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/rc4
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/rsa_extra
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/siphash
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/stack
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/trust_token
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/x509
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/crypto/x509v3
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/boringssl-with-bazel/src/ssl
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/cares
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/cares/cares
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/re2
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/re2/re2
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/re2/util
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/upb
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/upb/upb
  creating python_build/temp.macosx-10.14-x86_64-3.9/third_party/zlib
  clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/System/Library/Frameworks/Tk.framework/Versions/8.5/Headers -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) PyObject* -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_darwin -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/local/include -I/usr/local/opt/openssl@1.1/include -I/usr/local/opt/sqlite/include -I/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/include/python3.9 -c src/core/ext/filters/census/grpc_context.cc -o python_build/temp.macosx-10.14-x86_64-3.9/src/core/ext/filters/census/grpc_context.o -std=c++11 -stdlib=libc++ -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
 
    Traceback (most recent call last):
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py"", line 117, in _compile
        self.spawn(compiler_so + cc_args + [src, '-o', obj] +
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_spawn_patch.py"", line 54, in _commandfile_spawn
        _classic_spawn(self, command)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/ccompiler.py"", line 910, in spawn
        spawn(cmd, dry_run=self.dry_run)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/spawn.py"", line 87, in spawn
        raise DistutilsExecError(
    distutils.errors.DistutilsExecError: command '/usr/bin/clang' failed with exit code 1
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py"", line 264, in build_extensions
        build_ext.build_ext.build_extensions(self)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 449, in build_extensions
        self._build_extensions_serial()
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 474, in _build_extensions_serial
        self.build_extension(ext)
      File ""/usr/local/lib/python3.9/site-packages/setuptools/command/build_ext.py"", line 196, in build_extension
        _build_ext.build_extension(self, ext)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 529, in build_extension
        objects = self.compiler.compile(sources,
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py"", line 58, in _parallel_compile
        multiprocessing.pool.ThreadPool(BUILD_EXT_COMPILER_JOBS).map(
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 364, in map
        return self._map_async(func, iterable, mapstar, chunksize).get()
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 771, in get
        raise self._value
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 125, in worker
        result = (True, func(*args, **kwds))
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 48, in mapstar
        return list(map(*args))
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py"", line 54, in _compile_single_file
        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py"", line 247, in new_compile
        return old_compile(obj, src, ext, cc_args, extra_postargs,
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py"", line 120, in _compile
        raise CompileError(msg)
    distutils.errors.CompileError: command '/usr/bin/clang' failed with exit code 1
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py"", line 448, in <module>
        setuptools.setup(
      File ""/usr/local/lib/python3.9/site-packages/setuptools/__init__.py"", line 153, in setup
        return distutils.core.setup(**attrs)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/core.py"", line 148, in setup
        dist.run_commands()
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py"", line 966, in run_commands
        self.run_command(cmd)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""/usr/local/lib/python3.9/site-packages/setuptools/command/install.py"", line 61, in run
        return orig.install.run(self)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/install.py"", line 546, in run
        self.run_command('build')
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/cmd.py"", line 313, in run_command
        self.distribution.run_command(command)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build.py"", line 135, in run
        self.run_command(cmd_name)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/cmd.py"", line 313, in run_command
        self.distribution.run_command(command)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/dist.py"", line 985, in run_command
        cmd_obj.run()
      File ""/usr/local/lib/python3.9/site-packages/setuptools/command/build_ext.py"", line 79, in run
        _build_ext.run(self)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 340, in run
        self.build_extensions()
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py"", line 268, in build_extensions
        raise CommandError(
    commands.CommandError: Failed `build_ext` step:
    Traceback (most recent call last):
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py"", line 117, in _compile
        self.spawn(compiler_so + cc_args + [src, '-o', obj] +
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_spawn_patch.py"", line 54, in _commandfile_spawn
        _classic_spawn(self, command)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/ccompiler.py"", line 910, in spawn
        spawn(cmd, dry_run=self.dry_run)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/spawn.py"", line 87, in spawn
        raise DistutilsExecError(
    distutils.errors.DistutilsExecError: command '/usr/bin/clang' failed with exit code 1
    
    During handling of the above exception, another exception occurred:
    
    Traceback (most recent call last):
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py"", line 264, in build_extensions
        build_ext.build_ext.build_extensions(self)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 449, in build_extensions
        self._build_extensions_serial()
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 474, in _build_extensions_serial
        self.build_extension(ext)
      File ""/usr/local/lib/python3.9/site-packages/setuptools/command/build_ext.py"", line 196, in build_extension
        _build_ext.build_extension(self, ext)
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/command/build_ext.py"", line 529, in build_extension
        objects = self.compiler.compile(sources,
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py"", line 58, in _parallel_compile
        multiprocessing.pool.ThreadPool(BUILD_EXT_COMPILER_JOBS).map(
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 364, in map
        return self._map_async(func, iterable, mapstar, chunksize).get()
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 771, in get
        raise self._value
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 125, in worker
        result = (True, func(*args, **kwds))
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/pool.py"", line 48, in mapstar
        return list(map(*args))
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/_parallel_compile_patch.py"", line 54, in _compile_single_file
        self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)
      File ""/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/src/python/grpcio/commands.py"", line 247, in new_compile
        return old_compile(obj, src, ext, cc_args, extra_postargs,
      File ""/usr/local/Cellar/python@3.9/3.9.0_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/distutils/unixccompiler.py"", line 120, in _compile
        raise CompileError(msg)
    distutils.errors.CompileError: command '/usr/bin/clang' failed with exit code 1
    
    ----------------------------------------
ERROR: Command errored out with exit status 1: /usr/local/opt/python@3.9/bin/python3.9 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'""'""'; __file__='""'""'/private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-install-gyz06eak/grpcio/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/5j/s9cvd7452bdfcrmdpmkwtnh00000gn/T/pip-record-j6oeuxp5/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.9/grpcio Check the logs for full command output.


Please refer to the following file for the detailed logs 
[tf_build_from_source_logs.txt](https://github.com/tensorflow/tensorflow/files/6838193/tf_build_from_source_logs.txt)



"
50828,binary_crossentropy() usage example is misleading,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.5/api_docs/python/tf/keras/losses/binary_crossentropy

The same problem occurs across many versions and aliases of this function.

## Description of issue (what needs changing):
The ""standalone usage"" example appears to be misleading, because it implies that rows and/or columns of the `y_pred` parameter should sum to 1.0. 

As I am new to TensorFlow, I am a little apprehensive about pointing out a potential problem in the documentation and I will be very grateful if an experienced practitioner can confirm whether my suggestion is correct or alternatively if I have misunderstood something. Thank you!

### Usage example

In the usage example given here, the `y_pred` parameter is `[[0.6, 0.4], [0.4, 0.6]]`. Any reader with a background in probability and statistics will immediately assume that these numbers represent normalized probabilities, because the rows and the columns sum to 1.0. Furthermore, because the name of the method is *binary* cross entropy, a reader is likely to assume that the rows or columns of y_pred represent the two possible binary outcomes. In fact, none of these assumptions is correct. The parameter `y_pred` can be any shape (subject to a certain restriction mentioned below). Each entry in `y_pred` has a value that does not depend on the other values in the tensor. Example code demonstrating this is attached.

My feeling is that a better usage example would use numbers that do not sum to 1.0, so that readers will not make the mistaken assumption that they represent normalized probabilities. In addition, the usage example could be further improved by breaking the symmetry of the 2x2 example, and avoiding using two rows or two columns so that it is clear the ""binary"" nature of the cross entropy has nothing to do with the number of rows and columns here. The smallest example conveying all of these ideas would probably be 4x3, as in the attached code.

Technical note: There is a possibility of confusion when we say that the parameter does not represent normalized probabilities. This is certainly true when the parameter `from_logits` is `True`. However, when `from_logits` is `False`, each element in `y_pred` does in fact represent a probability, and as with any other true probability it is a normalized probability. However, it is not normalized with respect to any other elements of the tensor. For example, the value 0.8 represents a prediction that the an instance has an 80% chance of being a positive instance.  This means there is a 20% chance of that same instance being negative, but the value 0.2 does not appear anywhere in the `y_pred` tensor; the 0.2 is implicit in the 0.8.

Details about the shape for `y_pred`: it must have either the same shape as `y_true`, or a shape that is compatible with the shape of `y_true` after broadcasting has been applied to `y_true`.

### Submit a pull request?

I will be happy to prepare and submit a pull request if an experienced contributor can confirm to me that my description of the problem is correct.

Again, I will be grateful if someone can let me know if my suggestions are correct and I do apologize in advance if I misunderstood something.

~~~~
import numpy as np
import tensorflow as tf


def my_sigmoid(x: np.ndarray):
    return 1 / (1 + np.exp(-x))


def safe_log(x: np.ndarray):
    eps = 1e-11
    return np.log(np.maximum(x, eps))


def my_cross_entropy(y: np.ndarray, z: np.ndarray, from_logits=True):
    if from_logits:
        z = my_sigmoid(z)
    return -(y * safe_log(z) + (1 - y) * safe_log((1 - z)))


def tf_cross_entropy(y: np.ndarray, z: np.ndarray, from_logits=True):
    y = tf.constant(y, dtype=tf.float32)
    z = tf.constant(z, dtype=tf.float32)
    return tf.keras.losses.binary_crossentropy(y_true=y, y_pred=z,
                                               from_logits=from_logits)


def compare_cross_entropy(y, z, from_logits=True):
    my_val = my_cross_entropy(y, z, from_logits)
    tf_val = tf_cross_entropy(y, z, from_logits)
    print(f""y {y}\nz {z}\n"")
    print(f""my_val {my_val}\ntf_val {tf_val}\n"")
    print(f""my_val shape {my_val.shape}\ntf_val shape {tf_val.shape}\n"")


##########
# main ###
##########
y_val = np.array([[1, 1, 1],
                  [1, 1, 1],
                  [0, 0, 0],
                  [0, 1, 0], ], dtype=np.float32)

z_val = np.array([[0.4, 0.45, 0.46],
                  [0.9, 0.95, 0.96],
                  [0.0, 0.0, 0.0],
                  [0.7, 0.7, 0.7],
                  ], dtype=np.float32)

print(f'y shape {y_val.shape}, z shape {z_val.shape}')
compare_cross_entropy(y_val, z_val, from_logits=False)
~~~~
"
50827,"""ModuleNotFoundError"", Some times the import of ""tensorflow_addons"" doesn't take place","Some time the import works, some time it doesn't.
    `!pip install --user tensorflow-addons`
    `import tensorflow_addons as tfa`

Output:
Collecting tensorflow-addons
  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)
     |████████████████████████████████| 686kB 4.3MB/s 
Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)
Installing collected packages: tensorflow-addons
Successfully installed tensorflow-addons-0.13.0

---------------------------------------------------------------------------

ModuleNotFoundError                       Traceback (most recent call last)

<ipython-input-29-4c254e4a3ee7> in <module>()
      1 get_ipython().system('pip install --user tensorflow-addons')
----> 2 import tensorflow_addons as tfa

ModuleNotFoundError: No module named 'tensorflow_addons'
-------------------------------------------------------------------------------------------------------------------------------
What to do?
"
50826,Cross-compilation error by Bazel in pip_package of TensorFlow Lite in r2.6 or v2.6.0-rc1 (armhf/aarch64),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 (HostPC), Ubuntu 16.04 (Docker)
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.6, v2.6.0-rc1
- Python version: 3.7 (Docker)
- Bazel version (if compiling from source): 3.7.2 (Docker)

**Describe the problem**
Abort by building the pip_package of TensorFlow Lite with Bazel using the same procedure as for the r2.5 or v2.5.0 branch. The same problem occurs in both r2.6 and the latest release v2.6.0-rc1 as of today. If I check out r2.5 or v2.5.0, the same command will successfully build it.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I referred to the procedure using Bazel below.
https://github.com/tensorflow/tensorflow/tree/v2.6.0-rc1/tensorflow/lite/tools/pip_package#cross-build-with-flex-for-armhf-python-37
```bash
$ git clone -b r2.6 https://github.com/tensorflow/tensorflow.git
$ cd tensorflow
```
- aarch64
```bash
$ sudo CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3.7 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7"" \
  tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
  tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh aarch64

 :
 :
SUBCOMMAND: # //tensorflow/lite/schema:schema_fbs_srcs [action 'Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs', configuration: d6b574c9b84611aa340a96e749e5599cae8f6d55e0af10df15724f62bdc6068b, execution platform: @local_execution_config_platform//:platform]
(cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/aarch64-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/aarch64-opt/bin/tensorflow/lite/schema $f; done')
ERROR: /workspace/tensorflow/lite/schema/BUILD:96:22: Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs failed (Exit 126): bash failed: error executing command 
  (cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/aarch64-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/aarch64-opt/bin/tensorflow/lite/schema $f; done')
Execution platform: @local_execution_config_platform//:platform
/bin/bash: bazel-out/aarch64-opt/bin/external/flatbuffers/flatc: cannot execute binary file: Exec format error
Target //tensorflow/lite/python/interpreter_wrapper:_pywrap_tensorflow_interpreter_wrapper failed to build
INFO: Elapsed time: 57.367s, Critical Path: 8.89s
INFO: 410 processes: 178 internal, 232 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```
- armhf
```bash
$ sudo CI_DOCKER_EXTRA_PARAMS=""-e CI_BUILD_PYTHON=python3.7 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7"" \
  tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \
  tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf

SUBCOMMAND: # //tensorflow/lite/schema:schema_fbs_srcs [action 'Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs', configuration: d2c4f92953c17c21701ba73a2ad97645e41ff9f8c325ec409c23649eb0856f42, execution platform: @local_execution_config_platform//:platform]
(cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/armhf-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/armhf-opt/bin/tensorflow/lite/schema $f; done')
ERROR: /workspace/tensorflow/lite/schema/BUILD:96:22: Generating flatbuffer files for schema_fbs_srcs: //tensorflow/lite/schema:schema_fbs_srcs failed (Exit 126): bash failed: error executing command 
  (cd /home/xxxxx/work/temp/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH='' \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \
    PYTHON_BIN_PATH=/usr/local/bin/python3.7 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for f in tensorflow/lite/schema/schema.fbs; do bazel-out/armhf-opt/bin/external/flatbuffers/flatc --no-union-value-namespacing --gen-object-api  -c -o bazel-out/armhf-opt/bin/tensorflow/lite/schema $f; done')
Execution platform: @local_execution_config_platform//:platform
/bin/bash: bazel-out/armhf-opt/bin/external/flatbuffers/flatc: cannot execute binary file: Exec format error
Target //tensorflow/lite/python/interpreter_wrapper:_pywrap_tensorflow_interpreter_wrapper failed to build
INFO: Elapsed time: 15.584s, Critical Path: 9.85s
INFO: 410 processes: 178 internal, 232 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```

In addition, I have confirmed that the build using the make command succeeds as shown below. Only the build workflow using Bazel does not seem to work as expected.
```
$ cd tensorflow/tensorflow/lite/tools/pip_package
$ sudo make BASE_IMAGE=debian:buster PYTHON=python3 TENSORFLOW_TARGET=aarch64 BUILD_DEB=y docker-build
```
![Screenshot 2021-07-19 23:11:09](https://user-images.githubusercontent.com/33194443/126174312-af38725a-c37c-4bbb-bffa-e2cfcdf3b6ac.png)
"
50825,dataset support prefetch_to_device,"If model in the device(GPU) and dataset in the host(CPU), the data output by dataset must be memcpyH2D, All compute graph spend long time to wait memcpyH2D done.
I think we need a queue to cache output of dataset. so I find  https://github.com/tensorflow/tensorflow/issues/43905, this issues tell me we can use ```prefetch_to_device ``` by ```map().batch()``` or ```experimental::map_and_batch```. But in fact ```map(parallel_num).batch()``` is too slow, we need ```batch().map()``` and ```prefetch_to_device```

batch().map() nsys profiling:
![image](https://user-images.githubusercontent.com/33950866/126093526-c21f6edc-1bf2-4f7c-a6d2-2d6812f1bd4f.png)

I re-copy output of ParallelMapDataset::Iterator to device by set_gpu_compatible(true), and I got a more obvious speedup.
so I would like to add a dataset named copy_to_device, usage like:

```
ds = tf.data.TFRecordDataset(files).batch(batch_size).map(map_func,4).copy_to_device().prefetch(2).
it = ds.make_one_shot_iterator()
gn = it.get_next()
...
```"
50824,Unknown: input/output error,"When running my training script, I encounter this error inconsistently for different tfrecords (in the run below it was 11, but this number changes). I don't think it's an issue with the particular file mentioned below as I've been able to read every tfrecord I'm using with a separate script.

Unknown: dataset-train.tfrecord-00011-of00032; Input/output error
[[{{node MultiDeviceIteratorGetNextShard}}]][[RemoteCall]][[while/boy/_1/IteratorGetNext_1]][[while/body/_1/replica_1/mod/y/_39]]

Does anyone have thoughts on what is triggered this inconsistency?

"
50823,Dark mode not working for `metric_names` attributes of `tf.keras.Model`,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/Model#attributes_1

## Description of issue (what needs changing):

The `metrics_names` attribute section of `tf.keras.Model` doesn't work properly while turning on dark mode.

<img width=""629"" alt=""Screenshot 2021-07-18 at 7 32 01 PM"" src=""https://user-images.githubusercontent.com/46242526/126070193-287588da-0504-4807-a63a-727b15426fb7.png"">

### Correct links

Doc for `Model` : https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/engine/training.py#L135-L207

Doc for attribute `metric_names` : https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/engine/training.py#L684-L717

### Parameters defined

The `layers` attribute of the `tf.keras.Model` is not defined
<img width=""858"" alt=""Screenshot 2021-07-18 at 8 27 48 PM"" src=""https://user-images.githubusercontent.com/46242526/126071975-ac217cea-2e23-439b-ac78-35c588c275da.png"">


### Submit a pull request?

Yes"
50822,Setting of Number of Threads for TFLite Interpreter API,"
**System information**
- TensorFlow version (you are using): 2.4.1
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

I am using TFLite  label image example - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/label_image/label_image.cc 

In this example, We are setting number of threads at line number 238.
```
if (settings->number_of_threads != -1) {
    interpreter->SetNumThreads(settings->number_of_threads);
  }
```


Could you confirm whether the number of threads setting is needed or not ?


Do the user need to specify the number of threads compulsory ?


**If not specified will it take max number of threads available ?** 



**Will this change the current api?** 

No need of setting the number of threads in the workflow.



**Who will benefit with this feature?**

Users need not to manually set the number of threads if its set to max threads available.

"
50821,TF 2.5 | preprocessing.CategoryCrossing behavior different than feature_column.crossed_column,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow version (use command below): 2.5( All 2+ )
- Python version: 3.7

**Describe the current behavior**
When using the new `experimental.preprocessing.CategoryCrossing` layer, it returns values like `[[b'1_X_2_X_3'], [b'4_X_5_X_6']]` as stated in the documentation. Now when the dimension space becomes very large, it is impossible to convert these values to embeddings using the layer `tf.keras.layers.Embedding` as it expects values to be encoded between 0 to N and the layer doesn't return any integerlookup for these new categories generated from `CategoryCrossing`.

One of the alternates that I was trying was as below:
```
cross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([cat_day, cat_hour])
hash_cross_day_hour = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=24 * 8)(cross_day_hour)
embed_cross_day_hour = tf.keras.layers.Embedding(193, 4)(hash_cross_day_hour)
```

However it is not reliable to use the above method as the Hashing layer will have possible collisions( even when num_bins = max number of values ) in each training loop of minibatch. The hashing layer doesn't remember values from previous loops, leading to same hash for different values in each iteration. This will lead to same value passing in the `Embedding` layer for same hash generated for two different values being passed to `Hashing` layer in separate training batches( loops ).

It was *possible earlier* using the `tf.feature_column.crossed_column` to convert it to embeddings by passing the output directly to `tf.feature_column.embedding_column` as `crossed_column` automatically used to return hashes but no more in case of the new layer. ***Please fix this.***

**Describe the expected behavior**:
Either of possible solutions:
1. The new layer `preprocessing.CategoryCrossing` should ideally be directly pluggable with the `layers.Embedding` layer to generate embeddings for very large categorical space. It should generate values = 0 to N
2. Or `preprocessing.CategoryCrossing` should return some other output as well which depicts what all possible unique values are there that can be passed to StringLookup layer to further generate Integer mapping per cross.
3. Or `preprocessing.Hashing` should be capable of remembering values from previous loops until re-instantiated in order to avoid generating same hashes for different values even though num_bins = total unique values

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
cross_day_hour = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([cat_day, cat_hour])
hash_cross_day_hour = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=24 * 8)(cross_day_hour)
embed_cross_day_hour = tf.keras.layers.Embedding(193, 4)(hash_cross_day_hour)
```

Also see how the ***Hashing*** layer generates same hash for different values even though num_bins is set to total number of unique values, which makes it impossible to use the above solution:

```
import tensorflow as tf
import tensorflow.keras as keras

layer = tf.keras.layers.experimental.preprocessing.Hashing(num_bins=10)
inp = [['A'], ['B'], ['C'], ['D'], ['E']]
print(layer(inp))

inp = [['F'], ['G'], ['H'], ['I'], ['J']]
print(layer(inp))
```

Output:
```
tf.Tensor(
[[4]
 [8]
 [7]
 [5]
 [2]], shape=(5, 1), dtype=int64)
tf.Tensor(
[[6]
 [1]
 [8]
 [0]
 [4]], shape=(5, 1), dtype=int64)

```

CC: @rsesha @AutoViML @rafiqhasan - This directly affects the libraries: https://github.com/AutoViML/deep_autoviml and https://github.com/rafiqhasan/auto-tensorflow/"
50820,Unclear how to adapt multiple Keras preprocessing layers,"## URL(s) with the issue:

https://www.tensorflow.org/guide/keras/preprocessing_layers

## Description of issue (what needs changing):

### Clear description

Currently all examples of calling `adapt()` on a preprocessing layer with a `Dataset` argument assumes a single input feature (and thus a single `Input`). In a model with multiple `Input`s and `PreprocessingLayer`s it's unclear how to use `adapt()` together with a `Dataset`.

### Usage example

(Cross-posted to https://stackoverflow.com/questions/68426974/how-do-you-use-keras-preprocessing-normalization-layers-with-multi-input-models):

```
x_norm = preprocessing.Normalization()
y_norm = preprocessing.Normalization()

x = layers.Input(shape=(1,))
x = x_norm(x)
y = layers.Input(shape=(1,))
y = y_norm(y)
concated = layers.Concatenate()([x, y])
output = layers.Dense(1)(concated)
model = keras.Model(inputs=[x, y], outputs=output)
```

This does *not* work but should:

```
x_norm.adapt(dataset)
y_norm.adapt(dataset)
```

Workaround that involve manual iteration over the `Dataset` result in inefficient execution as `adapt()` manages its own `tf.function` internally. This results in warning for the manual approach:

```
normalization_layers = {
    'x': preprocessing.Normalization(),
    'y': preprocessing.Normalization(),
    }
for batch in dataset:
  for name, layer in normalization_layers.items():
    layer.adapt(batch[0][name])
```"
50819,Which version of CUDA and cuDNN should i use with tensorflow2.5.0 ?,"https://tensorflow.google.cn/install/source_windows#gpu
In this page, I can't figure out what version of CUDA and cuDNN should I use with tf2.5.0.
When I use my tensorflow, it can't recognize my GPU.
it shows:
2021-07-18 14:45:58.223694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-07-18 14:45:58.223904: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

**System information**
- Windows 10
- TensorFlow installed from (source or binary): https://pypi.python.org/simple
- TensorFlow version: 2.5.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 11.2 cuDNN 8.2
- GPU model and memory: Nvidia 1660 Ti



**Describe the problem**
When I use my tensorflow, it can't recognize my GPU.
I think it is a version problem, but in this page[https://tensorflow.google.cn/install/source_windows#gpu] I can't find which version to use.

So, please update the installation info page and let us know which version of CUDA and cuDNN to use. Thanks!

"
50817,TF2 ‘saved_model.pb’ from ‘exporter_main_v2.py’ is different than ‘saved_model.pb’ from official TF2 Zoo,"Please make sure that this is a bug. As per our
GitHub Policy,
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.3.0
Python version: 3.6.9
Bazel version (if compiling from source): -
GCC/Compiler version (if compiling from source): -
CUDA/cuDNN version: CUDA 11.4
GPU model and memory: GeForce RTX 3090
I am trying to convert a re-trained TF2 object detection SSD MobilenetV2 model to a proprietary framework. I have successfully re-trained the network and it runs properly. However, I am having trouble with converting the saved_model.pb to the other framework. The conversion script from the SDK I am working with performs optimization on the saved_model.pb, using 'meta_optimizer.cc', which returns an empty graph after running through my re-trained model. I used 'exporter_main_v2.py' to export my re-trained checkpoint to the saved_model.pb which I am having trouble with.

The issue is not with my training or checkpoints, but with the exporting process from checkpoint to a saved_model.pb using 'exporter_main_v2.py'. I know this because I downloaded the SSD MobilenetV2 model from the TF2 Zoo to test with it. I have no issue converting the official saved_model.pb file found in the official repo, but when I try to convert the official checkpoints found in the repo to a saved_model.pb using 'exporter_main_v2.py', I face the same issue trying to convert the newly produced saved_model.pb file to the proprietary framework. This means that something wrong is happening when executing the 'exporter_main_v2.py' script.

Describe the expected behavior
The exported saved_model.pb file should not be different than the official saved_model.pb file found in the official repo.

The following is what I get, showing 0 nodes and 0 edges grappler_empty_graph
![AAEA8FD8-1609-4BAC-AE9B-53918E23EA20](https://user-images.githubusercontent.com/84783887/126050092-3161c0b0-ce22-4cb5-a054-8fcb08c4933e.png)


Standalone code to reproduce the issue
The model I downloaded is: http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz

The command I used to export the official checkpoint to a saved_model.pb is: python ~/models/research/object_detection/exporter_main_v2.py --input_type image_tensor --pipeline_config_path pipeline.config --trained_checkpoint_dir checkpoint/ --output_directory exported_model/"
50814,AttributeError: module 'tensorflow' has no attribute 'report_uninitialized_variables',"I'm using Tensorflow version 2 and get this issue when i run this code
```
uninitialized_variables = set([i.decode('ascii') for i in tf.report_uninitialized_variables()])

init_op = tf.variables_initializer(
    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]
)

init_op
```
Error : AttributeError: module 'tensorflow' has no attribute 'report_uninitialized_variables' "
50812,TensorFlow Certificate Network - region - australiasia ,"https://developers.google.com/certification/directory/tensorflow

select australia for region is not available due to incorrect name shown as australiasia.

selecting australiasia shows noting nether australia or Asia. 

I just passed Tensorflow exam and want to show my profile correct in australia.


![image](https://user-images.githubusercontent.com/24234662/126030411-4bf4f5e5-917e-46d9-bc13-9c025d357c2f.png)
"
50809,I'm working in colab and  changed `tf.gfile.GFile` to `tf.io.gfile.GFile` but still get this error,"@mihaimaruseac I'm working in colab and  changed `tf.gfile.GFile` to `tf.io.gfile.GFile` but still get this error
`AttributeError: module 'tensorflow' has no attribute 'gfile'
`

_Originally posted by @mitramir55 in https://github.com/tensorflow/tensorflow/issues/31315#issuecomment-643277101_"
50808,Regarding Scroll for the nearest points,"When we make a  projector using the vectors and select the 100 nearest points, then for the name of points we can see in the bottom left is not scrollable to see more nearest points.

The area can be see  in the attached file.
![image](https://user-images.githubusercontent.com/37951124/125999818-e7cdec52-f761-4c67-9465-13a5b2b78282.png)
"
50807,Using tf.function decorator on an instance method does not maintain a strong reference to self,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 11.4
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3.8.9

**Describe the current behavior**

Expressed in a minimal code example:

```python
import tensorflow as tf


class MyObject(object):
    def __init__(self):
        self.some_attribute = 2

    @tf.function
    def some_tf_function(self, param):
        return self.some_attribute + param


# This works:
obj = MyObject()
obj.some_tf_function(3)  # returns 5

# This throws AttributeError: 'NoneType' has no attribute 'some_attribute'
result = MyObject().some_tf_function(3)
```

**Describe the expected behavior**

Running `MyObject().some_tf_function(...)` in the example above should not throw an exception. It seems that when wrapped with `tf.function`, instance methods don't maintain strong Python references to the objects the functions are bound to."
50806,Issue running code on linux server remotely,"I am doing ssh to my university sever in order to run my code which makes use of large dataset, however when i run my code i am getting bellow error after feature extraction in the code, Can someone please help as i am doing my final year project and should rectify this within 2 days

2021-07-10 09:35:48.234847: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2021-07-10 09:35:48.238831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2021-07-10 09:35:49.584522: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Not found: No algorithm worked!
Traceback (most recent call last):
File ""copy_of_copy_of_copy_of_untitled9.py"", line 157, in
train_validate_features = extract_features(image_dataset_path, train_validate_images)
File ""copy_of_copy_of_copy_of_untitled9.py"", line 143, in extract_features
feature = model.predict(image, verbose=0)
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py"", line 1629, in predict
tmp_batch_outputs = self.predict_function(iterator)
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 828, in call
result = self._call(*args, **kwds)
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py"", line 894, in _call
return self._concrete_stateful_fn._call_flat(
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 1918, in _call_flat
return self._build_call_outputs(self._inference_function.call(
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py"", line 555, in call
outputs = execute.execute(
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: No algorithm worked!
[[node model/block1_conv1/Relu (defined at copy_of_copy_of_copy_of_untitled9.py:143) ]] [Op:__inference_predict_function_610]

Function call stack:
predict_function
"
50804,Saving data as SequenceExample and reading TFRecords for LSTM,"Let's say I have a 3dimentional dataset with shape (sample, timesteps, features) and I want to save it with suitable tensroflow dataset format, e.g. using SequenceExample for further reading with TFRecord and using in LSTM. There is a dataset:

```
import numpy as np
import tensorflow as tf
import numexpr

data = np.array(
[
    [
        [1 , 10, ],
        [2 , 11, ],
    ],
    [
        [2 , 11, ],
        [3 , 12, ],
    ]
], dtype=np.float32)
y = np.array([101., 202.], dtype=np.float32)
```

There is a model:

```
inputs= tf.keras.layers.Input(
shape=(2, 2),
name='input',
)
model = tf.keras.layers.LSTM(
    units=data.shape[2],
    return_sequences=False,
    return_state=False,
    name='lstm',
)(inputs)
model = tf.keras.layers.Dense(
    units=1,
    name='dense',
)(model)
outputs = model
loss = tf.keras.losses.MSE
model = tf.keras.Model(
    inputs=inputs,
    outputs=outputs,
    name='model',
)
model.compile(
    optimizer='rmsprop',
    loss='mse',
    metrics='mse',
)
model.summary()
model.fit(
    x=data,
    y=y,
    batch_size=1,
)
```

Let's try to save and read dataset using tensorflow API:

```
def _float_feature(value):
  """"""Returns a float_list from a float / double.""""""
  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))

# writer
options = tf.io.TFRecordOptions(
    compression_type='ZLIB',
    flush_mode=None,
    input_buffer_size=None,
    output_buffer_size=None,
    window_bits=None,
    compression_level=0,
    compression_method=None,
    mem_level=None,
    compression_strategy=None,
)
writer = tf.io.TFRecordWriter(
    path=r'test.tfrecord',
    options=options,
)
# iterate over each row
for i in range(data.shape[0]):
    # set example id
    sample_dict = {
        'index': tf.train.Feature(int64_list=tf.train.Int64List(value=[i]))
    }
    features_list = {}
    # iterate over each feature
    for c in range(data[0].shape[1]):
        feature_values = [
            _float_feature(v) for v in data[i][:, c]
        ]
        features_list[str(c)] = tf.train.FeatureList(feature=feature_values)
    # set example
    example = tf.train.SequenceExample(
        context=tf.train.Features(feature=sample_dict),
        feature_lists=tf.train.FeatureLists(feature_list=features_list)
    )
    # write
    writer.write(example.SerializeToString())
writer.close()

# read raw
data_raw = tf.data.TFRecordDataset(
    filenames=[r'test.tfrecord'],
    compression_type='ZLIB',
    buffer_size=10*1024, # 10MB
    num_parallel_reads=numexpr.detect_number_of_cores()-1,
)
# parse real
schema = dict(
    zip(
        [str(s) for s in range(data[0].shape[1])],
        [tf.io.FixedLenSequenceFeature([], dtype=tf.float32)] * data[0].shape[1]
    )
)
def decode_fn(record_bytes):
    context, features = tf.io.parse_single_sequence_example(
        serialized=record_bytes,
        context_features={'index': tf.io.FixedLenFeature([], dtype=tf.int64)},
        sequence_features=schema,
    )
    return features
# read real
for r in data_raw.map(decode_fn):
    print(r, '\n')
```

When I'm trying to fit model with tensorflow dataset it's getting me an error

```
model.fit(
    data_raw,
    batch_size=1,
)
ValueError: Input 0 of layer lstm is incompatible with the layer: expected ndim=3, found ndim=0. Full shape received: []
```

I understand that I did not add label to tensorflow dataset but it does not matter in this case cause dataset has no incomplitable shape. Can anybody help me to understand why and where am I wrong in the code?"
59505,"Sucessful tflite conversion to uint8, but model has wrong box shape, class, and scores. ","# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [x ] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [x ] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [x ] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/tree/master/official/...

## 2. Describe the bug

A clear and concise description of what the bug is.

## 3. Steps to reproduce
```
1) export trained step to intermediate saved_model.pb using export_tflite_graph_tf2.py
2) convert to tflite and do post quantization.
3) deploy on raspberry pi
4) Output Scores, class, boxes are all wrong.
```
![20210712_220925](https://user-images.githubusercontent.com/81843191/125955317-6256b28d-0e1a-454b-a530-8767acaef72d.jpg)

terminal logs:
```
input:  <class 'numpy.uint8'>
output:  <class 'numpy.uint8'>
{'name': 'StatefulPartitionedCall:3', 'index': 384, 'shape': array([ 1, 10,  4]), 'shape_signature': array([ 1, 10,  4]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.007398997899144888, 51), 'quantization_parameters': {'scales': array([0.007399], dtype=float32), 'zero_points': array([51]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}
```


## 4. Expected behavior
Output of the model should not quantize the class, scores and the box size. 

## 5. Additional context

conversion script i assembled using codes copied from `https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization` and load data 
```
import logging
logging.getLogger(""tensorflow"").setLevel(logging.DEBUG)

import tensorflow as tf
import numpy as np
assert float(tf.__version__[:3]) >= 2.5
import os
import PIL
import PIL.Image
import tensorflow_datasets as tfds
import pathlib

def representative_data_gen():
    #point to the data path for train
    data_dir = pathlib.Path(r'D:\Development\fruits_data\test1\train') #Set the path to the image data
    batch_size = 10
    img_height = 640
    img_width = 640
    #check number of image
    image_count = len(list(data_dir.glob('*/*.jpeg')))
    print(image_count)

    #load train_images here. 
    train_images=tf.keras.preprocessing.image_dataset_from_directory(
        data_dir,
        validation_split=0.2,
        subset=""training"",
        seed=123,
        image_size=(img_height, img_width),
        batch_size=batch_size)
        
    #standardize the images
    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1/255)
    normalized_ds = train_images.map(lambda x, y: (normalization_layer(x), y))
    image_batch, labels_batch = next((iter(normalized_ds)))
    first_image = image_batch[0]
    #print(image_batch)
    # Notice the pixels values are now in `[0,1]`.
    print(np.min(first_image), np.max(first_image))
    
    for input_value in tf.data.Dataset.from_tensor_slices(image_batch).batch(1).take(100):
        # Model has only one input so each data point has one element.
        yield [input_value]

   
model_path = r'D:\Development\fruits_data\exported_models\tflite\test1\saved_model'
#check model details
model = tf.saved_model.load(model_path)
#check model input
print(list(model.signatures.keys()))
infer = model.signatures[""serving_default""]
print(infer.structured_input_signature)
print(infer.structured_outputs)

converter = tf.lite.TFLiteConverter.from_saved_model(model_path)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
# Ensure that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]
# Set the input and output tensors to int8 (APIs added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.allow_custom_ops = True
tflite_model_quant = converter.convert()

#see what model type
interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)
input_type = interpreter.get_input_details()[0]['dtype']
print('input: ', input_type)
output_type = interpreter.get_output_details()[0]['dtype']
print('output: ', output_type)

# Initialize the interpreter
interpreter.allocate_tensors()
output_details = interpreter.get_output_details()[0]
print(output_details)


#Save the file

tflite_models_dir = pathlib.Path(r""D:\Development\fruits_data\tflite"")
tflite_models_dir.mkdir(exist_ok=True, parents=True)

tflite_model_quant_file = tflite_models_dir/""test_model_quant3a.tflite""
tflite_model_quant_file.write_bytes(tflite_model_quant)


```

## 6. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win 19
- Mobile device name if the issue happens on a mobile device: raspberry pi 4b 8gb
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.5
- Python version: 3.7

"
50803,make tf.rsqrt available!,"**System information**
- TensorFlow version: 2.5.0
- Are you willing to contribute it: Not Sure

Since TensorFlow 2.0.0, why `tf.rsqrt` is unavailable while `tf.square`, `tf.reduce_sum` and etc are not?

From my opinion, TensorFlow should acts as a math calculating framework, so it should provide some shortcuts for `tf.math` calculation. Like PyTorch, every calculation can be carried out via top-level module.

Why you guys remove them from `tensorflow` module?

```python
tf.sqrt  # <function tensorflow.python.ops.math_ops.sqrt(x, name=None)>

tf.rsqrt # AttributeError: module 'tensorflow' has no attribute 'rsqrt'
```

I think not only `tf.rsqrt`, there are also some other functions should be bring back. Or, you should provide some reasonable explanation, especially:
  - Why `tf.sqrt` are available while `tf.rsqrt` are not?
  - Why some math functions are removed from top-level module since 2.0.0?"
50802,tf.compat.v1.profiler.profile produces wrong flops on Conv2D,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Pip
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: - 
- GPU model and memory: -


Flops calculation for a Convolution2D Layer via tf.compat.v1.profiler.profile seems to be wrong. More specifically, it seems to only calculate flops for one application of the kernel and leave out the input size.

I use the following to calculate flops of a model containing only one conv layer:

`
from typing import Callable, Any
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers


def calculate_flops(model_generating_function: Callable, *args: Any, **kwargs: Any) -> int:
    """"""
    Calculates the flops of a keras model. For implementation reasons, which include creating and tearing down the
    tensorflow graph, the function does not take a model as input, but a function that returns said model.
    Adapted from answer of ch271828n on
    https://stackoverflow.com/questions/49525776/how-to-calculate-a-mobilenet-flops-in-keras.
    :param model_generating_function: a function that returns a keras model.
    :param args: positional arguments for model_generating_function
    :param kwargs: keyword arguments for model_generating_function
    :return: number of float point operations
    """"""
    tf.compat.v1.reset_default_graph()
    session = tf.compat.v1.Session()
    graph = tf.compat.v1.get_default_graph()

    with graph.as_default():
        with session.as_default():
            _ = model_generating_function(*args, **kwargs)

            run_meta = tf.compat.v1.RunMetadata()
            opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()

            # We use the Keras session graph in the call to the profiler.
            flops = tf.compat.v1.profiler.profile(
                graph=graph,
                run_meta=run_meta,
                cmd='op',
                options=opts
            )
    # necessary to not clog up graph and add flops over multiple calls to this function.
    tf.compat.v1.reset_default_graph()

    return flops.total_float_ops


def get_model(input_size: int, n_channels: int, n_filters: int, kernel_size: int) -> keras.Sequential:

    model = keras.Sequential(
        [
            keras.Input(shape=(input_size, input_size, n_channels)),
            layers.Conv2D(n_filters, kernel_size=(kernel_size, kernel_size), activation=None, padding=""same"", use_bias=False)
        ]
    )

    return model


assert calculate_flops(get_model, input_size=16, n_channels=1, n_filters=1, kernel_size=3) == 2 * 3 * 3 +1
`

will return 19 = 2 * kernel_size * kernel_size + 1

**Describe the expected behavior**
I would have expected something around 16 * 16 *  actual_output
"
50801,Adding some Boosted tree ops to the 'allowed' list,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.4
- Are you willing to contribute it (Yes/No):Yes/will need some help



**Describe the feature and the current behavior/state.** 

Currently, we cant convert tensorflow boosted tree model to tensorflow lite using tf.lite.TFLiteConverter.from_saved_model even after having 
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS
    # enable TensorFlow ops.
]
I am getting this error,

`ConverterError: <unknown>:0: error: loc(""boosted_trees""): 'tf.BoostedTreesEnsembleResourceHandleOp' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""boosted_trees/BoostedTreesPredict""): 'tf.BoostedTreesPredict' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""boosted_trees/head/predictions/str_classes""): 'tf.AsString' op is neither a custom op nor a flex op
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.AsString {device = """", fill = """", precision = -1 : i64, scientific = false, shortest = false, width = -1 : i64}
	tf.BoostedTreesEnsembleResourceHandleOp {container = """", device = """", shared_name = ""boosted_trees/""}
	tf.BoostedTreesPredict {device = """", logits_dimension = 7 : i64, num_bucketized_features = 18 : i64}

`
**Will this change the current api? How?**
Not sure

**Who will benefit with this feature?**

Anyone who want to use boosted tree tensorflow lite model will be benifted.

**Any Other info.**
Thanks to @MeghnaNatraj and @abattery for responding to case #50667 .After referring this [https://www.tensorflow.org/lite/guide/op_select_allowlist#add_tensorflow_core_operators_to_the_allowed_list], i have raised this feature request to add the unsupported ops.


"
50800,Problem in adjust gamma function (tf.image.adjust_gamma),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Not applicable (NA)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below):  2.5.0
- Python version: NA
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Pixels values are manipulated using this equation: Out = gain * In**gamma

**Describe the expected behavior**
This function should preserve range of pixel values by first converting them between 0 and 1 and then again rescaling back to original range or atleast provide an argument for preserving range.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):  yes
"
50798,Word Embeddings not Accuracte,"I am trying to build my own word2vec model using the code provided here
Link: - https://www.tensorflow.org/tutorials/text/word2vec

So i have even tried to increase the data as well for training the word embedding and i am able to achieve a good model accuracy but when i plot the word vectors on the Embedding Projector the distance between words or the word similarity is really bad, if i even use the cosine distance formula between very similar words the result is bad.

Whereas if the same data is used to train own embeddings using the Gensim library ( not pre-trained) the results of distance and similarity are way better, even on the Embedding Projector as well.

Please can someone help me regarding this, i want to use the Word2Vec code only which is provided by TensorFlow but i am not able to get good results for word distance and word similarity.
"
50797,Documented and more fine grained XLA auto-clustering flags in ConfigProto,"**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it: Probably not

**Describe the feature and the current behavior/state.**
Currently, to enable XLA auto-clustering, you have to either use global configuration flags (`TF_XLA_FLAGS`) or `config.proto` options.  However, several options from the global flags are missing from `config.proto`, most importantly to do it on CPU (`--tf_xla_cpu_global_jit`), but also including debug settings.

I would like the option to set all relevant XLA options (but especially to enable it on CPU) in `config.proto` in addition to the global settings.  It avoids forcing global (JVM-wide in this case) configuration and allows setting it from code.


**Will this change the current api? How?**
It will add properties to `config.proto`.

**Who will benefit with this feature?**
Anyone wanting to use XLA auto-clustering programmatically.  The motivating use case was for Graphs in tensorflow/java.
"
50796,ResourceVariable GC bug,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.5.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing): Fix ResourceVariable gc bug when it works with tf.cond 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
from tensorflow_addons.utils import types
from typeguard import typechecked


physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(
    physical_devices[0],
    [tf.config.LogicalDeviceConfiguration(memory_limit=1024),
    tf.config.LogicalDeviceConfiguration(memory_limit=1024)])
l_devices = tf.config.list_logical_devices('GPU')

@tf.keras.utils.register_keras_serializable(package=""Addons"")
class GradientAccumulator(tf.keras.optimizers.Optimizer):
    """"""Optimizer wrapper for gradient accumulation.""""""

    @typechecked
    def __init__(
        self,
        optimizer: types.Optimizer,
        accum_steps: types.TensorLike = 4,
        name: str = ""GradientAccumulator"",
        **kwargs,
    ):
        r""""""Construct a new GradientAccumulator optimizer.

        Args:
            optimizer: str or `tf.keras.optimizers.Optimizer` that will be
                used to compute and apply gradients.
            accum_steps: int > 0. Update gradient in every accumulation steps.
            name: Optional name for the operations created when applying
                gradients. Defaults to ""GradientAccumulator"".
            **kwargs: keyword arguments. Allowed to be {`clipnorm`,
                `clipvalue`, `lr`, `decay`}. `clipnorm` is clip gradients by
                norm; `clipvalue` is clip gradients by value, `decay` is
                included for backward compatibility to allow time inverse
                decay of learning rate. `lr` is included for backward
                compatibility, recommended to use `learning_rate` instead.
        """"""
        super().__init__(name, **kwargs)
        self._optimizer = tf.keras.optimizers.get(optimizer)
        self._gradients = []
        self._accum_steps = accum_steps

    def _create_slots(self, var_list):
        self._optimizer._create_slots(var_list=var_list)
        for var in var_list:
            self.add_slot(var, ""ga"")

        self._gradients = [self.get_slot(var, ""ga"") for var in var_list]

    @property
    def gradients(self):
        """"""The accumulated gradients on the current replica.""""""
        if not self._gradients:
            raise ValueError(
                ""The accumulator should be called first to initialize the gradients""
            )
        return list(
            gradient.read_value() if gradient is not None else gradient
            for gradient in self._gradients
        )

    def apply_gradients(self, grads_and_vars, name=None, **kwargs):
        self._optimizer._iterations = self.iterations
        return super().apply_gradients(grads_and_vars, name, **kwargs)

    def _resource_apply_dense(self, grad, var, apply_state=None):
        accum_gradient = self.get_slot(var, ""ga"")
        if accum_gradient is not None and grad is not None:
            accum_gradient.assign_add(
                grad, use_locking=self._use_locking, read_value=False
            )

        def _apply():
            if ""apply_state"" in self._optimizer._dense_apply_args:
                train_op = self._optimizer._resource_apply_dense(
                    accum_gradient.read_value(), var, apply_state=apply_state
                )
            else:
                train_op = self._optimizer._resource_apply_dense(
                    accum_gradient.read_value(), var
                )
            reset_op = accum_gradient.assign(
                tf.zeros_like(accum_gradient),
                use_locking=self._use_locking,
                read_value=False,
            )
            return tf.group(train_op, reset_op)

        apply_op = tf.cond(
            (self.iterations+1) % self._accum_steps == 0, _apply, lambda: tf.no_op()
        )
        return apply_op

    def _resource_apply_sparse(self, grad: types.TensorLike, var, indices, apply_state):
        accum_gradient = self.get_slot(var, ""ga"")
        if accum_gradient is not None and grad is not None:
            self._resource_scatter_add(accum_gradient, indices, grad)

        def _apply():
            if ""apply_state"" in self._optimizer._sparse_apply_args:
                train_op = self._optimizer._resource_apply_sparse(
                    accum_gradient.sparse_read(indices),
                    var,
                    indices,
                    apply_state=apply_state,
                )
            else:
                train_op = self._optimizer._resource_apply_sparse(
                    accum_gradient.sparse_read(indices), var, indices
                )
            reset_op = accum_gradient.assign(
                tf.zeros_like(accum_gradient),
                use_locking=self._use_locking,
                read_value=False,
            )
            return tf.group(train_op, reset_op)

        apply_op = tf.cond(
            (self.iterations+1) % self._accum_steps == 0, _apply, lambda: tf.no_op()
        )
        return apply_op

    def reset(self):
        """"""Resets the accumulated gradients on the current replica.""""""
        assign_ops = []
        if not self._gradients:
            return assign_ops

        for gradient in self._gradients:
            if gradient is not None:
                assign_ops.append(
                    gradient.assign(
                        tf.zeros_like(gradient),
                        use_locking=self._use_locking,
                        read_value=False,
                    )
                )

        return tf.group(assign_ops)

    @property
    def lr(self):
        return self._optimizer._get_hyper(""learning_rate"")

    @lr.setter
    def lr(self, lr):
        self._optimizer._set_hyper(""learning_rate"", lr)  #

    @property
    def learning_rate(self):
        return self._optimizer._get_hyper(""learning_rate"")

    @learning_rate.setter
    def learning_rate(self, learning_rate):
        self._optimizer._set_hyper(""learning_rate"", learning_rate)

    def get_config(self):
        config = {
            ""accum_steps"": self._accum_steps,
            ""optimizer"": tf.keras.optimizers.serialize(self._optimizer),
        }
        base_config = super().get_config()
        return {**base_config, **config}

    @classmethod
    def from_config(cls, config, custom_objects=None):
        optimizer = tf.keras.optimizers.deserialize(
            config.pop(""optimizer""), custom_objects=custom_objects
        )
        return cls(optimizer, **config)


def main():
    for precision_policy in ['mixed_float16']:
        print('#' * 72)
        print(f'Setting precision-policy to ""{precision_policy}""')

        tf.keras.mixed_precision.set_global_policy(precision_policy)
        strategy = tf.distribute.MirroredStrategy(devices=l_devices)

        with strategy.scope():
            mnist = tf.keras.datasets.mnist

            (x_train, y_train), (x_test, y_test) = mnist.load_data()
            x_train, x_test = x_train / 255.0, x_test / 255.0

            model = tf.keras.models.Sequential([
                tf.keras.layers.Flatten(input_shape=(28, 28)),
                tf.keras.layers.Dense(128, activation='relu'),
                tf.keras.layers.Dropout(0.2),
                tf.keras.layers.Dense(10)
            ])

            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
            model.compile(optimizer=GradientAccumulator(tf.keras.optimizers.Adam()),
                          loss=loss_fn,
                          metrics=['accuracy'])
            model.fit(x_train, y_train, epochs=5)


if __name__ == '__main__':
    main()

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
2021-07-16 09:15:20.111909: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
   2/1875 [..............................] - ETA: 8:34 - loss: 2.3555 - accuracy: 0.1406   Traceback (most recent call last):
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3296, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-42bda5d10b07>"", line 3, in <module>
    runfile('/media/fangsixie/data/automl/efficientdet/mAP.py', wdir='/media/fangsixie/data/automl/efficientdet')
  File ""/media/fangsixie/data/pycharm-2019.3/plugins/python/helpers/pydev/_pydev_bundle/pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""/media/fangsixie/data/pycharm-2019.3/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/media/fangsixie/data/automl/efficientdet/mAP.py"", line 218, in <module>
    main()
  File ""/media/fangsixie/data/automl/efficientdet/mAP.py"", line 214, in main
    model.fit(x_train, y_train, epochs=5)
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1183, in fit
    tmp_logs = self.train_function(iterator)
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 889, in __call__
    result = self._call(*args, **kwds)
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 917, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3024, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1961, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 596, in call
    ctx=ctx)
  File ""/home/fangsixie/.conda/envs/venv/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.FailedPreconditionError: 3 root error(s) found.
  (0) Failed precondition:  Could not find variable _AnonymousVar58. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar58/N10tensorflow3VarE does not exist.
	 [[{{node cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/then/_200/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/Cast/ReadVariableOp}}]]
	 [[cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update_1/update_1/add/_86]]
  (1) Failed precondition:  Could not find variable _AnonymousVar58. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar58/N10tensorflow3VarE does not exist.
	 [[{{node cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/then/_200/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/Cast/ReadVariableOp}}]]
	 [[cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update_2/update_1/mod/_100]]
  (2) Failed precondition:  Could not find variable _AnonymousVar58. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar58/N10tensorflow3VarE does not exist.
	 [[{{node cond_1/then/_12/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/then/_200/cond_1/GradientAccumulator/GradientAccumulator/update/update_0/cond/Cast/ReadVariableOp}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_3163]
Function call stack:
train_function -> train_function -> train_function

```
Change (self.iterations+1) to self.iterations fix the bug.
"
50795,"Installed successfully the TensorFlow-gpu==1.15 but got error tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible resource devices: /device:CPU:0 vs /device:GPU:0. The edge src node is input_producer , and the dst node is ReaderReadV2","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS BigSur
- TensorFlow installed from (source or binary): source
- TensorFlow version: tensorflow 2.5.0
- Python version: 3.9.6
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: TensorFlow-gpu==1.15 



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Environment and Configuration needed to run the evaluation code.
Python 3.6.4 --> version 3.9.6
Tensorflow-gpu 1.8.0 (pip install tensorflow-gpu==1.8.0) --> not available instead installed the TensorFlow-gpu==1.15.
Tensorpack (pip install tensorpack) version - 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Executed code :
_user@Olens-MacBook-Air SELFIE % python3 -m pip3 install tensorflow-gpu==1.15
/Library/Frameworks/Python.framework/Versions/3.9/bin/python3: No module named pip3
user@Olens-MacBook-Air SELFIE % python3 -m pip3 install tensorflow-gpu==1.8.0
/Library/Frameworks/Python.framework/Versions/3.9/bin/python3: No module named pip3
user@Olens-MacBook-Air SELFIE % python3 main.py  0  CIFAR-10  DenseNet-10-12  SELFIE  pair  0.05  /Users/user/Desktop/Summer\ 2021/log_
['main.py', '0', 'CIFAR-10', 'DenseNet-10-12', 'SELFIE', 'pair', '0.05', '/Users/olenbaduria/Desktop/Summer 2021/log']
------------------------------------------------------------------------
This code trains Densnet(L={10,25,40}, k=12) using SELFIE in tensorflow-gpu environment.

Description -----------------------------------------------------------
Please download datasets from our github before running command.
For SELFIE, the hyperparameter was set to be uncertainty threshold = 0.05 and  history length=15.
For Training, we follow the same configuration in our paper
For Training, training_epoch = 100, batch = 128, initial_learning rate = 0.1 (decayed 50% and 75% of total number of epochs), use momentum of 0.9, warm_up=25, restart=2, ...
You can easily change the value in main.py
Dataset exists in  /Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10
2021-07-15 17:50:10.016830: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Now read following files.
['/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10/data_batch_1.bin', '/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10/data_batch_2.bin', '/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10/data_batch_3.bin', '/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10/data_batch_4.bin', '/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10/data_batch_5.bin']
Filling queue with 20000 data before starting to train. This will take a few minutes.
Now read following files.
['/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/dataset/CIFAR-10/test_batch.bin']
Filling queue with 4000 data before starting to train. This will take a few minutes.
/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
[0715 17:50:10 @registry.py:90] 'DenseNet/conv0': [?, 32, 32, 3] --> [?, 32, 32, 16]
[0715 17:50:10 @registry.py:90] 'DenseNet/block1/dense_layer.0/conv1': [?, 32, 32, 16] --> [?, 32, 32, 12]
[0715 17:50:10 @registry.py:90] 'DenseNet/block1/dense_layer.1/conv1': [?, 32, 32, 28] --> [?, 32, 32, 12]
[0715 17:50:10 @registry.py:90] 'DenseNet/block1/transition1/conv1': [?, 32, 32, 40] --> [?, 32, 32, 40]
[0715 17:50:10 @registry.py:90] 'DenseNet/block1/transition1/pool': [?, 32, 32, 40] --> [?, 16, 16, 40]
[0715 17:50:10 @registry.py:90] 'DenseNet/block2/dense_layer.0/conv1': [?, 16, 16, 40] --> [?, 16, 16, 12]
[0715 17:50:10 @registry.py:90] 'DenseNet/block2/dense_layer.1/conv1': [?, 16, 16, 52] --> [?, 16, 16, 12]
[0715 17:50:10 @registry.py:90] 'DenseNet/block2/transition2/conv1': [?, 16, 16, 64] --> [?, 16, 16, 64]
[0715 17:50:10 @registry.py:90] 'DenseNet/block2/transition2/pool': [?, 16, 16, 64] --> [?, 8, 8, 64]
[0715 17:50:10 @registry.py:90] 'DenseNet/block3/dense_layer.0/conv1': [?, 8, 8, 64] --> [?, 8, 8, 12]
[0715 17:50:10 @registry.py:90] 'DenseNet/block3/dense_layer.1/conv1': [?, 8, 8, 76] --> [?, 8, 8, 12]
[0715 17:50:10 @registry.py:90] 'DenseNet/gap': [?, 8, 8, 88] --> [?, 88]
[0715 17:50:10 @registry.py:90] 'DenseNet/linear': [?, 88] --> [?, 10]
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 1375, in _do_call
    return fn(*args)
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 1358, in _run_fn
    self._extend_graph()
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 1398, in _extend_graph
    tf_session.ExtendSession(self._session)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot place the graph because a reference or resource edge connects colocation groups with incompatible resource devices: /device:CPU:0 vs /device:GPU:0. The edge src node is input_producer , and the dst node is ReaderReadV2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/main.py"", line 108, in <module>
    main()
  File ""/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/main.py"", line 104, in main
    selfie(gpu_id, input_reader, model_name, total_epochs, batch_size, lr_boundaries, lr_values, optimizer, noise_rate, noise_type, warm_up, threshold, queue_size, restart=restart, log_dir=log_dir)
  File ""/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/algorithm/selfie.py"", line 167, in selfie
    train_batch_patcher.bulk_load_in_memory(sess, train_ids, train_images, train_labels)
  File ""/Users/user/Desktop/Summer 2021/SELFIE/SELFIE/reader/batch_patcher.py"", line 40, in bulk_load_in_memory
    mini_ids, mini_images, mini_labels = sess.run([ids, images, labels])
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 967, in run
    result = self._run(None, fetches, feed_dict, options_ptr,
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 1190, in _run
    results = self._do_run(handle, final_targets, final_fetches,
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 1368, in _do_run
    return self._do_call(_run_fn, feeds, fetches, targets, options,
  File ""/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/client/session.py"", line 1394, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: **_Cannot place the graph because a reference or resource edge connects colocation groups with incompatible resource devices: /device:CPU:0 vs /device:GPU:0. The edge src node is input_producer , and the dst node is ReaderReadV2_**
user@Olens-MacBook-Air SELFIE % python3 --version
Python 3.9.6
"
50793,Serialize tf.keras Preprocessing layers,"I created some keras preprocessing layers using the following:
This example is for categorical columns but I could have done this for any type of preprocessing as shown in [Module: tf.keras.layers.experimental.preprocessing](Module: tf.keras.layers.experimental.preprocessing)
```
categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')

index = preprocessing.StringLookup(max_tokens=max_tokens)
index.adapt(feature_ds)
encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())
encoding_layer = lambda feature: encoder(index(feature))
```
Now if I want to serialize this `encoding_layer` or the `categorical_col` there is no way to do this.

I tried pickle dump and got the following error:
`pickle.dumps(encoding_layer)`
```
--------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-15-da3341eebce4> in <module>
      1 import pickle
----> 2 pickle.dumps(tfp.encoded_features[0])

AttributeError: Can't pickle local object 'PreprocessingLayer.make_adapt_function.<locals>.adapt_step'
```
I also tried to use the tf.keras serializer and I got the following error:
`tf.keras.layers.serialize(encoding_layer)`

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-16-c9875a7f3e69> in <module>
----> 1 tf.keras.layers.serialize(tfp.encoded_features[0])

~/Dev-Stage/armet/env/lib/python3.6/site-packages/tensorflow/python/keras/layers/serialization.py in serialize(layer)
    141 @keras_export('keras.layers.serialize')
    142 def serialize(layer):
--> 143   return generic_utils.serialize_keras_object(layer)
    144 
    145 

~/Dev-Stage/armet/env/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py in serialize_keras_object(instance)
    528   if hasattr(instance, '__name__'):
    529     return get_registered_name(instance)
--> 530   raise ValueError('Cannot serialize', instance)
    531 
    532 

ValueError: ('Cannot serialize', <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'normalization')>)
```
Is there a way to serialize the keras preprocessing layers? I am not sure why this serialization is not working."
50791,tf.keras.models.clone_model ignores input_tensors argument ,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution. Linux Ubuntu 20.04:
- TensorFlow installed from binary:
- TensorFlow version (use command below): v2.4.0-49-g85c8b2a817f 2.4.1
- Python version: 3.8.5
- CUDA/cuDNN version: 11.2
- GPU model and memory: NVIDIA Quadro RTX 8000

**Describe the current behavior**

`tf.keras.models.clone_model` ignores `input_tensors` argument and reuses the inputs of the original model for functional models. It works for sequential models.


**Describe the expected behavior**

If I provide `input_tensors`, it should use it.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes

I think that the error is in the following [line](https://github.com/tensorflow/tensorflow/blob/383f3a58a682aaf8e460170ccd76f216db375f9f/tensorflow/python/keras/models.py#L187)

I would replace this line:
`new_input_layers[original_input_layer] = original_input_layer`
by this line:
`new_input_layers[original_input_layer] = input_tensor._keras_history.layer`

This would be similar to the [line in sequential models](https://github.com/tensorflow/tensorflow/blob/383f3a58a682aaf8e460170ccd76f216db375f9f/tensorflow/python/keras/models.py#L344)

It works for me, but I'm not 100% sure if that is the intended behavior.

**Standalone code to reproduce the issue**
[Colab](https://colab.research.google.com/drive/1ljevVbdSon7Vkz21lA9Bd0-dYw1tkuES?usp=sharing)
```
import tensorflow as tf
from tensorflow.keras import layers

inputs_small = layers.Input((64, 64, 3), name=""small"")
outputs = layers.Conv2D(32, 1)(inputs_small)
model_small = tf.keras.models.Model(inputs=inputs_small, outputs=outputs)

inputs_large = layers.Input((128, 128, 3), name=""large"")
model_large = tf.keras.models.clone_model(model_small, input_tensors=inputs_large)
model_large.summary()
```
This results into:
```
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
small (InputLayer)           [(None, 64, 64, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 64, 64, 32)        128       
=================================================================
Total params: 128
Trainable params: 128
Non-trainable params: 0
_________________________________________________________________
```
I like to see this behavior:
```
Model: ""model""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
large (InputLayer)           [(None, 128, 128, 3)]     0         
_________________________________________________________________
conv2d (Conv2D)              (None, 128, 128, 32)      128       
=================================================================
Total params: 128
Trainable params: 128
Non-trainable params: 0
_________________________________________________________________
```
The same happens if the new input tensor just has a different name than the original one"
50790,Out of memory when using MultiWorkerMirroredStrategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): REHEL 7.9
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.1
- Python version: 3.7.4
- Bazel version (if compiling from source): 3.7.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: 10.2
- GPU model and memory: GTX 1080Ti

**Describe the current behavior**

When running a trivial example TF starts allocation gigabytes of memory continously until it runs out of memory.
This does only happen when running on more than 2 nodes, not when running on only 1 or 2 nodes and it happens in the creation of MultiWorkerMirroredStrategy
I can also start e.g. 6 tasks on 2 nodes (3 tasks each) without problems, but 3 tasks on 3 nodes (1 task each) does not work

I also observed that it happens only one 1 of the ranks used, the other workers are fine and waiting for that one to finish init (I suppose)

**Describe the expected behavior**

It works or a reasonable error.

**Standalone code to reproduce the issue**

```

import tensorflow as tf
from mpi_cluster_resolver import MPIClusterResolver

resolver = MPIClusterResolver()
strategy = tf.distribute.MultiWorkerMirroredStrategy(cluster_resolver=resolver)
```

With 
[mpi_cluster_resolver.py.txt](https://github.com/tensorflow/tensorflow/files/6823734/mpi_cluster_resolver.py.txt)

This is so that running distributed TF is possible via SLURM/MPI on HPC clusters"
50789,Import error when multiple versions of tensorflow are in python path,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 10 (buster)
- TensorFlow installed from (source or binary): via pip
- TensorFlow version (use command below): 2.4.1 and 2.5.0
- Python version: 3.7
- CUDA/cuDNN version: Environment without GPU
- GPU model and memory: Environment without GPU

**Initial environment**
I have empty virtual environment without system libraries, created via command `virtualenv --system-site-packages`. Outside of the environment I have installed a set of common data-science libraries , including `tensorflow==2.4.1`. My python path looks like this: 
```
['/usr/local/lib/python37.zip',
 '/usr/local/lib/python3.7',
 '/usr/local/lib/python3.7/lib-dynload',
 '/root/venv/lib/python3.7/site-packages',
 '/usr/local/lib/python3.7/site-packages',
 '/shared-libs/python3.7/py/lib/python3.7/site-packages',
 '/deepnote-config/ipython',
 '/root/work']
```

where `/shared-libs/python3.7/py/lib/python3.7/site-packages` contains tensorflow==2.4.1.

**Describe the current behavior**
When I import tensorflow in this environment, everything works ok. Problem appears when I install newer `tensorflow` to my env via command `pip install tensorflow==2.5.0`. After succesfull installation I get this error while importing tensorflow:
`NotFoundError: /shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow6thread10ThreadPool26TransformRangeConcurrentlyExxRKSt8functionIFvxxEE `. 

Why is tensorflow trying  to load `libtfkernel_sobol_op.so` module form last path in python path `/shared-libs/python3.7/py`. Just to clarify, `cat /root/venv/lib/python3.7/site-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so` file exists.

When I remove  '/shared-libs/python3.7/py/lib/python3.7/site-packages' (which contains tf 2.4.1) from python path, the problem seems to disappear. Therefore it seems like presence of different version of tf later in the path causes the issue, which is unexpected. 

**Describe the expected behavior**
I expect that python will search tensorflow according to the order of the python path. In other words, I expect that tensorflow 2.5.0 will be imported from  '/root/venv/lib/python3.7/site-packages' and tensorflow outside of my venv will be ignored '/shared-libs/python3.7/py/lib/python3.7/site-packages'. 

**Other info / logs** 
I found this similar error https://github.com/tensorflow/tensorflow/issues/42978 . I tried to run logic for for sorting site_packages dirs:

```python
import six as _six
import sys as _sys
import site as _site

# Get sitepackages directories for the python installation.
_site_packages_dirs = []
if _site.ENABLE_USER_SITE and _site.USER_SITE is not None:
  _site_packages_dirs += [_site.USER_SITE]
  _site_packages_dirs += [_p for _p in _sys.path if 'site-packages' in _p]
  print(_site_packages_dirs)
```
Output:
```
[ '/root/venv/lib/python3.7/site-packages', '/usr/local/lib/python3.7/site-packages', '/shared-libs/python3.7/py/lib/python3.7/site-packages']
```
Happy to provide any assistance in debugging and I am also happy to provide a fix if anyone can point me in the right direction. "
50788,ValueError: destinations can not be empty,"I'm having this bug when I try to: get features at the layer before last layer, compute loss with expected features using cosine similarity, then propagate back to input (I update input, not network's weight) with optimizer.minimine(loss,var_list = input). I cannot find any information about this bug. Please give me advice"
50787,Library using libtensorflow crashes with the TensorFlow packege in Python,"First, thanks for attending this issue. As I couldn't find a precise category for this problem, I considered that this one was the better suited. Please let me know if this is not appropriate and I should direct my question somewhere else. 

**System information**
- OS Platform and Distribution: Ubuntu 20.04.2 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.5.0
- Python version: 3.8/3.9
- Installed using virtualenv? pip? conda?: pip and the C API
- CUDA/cuDNN version: None
- GPU model and memory: None



**Describe the problem**
[Essentia](https://essentia.upf.edu/) is a C++ music and sound analysis library with Python bindings that uses the C TensorFlow API for machine learning inference. When Essentia is linked against [libtensorflow](https://www.tensorflow.org/install/lang_c), and we import both  `essentia` and `tensorflow`  in a Python session, a segmentation fault happens. However, they can work perfectly in separate sessions. We are opening this issue as we believe that a similar problem can happen to other projects with a Python interface relying on `libtensorflow`.

As pointed out in https://github.com/tensorflow/tensorflow/issues/22810#issuecomment-433225466, using the same TensorFlow library should fix the problem. However, even if we `pip install tensorflow==2.5.0` and we link Essentia against `libtensorflow 2.5.0` the problem persists. Maybe this is because the way TensorFlow is shipped inside the Python wheel is not through `libtensorflow` so it is not recognized as the same library?

We have found two ways to overcome this issue:
- **With a static build of TensorFlow**. However, this method was only achieved with the [contrib Makefile](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/makefile/Makefile) for TensorFlow 1.15. The main problem is that this approach requires substantial patching to the Makefile, and each time it is more difficult to keep track with the updates of the library. Also, this solution makes the final build larger, and we would prefer to avoid it. 
- **Linking against `libtensorflow_framework` inside the Python wheel**. While this approach was working with Tensorflow 1.X, it is not working for Tensorflow 2.X. Also, while this approach was working (and it is our current way to create [wheels](https://pypi.org/project/essentia/)) it feels a bit hacky, and we would prefer to use `libtensorflow`. 

Our question is, is there a way in which we could link our library against `libtensorflow` without crashing with the official TensorFlow library in Python?

**Provide the exact sequence of commands / steps that you executed before running into the problem**
We have Python [wheels](https://drive.google.com/drive/folders/1Ipl48pcZAvdX-ogYk0cx2gwwkDE58rbX?usp=sharing) linked against `libtensorflow` that can be installed offline. After this:
```
import tensorflow
import essentia.standard
```


**Any other info / logs**
The lines above produce:
```
2021-07-15 10:15:35.710295: F tensorflow/core/framework/variant_op_registry.cc:66] Check failed: existing == nullptr (0x563975228328 vs. nullptr)Unary VariantDecodeFn for type_name: tensorflow::data::WrappedDatasetVariant already registered
Aborted (core dumped)
```
"
50785,About pb model quantification,"Hello, I have a `float32 pb` model, and I want to convert it to an `int8 pb` model, how should I operate it?"
50784,NotImplementedError: Cannot convert a symbolic Tensor (lstm_20/strided_slice:0) to a numpy array...,"My code:

model = Sequential()

model.add(LSTM(50, return_sequences=True, input_shape=(50, 1)))

model.add(LSTM(64, return_sequences=False))

model.add(Dense(1, activation='linear'))

model.compile(loss='mse', optimizer='rmsprop')

model.summary()

-------------------------------------------------------------------------

NotImplementedError                       Traceback (most recent call last)
<ipython-input-111-b51fee4336b3> in <module>
      1 model = Sequential()
      2 
----> 3 model.add(LSTM(50, return_sequences=True, input_shape=(50, 1)))
      4 
      5 model.add(LSTM(64, return_sequences=False))

~\anaconda3\lib\site-packages\tensorflow\python\training\tracking\base.py in _method_wrapper(self, *args, **kwargs)
    455         self._checkpoint.restore_saveables(tensor_saveables, python_saveables))
    456     return restore_ops
--> 457 
    458   @property
    459   def checkpoint(self):

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\sequential.py in add(self, layer)
    204               batch_shape=batch_shape, dtype=dtype, name=layer.name + '_input')
    205           # This will build the current layer
--> 206           # and create the node connecting the current layer
    207           # to the input layer we just created.
    208           layer(x)

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)
    661 
    662     # If any of `initial_state` or `constants` are specified and are Keras
--> 663     # tensors, then add them to the inputs and temporarily modify the
    664     # input_spec to include them.
    665 

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\base_layer.py in __call__(self, *args, **kwargs)
    923       ValueError: if the layer's `call` method returns None (an invalid value).
    924       RuntimeError: if `super().__init__()` was not called in the constructor.
--> 925     """"""
    926     if not hasattr(self, '_thread_local'):
    927       raise RuntimeError(

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)
   1115         layer=self, inputs=inputs, build_graph=True, training=training_value):
   1116       # Symbolic execution on symbolic tensors. We will attempt to build
-> 1117       # the corresponding TF subgraph inside `backend.get_graph()`
   1118       # TODO(reedwm): We should assert input compatibility after the inputs
   1119       # are casted, not before.

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent_v2.py in call(self, inputs, mask, training, initial_state)
   1106         recurrent_activation=recurrent_activation,
   1107         use_bias=use_bias,
-> 1108         kernel_initializer=kernel_initializer,
   1109         recurrent_initializer=recurrent_initializer,
   1110         bias_initializer=bias_initializer,

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in _process_inputs(self, inputs, initial_state, constants)
    860 
    861     if len(initial_state) != len(self.states):
--> 862       raise ValueError('Layer has ' + str(len(self.states)) +
    863                        ' states but was passed ' + str(len(initial_state)) +
    864                        ' initial states.')

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in get_initial_state(self, inputs)
    643           inputs=None, batch_size=batch_size, dtype=dtype)
    644     else:
--> 645       init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,
    646                                                dtype)
    647     # Keras RNN expect the states in a list, even if it's a single state tensor.

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in get_initial_state(self, inputs, batch_size, dtype)
   2521   ""We find that LSTM augmented by 'peephole connections' from its internal
   2522   cells to its multiplicative gates can learn the fine distinction between
-> 2523   sequences of spikes spaced either 50 or 49 time steps apart without the help
   2524   of any short training exemplars.""
   2525 

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype)
   2966       return x
   2967     if isinstance(x, tuple):
-> 2968       return list(x)
   2969     return [x]
   2970 

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in _generate_zero_filled_state(batch_size_tensor, state_size, dtype)
   2982 
   2983 def _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):
-> 2984   if inputs is not None:
   2985     batch_size = array_ops.shape(inputs)[0]
   2986     dtype = inputs.dtype

~\anaconda3\lib\site-packages\tensorflow\python\util\nest.py in map_structure(func, *structure, **kwargs)
    633     ValueError: If no structure is provided or if the structures do not match
    634       each other by type.
--> 635     ValueError: If wrong keyword arguments are provided.
    636   """"""
    637   if not callable(func):

~\anaconda3\lib\site-packages\tensorflow\python\util\nest.py in <listcomp>(.0)
    633     ValueError: If no structure is provided or if the structures do not match
    634       each other by type.
--> 635     ValueError: If wrong keyword arguments are provided.
    636   """"""
    637   if not callable(func):

~\anaconda3\lib\site-packages\tensorflow\python\keras\layers\recurrent.py in create_zeros(unnested_state_size)
   2979   return (hasattr(state_size, '__len__') and
   2980           not isinstance(state_size, tensor_shape.TensorShape))
-> 2981 
   2982 
   2983 def _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):

~\anaconda3\lib\site-packages\tensorflow\python\util\dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~\anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py in wrapped(*args, **kwargs)
   2745                          [1, 2, 3],
   2746                          [0, 4, 5]],
-> 2747                         [[1, 2, 0],
   2748                          [5, 6, 4],
   2749                          [6, 1, 2],

~\anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py in zeros(shape, dtype, name)
   2792       the left (right-pads the row). It is the packing format LAPACK uses.
   2793       cuSPARSE uses ""LEFT_RIGHT"", which is the opposite alignment.
-> 2794   """"""
   2795   return gen_array_ops.matrix_set_diag_v3(
   2796       input=input, diagonal=diagonal, k=k, align=align, name=name)

~\anaconda3\lib\site-packages\tensorflow\python\ops\array_ops.py in _constant_if_small(value, shape, dtype, name)
   2730           [7, 5, 7, 7],
   2731           [7, 7, 6, 7]]]
-> 2732 
   2733   # A superdiagonal (per batch).
   2734   tf.matrix_set_diag(input, diagonal, k = 1)

<__array_function__ internals> in prod(*args, **kwargs)

~\anaconda3\lib\site-packages\numpy\core\fromnumeric.py in prod(a, axis, dtype, out, keepdims, initial, where)
   3028         but the type of the resulting values will be cast if necessary.
   3029 
-> 3030     Returns
   3031     -------
   3032     cumprod : ndarray

~\anaconda3\lib\site-packages\numpy\core\fromnumeric.py in _wrapreduction(obj, ufunc, method, axis, dtype, out, **kwargs)
     85                 return reduction(axis=axis, out=out, **passkwargs)
     86 
---> 87     return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
     88 
     89 

~\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py in __array__(self)
    843   # operators to run when the left operand is an ndarray, because it
    844   # accords the Tensor class higher priority than an ndarray, or a
--> 845   # numpy matrix.
    846   # TODO(mrry): Convert this to using numpy's __numpy_ufunc__
    847   # mechanism, which allows more control over how Tensors interact

NotImplementedError: Cannot convert a symbolic Tensor (lstm_20/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported


-----------------------------------------------------------------------------------------------

Tensorflow : 2.4.1
numpy : 1.19.5

NumPy version 1.20 or later has been reported to be a problem, so I changed it to 1.19.5 but it is the same.
Even if I downgrade TensorFlow to 2.2, it's the same.
What action should I take?"
50783,Getting clang errors while building tensorflow-lite using bazel on windows machine.,"**System information**
- OS Platform and Distribution : Windows 10 Home 
- TensorFlow installed from : source
- TensorFlow version: Building from top of 926e8aaf98078d57175795025bf3f8a93db813bc
- Python version: 3.9.6
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): MSVC 2019
- CUDA/cuDNN version: NA




**Describe the problem**
I'm trying to compile tflite with custom operations using bazel. This is the command I'm using -  
`.\bazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain tensorflow/lite/java:tensorflow-lite` but the build is failing every-time with the following errors - 

```
 C++ compilation of rule '@com_google_absl//absl/base:base' failed (Exit 1): clang failed: error executing command
  cd C:/users/gojo/_bazel_gojo/o26qhjr4/execroot/org_tensorflow
  SET ANDROID_BUILD_TOOLS_VERSION=30.0.3
    SET ANDROID_NDK_API_LEVEL=21
    SET ANDROID_NDK_HOME=C:/Users/gojo/AppData/Local/Android/Sdk/ndk/21.4.7075529
    SET ANDROID_SDK_API_LEVEL=30
    SET ANDROID_SDK_HOME=C:/Users/gojo/AppData/Local/Android/Sdk
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Program Files\jdk-11.0.2\;C:\Users\gojo\Downloads\bazel.exe;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\msys64\usr\bin;C:\Users\gojo\AppData\Roaming\Python\Python39\Scripts;C:\Users\gojo\Downloads\bazel.exe;C:\Users\gojo\AppData\Local\Programs\Python\Python39\Scripts\;C:\Users\gojo\AppData\Local\Programs\Python\Python39\;C:\Users\gojo\AppData\Local\Microsoft\WindowsApps;C:\Users\gojo\AppData\Local\Programs\Microsoft VS Code\bin;
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/gojo/AppData/Local/Programs/Python/Python39/python.exe
    SET PYTHON_LIB_PATH=C:/Users/gojo/AppData/Local/Programs/Python/Python39/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
  external/androidndk/ndk/toolchains/llvm/prebuilt/windows-x86_64/bin/clang -D__ANDROID_API__=21 -isystemexternal/androidndk/ndk/sysroot/usr/include/arm-linux-androideabi -target armv7-none-linux-androideabi -march=armv7-a -mfloat-abi=softfp -mfpu=vfpv3-d16 -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/windows-x86_64 -fpic -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig -Werror=return-type -Werror=int-to-pointer-cast -Werror=pointer-to-int-cast -Werror=implicit-function-declaration -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/android-armeabi-v7a-opt/bin/external/com_google_absl/absl/base/_objs/base/cycleclock.pic.d -frandom-seed=bazel-out/android-armeabi-v7a-opt/bin/external/com_google_absl/absl/base/_objs/base/cycleclock.pic.o -fPIC -iquote external/com_google_absl -iquote bazel-out/android-armeabi-v7a-opt/bin/external/com_google_absl /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /std:c++14 --std=c++11 -Wall -Wextra -Wcast-qual -Wconversion-null -Wformat-security -Wmissing-declarations -Woverlength-strings -Wpointer-arith -Wundef -Wunused-local-typedefs -Wunused-result -Wvarargs -Wvla -Wwrite-strings -DNOMINMAX --sysroot=external/androidndk/ndk/platforms/android-21/arch-arm -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c external/com_google_absl/absl/base/internal/cycleclock.cc -o bazel-out/android-armeabi-v7a-opt/bin/external/com_google_absl/absl/base/_objs/base/cycleclock.pic.o
Execution platform: @local_execution_config_platform//:platform
clang: error: no such file or directory: '/W0'
clang: error: no such file or directory: '/D_USE_MATH_DEFINES'
clang: error: no such file or directory: '/experimental:preprocessor'
clang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions'
clang: error: no such file or directory: '/std:c++14'
Target //tensorflow/lite/java:tensorflow-lite failed to build
```
"
50781,tf.keras.preprocessing.timeseries_dataset_from_array function is broken in latest code,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- TensorFlow installed from (source or binary): latest source
- TensorFlow version (use command below): latest source
- Python version: 3.x.x
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.4
- GPU model and memory:

**Describe the current behavior**
The error says that there is a circular Keras reference. However , if i install last month's code, it works.

**Describe the expected behavior**
"
50779,"when i use tf2.4, tf.image_resize takes more time than tf1.2","when i use tf.compact.v1 to run the tensorflow1.2 code , find that tf.image_resize takes 40% longer
Besides，unpool and conv2d_transpose encountered the same phenomenon
Is this a bug or a normal phenomenon?"
50777,gast_archive URL error,"There's an error in the mirrored URL for gast_archive:

https://github.com/tensorflow/tensorflow/blob/e7017fd09cc249d0d522a2b77f0dcae4642dd04a/tensorflow/workspace2.bzl#L441
That URL gives an error, ""The specified key does not exist.""  The URL should be `https://storage.googleapis.com/mirror.tensorflow.org/files.pythonhosted.org/packages/83/4a/07c7e59cef23fb147454663c3271c21da68ba2ab141427c20548ae5a8a4d/gast-0.4.0.tar.gz`

We've only whitelisted storage.googleapis.com in our firewall, so when the build tries to fall back to the official files.pythonhosted.org source, it fails."
50776,MKL XLA CPU Runtime Test Failure,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 9.3.0


**Describe the problem**

When MKL is enabled, the `tensorflow/compiler/xla/service/cpu:cpu_runtime_test` unit test fails while attempting to load the  [third_party/intel_mkl_ml/include/mkl_cblas.h](https://github.com/tensorflow/tensorflow/blob/81b2bcb9ba3316759a08db614bd76d572a1cb320/tensorflow/compiler/xla/service/cpu/runtime_matmul_mkl.h#L22) header file.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel test --config=mkl //tensorflow/compiler/xla/service/cpu:cpu_runtime_test`

**Any other info / logs**

```
ERROR: /opt/tensorflow/tensorflow-source/tensorflow/compiler/xla/service/cpu/BUILD:858:11: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu:cpu_runtime_test' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/xla/service/cpu/_objs/cpu_runtime_test/cpu_runtime_test.d ... (remaining 390 argument(s) skipped)
cc1plus: warning: command line option ‘-Wno-pointer-sign’ is valid for C/ObjC but not for C++
In file included from tensorflow/compiler/xla/service/cpu/cpu_runtime_test.cc:28:
./tensorflow/compiler/xla/service/cpu/runtime_matmul_mkl.h:22:10: fatal error: third_party/intel_mkl_ml/include/mkl_cblas.h: No such file or directory
   22 | #include ""third_party/intel_mkl_ml/include/mkl_cblas.h""
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
```
"
50774,tf.keras.models.save_model not saving the probabilistic_model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Tensorflow_probability.__version__:  '0.13.0'
- Python version: 3.8.10
- CUDA/cuDNN version: cuda_11.2.r11.2/compiler.29373293_0 
- GPU model and memory: 12Gb TitanXP

**Describe the current behavior**
Tensorflow model with tensorflow_probability layers creates errors while saving using 

** The model is created using the below code**
`
_model = Sequential([
        Conv2D(8, 5, activation='relu', padding='valid', input_shape=input_shape),
        MaxPooling2D(6),
        Flatten(),
        Dense(10),
        tfpl.OneHotCategorical(10)
    ])
    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)

probabilistic_model = get_probabilistic_model(
    input_shape=(28, 28, 1), 
    loss=nll, 
    optimizer=RMSprop(), 
    metrics=['accuracy']

probabilistic_model.fit(x_train, y_train_oh, epochs=5)

_
`

![probabilistic_model_summary](https://user-images.githubusercontent.com/70491128/125684752-f0aaec59-e4a3-45a6-8acd-dfdd5589851d.png)

**For saving the model**
`_probabilistic_model.save('/tmp/model/probabilistic_model')_
`
The saving steps create the error as shown below.

`
_OperatorNotAllowedInGraphError            Traceback (most recent call last)
/tmp/ipykernel_11377/1109926494.py in <module>
----> 1 probabilistic_model.save('/tmp/model/probabilistic_model')

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)
   2109     """"""
   2110     # pylint: enable=line-too-long
-> 2111     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
   2112                     signatures, options, save_traces)
   2113 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)
    148   else:
    149     with generic_utils.SharedObjectSavingScope():
--> 150       saved_model_save.save(model, filepath, overwrite, include_optimizer,
    151                             signatures, options, save_traces)
    152 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)
     87   with K.deprecated_internal_learning_phase_scope(0):
     88     with utils.keras_option_scope(save_traces):
---> 89       saved_nodes, node_paths = save_lib.save_and_return_nodes(
     90           model, filepath, signatures, options)
     91 

~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in save_and_return_nodes(obj, export_dir, signatures, options, raise_metadata_warning, experimental_skip_checkpoint)
   1101 
   1102   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (
-> 1103       _build_meta_graph(obj, signatures, options, meta_graph_def,
   1104                         raise_metadata_warning))
   1105   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION

~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, signatures, options, meta_graph_def, raise_metadata_warning)
   1288 
   1289   with save_context.save_context(options):
-> 1290     return _build_meta_graph_impl(obj, signatures, options, meta_graph_def,
   1291                                   raise_metadata_warning)

~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in _build_meta_graph_impl(obj, signatures, options, meta_graph_def, raise_metadata_warning)
   1205   checkpoint_graph_view = _AugmentedGraphView(obj)
   1206   if signatures is None:
-> 1207     signatures = signature_serialization.find_function_to_export(
   1208         checkpoint_graph_view)
   1209 

~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/signature_serialization.py in find_function_to_export(saveable_view)
     97   # If the user did not specify signatures, check the root object for a function
     98   # that can be made into a signature.
---> 99   functions = saveable_view.list_functions(saveable_view.root)
    100   signature = functions.get(DEFAULT_SIGNATURE_ATTR, None)
    101   if signature is not None:

~/tf2/lib/python3.8/site-packages/tensorflow/python/saved_model/save.py in list_functions(self, obj)
    152     obj_functions = self._functions.get(obj, None)
    153     if obj_functions is None:
--> 154       obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access
    155           self._serialization_cache)
    156       self._functions[obj] = obj_functions

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in _list_functions_for_serialization(self, serialization_cache)
   2711     self.test_function = None
   2712     self.predict_function = None
-> 2713     functions = super(
   2714         Model, self)._list_functions_for_serialization(serialization_cache)
   2715     self.train_function = train_function

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py in _list_functions_for_serialization(self, serialization_cache)
   3014 
   3015   def _list_functions_for_serialization(self, serialization_cache):
-> 3016     return (self._trackable_saved_model_saver
   3017             .list_functions_for_serialization(serialization_cache))
   3018 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/base_serialization.py in list_functions_for_serialization(self, serialization_cache)
     90       return {}
     91 
---> 92     fns = self.functions_to_serialize(serialization_cache)
     93 
     94     # The parent AutoTrackable class saves all user-defined tf.functions, and

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in functions_to_serialize(self, serialization_cache)
     71 
     72   def functions_to_serialize(self, serialization_cache):
---> 73     return (self._get_serialized_attributes(
     74         serialization_cache).functions_to_serialize)
     75 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes(self, serialization_cache)
     87       return serialized_attr
     88 
---> 89     object_dict, function_dict = self._get_serialized_attributes_internal(
     90         serialization_cache)
     91 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/model_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)
     51     # the ones serialized by Layer.
     52     objects, functions = (
---> 53         super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(
     54             serialization_cache))
     55     functions['_default_save_signature'] = default_signature

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/layer_serialization.py in _get_serialized_attributes_internal(self, serialization_cache)
     97     """"""Returns dictionary of serialized attributes.""""""
     98     objects = save_impl.wrap_layer_objects(self.obj, serialization_cache)
---> 99     functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
    100     # Attribute validator requires that the default save signature is added to
    101     # function dict, even if the value is None.

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in wrap_layer_functions(layer, serialization_cache)
    202           if isinstance(fn, LayerCall):
    203             fn = fn.wrapped_call
--> 204           fn.get_concrete_function()
    205 
    206   # Restore overwritten functions and losses

/usr/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback)
    118         if type is None:
    119             try:
--> 120                 next(self.gen)
    121             except StopIteration:
    122                 return False

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in tracing_scope()
    365       if training is not None:
    366         with K.deprecated_internal_learning_phase_scope(training):
--> 367           fn.get_concrete_function(*args, **kwargs)
    368       else:
    369         fn.get_concrete_function(*args, **kwargs)

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in get_concrete_function(self, *args, **kwargs)
   1365       ValueError: if this object has not yet been called on concrete values.
   1366     """"""
-> 1367     concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
   1368     concrete._garbage_collector.release()  # pylint: disable=protected-access
   1369     return concrete

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)
   1282       # In this case we have not created variables on the first call. So we can
   1283       # run the first trace but we should fail if variables are created.
-> 1284       concrete = self._stateful_fn._get_concrete_function_garbage_collected(  # pylint: disable=protected-access
   1285           *args, **kwargs)
   1286       if self._created_variables:

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)
   3098       args, kwargs = None, None
   3099     with self._lock:
-> 3100       graph_function, _ = self._maybe_define_function(args, kwargs)
   3101       seen_names = set()
   3102       captured = object_identity.ObjectIdentitySet(

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3442 
   3443           self._function_cache.missed.add(call_context_key)
-> 3444           graph_function = self._create_graph_function(args, kwargs)
   3445           self._function_cache.primary[cache_key] = graph_function
   3446 

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3277     arg_names = base_arg_names + missing_arg_names
   3278     graph_function = ConcreteFunction(
-> 3279         func_graph_module.func_graph_from_py_func(
   3280             self._name,
   3281             self._python_function,

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    997         _, original_func = tf_decorator.unwrap(python_func)
    998 
--> 999       func_outputs = python_func(*func_args, **func_kwargs)
   1000 
   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    670         # the function a weak reference to itself to avoid a reference cycle.
    671         with OptionalXlaContext(compile_with_xla):
--> 672           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    673         return out
    674 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in wrapper(*args, **kwargs)
    597       with autocast_variable.enable_auto_cast_variables(
    598           layer._compute_dtype_object):  # pylint: disable=protected-access
--> 599         ret = method(*args, **kwargs)
    600     _restore_layer_losses(original_losses)
    601     return ret

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in wrap_with_training_arg(*args, **kwargs)
    163       return wrapped_call(*args, **kwargs)
    164 
--> 165     return control_flow_util.smart_cond(
    166         training, lambda: replace_training_and_call(True),
    167         lambda: replace_training_and_call(False))

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/control_flow_util.py in smart_cond(pred, true_fn, false_fn, name)
    107     return control_flow_ops.cond(
    108         pred, true_fn=true_fn, false_fn=false_fn, name=name)
--> 109   return smart_module.smart_cond(
    110       pred, true_fn=true_fn, false_fn=false_fn, name=name)
    111 

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py in smart_cond(pred, true_fn, false_fn, name)
     52   if pred_value is not None:
     53     if pred_value:
---> 54       return true_fn()
     55     else:
     56       return false_fn()

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in <lambda>()
    164 
    165     return control_flow_util.smart_cond(
--> 166         training, lambda: replace_training_and_call(True),
    167         lambda: replace_training_and_call(False))
    168 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in replace_training_and_call(training)
    161     def replace_training_and_call(training):
    162       set_training_arg(training, training_arg_index, args, kwargs)
--> 163       return wrapped_call(*args, **kwargs)
    164 
    165     return control_flow_util.smart_cond(

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in call(inputs, *args, **kwargs)
    679     return layer.keras_api.__call__  # pylint: disable=protected-access
    680   def call(inputs, *args, **kwargs):
--> 681     return call_and_return_conditional_losses(inputs, *args, **kwargs)[0]
    682   return _create_call_fn_decorator(layer, call)
    683 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in __call__(self, *args, **kwargs)
    637   def __call__(self, *args, **kwargs):
    638     self._maybe_trace(args, kwargs)
--> 639     return self.wrapped_call(*args, **kwargs)
    640 
    641   def get_concrete_function(self, *args, **kwargs):

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    887 
    888       with OptionalXlaContext(self._jit_compile):
--> 889         result = self._call(*args, **kwds)
    890 
    891       new_tracing_count = self.experimental_get_tracing_count()

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    922       # In this case we have not created variables on the first call. So we can
    923       # run the first trace but we should fail if variables are created.
--> 924       results = self._stateful_fn(*args, **kwds)
    925       if self._created_variables:
    926         raise ValueError(""Creating variables on a non-first call to a function""

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   3020     with self._lock:
   3021       (graph_function,
-> 3022        filtered_flat_args) = self._maybe_define_function(args, kwargs)
   3023     return graph_function._call_flat(
   3024         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3442 
   3443           self._function_cache.missed.add(call_context_key)
-> 3444           graph_function = self._create_graph_function(args, kwargs)
   3445           self._function_cache.primary[cache_key] = graph_function
   3446 

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3277     arg_names = base_arg_names + missing_arg_names
   3278     graph_function = ConcreteFunction(
-> 3279         func_graph_module.func_graph_from_py_func(
   3280             self._name,
   3281             self._python_function,

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    997         _, original_func = tf_decorator.unwrap(python_func)
    998 
--> 999       func_outputs = python_func(*func_args, **func_kwargs)
   1000 
   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    670         # the function a weak reference to itself to avoid a reference cycle.
    671         with OptionalXlaContext(compile_with_xla):
--> 672           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    673         return out
    674 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in wrapper(*args, **kwargs)
    597       with autocast_variable.enable_auto_cast_variables(
    598           layer._compute_dtype_object):  # pylint: disable=protected-access
--> 599         ret = method(*args, **kwargs)
    600     _restore_layer_losses(original_losses)
    601     return ret

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in wrap_with_training_arg(*args, **kwargs)
    163       return wrapped_call(*args, **kwargs)
    164 
--> 165     return control_flow_util.smart_cond(
    166         training, lambda: replace_training_and_call(True),
    167         lambda: replace_training_and_call(False))

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/control_flow_util.py in smart_cond(pred, true_fn, false_fn, name)
    107     return control_flow_ops.cond(
    108         pred, true_fn=true_fn, false_fn=false_fn, name=name)
--> 109   return smart_module.smart_cond(
    110       pred, true_fn=true_fn, false_fn=false_fn, name=name)
    111 

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/smart_cond.py in smart_cond(pred, true_fn, false_fn, name)
     52   if pred_value is not None:
     53     if pred_value:
---> 54       return true_fn()
     55     else:
     56       return false_fn()

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in <lambda>()
    164 
    165     return control_flow_util.smart_cond(
--> 166         training, lambda: replace_training_and_call(True),
    167         lambda: replace_training_and_call(False))
    168 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/utils.py in replace_training_and_call(training)
    161     def replace_training_and_call(training):
    162       set_training_arg(training, training_arg_index, args, kwargs)
--> 163       return wrapped_call(*args, **kwargs)
    164 
    165     return control_flow_util.smart_cond(

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py in call_and_return_conditional_losses(*args, **kwargs)
    661   def call_and_return_conditional_losses(*args, **kwargs):
    662     """"""Returns layer (call_output, conditional losses) tuple.""""""
--> 663     call_output = layer_call(*args, **kwargs)
    664     if version_utils.is_v1_layer_or_model(layer):
    665       conditional_losses = layer.get_losses_for(

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in call(self, inputs, training, mask)
    378       if not self.built:
    379         self._init_graph_network(self.inputs, self.outputs)
--> 380       return super(Sequential, self).call(inputs, training=training, mask=mask)
    381 
    382     outputs = inputs  # handle the corner case where self.layers is empty

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py in call(self, inputs, training, mask)
    418         a list of tensors if there are more than one outputs.
    419     """"""
--> 420     return self._run_internal_graph(
    421         inputs, training=training, mask=mask)
    422 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py in _run_internal_graph(self, inputs, training, mask)
    554 
    555         args, kwargs = node.map_arguments(tensor_dict)
--> 556         outputs = node.layer(*args, **kwargs)
    557 
    558         # Update tensor_dict.

~/tf2/lib/python3.8/site-packages/tensorflow_probability/python/layers/distribution_layer.py in __call__(self, inputs, *args, **kwargs)
    228   def __call__(self, inputs, *args, **kwargs):
    229     self._enter_dunder_call = True
--> 230     distribution, _ = super(DistributionLambda, self).__call__(
    231         inputs, *args, **kwargs)
    232     self._enter_dunder_call = False

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __iter__(self)
    518   def __iter__(self):
    519     if not context.executing_eagerly():
--> 520       self._disallow_iteration()
    521 
    522     shape = self._shape_tuple()

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _disallow_iteration(self)
    511       self._disallow_when_autograph_disabled(""iterating over `tf.Tensor`"")
    512     elif ag_ctx.control_status_ctx().status == ag_ctx.Status.ENABLED:
--> 513       self._disallow_when_autograph_enabled(""iterating over `tf.Tensor`"")
    514     else:
    515       # Default: V1-style Graph execution.

~/tf2/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _disallow_when_autograph_enabled(self, task)
    487 
    488   def _disallow_when_autograph_enabled(self, task):
--> 489     raise errors.OperatorNotAllowedInGraphError(
    490         ""{} is not allowed: AutoGraph did convert this function. This might""
    491         "" indicate you are trying to use an unsupported feature."".format(task))

OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature._
`

**Workaround works with limited capability** as shown in [https://github.com/tensorflow/probability/issues/325#issuecomment-477213850](url)
But this only saves the weights and not other details of the model.

**Workaround works with h5 format**
h5 format saving works, but cannot load the model

`
loaded_model = tf.keras.models.load_model('/tmp/model/probabilistic_model.h5')

`
Error while using h5 format for saving and then loading the model is shown below.
`
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/ipykernel_11377/686337657.py in <module>
----> 1 loaded_model = tf.keras.models.load_model('/tmp/model/probabilistic_model.h5')

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py in load_model(filepath, custom_objects, compile, options)
    199         if (h5py is not None and
    200             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--> 201           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,
    202                                                   compile)
    203 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    178       model_config = model_config.decode('utf-8')
    179     model_config = json_utils.decode(model_config)
--> 180     model = model_config_lib.model_from_config(model_config,
    181                                                custom_objects=custom_objects)
    182 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/saving/model_config.py in model_from_config(config, custom_objects)
     57                     '`Sequential.from_config(config)`?')
     58   from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top
---> 59   return deserialize(config, custom_objects=custom_objects)
     60 
     61 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    157   """"""
    158   populate_deserializable_objects()
--> 159   return generic_utils.deserialize_keras_object(
    160       config,
    161       module_objects=LOCAL.ALL_OBJECTS,

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    666 
    667       if 'custom_objects' in arg_spec.args:
--> 668         deserialized_obj = cls.from_config(
    669             cls_config,
    670             custom_objects=dict(

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py in from_config(cls, config, custom_objects)
    495     model = cls(name=name)
    496     for layer_config in layer_configs:
--> 497       layer = layer_module.deserialize(layer_config,
    498                                        custom_objects=custom_objects)
    499       model.add(layer)

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/serialization.py in deserialize(config, custom_objects)
    157   """"""
    158   populate_deserializable_objects()
--> 159   return generic_utils.deserialize_keras_object(
    160       config,
    161       module_objects=LOCAL.ALL_OBJECTS,

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    651     # In this case we are dealing with a Keras config dictionary.
    652     config = identifier
--> 653     (cls, cls_config) = class_and_config_for_serialized_keras_object(
    654         config, module_objects, custom_objects, printable_module_name)
    655 

~/tf2/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py in class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
    554   cls = get_registered_object(class_name, custom_objects, module_objects)
    555   if cls is None:
--> 556     raise ValueError(
    557         'Unknown {}: {}. Please ensure this object is '
    558         'passed to the `custom_objects` argument. See '

ValueError: Unknown layer: OneHotCategorical. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.
`


**Describe the expected behavior**
_Saves a probabilistic_model as a TensorFlow SavedModel_ 
"
50769,apply_gradients() with Adam Optimizer gives error,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: maOS 11.4
- TensorFlow version: 2.5.0
- Python version: 3.9.6
- GPU model and memory: Apple M1 

**Describe the current behavior**
SGD and Adam gives error when using **apply_gradients()**, please see output and source code below 
When adam is used in **model.fit()** it works normally
- Do you want to contribute a PR? (yes/no): no

**Other info / logs** 
Installed TensorFlow after following instructions from [Getting Started with tensorflow-metal PluggableDevice](https://developer.apple.com/metal/tensorflow-plugin/)

Source code for training: 
```
'''---- Training -----'''
model=tf.keras.Sequential() # model has 1 hidden layer
model.add(tf.keras.layers.Dense(20,input_shape=(dimVectors,),activation='relu'))
model.add(tf.keras.layers.Dense(5,activation='softmax')) # 5 is ouput shape
optimizer=tf.keras.optimizers.Adam(
    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,
    name='Adam'
)
epochs=10
# without padding
wordVectors=tf.Variable(tf.convert_to_tensor(wordVectors))
trainLabels=tf.keras.utils.to_categorical(trainLabels,5)
for epoch in range(epochs):
    sent_count=0
    print(""---Epoch no:"",epoch,""----"")
    #one sentence in each batch
    for sent in train_Sentences:
        if((sent_count%10)==0):
            print(""Optimizing sentence number"",sent_count+1)
        sent_count+=1
        len_sent=len(sent)
        one_hot=np.zeros((len_sent,total_words))
        label=(trainLabels[sent_count-1]).reshape(-1,1)
        label=tf.convert_to_tensor(label)
        for i,word in enumerate(sent):
            index=token_dict[word]
            one_hot[i,index]=1
        one_hot=tf.convert_to_tensor(one_hot)
        with tf.GradientTape() as tape:
            #tape.watch(wordVectors)
            feature=tf.matmul(one_hot,wordVectors)
            feature_sum=tf.math.reduce_sum(feature,axis=0,keepdims=True)
            y_pred=model(feature_sum)
            loss=tf.losses.MeanSquaredError()(y_pred,label)
        gradients=tape.gradient(loss,[wordVectors]+model.trainable_variables)
        if(((sent_count-1)%10)==0):
                print(""Loss: "",loss)
        '''wordVectors.assign(wordVectors-learning_rate*gradients[0])
        (model.trainable_variables[0]).assign(model.trainable_variables[0]-learning_rate*gradients[1])
        (model.trainable_variables[1]).assign(model.trainable_variables[1]-learning_rate*gradients[2])
        (model.trainable_variables[2]).assign(model.trainable_variables[2]-learning_rate*gradients[3])
        (model.trainable_variables[3]).assign(model.trainable_variables[3]-learning_rate*gradients[4])'''
        optimizer.apply_gradients(zip(gradients,[wordVectors]+model.trainable_variables))
    
```
Traceback :
```
Traceback (most recent call last):
  File ""/Users/arpitjjw/Desktop/Training Program/Module 2/Sentiment_day1/model-tf.py"", line 152, in <module>
    optimizer.apply_gradients(zip(gradients,[wordVectors]+model.trainable_variables))
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 667, in apply_gradients
    return self._distributed_apply(strategy, grads_and_vars, name,
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 714, in _distributed_apply
    update_op = distribution.extended.update(
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2576, in update
    return self._update(var, fn, args, kwargs, group)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 3622, in _update
    return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 3628, in _update_non_slot
    result = fn(*args, **kwargs)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py"", line 597, in wrapper
    return func(*args, **kwargs)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 697, in apply_grad_to_update_var
    update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/adam.py"", line 172, in _resource_apply_dense
    return gen_training_ops.ResourceApplyAdam(
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/util/tf_export.py"", line 404, in wrapper
    return f(**kwargs)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/ops/gen_training_ops.py"", line 1427, in resource_apply_adam
    _ops.raise_from_not_ok_status(e, name)
  File ""/Users/arpitjjw/miniforge3/envs/tf-m1/lib/python3.9/site-packages/tensorflow/python/framework/ops.py"", line 6897, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.NotFoundError: No registered 'ResourceApplyAdam' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyAdam}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_DOUBLE, use_locking=true, use_nesterov=false
	.  Registered:  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
 [Op:ResourceApplyAdam]
```
"
50766,Incomplete Installation of Tensorflow FreeBSD,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): FreeBSD 13
- TensorFlow installed from (source or binary): Source
- TensorFlow version: v2.1.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.29.0
- GCC/Compiler version (if compiling from source):  clang version 11.0.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
While tensorflow will build on FreeBSD, the installation is incomplete and only provides lib/python3.8/site-packages/tensorflow_core with nothing else.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Commands for building:
`        @cd ${WRKSRC} && \
                bazel --bazelrc=""${WRKDIR}/bazelrc"" ${BAZEL_BOOT} build ${BAZEL_COPT} --host_copt=""-I${LOCALBASE}/include"" \
                --host_linkopt=""-L${LOCALBASE}/lib"" --linkopt=""-L${LOCALBASE}/lib"" --copt=""-I${LOCALBASE}/include"" \
                --verbose_failures -s --incompatible_restrict_string_escapes=false \
                --distdir=${WORKDIR}/bazel-dist --linkopt='-fuse-ld=lld' \
                //tensorflow:libtensorflow_framework.so \
                //tensorflow:libtensorflow.so \
                //tensorflow:libtensorflow_cc.so \
                //tensorflow/tools/pip_package:build_pip_package
`
The creation of the pip package:

`
        @cd ${WRKSRC} && ${SETENV} TMPDIR=${WRKDIR} \
                bazel-bin/tensorflow/tools/pip_package/build_pip_package \
                ${WRKDIR}/whl
`

The following variables in the above command contain the following information:

LOCALBASE=/usr/local
BAZEL_BOOT= --output_user_root=${WRKDIR}/bazel_out
BAZEL_COPT=""-c opt --copt=-march=native --copt=-mfpmath=sse""

**Any other info / logs**
I'm assuming the problem is just from the build files failing to default to a suitable platform and is falling back to default values. If I could be pointed into the right direction and files so that I could move forward and patch them it would be helpful.
"
50765,Memory leak in custom training loop + tf.function ,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18 (google colab)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below):  v2.5.0-0-ga4dfb8d1a71 2.5.0
- Python version: 3.7
- CUDA/cuDNN version: Build cuda_11.0_bu.TC445_37.28845127_0
- GPU model and memory: Tesla T4 - 15109MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I'm encountering a subtle memory leak, and unable to determine the source using tracemalloc. I run the code in google colab, which is meant to optimize hyperparameters for a custom ppo agent. Also, the speed at which the leak happens varies: sometimes it happens within 10-20 minutes of runtime / 5-10 iterations while on other times it may take up to an hour.

**Describe the expected behavior**

Memory usage should be constant over time, since there are no objects stored in memory intentionally as the training progresses.

**Standalone code to reproduce the issue**

Here's a colab [notebook](https://colab.research.google.com/drive/1mIO3Pd-HSskvIrcl3Bp3Evg_MzAEuwPc?usp=sharing)

**Other info / logs**

And here are the resulting [memory snapshots](https://drive.google.com/file/d/1RH89X5B5xsUY8a1RA4Gh9WmEIqXhs84R/view?usp=sharing) at 15 consecutive iterations up to the crash, which do not show any particular red flags. Besides, by summing up the `size` column of the most recent snapshot, it totals 967249710 bytes ~= 1GB, which is weird because the available memory on colab ~= 12GB. 

Here's a log after crashing:


```
   Timestamp                  Level    Message

Jul 14, 2021, 11:07:41 AM | WARNING | WARNING:root:kernel a3ecdd9e-1765-4f67-af0e-60c198c896ec restarted
Jul 14, 2021, 11:07:41 AM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports
Jul 14, 2021, 10:22:16 AM | WARNING | 2021-07-14 08:22:16.518184: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
Jul 14, 2021, 10:22:13 AM | WARNING | 2021-07-14 08:22:13.939377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
Jul 14, 2021, 10:21:50 AM | WARNING | 2021-07-14 08:21:50.140299: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8004
Jul 14, 2021, 10:21:47 AM | WARNING | 2021-07-14 08:21:47.841310: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
Jul 14, 2021, 10:21:44 AM | WARNING | 2021-07-14 08:21:44.642335: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz
Jul 14, 2021, 10:21:44 AM | WARNING | 2021-07-14 08:21:44.559306: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.355834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.355771: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.354979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.354000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.352104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.351844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0: N
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.351828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264] 0
Jul 14, 2021, 10:21:30 AM | WARNING | 2021-07-14 08:21:30.351772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.206565: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.203344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.202526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.201577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:25 AM | WARNING | coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
Jul 14, 2021, 10:21:25 AM | WARNING | pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.201438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.200536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.199581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.195723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.194598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.194398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.190679: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
Jul 14, 2021, 10:21:25 AM | WARNING | 2021-07-14 08:21:25.144200: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.851273: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.832903: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.660570: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.660379: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.533359: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
Jul 14, 2021, 10:21:24 AM | WARNING | coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
Jul 14, 2021, 10:21:24 AM | WARNING | pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.533253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.532176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
Jul 14, 2021, 10:21:24 AM | WARNING | 2021-07-14 08:21:24.461038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
Jul 14, 2021, 10:21:07 AM | WARNING | 2021-07-14 08:21:07.977292: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
Jul 14, 2021, 10:20:27 AM | INFO | Adapting to protocol v5.1 for kernel a3ecdd9e-1765-4f67-af0e-60c198c896ec
Jul 14, 2021, 10:20:26 AM | INFO | Kernel started: a3ecdd9e-1765-4f67-af0e-60c198c896ec
Jul 14, 2021, 10:20:20 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
Jul 14, 2021, 10:20:20 AM | INFO | http://172.28.0.12:9000/
Jul 14, 2021, 10:20:20 AM | INFO | The Jupyter Notebook is running at:
Jul 14, 2021, 10:20:20 AM | INFO | Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
Jul 14, 2021, 10:20:20 AM | INFO | 0 active kernels
Jul 14, 2021, 10:20:20 AM | INFO | http://172.28.0.2:9000/
Jul 14, 2021, 10:20:20 AM | INFO | The Jupyter Notebook is running at:
Jul 14, 2021, 10:20:20 AM | INFO | Serving notebooks from local directory: /
Jul 14, 2021, 10:20:20 AM | INFO | 0 active kernels
Jul 14, 2021, 10:20:20 AM | INFO | Serving notebooks from local directory: /
Jul 14, 2021, 10:20:20 AM | INFO | google.colab serverextension initialized.
Jul 14, 2021, 10:20:20 AM | INFO | google.colab serverextension initialized.
Jul 14, 2021, 10:20:20 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
Jul 14, 2021, 10:20:20 AM | INFO | Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
```"
50764,AssertionError occurred when initializing NLClassifier with TFlite model,"
I am using NLClassifier in my android application for a text classification problem

Dependency used - **implementation 'org.tensorflow:tensorflow-lite-task-text:0.2.0'**

I am downloading the TFlite model from firebase using FirebaseModelDownloader with the following code
Dependency used - **implementation 'com.google.firebase:firebase-ml-modeldownloader-ktx:24.0.0'**

```
val conditions = CustomModelDownloadConditions.Builder().build()
    FirebaseModelDownloader.getInstance()
    .getModel(ADULT_FILTER_MODEL, DownloadType.LOCAL_MODEL_UPDATE_IN_BACKGROUND, conditions)
    .addOnSuccessListener { model: CustomModel? ->
        model?.file?.let { modelFile ->
            try {
                val classifier = NLClassifier.createFromFile(model)
            } catch (e: IOException) {
                e.printStackTrace()
            }
        }

    }
    .addOnFailureListener {
        // failure handling
    }
```

**Describe the current behavior**
I am getting AssertionError while creating NLClassifier instance with given line of code irregularly
`val classifier = NLClassifier.createFromFile(model)`

StackTrace - 
_Fatal Exception: java.lang.AssertionError: Error occurred when initializing NLClassifier: The model is not a valid Flatbuffer buffer
       at org.tensorflow.lite.task.text.nlclassifier.NLClassifier.initJniWithFileDescriptor(NLClassifier.java)
       at org.tensorflow.lite.task.text.nlclassifier.NLClassifier.access$000(NLClassifier.java:67)
       at org.tensorflow.lite.task.text.nlclassifier.NLClassifier$1.createHandle(NLClassifier.java:195)
       at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:91)
       at org.tensorflow.lite.task.text.nlclassifier.NLClassifier.createFromFileAndOptions(NLClassifier.java:191)
       at org.tensorflow.lite.task.text.nlclassifier.NLClassifier.createFromFile(NLClassifier.java:161)_


**Describe the expected behavior**
I should not get the Error while creating NlClassifier on an irregular basis

Any reason for this and a solution?

"
50763,ModuleNotFounderror:no module named tensorflor_core.estimator ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
50762,Not linking properly on XCode with Mac M1,"Platform: MacBook M1 BigSur
Installed: CocoaPods

**Describe the problem**
I have created a new project and added a Podfile from here: https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/ios

When I build in XCode I get 

`building for iOS Simulator, but linking in object file built for iOS, file.
'/Users/name/Code/name2/ios/SwingAIAnalyzer/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC' for architecture arm64`

But when I try the example `ImageClassification` directly it works. I have check the settings of the two projects but cannot find any differences.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1 Create a new project
2 Copy the Podfile in ImageClassfication and change project name in podfile.
3 Run pod install or pod update
4 Open .xcworkspace
5 Build and here I fail

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
50761,Cannot login to jupyter notebook by Docker Tensorlfow,"My docker version

[![enter image description here][1]][1]

I run `docker pull tensorflow/tensorflow:latest-jupyter`

[![enter image description here][2]][2]


log

[![enter image description here][3]][3]

```
[I 03:09:11.380 NotebookApp](B Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret

jupyter_http_over_ws extension initialized. Listening on /http_over_websocket

[I 03:09:11.626 NotebookApp](B Serving notebooks from local directory: /tf

[I 03:09:11.626 NotebookApp](B Jupyter Notebook 6.3.0 is running at:

[I 03:09:11.626 NotebookApp](B http://2271c0952dc1:8888/?token=43b3f33c0c9ff0fe3420c21ca3505865e9396dd613412ce7

[I 03:09:11.626 NotebookApp](B or http://127.0.0.1:8888/?token=43b3f33c0c9ff0fe3420c21ca3505865e9396dd613412ce7

[I 03:09:11.626 NotebookApp](B Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).

[C 03:09:11.632 NotebookApp](B


To access the notebook, open this file in a browser:

file:///root/.local/share/jupyter/runtime/nbserver-1-open.html

Or copy and paste one of these URLs:

http://2271c0952dc1:8888/?token=43b3f33c0c9ff0fe3420c21ca3505865e9396dd613412ce7

or http://127.0.0.1:8888/?token=43b3f33c0c9ff0fe3420c21ca3505865e9396dd613412ce7

[C 03:13:56.481 NotebookApp](B received signal 15, stopping

[I 03:13:56.483 NotebookApp](B Shutting down 0 kernels

[I 03:13:56.483 NotebookApp](B Shutting down 0 terminals

jupyter_http_over_ws extension initialized. Listening on /http_over_websocket

[I 03:14:01.997 NotebookApp](B Serving notebooks from local directory: /tf

[I 03:14:01.998 NotebookApp](B Jupyter Notebook 6.3.0 is running at:

[I 03:14:01.998 NotebookApp](B http://2271c0952dc1:8888/?token=e52451166ea610fe5559c59eee0f3865e3af25b44c4966d6

[I 03:14:01.998 NotebookApp](B or http://127.0.0.1:8888/?token=e52451166ea610fe5559c59eee0f3865e3af25b44c4966d6

[I 03:14:01.998 NotebookApp](B Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).

[C 03:14:02.003 NotebookApp](B


To access the notebook, open this file in a browser:

file:///root/.local/share/jupyter/runtime/nbserver-1-open.html

Or copy and paste one of these URLs:

http://2271c0952dc1:8888/?token=e52451166ea610fe5559c59eee0f3865e3af25b44c4966d6

or http://127.0.0.1:8888/?token=e52451166ea610fe5559c59eee0f3865e3af25b44c4966d6
```
[![enter image description here][4]][4]

I enter token `e52451166ea610fe5559c59eee0f3865e3af25b44c4966d6` but cannot login.

Even, when I use command line to set password, it still did not work

[![enter image description here][5]][5]

I also enter token then set password, then login, but not success. How to login success?


  [1]: https://i.stack.imgur.com/SaJZ8.png
  [2]: https://i.stack.imgur.com/HnLkB.png
  [3]: https://i.stack.imgur.com/JvTVB.png
  [4]: https://i.stack.imgur.com/W8LDx.png
  [5]: https://i.stack.imgur.com/8gGqm.png

( https://stackoverflow.com/questions/68371609/how-to-login-to-jupyter-notebook-generated-by-tensorflow-docker )
"
50758,Dynamic-sized CoreML Delegate,"**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
The TensorflowLite Core ML delegate currently does not support graphs with dynamic-sized tensors. However, Core ML can in fact support dynamic re-shaping, as demonstrated by the `coremltools` package being able to create dynamic-sized core ML models since WWDC 2020. Therefore, it should hopefully be possible to get the Core ML delegate to support dynamic shapes.

**Will this change the current api? How?**
The API will be the same, but it will no longer throw this error:
```
TensorFlow Lite Error: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.
```

**Who will benefit with this feature?**
iOS developers building complex models with dynamic-sized tensors for mobile who wish to maintain just one tflite mobile model for both Android and iOS devices, instead of converting the tensorflow models to Core ML to support dynamic sizes."
50755,InvalidArgumentError: 2 root error(s) found.,"### System information

- Colab with GPU
- Latest tflite version

[COLAB LINK](https://colab.research.google.com/drive/18HYg1-SLnNnYcGTIy4yQCgPGA0ZKyYx5?usp=sharing)

### Failure after conversion

INFO:tensorflow:Load image with size: 25002, num_label: 2, labels: Cat, Dog.
INFO:tensorflow:Load image with size: 25002, num_label: 2, labels: Cat, Dog.
INFO:tensorflow:Retraining the models...
INFO:tensorflow:Retraining the models...
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.
Model: ""sequential_2""

Total params: 3,415,586
Trainable params: 2,562
Non-trainable params: 3,413,024


9 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py in create(cls, train_data, model_spec, validation_data, batch_size, epochs, train_whole_model, dropout_rate, learning_rate, momentum, shuffle, use_augmentation, use_hub_library, warmup_steps, model_dir, do_train)
    318     if do_train:
    319       tf.compat.v1.logging.info('Retraining the models...')
--> 320       image_classifier.train(train_data, validation_data)
    321     else:
    322       # Used in evaluation.

/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py in train(self, train_data, validation_data, hparams)
    179       lib = train_image_classifier_lib
    180     self.history = lib.train_model(self.model, hparams, train_data_and_size,
--> 181                                    validation_data_and_size)
    182     return self.history
    183 

/usr/local/lib/python3.7/dist-packages/tensorflow_hub/tools/make_image_classifier/make_image_classifier_lib.py in train_model(model, hparams, train_data_and_size, valid_data_and_size, log_dir)
    249       validation_data=valid_data,
    250       validation_steps=validation_steps,
--> 251       callbacks=callbacks)
    252 
    253 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1181                 _r=1):
   1182               callbacks.on_train_batch_begin(step)
-> 1183               tmp_logs = self.train_function(iterator)
   1184               if data_handler.should_sync:
   1185                 context.async_wait()

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    887 
    888       with OptionalXlaContext(self._jit_compile):
--> 889         result = self._call(*args, **kwds)
    890 
    891       new_tracing_count = self.experimental_get_tracing_count()

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    915       # In this case we have created variables on the first call, so we run the
    916       # defunned version which is guaranteed to never create variables.
--> 917       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    918     elif self._stateful_fn is not None:
    919       # Release the lock early so that multiple threads can perform the call

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   3022        filtered_flat_args) = self._maybe_define_function(args, kwargs)
   3023     return graph_function._call_flat(
-> 3024         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
   3025 
   3026   @property

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1959       # No tape is watching; skip to running the function.
   1960       return self._build_call_outputs(self._inference_function.call(
-> 1961           ctx, args, cancellation_manager=cancellation_manager))
   1962     forward_backward = self._select_forward_and_backward_functions(
   1963         args,

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    594               inputs=args,
    595               attrs=attrs,
--> 596               ctx=ctx)
    597         else:
    598           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError: 2 root error(s) found.
  (0) _Invalid argument:  Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodePng_
	 [[{{node cond/else/_1/cond/DecodePng}}]]
	 [[IteratorGetNext]]
	 [[IteratorGetNext/_2]]
  (1) _Invalid argument:  Trying to decode BMP format using a wrong op. Use `decode_bmp` or `decode_image` instead. Op used: DecodePng_
	 [[{{node cond/else/_1/cond/DecodePng}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_33212]

Function call stack:
train_function -> train_function
"
50753,quantize.cpp:58 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 || inp was not true,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- Tensorflow version (commit SHA if source): 2.5.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Arduino Nano 33 BLE Sense

**Describe the problem**

I have converted our CNN to TFLite using full integer quantization (in and out: uint8)
AllocateTensors fails with quantize.cpp:58 input->type == kTfLiteFloat32 || input->type == kTfLiteInt16 || inp was not true

![all_nano_33_ble_sense](https://user-images.githubusercontent.com/6291410/125519397-d10a8aa4-e1c9-4631-b896-a4f59b23aeee.png)

"
50752,tf.keras.layers.TimeDistributed build method passes shapes as tuples instead of TensorShapes.,"https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/layers/wrappers.py#L186

This causes inconsistencies in wrapped layer."
50751,As (x*w+x1*w1+...xn*wn+b) checks if the obtained value is the difference between (x) and (y).,"It would be interesting that at the end of the model.predict function the value obtained the difference between the X_test and the y_test, thus being necessary to multiply the test matrix (X_test) and the prediction matrix (y_preds) to obtain the final value (y_train), instead of needing to multiply the matrix I'm trying to predict (y_train) and the prediction matrix (y_preds) to get the matrix I'm trying to predict (y_train).
This would be useful in cases of future price forecasts of some stock on the stock exchange, because in a real use case, we would have the opening price of the day for example, and we would like to predict the closing price of that same day, using for this the opening price we have at hand.

**System information**
- TensorFlow version (you are using):
2.4.1

- Are you willing to contribute it (Yes/No):
Yes.

**Describe the feature and the current behavior/state.**
By default as this happens at the moment we depend on the closing price itself (y_train) to be multiplied by the forecast matrix (y_preds) to get the closing price itself (y_train), this doesn't make much sense in case of future forecasts, of which we do not yet have the future price in hand.

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Developers.
"
50750,Error converting  mask_rcnn/inception_resnet_v2_1024x1024 Tensorflow model from TFHub to Tflite ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>


### System information

- Ubuntu 18.02
- Tensorflow 2.5
- WSL

**Describe the current behavior**
I have been trying to convert the [mask_rcnn/inception_resnet_v2_1024x1024](https://hub.tensorflow.google.cn/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1) model from TFHub to Tflite using the using the saved model conversion here https://www.tensorflow.org/lite/convert. The problem here is that for some reason when I run the sample code from Tensorflow the model does not convert correctly and gives me a segmentation fault or an error.

**Describe the expected behavior**
Should be able to have a successful conversion from saved_model to tflite model.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
This is the source code I used for the conversion here taken from the Tensorflow website. All I did was download the model from Tfhub onto my Ubuntu.
![image](https://user-images.githubusercontent.com/22630158/125495414-930090b6-20b4-4ac1-8bec-cde371f59edb.png)

Here is the error when I try to convert the .pb file to a .tflite
![image](https://user-images.githubusercontent.com/22630158/125495918-146443da-7041-480a-9cf9-393d005d44b4.png)

My files
![image](https://user-images.githubusercontent.com/22630158/125496188-77a0b99f-8f0e-4c37-839f-c36ca51e4ebb.png)


"
50749,"Custom metric fails with ""ValueError: Metric should be a callable""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 34
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: Python 3.8.10
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Given the _minimal viable program_ below I get an error (also when defining `call` instead of `__call__`):
```
ValueError: Metric should be a callable, found: <__main__.MyLoss object at 0xaddress>
```

**Describe the expected behavior**
I expect the fitting to commence and complete without error.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**
```python
import tensorflow.keras as keras
import numpy as np

class MyLoss(keras.losses.Loss):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    def __call__(self, x, y):
        return x-y

def get_model():
    i = keras.Input((1,))
    m = keras.layers.Dense(10)(i)
    m = keras.layers.Dense(1)(i)
    return keras.Model(i,m)

m = get_model()
m.compile(loss='mse', metrics=[MyLoss()])
m.fit(np.arange(100), np.arange(100))
```

**Other info / logs**
[Full output](https://gist.github.com/obtu/763908fb4111b5da0f785cb13e1d7d34)
"
50748,Getting Embeddings from nested sequences,"With reference to my previous issue : #50739 

@Saduf2019, I just wanted to get some clarifications on your answer, particularly the second approach. 

```
t just encode the entire series and represent it as a single unit which is a number in your case? This method will increase your output nodes but will flatten the nested structure.

A second option may be to pass this list through a separate embedding layer and obtain a single time series or a single value representation of the entire sublist. This may require tuning your embedding size to get the best results but this should work well if the number of events in a sublist is large and it is not possible for you to exhaustively assign a number to all sublist combinations as explained in the first solution

Example for approach 1:
Original: A,B,[D,E,F],K
Final: A,B,C,K

Example for approach 2:
Original: A,B,[D,E,F],K
After passing [D,E,K] through a trainable embedding layer: A,B,C=flatten(emb([DEK])),K where C is a flattened representation of the output of the embedding layer

```
Supposing I use 250-dimension embeddings, then events A, B would be 250-dim embeddings whereas C would be 3*250 = 750 dim since it is flattened. In that case, how would I be able to pass this input sequence to LSTM since all elements do not have the same dim-embeds ? "
50747,MLIR converter quantizes conv2d before bias when dilaition rate > 1,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.5.0
### 2. Code

Provide code to help us reproduce your issues using one of the following options:


#### Option A: Reference colab notebooks

Reference [TensorFlow Model Colab](https://colab.research.google.com/drive/1Pp0ZwbHTz3QjC2YxTn6l2kIro_DNxDqx?usp=sharing): Demonstrate how to build your TF model, convert to TFLite, and infer.

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:
When creating a Conv2D with a dilation rate that is greater than 1, and the Conv2D has a bias, the MLIR converter splits the bias to a separate layer, and quantizes the tensor between them, thus causing accuracy degradation.


### 5. (optional) Any other info / logs
![image](https://user-images.githubusercontent.com/44209964/125436409-85a7a2e9-3158-4622-846e-baf1e08eae75.png)
"
50746,"In distributed training, different workers get different results from the information","In distributed training.
The savedmodel model saved by the estimator.
Is it different to save in different workers?
However, I have different results in different savedmodels of different workers for C + + online inference
![43701B~1](https://user-images.githubusercontent.com/52573793/125428034-a7ef27b7-9123-4455-89fa-4ab1ae32ffc6.PNG)
"
50745,Unable to use Keras data generator with Functional API model,"Here is my data generator class:
class DataGenerator(tensorflow.keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, image_path, label_path,
                 to_fit=True, batch_size=16, dim=(160, 160),
                 n_channels=4, n_classes=4, shuffle=True):
        """"""Initialization
        :param list_IDs: list of all 'label' ids to use in the generator
        :param labels: list of image labels (file names)
        :param image_path: path to images location
        :param mask_path: path to masks location
        :param to_fit: True to return X and y, False to return X only
        :param batch_size: batch size at each iteration
        :param dim: tuple indicating image dimension
        :param n_channels: number of image channels
        :param n_classes: number of output masks
        :param shuffle: True to shuffle label indexes after every epoch
        """"""
        self.list_IDs = list_IDs
        #self.labels = labels
        self.image_path = image_path
        self.label_path = label_path
        self.to_fit = to_fit
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.on_epoch_end()
    
    def __len__(self):
        'Denotes the number of batches per epoch'
        #print('Batch per epoch: ', self.batch_per_epoch)
        #return self.batch_per_epoch
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __getitem__(self, index):
        'Generate one batch of data'
        #data = np.load('.\\SplitDataSet\\Data\\x_1.npy')
        #labels = np.load('.\\SplitDataSet\\Label\\y_1.npy')
        """"""list_IDs_temp = []
        for i in range(self.start_index, self.end_index + 1):
            list_IDs_temp.append(i)""""""
        # Generate indexes of the batch
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]

        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]
        #print(list_IDs_temp)
        X = self._generate_X(list_IDs_temp)
        print('X shape', X.shape)
        y = self._generate_y(list_IDs_temp)
        print('Y shape', y.shape)
        return X, y

    def _generate_X(self, list_IDs_temp):
        # Initialization
        X = np.empty((self.batch_size, 155, *self.dim, self.n_channels))
        for i, ID in enumerate(list_IDs_temp):
            X[i,] = np.load('./SplitDataSet/Data_4/x_' + str(ID) + '.npy')
            #test = np.load('.\\SplitDataSet\\Data\\x_' + str(ID) + '.npy')
            #print('File name: ', './SplitDataSet/Data/x_' + str(ID) + '.npy')
            #print(test.shape)
        X = X.reshape([-1,160,160,4])
        return X
    
    def _generate_y(self, list_IDs_temp):
        # Initialization
        y = np.empty((self.batch_size, 155, *self.dim, self.n_channels))
        #y = np.empty((self.batch_size, 155, *self.dim, 2))
        for i, ID in enumerate(list_IDs_temp):
            y[i,] = np.load('./SplitDataSet/Label_4/y_' + str(ID) + '.npy')
        y = y.reshape([-1,160,160,4])
        return y


And my model looks like this:
input_ = Input(shape=(160, 160, 4), name='input')



#   EXAMPLE ENCODER
block1_conv1 = Conv2D(64, 3, padding='same', activation='relu', name='block1_conv1')(input_)
block1_conv2 = Conv2D(64, 3, padding='same', activation='relu', name='block1_conv2')(block1_conv1)
block1_norm = BatchNormalization(name='block1_batch_norm')(block1_conv2)
block1_pool = MaxPooling2D(name='block1_pool')(block1_norm)

block2_conv1 = Conv2D(128, 3, padding='same', activation='relu', name='block2_conv1')(block1_pool)
block2_conv2 = Conv2D(128, 3, padding='same', activation='relu', name='block2_conv2')(block2_conv1)
block2_norm = BatchNormalization(name='block2_batch_norm')(block2_conv2)
block2_pool = MaxPooling2D(name='block2_pool')(block2_norm)

dropout_1 = Dropout(0.2, name='encoder_dropout_1')(block2_pool)

block3_conv1 = Conv2D(256, 3, padding='same', activation='relu', name='block3_conv1')(dropout_1)
block3_conv2 = Conv2D(256, 3, padding='same', activation='relu', name='block3_conv2')(block3_conv1)
block3_norm = BatchNormalization(name='block3_batch_norm')(block3_conv2)
block3_pool = MaxPooling2D(name='block3_pool')(block3_norm)

block4_conv1 = Conv2D(512, 3, padding='same', activation='relu', name='block4_conv1')(block3_pool)
block4_conv2 = Conv2D(512, 3, padding='same', activation='relu', name='block4_conv2')(block4_conv1)
block4_norm = BatchNormalization(name='block4_batch_norm')(block4_conv2)
block4_pool = MaxPooling2D(name='block4_pool')(block4_norm)

#BOTTOM OF U
block5_conv1 = Conv2D(1024, 3, padding='same', activation='relu', name='block5_conv1')(block4_pool)

#   EXAMPLE DECODER

up_pool1 = Conv2DTranspose(1024, 3, strides=(2, 2), padding='same', activation='relu', name='up_pool1')(block5_conv1)
merged_block1 = concatenate([block4_norm, up_pool1], name='merged_block1')
decod_block1_conv1 = Conv2D(512, 3, padding='same', activation='relu', name='decod_block1_conv1')(merged_block1)

up_pool2 = Conv2DTranspose(512, 3, strides=(2, 2), padding='same', activation='relu', name='up_pool2')(decod_block1_conv1)
merged_block2 = concatenate([block3_norm, up_pool2], name='merged_block2')
decod_block2_conv1 = Conv2D(256, 3, padding='same', activation='relu', name='decod_block2_conv1')(merged_block2)

dropout_2 = Dropout(0.2, name='decoder_dropout_1')(decod_block2_conv1)

up_pool3 = Conv2DTranspose(256, 3, strides=(2, 2), padding='same', activation='relu', name='up_pool3')(dropout_2)
merged_block3 = concatenate([block2_norm, up_pool3], name='merged_block3')
decod_block3_conv1 = Conv2D(128, 3, padding='same', activation='relu', name='decod_block3_conv1')(merged_block3)

up_pool4 = Conv2DTranspose(128, 3, strides=(2, 2), padding='same', activation='relu', name='up_pool4')(decod_block3_conv1)
merged_block4 = concatenate([block1_norm, up_pool4], name='merged_block4')
decod_block4_conv1 = Conv2D(64, 3, padding='same', activation='relu', name='decod_block4_conv1')(merged_block4)


pre_output = Conv2D(64, 1, padding='same', activation='relu', name='pre_output')(decod_block4_conv1)
output = Conv2D(4, 1, padding='same', activation='softmax', name='output')(pre_output)
modelUNet = Model(inputs=input_, outputs=output)
print(modelUNet.summary())


image_path = 'path to images'
label_path = 'path to masks'
total_records = 150
train_start = 0
train_end = int(np.floor(0.8*total_records))
val_start = train_end + 1
val_end = total_records
train_idx = []
val_idx = []
for i in range(1, val_start):
    train_idx.append(i)
for i in range(val_start, total_records + 1):
    val_idx.append(i)

training_generator = DataGenerator(train_idx, image_path, label_path)
validation_generator = DataGenerator(val_idx, image_path, label_path)



# The model is compiled with the dice_loss_function and the dice_function metric:
print(""About to compile..."")
#modelUNet = Sequential()
modelUNet.compile(optimizer=Adam(lr=1e-5), loss=dice_loss_function, metrics=[dice_function])

# EarlyStopping is applied incase the model stops improving with each epoch:
callbacks = [tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss')]

print(""About to fit the model..."")

history = modelUNet.fit(
	x=training_generator,
	validation_data=validation_generator,
	epochs=10, callbacks=callbacks)


Now the issue is my model is not sequential, so when I comment out the line: modelUNet = Sequential() and run the code, it throws the following error: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
         [[{{node PyFunc}}]]
And the process terminates, but if I uncomment the modelUNet = Sequential(), then the model runs but since it is not sequential, it does not learn and finishes at 5 epochs because it crosses the patience.
How do I use a data generator with a non-sequential model?"
50744,C++ compile tensorflow ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): Tensorflow r2.4
- Python version: 3.6.8
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): VS2019
- CUDA/cuDNN version: cuda_11.2.1_461.09_win10/cudnn-11.2-windows-x64-v8.1.1.33
- GPU model and memory: RTX3080Ti 12G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
G:\tensorflow-r2.4.0-gpu\tensorflow-r2.4>bazel build -c dbg --config=opt --config=cuda //tensorflow:tensorflow_cc.dll
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [cuda, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=D:/Python36/python.exe
INFO: Reading rc options for 'build' from g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=D:/Python36/python.exe --action_env PYTHON_LIB_PATH=D:/Python36/lib/site-packages --python_path=D:/Python36/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.6 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:opt in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.tf_configure.bazelrc: --copt=/arch:AVX --host_copt=/arch:AVX --define with_default_optimizations=true
INFO: Found applicable config definition build:cuda in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:windows in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file g:\tensorflow-r2.4.0-gpu\tensorflow-r2.4\.bazelrc: --define framework_shared_object=false
INFO: Analyzed target //tensorflow:tensorflow_cc.dll (218 packages loaded, 19915 targets configured).
INFO: Found 1 target...
INFO: Deleting stale sandbox base C:/users/administrator/_bazel_administrator/nkxc6ocj/sandbox
ERROR: G:/tensorflow-r2.4.0-gpu/tensorflow-r2.4/tensorflow/compiler/xla/BUILD:423:1: C++ compilation of rule '//tensorflow/compiler/xla:literal' failed (Exit 2): python.exe failed: error executing command
  cd C:/users/administrator/_bazel_administrator/nkxc6ocj/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2
    SET INCLUDE=D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\ATLMFC\include;D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\cppwinrt
    SET LIB=D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\ATLMFC\lib\x64;D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\lib\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\um\x64
    SET PATH=D:\Microsoft Visual Studio\2019\Community\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\bin\HostX64\x64;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\VC\VCPackages;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TestWindow;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;D:\Microsoft Visual Studio\2019\Community\MSBuild\Current\bin\Roslyn;D:\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools\x64;D:\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;D:\Microsoft Visual Studio\2019\Community\Common7\Tools\devinit;C:\Program Files (x86)\Windows Kits\10\bin\10.0.19041.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;D:\Microsoft Visual Studio\2019\Community\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\;D:\Microsoft Visual Studio\2019\Community\Common7\Tools\;;C:\Windows\system32;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja;D:\Microsoft Visual Studio\2019\Community\Common7\IDE\VC\Linux\bin\ConnectionManagerExe
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=D:/Python36/python.exe
    SET PYTHON_LIB_PATH=D:/Python36/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\ADMINI~1\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=8.6
    SET TF_NEED_CUDA=1
    SET TMP=C:\Users\ADMINI~1\AppData\Local\Temp
  D:/Python36/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-dbg/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-dbg/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-dbg/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-dbg/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-dbg/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-dbg/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-dbg/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-dbg/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-dbg/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-dbg/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-dbg/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-dbg/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-dbg/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-dbg/bin/external/snappy /Iexternal/nsync/public /Ibazel-out/x64_windows-dbg/bin/external/nsync/public /Iexternal/eigen_archive /Ibazel-out/x64_windows-dbg/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-dbg/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-dbg/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-dbg/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-dbg/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-dbg/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-dbg/bin/external/double_conversion /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MDd /Od /Z7 /DDEBUG /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /arch:AVX /std:c++14 /Fobazel-out/x64_windows-dbg/bin/tensorflow/compiler/xla/_objs/literal/literal.obj /c tensorflow/compiler/xla/literal.cc
Execution platform: @local_execution_config_platform//:platform
cl: 命令行 warning D9035 :“experimental:preprocessor”选项已否决，并将在将来的版本中移除
cl: 命令行 warning D9036 :使用“Zc:preprocessor”而不使用“experimental:preprocessor”
注意: 包含文件:  C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/literal.h
注意: 包含文件:   D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\functional
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\yvals_core.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\sal.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\concurrencysal.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vadefs.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xkeycheck.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\exception
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\yvals.h
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\crtdbg.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime_new_debug.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime_new.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\crtdefs.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\use_ansi.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\type_traits
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cstdint
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\stdint.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xstddef
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cstddef
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\stddef.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xtr1common
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cstdlib
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\math.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_math.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_math_defines.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\stdlib.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_malloc.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_search.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wstdlib.h
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\limits.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\initializer_list
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\malloc.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime_exception.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\eh.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_terminate.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\tuple
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xutility
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\climits
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cstring
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\string.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_memory.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_memcpy_s.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\errno.h
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime_string.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wstring.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\utility
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\typeinfo
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime_typeinfo.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xmemory
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\limits
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cfloat
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\float.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cwchar
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cstdio
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\stdio.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wstdio.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_stdio_config.h
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\wchar.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wconio.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wctype.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wdirect.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wio.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_share.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wprocess.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_wtime.h
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\sys/stat.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\sys/types.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\intrin0.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\isa_availability.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\new
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xatomic.h
注意: 包含文件:   D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\iterator
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\iosfwd
注意: 包含文件:   D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\memory
注意: 包含文件:   D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ostream
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ios
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xlocnum
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cmath
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\streambuf
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xiosbase
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\share.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\system_error
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\__msvc_system_error_abi.hpp
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cerrno
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\stdexcept
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xstring
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xcall_once.h
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xerrc.h
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\atomic
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xthreads.h
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xtimec.h
注意: 包含文件:            D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ctime
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\time.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xlocale
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xfacet
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xlocinfo
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xlocinfo.h
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cctype
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\ctype.h
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\clocale
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\locale.h
注意: 包含文件:   D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\string
注意: 包含文件:   D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vector
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/memory/memory.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/macros.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:      C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/attributes.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/optimization.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/config.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/options.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ciso646
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\iso646.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/policy_checks.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\intrin.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\setjmp.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\immintrin.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\wmmintrin.h
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\nmmintrin.h
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\smmintrin.h
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\tmmintrin.h
注意: 包含文件:            D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\pmmintrin.h
注意: 包含文件:             D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\emmintrin.h
注意: 包含文件:              D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xmmintrin.h
注意: 包含文件:               D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\mmintrin.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\zmmintrin.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ammintrin.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/port.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/meta/type_traits.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/string_view.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\algorithm
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/throw_delegate.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/types/optional.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/utility/utility.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/inline_variable.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/identity.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/invoke.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/types/bad_optional_access.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/types/internal/optional.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/types/span.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:     C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/types/internal/span.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/algorithm/algorithm.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/array2d.h
注意: 包含文件:    D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\random
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xbit_ops.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/str_cat.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\array
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/numbers.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/bits.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/numeric/int128.h
注意: 包含文件:       D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:        C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/numeric/int128_no_intrinsic.inc
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/array.h
注意: 包含文件:     D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\numeric
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/str_join.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_join_internal.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/ostringstream.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/resize_uninitialized.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/status.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/core/status.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/status.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/logging.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/platform.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/types.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/bfloat16.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/byte_order.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party/eigen3/Eigen/Core
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen/Core
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/DisableStupidWarnings.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/Macros.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/ConfigureVectorization.h
注意: 包含文件:             D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\complex
注意: 包含文件:              D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\sstream
注意: 包含文件:               D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\istream
注意: 包含文件:              D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ymath.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/MKL_support.h
注意: 包含文件:             D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:              C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/Constants.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/Meta.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/ForwardDeclarations.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/StaticAssert.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/XprHelper.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/Memory.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/IntegralConstant.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/SymbolicIndex.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/NumTraits.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/MathFunctions.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/GenericPacketMath.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/MathFunctionsImpl.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/ConjHelper.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/Half.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/BFloat16.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/TypeCasting.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/GenericPacketMathFunctionsFwd.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/SSE/PacketMath.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/SSE/TypeCasting.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/SSE/Complex.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/AVX/PacketMath.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/AVX/TypeCasting.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/AVX/Complex.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/SSE/MathFunctions.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/AVX/MathFunctions.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/Settings.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/arch/Default/GenericPacketMathFunctions.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/TernaryFunctors.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/BinaryFunctors.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/UnaryFunctors.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/NullaryFunctors.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/StlFunctors.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/functors/AssignmentFunctors.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/IndexedViewHelper.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/ReshapedHelper.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/ArithmeticSequence.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/IO.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/DenseCoeffsBase.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/DenseBase.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/CommonCwiseUnaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/BlockMethods.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/IndexedViewMethods.h
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\plugins\IndexedViewMethods.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/ReshapedMethods.h
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\plugins\ReshapedMethods.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/MatrixBase.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/CommonCwiseBinaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/MatrixCwiseUnaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/MatrixCwiseBinaryOps.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/EigenBase.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Product.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CoreEvaluators.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/AssignEvaluator.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Assign.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/ArrayBase.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/MatrixCwiseUnaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/ArrayCwiseUnaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/CommonCwiseBinaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/MatrixCwiseBinaryOps.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src\Core\../plugins/ArrayCwiseBinaryOps.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/BlasUtil.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/DenseStorage.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/NestByValue.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/ReturnByValue.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/NoAlias.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/PlainObjectBase.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Matrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Array.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseTernaryOp.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseBinaryOp.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseUnaryOp.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseNullaryOp.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CwiseUnaryView.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/SelfCwiseBinaryOp.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Dot.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/StableNorm.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Stride.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/MapBase.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Map.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Ref.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Block.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/VectorBlock.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/IndexedView.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Reshaped.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Transpose.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/DiagonalMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Diagonal.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/DiagonalProduct.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Redux.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Visitor.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Fuzzy.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Swap.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CommaInitializer.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/GeneralProduct.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Solve.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Inverse.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/SolverBase.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/PermutationMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Transpositions.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/TriangularMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/SelfAdjointView.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/GeneralBlockPanelKernel.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/Parallelizer.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/ProductEvaluators.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/GeneralMatrixVector.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/GeneralMatrixMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/SolveTriangular.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/GeneralMatrixMatrixTriangular.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/SelfadjointMatrixVector.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/SelfadjointMatrixMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/SelfadjointProduct.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/SelfadjointRank2Update.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/TriangularMatrixVector.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/TriangularMatrixMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/TriangularSolverMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/products/TriangularSolverVector.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/BandMatrix.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/CoreIterators.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/ConditionEstimator.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/BooleanRedux.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Select.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/VectorwiseOp.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/PartialReduxEvaluator.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Random.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Replicate.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/Reverse.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/ArrayWrapper.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/StlIterators.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/GlobalFunctions.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/util/ReenableStupidWarnings.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/tstring.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/cord.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/default/cord.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/ctstring.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/ctstring_internal.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/default/integral_types.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/default/logging.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/log_severity.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/macros.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/stringpiece.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\bazel-out\x64_windows-dbg\bin\tensorflow/core/protobuf/error_codes.pb.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/io/coded_stream.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/common.h
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\iostream
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\map
注意: 包含文件:            D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xtree
注意: 包含文件:           D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\set
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/port.h
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/platform_macros.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/macros.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/arena.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/arena_impl.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/logging.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/arenastring.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/fastmem.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/generated_message_table_driven.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/generated_enum_util.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/message_lite.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/once.h
注意: 包含文件:              D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\mutex
注意: 包含文件:               D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\chrono
注意: 包含文件:                D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\ratio
注意: 包含文件:               D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\thread
注意: 包含文件:                C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\process.h
注意: 包含文件:                 C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\corecrt_startup.h
注意: 包含文件:                  C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\math.h
注意: 包含文件:                  D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\vcruntime_startup.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/strutil.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/stringpiece.h
注意: 包含文件:               C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/hash.h
注意: 包含文件:                D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\unordered_map
注意: 包含文件:                 D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xhash
注意: 包含文件:                  D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\list
注意: 包含文件:                D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\unordered_set
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map_type_handler.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/parse_context.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/io/zero_copy_stream.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/implicit_weak_message.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/metadata_lite.h
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/generated_message_util.h
注意: 包含文件:               C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/has_bits.h
注意: 包含文件:                C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:                C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/wire_format_lite.h
注意: 包含文件:                C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/repeated_field.h
注意: 包含文件:                 C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/casts.h
注意: 包含文件:                 C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:                 C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:                C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:                C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:               C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:              C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map_entry_lite.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map_field_lite.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/inlined_string_field.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/metadata.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/unknown_field_set.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/generated_message_reflection.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/descriptor.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/mutex.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/generated_enum_reflection.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/extension_set.h
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/types.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party/eigen3/Eigen/Core
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/framework/numeric_types.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party/eigen3/unsupported/Eigen/CXX11/Tensor
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported/Eigen/CXX11/Tensor
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\../SpecialFunctions
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\math.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\../../Eigen/src/Core/util/DisableStupidWarnings.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/BesselFunctionsImpl.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/BesselFunctionsPacketMath.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/BesselFunctionsBFloat16.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/BesselFunctionsHalf.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/BesselFunctionsFunctors.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/BesselFunctionsArrayAPI.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/SpecialFunctionsImpl.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/SpecialFunctionsPacketMath.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/SpecialFunctionsBFloat16.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/SpecialFunctionsHalf.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/SpecialFunctionsFunctors.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\src/SpecialFunctions/SpecialFunctionsArrayAPI.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\../../Eigen/src/Core/util/ReenableStupidWarnings.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\../../../Eigen/src/Core/util/DisableStupidWarnings.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/util/CXX11Meta.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src\util\EmulateArray.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src\util\CXX11Workarounds.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/util/MaxSizeVector.h
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\windows.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\winapifamily.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\winpackagefamily.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\sdkddkver.h
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\excpt.h
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\stdarg.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\windef.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\minwindef.h
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\specstrings.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\specstrings_strict.h
注意: 包含文件:              C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\specstrings_undef.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\driverspecs.h
注意: 包含文件:              C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\sdv_driverspecs.h
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnt.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\kernelspecs.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\basetsd.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\guiddef.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack4.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack4.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack4.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack8.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack1.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack1.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\apiset.h
注意: 包含文件:             C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\ktmtypes.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winbase.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\apisetcconv.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\minwinbase.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\apiquery2.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\processenv.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\fileapifromapp.h
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\fileapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\debugapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\utilapiset.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\handleapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\errhandlingapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\fibersapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\namedpipeapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\profileapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\heapapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\ioapiset.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\synchapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\interlockedapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\processthreadsapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\sysinfoapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\memoryapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\enclaveapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\threadpoollegacyapiset.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\threadpoolapiset.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\jobapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\jobapi2.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wow64apiset.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\libloaderapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\securitybaseapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\namespaceapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\systemtopologyapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\processtopologyapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\securityappcontainer.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\realtimeapiset.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\winerror.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\timezoneapi.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wingdi.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winuser.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\pshpack2.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\poppack.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\tvout.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnls.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\datetimeapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\stringapiset.h
注意: 包含文件:            C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnls.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wincon.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\wincontypes.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\consoleapi.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\consoleapi2.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\consoleapi3.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winver.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\verrsrc.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winreg.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\reason.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winnetwk.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\wnnc.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared\stralign.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\winsvc.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\mcx.h
注意: 包含文件:          C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\imm.h
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um\ime_cmodes.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorMacros.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorForwardDeclarations.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorMeta.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorFunctors.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorCostModel.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDeviceDefault.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDeviceThreadPool.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDeviceGpu.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDeviceSycl.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorIndexList.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDimensionList.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDimensions.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorInitializer.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorTraits.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorRandom.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorUInt128.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorIntDiv.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorGlobalFunctions.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorBase.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorBlock.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorEvaluator.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorExpr.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorReduction.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorReductionGpu.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorArgMax.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorConcatenation.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorContractionMapper.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorContractionBlocking.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorContraction.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorContractionThreadPool.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorContractionGpu.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorConversion.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorConvolution.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorFFT.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorPatch.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorImagePatch.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorVolumePatch.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorBroadcasting.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorChipping.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorInflation.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorLayoutSwap.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorMorphing.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorPadding.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorReverse.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorShuffling.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorStriding.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorCustomOp.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorEvalTo.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorForcedEval.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorGenerator.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorAssign.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorScan.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorTrace.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorExecutor.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorDevice.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorStorage.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/Tensor.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorFixedSize.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorMap.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorRef.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorIO.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\../../../Eigen/src/Core/util/ReenableStupidWarnings.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party\eigen3\unsupported\Eigen\CXX11\src/FixedPoint/FixedPointTypes.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party\eigen3\unsupported\Eigen\CXX11\src/FixedPoint/PacketMathAVX.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party\eigen3\unsupported\Eigen\CXX11\src/FixedPoint/MatMatProduct.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party\eigen3\unsupported\Eigen\CXX11\src/FixedPoint/MatVecProduct.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/core/bits.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/array3d.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/array4d.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/index_util.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/shape.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/container/inlined_vector.h
注意: 包含文件:      D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:       C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/container/internal/inlined_vector.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/container/internal/compressed_tuple.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/layout.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/util.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/algorithm/container.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:         C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/thread_annotations.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/thread_annotations.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/str_format.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_format/arg.h
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\iomanip
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xlocmon
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\xloctime
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_format/extension.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_format/output.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_format/bind.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_format/checker.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_format/parser.h
注意: 包含文件:          D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:           C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/status_macros.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/statusor.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/stream_executor/lib/statusor.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/stream_executor/lib/status.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/stream_executor/lib/error.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/stream_executor/platform/logging.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/stream_executor/platform/port.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/stream_executor/lib/statusor_internals.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\bazel-out\x64_windows-dbg\bin\tensorflow/compiler/xla/xla_data.pb.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/message.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map_entry.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/reflection_ops.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map_field_inl.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/map_field.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/core/errors.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/errors.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/str_util.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/str_split.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/raw_logging.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/internal/atomic_hook.h
注意: 包含文件:             D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\cassert
注意: 包含文件:              C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt\assert.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/internal/str_split_internal.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/strip.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/ascii.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/strings/match.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/strcat.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/numbers.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/math/math_util.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/strings/numbers.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/mutex.h
注意: 包含文件:        D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\condition_variable
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/thread_annotations.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/default/mutex_data.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/default/mutex.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/protobuf.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/io/tokenizer.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/io/zero_copy_stream_impl_lite.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/callback.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/stl_util.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/descriptor.pb.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/dynamic_message.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/text_format.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/util/json_util.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/util/type_resolver.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/type.pb.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/any.pb.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/any.h
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:             C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/source_context.pb.h
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:            C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/status.h
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:           C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/stubs/bytestream.h
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:          C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/util/type_resolver_util.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_def.inc
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_protobuf\src\google/protobuf/port_undef.inc
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/primitive_util.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/layout_util.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/compiler/xla/shape_util.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/core/threadpool.h
注意: 包含文件:     C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/threadpool.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/env.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/env_time.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/file_system.h
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/file_statistics.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/numa.h
注意: 包含文件:      C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/threadpool_interface.h
注意: 包含文件:       C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\third_party/eigen3/unsupported/Eigen/CXX11/ThreadPool
注意: 包含文件:        C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported/Eigen/CXX11/ThreadPool
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\../../../Eigen/src/Core/util/DisableStupidWarnings.h
注意: 包含文件:         D:\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.29.30037\include\deque
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/ThreadLocal.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/ThreadYield.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/ThreadCancel.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/EventCount.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/RunQueue.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/ThreadPoolInterface.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/ThreadEnvironment.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/Barrier.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/ThreadPool/NonBlockingThreadPool.h
注意: 包含文件:         C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\../../../Eigen/src/Core/util/ReenableStupidWarnings.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/cpu_info.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/core/bitmap.h
注意: 包含文件:  C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\external\com_google_absl\absl/base/casts.h
注意: 包含文件:  C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/lib/hash/hash.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/hash.h
注意: 包含文件:  C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/mem.h
注意: 包含文件:   C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/dynamic_annotations.h
注意: 包含文件:    C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow/core/platform/default/dynamic_annotations.h
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<short,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<bool,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,std::complex<double> >”: 必须返回一 个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned char,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned short,std::complex<float> >”: 必须返回一 个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<int,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,std::complex<float> >”: 必须返回一个 值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned int,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<__int64,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<signed char,std::complex<double> >”: 必须返回一个 值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<unsigned __int64,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::half,std::complex<double> >”: 必须返回一个 值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<float,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,unsigned short>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,Eigen::half>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,Eigen::bfloat16>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,std::complex<double> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<double,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,bool>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,signed char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,unsigned char>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,__int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,unsigned int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,int>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,unsigned __int64>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,float>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,std::complex<float> >”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,double>”: 必须返回一个值
C:\users\administrator\_bazel_administrator\nkxc6ocj\execroot\org_tensorflow\tensorflow\compiler\xla\literal.cc(1392) : error C4716: “xla::`anonymous namespace'::BitcastBetweenNativeTypes<Eigen::bfloat16,std::complex<double> >”: 必须返回 一个值
Target //tensorflow:tensorflow_cc.dll failed to build
INFO: Elapsed time: 865.205s, Critical Path: 311.95s
INFO: 5039 processes: 5039 local.
FAILED: Build did NOT complete successfully
**Describe the expected behavior**
Build complete successfully
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50741,KerasTensors do not support tf.custom_gradient(),"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Red Hat Enterprise Linux release 8.2 (Ootpa)
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version: v1.12.1-59375-ga5317d67e6c 2.6.0-rc0
- Python version: 3.6.8

**Describe the current behavior**
`tf.KerasTensor` cannot be used with `tf.custom_gradient()`. Trying to do so results in a `TypeError`.

**Describe the expected behavior**
This should be possible and return another `tf.KerasTensor`.

**Standalone code to reproduce the issue**
```python3
import tensorflow as tf

@tf.custom_gradient
def identity(x):
    def grad_fn(grad_y):
        return grad_y
    return (x, grad_fn)

keras_tensor = tf.keras.layers.Input(shape=(2,))
print(keras_tensor)
print(identity(keras_tensor))
```

which gives:

```
KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name='input_1'), name='input_1', description=""created by layer 'input_1'"")
Traceback (most recent call last):
  File ""test.py"", line 15, in <module>
    print(identity(keras_tensor))
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py"", line 309, in __call__
    return self._d(self._f, a, k)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py"", line 263, in decorated
    return _eager_mode_decorator(wrapped, args, kwargs)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py"", line 510, in _eager_mode_decorator
    flat_result = [gen_array_ops.identity(x) for x in flat_result]
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/ops/custom_gradient.py"", line 510, in <listcomp>
    flat_result = [gen_array_ops.identity(x) for x in flat_result]
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3941, in identity
    input, name=name, ctx=_ctx)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3960, in identity_eager_fallback
    _attr_T, (input,) = _execute.args_to_matching_eager([input], ctx, [])
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 274, in args_to_matching_eager
    t, dtype, preferred_dtype=default_dtype, ctx=ctx)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/profiler/trace.py"", line 163, in wrapped
    return func(*args, **kwargs)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 346, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 272, in constant
    allow_broadcast=True)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/tensorflow/python/framework/constant_op.py"", line 106, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
  File ""/home/loic/venv/tf_2.6.0rc0/lib64/python3.6/site-packages/keras/engine/keras_tensor.py"", line 245, in __array__
    'Cannot convert a symbolic Keras input/output to a numpy array. '
TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.
```

**Other info / logs**

This works with Eager tensors.

```python3
eager_tensor = tf.constant([4.0])
print(identity(eager_tensor))
```

gives

```
tf.Tensor([4.], shape=(1,), dtype=float32)
```
"
50740,Dataset.as_numpy_iterator() throws error inside tensorflow.numpy_function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 and Google Colab 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.10
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: CPU 8GB


**Describe the expected behavior** tensorflow.data.Dataset.as_numpy_iterator should return iterator when called from inside tensorflow.py_func used inside Dataset.interleave's map_function.


**Describe the current behavior** Throwing error 'Tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]'

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): NA

**Standalone code to reproduce the issue**
````
import tensorflow as tf
path = ""saved_data_2""

# Save a dataset
dataset = tf.data.Dataset.range(10)
tf.data.experimental.save(dataset, path)
new_dataset = tf.data.experimental.load(path)
for elem in new_dataset:
  print(elem)


#flat_map code error below
filenames = [path]
dataset = tf.data.Dataset.from_tensor_slices(filenames)


def parse_fn(filename):
    part_ds = tf.data.experimental.load(bytes.decode(filename),compression='GZIP')
    ar = []
    for i in part_ds.as_numpy_iterator():
        ar.append(i)
    return ar

dataset = dataset.interleave(lambda x:tf.data.Dataset.from_tensor_slices(
            tf.numpy_function(parse_fn,[x],[tf.int64])),
            cycle_length=4, block_length=16)

for item in dataset.as_numpy_iterator():
    print(item)
````

**Other info / logs** 

````
C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\python.exe C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py
2021-07-12 21:14:47.985114: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2021-07-12 21:14:47.985404: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2021-07-12 21:14:50.932059: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2021-07-12 21:14:50.932192: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2021-07-12 21:14:50.935815: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: LAPTOP-76MAP85S
2021-07-12 21:14:50.936005: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: LAPTOP-76MAP85S
2021-07-12 21:14:50.936609: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-12 21:14:50.967628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
2021-07-12 21:14:51.013124: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.
tf.Tensor(0, shape=(), dtype=int64)
tf.Tensor(1, shape=(), dtype=int64)
tf.Tensor(2, shape=(), dtype=int64)
tf.Tensor(3, shape=(), dtype=int64)
tf.Tensor(4, shape=(), dtype=int64)
tf.Tensor(5, shape=(), dtype=int64)
tf.Tensor(6, shape=(), dtype=int64)
2021-07-12 21:14:51.017583: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.
tf.Tensor(7, shape=(), dtype=int64)
tf.Tensor(8, shape=(), dtype=int64)
tf.Tensor(9, shape=(), dtype=int64)
2021-07-12 21:14:51.102540: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.
2021-07-12 21:14:51.109462: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.
2021-07-12 21:14:51.133405: W tensorflow/core/framework/op_kernel.cc:1755] Unknown: DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]
Traceback (most recent call last):

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 249, in __call__
    ret = func(*args)

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 645, in wrapper
    return func(*args, **kwargs)

  File ""C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py"", line 20, in parse_fn
    for i in part_ds.as_numpy_iterator():

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 4194, in __next__
    return nest.map_structure(to_numpy, next(self._iterator))

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 761, in __next__
    return self._next_internal()

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 744, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py"", line 2727, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\framework\ops.py"", line 6897, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)

  File ""<string>"", line 3, in raise_from

tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]


Traceback (most recent call last):
  File ""C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py"", line 28, in <module>
    for item in dataset.as_numpy_iterator():
  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 4194, in __next__
    return nest.map_structure(to_numpy, next(self._iterator))
  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 761, in __next__
    return self._next_internal()
  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 744, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(
  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py"", line 2727, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\framework\ops.py"", line 6897, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.UnknownError: DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]
Traceback (most recent call last):

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 249, in __call__
    ret = func(*args)

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 645, in wrapper
    return func(*args, **kwargs)

  File ""C:/Users/kurud/Documents/ineaurondeeplearn/internship/DrowsyDetectCNNmodel/DataPipelineIssues2.py"", line 20, in parse_fn
    for i in part_ds.as_numpy_iterator():

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 4194, in __next__
    return nest.map_structure(to_numpy, next(self._iterator))

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 761, in __next__
    return self._next_internal()

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 744, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py"", line 2727, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)

  File ""C:\Users\kurud\Anaconda3\envs\DrowsyDetectCNNmodel\lib\site-packages\tensorflow\python\framework\ops.py"", line 6897, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)

  File ""<string>"", line 3, in raise_from

tensorflow.python.framework.errors_impl.DataLossError: inflate() failed with error -3: incorrect header check [Op:IteratorGetNext]


	 [[{{node PyFunc}}]] [Op:IteratorGetNext]

Process finished with exit code 1

````"
50739,Getting Embeddings from sequence of one-hot vectors ,"TF version : 2.5

Data : Lists of sequences, some of which may contain nested sequences.(As in the example below)

I have input sequences that contain not just single elements, but also lists. 

Eg : i1 = [2, 5, 10, [1, 7 ,9 , 20], 11, 32].

If it were just a sequence like [2,4,6,7] that does not contain a nested sequence, I would just directly pass them to the embedding layer. 

But, in my case, that's not possible. So, I have decided to one-hot encode my sequences. 

For example, 

input = [2, 3, [1,4], 5]

Its one hot representation would be :

```
one_hot = [[0,0,1,0,0,0],
                  [0,0,0,1,0,0],
                  [0,1,0,0,1,0],
                  [0,0,0,0,0,0]]
```
How do I get embeddings for such one hot vector sequences ? Or, could someone suggest better ways to represent my inputs to get embeddings, rather than using one-hot vectors ? "
50738,Explanation for GetInvSqrtQuantizedMultiplierExp()?,"Hey everyone,

I was looking at the L2 Normalization routine for TFLite, and noticed the use of `GetInvSqrtQuantizedMultiplierExp` function [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/common.h#L642). While I understand the high level goal of this routine is to find a multiplier which acts as 1 / sqrt(sum_of_squared_inputs) normalizing factor, I'm having trouble understanding how exactly is this computation being done, and what is the purpose and formulation for Newton-Raphson in this function? Any help would be appreciated. Thanks in advance.
"
50737,tfa.activations.snake - wrong function in docs,"## URL(s) with the issue:

https://www.tensorflow.org/addons/api_docs/python/tfa/activations/snake

## Description of issue (what needs changing):

The computed function in the source code is:

x + (1 - cos(2*frequency*x)) / (2*frequency)

but the function in the docs is:

(x + (1 - cos(2*frequency*x))) / (2*frequency)
"
50735,CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**This is an urgent issue! It has caused a production problem!**

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Amazon Sagemaker)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): **latest**: 2.5
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.020/8.202
- GPU model and memory: Tesla T4/13.8 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I updated my model and when I train, I get the following error:

`
2021-07-11T23:08:22.514-04:00	2021-07-12 03:08:22.053193: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: ""Softmax"" attr { key: ""T"" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: ""GPU"" vendor: ""NVIDIA"" model: ""Tesla T4"" frequency: 1590 num_cores: 40 environment { key: ""architecture"" value: ""7.5"" } environment { key: ""cuda"" value: ""11020"" } environment { key: ""cudnn"" value: ""8100"" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14474280960 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }

2021-07-11T23:08:22.514-04:00	2021-07-12 03:08:22.053330: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:689] Error in PredictCost() for the op: op: ""Softmax"" attr { key: ""T"" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: ""GPU"" vendor: ""NVIDIA"" model: ""Tesla T4"" frequency: 1590 num_cores: 40 environment { key: ""architecture"" value: ""7.5"" } environment { key: ""cuda"" value: ""11020"" } environment { key: ""cudnn"" value: ""8100"" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14474280960 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }

2021-07-11T23:08:32.516-04:00	2021-07-12 03:08:32.060022: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8

2021-07-11T23:08:34.517-04:00	2021-07-12 03:08:34.183639: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8202

2021-07-11T23:08:36.517-04:00	2021-07-12 03:08:36.256607: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11

2021-07-11T23:08:38.518-04:00	2021-07-12 03:08:38.161603: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11

2021-07-11T23:08:50.608-04:00

**2021-07-12 03:08:50.058288: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2021-07-12 03:08:50.058288: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountere**d`

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**LOGS:**
[logs.txt](https://github.com/tensorflow/tensorflow/files/6801798/logs.txt)

"
50734,ProtoCompile Error while building tf 2.5 from source,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary):  source
- TensorFlow version: 2.5.0
- Python version: 3.8.6
- Installed using : 
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): Visual Studio 2019
- No GPU

Build always fails to complete due to some Proto Compile error ( .pb.h files)
I have followed all the steps given in https://www.tensorflow.org/install/source_windows

**Configuration**
```
C:\tensorflow>python ./configure.py
You have bazel 3.7.2 installed.
Please specify the location of python. [Default is C:\Users\Sundara Rajan\AppData\Local\Programs\Python\Python38\python.exe]:


Found possible Python library paths:
  C:\Users\Sundara Rajan\AppData\Local\Programs\Python\Python38\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\Sundara Rajan\AppData\Local\Programs\Python\Python38\lib\site-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]: -march=native


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y
Eigen strong inline overridden.

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).
        --config=monolithic     # Config for mostly static monolithic build.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
```
**Error message**
```
C:\tensorflow>bazel --output_user_root=C:\bazel_build build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/python.exe
INFO: Reading rc options for 'build' from c:\tensorflow\.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from c:\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/python.exe --action_env PYTHON_LIB_PATH=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/lib/site-packages --python_path=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/python.exe --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --define=override_eigen_strong_inline=true
INFO: Found applicable config definition build:short_logs in file c:\tensorflow\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file c:\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:opt in file c:\tensorflow\.tf_configure.bazelrc: --copt=-march=native --host_copt=-march=native
INFO: Found applicable config definition build:windows in file c:\tensorflow\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file c:\tensorflow\.bazelrc: --define framework_shared_object=false
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (413 packages loaded, 26988 targets configured).
INFO: Found 1 target...
ERROR: C:/tensorflow/tensorflow/core/protobuf/BUILD:65:17: ProtoCompile tensorflow/core/protobuf/conv_autotuning.pb.h failed (Exit -1073741515): protoc.exe failed: error executing command
  cd C:/bazel_build/xv6zejqw/execroot/org_tensorflow
  SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0
    SET PYTHON_BIN_PATH=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/python.exe
    SET PYTHON_LIB_PATH=C:/Users/Sundara Rajan/AppData/Local/Programs/Python/Python38/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
  bazel-out/x64_windows-opt/bin/external/com_google_protobuf/protoc.exe --cpp_out=bazel-out/x64_windows-opt/bin -I. -Iexternal/com_google_protobuf/src -Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src tensorflow/core/protobuf/conv_autotuning.proto
Execution platform: @local_execution_config_platform//:platform
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 210.672s, Critical Path: 20.27s
INFO: 693 processes: 215 internal, 478 local.
FAILED: Build did NOT complete successfully
```
had built it once before similarly and had stopped at the same spot
The same error was mentioned in #30999 but that issue didnt have any solution and was closed"
50733,Increasing physical memory usage implemented with tensorflow.,"** Version Info **
Version: v3.9.2
Language: C++
OS Version: Centos 7.2 final
Tensorflow version: 2.4
Compiler: g++ 8.3

**What did you do?**
We are ready to use libtensorflow_cc 2.4 on machine learning platform and libtensorflow uses protobuf of which the Arena memory management is a requirement. We use the message GraphDef and SparseWeights (which are variables on stack) to deserialize data from pb files every 10 minutes. We see the usage of physical memory is increasing slowly when our application runs for a long time。
From the manual, I known that Arena is suggested for short-time variables and that is what we did. Using the pmap tool, i  see that a lot of memory are with the type of anonymous mapping, which are allocated by jemalloc.
What can we do to let the physical memory not to increase ?

**What did you expect to see**
The usage of physical memory is not increasing.

**What did you see instead?**
The physical memory is increasing slowly.

Make sure you include information that can help us debug (full error message, exception listing, stack trace, logs).
<img width=""1072"" alt=""截屏2021-07-12 下午5 19 13"" src=""https://user-images.githubusercontent.com/5698293/125266073-04045a80-e338-11eb-9722-a4e3637466ad.png"">
"
50731,Possibility to define operator version,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installation (pip package or built from source): pip package 2.3.0 CPU
- TensorFlow library (version, if pip package or github SHA, if built from source): from installation

### 2. Code

```
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet import preprocess_input

TEST_DIR = ""/mnt/Storage/training/unet_multi_class/dataset/kellogs/combo/valid/images""
#IMAGE_SIZE = [480, 640]
IMAGE_SIZE = [256, 256]

#converter = tf.lite.TFLiteConverter.from_saved_model('/media/sally/STORAGE/training/unet_multi_class/conversion/checkpoint')
model=tf.keras.models.load_model(""/mnt/Storage/training/unet_multi_class/Multiclass-Segmentation-in-Unet/conversion/model_non_custom_256x256.h5"")
converter = tf.lite.TFLiteConverter.from_keras_model(model)

def representative_data_gen():

  dataset_list = tf.data.Dataset.list_files(TEST_DIR + '/*.png')
  for i in range(100):
    image = next(iter(dataset_list))
    image = tf.io.read_file(image)
    image = tf.io.decode_png(image, channels=3)
    image = tf.image.resize(image, IMAGE_SIZE)
    image = tf.cast(image / 255., tf.float32)
    image = tf.expand_dims(image, 0)
    yield [image]

#converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = False
#converter.allow_custom_ops = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
# Ensure that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# Set the input and output tensors to uint8 (APIs added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model_quant = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)
input_type = interpreter.get_input_details()[0]['dtype']
print('input: ', input_type)
output_type = interpreter.get_output_details()[0]['dtype']
print('output: ', output_type)



with open('/mnt/Storage/training/unet_multi_class/Multiclass-Segmentation-in-Unet/conversion/model_non_custom_256x256.tflite', 'wb') as f:
  f.write(tflite_model_quant)
```


### 5. (optional) Any other info / logs

I've trained a UNet model according to these [intructions](https://colab.research.google.com/drive/1CCSM2FLOtHx0dPr1HgHFX0yLAgpOs7eT?usp=sharing#scrollTo=ikrzoG24qwf5) but with two classes instead of three. Converting and compiling the model works fine, but loading the model with the interpreter yields an error.

Error when loading the interpreter:
` Didn't find op for builtin opcode 'TRANSPOSE_CONV' version '3'`

 I'm on a custom aarch64 system and already needed to build tflite runtime 2.1.0 for python 3.6 and python 3.8 to get it running for other models. Do I need to upgrade to another tflite runtime version and if so which version? Or would it be possible to specify which version of the TRANSPOSE_CONV operator should be used to avoid this error?
 
 Best regards,
Sally
"
50730,markdown render incorrectly in operation_semantics#batchnormgrad,"## URL(s) with the issue:

https://www.tensorflow.org/xla/operation_semantics#batchnormgrad

## Description of issue (what needs changing):

the brachnormgrad table render incorrectly

### Clear description

![image](https://user-images.githubusercontent.com/1769997/125224912-fb446200-e300-11eb-9b90-39edc743582f.png)

### Correct links

no find yet

markdown to html used google internel doc system.
"
50728,TF25 inconsistency between eager and graph mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes, I use a custom layer.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

CentOS 7, Ubuntu 20.04

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

not mobile

- TensorFlow installed from (source or binary):

pypi

- TensorFlow version (use command below):

2.5.0

- Python version:

3.7

- CUDA/cuDNN version:

11


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

T2.5 no longer supports creating layers using Conv1D as base class when the derived class 
changes the output shape.

The problem appears only in graph mode, eager mode runs fine


**Describe the expected behavior**

Similar to TF2.4 it should be possible to create new layer types that change the output shape
of the final result by means of deriving from  the Conv1D layer


**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):

yes

- Briefly describe your candidate solution(if contributing):


The problem is in  lines 270- 273 in convolutional.py

```
    if not context.executing_eagerly():
      # Infer the static output shape:
      out_shape = self.compute_output_shape(input_shape)
      outputs.set_shape(out_shape)
```

Calling self.compute_output_shape calls the method of the derived class.
This is not providing the correct value.

Proposed solutions:

1) the related lines did not exist in previous versions of TF2, so probably they should simply be removed.
In any case they will introduce a difference in behavior between eager and graph mode.  Which is probably a problem

2) if the explicit imposition of the output shape is required in tf 2.5 then it should be performed like

```
   if not context.executing_eagerly():
      # Infer the static output shape:
      out_shape = Conv.compute_output_shape(self, input_shape)
      outputs.set_shape(out_shape)
```


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

This script fails on TF2.5  but runs fine on TF2.4. It also runs fine under TF2.5 
once the `@tf.function` annotation is removed

```
import tensorflow as tf
print(tf.version.VERSION)

class MyFlatConv(tf.keras.layers.Conv1D):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        

    def compute_output_shape(self, input_shape):

        res_shape = super().compute_output_shape(input_shape)
        return res_shape[0], res_shape[1]*res_shape[2]

    @tf.function
    def call(self, inputs):
        res = super().call(inputs)

        return tf.reshape(res, (res.shape[0], -1))

if __name__ == ""__main__"":

    mm = MyFlatConv(filters=3, kernel_size=3, padding=""same"")
    zz= tf.zeros((3,10,3), dtype=tf.float32)
    print(mm(zz))

```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
50727,Translate use of Adam Optimizer from TF 1 to TF2 causing TF2 to coredump,"**System information**

- OS Platform and Distribution: Ubuntu 21.04
- TensorFlow installed from (source or binary): pip install tensorflow=2.5.0
- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0
- Python version: 3/8/10
- CUDA/cuDNN version: cuda_11.3.r11.3/compiler.29920130_0
- GPU model and memory: NVIDIA GeForce RTX 2080 Ti, 11GB

**Describe the current behavior**

I am trying to translate this [Tensorflow 1 notebook](https://github.com/mgroncki/IPythonScripts/blob/master/BermudanTensorFlow.ipynb) by Matthias Groncki to do Bermudan option pricing, from Tensorflow 1 to Tensorflow 2.

To move from non-eager graph mode with placeholders to eager mode with `tf.function`s, I have had to unroll his code and isolate spots where the unrolling runs into problems.

My use of the Adam optimizer is causing Tensorflow versions 2.4.1 and 2.5 with GPU to coredump. 

NOTE: This is pure Tensorflow 2 code with eager mode on, no use of TF 1 compatibility features, and no use of NumPy.

**Describe the expected behavior**

No coredump.  I think it's coredumping because the expression `y = E_t[:, i+1:i+2]`, where `i=1` and the shape of `E` is (10000,2), is giving an empty tensor for `y` with signature

`    <tf.Tensor: shape=(10000, 0), dtype=float32, numpy=array([], shape=(10000, 0), dtype=float32)>`

Tensorflow could do better than to coredump in this case, there should be guards in the tensor operations to raise exceptions in Python rather than simply die.

**[Contributing](https://www.tensorflow.org/community/contribute)**

I don't know candidate solution, I am not a TF internals programmer.

**Standalone code to reproduce the issue**

```
import tensorflow as tf

N_samples_learn = 10000
N_samples_pricing = 100000
calldates = 2
tf.random.set_seed(7)

N = tf.random.normal((N_samples_learn,calldates))
N_pricing = tf.random.normal((N_samples_pricing,calldates))
(S_0, strike, exTimes, impliedvol, riskfree_r) = (100., 110., tf.constant([1., 1.]), 0.2, 0.03)

number_call_dates = len(exTimes)       
dW = tf.sqrt(exTimes)*N

S=tf.Variable(S_0)
r=tf.Variable(riskfree_r)
sigma=tf.Variable(impliedvol)
previous_exercises = 0

# Last exercise date
with tf.GradientTape() as tape:
    S_t = S * tf.math.cumprod(tf.exp((r-sigma**2/2)*exTimes + sigma*dW), axis=1)
    E_t = tf.exp(-r*tf.cumsum(exTimes))*tf.maximum(S_t-strike, 0)
    inMoney = tf.cast(tf.greater(E_t[:,-1], 0.), tf.float32)
    exercise = inMoney * (1-previous_exercises)
    npv = exercise*E_t[:,-1]
    npv = tf.reduce_mean(npv)

greeks = tape.gradient(npv, [S, r, sigma])

training_functions = []
for i in range(number_call_dates):
    w = tf.Variable(tf.random.normal((3,1))*0.1)
    b = tf.Variable(tf.ones(1)*1)
    training_functions.append((w, b))
    state = S_t[:, i]
    feature_0 = tf.pow(state,0)
    feature_1 = tf.pow(state,1)
    feature_1_mean = tf.reduce_mean(feature_1)
    feature_1_std = tf.sqrt(tf.reduce_sum(tf.square(feature_1 - feature_1_mean))/(N_samples_pricing+1))
    feature_1_norm = (feature_1 - feature_1_mean) / feature_1_std
    feature_2 = 2*tf.pow(state,2)-1
    feature_2_mean = tf.reduce_mean(feature_2)
    feature_2_std = tf.sqrt(tf.reduce_sum(tf.square(feature_2 - feature_2_mean))/(N_samples_pricing+1))
    feature_2_norm = (feature_2 - feature_2_mean) / feature_2_std
    feature_3 = 4*tf.pow(state,3)-3*feature_1
    feature_3_mean = tf.reduce_mean(feature_3)
    feature_3_std = tf.sqrt(tf.reduce_sum(tf.square(feature_3 - feature_3_mean))/(N_samples_pricing+1))
    feature_3_norm = (feature_3 - feature_3_mean) / feature_3_std
    features = tf.stack([feature_1_norm, feature_2_norm, feature_3_norm])
    X = tf.transpose(features)
    contValue = tf.add(tf.matmul(X, w),b)
    inMoney = tf.cast(tf.greater(E_t[:,i], 0.), tf.float32)
    exercise = tf.cast(tf.greater(E_t[:,i], contValue[:,0]), tf.float32) * inMoney * (1-previous_exercises)
    previous_exercises += exercise
    npv += exercise*E_t[:,i]

i=number_call_dates-1

(w, b) = training_functions[i]
y = E_t[:, i+1:i+2]
X = S_t[:, i]

X = tf.stack([X**1, 2*X**2-1, 4*X**3 - 3 * X], axis=1)

X = (X - tf.reduce_mean(X, axis=0)) / tf.math.reduce_std(X, axis=0)

epoch = 0

input_x = X[E_t[:,i]>0]
input_y = y[E_t[:,i]>0]
y_hat = tf.Variable(tf.add(tf.matmul(input_x,w), b))
pre_error = tf.Variable(tf.pow(input_y-y_hat,2))
error = lambda: tf.reduce_mean(pre_error)

opt = tf.keras.optimizers.Adam(learning_rate=0.1)

train = opt.minimize(error, [pre_error])  ### COREDUMP
```
**Note:** I tried to create a simpler coredumpy example like

```
import tensorflow as tf
foo=tf.Variable([[1.,1.]])
foo=foo[:,2:3]
bar=lambda: foo
opt = tf.keras.optimizers.Adam(learning_rate=0.1)
train = opt.minimize(bar, [foo])
```
However, this shorter version doesn't coredump, it instead raises the exception

`AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_in_graph_mode'`

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
[tf_log.txt](https://github.com/tensorflow/tensorflow/files/6797227/tf_log.txt)
"
50726,Print a warning or error when an empty TFRecord file is used.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

This is a feature request in the sense that it's asking for a new functionality to make a scenario not fail silently. Not a substantial feature for TF, just a quality of life change.


**Describe the feature and the current behavior/state.**

Many people use TFRecord generation scripts that fail silently if they can't find images and generate empty TFRecords. When Tensorflow encounters empty TFRecords, it fails silently, leaving users confused:

https://github.com/tensorflow/models/issues/9581

**Will this change the current api? How?**

No

**Who will benefit with this feature?**

All new users

**Any Other info.**
"
50725,TFlite from keras model full integer quantization fails with zero padding,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): oneAPI AI Analytics Toolkit
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.10
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Full integer quantization fails with RuntimeError: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context->paddings, 0) != op_context->dims (4 != 3)Node number 0 (PAD) failed to prepare.

**Describe the expected behavior**
Model should be optimized

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**



		def representative_dataset():

			data_dir = pathlib.Path(
				self.helpers.confs[""data""][""train_dir""])
			data = list(data_dir.glob(
				'*' + self.helpers.confs[""data""][""file_type""]))

			for rimage in data:
				fpath = str(rimage)
				fname = os.path.basename(rimage)

				image = self.data.resize(fpath, self.helpers.confs[""data""][""dim""])

				if image.shape[2] == 1:
					image = np.dstack(
						[image, image, image])

				print(image.shape)

				yield [image]

		converter = tf.lite.TFLiteConverter.from_keras_model(model)
		converter.optimizations = [tf.lite.Optimize.DEFAULT]
		converter.representative_dataset = representative_dataset
		converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
		converter.inference_input_type = tf.int8  # or tf.uint8
		converter.inference_output_type = tf.int8  # or tf.uint8
		tflite_model = converter.convert()

**Other info / logs** Include any logs or source code that would be helpful

Shape is (100, 100, 3) - 3D not 4D

  File ""/home/nuci71/Acute-Lymphoblastic-Leukemia-TFLite-Classifier/modules/model.py"", line 195, in convert_to_tflite_test
    tflite_model = converter.convert()
  File ""/home/nuci71/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1058, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File ""/home/nuci71/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 795, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""/home/nuci71/.local/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 522, in _calibrate_quantize_model
    self.representative_dataset.input_gen)
  File ""/home/nuci71/.local/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 172, in calibrate
    self._calibrator.Prepare([list(s.shape) for s in sample])
RuntimeError: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context->paddings, 0) != op_context->dims (4 != 3)Node number 0 (PAD) failed to prepare.

Model:


self.tf_model = tf.keras.models.Sequential([
	tf.keras.layers.ZeroPadding2D(
		padding=(2, 2), input_shape=self.data.X_train.shape[1:]),
	tf.keras.layers.Conv2D(30, (5, 5), strides=1,
		padding=""valid"", activation='relu'),
	tf.keras.layers.ZeroPadding2D(padding=(2, 2)),
	tf.keras.layers.Conv2D(30, (5, 5), strides=1,
		padding=""valid"", activation='relu'),
	tf.keras.layers.MaxPooling2D(
		pool_size=(2, 2), strides=2, padding='valid'),
	tf.keras.layers.Flatten(),
	tf.keras.layers.Dense(2),
	tf.keras.layers.Activation('softmax')
"
50721,Model with nested input spec fails,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.9

**Describe the current behavior**
The [logic](https://github.com/tensorflow/tensorflow/blob/0d4c07f5ae1b264bdfbae9e4d683d769852d88db/tensorflow/python/keras/engine/functional.py#L266)  to test if a structure is nested is wrong. Example of failing case: `{""a"": {""b"": 1}}`

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing):
Change this [line](https://github.com/tensorflow/tensorflow/blob/0d4c07f5ae1b264bdfbae9e4d683d769852d88db/tensorflow/python/keras/engine/functional.py#L266) from:
```python
if (isinstance(self._nested_inputs, (dict, list, tuple)) and
        len(self._nested_inputs) != len(self.inputs)):
```
to:
```python
if max([len(path) for path in nest.yield_flat_paths(
        self._nested_inputs)]) > 1:
```

**Standalone code to reproduce the issue**

```python
import tensorflow as tf
import numpy as np

input_tensor_shape = [16]
random_tensor = np.random.random([1]+input_tensor_shape)

def sequential():
  layers = [tf.keras.layers.InputLayer(input_shape=input_tensor_shape),
            tf.keras.layers.Dense(8)]
  return tf.keras.Sequential(layers=layers)

network = sequential()
network2 = sequential()

nested_input = {'input': {'sub_input1': network.input,
                          'sub_input2': network2.input}}

model = tf.keras.Model(inputs=nested_input, outputs=network.output)

input = {'input': {'sub_input1': random_tensor,
                   'sub_input2': random_tensor}}
# Works
model(input)

fail_nested_input = {'input': {'sub_input': network.input}}
fail_model = tf.keras.Model(inputs=fail_nested_input, outputs=network.output)

input = {'input': {'sub_input': random_tensor}}
# Fails
fail_model(input)
```
"
50720,Docker image tensorflow:latest or tensorflow:2.5.0 is missing git,"Following the steps in Docker Linux builds / CPU-only from https://www.tensorflow.org/install/source , I noticed git was missing when issuing git pull. It works with the :devel image, but not with :latest or :2.5.0.
Even installing git manually inside the container is not enough, because the source code is also missing in /tensorflow.
Perhaps the documented steps only work for certain versions?"
50719,Cannot convert a symbolic Keras input/output to a numpy array when using TF Lite converter,"**System information**

- OS Platform and Distribution: Linux Ubuntu 20.10
- TensorFlow version: 2.4.1
- Python version: 3.8

**Describe the problem**

Hi, I need to implement a custom convolution layer which is not supported by Tensorflow and TF Lite, so I tried to define it by using this link: https://www.tensorflow.org/guide/create_op (in order to have a TF operator for the op) and this link: https://www.tensorflow.org/lite/guide/ops_custom (to have a TF Lite operator for this op). However, when I try to convert the operator with TF Lite converter, I get this error:

     Traceback (most recent call last):
     File ""es.py"", line 39, in <module>
     converter =  
     tf.lite.TFLiteConverter.from_concrete_functions([tf.function(convol1d).get_concrete_function(inp)])
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"",    
     line 1299, in get_concrete_function
     concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"",    
     line 1205, in _get_concrete_function_garbage_collected
     self._initialize(args, kwargs, add_initializers_to=initializers)
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"",     
     line 725, in _initialize 
     self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-   
     access
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line  
     2969, in _get_concrete_function_internal_garbage_collected
     graph_function, _ = self._maybe_define_function(args, kwargs)
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line    
     3314, in _maybe_define_function
     self._function_spec.canonicalize_function_inputs(*args, **kwargs)
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line     
     2697, in canonicalize_function_inputs
     inputs, flat_inputs, filtered_flat_inputs = _convert_numpy_inputs(inputs)
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line  
     2753, in _convert_numpy_inputs
     a = _as_ndarray(value)
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line    
     2711, in _as_ndarray
     return value.__array__()
     File ""/home/em/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine   
     /keras_tensor.py"", line 273, in __array__
     raise TypeError(
     TypeError: Cannot convert a symbolic Keras input/output to a numpy array. This error may    
     indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or,   
     you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register 
     dispatching, preventing Keras from automatically converting the API call to a lambda layer in the 
     Functional Model.

The code is like this:

    import tensorflow as tf
    tf.config.run_functions_eagerly(True)
    from keras.datasets import mnist
    from keras.models import Model
    from keras.layers import add,Input,Activation,Flatten,Dense

    def convol(inp):
        conv_module = tf.load_op_library('./conv.so')
        x = conv_module.conv(inp, name=""Conv"")
        return x
   
    def read_mnist(path):
        (train_x,train_y), (test_x,test_y)=mnist.load_data()
        return train_x,train_y,test_x,test_y

    def tcn(train_x,train_y,test_x,test_y):
          inp=Input(shape=(28,28))
          x = convol(inp)
          x=Flatten()(x)
          x=Dense(10,activation='softmax')(x)
          model=Model(inputs=inp,outputs=x)
          model.summary()
          model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics= 
          ['accuracy'])
           model.fit(train_x,train_y,batch_size=100,epochs=10,validation_data=(test_x,test_y))
           pred=model.evaluate(test_x,test_y,batch_size=100)
           print('test_loss:',pred[0],'- test_acc:',pred[1])
    
     train_x,train_y,test_x,test_y=read_mnist('MNIST_data')
     tcn(train_x,train_y,test_x,test_y)
     tflite_model_name = 'net'
     inp=Input(shape=(28,28))
     converter =   
     tf.lite.TFLiteConverter.from_concrete_functions([tf.function(convol).get_concrete_function(inp)])
     converter.allow_custom_ops = True
     tflite_model = converter.convert()
     open(tflite_model_name + '.tflite', 'wb').write(tflite_model)




"
50718,Why is it so slow?,"I'm using MacBook Air with M1 chip. OS version is Big Sur 11.4.
`which python`
`/Users/dmitry/Applications/Miniforge3/bin/python`
I run the following code using [tensorflow-macos](https://developer.apple.com/metal/tensorflow-plugin/) and [tensorflow_macos](https://github.com/apple/tensorflow_macos), respectively.
`import tensorflow as tf`
`mnist = tf.keras.datasets.mnist`
`(x_train, y_train), (x_test, y_test) = mnist.load_data()`
`x_train, x_test = x_train / 255.0, x_test / 255.0`
`model = tf.keras.models.Sequential([`
 `     tf.keras.layers.Flatten(input_shape=(28, 28)),`
 `     tf.keras.layers.Dense(128, activation='relu'),`
 `     tf.keras.layers.Dropout(0.2),`
 `     tf.keras.layers.Dense(10)`
`])`
`predictions = model(x_train[:1]).numpy()`
`tf.nn.softmax(predictions).numpy()`
`loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)`
`loss_fn(y_train[:1], predictions).numpy()`
`model.compile(optimizer = 'sgd', loss = loss_fn)`
`model.fit(x_train, y_train, epochs=100)`

I got this! with [tensorflow-macos](https://developer.apple.com/metal/tensorflow-plugin/) and python3.9:
1875/1875 [==============================] - 8s 4ms/step - loss: 0.7026
Epoch 2/100
1875/1875 [==============================] - 8s 4ms/step - loss: 0.3872
Epoch 3/100
1875/1875 [==============================] - 8s 4ms/step - loss: 0.3284
Epoch 4/100
1875/1875 [==============================] - 8s 4ms/step - loss: 0.2891
Epoch 5/100
1875/1875 [==============================] - 8s 4ms/step - loss: 0.2622


with [tensorflow_macos](https://github.com/apple/tensorflow_macos) and python3.8 env:
Epoch 1/100
1875/1875 [==============================] - 1s 276us/step - loss: 1.2181
Epoch 2/100
1875/1875 [==============================] - 1s 270us/step - loss: 0.4678
Epoch 3/100
1875/1875 [==============================] - 1s 269us/step - loss: 0.3935
Epoch 4/100
1875/1875 [==============================] - 1s 271us/step - loss: 0.3507
Epoch 5/100
1875/1875 [==============================] - 1s 270us/step - loss: 0.3231

Why [tensorflow-macos](https://developer.apple.com/metal/tensorflow-plugin/) is so slower than [tensorflow_macos](https://github.com/apple/tensorflow_macos)?Did I miss something?

"
50714,RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 13 (FlexRandomStandardNormal) failed to prepare.,"hi

i use colab to train and  save an VAE model (use default colab environment ,tensorflow version is 2.5.0)
i want deploy model on jetson nano ,
i install tflite_runtime version is  2.5.0 

when running(  interpreter.allocate_tensors() ) error come:

usr/bin/python3 /home/jz/Desktop/test/demo/testTFLiteRuntime.py
Traceback (most recent call last):
File ""/home/jz/Desktop/test/demo/testTFLiteRuntime.py"", line 6, in <module>
interpreter.allocate_tensors()
File ""/home/jz/.local/lib/python3.6/site-packages/tflite_runtime/interpreter.py"", line 259, in allocate_tensors
return self._interpreter.AllocateTensors()
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 13 (FlexRandomStandardNormal) failed to prepare.

i think tflite_runtime 2.5.0 is supported RandomStandardNormal op
so i don't know what i missing...

edit:
in colab enviroment,
i install tflite_runtime 2.5.0  and test 
interpreter init well and allocate_tensors() run well too 

https://stackoverflow.com/questions/68341183/jetson-nano-install-tflite-runtime-2-5-0-didt-supported-randomstandardnormal-op

thank you for any help~!!
"
50713,tf.math.segment_sum XLA,"tf.math.unsorted_segment_sum works on XLA (jit_compile=True), but tf.math.segment_sum is reported as missing op.
Is it possible to implement tf.math.segment_sum on XLA?"
50712,tf.repeat memory consumption and performance,"Windows 10
TF 2.5.0
Python 3.8
CUDA 11.2
RTX 3060 6 GB

tf.repeat consumes much more memory with axis=0 in comparison if I create the same array with tf.gather.

```
D = 4000
a = tf.ones((D, 20))
Ns = tf.repeat([1000], D)
b = tf.repeat(a, Ns, axis=0)
tf.config.experimental.get_memory_info('GPU:0')
# {'current': 320337920, 'peak': 676338176}
```

```
D = 4000
a = tf.ones((D, 20))
Ns = tf.repeat([1000], D)
Ns_r = tf.range(0, D, dtype=tf.int64)
Ns_r = tf.repeat(Ns_r, Ns)
c = tf.gather(a, Ns_r, axis=0)
tf.config.experimental.get_memory_info('GPU:0')
# {'current': 352337920, 'peak': 352337920}
```

Also my code ( I might share it, but is quite huge) runs 58 sec when I use tf.gather on each iteration and 73 sec when I use repeat, that is a bit strange (as tf.repeat is just a particular case of gather in this case). 
When I add creration of Ns_r on each it too, the time is same, but I do not consider tf.gather as optimal - the elements are ordered and just repeated, while gather does not use this assumption"
50711,My model seems not using my custom designed loss function,"I defined a triplet loss function as follow:

```
def triplet_loss( self, alpha ):
     def loss( y_true, y_pred ):
        anc, pos, neg = y_pred[ :, :emb_size ], y_pred[ :, emb_size:2 * emb_size ], y_pred[ :, 2 * emb_size: ]
        distance1 = tf.sqrt( tf.reduce_sum( tf.pow( anc - pos, 2 ), 1, keepdims=True ) )
        distance2 = tf.sqrt( tf.reduce_sum( tf.pow( anc - neg, 2 ), 1, keepdims=True ) )
        return tf.reduce_mean( tf.maximum( distance1 - distance2 + alpha, 0. ) )
    return loss
```

and then I compile it with my model by

   

    self.model.compile(loss=self.triplet_loss(alpha=margin,
                                              # emb_dim=emb_size
                                               ),
                        optimizer=optimizer )


then the model start training process by using `self.model.train_on_batch(data)`,
```
`Iteration 1/10000: Train loss: 4.558698, lr = 0.001000
Iteration 2/10000: Train loss: 4.558681, lr = 0.001000
Iteration 3/10000: Train loss: 4.558654, lr = 0.001000
Iteration 4/10000: Train loss: 4.558623, lr = 0.001000`
```
However, the problem is that I didn't even pass the emb_size  to the loss function. And I tried to remove the every thing in my function loss in my loss function as:
```
`def triplet_loss( self, alpha ):
    def loss( y_true, y_pred ):
        print(""My loss function"")
    #     anc, pos, neg = y_pred[ :, :emb_size ], y_pred[ :, emb_size:2 * emb_size ], y_pred[ :, 2 * emb_size: ]
    #     distance1 = tf.sqrt( tf.reduce_sum( tf.pow( anc - pos, 2 ), 1, keepdims=True ) )
    #     distance2 = tf.sqrt( tf.reduce_sum( tf.pow( anc - neg, 2 ), 1, keepdims=True ) )
    #     return tf.reduce_mean( tf.maximum( distance1 - distance2 + alpha, 0. ) )
    return loss`
```
and run the training program again, the training can still working, and the loss is similar to above

```
Iteration 1/10000: Train loss: 4.556189, lr = 0.001000
Iteration 2/10000: Train loss: 4.556171, lr = 0.001000
Iteration 3/10000: Train loss: 4.556145, lr = 0.001000
```

So I think the keras is not using my loss function at all, why would this happen? what should I do to fix this problem?

The complete code is [here](https://github.com/Colin-Guolin/Oneshot-Learning/blob/main/SiameseNetworkWithTripletLoss.py)

Please help me, I have struggled for a long time. Thanks in advance"
50710,Understanding How Masking Affects BCE Loss Function,"Hi, I'm experimenting with masking and have come across an interesting observation. I've created a simple GRU-based model with zeroed-out weights and biases along with a simple X and Y tensor. Theoretically, because my weights and biases are set to zero I should get the same loss value for the same dataset regardless if masking is on or not. However, I find that masking affects my results and I'd like more clarification on why this is happening. Below is my code to reproduce the difference. Additionally, I am using version 2.4.1 and 2.4.0 for tensorflow and keras, respectively

```
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow.keras import regularizers
from tensorflow.keras import initializers
from tensorflow.keras import Model
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam

GRU_SIZE = 50
DENSE_DIM = 200

# generate data
data = tf.random.uniform([2, 4, 4], maxval=2, dtype=tf.int32, seed=1)
data = tf.cast(data, tf.float32)
data = K.eval(tf.identity(data))

# zero-out specific timesteps in each patient
data[0, 2, :] = 0.0
data[0, 3, :] = 0.0
data[1, 2, :] = 0.0
data[1, 3, :] = 0.0

# use the 1st n-1 timesteps in X to predict the last n-1 timesteps in Y
x_dummy_data = data[:, 0:-1, :]
y_dummy_data = data[:, 1:, :]

# create the masked model
input_shape = (x_dummy_data.shape[1], x_dummy_data.shape[2])
inputs = layers.Input(shape=input_shape)
masking = layers.Masking(mask_value=0, input_shape=input_shape)
input_masked = masking.compute_mask(inputs)
output1 = layers.Dense(DENSE_DIM)(inputs)
output3 = layers.GRU(GRU_SIZE, return_sequences=True)(output1, mask=input_masked)
output4_code = layers.Dense(input_shape[1], 
                                                   activation='sigmoid', 
                                                   name=""output_code"")(output3)
model_mask = Model(inputs=inputs, outputs = output4_code)
model_mask.summary()
model_mask.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, from_logits=False),
                                     optimizer=Adam(learning_rate=1e-4))

# set weights and bias to zero
for ix, layer in enumerate(model_mask.layers):
     weights = layer.get_weights()
     for arr in weights:
        arr[(arr > 0) | (arr < 0)] = 0
     layer.set_weights(weights) 

# create the unmasked model
input_shape = (x_dummy_data.shape[1], x_dummy_data.shape[2])
inputs = layers.Input(shape=input_shape)
output1 = layers.Dense(DENSE_DIM)(inputs)
output3 = layers.GRU(GRU_SIZE, return_sequences=True)(output1)
output4_code = layers.Dense(input_shape[1], 
                                                   activation='sigmoid', 
                                                   name=""output_code"")(output3)
model_unmask = Model(inputs=inputs, outputs = output4_code)
model_unmask.summary()
model_unmask.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, from_logits=False),
                                     optimizer=Adam(learning_rate=1e-4))

# set weights and bias to zero
for ix, layer in enumerate(model_unmask.layers):
     weights = layer.get_weights()
     for arr in weights:
        arr[(arr > 0) | (arr < 0)] = 0
     layer.set_weights(weights) 

# evaluate on fake data
model_unmask.evaluate(x_dummy_data, y_dummy_data)
model_mask.evaluate(x_dummy_data, y_dummy_data)
```

The model_unmask.evaluate leads to a loss of 0.6931471824645996, while the masked model is 0.4620981216430664. Can you explain how the latter is calculated? If weights and biases are set to 0 and the last layer is sigmoid activated then the only input into the loss function is a tensor of 0.5's. Shouldn't these both be the same when you take an average over the batch?"
50709,Failed precondition: Cannot compute input sources for dataset of type PaddedBatchDatasetV2,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.6.0 rc0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2 8.1
- GPU model and memory:

When I use bucket_by_sequence_length function, program appear the following error message: 

2021-07-10 03:46:46.503910: E tensorflow/core/framework/dataset.cc:552] Failed precondition: Cannot compute input sources for dataset of type PaddedBatchDatasetV2, because sources could not be computed for input dataset of type Window

"
50706,Saved model loading : KeyError: '__inference_depthwise_conv2d_layer_call_fn_126',"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.5
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1
- GPU model and memory: 2080 Ti

**Describe the current behavior**

Please download the scripts to reproduce from : https://drive.google.com/drive/folders/15cajAZ9sAZ2Uyix8sDVSYku6QCqDCec7?usp=sharing

Command to run : `python sample.py`.

I have a simple model with input layer and a depthwise conv2d layer. I quantize this model by adding quantize_and_dequantize nodes at the input of depthwiseconv2d layer (commented in the code). When I save the model and load it back, I see the following 

```
  File ""/home/dperi/Downloads/py3/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 544, in <lambda>
    ""function"": lambda: self._recreate_function(proto.function),
  File ""/home/dperi/Downloads/py3/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 586, in _recreate_function
    proto, self._concrete_functions), setattr
  File ""/home/dperi/Downloads/py3/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 295, in recreate_function
    concrete_function_objects.append(concrete_functions[concrete_function_name])
KeyError: '__inference_depthwise_conv2d_layer_call_and_return_conditional_losses_117'
```

If I change the depthwise conv2d layer to a regular conv2d layer, the saving and loading quantized model works fine. This is weird and I'm not sure why that's happening. 
Can anyone help me resolve the issue ? 

Related issues  that I checked : There are similar issues filed but the comments were not helpful for me. 
https://github.com/tensorflow/tensorflow/issues/42004
https://github.com/tensorflow/tensorflow/issues/45945

**Describe the expected behavior**
Saved model loading works fine. 

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes):

**Standalone code to reproduce the issue**

Please download the scripts to reproduce from : https://drive.google.com/drive/folders/15cajAZ9sAZ2Uyix8sDVSYku6QCqDCec7?usp=sharing

"
50705,tf.saved_model.save() much slower than tf.compat.v1.saved_model.loader.load(),"**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Ubuntu 18.04.5 LTS
- TensorFlow installed from: binary
- TensorFlow version: 2.3.2
- Python version: 3.8.5
- CUDA/cuDNN version: 11.1.74 / 8.0.5
- GPU model and memory: NVidia Tesla V100-SXM2-32GB

**Describe the current behavior**
To load a `tf.Module` saved with `tf.saved_model.save()`, `tf.saved_model.load()` is much slower than `tf.compat.v1.saved_model.loader.load()`
(4x slower in the attached colab)

**Describe the expected behavior**
Should be approximately the same time.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1baHS4efEYUP_BCvP8OzStMe9zv92vQhs?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
We have strict latency requirements and need to use `tf.compat.v1.saved_model.loader.load()`, extract operations and tensors from the graph to use `session.run()` to meet them.

The same was observed with TF2.5.0"
50704,Retrieving the Unreduced Losses,"If we set the reduction in our binary cross entropy loss to tf.losses.Reduction.NONE when we compile our model (code below) is there a way to retrieve the unreduced losses when we evaluate on a sample?

```
model.compile(loss= tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=False),
              optimizer=Adam(learning_rate=1e-4))
```

I'm running into an issue where the loss in my model (with zeroed-out weights and bias - code below on how i'm doing this) is not what I'm expecting.

```
for ix, layer in enumerate(model.layers):
      weights = layer.get_weights()
      for arr in weights:
        arr[(arr > 0) | (arr < 0)] = 0
      layer.set_weights(weights)
```

So I'd like to diagnose how my model is calculating the loss by looking at output from the 3 stages of reduction: NONE, SUM, and SUM_OVER_BATCH_SIZE
"
50702,AttributeError: 'ReLU' object has no attribute '_saved_model_inputs_spec',"Got following error `AttributeError: 'ReLU' object has no attribute '_saved_model_inputs_spec'` when trying to export a model (`tf.keras.models.save_model`) with an `input_signature`.

-> I could solve it by switching `tensorflow.keras.layers.ReLU()(x)` to `tf.nn.relu(x)`

<br>

Tested in tf=2.4.0
Stack trace:
```
/Scribosermo/extras/exporting/model.py:164 call  *
    x = self.model(x)
/Scribosermo/training/scode/nets/quartznet.py:221 call  *
    x = self.model(x, training=False)
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:786 __call__  **
    outputs = call_fn(cast_inputs, *args, **kwargs)
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:424 call
    return self._run_internal_graph(
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/functional.py:560 _run_internal_graph
    outputs = node.layer(*args, **kwargs)
/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/base_layer.py:1018 __call__
    if self._saved_model_inputs_spec is None:

AttributeError: 'ReLU' object has no attribute '_saved_model_inputs_spec'
```"
50697,TfLite static MT build ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- TensorFlow installed from (source or binary):
- TensorFlow version: 2.5
- Python version: 3.9
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): Bazel 2.7.2
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


Hi, 
I'm trying to use TfLite static library in a visualProjet build in MT.
My issue is that TfLite is build in MD and even if I tried to force the MT build ( by adding ""set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} /MT"")"" in TfLite cmake and every dependances ), I still have error like :

Error LNK2001	Unresolved external symbol  ""void __cdecl ruy::KernelFloatAvx(struct ruy::KernelParamsFloat<8,8> const &)"" (?KernelFloatAvx@ruy@@YAXAEBU?$KernelParamsFloat@$07$07@1@@Z)peerconnection_client	.......\tensorflow-lite.lib(fully_connected.obj)

Does someone has already build TfLite as a static MT lib ? 

Thanks"
50696,Snapshot not saved in tf.data.experimental.save,"Unable to load tf dataset at a later stage as the snapshot is not saved while running  - 
```
# tf.data.experimental.save(
#     ds_train, path = train_ds_path, compression=None, shard_func=None
# )
```

What is the solution for this?

I have to save a tf dataset and reload it later.

"
50695,TFLite Variable Batch Size for Models,"Lets say my TFLite Model (mobilenet_v1) whose size is [1,224,224,3] where 1 is batch size.

I want to run for batch size 2. 

```
l = np.ones((2,224,224,3), dtype = 'float32');
interpreter.reset_all_variables()
interpreter.resize_tensor_input(0, [2, 224, 224, 3])
interpreter.allocate_tensors()
interpreter.set_tensor(input_details[0][""index""], l)
interpreter.invoke()
```

Will the code I mentioned works for any TFLite model irrespective of any operations involved in model ?
Can I rely on the code for any TFLite Model ?


I got issue with Variable sequence length for few models. So wanted to confirm whether the same issue holds for variable batch size . 
Variable Sequence length is not supported for few operations - https://github.com/tensorflow/tensorflow/issues/44819 (confirmed from this issue).
So needed a confirmation regarding the support of variable batch size and usage of the code I mentioned.
"
50694,Error when applying tf.map_fn on symbolic tensors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): tensorflow-gpu 2.3.0 (from conda install - he13fc11_0)
- Python version: 3.8.10
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: cudatoolkit 10.1.243 (from conda install), cudnn 7.6.5 (from conda install)
- GPU model and memory: NVIDIA GeForce GT 730M (1GB)

**Current behavior**
Error when applying tf.map_fn on symbolic tensors

**Describe the expected behavior**
No error when applying tf.map_fn on symbolic tensors

**Standalone code to reproduce the issue**
This is a toy example, of course I would like to perform a specific per-row function:

```
import tensorflow as tf
input = tf.keras.layers.Input(shape=[1,1,3], 
                              batch_size=4,
                              dtype=tf.double)
result = tf.map_fn(lambda x: x,
                   input)
```

I would like the function to be applied on each of the 4 elems of the batch dimension.

**Traceback:**
```
Traceback (most recent call last):

  File ""<ipython-input-119-118c58833a26>"", line 4, in <module>
    result = tf.map_fn(lambda x: x,

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\util\deprecation.py"", line 574, in new_func
    return func(*args, **kwargs)

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\ops\map_fn.py"", line 633, in map_fn_v2
    return map_fn(

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\ops\map_fn.py"", line 440, in map_fn
    elems_batchable_ta = [

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\ops\map_fn.py"", line 441, in <listcomp>
    tensor_array_ops.TensorArray(

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\ops\tensor_array_ops.py"", line 1071, in __init__
    self._implementation = implementation(

  File ""C:\ProgramData\Anaconda3\envs\py3tf2_3\lib\site-packages\tensorflow\python\ops\tensor_array_ops.py"", line 718, in __init__
    self._tensor_array = [None for _ in range(size)]

TypeError: 'Tensor' object cannot be interpreted as an integer
```
"
50693,Error log when using Dataset.group_by_window with Dataset.padded_batch,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: binary
- TensorFlow version: 2.6.0rc0
- Python version: 3.6.9

**Describe the current behavior**

In TensorFlow 2.6.0rc0, an error log is emitted when `tf.data.Dataset.padded_batch` is used in the `reduce_func` of `tf.data.Dataset.group_by_window`.

This code did not log any error in previous TensorFlow versions.

**Describe the expected behavior**

No errors should be logged for this operation.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? no
- Briefly describe your candidate solution(if contributing): N/A

**Standalone code to reproduce the issue**

Here's a dummy example to reproduce the log:

```python
import tensorflow as tf

batch_size = 5

def key_func(element):
    return tf.size(element, out_type=tf.int64)

def reduce_func(key, dataset):
    return dataset.padded_batch(batch_size, padded_shapes=tf.TensorShape([None]))

dataset = tf.data.Dataset.from_tensor_slices([""a"", ""bb"", ""ccc""])
dataset = dataset.map(tf.strings.bytes_split)
dataset = dataset.group_by_window(key_func, reduce_func, window_size=batch_size)
next(iter(dataset))
```

**Other info / logs**

The code above logs the following line:

> `2021-07-09 12:04:33.530961: E tensorflow/core/framework/dataset.cc:552] Failed precondition: Cannot compute input sources for dataset of type PaddedBatchDatasetV2, because sources could not be computed for input dataset of type Window`"
50692,Build tensorflow-lite for armv7-a (embedded linux) failed？,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

> 

**System information**
- OS Platform and Distribution :Linux Ubuntu 16.04 LTS
-target platform - embedded linux - OS Openwrt, CPU - IMX6ULL;
TensorFlow installed from source:
TensorFlow version: 2.4.2
Cross compilation using C++ and CMake. CMake version - 3.16.0



**Describe the problem**
Trying to cross-compile Tensorflow-lite minimal c++ example using CMake.

`cmake -DCMAKE_C_COMPILER=${ARMCC_PREFIX}gcc   -DCMAKE_CXX_COMPILER=${ARMCC_PREFIX}g++   -DCMAKE_C_FLAGS=""${ARMCC_FLAGS}""   -DCMAKE_CXX_FLAGS=""${ARMCC_FLAGS}""   -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON   -DCMAKE_SYSTEM_NAME=Linux    -DCMAKE_SYSTEM_PROCESSOR=armv7-a   ../tensorflow-2.4.2/tensorflow/lite/
`

The results are as follows

> -- Available targets (use: make TARGET):
-- ---------+--------------------------------------------------------------
-- Target   |   Description
-- ---------+--------------------------------------------------------------
-- install  | Install Eigen. Headers will be installed to:
--          |     <CMAKE_INSTALL_PREFIX>/<INCLUDE_INSTALL_DIR>
--          |   Using the following values:
--          |     CMAKE_INSTALL_PREFIX: /usr/local
--          |     INCLUDE_INSTALL_DIR:  include/eigen3
--          |   Change the install location of Eigen headers using:
--          |     cmake . -DCMAKE_INSTALL_PREFIX=yourprefix
--          |   Or:
--          |     cmake . -DINCLUDE_INSTALL_DIR=yourdir
-- doc      | Generate the API documentation, requires Doxygen & LaTeX
-- blas     | Build BLAS library (not the same thing as Eigen)
-- uninstall| Remove files installed by the install target
-- ---------+--------------------------------------------------------------
-- 
-- Performing Test FARMHASH_HAS_BUILTIN_EXPECT
-- Performing Test FARMHASH_HAS_BUILTIN_EXPECT - Success
**And then it doesn't go down，What should I do?**"
50691,Custom training and and inference functions defined outside k-fold loop cause FailedPreconditionError,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.9.6
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.29)

I am not running this code on a GPU on my personal computer, but a colleague has run it on a computer with an NVIDIA card and has confirmed this error.

**Describe the current behavior**
I have implemented k-fold cross-validation for use on a custom Tensorflow model (extending tf.keras.Model). At the start of each loop the model is instantiated, the weights are initialised (with `model.build()`) and so is the Adam optimiser, since it has its own learned variables. The `_train_step` and `_inference_step` functions are called outside the fold while-loop since they are the same for each model and Tensorflow warns that retracing is an expensive process.

The code throws a `FailedPreconditionError`, however, complaining of some variable being missing. It is never the same variable.

The error disappears when I enable eager execution, by which I mean that I comment out the decorator `@tf.function` and use gradient tape.

**Describe the expected behavior**
I expect that this error wouldn't be thrown, and that I wouldn't have to redefine the aforementioned functions each time the loop is called.

**Standalone code to reproduce the issue**
[Working and faulty code.](https://colab.research.google.com/drive/1mUKEOcQqGYX4YC-mrX1WgzWHbLL5JpXL?usp=sharing)

**Other info / logs**
```
python3.9/bin/python3.9 ""training_example.py""
2021-07-09 11:25:50.103064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-09 11:25:50.957307: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
fold 0: epoch 1: train_loss: 0.99761 train_prec: 1.00000 train_recall: 0.30856
fold 0: epoch 1: val_loss: 0.98867 val_prec: 1.00000 val_recall: 0.23142
fold 0: epoch 2: train_loss: 0.99167 train_prec: 1.00000 train_recall: 0.13224
fold 0: epoch 2: val_loss: 0.98676 val_prec: 1.00000 val_recall: 0.11571
Traceback (most recent call last):
  File ""training_example.py"", line 118, in <module>
    for batch_features, batch_labels in training_set: _train_step(batch_features,
  File ""python3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py"", line 889, in __call__
    result = self._call(*args, **kwds)
  File ""python3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py"", line 917, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""python3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py"", line 3023, in __call__
    return graph_function._call_flat(
  File ""python3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py"", line 1960, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""python3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py"", line 591, in call
    outputs = execute.execute(
  File ""python3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.FailedPreconditionError:  Could not find variable _AnonymousVar13. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/_AnonymousVar13/N10tensorflow3VarE does not exist.
	 [[node test_model/dense_2/Tensordot/ReadVariableOp (defined at training_example.py:32) ]] [Op:__inference__train_step_1082]

Function call stack:
_train_step
```"
50689,"""RuntimeError: Division by 0Node number 1252 (FLOOR_MOD) failed to invoke."" after conversion from TensorFlow to tflite","### 1. System information

-    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
-    TensorFlow installation (pip package or built from source): `tb-nightly==2.6.0a20210706` installed via pip


### 2. Code

I am trying to convert a model from Pytorch -> ONNX -> Tensorflow -> tflite. The conversion works, but the results diverge between Tensorflow and tflite.

The original model is a Faster-RCNN with a MobileNet backbone (`fasterrcnn_mobilenet_v3_large_320_fpn` to be exact). I am having a similar, but different issue when converting the same model with a Resnet backbone (see my other issue for that: https://github.com/tensorflow/tensorflow/issues/50676 )

```python
import tensorflow as tf
import numpy as np

# tensorflow inference: works
model_tf = tf.saved_model.load('assets/tfsavedmodel')
sample = np.zeros((1, 3, 256, 256), dtype=np.float32)
model_tf(input=sample)  #works

# tflite inference: fails
interpreter = tf.lite.Interpreter('assets/model.tflite')
print(interpreter.get_input_details()[0]['shape'])  # array([  1,   3, 256, 256], dtype=int32)
model_tflite = interpreter.get_signature_runner()
out_tflite = model_tflite(input=sample)
```

Fails with error:

```
Traceback (most recent call last):
  File ""/home/florian/projects/video-analysis-prototype/model-conversion/convert.py"", line 375, in <module>
    Converter().verify()
  File ""/home/florian/projects/video-analysis-prototype/model-conversion/convert.py"", line 371, in verify
    verify_tflite(self.target_dir/self.fname_tflite, x)
  File ""/home/florian/projects/video-analysis-prototype/model-conversion/convert.py"", line 45, in verify_tflite
    output = signature(input=tf.constant(np.zeros_like(sample)))  # FIXME: get actual sample in
  File ""/home/florian/projects/video-analysis-prototype/model-conversion/venv/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py"", line 239, in __call__
    self._interpreter.invoke()
  File ""/home/florian/projects/video-analysis-prototype/model-conversion/venv/lib/python3.8/site-packages/tensorflow/lite/python/interpreter.py"", line 905, in invoke
    self._interpreter.Invoke()
RuntimeError: Division by 0Node number 1252 (FLOOR_MOD) failed to invoke.
```

Model files mentioned can be found here: https://florianletsch.de/media/assets-tflite.zip (468 MB)

This is how I converted the model (note that this takes >1hr, not sure why)

```
converter = tf.lite.TFLiteConverter.from_saved_model('assets/tfsavedmodel')
converter.experimental_enable_resource_variables = True  # requires tf-nightly or tf-nightly-cpu
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS,
  tf.lite.OpsSet.SELECT_TF_OPS
]

tflite_model = converter.convert()
with open('assets/model.tflite', 'wb') as f:
    f.write(tflite_model)
```


### 3. Failure after conversion

- Conversion works but model can't be loaded for inference, see error message above.

### Environment 

Output of `pip freeze`

```
absl-py==0.13.0
astunparse==1.6.3
cachetools==4.2.2
certifi==2021.5.30
chardet==4.0.0
flatbuffers==1.12
gast==0.4.0
google-auth==1.32.1
google-auth-oauthlib==0.4.4
google-pasta==0.2.0
grpcio==1.38.1
h5py==3.1.0
idna==2.10
keras-nightly==2.6.0.dev2021062500
Keras-Preprocessing==1.1.2
libclang==12.0.0
Markdown==3.3.4
netron==5.0.0
numpy==1.19.2
oauthlib==3.1.1
onnx==1.9.0
onnx-tf==1.8.0
onnxruntime==1.8.0
opt-einsum==3.3.0
Pillow==8.3.1
protobuf==3.17.3
pyasn1==0.4.8
pyasn1-modules==0.2.8
PyYAML==5.4.1
requests==2.25.1
requests-oauthlib==1.3.0
rsa==4.7.2
six==1.15.0
tb-nightly==2.6.0a20210706
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.0
tensorflow-addons==0.13.0
termcolor==1.1.0
tf-estimator-nightly==2.6.0.dev2021062501
tf-nightly-cpu==2.7.0.dev20210706
torch==1.9.0
torchvision==0.10.0
typeguard==2.12.1
typing-extensions==3.7.4
urllib3==1.26.6
Werkzeug==2.0.1
wrapt==1.12.1
```
"
50688,Cropped Image feature in TFlite Image Segmentation Example,"Hello Tf Team!,... I'm using your image segmentation Android example in which deeplab model is being used. We get result and masked image in response. Could you please tell me how we can get the cropped image as we get the masked image! Please do let me know ASAP!
Thanks & Regards."
50687,Failed to convert mhlo dialect to Linalg dialect when the layout of Conv2d is NCHW,"I want to convert the conv2d operator from mhlo to linalg dialect. It seems like that it can't process the situation when the  layout of conv2d is NCHW.
The mhlo dialect of conv2d.mlir is shown below:
```
module  {
  func @main(%arg0: tensor<64x3x7x7xf32>, %arg1: tensor<1x3x224x224xf32>) -> tuple<tensor<1x64x112x112xf32>> {
    %0 = ""mhlo.convolution""(%arg1, %arg0) {batch_group_count = 1 : i64, dimension_numbers = {input_batch_dimension = 0 : i64, input_feature_dimension = 1 : i64, input_spatial_dimensions = dense<[2, 3]> : tensor<2xi64>, kernel_input_feature_dimension = 1 : i64, kernel_output_feature_dimension = 0 : i64, kernel_spatial_dimensions = dense<[2, 3]> : tensor<2xi64>, output_batch_dimension = 0 : i64, output_feature_dimension = 1 : i64, output_spatial_dimensions = dense<[2, 3]> : tensor<2xi64>}, feature_group_count = 1 : i64, lhs_dilation = dense<1> : tensor<2xi64>, padding = dense<3> : tensor<2x2xi64>, precision_config = [""DEFAULT"", ""DEFAULT""], rhs_dilation = dense<1> : tensor<2xi64>, window_strides = dense<2> : tensor<2xi64>} : (tensor<1x3x224x224xf32>, tensor<64x3x7x7xf32>) -> tensor<1x64x112x112xf32>
    %1 = ""mhlo.tuple""(%0) : (tensor<1x64x112x112xf32>) -> tuple<tensor<1x64x112x112xf32>>
    return %1 : tuple<tensor<1x64x112x112xf32>>
  }
}
```
I use ""./mlir-hlo-opt ./conv2d.mlir -hlo-legalize-to-linalg -o conv2d_linalg.mlir"" to do the transformation.
I traced the workflow and found out when it checks ""HasCanonicalDimensionNumbers()"", it returns false.
[legalize_to_linalg.cc:1771](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/legalize_to_linalg.cc#L1771)
```
  if (dimension_numbers.input_batch_dimension().getInt() != 0 ||
      dimension_numbers.input_feature_dimension().getInt() !=
          (input_spatial_rank + 1)) {
    return false;
  }
```"
50686,InvalidArgumentError: No OpKernel was registered to support Op 'QuantizedMatMulWithBiasAndDequantize',"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Google Colab
- TensorFlow installed from: binary
- TensorFlow version: 2.4.0
- Python version: 3.7
- (run on CPU)


I used a quantization package [LPOT](https://github.com/intel/lpot) supported with [Intel-Tensorflow](https://github.com/Intel-tensorflow/) to quantize my model, and ran inference under native Tensorflow environment.

**Describe the current behavior**
The Quantized kernel does not seem to have registered OpKernel.

**Describe the expected behavior**
The session should run fine and print the MSE loss, which is the case for my trained & un-quantized TF 2.4 frozen pb model (converted from keras model).

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No


**Other info / logs** 

Source code:
`with tf.compat.v1.Session(graph=graph) as sess:`
 `       output = graph.get_tensor_by_name(output_tensor_name)`
`        predictions = sess.run(output, {input_tensor_name: x})`
 `       mse = tf.reduce_mean(tf.keras.losses.mean_squared_error(y, predictions))`
  `      print(mse.eval())`

**Traceback:**

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1374     try:
-> 1375       return fn(*args)
   1376     except errors.OpError as e:

8 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1357       # Ensure any changes to the graph are reflected in the runtime.
-> 1358       self._extend_graph()
   1359       return self._call_tf_sessionrun(options, feed_dict, fetch_list,

/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)
   1397     with self._graph._session_run_lock():  # pylint: disable=protected-access
-> 1398       tf_session.ExtendSession(self._session)
   1399 

InvalidArgumentError: No OpKernel was registered to support Op 'QuantizedMatMulWithBiasAndDequantize' used by {{node model/dense/Tensordot/MatMul_eightbit_requantize}} with these attrs: [input_quant_mode=""MIN_FIRST"", Toutput=DT_FLOAT, T1=DT_QUINT8, T2=DT_QINT8, Tbias=DT_QINT32, transpose_a=false, transpose_b=false]
Registered devices: [CPU]
Registered kernels:
  <no registered kernels>

	 [[model/dense/Tensordot/MatMul_eightbit_requantize]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-5-ade3637a3169> in <module>()
----> 1 loss = inference(path_to_pb='./model.pb',                  
input_tensor_name='x:0', output_tensor_name='Identity:0',                  
x=x[:64], y=y[:64])

<ipython-input-3-c2f290fad90b> in inference(path_to_pb, input_tensor_name, output_tensor_name, x, y)
     20       with tf.compat.v1.Session(graph=graph) as sess:
     21         output = graph.get_tensor_by_name(output_tensor_name)
---> 22         predictions = sess.run(output, {input_tensor_name: x})
     23         mse = tf.reduce_mean(tf.keras.losses.mean_squared_error(y, predictions))
     24         print(mse.eval())

/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    966     try:
    967       result = self._run(None, fetches, feed_dict, options_ptr,
--> 968                          run_metadata_ptr)
    969       if run_metadata:
    970         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1189     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1190       results = self._do_run(handle, final_targets, final_fetches,
-> 1191                              feed_dict_tensor, options, run_metadata)
   1192     else:
   1193       results = []

/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1367     if handle is None:
   1368       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1369                            run_metadata)
   1370     else:
   1371       return self._do_call(_prun_fn, handle, feeds, fetches)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)
   1392                     '\nsession_config.graph_options.rewrite_options.'
   1393                     'disable_meta_optimizer = True')
-> 1394       raise type(e)(node_def, op, message)
   1395 
   1396   def _extend_graph(self):

InvalidArgumentError: No OpKernel was registered to support Op 'QuantizedMatMulWithBiasAndDequantize' used by node model/dense/Tensordot/MatMul_eightbit_requantize (defined at <ipython-input-2-28418ad07e47>:24)  with these attrs: [input_quant_mode=""MIN_FIRST"", Toutput=DT_FLOAT, T1=DT_QUINT8, T2=DT_QINT8, Tbias=DT_QINT32, transpose_a=false, transpose_b=false]
Registered devices: [CPU]
Registered kernels:
  <no registered kernels>
"
