Issue Number,Issue Title,Issue Body
58831,"New optimizers API accepts 'lr' as argument, but ignores it","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.11

### Custom Code

Yes

### OS Platform and Distribution

All

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The 'lr' argument for learning rate got deprecated in recent TF versions, and replaced by 'learning_rate'. Recent TF versions gave a warning when 'lr' was used, which got updated to:

""WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adagrad.""

However, training still continuous, ignoring the learning rate set. See the code to reproduce: when 'lr=' is used, the final train loss is 0.1577; when 'learning_rate=' is used the final train loss is 0.5490 (higher loss due to much smaller learning rate).

I think the expected behavior here is that TF throwns an exception when 'lr' is used as an argument. The fact that the optimizer ignores it may easily go unnoticed, despite the warning, e.g. in an MLOps scenario, or when using a third-party module that still uses 'lr=' internally.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import backend as K
from tensorflow.keras.layers import BatchNormalization
import timeit

print('TF version: {}'.format(tf.__version__))

batch_size = 128
num_classes = 10
epochs = 12
lr = 1e-4

# input image dimensions
img_rows, img_cols = 28, 28

# the data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)


model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 input_shape=input_shape))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adagrad(lr=lr),
              metrics=['accuracy'])

tic = timeit.default_timer()
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))
toc = timeit.default_timer()
print('Total training time: %f sec' % (toc-tic))

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
```


### Relevant log output

_No response_</details>"
58829,tf.compat.v1.profiler.profile don't report flops of ops in tf.cond,"
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.5.1 

### Custom Code

Yes

### Current Behaviour?

A bug happened!
I use a tf.cond op in model:

```
import tensorflow as tf

@tf.function
def model(input, is_train):
    input = tf.cond(is_train, lambda: tf.subtract(input, 2, name=""cond_test1""),
                    lambda: tf.multiply(input, 3, name=""cond_test2""))
    input = tf.add(input, 3)
    return input


input = tf.ones([3,4])
is_train = tf.constant(1) == 1

output = model(input, is_train)

```
there are a subtract op and a multiply op in tf.cond.

then i  try to get flops of ""model"":
```
graph = model._list_all_concrete_functions()[-1].graph


builder = tf.compat.v1.profiler.ProfileOptionBuilder
opts = (builder(builder.trainable_variables_parameter()).with_file_output(
    ""cond_test_flops.log"").with_accounted_types(['.*']).select([""float_ops""
                                                                ]).build())
tfprof_node = tf.compat.v1.profiler.profile(graph, options=opts)
``` 

I print the flops detail log and found the ops in tf.cond are ignored, only an add op's flops is reported
```
Profile:
node name | # float_ops
_TFProfRoot (--/12 flops)
  Add (12/12 flops). // only an Add op 
    Add/y (0/0 flops)
  Identity (0/0 flops)
  cond (0/0 flops)
    cond/Identity (0/0 flops)
  input (0/0 flops)
  is_train (0/0 flops)
```
```


"
58828,Significant slowdown in Keras model.fit() on simple problem when using validation data,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.10.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2 / 8.1.0

### GPU model and memory

NVIDIA Quadro GV100 (32 GB)

### Current Behaviour?

I observe a significant slowdown when using Keras model.fit() to train a simple
3-layer fully-connected network when the validation_data parameter is set.  A
typical run of the provided code on my machine results in the following output:
```
Time with validation:     3.89 s
Time without validation:  0.39 s
```
The validation data set is 1/8 the size of the training dataset.  I don't
expect validation to be free, but it should not result in a 10x slowdown.

Some notes / things I've tried:

 - Setting validation_batch_size makes no difference.

 - Using a single NumPy array to hold both the training and validation datasets
   and using validation_split instead of validation_data also makes no
   difference.

 - I found the possibly related issue #57645, which suggests that it might be a
   problem related to eager execution.  The poster of that issue is able to fix
   things by calling tf.compat.v1.disable_eager_execution(), but if I try this
   in my own code with TF 2.11.0, I run into errors (not really surprising).

 - One of the respondents on that same issue suggested swapping out the NumPy
   arrays for tf.data.Dataset objects.  I found this made no difference, even
   using `.prefetch(tf.data.AUTOTUNE)` as recommended.

 - Deactivating the GPU (by setting CUDA_VISIBLE_DEVICES=-1) makes no
   difference to the time with validation but increases the time without
   validation by about 50%.  That suggests the validation step might not be
   leveraging the GPU, which would certainly be an issue, but that's still
   not enough to account for a 6x slowdown.

Is this a bug?  Or am I missing something obvious?

### Standalone code to reproduce the issue

```python
import tensorflow as tf
import numpy as np
import time
    
xTrain = np.random.randn(2048, 128)
yTrain = np.random.randn(2048, 128)
xValid = np.random.randn(256,  128)
yValid = np.random.randn(256,  128)
                
model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape = (128,)),
    tf.keras.layers.Dense(128, activation = ""tanh""),
    tf.keras.layers.Dense(128)
])      
        
model.compile(
    optimizer = tf.keras.optimizers.Adam(1.0e-3),
    loss = tf.keras.losses.MeanSquaredError(),
)   
    
# Preliminary run to build graphs.
model.fit(x = xTrain, y = yTrain, epochs = 5, batch_size = 2048,
    validation_data = (xValid, yValid)
)

t1 = time.time()

model.fit(x = xTrain, y = yTrain, epochs = 100, batch_size = 2048,
    validation_data = (xValid, yValid)
)

t2 = time.time()

model.fit(x = xTrain, y = yTrain, epochs = 100, batch_size = 2048)

t3 = time.time()

print(""Time with validation:     %.2f s"" % (t2 - t1))
print(""Time without validation:  %.2f s"" % (t3 - t2))
```


### Relevant log output

_No response_</details>"
58826,Memory leak in decode_jpeg(),"Hi, I am using cppflow wrapper to interface directly with tensorflow-2.8 via the native TF C-API. Basically, I have two different ways of creating a tensor. The first method is by using cppflow::decode_jpeg() to create a tensor on GPU memory; the second method is by creating a tensor manually on system memory. The first method causes memory leak, where as the second method does not. The code is as follow:

```cpp
#define USE_TENSORFLOW_GPU_API
#ifdef USE_TENSORFLOW_GPU_API
    input = cppflow::decode_jpeg(req->image().content());
    input = cppflow::expand_dims(input, 0);
#else
    std::vector<uint8_t> data;
    for(int i=0; i < h; i++){
        for(int j=0; j < w; j++){
            QColor color = image.pixelColor(j,i);
            int red, green, blue;
            green = color.green();
            blue = color.blue();
            red = color.red();
            data.push_back(red);
            data.push_back(green);
            data.push_back(blue);
        }
    }

    input = cppflow::tensor(data, {1, h, w, 3});
#endif
```

I am not sure what causes the memory leak, would someone comment on this issue?

I read from this [thread](https://groups.google.com/a/tensorflow.org/g/discuss/c/3czXdek8rEg?pli=1) that GPU memory (of CUDA toolkit) does not get de-allocated until a process is terminated. Please advise if you know anything about this.

Thank you,"
58825,Bazel downstream failure: Tensorflow visibility issue,"Tensorflow is failing in Bazel downstream with this error:

<img width=""1045"" alt=""image"" src=""https://user-images.githubusercontent.com/16399431/206544199-fc82707a-2237-4524-bd06-51262e594299.png"">

After checking the runtime repository, I found that :support target is visible to a package group which ONLY includes targets in the same project, while it is used as a dependency in Tensorflow repository:

<img width=""306"" alt=""image"" src=""https://user-images.githubusercontent.com/16399431/206544753-77ca7780-3185-4458-b423-c71b76d24fd6.png"">

Please update this target to be visible from needed projects

"
58824,TF 2.11 on redhat Could not load dynamic library  and This TensorFlow binary is optimized.....,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Red Hat Enterprise Linux Server release 7.9 (Maipo)

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuDNN/8.1.1.33-CUDA-11.2.2

### GPU model and memory

Tesla V100 16gb

### Current Behaviour?

```shell
I'm using:

Red Hat Enterprise Linux Server release 7.9 (Maipo)
TF = 2.10.0
python = 3.10
cuDNN/8.1.1.33
CUDA-11.2.2

I get :
 tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-08 13:52:50.672384: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.

W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH:


Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.


Older versions of TF are working fine. Do we need to update cuda?
```


### Standalone code to reproduce the issue

```shell
Install tf 2.10.0 using anaconda in RedHat Enterprise.


Red Hat Enterprise Linux Server release 7.9 (Maipo)
TF = 2.10.0
python = 3.10
cuDNN/8.1.1.33
CUDA-11.2.2
```


### Relevant log output

_No response_</details>"
58823,Model size i n c r e a s e s (by up to 45%!) when quantization is applied ,"Hello,
I am now learning TFLite (using a book ,TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers"") and I have a problem with quantization.
It increases the size of my file!

I looked up the quantization example on your webpage(https://www.tensorflow.org/lite/performance/post_training_integer_quant) , but it involves integer quantization, model saving/reading and all other stuff that isn't directly related to quantization per se, which makes it harder for me to solve my particular problem. 
Same thing with code ,,from the book"" - its version available on github (https://github.com/tensorflow/tflite-micro/tree/main/tensorflow/lite/micro/examples/hello_world) has been updated quite a lot since the release of the book, which means that I don't know where exactly I made a mistake.

I generally think that the whole problem is rooted in model conversion part of quantization process, because right after it I can see that the size of not-quantized model and quantized model is determined:
![obraz](https://user-images.githubusercontent.com/119885480/206506705-58157e1e-d0fd-4be2-a895-08ac17eeacb6.png)

Can you tell me, how to fix this problem? I really have no clue, despite the fact that I checked your offical documentation and tutorials. I also read the chapter about model making three times, and still, I can't find a solution.
 
Link to both of my projects:
https://colab.research.google.com/drive/1eyqMB1POAZ9qw3lPCZkiyU7zfQ0Y1OxF#scrollTo=_LGjpaXeSsnv
https://colab.research.google.com/drive/1p8Y5UpXZznejXSK7YRYJKCHulAVyKvxy
(first - sine - 1:1 as in the book. Second one - cosine - I tried to apply what I learnt independently).
"
58821,Can't use adpt function to normarlization the data,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11

### GPU model and memory

3060

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
colab link:https://colab.research.google.com/drive/1FhnUPoJGUIMeyiOJcpf9n9iLL_Ms6SNL?usp=sharing
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers,utils
import tensorflow_addons as tfa
import matplotlib.pyplot as plt

num_classes = 2
input_shape = (256,256,1)

train_data_path = '/content/chest_xray/train'
test_data_path = '/content/chest_xray/test'
val_data_path = '/content/chest_xray/val'

train_dataset = utils.image_dataset_from_directory(train_data_path,batch_size=32,image_size=(256,256),color_mode='grayscale')
test_dataset = utils.image_dataset_from_directory(test_data_path,batch_size=32,image_size=(256,256),color_mode='grayscale')
val_dataset = utils.image_dataset_from_directory(val_data_path,batch_size=32,image_size=(256,256),color_mode='grayscale')

image_size = 256

data_augmentation = keras.Sequential(
    [
        layers.Normalization(),
        layers.Resizing(image_size, image_size),
        layers.RandomFlip(""horizontal""),
        layers.RandomRotation(factor=0.02),
        layers.RandomZoom(
            height_factor=0.2, width_factor=0.2
        ),
    ],
    name=""data_augmentation"",
)

# Compute the mean and the variance of the training data for normalization.
data_augmentation.layers[0].adapt(train_dataset)
```


### Relevant log output

```shell
ValueError                                Traceback (most recent call last)
<ipython-input-21-f5be785e5ca1> in <module>
     13 
     14 # Compute the mean and the variance of the training data for normalization.
---> 15 data_augmentation.layers[0].adapt(train_dataset)

5 frames
/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py in build(self, input_shape)
    135                        'please convert to a numpy array or `tf.Tensor`.')
    136 
--> 137     input_shape = tf.TensorShape(input_shape).as_list()
    138     ndim = len(input_shape)
    139 

ValueError: in user code:

    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_preprocessing_layer.py"", line 117, in adapt_step  *
        self._adapt_maybe_build(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_preprocessing_layer.py"", line 285, in _adapt_maybe_build  **
        self.build(data_shape)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/preprocessing/normalization.py"", line 137, in build
        input_shape = tf.TensorShape(input_shape).as_list()

    ValueError: as_list() is not defined on an unknown TensorShape.
```
</details>"
58820,Installation process on dead pip,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/Compiler version

11.3.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

None

### Current Behaviour?

```shell
I was trying to install tensorflow, using  install tensorflow, but it didn't even start the installation and said that the installation process was killed. I wanted to know how to solve this problem. I managed to install the Keras library, but to run it you need the Tensorflow library.

Here is some technical information about my notebook:
CPU Intel Celeron 1.9 Ghz x 2
4 GB of RAM
I don't have a GPU.

I don't know if it could have something to do with the hardware requirements, but I believe it could have something to do with that.
```


### Standalone code to reproduce the issue

```shell
pip install tensorflow
```


### Relevant log output

```shell
Defaulting to user installation because normal site-packages is not writeable
Collecting tensorflow
Dead
```
</details>"
58819,How to tell choosen tf.data.AUTOTUNE values? Troubleshooting low parallelism issue,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How to tell Autotune actual chosen values?  
I'm training a NN on a machine with 1 GPU and 8 vCPUs. I see that the GPU utilization is about 20% and CPU utilization pegs at 200%/800%. Was expecting either of these to be closer to be fully utilized.
I'm using tf.data and set parallelism of different operations [like map(), prefetch()] to -1 (Autotune).  
Based on the 200%/800% cpu usage it seems the degree of parallization isn't high enough, how can I figure out what values were chosen for num_parallel_calls and other parallel parameters that I asked to be auto tune. e.g., Any logging I can turn on?
Before diving into serious profiling work, I would like to check these basic values.
```


### Standalone code to reproduce the issue

```shell
Not necessary in order to address the issue.
```


### Relevant log output

_No response_</details>"
58816,Tensorflow 2.11 is still using CUDA 11.2 + CuDNN 8.1 that were released 2 years ago,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensorflow 2.11 is still using CUDA 11.2 + CuDNN 8.1 that were released 2 years ago: https://www.tensorflow.org/install/source#gpu. This makes our stack have to use the old CUDA/CuDNN without new features. Is it possible to make new TF version work with newest CUDA/CuDNN?
```


### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_</details>"
58812,Deploy yolo5 model into TensorFlow Lite Object Detection Android,"Hello Tensorflow team!

I checked your real time object detection app which works good with the initial models (MobileNet V1, EfficientNet Lite0, EfficientNet Lite1, EfficientNet Lite2). https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android

But I receive errors when I try to add other model for example yolo5s model trained on COCO dataset which converted from **pt** format to **tflite** with export.py script https://github.com/ultralytics/yolov5/blob/master/export.py

Below you can find converted models for yolo5s (fp16 and int8 options), I already checked they are working fine with detect.py.
https://github.com/HripsimeS/Projects/blob/main/yolov5s-fp16.tflite
https://github.com/HripsimeS/Projects/blob/main/yolov5s-int8.tflite

Is it possible to deploy/integrate yolo5 model into your real time object detection app? If yes, can you please check if you can deploy into app one of those two models (fp16 or int8) I shared with you above. In case if it works for you, can you share your experience what did you exactly modify in initial TensorFlow Lite Object Detection app scripts. Thank you in advance!"
58810,TensorFlow Lite example label_image run err,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  arm64 buildroot
- TensorFlow installation (pip package or built from source):  TensorFlow lite
- TensorFlow library (version, if pip package or github SHA, if built from source):  2.10

### 2. describe

Hi, I am trying to use tensorflow lite on an arm64 device, I compiled using the instructions on this page to compile：https://www.tensorflow.org/lite/guide/build_cmake_arm?hl=zh-cn

`export ARMCC_PREFIX=~/tool_chain/gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu/bin/aarch64-none-linux-gnu- && export ARMCC_FLAGS=""-funsafe-math-optimizations""  && cmake -DCMAKE_C_COMPILER=${ARMCC_PREFIX}gcc  -DCMAKE_CXX_COMPILER=${ARMCC_PREFIX}g++  -DCMAKE_C_FLAGS=""${ARMCC_FLAGS}""  -DCMAKE_CXX_FLAGS=""${ARMCC_FLAGS}"" -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON   -DCMAKE_SYSTEM_NAME=Linux   -DCMAKE_SYSTEM_PROCESSOR=aarch64 -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON ../tensorflow/lite/`

The final compilation libtensorflow-lite.a, label_image , etc.

And then I do this:

scp label_image into my device

and I try to run it:
./label_image --tflite_model testdata/mobilenet_v1_1.0_224.tflite  --labels testdata/labels.txt --image testdata/grace_hopper.bmp
It came up with this log:

INFO: Loaded model testdata/mobilenet_v1_1.0_224.tflite
INFO: resolved reporter
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
ERROR: failed to get XNNPACK profile information.
ERROR: failed to get XNNPACK profile information.
ERROR: failed to get XNNPACK profile information.
ERROR: failed to get XNNPACK profile information.
ERROR: failed to get XNNPACK profile information.
ERROR: failed to get XNNPACK profile information.
INFO: invoked
INFO: average time: 17.374 ms
INFO: 0.860173: 653 653:military uniform
INFO: 0.0481023: 907 907:Windsor tie
INFO: 0.00786704: 466 466:bulletproof vest
INFO: 0.00644933: 514 514:cornet, horn, trumpet, trump
INFO: 0.00608027: 543 543:drumstick

After my driver tests, I found that my device's gpu was not being used,  GPU is mali610, opencl 1.2 is supported, Someone can help me?



"
58809,"MirroredStrategy error INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds when training a model, most related to batch size strategy across all GPUs","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: [ngc](https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/rel-22-10.html#rel-22-10)
-   **TensorFlow version (use command below)**: 2.10
-   **Python version**: 3.8.10
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: 11.8
-   **GPU model and memory**: A100 80G (8 Gpus)
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am using 8 Gpus to train a model with custome dataset generator loader. However, when I am trying to train the model, at the final batch it will throw error as ""INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds."". I tried the same scripts and data with only one GPUs and it goes fine. 
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
The code I uses to train is:
```
val = pd.read_csv('data/val.csv')
window_length = 40
feats = 4
def get_LSTM_AE_model():
    model = keras.Sequential()
    model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', batch_input_shape=(None, window_length, feats), return_sequences=True, name='encoder_1'))
    model.add(keras.layers.Dropout(0.25))
    model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='encoder_2'))
    model.add(keras.layers.Dropout(0.25))
    model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=False, name='encoder_3'))
    model.add(keras.layers.Dropout(0.25))
    model.add(keras.layers.RepeatVector(window_length, name='encoder_decoder_bridge'))
    model.add(keras.layers.LSTM(16, kernel_initializer='he_uniform', return_sequences=True, name='decoder_1'))
    model.add(keras.layers.Dropout(0.25))
    model.add(keras.layers.LSTM(32, kernel_initializer='he_uniform', return_sequences=True, name='decoder_2'))
    model.add(keras.layers.Dropout(0.25))
    model.add(keras.layers.LSTM(64, kernel_initializer='he_uniform', return_sequences=True, name='decoder_3'))
    model.add(keras.layers.Dropout(0.25))
    model.add(keras.layers.TimeDistributed(keras.layers.Dense(feats)))
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00005), loss=""mse"")
    model.summary()
    
    return model

#distribute training
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
BATCH_SIZE_PER_REPLICA = 4096
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
with strategy.scope():
    model = get_LSTM_AE_model()

val_events = []
val.groupby('vin').apply(lambda x:val_events.append(x[['a','b','v','d']].values))
def val_data_generator():
    # np.random.shuffle(val_events)
    for events in val_events:
        yield events
val_dataset = tf.data.Dataset.from_generator(
    generator=val_data_generator,
    output_types=tf.float32
)
def tensor_2_window(x):
    x = tf.data.Dataset.from_tensor_slices(x)
    x = x.window(40,shift=1,drop_remainder=True)
    x = x.flat_map(lambda window: window.batch(40))
    return x
val_dataset = val_dataset.flat_map(tensor_2_window)
val_dataset = val_dataset.map(lambda window: (window, window))
val_dataset = val_dataset.cache().batch(4096*9).prefetch(buffer_size=tf.data.AUTOTUNE)
history = model.fit(
    val_dataset,
    epochs=50,
    # validation_data=val_dataset
)
```
then after training to the last batch, error apperas:
```
2022-12-07 03:37:26.605819: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606363: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606475: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606605: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606675: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606747: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606807: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606831: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606908: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.606998: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.607074: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
2022-12-07 03:37:26.607141: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at strided_slice_op.cc:105 : INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds.
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
Cell In [52], line 1
----> 1 history = model.fit(
      2     val_dataset,
      3     epochs=50,
      4     # validation_data=val_dataset
      5 )

File /usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File /usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     52 try:
     53   ctx.ensure_initialized()
---> 54   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     55                                       inputs, attrs, num_outputs)
     56 except core._NotOkStatusException as e:
     57   if name is not None:

InvalidArgumentError: Graph execution error:

Detected at node 'replica_5/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 994, in train_step
      loss = self.compute_loss(x, y, y_pred, sample_weight)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1052, in compute_loss
      return self.compiled_loss(
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py"", line 279, in __call__
      batch_dim = tf.shape(y_t)[0]
Node: 'replica_5/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
Detected at node 'replica_3/sequential/encoder_1/strided_slice' defined at (most recent call last):
    File ""/usr/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 1135, in run_step
      outputs = model.train_step(data)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 993, in train_step
      y_pred = self(x, training=True)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/training.py"", line 557, in __call__
      return super().__call__(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/sequential.py"", line 410, in call
      return super().call(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 510, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py"", line 667, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 553, in __call__
      return super().__call__(inputs, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 65, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py"", line 1097, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 96, in error_handler
      return fn(*args, **kwargs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/lstm.py"", line 607, in call
      inputs, initial_state, _ = self._process_inputs(
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 810, in _process_inputs
      initial_state = self.get_initial_state(inputs)
    File ""/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py"", line 529, in get_initial_state
      batch_size = input_shape[1] if self.time_major else input_shape[0]
Node: 'replica_3/sequential/encoder_1/strided_slice'
9 root error(s) found.
  (0) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_5/strided_slice}}]]
  (1) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[replica_6/mean_squared_error/cond/else/_189/replica_6/mean_squared_error/cond/remove_squeezable_dimensions/Equal/_385]]
  (2) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[replica_4/mean_squared_error/cond/else/_139/replica_4/mean_squared_error/cond/remove_squeezable_dimensions/Equal/_377]]
  (3) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[replica_1/strided_slice/_296]]
  (4) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[replica_1/mean_squared_error/cond/then/_63/replica_1/mean_squared_error/cond/cond/then/_690/replica_1/mean_squared_error/cond/cond/remove_squeezable_dimensions/cond/pivot_t/_1455/_729]]
  (5) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[gradient_tape/replica_7/mean_squared_error/cond/StatelessIf/pivot_f/_228/_346]]
  (6) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[div_no_nan/ReadVariableOp_8/_916]]
  (7) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
	 [[Func/replica_2/mean_squared_error/cond/else/_89/replica_2/mean_squared_error/cond/remove_squeezable_dimensions/cond/else/_742/input/_1165/_468]]
  (8) INVALID_ARGUMENT:  slice index 0 of dimension 0 out of bounds.
	 [[{{node replica_3/sequential/encoder_1/strided_slice}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_112593]
```"
58808,ModuleNotFoundError: No module named 'tensorflow.compat',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

windows10

### Mobile device

_No response_

### Python version

3.9.5

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2 / 8.1

### GPU model and memory

1650ti

### Current Behaviour?

```shell
after installing tensorflow==2.11 while testing it always shows up ModuleNotFoundError: No module named 'tensorflow.compat'  ALSO I want to include everything is fine if I install and try any other version of tensorflow ex. everything was working fine and as expected the issue only lies in tf==2.11 distribution.
```


### Standalone code to reproduce the issue

```shell
from tensorflow import compat
```


### Relevant log output

```shell
.ipynb Cell 1 in <cell line: 1>()
----> 1 from tensorflow import compat

ImportError: cannot import name 'compat' from 'tensorflow' (unknown location)
```
</details>"
58807,AutoCastDistributedVariable __deepcopy__ bug," ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.4

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Running copy.deepcopy on AutoCastDistributedVariable will result in error. 

In __deepcopy__ method inside DistributedVariable type(self) is used. Thus, copied_variable will be initialized from AutoCastVariable. However, for this class strategy argument is missing. 

AutoCastDistributedVariable should implement its own __init__.
```


### Standalone code to reproduce the issue

```shell
from keras.mixed_precision.autocast_variable import create_autocast_variable
import tensorflow as tf
import copy

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    distributed_var = tf.Variable([])
autocast_distributed_var = create_autocast_variable(distributed_var)
copied_variable = copy.deepcopy(autocast_distributed_var)
```


### Relevant log output

```shell
File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/values.py"", line 553, in __deepcopy__
    copied_variable = type(self)(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/variables.py"", line 273, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
TypeError: __init__() got an unexpected keyword argument 'strategy'
```"
58805,tensorflow does not build on macOS,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

macOS 12.6.1 21G217 x86_64

### Mobile device

_No response_

### Python version

3.10, 3.9, 3.8

### Bazel version

5.3.2

### GCC/Compiler version

Xcode 14.1 14B47b

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I am trying to update the MacPorts distribution of `tensorflow`. It fails to build with the latest version 2.11.0. The build uses Xcode.

Related:
* https://github.com/macports/macports-ports/pull/15397
* #57936

### Standalone code to reproduce the issue

```shell
sudo port -pNc install py310-tensorflow
```

The MacPorts build recipe has worked up until the last version or so: https://github.com/macports/macports-ports/blob/master/python/py-tensorflow/Portfile
```


### Relevant log output

```shell
:debug:build system -W /opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py310-tensorflow/work/tensorflow-2.11.0: PATH=/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py310-tensorflow/work/bazelwrap:/opt/local/libexec/bazel/bin:/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py310-tensorflow/work/bin:/opt/local/bin:/opt/local/sbin:/bin:/sbin:/usr/bin:/usr/sbin BAZEL_SH=/bin/bash CC_OPT_FLAGS=-march=x86-64 /opt/local/libexec/bazel/bin/bazel --max_idle_secs=10 --output_user_root=/opt/local/var/macports/build/_opt_local_ports_python_py-tensorflow/py310-tensorflow/work/bazel_build  fetch //tensorflow/tools/pip_package:build_pip_package

…

:info:build ld: malformed trie, childNodeOffset==0 file 'bazel-out/darwin-opt/bin/_solib_darwin_x86_64/libtensorflow_Spython_S_Upywrap_Utensorflow_Uinternal.so'
:info:build clang: error: linker command failed with exit code 1 (use -v to see invocation)
:info:build Error in child process '/usr/bin/xcrun'. 1
:info:build external/local_config_cc/cc_wrapper.sh: line 69: 75369 Abort trap: 6           ""$(/usr/bin/dirname ""$0"")""/wrapped_clang ""$@""
:info:build Target //tensorflow/tools/pip_package:build_pip_package failed to build
:info:build INFO: Elapsed time: 7166.337s, Critical Path: 421.62s
```
</details>"
58801,save_optimizer_weights_to_hdf5_group method attempts to access attribute in optimizer that no longer exists in 2.11.0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04.3

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The save_optimizer_weights_to_hdf5_group method accesses an attribute (weights) of the optimizer class that no longer exists in tensorflow 2.11.0 (at least for the Adam optimizer).
```


### Standalone code to reproduce the issue

```shell
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.python.keras.saving import hdf5_format

model = Sequential()
model.add(Dense(10, input_dim=100))
model.compile(optimizer=Adam())
hdf5_format.save_model_to_hdf5(model, ""test.h5"")
```


### Relevant log output

```shell
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Cell In [3], line 4
      2 model.add(Dense(10, input_dim=100))
      3 model.compile(optimizer=Adam())
----> 4 hdf5_format.save_model_to_hdf5(model, ""test.h5"")

File ~/miniconda3/envs/tf_bug/lib/python3.9/site-packages/tensorflow/python/keras/saving/hdf5_format.py:126, in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
    122   # TODO(b/128683857): Add integration tests between tf.keras and external
    123   # Keras, to avoid breaking TF.js users.
    124   if (include_optimizer and model.optimizer and
    125       not isinstance(model.optimizer, optimizer_v1.TFOptimizer)):
--> 126     save_optimizer_weights_to_hdf5_group(f, model.optimizer)
    128   f.flush()
    129 finally:

File ~/miniconda3/envs/tf_bug/lib/python3.9/site-packages/tensorflow/python/keras/saving/hdf5_format.py:587, in save_optimizer_weights_to_hdf5_group(hdf5_group, optimizer)
    579 def save_optimizer_weights_to_hdf5_group(hdf5_group, optimizer):
    580   """"""Saves optimizer weights of a optimizer to a HDF5 group.
    581 
    582   Args:
    583       hdf5_group: HDF5 group.
    584       optimizer: optimizer instance.
    585   """"""
--> 587   symbolic_weights = getattr(optimizer, 'weights')
    588   if symbolic_weights:
    589     weights_group = hdf5_group.create_group('optimizer_weights')

AttributeError: 'Adam' object has no attribute 'weights'
```
</details>"
58799,which encoding can i use to parse tensorflow_stats.pb?,"### Issue Type

Others

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

ubuntu 16.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

i get a tensorflow_stats.pb file by tf.profiler. code like this:
```

            tf.profiler.experimental.start(""./logs_dir"")
            loss = dnn_model.train_step(batch_data)
            tf.profiler.experimental.stop()
```
I want to read tensorflow_stats.pb in my python code, but i don't know which Encoding this file use.
the file content is:
```
""ä°
pHostUpdateMetricState""UpdateMetricState(1ňŇMbx@9ňŇMbx@AňŇMbx@IňŇMbx@a×ÝťÁ.Ň?i×ÝťÁ.Ň?Unknown
rHostUpdateMetricState""UpdateMetricState_1(11ŹZB@91ŹZB@A1ŹZB@I1ŹZB@ać
[ŤŻóĚ?iĽą´KAŕ?Unknown
BHostIDLE""IDLE1ÁĘĄEś×l@AÁĘĄEś×l@aľśş?iôűŮă?Unknown
rHostUpdateMetricState""UpdateMetricState_2(1ŮÎ÷ób@9ŮÎ÷ób@AŮÎ÷ób@IŮÎ÷ób@aÍÖ×;Öą?iďîĂÉĺ?Unknown
pHostAsyncPushGradient""AsyncPushGradient(1î|?5^BV@9î|?5^BV@Aî|?5^BV@Iî|?5^BV@ać^EĂ¤?iYÝe÷pç?Unknown
dHostEmbOutputTransfer""label(1×Łp=
I@9×Łp=
I@A×Łp=
I@I×Łp=
I@aiśÂ­¤?i[veĐç?Unknown
\HostPrintV2""PrintV2(1+ŮÎF@9+ŮÎF@A+ŮÎF@I+ŮÎF@aâÉ­ß?i[ŮŢbyč?Unknown
HostGlobalNormGrad""Bgradient_tape/simple_dnn_model/global_normalization/GlobalNormGrad(19´Čvž?B@99´Čvž?B@A9´Čvž?B@I9´Čvž?B@aĐţ~[ęć?iRŃşľĚé?Unknown
b	Host
```

"
58798,'utf-8' codec can't decode byte 0xcd in position 133: invalid continuation byte,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

windows 64

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
secundum commendationem feci replacement error est, nunc aliud 
with tf.io.gfile.GFile(path, 'r') as fid:

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 133: invalid continuation byte
```


### Standalone code to reproduce the issue

```shell
https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#preparing-the-dataset
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""C:\Python\TensorFlow_Trainin_Custom\venv\lib\site-packages\object_detection\utils\label_map_util.py"", line 133, in load_labelmap
    label_map_string = fid.read()
  File ""C:\Python\TensorFlow_Trainin_Custom\venv\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 116, in read
    self._preread_check()
  File ""C:\Python\TensorFlow_Trainin_Custom\venv\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 77, in _preread_check
    self._read_buf = _pywrap_file_io.BufferedInputStream(
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 133: invalid continuation byte
```
</details>"
58797,Bug when using TFLite converter - error message suggests to send it to you,"I was trying to convert a standard model (properly defined, works just fine when trying to predict stuff) when I encountered this error:

```
WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f7981227160> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Unknown node type <gast.gast.Expr object at 0x7f79811d2df0>
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f7981227160> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10) and attach the full output.
Cause: Unknown node type <gast.gast.Expr object at 0x7f79811d2df0>
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```

I am using a book ,,TinyML: Machine Learning with TensorFlow on Arduino, and Ultra-Low Power Micro-Controllers "", which seems to be written by someone from TF development team.
I follow all the instructions from chapter 4.
If you are interested in my colab code, here it is:
[https://colab.research.google.com/drive/1eyqMB1POAZ9qw3lPCZkiyU7zfQ0Y1OxF#scrollTo=u26RmYUMC3Rw]
Any idea, any help?

UPDATE 06.12.2022
After re-running the entire code the day after I posted the issue (which is today), it worked just fine.
Still, I would like to know what might have caused the problem.
Should I close the issue?"
58796,Question about cuda kernel performance,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.11.0

### Custom Code

Yes

### OS Platform and Distribution

Linux/Ubuntu 20.04

### Mobile device

no

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuda V11.2.152/cudnn 8.1.0

### GPU model and memory

_No response_

### Current Behaviour?


When running my model in eager mode on NVIDIA T4, The elapsed time for cuda kernel will become faster after several iterations (4 to be precise).

The following is the summary from Nsight system. 
As shown, for eager mode, the max is 1.2ms, while the avg is about 500 us after 100 iterations;
for compat.v1.Session style with the same code base, the kernel time is about 1.2ms consistently.  

The question is how does it happen, and which feature from tf2/eager mode can make cuda kernel run faster after several iters? As I understand, the cuda kernel is either from cudnn or cublas, tf itself or tracing or graph compilation should not touch that low-level logic.

```shell
// TF2.11.0 eager mode
 Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)     GridXYZ         BlockXYZ                                                     Name
 --------  ---------------  ---------  --------  --------  --------  --------  -----------  --------------  --------------  ----------------------------------------------------------------------------------------------------
     13.4        258681374        500  517362.7  479449.5    469753   1222701     138505.1     8    5    1   256    1    1  volta_sgemm_128x128_nn 


// TF 2.11.0 tf.compat.v1.Session()
 Time (%)  Total Time (ns)  Instances   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)     GridXYZ         BlockXYZ                                                     Name
 --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  --------------  --------------  ----------------------------------------------------------------------------------------------------
     16.4      607,754,406        500  1,215,508.8  1,221,934.0  1,161,743  1,228,110     18,653.6     8    5    1   256    1    1  volta_sgemm_128x128_nn
```


### Standalone code to reproduce the issue

```shell
// eager mode
for i in tf.range(100):
    tf.print(model(x))

// sess
With tf.compat.v1.Session() as sess:
     print(sess.run(output_name_list, x))
```


### Relevant log output

_No response_</details>"
58791,TF2.9 perf is slower,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf2.9

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

A100 

### Current Behaviour?

```shell
We migrate from tf2.4 to tf2.9, and observed that the training speed of some models has ~20% decrease. 

On tf2.4, it takes ~30mins after starting the job, before processing the 1st batch. Training speed increase and then become stable.
On tf2.9, it takes ~5mins after starting the job, before processing the 1st batch. Training speed does not increase.

Q1: Can we use tf2.4 to train the model and use tf2.9 for inferencing? Any potential issues?
Q2: How can we find the root cause of tf2.9 training slowness?
```


### Standalone code to reproduce the issue

```shell
Can't share the source code.
```


### Relevant log output

_No response_</details>"
58790,tf.math.cumsum() propagates Inf or NaN when axis is ragged,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.11

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.7, cuDNN 8.2.4

### GPU model and memory

RTX 3090 24GiB

### Current Behaviour?

```shell
When using `tf.math.cumsum(ragged_tensor, axis=axis)`, if `axis` is ragged and `ragged_tensor` contains `inf` or `nan`, the output will be `nan` for *all* the following flat values, even for those that are not supposed to be summed with those `nan`s. This doesn't happen for regular `Tensor`s. 

Moreover, the behavior persists when `exlusive=True` or `reverse=True` is passed to `cumsum()`. In the latter case, additional `nan`s occur before the problematic value, instead of after it.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf 
import numpy as np 

# RaggedTensor without NaNs or Infs
rt = tf.ragged.constant([[3, 1, 4], [1, 5], [9, 2], [6, 5, 3]], dtype=tf.float32)
print('tf.math.cumsum(rt, axis=-1) = ', tf.math.cumsum(rt, axis=-1))

# RaggedTensor with Inf
rt2 = tf.ragged.constant([[3, 1, 4], [1, np.inf], [9, 2], [6, 5, 3]], dtype=tf.float32)
print('tf.math.cumsum(rt2, axis=-1) = ', tf.math.cumsum(rt2, axis=-1))
print('tf.math.cumsum(rt2.to_tensor(), axis=-1) = ', tf.math.cumsum(rt2.to_tensor(), axis=-1))
print('tf.math.cumsum(rt2, axis=-1, exclusive=True) = ', tf.math.cumsum(rt2, axis=-1, exclusive=True))
print('tf.math.cumsum(rt2.to_tensor(), axis=-1, exclusive=True) = ', tf.math.cumsum(rt2.to_tensor(), axis=-1, exclusive=True))
print('tf.math.cumsum(rt2, axis=-1, reverse=True) = ', tf.math.cumsum(rt2, axis=-1, reverse=True))
print('tf.math.cumsum(rt2.to_tensor(), axis=-1, reverse=True) = ', tf.math.cumsum(rt2.to_tensor(), axis=-1, reverse=True))

""""""Expected output
tf.math.cumsum(rt, axis=-1) =  <tf.RaggedTensor [[3.0, 4.0, 8.0], [1.0, 6.0], [9.0, 11.0], [6.0, 11.0, 14.0]]>
tf.math.cumsum(rt2, axis=-1) =  <tf.RaggedTensor [[3.0, 4.0, 8.0], [1.0, inf],  [9.0, 11.0], [6.0, 11.0, 14.0]]>
tf.math.cumsum(rt2.to_tensor(), axis=-1) =  tf.Tensor(
[[ 3.  4.  8.]
 [ 1. inf inf]
 [ 9. 11. 11.]
 [ 6. 11. 14.]], shape=(4, 3), dtype=float32)
tf.math.cumsum(rt2, axis=-1, exclusive=True) =  <tf.RaggedTensor [[0.0, 3.0, 4.0], [0.0, 1.0], [0.0, 9.0], [0.0, 6.0, 11.0]]>
tf.math.cumsum(rt2.to_tensor(), axis=-1, exclusive=True) =  tf.Tensor(
[[ 0.  3.  4.]
 [ 0.  1. inf]
 [ 0.  9. 11.]
 [ 0.  6. 11.]], shape=(4, 3), dtype=float32)
tf.math.cumsum(rt2, axis=-1, reverse=True) =  <tf.RaggedTensor [[8.0, 5.0, 4.0], [inf, inf], [11.0, 2.0], [14.0, 8.0, 3.0]]>
tf.math.cumsum(rt2.to_tensor(), axis=-1, reverse=True) =  tf.Tensor(
[[ 8.  5.  4.]
 [inf inf  0.]
 [11.  2.  0.]
 [14.  8.  3.]], shape=(4, 3), dtype=float32)
""""""

""""""Actual output
tf.math.cumsum(rt, axis=-1) =  <tf.RaggedTensor [[3.0, 4.0, 8.0], [1.0, 6.0], [9.0, 11.0], [6.0, 11.0, 14.0]]>
tf.math.cumsum(rt2, axis=-1) =  <tf.RaggedTensor [[3.0, 4.0, 8.0], [1.0, inf], [nan, nan], [nan, nan, nan]]>
tf.math.cumsum(rt2.to_tensor(), axis=-1) =  tf.Tensor(
[[ 3.  4.  8.]
 [ 1. inf inf]
 [ 9. 11. 11.]
 [ 6. 11. 14.]], shape=(4, 3), dtype=float32)
tf.math.cumsum(rt2, axis=-1, exclusive=True) =  <tf.RaggedTensor [[0.0, 3.0, 4.0], [0.0, 1.0], [nan, nan], [nan, nan, nan]]>
tf.math.cumsum(rt2.to_tensor(), axis=-1, exclusive=True) =  tf.Tensor(
[[ 0.  3.  4.]
 [ 0.  1. inf]
 [ 0.  9. 11.]
 [ 0.  6. 11.]], shape=(4, 3), dtype=float32)
tf.math.cumsum(rt2, axis=-1, reverse=True) =  <tf.RaggedTensor [[nan, nan, nan], [inf, inf], [11.0, 2.0], [14.0, 8.0, 3.0]]>
tf.math.cumsum(rt2.to_tensor(), axis=-1, reverse=True) =  tf.Tensor(
[[ 8.  5.  4.]
 [inf inf  0.]
 [11.  2.  0.]
 [14.  8.  3.]], shape=(4, 3), dtype=float32)
""""""
```


### Relevant log output

_No response_</details>"
58787,MNMG training with jit_compile=True is not working,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf2.11

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.0

### Bazel version

5.1.1

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuda 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
We trained the ResNet-50 model in tf-model-garden repository (tag v2.11.0) with config runtime_enable_xla=True, on 2 nodes each with 8 gpus. Ran into Graph Execution Error. The expected behavior is that no error should happen when compiling the graph. However, we can use the following walkaround https://github.com/tensorflow/models/pull/10845 for now.
```


### Standalone code to reproduce the issue

```shell
/usr/local/bin/python3.9 official/vision/train.py --config_file official/vision/configs/experiments/image_classification/imagenet_resnet50_gpu.yaml --experiment resnet_imagenet --mode train --model_dir /opt/ml/model --params_override runtime.enable_xla=True,runtime.num_gpus=8,runtime.distribution_strategy=multi_worker_mirrored,runtime.mixed_precision_dtype=float16,task.train_data.global_batch_size=1024,task.train_data.input_path=/opt/ml/input/data/training/train*,task.train_data.cache=True,trainer.train_steps=12792,trainer.steps_per_loop=1279,trainer.summary_interval=1279,trainer.checkpoint_interval=12792,task.model.backbone.type=resnet,task.model.backbone.resnet.model_id=50
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/opt/ml/code/official/vision/train.py"", line 93, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.9/site-packages/absl/app.py"", line 308, in run
_run_main(main, args)
  File ""/usr/local/lib/python3.9/site-packages/absl/app.py"", line 254, in _run_main
sys.exit(main(argv))
  File ""/opt/ml/code/official/vision/train.py"", line 81, in main
train_lib.run_experiment(
  File ""/opt/ml/code/official/core/train_lib.py"", line 306, in run_experiment
return runner.run()
  File ""/opt/ml/code/official/core/train_lib.py"", line 215, in run
self.controller.train(steps=params.trainer.train_steps)
  File ""/opt/ml/code/orbit/controller.py"", line 260, in train
self._train_n_steps(num_steps)
  File ""/opt/ml/code/orbit/controller.py"", line 463, in _train_n_steps
train_output = self.trainer.train(num_steps_tensor)
  File ""/opt/ml/code/orbit/standard_runner.py"", line 146, in train
self._train_loop_fn(self._train_iter, num_steps)
  File ""/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute
tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.
InternalError: Graph execution error:
Detected at node 'replica_5/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_5/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_3/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_3/StatefulPartitionedCall'
Detected at node 'replica_2/StatefulPartitionedCall' defined at (most recent call last):
    File ""/usr/local/lib/python3.9/threading.py"", line 930, in _bootstrap
      self._bootstrap_inner()
    File ""/usr/local/lib/python3.9/threading.py"", line 973, in _bootstrap_inner
      self.run()
    File ""/tmp/__autograph_generated_filew7jlrzp1.py"", line 30, in step_fn
      logs = ag__.converted_call(ag__.ld(task_train_step), (ag__.ld(inputs),), dict(model=ag__.ld(self).model, optimizer=ag__.ld(self).optimizer, metrics=ag__.ld(self).train_metrics), fscope_1)
Node: 'replica_2/StatefulPartitionedCall'
9 root error(s) found.
  (0) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_5/StatefulPartitionedCall}}]]
  (1) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
#011 [[while/body/_1/update_2/AssignAddVariableOp/_172]]
#011 [[while/LoopCond/_3558/_213]]
  (2) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
#011 [[while/body/_1/update_2/AssignAddVariableOp/_172]]
#011 [[cluster_2_1/data_as_ctrl/_136]]
  (3) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
#011 [[while/body/_1/update_2/AssignAddVariableOp/_172]]
#011 [[cluster_0_1/data_as_ctrl/_160]]
  (4) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
#011 [[while/body/_1/update_2/AssignAddVariableOp/_172]]
#011 [[cluster_0_1/data_as_ctrl/_148]]
  (5) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
#011 [[while/body/_1/update_2/AssignAddVariableOp/_172]]
#011 [[Func/while/body/_1/input/_7599/_81]]
  (6) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
#011 [[while/body/_1/update_2/AssignAddVariableOp/_172]]
  (7) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_3/StatefulPartitionedCall}}]]
  (8) INTERNAL:  tensorflow/compiler/xla/service/gpu/nccl_utils.cc:266: NCCL operation ncclCommInitRank(comm.get(), nranks, id, rank) failed: remote process exited or there was a network error
#011 [[{{node replica_2/StatefulPartitionedCall}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_loop_fn_163070]
```
</details>"
58786,Tensorflow Layer Reshape not working for same size arrays,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

Yes

### OS Platform and Distribution

Windows 10 Pro

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.8

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensorflow Reshape layer was throwing size mismatch errors when trying to reshape an array to another of the same size.
Sometimes it was working, sometimes not. After testing found examples of Reshape not working for a target array of the exact same shape as input array.

This behaviour only seems to happen on windows and code works on linux
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

tensor = tf.keras.Input(shape=(512, 512, 512, 32))
out = tf.keras.layers.Reshape((512, 512, 512, 32))(tensor)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""d:\Miniconda3\envs\python\lib\site-packages\keras\utils\traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""d:\Miniconda3\envs\python\lib\site-packages\keras\layers\reshaping\reshape.py"", line 118, in _fix_unknown_dimension
    raise ValueError(msg)
ValueError: Exception encountered when calling layer ""reshape_1"" (type Reshape).

total size of new array must be unchanged, input_shape = [512, 512, 512, 32], output_shape = [512, 512, 512, 32]

Call arguments received by layer ""reshape_1"" (type Reshape):
  • inputs=tf.Tensor(shape=(None, 512, 512, 512, 32), dtype=float32)
```
</details>"
58784,TensorFlow Lite Image Classification - add a new model,"Hello. I tested your TensorFlow Lite Image Classification android app and it works perfect with these models (MobileNet V1, EfficientNet Lite0, EfficientNet Lite1, EfficientNet Lite2) which are downloading automatically by the download.gradle file.

https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android

Then I wanted to add my own classification model which has different labels compared to models mentioned above. I placed my model in **assets** folder app\src\main\assets and then did some modification in **ImageClassifierHelper.kt** file.

val modelName =
            when (currentModel) {
                MODEL_MYMODEL -> ""mymodel.tflite""
                MODEL_MOBILENETV1 -> ""mobilenetv1.tflite""
                else -> ""mymodel.tflite""
            }

companion object {
        const val DELEGATE_CPU = 0
        const val DELEGATE_GPU = 1
        const val DELEGATE_NNAPI = 2
        const val MODEL_MYMODEL = 0
        const val MODEL_MOBILENETV1 = 1
        private const val TAG = ""ImageClassifierHelper""
    }


While I build and launch the app, I received the following error:

**Launching 'app' on Xiaomi .....
Install successfully finished in 6 s 117 ms.
$ adb shell am start -n ""org.tensorflow.lite.examples.imageclassification/org.tensorflow.lite.examples.imageclassification.MainActivity"" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER
Connected to process 15146 on device 'xiaomi-......'.**

Can you please let me know how to fix the issue and do I need to do other modification in scripts to make it work with my model. 

Look forward to hearing from you and thank you in advance!
"
58783,A error when using tfmot.quantization.keras.quantize_model to quantize keras model,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf=2.4.1, tensorflow_model_optimization==0.5.0                                            

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.6.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
A error when using tfmot.quantization.keras.quantize_model to quantize keras model:
RuntimeError: Layer conv1d:<class 'tensorflow.python.keras.layers.convolutional.Conv1D'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API.

dose fmot.quantization.keras.quantize_model not support 1DCNN?
```


### Standalone code to reproduce the issue

```shell
LOGGER.info(f""starting"")
        prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude
        pruning_params = {'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=0.30,begin_step=0,end_step=-1)}
        LOGGER.info(f""pruning"")
        self._model = prune_low_magnitude(self._model, **pruning_params)
        LOGGER.info(f""compiling"")
        self._model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=[""accuracy""])
        LOGGER.info(f""fitting"")
        history=self._model.fit(x=data, epochs=8, verbose=1, shuffle=True, callbacks=callbacks)

        LOGGER.info(f""striping"")
        self._model = tfmot.sparsity.keras.strip_pruning(self._model)

        LOGGER.info(f""quantizing"")
        quantize_model = tfmot.quantization.keras.quantize_model
        self._model = quantize_model(self._model)

        LOGGER.info(f""compiling"")
        self._model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=[""accuracy""])


        LOGGER.info(f""fitting"")
        history = self._model.fit(x=data, epochs=2, verbose=1, shuffle=True, callbacks=callbacks)
```


### Relevant log output

_No response_</details>"
58782,Use cl_khr_integer_dot_product if available,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

707f1dcba4c8 (HEAD -> master, origin/master, origin/HEAD) compat: Update forward compatibility horizon to 2022-12-05

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Are there any plans to make use of cl_khr_integer_dot_product to speed up execution on GPUs that support it?
```


### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_</details>"
58781,Convert saved model (trained in TF1) from using Float32 into BFloat16 (or Float16),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04


### Python version

3.8

### CUDA/cuDNN version

11.4

### GPU model and memory

NVIDIA GeForce RTX 3070 Laptop GPU ; 8GB GPU RAM + 64 GB RAM

### Current Behaviour?

```shell
I am trying to convert a pretrained Model from using Float32 operations/Weights into using BFloat16 operations and weights. 

I came accross this [Blog by intel](https://www.intel.com/content/www/us/en/developer/articles/guide/getting-started-with-automixedprecisionmkl.html) That promises to just what I want.

Note: I modified the code to make the transformed model always in .pb instead of text format

The Expected Behavior: it should produce the same model with the same signatures kept intact (Signatures def and metagraphdef tags) but with modified operations and weights

Current Behavior: the output model has less weight but it doesn't have any signatures... so for example if I do:

import tensorflow as tf
m = tf.saved_model.load(""path/to/BFloat16-model/"")
print(m.signatures)
# outputs : _SignatureMap({})

Note: the produced model has less weight than the input model; and the logs during the transformation states that some operations have succeessfully been transformed
```


### Standalone code to reproduce the issue

```shell
# code to save a model
import tensorflow as tf 
import tensorflow.python.saved_model 
from tensorflow.python.saved_model import tag_constants 
from tensorflow.python.saved_model.signature_def_utils_impl import predict_signature_def 

# Disable Eager execution mode 
tf.compat.v1.disable_eager_execution() 

def conv2d(x, w, b, strides=1): 
    # Conv2D wrapper, with bias and relu activation 
    x = tf.nn.conv2d(x, w, strides=[1, strides, strides, 1], padding='SAME',name=""myInput"") 
    x = tf.nn.bias_add(x, b) 
    return tf.nn.relu(x, name=""myOutput"")  

X = tf.Variable(tf.compat.v1.random_normal([784], name=""myInput"")) 
W = tf.Variable(tf.compat.v1.random_normal([5, 5, 1, 32])) 
B = tf.Variable(tf.compat.v1.random_normal([32])) 
x = tf.reshape(X, shape=[-1, 28, 28, 1]) 

export_dir='./model'  

with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto()) as sess: 
    sess.run(tf.compat.v1.global_variables_initializer()) 
    y=conv2d(x,W,B) 
    sess.run([y]) 
    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir) 
    signature = predict_signature_def(inputs={'myInput': X}, 
                                  outputs={'myOutput': y}) 
    builder.add_meta_graph_and_variables(sess=sess, 
                                     tags=[""myTag""], 
                                     signature_def_map={'predict': signature}) 
    builder.save() 


```Python
# Code to transform the model from Float32 -> BFloat16
from argparse import ArgumentParser 
from tensorflow.core.protobuf import config_pb2 
from tensorflow.core.protobuf import rewriter_config_pb2 
from tensorflow.python.grappler import tf_optimizer 
from tensorflow.python.tools import saved_model_utils 
import tensorflow as tf 
import time   

parser = ArgumentParser() 
parser.add_argument(""input_dir"", help=""Input directory containing saved_model.pb."", type=str) 
parser.add_argument(""output_dir"", help=""Directory to store output graph."", type=str) 
parser.add_argument(""output_graph"", help=""Output graph name. (e.g., foo.pb,"" 
                    ""foo.pbtxt, etc)"", type=str) 
args = parser.parse_args()   

graph_options = tf.compat.v1.GraphOptions(rewrite_options=rewriter_config_pb2.RewriterConfig(
     auto_mixed_precision_onednn_bfloat16=rewriter_config_pb2.RewriterConfig.ON)) 
optimizer_config = tf.compat.v1.ConfigProto(graph_options=graph_options) 
metagraph_def = saved_model_utils.get_meta_graph_def(args.input_dir, ""myTag"") 
output_graph = tf_optimizer.OptimizeGraph(optimizer_config, metagraph_def) 
tf.io.write_graph(output_graph, args.output_dir, args.output_graph, 
                  as_text=False) 
```
```
"
58780,Memory overflow using timeseries_dataset_from_array,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.6.4

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Memory overflow using timeseries_dataset_from_array
I have a 600,000row by 5 feature dataset that I converted to a TensorFlow dataset using the timeseries_dataset_from_array function. In Kaggle, when I use the CPU, the memory is normal (about one GB), but when I use the GPU, the memory overflows (more than 16 GB)and gives a series of warnings.
In addition, the timeseries_dataset_from_array function gives one output for each data series and cannot output for all time steps.
That is now: (Batch, Steps, Features)=>(Batch, targets) 
But I wana: (Batch, Steps, Features)=>(Batch,Steps, targets)
Another case is that an output cannot be adjusted based on the order of the input steps. 
That is now:
(x1,y1), (x2,y2), (x3,y3) => (x1,x2,x3  ,y3)
But I wana:
(x1,y1), (x2,y2), (x3,y3) => (x1,x2,x3  ,y1)
```


### Standalone code to reproduce the issue

```shell
sorry, private code
```


### Relevant log output

```shell
GPU memory overflow warning:

2022-12-05 07:04:09.449335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:09.460257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:09.461223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:09.463592: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-05 07:04:09.463905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:09.464943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:09.465852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:10.201418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:10.202311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:10.203072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-05 07:04:10.203715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability:
```
</details>"
58778,Cannot convert Handwriting recognition model to tflite model,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installation (pip package or built from source): pip install ""tensorflow<2.11""
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.1
- Python 3.10

### 2. Code

Used the code from the tutorial on this page:
https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/handwriting_recognition.ipynb
And at the end tried converting the prediction model to a TF Lite model using following code:

```
converter = tf.lite.TFLiteConverter.from_keras_model(prediction_model)
tflite_float_model = converter.convert()
```
And then I get the following error:
[error_log_1.txt](https://github.com/tensorflow/tensorflow/files/10149753/error_log_1.txt)
Which basically says that I need to set supported_ops flags. First of all, is there any way I can prevent that? I don't understand what function in the code is using select TensorFlow core operators, I don't want to be using any select TensorFlow core operators since it makes it creates other problems.

And then when I do set these flags:
```
converter = tf.lite.TFLiteConverter.from_keras_model(prediction_model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter._experimental_lower_tensor_list_ops = False
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_float_model = converter.convert()
```

Then I get the following messages, which i'm not sure if these are indicating if something's gone wrong or not:
[error_log_2.txt](https://github.com/tensorflow/tensorflow/files/10149850/error_log_2.txt)

And export the model and import it in my android project using these instructions: https://www.tensorflow.org/lite/guide/ops_select
On Android I then convert the model file to byte buffer and try to pass it to TF Lite Interpreter as follows:
```
val fileDescriptor = context.assets.openFd(filename)
val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
val fileChannel = inputStream.channel
val startOffset = fileDescriptor.startOffset
val declaredLength = fileDescriptor.declaredLength
val byteBuffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
val interpreter = org.tensorflow.lite.Interpreter(byteBuffer)
```
I then get a IllegalArgumentException with following message:
`""Model ByteBuffer should be either a MappedByteBuffer of the model file, or a direct ByteBuffer using ByteOrder.nativeOrder() which contains bytes of model content.""`
I think there is something wrong with the exported TF Lite model file. 

Best solution would probably be to avoid using select TF operators, would really like to avoid it if possible.
Would appreciate your help!



"
58777,tfds plant_leaves downloads failing,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

macOS Monterey version 12.6

### Mobile device

n/a

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

I am getting timeouts when trying to download the [`plant_leaves`](https://www.tensorflow.org/datasets/catalog/plant_leaves) dataset on December 4th, 2022.

### Standalone code to reproduce the issue

```python
import tensorflow_datasets as tfds

dataset = tfds.load(name=""plant_leaves"", split=""train"", as_supervised=True)
```

### Relevant log output

```None
File ""/path/to/lib/python3.10/site-packages/tensorflow_datasets/core/download/downloader.py"", line 306, in _assert_status
    raise DownloadError('Failed to get url {}. HTTP code: {}.'.format(
tensorflow_datasets.core.download.downloader.DownloadError: Failed to get url https://data.mendeley.com/v1/datasets/hb74ynkjcn/1/files/7f977a2c-aa75-4610-a6f6-84c8738d8c79/0001_0001.JPG. HTTP code: 404.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/path/to/lib/python3.10/site-packages/tensorflow_datasets/core/logging/__init__.py"", line 250, in decorator
    return function(*args, **kwargs)
  File ""/path/to/lib/python3.10/site-packages/tensorflow_datasets/core/load.py"", line 575, in load
    dbuilder.download_and_prepare(**download_and_prepare_kwargs)
  File ""/path/to/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py"", line 523, in download_and_prepare
    self._download_and_prepare(
  File ""/path/to/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_builder.py"", line 1244, in _download_and_prepare
    split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg
  File ""/path/to/lib/python3.10/site-packages/tensorflow_datasets/image_classification/plant_leaves.py"", line 123, in _split_generators
    raise DownloadRetryLimitReachedError(
tensorflow_datasets.image_classification.plant_leaves.DownloadRetryLimitReachedError: Retry limit reached. Try downloading the dataset again.
```
</details>"
58776,importError,"I tried running a streamlit app taken from github 
github link: https://github.com/AjinkyaChavan9/RGB-Color-Classifier-with-Deep-Learning-using-Keras-and-Tensorflow

(TF Version: 2.5.1, python version 3.9.15)
But its showing 






Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
                                  ^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py"", line 564, in _run_script
    exec(code, module.__dict__)
  File ""C:\Users\Deehan\rgbColor\master\RgBCOLOR\RGB_Color_Classifier_app\RGB_web_app.py"", line 5, in <module>
    from color_classifier import predict_color #importing predicting color function
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\rgbColor\master\RgBCOLOR\RGB_Color_Classifier_app\color_classifier.py"", line 7, in <module>
    import tensorflow as tf
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
                                  ^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
2022-12-04 11:43:32.680 Uncaught app exception
Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
                                  ^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py"", line 564, in _run_script
    exec(code, module.__dict__)
  File ""C:\Users\Deehan\rgbColor\master\RgBCOLOR\RGB_Color_Classifier_app\RGB_web_app.py"", line 5, in <module>
    from color_classifier import predict_color #importing predicting color function
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\rgbColor\master\RgBCOLOR\RGB_Color_Classifier_app\color_classifier.py"", line 7, in <module>
    import tensorflow as tf
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
                                  ^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\Deehan\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

"
58775,Pass keyword arguments in keras CTC to tensorflow CTC function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Running a CTC-loss training can cause an error if the label is larger than the model's output. This error can be converted to a warning if you pass the approperiate flag. However, using keras ctc function (which is a wrapper to the tensorflow ctc function) doesn't allow the passing of key-word arguments to the ctc function in tensorflow.

The error text is 

Not enough time for target transition sequence (required: 156, available: 13)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
```
```


### Standalone code to reproduce the issue

```shell
The code in this keras tutorial https://keras.io/examples/audio/ctc_asr/
```


### Relevant log output

```shell
File ""/home/username/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1082, in compute_loss
      return self.compiled_loss(
    File ""/home/username/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py"", line 265, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File ""/home/username/.local/lib/python3.10/site-packages/keras/losses.py"", line 152, in __call__
      losses = call_fn(y_true, y_pred)
    File ""/home/username/.local/lib/python3.10/site-packages/keras/losses.py"", line 284, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""/tmp/ipykernel_8261/142572972.py"", line 10, in CTCLoss
      loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)
    File ""/home/username/.local/lib/python3.10/site-packages/keras/backend.py"", line 7023, in ctc_batch_cost
      tf.compat.v1.nn.ctc_loss(
Node: 'CTCLoss/CTCLoss'
2 root error(s) found.
  (0) INVALID_ARGUMENT:  Not enough time for target transition sequence (required: 156, available: 13)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[{{node CTCLoss/CTCLoss}}]]
	 [[CTCLoss/CTCLoss/_86]]
  (1) INVALID_ARGUMENT:  Not enough time for target transition sequence (required: 156, available: 13)0You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs
	 [[{{node CTCLoss/CTCLoss}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_4574]
```
</details>"
58774,Could not find a version that satisfies the requirement tensorflow (from versions: none),"❯ python --version
Python 3.10.5
❯ pip3 install tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow

OS: Mac Ventura M1"
58773,Tensorflow 2.11.0 is incompatible with python 3.10.8,"`pip install -U --user tensorflow`
does not work on python 3.10.8

Tensorflow 2.11.0 depends on numpy==1.19.3
But that version of numpy is incompatible with python 3.10.8

There is a call `_Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@))` in numpy 1.19.3, but that function is changed to `_Py_HashDouble(PyObject *, double)` at https://github.com/python/cpython/commit/a07da09ad5bd7d234ccd084a3a0933c290d1b592

<details>
<summary> Compiler Output</summary>

#### In numpy/core/src/multiarray/scalartypes.c.src:

```
numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
In file included from /usr/include/python3.10/Python.h:77,
                 from numpy/core/src/multiarray/scalartypes.c.src:3:
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDoubl ’
 2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
      |            ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src: In function ‘cfloat_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2975 |     hashreal = _Py_HashDouble((double)
      |                               ^~~~~~~~
      |                               |
      |                               double
 2976 |             PyArrayScalar_VAL(obj, C@name@).real);
      |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDoubl ’
 2975 |     hashreal = _Py_HashDouble((double)
      |                ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2981 |     hashimag = _Py_HashDouble((double)
      |                               ^~~~~~~~
      |                               |
      |                               double
 2982 |             PyArrayScalar_VAL(obj, C@name@).imag);
      |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDoubl ’
 2981 |     hashimag = _Py_HashDouble((double)
      |                ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2967:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2967:12: error: too few arguments to function ‘_Py_HashDoubl ’
 2967 |     return _Py_HashDouble((double) PyArrayScalar_VAL(obj, @name@));
      |            ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src: In function ‘clongdouble_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2975:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2975 |     hashreal = _Py_HashDouble((double)
      |                               ^~~~~~~~
      |                               |
      |                               double
 2976 |             PyArrayScalar_VAL(obj, C@name@).real);
      |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2975:16: error: too few arguments to function ‘_Py_HashDoubl ’
 2975 |     hashreal = _Py_HashDouble((double)
      |                ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2981:31: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2981 |     hashimag = _Py_HashDouble((double)
      |                               ^~~~~~~~
      |                               |
      |                               double
 2982 |             PyArrayScalar_VAL(obj, C@name@).imag);
      |             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2981:16: error: too few arguments to function ‘_Py_HashDoubl ’
 2981 |     hashimag = _Py_HashDouble((double)
      |                ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2997:27: error: incompatible type for argument 1 of ‘_Py_HashDouble’
 2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));
      |                           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |                           |
      |                           double
/usr/include/python3.10/pyhash.h:10:38: note: expected ‘PyObject *’ {aka ‘struct _object *’} but argument is of type ‘double’
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                                      ^~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src:2997:12: error: too few arguments to function ‘_Py_HashDoubl ’
 2997 |     return _Py_HashDouble(npy_half_to_double(PyArrayScalar_VAL(obj, Half)));
      |            ^~~~~~~~~~~~~~
/usr/include/python3.10/pyhash.h:10:23: note: declared here
   10 | PyAPI_FUNC(Py_hash_t) _Py_HashDouble(PyObject *, double);
      |                       ^~~~~~~~~~~~~~
numpy/core/src/multiarray/scalartypes.c.src: In function ‘longdouble_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]
 2968 | }
      | ^
numpy/core/src/multiarray/scalartypes.c.src: In function ‘float_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2968:1: warning: control reaches end of non-void function [-Wreturn-type]
 2968 | }
      | ^
numpy/core/src/multiarray/scalartypes.c.src: In function ‘half_arrtype_hash’:
numpy/core/src/multiarray/scalartypes.c.src:2998:1: warning: control reaches end of non-void function [-Wreturn-type]
 2998 | }
      | ^

```
</details>

It is fixed in https://github.com/numpy/numpy/commit/ad2a73c18dcff95d844c382c94ab7f73b5571cf3, which is of numpy version 1.22.0
I guess updating numpy dependency may fix this"
58772,Issue created for Rollback of PR #57983:  Fix crash in tf.nn.conv2d_transpose when output shape is invalid,"Merged PR #57983 is rolled back in a61d35414420ea53f02fedada7e92e80a69cd9d4.
    Please follow up with the reviewer and close this issue once its resolved."
58768,Build on PPC fails due to import of `__subpackages__`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

TF since 2.8

### Custom Code

No

### OS Platform and Distribution

Linux RHEL 7

### Mobile device

_No response_

### Python version

3.10

### Bazel version

4.2.2

### GCC/Compiler version

11.2

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_
</details>

### Current Behaviour?

```shell
The build on POWER/PPC machine fails with e.g. 

/XNNPACK/BUILD.bazel:7746:26: Configurable attribute ""deps"" doesn't match this con
figuration (would a default condition help?).
Conditions checked:
 @XNNPACK//:linux_k8
 @XNNPACK//:linux_arm
 @XNNPACK//:linux_armeabi
 @XNNPACK//:linux_armhf
 @XNNPACK//:linux_armv7a
 @XNNPACK//:linux_arm64
 @XNNPACK//:macos_x86_64
 @XNNPACK//:macos_arm64
 @XNNPACK//:windows_x86_64_clang
 @XNNPACK//:windows_x86_64_mingw
 @XNNPACK//:windows_x86_64_msys
 @XNNPACK//:windows_x86_64
 @XNNPACK//:android_armv7
 @XNNPACK//:android_arm64
 @XNNPACK//:android_x86
 @XNNPACK//:android_x86_64
 @XNNPACK//:ios_armv7
 @XNNPACK//:ios_arm64
 @XNNPACK//:ios_arm64e
 @XNNPACK//:ios_x86
 @XNNPACK//:ios_x86_64
 @XNNPACK//:watchos_armv7k
 @XNNPACK//:watchos_arm64_32
 @XNNPACK//:watchos_x86
 @XNNPACK//:watchos_x86_64
 @XNNPACK//:tvos_arm64
 @XNNPACK//:tvos_x86_64
 @XNNPACK//:emscripten_wasm
 @XNNPACK//:emscripten_wasmsimd
```

I don't think that blindly importing/depending on everything is a good idea. Besides that issues like that should likely be fixed in the other repos (see the link below).



### Standalone code to reproduce the issue
Simply build the PIP package per the instructions.

Reason is https://github.com/tensorflow/tensorflow/commit/754b33d9526ac4ed9d4900ffea1a35107037b37f which makes a target depend on `@XNNPACK//:__subpackages__` (and also e.g. `@cpuinfo//:__subpackages__`) but those are not (correctly?) define for PPC. See e.g. https://github.com/google/XNNPACK/issues/3950

When removing the XNNPACK dependency then I get a similar issue for CPUINFO:

```
ERROR: /dev/shm/s3248973-EasyBuild/TensorFlow/2.8.2/foss-2021b/TensorFlow/bazel-root/366a3a873d5422e1454f21ea2c9f7525/external/cpuinfo/BUILD.bazel:100:11: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
```"
58766,//tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test fails to build,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.10

### Bazel version

5.3.0

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
Trying to build the test //tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test fails with link errors such as
`bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::_AlgorithmProto_default_instance_'`
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=2 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --build_tests_only -- //tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test
```


### Relevant log output

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=2 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --build_tests_only -- //tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=117
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --define framework_shared_object=true --define tsl_protobuf_header_only=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 --action_env PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages --python_path=/home/builder/1/tensorflow_build/venv_py38/bin/python3
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium
INFO: Found applicable config definition build:short_logs in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition test:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
INFO: Found applicable config definition build:nonccl in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:mkl_aarch64_threadpool in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=build_with_mkl_aarch64=true -c opt
INFO: Found applicable config definition build:linux in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-unknown-warning --copt=-Wno-array-parameter --copt=-Wno-stringop-overflow --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --copt=-Wswitch --copt=-Werror=switch --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test (1 packages loaded, 7 targets configured).
INFO: Found 1 test target...
ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/xla/tools/BUILD:255:14: Linking tensorflow/compiler/xla/tools/interactive_graphviz failed: (Exit 1): gcc failed: error executing command 
  (cd /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow && \
  exec env - \
    PATH=/home/builder/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-arm64/bin:/home/builder/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 \
    PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /usr/local/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/tools/interactive_graphviz-2.params)
# Configuration: d45cf8a96c93cdeab0dbdaf20276fe89827c573a72a6bad81998b5c180ddbd8c
# Execution platform: @local_execution_config_platform//:platform
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::_AlgorithmProto_default_instance_'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::_AlgorithmProto_default_instance_'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::AlgorithmProto(stream_executor::dnn::AlgorithmProto const&)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::AlgorithmProto()'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::InternalSwap(stream_executor::dnn::AlgorithmProto*)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::~AlgorithmProto()'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::~AlgorithmProto()'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::~AlgorithmProto()'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/_objs/hlo_graph_dumper/hlo_graph_dumper.o:hlo_graph_dumper.cc:function xla::(anonymous namespace)::HloDotDumper::GetInstructionNodeBackendConfig(xla::HloInstruction const*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::~AlgorithmProto()'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function InitDefaultsscc_info_CudnnConvBackendConfig_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto(): error: undefined reference to 'stream_executor::dnn::_AlgorithmProto_default_instance_'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function InitDefaultsscc_info_CudnnConvBackendConfig_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto(): error: undefined reference to 'stream_executor::dnn::_AlgorithmProto_default_instance_'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergeFrom(xla::gpu::CudnnConvBackendConfig const&): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::MergeFrom(stream_executor::dnn::AlgorithmProto const&)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergeFrom(xla::gpu::CudnnConvBackendConfig const&): error: undefined reference to 'stream_executor::dnn::AlgorithmProto* google::protobuf::Arena::CreateMaybeMessage<stream_executor::dnn::AlgorithmProto>(google::protobuf::Arena*)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergeFrom(xla::gpu::CudnnConvBackendConfig const&): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::MergeFrom(stream_executor::dnn::AlgorithmProto const&)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergeFrom(google::protobuf::Message const&): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::MergeFrom(stream_executor::dnn::AlgorithmProto const&)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergeFrom(google::protobuf::Message const&): error: undefined reference to 'stream_executor::dnn::AlgorithmProto* google::protobuf::Arena::CreateMaybeMessage<stream_executor::dnn::AlgorithmProto>(google::protobuf::Arena*)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergeFrom(google::protobuf::Message const&): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::MergeFrom(stream_executor::dnn::AlgorithmProto const&)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*): error: undefined reference to 'stream_executor::dnn::AlgorithmProto* google::protobuf::Arena::CreateMaybeMessage<stream_executor::dnn::AlgorithmProto>(google::protobuf::Arena*)'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::InternalSerializeWithCachedSizesToArray(unsigned char*) const: error: undefined reference to 'stream_executor::dnn::AlgorithmProto::InternalSerializeWithCachedSizesToArray(unsigned char*) const'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:function xla::gpu::CudnnConvBackendConfig::ByteSizeLong() const: error: undefined reference to 'stream_executor::dnn::AlgorithmProto::ByteSizeLong() const'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/service/gpu/_objs/backend_configs_cc_impl/backend_configs.pb.o:backend_configs.pb.cc:scc_info_CudnnConvBackendConfig_tensorflow_2fcompiler_2fxla_2fservice_2fgpu_2fbackend_5fconfigs_2eproto: error: undefined reference to 'scc_info_AlgorithmProto_tensorflow_2ftsl_2fprotobuf_2fdnn_2eproto'
bazel-out/aarch64-opt/bin/tensorflow/compiler/xla/stream_executor/_objs/dnn_proto_cc_impl/dnn.pb.o:dnn.pb.cc:descriptor_table_tensorflow_2fcompiler_2fxla_2fstream_5fexecutor_2fdnn_2eproto_deps: error: undefined reference to 'descriptor_table_tensorflow_2ftsl_2fprotobuf_2fdnn_2eproto'
collect2: error: ld returned 1 exit status
Target //tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test failed to build
INFO: Elapsed time: 33.177s, Critical Path: 32.38s
INFO: 3 processes: 2 internal, 1 local.
FAILED: Build did NOT complete successfully
//tensorflow/compiler/xla/tools:interactive_graphviz_build_only_test FAILED TO BUILD

FAILED: Build did NOT complete successfully
```
</details>"
58764,TFLite Model Maker changes the order of the outputs for object detection,"### 1. System information

- Linux Ubuntu 18.04 as Windows subsystem for linux
- TensorFlow installation (pip package or built from source): 2.8.0
- TensorFlow Lite Model maker(0.4.2) installation: Installed all the requirements from [Github repo](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/requirements.txt), plus from [prerequisites ](https://www.tensorflow.org/lite/models/modify/model_maker/object_detection#install_the_required_packages)of object detection example

### 2. Code
As described in [example](https://www.tensorflow.org/lite/models/modify/model_maker/object_detection)

### 3. Changes the output order of object detection model.
As per the tflite model maker, the model generated by tflite model maker can be directly used in Task Library.  As per [Model compatibility requirements](https://www.tensorflow.org/lite/inference_with_metadata/task_library/object_detector#model_compatibility_requirements), out put order is already defined. But in tflite model maker case, it changes the output order, in general it should be  location, classes, scores and number of detection, but here it is, score, location, number of detection, classes. Here is the output of generated tflite model meta data from tflite model maker.
``` JSON
{
  ""name"": ""ObjectDetector"",
  ""description"": ""Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream."",
  ""subgraph_metadata"": [
    {
      ""input_tensor_metadata"": [
        {
          ""name"": ""image"",
          ""description"": ""Input image to be detected."",
          ""content"": {
            ""content_properties_type"": ""ImageProperties"",
            ""content_properties"": {
              ""color_space"": ""RGB""
            }
          },
          ""process_units"": [
            {
              ""options_type"": ""NormalizationOptions"",
              ""options"": {
                ""mean"": [
                  127.0
                ],
                ""std"": [
                  128.0
                ]
              }
            }
          ],
          ""stats"": {
            ""max"": [
              255.0
            ],
            ""min"": [
              0.0
            ]
          }
        }
      ],
      ""output_tensor_metadata"": [
        {
          ""name"": ""score"",
          ""description"": ""The scores of the detected boxes."",
          ""content"": {
            ""content_properties_type"": ""FeatureProperties"",
            ""content_properties"": {
            },
            ""range"": {
              ""min"": 2,
              ""max"": 2
            }
          },
          ""stats"": {
          }
        },
        {
          ""name"": ""location"",
          ""description"": ""The locations of the detected boxes."",
          ""content"": {
            ""content_properties_type"": ""BoundingBoxProperties"",
            ""content_properties"": {
              ""index"": [
                1,
                0,
                3,
                2
              ],
              ""type"": ""BOUNDARIES""
            },
            ""range"": {
              ""min"": 2,
              ""max"": 2
            }
          },
          ""stats"": {
          }
        },
        {
          ""name"": ""number of detections"",
          ""description"": ""The number of the detected boxes."",
          ""content"": {
            ""content_properties_type"": ""FeatureProperties"",
            ""content_properties"": {
            }
          },
          ""stats"": {
          }
        },
        {
          ""name"": ""category"",
          ""description"": ""The categories of the detected boxes."",
          ""content"": {
            ""content_properties_type"": ""FeatureProperties"",
            ""content_properties"": {
            },
            ""range"": {
              ""min"": 2,
              ""max"": 2
            }
          },
          ""stats"": {
          },
          ""associated_files"": [
            {
              ""name"": ""labelmap.txt"",
              ""description"": ""Labels for categories that the model can recognize."",
              ""type"": ""TENSOR_VALUE_LABELS""
            }
          ]
        }
      ],
      ""output_tensor_groups"": [
        {
          ""name"": ""detection_result"",
          ""tensor_names"": [
            ""location"",
            ""category"",
            ""score""
          ]
        }
      ]
    }
  ],
  ""min_parser_version"": ""1.2.0""
}

```

How we can fix the issue with changed output order by TFLite Model Maker.
"
58762,"To use the argument `sampling_rate`, you should install tensorflow_io. You can install it via `pip install tensorflow-io`","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu

### Mobile device

22.04

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
i installed tensorflow-io, but i see this error again:

ImportError: To use the argument `sampling_rate`, you should install tensorflow_io. You can install it via `pip install tensorflow-io`.
```
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras.utils import audio_dataset_from_directory

dataset = audio_dataset_from_directory(
    ""dataset"",
    labels=""inferred"",
    label_mode=""categorical"",
    class_names=None,
    batch_size=1,
    sampling_rate=16000,
    output_sequence_length=100,
    ragged=False,
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    follow_links=False,
)
```
```


### Relevant log output

```shell
File ~/.local/lib/python3.10/site-packages/keras/utils/audio_dataset.py:172, in audio_dataset_from_directory(directory, labels, label_mode, class_names, batch_size, sampling_rate, output_sequence_length, ragged, shuffle, seed, validation_split, subset, follow_links)
    166         raise ValueError(
    167             ""`sampling_rate` should be higher than 0. ""
    168             f""Received: sampling_rate={sampling_rate}""
    169         )
...
    176         )
    178 if labels is None or label_mode is None:
    179     labels = None

ImportError: To use the argument `sampling_rate`, you should install tensorflow_io. You can install it via `pip install tensorflow-io`.
```
</details>"
58761,Legalization TFL.Call_Once to TOSA Insert Pattern Failure,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

N/A

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Trying to legalize `TFL.Call_Once` to TOSA. When inserting the pattern in the bottom, it's throwing the following the following errors in log output.
```


### Standalone code to reproduce the issue

```shell
In building the source.
```


### Relevant log output

</details>"
58760,How to convert model with multiple input?,"### 1. System information

- OS Platform and Distribution (e.g., window 10):
- TensorFlow installation (pip package):
- TensorFlow library (tensorflow 2.9.1):

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

I'm use code as below, what should I change to make convertion success? 
```
import numpy as np
import tensorflow as tf
from tensorflow import keras

# how to write ""representative_dataset_gen"" function?
def representative_dataset_gen():
    for _ in range(20):
        data1 = np.random.rand(1, 3, 16, 16).astype(np.float32)
        data2 = np.random.rand(1, 3, 16, 16).astype(np.float32)
        yield [data1, data2]

# build model
kinput1 = keras.Input(shape=(16, 16, 3), batch_size=1, name=""input_1"")
kinput2 = keras.Input(shape=(16, 16, 3), batch_size=1, name=""input_2"")
conv1 = keras.layers.Conv2D(16, 3, 2)(kinput1)
conv2 = keras.layers.Conv2D(16, 3, 2)(kinput2)
out = conv1 + conv2

keras_model = keras.Model(inputs=[kinput1, kinput2], outputs=out)
keras_model.trainable = False
keras_model.summary()

# convert
converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8  # or tf.int8
converter.inference_output_type = tf.uint8  # or tf.int8
converter.representative_dataset = representative_dataset_gen
tflite_model = converter.convert()
with open(""./model.tflite"", ""wb"") as fp:
    fp.write(tflite_model)
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

error info:
```
ValueError: The inference_input_type and inference_output_type must be tf.float32.
```
"
58758,AvgPool3D throws if filter size is larger than input size,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

MacBook Pro 2019

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
For `AvgPool3D`, if filter size is larger than the tensor size, an error was thrown. Take my code below for example, should `y` be returned with a shape `[1,1,1,0,1]`?
```


### Standalone code to reproduce the issue

```shell
x = tf.ones([1,1,1,1,1],float)
y = tf.raw_ops.AvgPool3D(input=a, ksize=[1,1,1,3,1],strides=[1,1,1,1,1], padding='VALID')
```


### Relevant log output

```shell
2022-12-01 13:27:33.388230: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at pooling_ops_3d.cc:188 : INVALID_ARGUMENT: Computed output size would be negative: -1 [input_size: 1, effective_filter_size: 3, stride: 1]
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/linchan/miniconda3/lib/python3.9/site-packages/tensorflow/python/util/tf_export.py"", line 412, in wrapper
    return f(**kwargs)
  File ""/Users/linchan/miniconda3/lib/python3.9/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 342, in avg_pool3d
    _ops.raise_from_not_ok_status(e, name)
  File ""/Users/linchan/miniconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py"", line 7215, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__AvgPool3D_device_/job:localhost/replica:0/task:0/device:CPU:0}} Computed output size would be negative: -1 [input_size: 1, effective_filter_size: 3, stride: 1] [Op:AvgPool3D]
```
```
</details>"
58757,"Re-creation of old environment with TF 1.0.1 leads to ""No module named _pywrap_tensorflow"" issue","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

1.0.1

### Custom Code

No

### OS Platform and Distribution

Windows 10 , 64-bit

### Mobile device

_No response_

### Python version

2.7.18

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

8.0.61 / 5.1

### GPU model and memory

RTX A 2000 (Laptop GPU) ; 4GB

### Current Behaviour?


Basically I try to re-create an old environment to re-use a scientific publication (https://github.com/okraus/DeepLoc).
I install CUDA 8 and CUDNN 5.1 according to various step-by-step tutorials (primarily https://shawnhymel.com/1961/how-to-install-tensorflow-with-gpu-support-on-windows/#Install_cuDNN).
(I keep the current up to date graphics card driver.)
I then install `tensorflow_gpu-1.0.1-py2-none-any.whl` which I found somewhere in the depths of the net after some research.
Unfortunately even the simple `import tensorflow` will give the error message below.
I have been through various github/stackoverflow issues/threads and cannot find the solution to this.
(relevant) System variables:
```
CUDA_PATH_V8_0 = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0 (just to be safe)
PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\bin ; C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\libnvvp
```

Regarding the `MSVCP140.DLL` suggestion:
```
(DeepLoc) C:\Users\Jens>where MSVCP140.DLL
C:\Windows\System32\msvcp140.dll
C:\Program Files\HDF_Group\HDF5\1.8.22\bin\msvcp140.dll
C:\ProgramData\Anaconda3\msvcp140.dll
C:\Program Files\Java\jdk-19\bin\msvcp140.dll
```
And I have the `Microsof Visual C++ 2015-2022 Redistributable (x64) - 14.32.31326`, which is the reason - I assume - that I cannot install the Redistributable referenced here https://github.com/tensorflow/tensorflow/issues/8385#issuecomment-286621655

I have no more sensible ideas to try out.
Even though this is one of your first versions and I understand this is not a top priority I would still greatly appreciate any kind of help!

Best,

Jens
```


### Standalone code to reproduce the issue

python
import tensorflow
```


### Relevant log output

```shell
(DeepLoc) C:\Users\Jens>python
Python 2.7.18 |Anaconda, Inc.| (default, Apr 23 2020, 17:26:54) [MSC v.1500 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import os
>>> print(os.environ.get('CUDA_PATH'))
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0
>>> import tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named tf
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Jens\.conda\envs\DeepLoc\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Jens\.conda\envs\DeepLoc\lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Jens\.conda\envs\DeepLoc\lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Jens\.conda\envs\DeepLoc\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\Jens\.conda\envs\DeepLoc\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ImportError: No module named _pywrap_tensorflow


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error
```
</details>"
58752,Enabling tf.function(jit_compile=True) causes inconsistent results,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.9.1

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.8.8


### CUDA/cuDNN version

CUDA 11.4

### Current Behaviour?

```shell
Executing the following code snippet with and without tf.function produces inconsistent results.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

def main_jit():
  class my_mod(tf.Module):
    def __init__(self,name=None):
      super().__init__(name=name)
    @tf.function(jit_compile=True)
    def __call__(self):
      Input_0 = tf.random.stateless_uniform([2,],seed=(1, 2) ,minval=-5, maxval=5, dtype=tf.float64)
      cosh3 = tf.math.cosh(Input_0)
      cosh6 = tf.math.cosh(cosh3)
      tan11 = tf.math.tan(cosh6)
      return tan11
  mod = my_mod()
  res = mod()
  return res

def main():
  class my_mod(tf.Module):
    def __init__(self,name=None):
      super().__init__(name=name)
    def __call__(self):
      Input_0 = tf.random.stateless_uniform([2,],seed=(1, 2) ,minval=-5, maxval=5, dtype=tf.float64)
      cosh3 = tf.math.cosh(Input_0)
      cosh6 = tf.math.cosh(cosh3)
      tan11 = tf.math.tan(cosh6)
      return tan11
  mod = my_mod()
  res = mod()
  return res

res_jit = main_jit()
res = main()

np_res = np.allclose(res_jit.numpy(),res.numpy(),rtol=1e-1, atol=1e-3, equal_nan=True)
print(res_jit.numpy()-res.numpy())
print(np_res)
```

"
58751,Error in inference when the model is exported with ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tensorflow-inference-2.10.0

### Custom Code

No

### OS Platform and Distribution

ubuntu20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.1/8.1.0.77-1

### GPU model and memory

Tesla T4

### Current Behaviour?

```shell
The model is exported like this:

MAX_SEQ_LENGTH=128
class ExportModel(tf.Module):
  def __init__(self, classifier):
    self.classifier = classifier

  @tf.function(input_signature=[{
      'input_word_ids': tf.TensorSpec(shape=[None, MAX_SEQ_LENGTH], dtype=tf.int32, name='input_word_ids'),
      'input_mask': tf.TensorSpec(shape=[None, MAX_SEQ_LENGTH], dtype=tf.int32, name='input_mask'),
      'input_type_ids': tf.TensorSpec(shape=[None, MAX_SEQ_LENGTH], dtype=tf.int32, name='input_type_ids')}]
               ,jit_compile=True
              )
  def __call__(self, inputs):
    logits =  self.classifier(inputs, training=False)
    probs = tf.nn.softmax(logits)[:,1]
    return {
        'predictions': probs
    }

On my notebook I get around 30% decrease in response time, but on a Sagemaker Endpoint with tensorflow-inference: 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.10.0-cpu-py39-ubuntu20.04-sagemaker, I get this error:
external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at xla_ops.cc:296 : UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- was support for that platform linked in?
```


### Standalone code to reproduce the issue

```shell
1- Export any model with jit_compile=True
2- Use this image 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.10.0-cpu-py39-ubuntu20.04-sagemaker for load and inference
```


### Relevant log output

```shell
external/org_tensorflow/tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at xla_ops.cc:296 : UNIMPLEMENTED: Could not find compiler for platform CUDA: NOT_FOUND: could not find registered compiler for platform CUDA -- was support for that platform linked in?
```
</details>"
58750,The same problem exists with tf.scatter_nd.,"        The same problem exists with tf.scatter_nd.

CPU test：

    import tensorflow as tf
    with tf.device('/CPU'):
        indices = tf.random.uniform([35, 2], minval=-256, maxval=257, dtype=tf.int64)
        updates = tf.random.uniform([35, 768], dtype=tf.float32)
        shape = [1, 35, 768]
        out = tf.scatter_nd(indices, updates, shape)
    print(out)

GPU test：

    import tensorflow as tf
    with tf.device('/GPU:0'):
        indices = tf.random.uniform([35, 2], minval=-256, maxval=257, dtype=tf.int64)
        updates = tf.random.uniform([35, 768], dtype=tf.float32)
        shape = [1, 35, 768]
        out = tf.scatter_nd(indices, updates, shape)
    print(out)

_Originally posted by @triumph-wangyuyang in https://github.com/tensorflow/tensorflow/issues/58748#issuecomment-1333523656_
      "
58749,The results of tf.image.convert_image_dtype running on CPU and GPU are very different.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.11

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.2    cuDNN 8.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The results of tf.image.convert_image_dtype running on CPU and GPU are very different.
```


### Standalone code to reproduce the issue

```shell
CPU code:

    import tensorflow as tf
    with tf.device('/CPU'):
        arg_0 = [[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], [[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]]
        out = tf.image.convert_image_dtype(arg_0, dtype=tf.uint32, saturate=-1)
    print(out)

GPU code:

    import tensorflow as tf
    with tf.device('/GPU:0'):
        arg_0 = [[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], [[7.0, 8.0, 9.0], [10.0, 11.0, 12.0]]]
        out = tf.image.convert_image_dtype(arg_0, dtype=tf.uint32, saturate=-1)
    print(out)
```


### Relevant log output

```shell
CPU result: tf.Tensor(
[[[0 0 0]
  [0 0 0]]

 [[0 0 0]
  [0 0 0]]], shape=(2, 2, 3), dtype=uint32)


GPU result: tf.Tensor(
[[[2147483647 2147483647 2147483647]
  [2147483647 2147483647 2147483647]]

 [[2147483647 2147483647 2147483647]
  [2147483647 2147483647 2147483647]]], shape=(2, 2, 3), dtype=uint32)
```
</details>"
58748,tf.tensor_scatter_nd_updat has different performance on CPU and GPU.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.4

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.2    cuDNN 8.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.tensor_scatter_nd_updat has different performance on CPU and GPU.
```


### Standalone code to reproduce the issue

```shell
CPU code:
  import tensorflow as tf
  with tf.device('/CPU'):
    tensor = tf.random.uniform([1, 2, 3], dtype=tf.float32)
    indices = tf.random.uniform([3, 2], minval=-256, maxval=257, dtype=tf.int64)
    updates = tf.random.uniform([3, 3], dtype=tf.float32)
    out = tf.tensor_scatter_nd_update(tensor, indices, updates)
  print(out)


GPU code:
  import tensorflow as tf
  with tf.device('/GPU:0'):
    tensor = tf.random.uniform([1, 2, 3], dtype=tf.float32)
    indices = tf.random.uniform([3, 2], minval=-256, maxval=257, dtype=tf.int64)
    updates = tf.random.uniform([3, 3], dtype=tf.float32)
    out = tf.tensor_scatter_nd_update(tensor, indices, updates)
  print(out)
```


### Relevant log output

```shell
CPU result: InvalidArgumentError: {{function_node __wrapped__TensorScatterUpdate_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = [-229, -237] does not index into shape [1,2,3] [Op:TensorScatterUpdate]


GPU result: tf.Tensor(
[[[0.88412964 0.6187128  0.3900485 ]
  [0.69401896 0.9752933  0.5505158 ]]], shape=(1, 2, 3), dtype=float32)
```
</details>"
58747,tf.numpy_function in tf.data.Dataset.map causes CUDA_ERROR_OUT_OF_MEMORY after hundreds of epochs,"### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

5.3.2

### GCC/Compiler version

gcc 9.3.0

### CUDA/cuDNN version

11.8/8.6.0

### GPU model and memory

Nvidia Quadro RTX 6000, 25.8G memory

### Current Behaviour?

```shell
I use `tf.data.Dataset` for my input pipeline as follows:
  1. `from_generator`
  2. `cache`
  3. `shuffle`
  4. `repeat`
  5. `map`
  6. `batch`
  7. `prefetch`

The step 5 call a data-augmentation function where there is a call to `tf.numpy_function` which wraps `scipy.ndimage.rotate`.

After a variable number of epochs (in general more than 100), a `CUDA_OUT_OF_MEMORY` appears and the kernel crashed. If I remove the call to `tf.numpy_function` from the data-augmentation function, I don't have this problem. Note that I don't use `tf.py_function` as it looks much slower.
```


### Standalone code to reproduce the issue

```shell
I haven't managed to create a simple reproducer for this bug.
```


### Relevant log output

```shell
2022-12-01 02:26:32.244730: E tensorflow/stream_executor/cuda/cuda_driver.cc:796] failed to alloc 17179869184 bytes on host: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2022-12-01 02:26:32.299769: W ./tensorflow/core/common_runtime/device/device_host_allocator.h:46] could not allocate pinned host memory of size: 17179869184
```
"
58746,TF-lite model with a Conv2DTranspose layer is fail to run on mobile gpu.,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
  - Conversion env: Centos7
  - Test env: Galaxy S10 `(samsung/beyond1lteks/beyond1:10/QP1A.190711.020/G973NKSU4CTE9:user/release-keys)`
- TensorFlow installation (pip package or built from source): pip install
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:
```
def get_model():
    inputs = tf.keras.Input(shape=(64, 64, 3))
    x = keras.layers.Conv2D(16, 3, activation=""relu"", name=""conv1"")(inputs)
    x = keras.layers.Conv2D(16, 3, activation=""relu"", name=""conv2"")(x)
    x = keras.layers.Conv2DTranspose(16, 3, strides=2, activation=""relu"", name=""deconv1"")(x)
    x = keras.layers.Conv2DTranspose(16, 3, strides=2, activation=""relu"", name=""deconv2"")(x)
    outputs = x
    
    model = keras.Model(inputs=inputs, outputs=outputs, name=""custom"")

    x = tf.ones((5, 64, 64, 3))
    y = model(x)

    print(x.shape)
    print(y.shape)
    
    return model

def convert_model(saved_model_dir, tflite_save_dir):
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float32]
    tflite_model = converter.convert()

    with open(tflite_save_dir, ""wb"") as f:
        f.write(tflite_model)

if __name__==""__main__"":
    model = get_model()

    current_path = os.path.dirname(os.path.realpath(__file__))
    save_dir = os.path.join(current_path, ""custom/1/"")
    tf.saved_model.save(model, save_dir)

    tflite_save_dir = os.path.join(current_path, ""my_model.tflite"")
    convert_model(save_dir, tflite_save_dir)
    test_tflite(tflite_save_dir)
```

### 3. Failure after conversion
TF Lite conversion and run on the mobile phone with cpu is OK, but when running with gpu, an error occurs. (I tested the model in adb shell)
![image](https://user-images.githubusercontent.com/33739495/205008146-3abb7c7e-9fea-4361-88cb-a110b6ca1aaa.png)"
58745,tflite build for armhf crashes in 2.10 and 2.11,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04.4 LTS
-   **TensorFlow installed from (source or binary)**: From Source
-   **TensorFlow version (use command below)**: 2.11 and 2.10
-   **Python version**: 3.9.12
-   **Bazel version (if compiling from source)**:5.3.0 (for TF 2.11) and 5.1.1 (for TF 2.10)
-   **GCC/Compiler version (if compiling from source)**:arm-linux-gnueabihf-gcc 8.3.0
-   **CUDA/cuDNN version**: not applicable
-   **GPU model and memory**:not applicable
-   **Exact command to reproduce**:bazel  build --config=elinux_armhf -c opt //tensorflow/lite:libtensorflowlite.so

### Describe the problem
During compilation of tflite, the XNNPACK build fails with *error: unknown type name 'int8x4_t'* and more of similar errors.
*-mfp16-format=ieee* is included in the compile command. This happens with tensorflow 2.10 and 2.11.
The compiler call issued by bazel is:
/home/user/.cache/bazel/_bazel_user/4e14a0b2593db001fc575b67dfb5d02a/external/armhf_linux_toolchain/bin/arm-linux-gnueabihf-gcc -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/armhf-opt/bin/external/XNNPACK/_objs/armsimd32_prod_microkernels/0/1x2c4-minmax-fp32-armsimd32.pic.d '-frandom-seed=bazel-out/armhf-opt/bin/external/XNNPACK/_objs/armsimd32_prod_microkernels/0/1x2c4-minmax-fp32-armsimd32.pic.o' -fPIC -iquote external/XNNPACK -iquote bazel-out/armhf-opt/bin/external/XNNPACK -isystem external/XNNPACK/include -isystem bazel-out/armhf-opt/bin/external/XNNPACK/include -isystem external/XNNPACK/src -isystem bazel-out/armhf-opt/bin/external/XNNPACK/src -Wno-all -Wno-extra -Wno-deprecated -Wno-deprecated-declarations -Wno-ignored-attributes -Wno-unknown-warning -Wno-array-parameter -Wno-stringop-overflow -Wno-array-bounds -Wunused-result '-Werror=unused-result' -DAUTOLOAD_DYNAMIC_KERNELS '-mfp16-format=ieee' -Iinclude -Isrc -marm '-march=armv6' '-mfpu=vfp' -munaligned-access '-std=c99' -fno-fast-math -fno-math-errno -O2 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c external/XNNPACK/src/qc8-gemm/gen/1x2c4-minmax-fp32-armsimd32.c -o bazel-out/armhf-opt/bin/external/XNNPACK/_objs/armsimd32_prod_microkernels/0/1x2c4-minmax-fp32-armsimd32.pic.o
"
58741,Tensorflow Lite Benchmark tool possible error when specifing input_layer_value_files,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9

### Custom Code

No

### OS Platform and Distribution

linux

### Mobile device

android

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


I would like to use benchmark tool, to see the results of inference. So there is an option to specify `input_layer_value_files` and `output_filepath`. When there is one input, it is easy. Problems are, when there are multiple inputs, and you cannot fully control input names, e.g. you need to escape. I think I escaped names, but I'm getting error:

```
Wrong input value file item specified: serving_default_input0\:0:/data/local/tmp/benchmarkomat/tflite/inferences/input__serving_default_input0__0_KYO5LZFG6A.bin
```

my command:

```
/data/local/tmp/tflite/execs/tflite_benchmark --graph=/data/local/tmp/tflite/models/5IZY3TP8V6_model.tflite --input_layer_value_files='serving_default_input0\:0':'/data/local/tmp/tflite/inferences/input__serving_default_input0__0_KYO5LZFG6A.bin','serving_default_input1\:0':'/data/local/tmp/tflite/inferences/input__serving_default_input1__0_KYO5LZFG6A.bin','serving_default_input2\:0':'/data/local/tmp/tflite/inferences/input__serving_default_input2__0_KYO5LZFG6A.bin' --output_filepath=/data/local/tmp/tflite/inferences/output__KYO5LZFG6A.bin
```

Similar problem, when I'm not using single quotes around key and value:
```shell
/data/local/tmp/tflite/execs/tflite_benchmark --graph=/data/local/tmp/tflite/models/3LMD92WLNY_model.tflite --input_layer_value_files=serving_default_input0\:0:/data/local/tmp/tflite/inferences/input__serving_default_input0__0_C3FB3DNGK8.bin,serving_default_input1\:0:/data/local/tmp/tflite/inferences/input__serving_default_input1__0_C3FB3DNGK8.bin,serving_default_input2\:0:/data/local/tmp/tflite/inferences/input__serving_default_input2__0_C3FB3DNGK8.bin --output_filepath=/data/local/tmp/tflite/inferences/output__C3FB3DNGK8.bin --use_xnnpack=false --use_nnapi=false --use_gpu=false --use_hexagon=false --gpu_precision_loss_allowed=true
```


### Standalone code to reproduce the issue

```shell
Code to create simple model:

import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers

print(tf.__version__)
input0 = keras.Input(shape=(64,), name=""input0"") 
input1 = keras.Input(shape=(16,), name=""input1"")
input2 = keras.Input(shape=(16,), name=""input2"")

layer0 = layers.Dense(3, activation=""relu"", name=""layer0"")(input0)
layer1 = layers.Dense(5, activation=""relu"", name=""layer1"")(input1)
layer2 = layers.Dense(7, activation=""relu"", name=""layer2"")(input2)

x0 = layers.concatenate([layer0, layer1, layer2])
x1 = layers.concatenate([layer0, layer1, layer2])

x0 = layers.Dense(3, name=""output0"")(x0)
x1 = layers.Dense(7, name=""output1"")(x1)

# Instantiate an end-to-end model predicting both priority and department
model = keras.Model(
    inputs=[input0, input1, input2],
    outputs=[x0, x1],
)
model.compile(optimizer='sgd', loss='mean_squared_error')
model.summary()

converter = tf.lite.TFLiteConverter.from_keras_model(model) # path to the SavedModel directory
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```


### Relevant log output

_No response_</details>"
58740,Tensorflow >=2.10 windows - model.load_weights file handling issue,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10 and 2.11

### Custom Code

No

### OS Platform and Distribution

Windows Server 2019

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

After loading a model with `model.load_weights` something is off with the directory that the weights were loaded from:
1. Savings weights to that directory again fails
2. Removing that directory fails as well

Edit: This does not happen on Linux. However, on windows systems, our CI crashes with the provided errors when fine tuning models or when temporary directories are cleaned up after loading models from them. The provided snippets represent minimal examples of what I was able to trace down would lead to crashes on windows.

### Standalone code to reproduce the issue
#### test code 1 (saving weights again)
```python

import tensorflow as tf
from pathlib import Path

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

tf_model_file = Path(""model"") / ""my_model.tf_model""

model.save_weights(tf_model_file, overwrite=True, save_format=""tf"")

model.load_weights(tf_model_file)
model.save_weights(tf_model_file, overwrite=True, save_format=""tf"")

```

#### test code 2 (removing directory)
```python

import tensorflow as tf
from pathlib import Path
import shutil

inputs = tf.keras.Input(shape=(3,))
x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)
outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

tf_model_file = Path(""model"") / ""my_model.tf_model""

model.save_weights(tf_model_file, overwrite=True, save_format=""tf"")

model.load_weights(tf_model_file)

shutil.rmtree(""model"")
```


### Relevant log output
#### Output for test 1
```shell
2022-11-30 09:18:57.932686: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-30 09:18:58.186560: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at save_restore_v2_ops.cc:286 : UNKNOWN: Failed to rename: model\my_model.tf_model_temp/part-00000-of-00001.data-00000-of-00001 to: model\my_model.tf_model.data-00000-of-00001 : Cannot create a file when that file already exists.
; Unknown error
Traceback (most recent call last):
  File ""C:\Users\thomas\Desktop\model-test\model-test.py"", line 14, in <module>
    model.save_weights(tf_model_file, overwrite=True, save_format=""tf"")
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\keras\engine\training.py"", line 2917, in save_weights
    self._checkpoint.write(filepath, options=options)
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\checkpoint.py"", line 2287, in write
    return self._write(file_prefix, options)
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\checkpoint.py"", line 2305, in _write
    output = self._saver.save(
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\checkpoint.py"", line 1351, in save
    save_path, new_feed_additions = self._save_cached_when_graph_building(
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\checkpoint.py"", line 1294, in _save_cached_when_graph_building
    return _run_save()
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\checkpoint.py"", line 1246, in _run_save
    save_op = saver.save(file_prefix, options=options)
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\functional_saver.py"", line 407, in save
    return save_fn()
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\checkpoint\functional_saver.py"", line 393, in save_fn
    return gen_io_ops.merge_v2_checkpoints(
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 547, in merge_v2_checkpoints
    return merge_v2_checkpoints_eager_fallback(
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\ops\gen_io_ops.py"", line 582, in merge_v2_checkpoints_eager_fallback
    _result = _execute.execute(b""MergeV2Checkpoints"", 0, inputs=_inputs_flat,
  File ""C:\Users\thomas\AppData\Local\pypoetry\Cache\virtualenvs\rasa-_GmHtu1y-py3.9\lib\site-packages\tensorflow\python\eager\execute.py"", line 52, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError: {{function_node __wrapped__MergeV2Checkpoints_device_/job:localhost/replica:0/task:0/device:CPU:0}} Failed to rename: model\my_model.tf_model_temp/part-00000-of-00001.data-00000-of-00001 to: model\my_model.tf_model.data-00000-of-00001 : Cannot create a file when that file already exists.

```
#### Output of error 2
```shell
2022-11-30 09:20:47.815422: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Traceback (most recent call last):
  File ""C:\Users\thomas\Desktop\model-test\model-delete-test.py"", line 16, in <module>
    shutil.rmtree(""model"")
  File ""C:\Users\thomas\AppData\Local\Programs\Python\Python39\lib\shutil.py"", line 759, in rmtree
    return _rmtree_unsafe(path, onerror)
  File ""C:\Users\thomas\AppData\Local\Programs\Python\Python39\lib\shutil.py"", line 633, in _rmtree_unsafe
    onerror(os.rmdir, path, sys.exc_info())
  File ""C:\Users\thomas\AppData\Local\Programs\Python\Python39\lib\shutil.py"", line 631, in _rmtree_unsafe
    os.rmdir(path)
OSError: [WinError 145] The directory is not empty: 'model'
```
</details>"
58739,The input type of the tf.math.sqrt operator parameters does not match the exception information.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.4

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.2    cuDNN 8.1

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
In the official document, the input types of tf.math.sqrt operator parameters are bfloat16, half, float32, float64.. It can be seen that the above does not contain complex64 or complex128 types, but in the following test code, the exception thrown In the information, you can see that the input can be of type complex64 or complex128. It is hoped that the documentation can be modified or the exception information can be modified.
```


### Standalone code to reproduce the issue

```shell
    import tensorflow as tf

    input = ""True""
    out = tf.math.sqrt(input)
    print(out)
```


### Relevant log output

```shell
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of string is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128
	; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]
```
</details>"
58738,tf2.11 tf.profiler.experimental  doesn't generate trace.json.gz and other files compared with tf2.10,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.11

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

Linux Ubuntu 20.04

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In tf2.10, when use the tf.profiler.experimental.start(logdir) and tf.profiler.experimental.stop(). It will generate many files as bellow in logdir folder.
.
├── events.out.tfevents.XXXX.profile-empty
└── plugins
    └── profile
        └── 2022_11_29_08_25_43
            ├── XXXX.input_pipeline.pb
            ├── XXXX.kernel_stats.pb
            ├── XXXX.memory_profile.json.gz
            ├── XXXX.overview_page.pb
            ├── XXXX.tensorflow_stats.pb
            ├── XXXX.trace.json
            └── XXXX.xplane.pb

But in tf2.11, it only generate these files.
.
├── events.out.tfevents.XXXX.profile-empty
└── plugins
    └── profile
        ├── 2022_11_29_08_32_10
        │   └── XXXX.xplane.pb

I think the tf2.11 outputs files should be the same as the tf2.10. 
Is this a bug? If not, can you tell me an alternative solution to get them in tf2.11?
```


### Standalone code to reproduce the issue

```shell
import random
import tensorflow as tf
options = tf.profiler.experimental.ProfilerOptions(host_tracer_level = 3,
                                                   python_tracer_level = 1,
                                                   device_tracer_level = 1)
tf.profiler.experimental.start(""logdir_simple_tf211(1)"", options=options)

"""""" Simple training model """"""
def Y(a, x):
    return a*(x**2 + 4)

"""""" Target model """"""
def Z(a):
    return a*(4**2 + 4)

lr = 0.01
x = tf.Variable(1.1,name = 'var')
optimizer = tf.keras.optimizers.Adam(lr=0.01)

for _ in range(10000):
    input = random.randint(1,255)
    target = Z(input)
    with tf.GradientTape() as tape:
        pre = Y(input, x)
        loss = abs(pre - target)

    gradient = tape.gradient(loss,x)
    optimizer.apply_gradients([(gradient, x)])

    if _ % 100 == 0:
        print(""loss:"", loss.numpy())
        
print(""x: "", x.numpy())
tf.profiler.experimental.stop(save=True)
```


### Relevant log output

_No response_</details>"
58737,tf.keras.losses.mean_absolute_error exception information is misleading.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.4

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.2    cuDNN 8.1

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
The exceptions thrown by tf.keras.losses.mean_absolute_error(y_true, y_pred)are different when running the following two test codes.
   In code1, I set y_pred to bool, and the exception message prompts me that bool is not in the legal type (bfloat16, half, float, double, uint8, int8, uint16, int16, int32, int64, complex64, complex128, uint32) (Remember that it includes uint16、complex64, complex128, which will be useful later).
   In code2, I set y_pred to uint16, and the exception information reminded me that uint16 is not in the legal type (bfloat16, half, float, double, int8, int16, int32, int64). It is obvious that the exception information before and after is contradictory.
```


### Standalone code to reproduce the issue

```shell
code 1:

    import tensorflow as tf

    y_true = tf.random.uniform([2, 3], minval=-5, maxval=5, dtype=tf.int32)
    y_pred = tf.cast(tf.random.uniform([2, 3], minval=-5, maxval=5, dtype=tf.int32), dtype=tf.bool)
    out = tf.keras.losses.mean_absolute_error(y_true, y_pred)

code 2:

    import tensorflow as tf

    y_true = tf.random.uniform([2, 3], minval=-5, maxval=5, dtype=tf.int32)
    y_pred = tf.cast(tf.random.uniform([2, 3], minval=-5, maxval=5, dtype=tf.int32), dtype=tf.uint16)
    out = tf.keras.losses.mean_absolute_error(y_true, y_pred)

```


### Relevant log output

```shell
code1 result : tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of bool is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, int64, complex64, complex128, uint32; NodeDef: {{node Sub}}; Op<name=Sub; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128, DT_UINT32]> [Op:Sub]



code2 result : tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of uint16 is not in the list of allowed values: bfloat16, half, float, double, int8, int16, int32, int64; NodeDef: {{node Abs}}; Op<name=Abs; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_INT8, DT_INT16, DT_INT32, DT_INT64]> [Op:Abs]

```
</details>"
58732,Expecting the same names when converting to tflite model,"Hello,

I have created very simple model, and I want to export it to tflite model, to benchmark it on android device, and run simple inferences. This is code to create model:
```python
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers

input0 = keras.Input(shape=(64,), name=""input0"") 
input1 = keras.Input(shape=(16,), name=""input1"")
input2 = keras.Input(shape=(16,), name=""input2"")

layer0 = layers.Dense(3, activation=""relu"", name=""layer0"")(input0)
layer1 = layers.Dense(5, activation=""relu"", name=""layer1"")(input1)
layer2 = layers.Dense(7, activation=""relu"", name=""layer2"")(input2)

x0 = layers.concatenate([layer0, layer1, layer2])
x1 = layers.concatenate([layer0, layer1, layer2])

output0 = layers.Dense(3, name=""output0"")(x0)
output1 = layers.Dense(7, name=""output1"")(x1)

model = keras.Model(
    inputs=[input0, input1, input2],
    outputs=[output0, output1],
)
model.compile(optimizer='sgd', loss='mean_squared_error')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)
```
environment: google colab

I expect, that tflite model would have `input0`, `input1`, `input2` input names, and `output0` , `output1` output names. But...
Real names are: `serving_default_input0:0`, `serving_default_input1:0`, `serving_default_input2:0`, `StatefulPartitionedCall:0`, `StatefulPartitionedCall:1`"
58731,TF 2.11 fails to compile on Linux with GPU support - Model Loads - Inference Fails,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Debian 11

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.1.1

### GCC/Compiler version

9.3.0

### CUDA/cuDNN version

11.2,8.1

### GPU model and memory

RTX 3060/12G

### Current Behaviour?

```shell
The final compiled wheel is like tensorflow-2.11.0-cp39-cp39-linux_x86_64.whl
whereas it should have a GPU indicator. 
Model loads in GPU, but inference fails with illegal instruction.
```


### Standalone code to reproduce the issue

```shell
build --action_env PYTHON_BIN_PATH=""/home/steve/.virtualenvs/mldev/bin/python3""
build --action_env PYTHON_LIB_PATH=""/home/steve/.virtualenvs/mldev/lib/python3.9/site-packages""
build --python_path=""/home/steve/.virtualenvs/mldev/bin/python3""
build --action_env TF_CUDA_VERSION=""11.2""
build --action_env TF_CUDNN_VERSION=""8.1""
build --action_env TF_NCCL_VERSION=""""
build --action_env TF_CUDA_PATHS=""/usr/local/cuda-11.2,/usr/local/cudnn,/usr/local/cuda-11.2/extras,/usr/local/cuda-11.2/targets/x86_64-linux/lib/,/usr/local/cuda-11.2/targets/x86_64-linux/includ
e,/usr/include/x86_64-linux-gnu/""
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-11.2""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""8.6""
build --action_env LD_LIBRARY_PATH=""/usr/local/cuda-11.2/lib64:/usr/local/cudnn/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cudnn/lib64:""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-9""
build --config=cuda
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-Wno-sign-compare
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
```


### Relevant log output

```shell
2022-11-29 17:29:50.821769: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-29 17:29:50.832486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-29 17:29:50.832736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-29 17:29:51.516556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-29 17:29:51.516808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-29 17:29:51.517025: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-29 17:29:51.517191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9039 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:02:00.0, compute capability: 8.6


2022-11-29 17:01:53.716468: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100
[1]    414085 illegal hardware instruction
```
</details>"
58729,GPU could not be recognized on Windows 11,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

v2.11.0-rc2-15-g6290819256d 2.11.0

### Custom Code

No

### OS Platform and Distribution

Edition: Windows 11 Home ; Version: 22H2; OS build：22621.819; Visual Studio: 2019&2022 with all packages MSVC 2015/2017/2019 v142;

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA Runtime API v11.2 / CUDA Driver API v12.0 / cuDNN 8.1.0

### GPU model and memory

NVIDIA GeForce RTX 3050 Ti Laptop GPU

### Current Behaviour?

```shell
I want to train my model on the GPU to accelerate the process. But it is not working.

I have followed the instruction on [TensorFlow pip Installation page](https://www.tensorflow.org/install/pip)
and [GPU support page](https://www.tensorflow.org/install/gpu)
but the GPU could not be found.
I tried installing tensorflow in (base) environment, in venv environment
I tried uninstalling all the packages of tensorflow, then tried the tensorflow-gpu package.
None of these worked...

I printed these commands to prove the results with the interpreter in every envoriment installed with tensorflow or tensorflow-gpu:

But unfortunately output stays the same, it can not find GPU.

P.S:
I found an [issue report](https://github.com/tensorflow/tensorflow/issues/40683#issuecomment-648152089) on Github here that is similar to my problem later.

Followed this instruction to install tf-nightly-gpu but there is a traceback after the installation.
Seems makes the situation even worse:

AttributeError: module 'tensorflow.compat.v2.__internal__' has no attribute 'register_load_context_function'
```


### Standalone code to reproduce the issue

```shell
-**In CMD:**

C:\Windows\System32>nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020
Cuda compilation tools, release 11.2, V11.2.67
Build cuda_11.2.r11.2/compiler.29373293_0

C:\Windows\System32>nvidia-smi
Tue Nov 29 15:40:36 2022
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 526.98       Driver Version: 526.98       CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |
| N/A   52C    P8     8W /  N/A |    221MiB /  4096MiB |      2%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1068    C+G   ...tudio\Installer\setup.exe    N/A      |
+-----------------------------------------------------------------------------+


- **with Python Scripts:**

tf.config.list_physical_devices('GPU')
>>> []

tf.test.is_built_with_cuda()
>>> False

tf.__version__
>>> 2.11.0

tf.test.gpu_device_name()
>>>
```


### Relevant log output

_No response_</details>"
58728,Tensorflow v2.10.0 incompatible with flatbuffer v2.0.5,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04.5 LTS (Focal Fossa) ARM V8 Processor

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1)

### CUDA/cuDNN version

release 11.4, V11.4.239

### GPU model and memory

5.10.104-tegra

### Current Behaviour?

```shell
As mentioned under Release 2.10.0 of TensorFlow, Upgrade Flatbuffers v2.0.5 from v1.12.0, but flat buffer v2.0.5 is not compatible with TensorFlow 2.10.0. There is a mismatch in one of the functions **VerifyField**. Flatt buffer has defined this function with 2 arguments(usr/local/include/flatbuffers/table.h:115:8:) while TensorFlow is calling this function with 3 arguments( tensorflow/tensorflow/lite/experimental/acceleration/configuration/configuration_generated.h). But this function has been updated in flat buffer version v2.0.6 to 3 arguments. So the TensorFlow release documentation under version v2.10.0 should be updated.
```


### Standalone code to reproduce the issue

```shell
Install flat buffer 2.0.5 using the following steps,
$git clone --depth 1 --branch v2.0.5 https://github.com/google/flatbuffers.git
$cd flatbuffers
$cmake -G ""Unix Makefiles"" -DCMAKE_BUILD_TYPE=Release
$sudo make install
Install TensorFlow using following steps
$git clone https://github.com/tensorflow/tensorflow
$git checkout v2.10.0
Install libedgetpu
$ git clone https://github.com/google-coral/libedgetpu.git
$ git clone https://github.com/abseil/abseil-cpp.git
$ cd abseil-cpp
$ cmake -DABSL_BUILD_TESTING=ON -DABSL_USE_GOOGLETEST_HEAD=ON -DCMAKE_CXX_STANDARD=14 ..
cmake --build . --target all
$cd libedgetpu
$ <TFROOT=path of TensorFlow folder installed in previous step> make -f makefile_build/Makefile -j$(nproc) libedgetpu
```


### Relevant log output

```shell
no matching function for call to ‘platforms::darwinn::Executable::VerifyField<int32_t>(flatbuffers::Verifier&, platforms::darwinn::Executable::FlatBuffersVTableOffset, int) const’
 2309 |            VerifyField<int32_t>(verifier, VT_BATCH_SIZE, 4) &&

local/include/flatbuffers/table.h:115:8: note:candidate: ‘bool flatbuffers::Table::VerifyField(const flatbuffers::Verifier&, flatbuffers::voffset_t) const [with T = int; flatbuffers::voffset_t = short unsigned int]’
  115 |   bool VerifyField(const Verifier &verifier, voffset_t field) const {
```
</details>"
58726,MultiHeadAttention layer bug with attention_mask computation if we pass attention_axes,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11.0 (GIT version: v2.11.0-rc2-17-gd5b57ca93e5)

### Custom Code

Yes

### OS Platform and Distribution

MacOS 13.0.1

### Mobile device

_No response_

### Python version

3.9.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

While using MultiHeadAttention module with attention mask, there seems to issue in computing the mask. The following code snippet fails by throwing the error:
```shell
{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [256,12,2,20,20] vs. [256,12,1,12,20] [Op:AddV2]

Call arguments received by layer 'softmax_16' (type Softmax):
  • inputs=tf.Tensor(shape=(256, 12, 2, 20, 20), dtype=float32)
  • mask=tf.Tensor(shape=(256, 12, 1, 12, 20), dtype=bool)
```
However, the below code works fine when we pass `mask_zero=False` while defining the Embedding layer.

### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
from keras import layers as tfl

class Encoder(tfl.Layer):
    def __init__(self,):
        super().__init__()
        self.embed_layer = tfl.Embedding(4500, 32, mask_zero=True)
        self.attn_layer = tfl.MultiHeadAttention(num_heads=2,
                                                 attention_axes=2,
                                                 key_dim=16)
        return

    def call(self, x):
        # Input shape: (256, 10, 20) (Batch size: 256)
        x = self.embed_layer(x)  # Output: (256, 10, 20, 32)
        x = self.attn_layer(query=x, key=x, value=x)  # Output: (256, 10, 20, 32)
        return x


eg_input = tf.constant(np.random.randint(0, 150, (256, 12, 20)))
enc = Encoder()
enc(eg_input).shape
```


### Relevant log output
```
{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [256,12,2,20,20] vs. [256,12,1,12,20] [Op:AddV2]

Call arguments received by layer 'softmax_16' (type Softmax):
  • inputs=tf.Tensor(shape=(256, 12, 2, 20, 20), dtype=float32)
  • mask=tf.Tensor(shape=(256, 12, 1, 12, 20), dtype=bool)
```
</details>"
58723,Cannot install tensorflow 2.3.0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.3.0

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I cannot, for the life of me, figure out how to install tensorflow 2.3.0. I've downgraded to Python 3.7 and have tried every resource I can. I've upgraded pip, installing via `pip install tensorflow==2.3.0`, and I've even tried downloading the wheels off of the pip site (which gave the explanation that they're not supported on my platform, even though I tried the cp35, cp36, and cp38 windows wheels, which are the only ones I saw).

When running my Python 3.7's pip, I get:
```
pip install tensorflow==2.3.0
ERROR: No matching distribution found for tensorflow==2.3.0
```
As well as:
```
pip install tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow
```
I specifically need 2.3.0 to work properly with keras-rl. Any help would really be appreciated, as I've scoured every resource on the internet that I can possibly find.
```


### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_</details>"
58722,Mac M1 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

macOS Ventura 13.0.01

### Mobile device

_No response_

### Python version

3.10 or up

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Is there a best way to upgrade TensorFlow for Mac Silicon? 

I installed it through miniconda->TensorFlow-metal->tensorflow-Mac

This has worked well but I’m unable to figure out how to upgrade to the newer versions. 

Any thoughts 

I’ve tried 
$ pip3 install —-upgrade <packages> 

Mac doesn’t recognize TensorFlow commands.
```


### Standalone code to reproduce the issue

```shell
Na
```


### Relevant log output

```shell
Na
```
</details>"
58721,How to write to input tensors in custom op?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How can I write to input tensors in a custom op? I can read and write to output tensors but only read on inputs. (compiling outputs ""assignment of read-only location"" error when trying to write to input tensor). I want to write an inplace op, and making it inplace is crucial for my project, as writting the results to an output tensor and then assigning the output to the variable is too slow). Here is a minimal example that just sets the input tensor to zero. What code can I add to this example code so that I can be able to write to the input tensor?
```


### Standalone code to reproduce the issue

```shell
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""tensorflow/core/framework/op_kernel.h""
#include ""tensorflow/core/util/work_sharder.h""

#include <iostream>

using namespace tensorflow;

REGISTER_OP(""Example"")
    .Input(""variable: float"")
    ;

class ExampleOp : public OpKernel {
public:
    
    explicit ExampleOp(OpKernelConstruction* context) : OpKernel(context) {}

    void Compute(OpKernelContext* context) override {

        const Tensor& variable_tensor = context->input(0);
        auto variable = variable_tensor.flat<float>();
        
        for(int i = 0; i < variable.size(); ++i)
            variable(i) = 0; 

    };

};


REGISTER_KERNEL_BUILDER(Name(""Example"").Device(DEVICE_CPU), ExampleOp);
```


### Relevant log output

```shell
minimal.cc: In member function ‘virtual void ExampleOp::Compute(tensorflow::OpKernelContext*)’:
minimal.cc:25:25: error: assignment of read-only location ‘variable.Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer>::operator()(((Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer>::Index)i))’
   25 |             variable(i) = 0;
      |             ~~~~~~~~~~~~^~~
```
</details>"
58716,ImportError: libflatbuffers.so.2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.4

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.04

### Mobile device

Linux Ubuntu 22.04

### Python version

3.9.15

### Bazel version

n/a

### GCC/Compiler version

gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0

### CUDA/cuDNN version

11.7.0 / 8.4.1.50

### GPU model and memory

Nvidia Geforce RTX 3060

### Current Behaviour?

```shell
In a separate environment without Spyder5 the installation and import works:

>>> import tensorflow
2022-11-28 21:11:44.598535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
>>> print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU')))
Num GPUs Available:  1
```
```


### Standalone code to reproduce the issue

```shell
In Spyder5 installed conda environment, after attempting multiple installs in anaconda env:

conda install tensorflow-gpu -c conda-forge
conda install -c anaconda tensorflow-gpu
```
Error received with standard:
```
import tensorflow as tf
```
Error report below:
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/antz/anaconda3/envs/vit-env/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: libflatbuffers.so.2: cannot open shared object file: No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/antz/anaconda3/envs/vit-env/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/home/antz/anaconda3/envs/vit-env/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 36, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""/home/antz/anaconda3/envs/vit-env/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 77, in <module>
    raise ImportError(
ImportError: Traceback (most recent call last):
  File ""/home/antz/anaconda3/envs/vit-env/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: libflatbuffers.so.2: cannot open shared object file: No such file or directory


Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors for some common causes and solutions.
If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
```
```
</details>"
58715,On threading library using the GPU implementing multithreaded RL algorithm,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

(v2.11.0-rc2-17-gd5b57ca93e5 2.11.0) But tried many different 2.11 versions

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 22.04.1 LTS

### Mobile device

Ubuntu 22.04.1 LTS

### Python version

3.10 and 3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuda 11.0

### GPU model and memory

_No response_

### Current Behaviour?

```shell
This is a bug when interacting with the threading library while using GPUs tested in docker environment using the latest tensorflow-gpu build. I even tried to update python to the latest version.
The code is an implementation of Asynchronous Advantage Actor-Critic playing with the Pong library. Even if there might be errors in the code, it works flawlessly when using CPUs. Switching to GPU brings up errors.

Two possible outcomes, depending on commenting the @tf.function code at line 224 of class Worker:

- If @tf.function is not commented, the code shows a warning: ""WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f909efa6670> triggered tf.function retracing"".

- If @tf.function is commented, many different errors show up, ranging from ""TensorArray"" not being used, to errors regarding reshape during gradients. These errors completely block the code execution.

Again, using the CPU-based versions, none of these problems shows up. I personally don't know the source code of TF but this makes me think that it might be caused by naming conflicts for variables stored in the GPU.
```


### Standalone code to reproduce the issue

```shell
Here's a repo containing a comparison between the errors shown when using GPU and CPU while commenting tf.function

https://github.com/occhialidaleso/A3C-TF-BUG
```


### Relevant log output

_No response_</details>"
58714,problem in 'tf.mlir.experimental.convert_function' translation to tosa of 'tf.reduce_sum' operation,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
converting following TF code:
A = tf.reduce_sum(B, axis=3)    
where B has 5 dimensions, and is of type: tf.dtypes.float32

generated a few MLIR lines, among them: 
%1 = ""tosa.transpose""(%arg0, %0) : (tensor<10x20x30x40x50xf32>, tensor<5xi32>) -> tensor<10x20x30x50x40xi32>

this is illegal, since transpose operation is not supposed to change the type of the output.

I would expect:
%1 = ""tosa.transpose""(%arg0, %0) : (tensor<10x20x30x40x50xf32>, tensor<5xi32>) -> tensor<10x20x30x50x40xf32>
```


### Standalone code to reproduce the issue

```shell
@tf.function
def transpose_type(inp_list, **kwargs):
    res = tf.reduce_sum(inp_list[0], axis=3)
    return res

def test_transpose_type():

    inputs = [
        tf.TensorSpec(shape=[10, 20, 30, 40, 50], dtype=tf.dtypes.float32),
    ]
    concrete_function = transpose_type.get_concrete_function(inputs)

    mlir = tf.mlir.experimental.convert_function(concrete_function,
        pass_pipeline=""tf-standard-pipeline,tf-functional-control-flow-to-regions,func.func(tosa-legalize-tf), convert-tf-control-flow-to-scf"")
        #pass_pipeline=""tf-standard-pipeline""),#tf-functional-control-flow-to-regions,func.func(tosa-legalize-tf), convert-tf-control-flow-to-scf""),
        # ""tf-standard-pipeline,builtin.module(convert-tf-control-flow-to-scf)""))

    filename = ""transpose_type.mlir""
    with open(filename, ""w"") as fd:
        print(mlir, file=fd)
    return True
```


### Relevant log output

```shell
module attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 1205 : i32}} {
  func.func @__inference_transpose_type_7(%arg0: tensor<10x20x30x40x50xf32> {tf._user_specified_name = ""inp_list""}) -> tensor<10x20x30x50xf32> attributes {tf.entry_function = {control_outputs = """", inputs = ""inp_list"", outputs = ""identity_RetVal""}} {
    %0 = ""tosa.const""() {value = dense<[0, 1, 2, 4, 3]> : tensor<5xi32>} : () -> tensor<5xi32>
    %1 = ""tosa.transpose""(%arg0, %0) : (tensor<10x20x30x40x50xf32>, tensor<5xi32>) -> tensor<10x20x30x50x40xi32>
    %2 = ""tosa.reshape""(%1) {new_shape = [300000, 40]} : (tensor<10x20x30x50x40xi32>) -> tensor<300000x40xf32>
    %3 = ""tosa.reduce_sum""(%2) {axis = 1 : i64} : (tensor<300000x40xf32>) -> tensor<300000x1xf32>
    %4 = ""tosa.reshape""(%3) {new_shape = [10, 20, 30, 50]} : (tensor<300000x1xf32>) -> tensor<10x20x30x50xf32>
    return %4 : tensor<10x20x30x50xf32>
  }
}
```
</details>"
58713,True==1、False==0?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.4, TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
Hello, in the bottom layer of python, bool values exist True and False, and the values are 1 and 0 by default, so we can equivalently represent True=1, False=0.
In the following test code, I try to change trainable=True to trainable=1, and then test in TensorFlow 2.10 version, I will find that an exception is thrown, so I guess the bottom layer should be a clear distinction between int type and bool type, but I tested others before When using the operator, I found that some operators allow changing bool to int value. I suspect that in the entire Tensorflow library, the type conversion between bool and int is not uniformly handled.
In order to find out if this happens in other versions, I tried to test in TensorFlow 2.4 and found that it can be run successfully.
Can you answer the two questions above for me?
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
    import os

    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    with tf.device('/CPU'):
        arg_class = tf.keras.layers.LocallyConnected2D(name=""locally_connected2d"",
                                                       trainable=1,
                                                       dtype=""float32"",
                                                       filters=3,
                                                       kernel_size=[3, 3],
                                                       strides=(1, 1))
        arg_input = tf.random.uniform([2, 6, 10, 4], dtype=tf.float32)
        out = arg_class(arg_input)
        print(out)
```


### Relevant log output

```shell
TensorFlow 2.10 reuslt:  TypeError: Expected `trainable` argument to be a boolean, but got: 1

TensorFlow 2.40 reuslt:  tf.Tensor(
[[[[-0.14315505  0.06499855  0.1216753 ]
   [-0.12515134 -0.00923991  0.00172077]
   [-0.41864938  0.02003886 -0.03438807]
   [ 0.02098705 -0.0746426   0.2031626 ]
   [-0.0728707   0.03610322  0.14793792]
   [-0.01780548  0.17400125 -0.14011937]
   [ 0.06005201 -0.10351056 -0.3389557 ]
   [ 0.15803254  0.17660744  0.00082554]]

  [[-0.01428804 -0.22738077 -0.02933689]
   [-0.02186381  0.11017214 -0.05838367]
   [ 0.05483316  0.04585953  0.18316194]
   [ 0.21922597  0.17010817  0.25584626]
   [-0.1008286  -0.10639497  0.12071656]
   [ 0.22636111 -0.02853697 -0.07310107]
   [-0.1485898   0.02738841  0.16978729]
   [-0.0090516  -0.05216654 -0.04658506]]

  [[-0.00877664  0.14235732  0.2121313 ]
   [ 0.22127396 -0.13508058 -0.31834558]
   [ 0.03935264 -0.23036832  0.15259065]
   [-0.20577691 -0.06493172  0.08293995]
   [-0.0963655  -0.0462731   0.05218513]
   [-0.10291788 -0.19309677  0.08959021]
   [-0.15569639 -0.04861056 -0.21688032]
   [ 0.15255114  0.11844756  0.03276695]]

  [[-0.1714233   0.05530884  0.01905462]
   [-0.16327316 -0.24063838  0.07224267]
   [ 0.17923783  0.02356955  0.31808606]
   [ 0.05519737 -0.2262343  -0.09526171]
   [ 0.06705513 -0.00699769 -0.11271586]
   [ 0.08290772 -0.15076353  0.20352224]
   [ 0.00327513 -0.14215843  0.11999539]
   [-0.03289764 -0.11100782 -0.12392078]]]


 [[[-0.11126763  0.04755261  0.17210905]
   [-0.22264665  0.01195438  0.06607565]
   [-0.25382042  0.11046582 -0.0901512 ]
   [-0.06138152 -0.00287328  0.1841901 ]
   [-0.3332898   0.13658786  0.17474082]
   [-0.04825393  0.25146523  0.01793581]
   [-0.06349282  0.00336953 -0.37769794]
   [ 0.20829338  0.19630632  0.08679034]]

  [[ 0.00682403 -0.1472453  -0.05004839]
   [ 0.02671506  0.03807459 -0.06085263]
   [ 0.17125078  0.07825888  0.18529892]
   [ 0.3258647   0.00920958  0.11021222]
   [-0.02069337 -0.01494252  0.15680203]
   [ 0.10269973 -0.04348599  0.0444208 ]
   [-0.14931358  0.05233786  0.20222609]
   [-0.02042234 -0.00546753 -0.01768769]]

  [[ 0.11787581  0.2359893   0.22494979]
   [ 0.13885225 -0.14175156 -0.36444566]
   [ 0.02330246 -0.19728938  0.13624257]
   [-0.06695578  0.00306335  0.18129912]
   [-0.06312215  0.13316229  0.12113601]
   [-0.07067803 -0.20414466  0.14369792]
   [-0.07599919 -0.06597348 -0.16438872]
   [ 0.10267115  0.05639628  0.20692885]]

  [[-0.33940262  0.07860201  0.12013634]
   [-0.02628985 -0.31915188  0.07179877]
   [-0.06511983  0.05447894  0.24597749]
   [ 0.11804631 -0.16325285  0.02923613]
   [ 0.00725327  0.01450248 -0.06370709]
   [ 0.17952165 -0.09148498  0.09543476]
   [-0.03884454  0.01504131  0.2514327 ]
   [-0.00173181  0.01126088 -0.08406446]]]], shape=(2, 4, 8, 3), dtype=float32)
```
</details>"
58712,tf.keras.layers.Layer runs successfully with inappropriate parameters.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

TF 2.4

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
There was a bug in the TF v2.4 version.
When using the functions tf.keras.layers.Convolution1DTranspose and tf.nn.embedding_lookup, there are also performance differences between running on CPU and GPU.
```


### Standalone code to reproduce the issue

```shell
import os
    import tensorflow as tf
    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    arg_class = tf.keras.layers.Layer(trainable=True)
    a = tf.constant([[0.6094154, 0.2760073]], dtype=tf.float32)
    input = [a, 2]
    out = arg_class(*input)
    print(out)
```


### Relevant log output

```shell
TensorFlow 2.4 result：
   TypeError: call() takes 2 positional arguments but 3 were given


</details>"
58711,BatchNormalization error in low version?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

TF 2.4, TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
Why does tf.keras.layers.BatchNormalization error occur in the low version (tensorflow2.4), but not in the high version (tensorflow2.10)?
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
    m = tf.keras.layers.BatchNormalization(axis=-1, epsilon=0.001, momentum=0.999)
    input = tf.saturate_cast(tf.random.uniform([1, 3, 1, 672], minval=0, maxval=256, dtype=tf.int64), dtype=tf.uint8)
    out = m(input)
    print(out)
```


### Relevant log output

_No response_</details>"
58710,Add support for 3rd part object storage (S3) in Docker image,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.6+

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When using tensorflow docker image to run tensorboard (Kubeflow uses this method), out of the box the image only supports gcs-filesystem and to support for 3rd party object storage (eg. S3) due to the dependency on `tensorflow-io`. The ask is to make tensorflow-io as required pip dependency while docker build happens that way lot of customizations could be avoided and the support is out of the box.
```


### Standalone code to reproduce the issue

```shell
When using the below sample spec (simplified to make the reproducibility easy):

    spec:
      affinity: {}
      containers:
      - args:
        - AWS_REGION=us-east-1 S3_ENDPOINT=https://SOME_S3_ENDPOINT
          AWS_ACCESS_KEY_ID=SOME_AWS_KEY AWS_SECRET_ACCESS_KEY= SOME_AWS_SECRET /usr/local/bin/tensorboard
          --logdir=s3:/LOGS_PATH --bind_all
        command:
        - /bin/sh
        - -c
        image: tensorflow/tensorflow:2.11.0
        imagePullPolicy: IfNotPresent
        name: tensorboard
        ports:
        - containerPort: 6006
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        workingDir: /
      dnsPolicy: ClusterFirst
      imagePullSecrets:
      - name: regcred
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```


### Relevant log output

```shell
when the above Spec is deployed we will run into the following error `Error: Unsupported filename scheme 's3' (supported schemes: ['ram', 'file', '', 'gs']). For additional filesystem support, consider instal │
│ ling TensorFlow I/O (https://www.tensorflow.org/io) via `pip install tensorflow-io`.`
```
</details>"
58709,error occurs when convert a tflite model with uint8 inference_input_type during quantization-aware-training,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- TensorFlow installation (pip package or built from source): tf 2.8
- TensorFlow library (version, if pip package or github SHA, if built from source): tf2.8

### 2. Code
I want to convert a model by quantization aware training. the fp32 model is simple and it can only be convert to a tflite model with fp32 input/output. how can i convert a fp32 model with uint8 intput and output, since it can be done by post-training quantization by assign the converter.inference_input_type = tf.uint8 and converter.inference_output_type  = tf.uint8.  
if i can not assign inference_input_type or inference_output_type   during quantization-aware-training, how can i convert a tflite model with specified input output dtype?
 Thank you !
**minimum code:**
```
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Conv2DTranspose


num_filters=512
inputs=tf.keras.Input((32,32,1024))

outputs= Conv2DTranspose(filters=num_filters,
                    kernel_size=(2, 2), 
                    strides=2, 
                    padding=""same"",name='convTrans')(inputs)

base_model=tf.keras.Model(inputs=inputs,outputs=outputs,name=""test_transConv2D_model"")
base_model.summary()
print(base_model.layers[1].weights[0].shape)
print(base_model.layers[1].weights[1].shape)
# (2, 2, 512, 1024)
# (512,)

import tensorflow_model_optimization as tfmot
quant_aware_model = tfmot.quantization.keras.quantize_model(base_model)

x_train = np.random.randn(4,32, 32, 1024).astype(np.float32)
y_train = np.random.randn(4, 64, 64, 512).astype(np.float32)
quant_aware_model.compile(
    loss=tf.keras.losses.categorical_crossentropy,
    optimizer='adam',
    metrics=['accuracy']
)
quant_aware_model.fit(x_train, y_train,epochs=1)
quant_aware_model.summary()

quant_aware_model.input.set_shape((1,) + quant_aware_model.input.shape[1:])

converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

quantized_tflite_model = converter.convert()
tflite_model_filename='test_transConv2D_model_uint8_inout.tflite'
with open(tflite_model_filename, 'wb') as f:
    f.write(quantized_tflite_model)
    print(""wirte tflite file done!"")
```
**ERRORS:**
```
C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(""Statistics for quantized inputs were expected, but not ""
Traceback (most recent call last):

  File ""D:\OneDrive\AI_Working_Directory\bio_cv\zz_test_transposcvon2d.py"", line 48, in <module>
    quantized_tflite_model = converter.convert()

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\lite.py"", line 803, in wrapper
    return self._convert_and_export_metrics(convert_func, *args, **kwargs)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\lite.py"", line 789, in _convert_and_export_metrics
    result = convert_func(self, *args, **kwargs)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\lite.py"", line 1221, in convert
    self).convert(graph_def, input_tensors, output_tensors)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\lite.py"", line 1010, in convert
    result, self._quant_mode, quant_io=self.experimental_new_quantizer)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\convert_phase.py"", line 216, in wrapper
    raise error from None  # Re-throws the exception.

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\convert_phase.py"", line 206, in wrapper
    return func(*args, **kwargs)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\lite.py"", line 759, in _optimize_tflite_model
    model = _modify_model_io_type(model, m_in_type, m_out_type)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\util.py"", line 979, in modify_model_io_type
    return _convert_model_from_object_to_bytearray(model_object)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\util.py"", line 561, in _convert_model_from_object_to_bytearray
    model_offset = model_object.Pack(builder)

  File ""C:\Users\indeed\.conda\envs\TF28_py37_1\lib\site-packages\tensorflow\lite\python\schema_py_generated.py"", line 5890, in Pack
    operatorCodes = builder.EndVector(len(self.operatorCodes))

TypeError: EndVector() takes 1 positional argument but 2 were given
```

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/gist/ymodak/e96a4270b953201d5362c61c1e8b78aa/tensorflow-datasets.ipynb?authuser=1): Demonstrate how to build your TF model.
2)  Reference [TensorFlow Lite Model Colab](https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).

```
(You can paste links or attach files by dragging & dropping them below)
- Provide links to your updated versions of the above two colab notebooks.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
(You can paste links or attach files by dragging & dropping them below)
- Include code to invoke the TFLite Converter Python API and the errors.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
58708,"tfp.JointDistributionSequential._build() -> line 236, in _build     if not isinstance(model, collections.Sequence): AttributeError: module 'collections' has no attribute 'Sequence'","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Mac OS 13.0.1 (22A400)

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!

I expected the code in the tfp guide to run as written. 

I did...
import collections.abc as collections

According to python doc:

isinstance(object, classinfo), 
Return True if the object argument is an instance of the classinfo argument

However, the classinfo argument in Pycharm is 
{ABCMeta} <class 'collections.abc.Sequence'>

and tfp code is

""if not isinstance(model, collections.Sequence)""

My guess is tfp code should be:

""if not isinstance(model, collections.abc.Sequence)""
```


### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/probability/blob/main/tensorflow_probability/examples/jupyter_notebooks/Modeling_with_JointDistribution.ipynb


Code to reproduce:

dfhogg = pd.DataFrame(np.array([[1,201,592,61,9,-0.84],
                                [2,244,401,25,4,0.31],
                                [3,47,583,38,11,0.64],
                                [4,287,402,15,7,-0.27],
                                [5,203,495,21,5,-0.33],
                                [6,58,173,15,9,0.67],
                                [7,210,479,27,4,-0.02],
                                [8,202,504,14,4,-0.05],
                                [9,198,510,30,11,-0.84],
                                [10,158,416,16,7,-0.69],
                                [11,165,393,14,5,0.30],
                                [12,201,442,25,5,-0.46],
                                [13,157,317,52,5,-0.03],
                                [14,131,311,16,6,0.50],
                                [15,166,400,34,6,0.73],
                                [16,160,337,31,5,-0.52],
                                [17,186,423,42,9,0.90],
                                [18,125,334,26,8,0.40],
                                [19,218,533,16,6,-0.78],
                                [20,146,344,22,5,-0.56]]),
                      columns=['id','x','y','sigma_y','sigma_x','rho_xy'])

## for convenience zero-base the 'id' and use as index
dfhogg['id'] = dfhogg['id'] - 1
dfhogg.set_index('id',inplace=True)

## standardize (mean center and divide by 1 sd)
dfhoggs = (dfhogg[['x','y']] - dfhogg[['x','y']].mean(0)) / dfhogg[['x','y']].std(0)
dfhoggs['sigma_y'] = dfhogg['sigma_y'] / dfhogg['y'].std(0)
dfhoggs['sigma_x'] = dfhogg['sigma_x'] / dfhogg['x'].std(0)

X_np = dfhogg['x'].values
sigma_y_np = dfhogg['y'].values
Y_np = dfhogg['y'].values

mdl_ols = tfd.JointDistributionSequential([
    # b0 ~ Normal(0, 1)
    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),
    # b1 ~ Normal(0, 1)
    tfd.Normal(loc=tf.cast(0, dtype), scale=1.),
    # x ~ Normal(b0+b1*X, 1)
    lambda b1, b0: tfd.Normal(
      # Parameter transformation
      loc=b0 + b1*X_np,
      scale=sigma_y_np)
])
```


### Relevant log output

```shell
line 236, in _build
    if not isinstance(model, collections.Sequence):
AttributeError: module 'collections' has no attribute 'Sequence'
```
</details>"
58707,"Problems with TensorFlow for C, Windows CPU Only, version 2.11.0","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I wanted to use the TensorFlow C Api.

But I think the 2.11.0 Windows CPU only files from https://www.tensorflow.org/install/lang_c are messed up a bit:

`include/tensorflow/c/c_api.h` tries to include `tf_buffer.h`, which is not in the zip archive.

With version 2.10.0 instead, everything is working.
```


### Standalone code to reproduce the issue

```shell
download https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-2.11.0.zip
```


### Relevant log output

_No response_</details>"
58706,Movenet low fps on movenet's official example app - GPU issue,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Android

### Mobile device

Android Mobile

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Running example app of movenet on android: https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/android

Movenet's lighning model is giving 20-25 fps instead of the mentioned 50+ fps on mobile device
(tested different android mobiles from mid to high range)
I figure it's likely because it's not using gpu, since the speed is constant with gpu and cpu.
```


### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/android

Just run this project in android studio and see apk.
```


### Relevant log output

_No response_</details>"
58704,how to fix sBad??,![image](https://user-images.githubusercontent.com/97845943/204128137-ae44f438-32ce-499b-a759-52eda151f52b.jpeg)
58703,Type restrictions on seeds in the tf.image.stateless_random_hue documentation.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

TF 2.4

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
The seed in the tf.image.stateless_random_hue(image, max_delta, seed) operator parameter, the requirement in the document is ""A shape [2] Tensor, the seed to the random number generator. Must have dtype int32 or int64. (When using XLA, only int32 is allowed.)"", you can clearly see ''When using XLA, only int32 is allowed.'', for this situation, I used the official test case, and used XLA, and then set the type of seed It is not designed to be int32, but int64. I found that the program can still run through, so I don't understand why the document is restricted''When using XLA, only int32 is allowed.''
```


### Standalone code to reproduce the issue

```shell
import os
    import tensorflow as tf

    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    with tf.device(""/device:XLA_CPU:0""):
        x = [[[1.0, 2.0, 3.0],
              [4.0, 5.0, 6.0]],
             [[7.0, 8.0, 9.0],
              [10.0, 11.0, 12.0]]]
        seed = tf.constant([1, 2], dtype=tf.int64)
        out = tf.image.stateless_random_hue(x, 0.2, seed)
        print(out)
```


### Relevant log output

```shell
result:
 tf.Tensor(
 [[[ 1.6514893  1.         3.       ]
  [ 4.6514893  4.         6.       ]]

 [[ 7.6514893  7.         9.       ]
  [10.651489  10.        12.       ]]], shape=(2, 2, 3), dtype=float32)
```

tf.image.stateless_random_brightness, tf.image.stateless_sample_distorted_bounding_box, tf.image.stateless_random_flip_up_down, tf.image.stateless_random_flip_left_right, etc. all have the same problem.



</details>"
58702,tf.image.rot90 has inconsistent results in different TensorFlow versions.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.4, TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
Comparing TensorFlow2.4 and TensorFlow2.10, it is found that the description of tf.image.rot90 is consistent, but the results of running TensorFlow2.4 and TensorFlow2.10 are inconsistent. It will fail in the lower version, but will succeed in the higher version. Judging from the exception thrown in the lower version, the data type is not supported, and the higher version supports this type, but this type of restriction is not proposed in the official document, which will cause misunderstanding.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

    with tf.device('/CPU'):
        image = tf.saturate_cast(tf.random.uniform([2, 2, 1], minval=0, maxval=257, dtype=tf.int64), dtype=tf.uint64)
        out = tf.image.rot90(image)
        print(out)
```


### Relevant log output

```shell
Results running on TensorFlow 2.4:  
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of uint64 is not in the list of allowed values: uint8, int8, uint16, int16, int32, int64, bool, bfloat16, half, float, double, complex64, complex128, string; NodeDef: {{node ReverseV2}}; Op<name=ReverseV2; signature=tensor:T, axis:Tidx -> output:T; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]; attr=T:type,allowed=[DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64, DT_BOOL, DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_STRING]> [Op:ReverseV2]


Results running on TensorFlow 2.10:  
tf.Tensor(
[[[72]
  [70]]

 [[35]
  [12]]], shape=(2, 2, 1), dtype=uint64)
```
</details>"
58700,tf.image.random_flip_left_right failed to run on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In the case of tf.image.random_flip_left_right input parameters, but the results are different on CPU and GPU.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

    image = tf.saturate_cast(tf.random.uniform([2, 2, 1, 1], minval=-128, maxval=128, dtype=tf.int64),dtype=tf.int8)
    with tf.device('/CPU'):
        out = tf.image.random_flip_left_right(image)
        print(""CPU: "", out)

    with tf.device('/GPU:0'):
        out = tf.image.random_flip_left_right(image)
        print(""GPU: "", out)
```


### Relevant log output

```shell
CPU:  tf.Tensor(
[[[[-53]]

  [[ 87]]]


 [[[  7]]

  [[ 30]]]], shape=(2, 2, 1, 1), dtype=int8)

tensorflow.python.framework.errors_impl.UnknownError: {{function_node __wrapped__Sub_device_/job:localhost/replica:0/task:0/device:GPU:0}} JIT compilation failed. [Op:Sub]
```
</details>"
58699,Question about tf.image.convert_image_dtype parameter type?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3    cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
tf.image.convert_image_dtype(image, dtype, saturate=False, name=None), for image and dtype parameters can be uint8, uint16, uint32, uint64, int8, int16, int32, int64, float16, float32, float64, bfloat16. Then I set the image to complex64 and found it to work, so I don't know if the documentation is adequate.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
    image = tf.constant([[[254 + 2j]], [[83]], [[72]]], dtype=tf.complex64)
    dtype = tf.float64
    out = tf.image.convert_image_dtype(image, dtype)
    print(out)
```


### Relevant log output

```shell
result :
tf.Tensor(
  [[[inf]]

 [[inf]]

 [[inf]]], shape=(3, 1, 1), dtype=float64)
```
</details>"
58698,tf.image.adjust_hue runs incorrectly on TensorFlow 2.4 version,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

TF 2.4

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3 cuDNN cuDNN 8.6.0

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When running the tf.image.adjust_hue operator test code on TensorFlow 2.4, the official requirement that the parameter delta must be in the interval [-1, 1], but when I set it to not be in this interval, it can still run successfully.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

    image = [[[1, 2, 3], [4, 5, 6]],
             [[7, 8, 9], [10, 11, 12]],
             [[13, 14, 15], [16, 17, 18]]]
    image = tf.constant(image)
    print(tf.image.adjust_hue(image, 12.0))
```


### Relevant log output

```shell
result: tf.Tensor(
[[[ 1  2  3]
  [ 4  5  6]]

 [[ 7  8  9]
  [10 11 12]]

 [[13 14 15]
  [16 17 18]]], shape=(3, 2, 3), dtype=int32)
```
</details>"
58697,The parameter indices in tf.gather are supported int16,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3 cuDNN cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
tf.gather(params, indices, validate_indices=None, axis=None, batch_dims=0, name=None) The parameter type requirement for indices in the official document is Tensor, and then the type is int32, int64. For this situation, I deliberately use Unreasonable types are tested. When indices are set to 1.0, it is a float type, but the exception thrown says that this is not int16, int32, int64, which is one more int16 than the official document. Therefore, it is recommended to add int16 to the document. Go up or remove int16 from the source code.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

    with tf.device('/CPU'):
        params = tf.random.uniform([1024, 2], dtype=tf.float64)
        indices = 1.0
        out = tf.gather(params=params, indices=indices)
```


### Relevant log output

```shell
result:tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'Tindices' of float is not in the list of allowed values: int16, int32, int64; NodeDef: {{node GatherV2}}; Op<name=GatherV2; signature=params:Tparams, indices:Tindices, axis:Taxis -> output:Tparams; attr=batch_dims:int,default=0; attr=Tparams:type; attr=Tindices:type,allowed=[DT_INT16, DT_INT32, DT_INT64]; attr=Taxis:type,allowed=[DT_INT32, DT_INT64]> [Op:GatherV2]
```
</details>"
58696,What is the real meaning of 6034766930529145842 in the exception information thrown by the tf.math.cumsum operator?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3       cuDNN cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
I deliberately use illegal parameters to test tf.math.cumsum, and set the parameter axis to an empty string to get exception information, but in the exception information, I am allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64] Here, I see a string of 6034766930529145842, but this information does not give me any useful information, and then test API, you will not get this long number, so it is recommended to modify the real meaning of 6034766930529145842.
```


### Standalone code to reproduce the issue

```shell
from tensorflow import int32
    import tensorflow as tf
    with tf.device('/CPU'):
        x = tf.random.uniform([2, 4], minval=-256, maxval=257, dtype=tf.int32)
        out = tf.math.cumsum(x, axis="""", exclusive=False, reverse=False)
```


### Relevant log output

```shell
tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'Tidx' of string is not in the list of allowed values: int32, int64; NodeDef: {{node Cumsum}}; Op<name=Cumsum; signature=x:T, axis:Tidx -> out:T; attr=exclusive:bool,default=false; attr=reverse:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, 6034766930529145842, DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]> [Op:Cumsum]
```
</details>"
58695,The information thrown by the tf.clip_by_norm operator in different TensorFlow versions does not match the description in the documentation.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

TF 2.4, TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3 cuDNN cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
The tf.clip_by_norm operator in TensorFlow2.4 version is completely consistent with the TensorFlow2.10 version description, and the data type for x is (A Tensor or IndexedSlices. This must be a floating point type.), so I am testing the code , when x is set to uint32, the information thrown is different in TensorFlow2.4 version and TensorFlow2.10 version, especially in TensorFlow2.4 version, the type of exception information description x can be (bfloat16, half, float, double , uint8, int8, uint16, int16, int32, int64, complex64, complex128) are inconsistent with the official description of a floating point type.
```


### Standalone code to reproduce the issue

```shell
from tensorflow import int32
    from tensorflow import uint32
    import tensorflow as tf
    import os

    os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
    with tf.device('/CPU'):
        t = tf.saturate_cast(tf.random.uniform([1, 5], minval=0, maxval=257, dtype=tf.int32), dtype=tf.uint32)
        clip_norm = 2.0
        out = tf.clip_by_norm(t, clip_norm)
    print(out)
```


### Relevant log output

```shell
Results running on TensorFlow 2.4:  tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of uint32 is not in the list of allowed values: bfloat16, half, float, double, uint8, int8, uint16, int16, int32, int64, complex64, complex128; NodeDef: {{node Mul}}; Op<name=Mul; signature=x:T, y:T -> z:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_UINT8, DT_INT8, DT_UINT16, DT_INT16, DT_INT32, DT_INT64, DT_COMPLEX64, DT_COMPLEX128]; is_commutative=true> [Op:Mul]

Results running on TensorFlow 2.10:  tensorflow.python.framework.errors_impl.InvalidArgumentError: Value for attr 'T' of uint32 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]
```
</details>"
58694,Incompatible Bazel version with the docs,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Debian 11

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.1.1

### GCC/Compiler version

9.3.0

### CUDA/cuDNN version

11.2,8.1

### GPU model and memory

RTX 3060/12G

### Current Behaviour?

```shell
As it has been discussed https://github.com/tensorflow/tensorflow/issues/58461#issuecomment-1325666595 Bazel version used from the project is not aligned with the one in docs. Since .bazelversion file pinpoints 5.3.0, there is version incompatibility and build from source fails to start.

Happy to do a PR refactoring .bazelversion
```


### Standalone code to reproduce the issue

```shell
Install bazel 5.1.1 and try to compile TF r2.10/2.11.
```


### Relevant log output

```shell
Use other bazel version
```
</details>"
58693,tf.math.add runs successfully Documentation Unsupported type: uint16,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

Yes

### OS Platform and Distribution

windows 11

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA: 11.3       cuDNN cuDNN 8.6.0

### GPU model and memory

RTX3060

### Current Behaviour?

```shell
According to the TensorFlow2.10 documentation, tf.math.add(x, y, name=None), the types of x and y must be A Tensor. types: bfloat16, half, float32, float64, uint8, int8, int16, int32, int64 , complex64, complex128, string.
But when the type of my x and y is input as uint16, I found that the program can run successfully, so I suggest that the document can be modified,or work on adding a type check on the input.
In order to prove that this is not an accidental behavior, I also tested tf.math.exp(x), the type of x needs to be bfloat16, half, float32, float64, complex64, complex128, if I enter int64, an exception will be thrown, indicating In the source code, there is a check on the parameter type.
```


### Standalone code to reproduce the issue

```shell
from tensorflow import int64
    from tensorflow import uint16
    import tensorflow as tf
    with tf.device('/CPU'):
        x = tf.saturate_cast(tf.random.uniform([1, 2, 1, 3], minval=0, maxval=257, dtype=tf.int64), dtype=tf.uint16)
        y = tf.saturate_cast(tf.random.uniform([2, 1, 3, 1], minval=0, maxval=257, dtype=tf.int64), dtype=tf.uint16)
        res = tf.math.add(x, y)
    print(res)
```


### Relevant log output

```shell
Test code result:
tf.Tensor(
  [[[[350 277 296]
   [259 186 205]
   [183 110 129]]

  [[376 204 403]
   [285 113 312]
   [209  37 236]]]


 [[[189 116 135]
   [244 171 190]
   [178 105 124]]

  [[215  43 242]
   [270  98 297]
   [204  32 231]]]], shape=(2, 2, 3, 3), dtype=uint16)
```
</details>"
58692,AttributeError: module 'tensorflow._api.v2.nn' has no attribute 'seq2seq',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

2.9

### Custom Code

Yes

### OS Platform and Distribution

Windows10

### Mobile device

_No response_

### Python version

3.7.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.7

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to know how can I convert this code:
        tf.nn.seq2seq.rnn_decoder
to tensorflow 2.9.1, Btw code is execute in tensorflow 0.10.0 before.
```


### Standalone code to reproduce the issue

```shell
This is a part of code. When it run til here:
        # TODO: Try attention decoder/use dynamic_rnn instead
        self.outputs, self.final_state = tf.nn.seq2seq.rnn_decoder(
            decoder_inputs=self.inputs,
            initial_state=None,  # The initial state is defined inside KeyboardCell
            cell=KeyboardCell(self.args),
            loop_function=loop_rnn
        )
The AttributeError is happened:
      File ""C:\Users\Sarynu\Desktop\AM\deepmusic\model.py"", line 212, in _build_network
        self.outputs, self.final_state = tf.nn.seq2seq.rnn_decoder(
    AttributeError: module 'tensorflow._api.v2.nn' has no attribute 'seq2seq'
```


### Relevant log output

```shell
File ""C:\Users\Sarynu\Desktop\AM\deepmusic\model.py"", line 212, in _build_network
    self.outputs, self.final_state = tf.nn.seq2seq.rnn_decoder(
AttributeError: module 'tensorflow._api.v2.nn' has no attribute 'seq2seq'
```
</details>"
58691,Load Model using load_model throws error when there is a Lambda layer in the model,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Please see the attached link to Colab for details. Any model with a Lambda layer will show the ""'str' object is not callable"" error when loading using the load_model method.
```


### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/gist/aicheung/bb211e6e1ce1220bbeeec8b8a3ee9e0b
```


### Relevant log output

```shell
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-a5a79acdb750> in <module>
----> 1 model = tf.keras.models.load_model(""./model"")

1 frames
/usr/local/lib/python3.7/dist-packages/keras/backend.py in error_handler(*args, **kwargs)
    144       # `is_traceback_filtering_enabled` (from the outer scope) may not be
    145       # accessible from inside this function
--> 146       return fn(*args, **kwargs)
    147 
    148     filtered_tb = None

TypeError: Exception encountered when calling layer ""lambda"" (type Lambda).

'str' object is not callable

Call arguments received by layer ""lambda"" (type Lambda):
  • inputs=tf.Tensor(shape=(None, 81), dtype=uint8)
  • mask=None
  • training=None
```
</details>"
58690,Bug: TypeError: can't multiply sequence by non-int of type 'NoneType',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

v2.4.0-49-g85c8b2a817f 2.4.1

### Custom Code

No

### OS Platform and Distribution

Kaggle Notebook

### Mobile device

No

### Python version

3.7.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

TPU v3-8

### Current Behaviour?

```shell
While I'm trying to train my model using TF and Kaggle Notebook with TPU Acceleration, I get the error message pasted in the logs below. I've read the source code and found this:
In https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/tpu_strategy.py, at lines 1605-1609, if rank was None, ValueError should be raised.
          if rank is None:
            raise ValueError(
                ""input tensor {} to TPUStrategy.run() has unknown rank, ""
                ""which is not allowed"".format(input_tensor))
          maximum_shape = tensor_shape.TensorShape([None] * rank)
Instead, I'm getting TypeError on the next line: TypeError: can't multiply sequence by non-int of type 'NoneType'.
Am I doing something wrong? This looks like a bug to me.
```


### Standalone code to reproduce the issue

```shell
https://github.com/guerchen/my-own-facematch-liveness/blob/main/my-own-facematch-liveness.ipynb
```


### Relevant log output

```shell
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/tmp/ipykernel_21/2489583751.py in <module>
----> 1 history = model.fit(train,epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,validation_data=(val))

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    869       # This is the first call of __call__, so we have to initialize.
    870       initializers = []
--> 871       self._initialize(args, kwds, add_initializers_to=initializers)
    872     finally:
    873       # At this point we know that the initialization is complete (or less

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    724     self._concrete_stateful_fn = (
    725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 726             *args, **kwds))
    727 
    728     def invalid_creator_scope(*unused_args, **unused_kwds):

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2967       args, kwargs = None, None
   2968     with self._lock:
-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)
   2970     return graph_function
   2971 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3359 
   3360           self._function_cache.missed.add(call_context_key)
-> 3361           graph_function = self._create_graph_function(args, kwargs)
   3362           self._function_cache.primary[cache_key] = graph_function
   3363 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3204             arg_names=arg_names,
   3205             override_flat_arg_shapes=override_flat_arg_shapes,
-> 3206             capture_by_value=self._capture_by_value),
   3207         self._function_attributes,
   3208         function_spec=self.function_spec,

/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    988         _, original_func = tf_decorator.unwrap(python_func)
    989 
--> 990       func_outputs = python_func(*func_args, **func_kwargs)
    991 
    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    632             xla_context.Exit()
    633         else:
--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    635         return out
    636 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, ""ag_error_metadata""):
--> 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

TypeError: in user code:

    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *
        return step_function(self, iterator)
    /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:540 run
        return self.extended.tpu_run(fn, args, kwargs, options)
    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:1296 tpu_run
        return func(args, kwargs)
    /opt/conda/lib/python3.7/site-packages/tensorflow/python/distribute/tpu_strategy.py:1345 tpu_function
        maximum_shape = tensor_shape.TensorShape([None] * rank)

    TypeError: can't multiply sequence by non-int of type 'NoneType'
```
</details>"
58689,installing tensor flow on m2,"ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow

getting this error when I try installing tensor flow on apple m2 MacBook Air"
58688,Instantiating std::complex as static_cast<int16_t>(std::abs<int32_t> in TfLiteStatus AbsInt16EvalImpl() is unspecified,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Window 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

Visual Studio 2022 Nov update

### CUDA/cuDNN version

_No response_

### GPU model and memory

nVidia

### Current Behaviour?

```shell
This is the compiler warning after the latest VS 2022 C++ upgrade:
error C4996: 'std::complex<int32_t>::complex': warning STL4037: The effect of instantiating the template std::complex for any type other than float, double, or long double is unspecified. You can define _SILENCE_NONFLOATING_COMPLEX_DEPRECATION_WARNING to suppress this warning.

Seems that the complex abs function may not give a guarantee for operation with int32_t.
```


### Standalone code to reproduce the issue

```shell
Just compile Tensor flow in VS with the latest updates and standard settings.
```


### Relevant log output

```shell
third_party\tensorflow\tensorflow\lite\kernels\elementwise.cc(169,57): error C4996: 'std::complex<int32_t>::complex': warning STL4037: The effect of instantiating the template std::complex for any type other than float, double, or long double is unspecified. You can define _SILENCE_NONFLOATING_COMPLEX_DEPRECATION_WARNING to suppress this warning.
```
</details>"
58687,Protobuf Package Dependency between Google ads and tensorflow,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello, would you be so kind to fix TensorFlow 2.11.0 depends on protobuf<3.20 and >=3.9.2 to be more relevant to the google ads package which uses protobuf==4.21.5
```


### Standalone code to reproduce the issue

```shell
protobuf==4.21.5
google-ads==19.0.0
tensorflow==2.11.0
google-api-core==2.10.1
googleapis-common-protos==1.56.4
```


### Relevant log output

```shell
The conflict is caused by:
    The user requested protobuf==4.21.5
    google-ads 19.0.0 depends on protobuf>=4.21.5
    google-api-core 2.10.1 depends on protobuf<5.0.0dev and >=3.20.1
    googleapis-common-protos 1.56.4 depends on protobuf<5.0.0dev and >=3.15.0
    tensorflow 2.11.0 depends on protobuf<3.20 and >=3.9.2
```
</details>"
58686,AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_unique_id',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Debian64 ( Unix )

### Mobile device

_No response_

### Python version

3.10.4

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello to Everyone

I need to training an Actor network for a reinforcement learning algorithm but in time i am trying to predict continuous actions i have a problem with the function: 

self.Actor.optimizer.apply_gradients ( zip ( grads2 , std ) )

also this one gives me the same error:
self.Actor.optimizer.apply_gradients ( zip ( [ grads1 , grads2 ] , [ self.Actor.model.trainable_variables , std ] ) )

Please note that with the following function all goes well:
self.Actor.optimizer.minimize ( loss_actions , var_list = [ self.Actor.model.trainable_variables , std ] , tape = tape_actions )

the problem seems to be caused by the external variable std ( that it is not internal to the model ), Did I make some mistakes? is there a way to clip_by_norm the std variable's gradients ?

Best Regards Samir
```


### Standalone code to reproduce the issue

```shell
one = tf.ones ( self.settings.action_size , dtype = float )
std = tf.Variable ( one , dtype = float , name = 'std' )

sample = self.replay.sample ()

with tf.GradientTape ( persistent = False ) as tape_actions :
     tape_actions.reset ()
               
     actions_local = self.Actor.model ( sample [ 0 ] )

     tfp_dist  = tfp.distributions.Normal ( loc = actions_local , scale = std )
     new_probs = tfp_dist.log_prob        (       sample [ 1 ]                )
     new_probs = tf.math.reduce_sum       (       new_probs     , axis  = 1   )
     new_probs = tf.math.exp              (       new_probs                   )

     ratio = new_probs / sample [ 3 ] # >= 0

     ratio = tf.math.reduce_min (
             tf.convert_to_tensor ( [ ratio * sample [ 4 ] , \
             tf.clip_by_value     (   ratio , clip_value_min = 1 - 0.1 ,
                                              clip_value_max = 1 + 0.1 ) * sample [ 4 ] ] ) ,
                                   axis = 0 )

     loss_actions = - tf.math.reduce_mean ( ratio )

grads = tape_actions.gradient ( loss_actions , [ self.Actor.model.trainable_variables , std ] )

grads1 = [ tf.clip_by_norm ( t = w , clip_norm = 0.75 ) for w in grads [ 0 ] ]
grads2 = [ tf.clip_by_norm ( t = w , clip_norm = 0.75 ) for w in grads [ 1 ] ]

self.Actor.optimizer.apply_gradients ( zip ( grads1 , self.Actor.model.trainable_variables ) )
self.Actor.optimizer.apply_gradients ( zip ( grads2 ,                                  std ) )
```


### Relevant log output

```shell
1/1250/usr/lib/python3/dist-packages/apport/report.py:13: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses
  import fnmatch, glob, traceback, errno, sys, atexit, locale, imp, stat
Traceback (most recent call last):
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/Reacher.py"", line 43, in <module>
    future.cross_entropy_loss ()
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 295, in cross_entropy_loss
    self.play_EP ( ie , self.settings.envs.reset ( train_mode = True ) [ self.settings.brain_name ] )
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 78, in play_EP
    print ( '' ) ; self.training_for_elite (real_steps_to_train) ; print ( '' )
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 169, in training_for_elite
    self.training ( self.future_rewards_elite , real_steps_to_train )
  File ""/home/kaumi/Git/deepL_RL2/4.ML_Agents/14.p2_continuous-control/Reacher_exam_code/agent.py"", line 272, in training
    self.Actor.optimizer.apply_gradients ( zip ( grads2 ,                                  std ) )
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 695, in apply_gradients
    self._create_all_weights(var_list)
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 959, in _create_all_weights
    self._create_slots(var_list)
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py"", line 126, in _create_slots
    self.add_slot(var, ""m"")
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 1017, in add_slot
    var_key = _var_key(var)
  File ""/home/kaumi/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 1650, in _var_key
    return var._unique_id
  File ""/home/kaumi/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py"", line 446, in __getattr__
    self.__getattribute__(name)
AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_unique_id'
```
</details>"
58684,How to set the half_pixel_centers of ResizeBilinear to False in the .tflite?,"### 1. System information

- OS Platform and Distribution (Linux Ubuntu 22.04):

Hi, i convert the model from pytorch into tflite：

   pytorch = 1.10 (.pth) -> onnx = 1.12 (.onnx) -> tensorflow = 2.11  (.tflite)

I find the half_pixel_centers  of the ResizeBilinear  operator is True, but i need this option to be False.  

How can i set the half_pixel_centers to False during model convert?

![image](https://user-images.githubusercontent.com/48872511/203933849-b9b0564b-85ec-427e-a2b0-ab32c1413c1a.png)

I try to set the half_pixel_centers  to False, when parsing the onnx model, and converting it into keras model:

---------------------------------------------------------------------------------------------------------------------------------
def keras_builder(onnx_model, new_input_nodes:list=None, new_output_nodes:list=None):
    model_graph = onnx_model.graph

    '''
        init onnx model's build-in tensors
    '''
    onnx_weights = dict()
    for initializer in model_graph.initializer:
        onnx_weights[initializer.name] = numpy_helper.to_array(initializer)

    '''
        build input nodes
    '''
    tf_tensor, input_shape = {}, []
    for inp in model_graph.input:
        input_shape = [x.dim_value for x in inp.type.tensor_type.shape.dim]
        if input_shape == []:
            continue
        batch_size = 1 if input_shape[0] <= 0 else input_shape[0]
        input_shape = input_shape[2:] + input_shape[1:2]
        tf_tensor[inp.name] = keras.Input(shape=input_shape, batch_size=batch_size)

    '''
        build model inline node by iterate onnx nodes.
    '''
    input_node_names, outputs_node_names = [], []
    for node in model_graph.node:
        op_name, node_inputs, node_outputs, node_name = node.op_type, node.input, node.output, node.name
        op_attr = decode_node_attribute(node)
        
        #print(""opt name {}, opt {}"".format(op_name, op_attr))

        tf_operator = OPERATOR.get(op_name)

        if(op_name == ""Resize""):
            print(tf_operator)
            op_attr['pytorch_half_pixel'] = False

        if tf_operator is None:
            raise KeyError(f""{op_name} not implemented yet"")
        
        _inputs = None 
        if len(node_inputs) > 0:
            _inputs = tf_tensor[node_inputs[0]] if node_inputs[0] in tf_tensor else onnx_weights[node_inputs[0]]

        for index in range(len(node_outputs)):
            tf_tensor[node_outputs[index]] = tf_operator(tf_tensor, onnx_weights, node_inputs, op_attr, index=index)(_inputs)
            if(op_name == ""Resize""):
                print(tf_operator(tf_tensor, onnx_weights, node_inputs, op_attr, index=index)(_inputs))
        '''
            reorganize input and output nodes
        '''
        if new_input_nodes is not None and node_name in new_input_nodes:
            input_node_names.append(node_outputs[0])
        # TODO for nodes with multiply outputs.
        if new_output_nodes is not None and node_name in new_output_nodes:
            outputs_node_names.append(node_outputs[0])
        if new_output_nodes is not None and len(outputs_node_names) == len(new_output_nodes):
            break
    
    '''
        process input and output nodes 
    '''
    input_nodes = []
    if new_input_nodes is None:
        input_nodes = [tf_tensor[x.name] for x in model_graph.input]
    else:
        for node in model_graph.input:
            if node.name in new_input_nodes:
                input_node_names.append(node.name)
        input_nodes = [tf_tensor[x] for x in input_node_names]
    outputs_nodes = []
    if new_output_nodes is None:
        outputs_nodes = [tf_tensor[x.name] for x in model_graph.output]
    else:
        for node in model_graph.output:
            if node.name in new_output_nodes:
                outputs_node_names.append(node.name)
        outputs_nodes = [tf_tensor[x] for x in outputs_node_names]

    '''
        build keras model
    '''
    keras_model = keras.Model(inputs=input_nodes, outputs=outputs_nodes)
    keras_model.trainable = False
    # keras_model.summary()

    return keras_model
------------------------------------------------------------------------------------------------------------------
    keras_model = keras_builder(model_proto, input_node_names, output_node_names)
    print(""Build keras model Done"")
    # set resize half_pixel_centers = False
    ind =0
    for layer in keras_model.layers:

        #print(layer.name)

        if (""resize"" in layer.name) or (""Resize"" in layer.name):
            print(""###############################"")
            
            keras_model.layers[ind].half_pixel_centers = False
            print(keras_model.layers[ind].half_pixel_centers)
         
        ind+=1

But when converting keras to tflite model by tf.lite.TFLiteConverter.from_keras_model(keras_model),  the half_pixel_centers  is still True.
"
58683,Tensorflow Lite iOS Interpreter production logs,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

iOS

### Mobile device

iOS

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The log outputs of the Interpreter cannot be disabled for production use, but we would need that.
See: https://github.com/tensorflow/tensorflow/blob/bb5ff1b22f5d4d6bf937dcd71f8b710064eadce6/tensorflow/lite/core/interpreter.cc#L97

Would be nice if you could introduce another option for the Interpreter where you could set log outputs enabled/disabled or even with LogLevels.
```


### Standalone code to reproduce the issue

```shell
Interpreter(modelPath: path, options: options)
```


### Relevant log output

```shell
Initialized TensorFlow Lite runtime.
```
</details>"
58682,<spam>,<spam removed>
58681,Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 22.04.01

### Mobile device

_No response_

### Python version

3.9.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.2, cuDNN 8.1.0

### GPU model and memory

Nvidia GTX 1060 6gb

### Current Behaviour?

```shell
I was installing tensorflow according to this guide https://www.tensorflow.org/install/pip and ran into the error. I am running a fresh install of ubuntu. I have tried `export XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda` to no avail.
```


### Standalone code to reproduce the issue

```shell
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5) #fails here
```


### Relevant log output

```shell
Epoch 1/5
2022-11-24 23:30:47.064919: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f4ce3255ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-24 23:30:47.064946: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1060 6GB, Compute Capability 6.1
2022-11-24 23:30:47.068586: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-11-24 23:30:47.086148: W tensorflow/compiler/xla/service/gpu/nvptx_helper.cc:56] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.
Searched for CUDA in the following directories:
  ./cuda_sdk_lib
  /usr/local/cuda-11.2
  /usr/local/cuda
  .
You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.
2022-11-24 23:30:47.087159: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc
2022-11-24 23:30:47.087339: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-24 23:30:47.087434: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc
2022-11-24 23:30:47.106008: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc
2022-11-24 23:30:47.106292: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc
2022-11-24 23:30:47.125456: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc
2022-11-24 23:30:47.125753: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc
2022-11-24 23:30:47.144359: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:326] libdevice is required by this HLO module but was not found at ./libdevice.10.bc
2022-11-24 23:30:47.144670: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:446 : INTERNAL: libdevice not found at ./libdevice.10.bc
Output exceeds the size limit. Open the full output data in a text editor
---------------------------------------------------------------------------
InternalError                             Traceback (most recent call last)
Cell In [4], line 1
----> 1 model.fit(x_train, y_train, epochs=5)

File ~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File ~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     50 try:
     51   ctx.ensure_initialized()
---> 52   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     53                                       inputs, attrs, num_outputs)
     54 except core._NotOkStatusException as e:
     55   if name is not None:

InternalError: Graph execution error:

Detected at node 'StatefulPartitionedCall_2' defined at (most recent call last):
    File ""/home/nathan/miniconda3/envs/tf/lib/python3.9/runpy.py"", line 197, in _run_module_as_main
...
    File ""/home/nathan/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"", line 1211, in apply_grad_to_update_var
      return self._update_step_xla(grad, var, id(self._var_key(var)))
Node: 'StatefulPartitionedCall_2'
libdevice not found at ./libdevice.10.bc
	 [[{{node StatefulPartitionedCall_2}}]] [Op:__inference_train_function_766]
```
</details>"
58680,TensorFlow Lite Model Maker has version conflict during install,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Windows 11 22H2

### Mobile device

_No response_

### Python version

3.17.13 and 3.10.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I was trying to install the tflite-model-maker through ""pip install tflite-model-maker"" in my terminal, I tried it with the different versions of python I have (in visual studio code, terminal) as mentioned above. I want to use tflite-model-maker to try the mobilenetv3. But in all of them, I get the error below. I also tried installing it with conda but failed too. btw Im new so I dont really know if this is from source or binary, so I just put ""source"" in Source field above. Thank you very much for your help.
```


### Standalone code to reproduce the issue

```shell
pip install tflite-model-maker
```


### Relevant log output

```shell
Using cached sentencepiece-0.1.83.tar.gz (497 kB)
  Preparing metadata (setup.py) ... error
  error: subprocess-exited-with-error

  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> [8 lines of output]
      Traceback (most recent call last):
        File ""<string>"", line 2, in <module>
        File ""<pip-setuptools-caller>"", line 34, in <module>
        File ""C:\Users\Jericho Longabela\AppData\Local\Temp\pip-install-9g31z9dp\sentencepiece_693a5d046a70461f8838ce79e5f24100\setup.py"", line 29, in <module>
          with codecs.open(os.path.join('..', 'VERSION'), 'r', 'utf-8') as f:
        File ""C:\Program Files\Python310\lib\codecs.py"", line 905, in open
          file = builtins.open(filename, mode, buffering)
      FileNotFoundError: [Errno 2] No such file or directory: '..\\VERSION'
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
```
</details>"
58676,"Higher Memory Usage with model.predict in Recent TF Versions (TF 2.10, 2.11 etc)","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary 
- we use `pip install` to reproduce the issue although we use `poetry` in production. 

### Tensorflow Version

2.10 and 2.11 and maybe others after 2.8.2 all have this issue

### Custom Code

No (can reproduce the issue with simple code below)

### OS Platform and Distribution

```
PRETTY_NAME=""Debian GNU/Linux 11 (bullseye)""
NAME=""Debian GNU/Linux""
VERSION_ID=""11""
VERSION=""11 (bullseye)""
VERSION_CODENAME=bullseye
ID=debian
HOME_URL=""https://www.debian.org/""
SUPPORT_URL=""https://www.debian.org/support""
BUG_REPORT_URL=""https://bugs.debian.org/""
```
```x86_64```

### Mobile device

_No response_

### Python version

3.8.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

We use TF to serve multiple models in production and recently we tried updating from TF 2.8.2 to TF 2.10. We noticed on many of our services/workers there was a memory increase/leak with some services even crashing. We had to revert back to 2.8.2. I also see the issue in TF 2.11. With this deploy in particular the only thing we upgraded was Tensorflow. No application code changes.

We monitor the memory with DataDog and all our host graphs showed major spikes. These are mostly `tf.keras` models. I thought originally it was a `ddtrace` issue because from TF 2.9 and up `model.predict` started printing progress bars and I thought all those were getting collected in  DataDog traces. But I set `verbose=0` on all model.predict calls and turned off ddtrace an the issue was still there.

Some screenshots from two different services

<img width=""1876"" alt=""Screenshot 2022-11-24 at 5 17 04 PM"" src=""https://user-images.githubusercontent.com/16509365/203864156-2faece9b-98b1-4cb0-bb9f-6c86faed633c.png"">
<img width=""1872"" alt=""Screenshot 2022-11-24 at 5 17 42 PM"" src=""https://user-images.githubusercontent.com/16509365/203864162-8ddfca83-add9-4040-93d9-eee2bb59501f.png"">



### Standalone code to reproduce the issue

Run this code on a machine with 8 cores and 16GB of ram for example.
Here is also a [colab](https://colab.research.google.com/drive/1fZ5I72KMPuoJf9Gqxd6XBo-294MM9jP5#scrollTo=RhJF-f7atWI6) with the same code as below although not sure you can replicate the memory leak issue in colab. I am replicating the issue on a standard aws ec2 instance `c5.2xlarge`. Running in a single ipython session for an hour or two will show the leak. You can speed it up by running 5 ipython sessions at once in 5 shells.

**Minimal Dockerfile**
```
FROM python:3.8-slim

WORKDIR /app

RUN apt-get update && apt-get install -y \
        wget \
        htop \
        vim

COPY . /app

RUN pip install tensorflow #  pip install tensorflow==2.8.2 does not have MEM leak
RUN pip install ipython
RUN pip install Pillow
EXPOSE 5000
```

```
docker build . -t tf
docker run -it tf /bin/bash
```

Now in the docker container
```
ipython
```

```
# download an image
!wget --output-document=my_image.jpg https://www.wwf.org.uk/sites/default/files/styles/social_share_image/public/2018-10/Large_WW1113482.jpg?itok=Bluh496C
```

```
import tensorflow
from tensorflow import keras
from tensorflow.keras.applications.resnet50 import ResNet50
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.resnet50 import preprocess_input
import numpy as np

model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
img_path = 'my_image.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)
for _ in range(100000):
    embedding = model.predict(x)
```


Look at the memory usage with `htop` with TF 2.8.2 and the memory will not grow.
Now repeat the same thing with TF 2.10, 2.11 etc (maybe even 2.9 But I never checked it)
and you will see much higher memory usage and a linear growth.

### Relevant log output

#### TF 2.8.2

Here is the `pip freeze` inside the Docker ENV for TF 2.8.2 version
```
absl-py==1.3.0
asttokens==2.1.0
astunparse==1.6.3
backcall==0.2.0
cachetools==5.2.0
certifi==2022.9.24
charset-normalizer==2.1.1
decorator==5.1.1
executing==1.2.0
flatbuffers==22.11.23
gast==0.5.3
google-auth==2.14.1
google-auth-oauthlib==0.4.6
google-pasta==0.2.0
grpcio==1.50.0
h5py==3.7.0
idna==3.4
importlib-metadata==5.1.0
ipython==8.6.0
jedi==0.18.2
keras==2.8.0
Keras-Preprocessing==1.1.2
libclang==14.0.6
Markdown==3.4.1
MarkupSafe==2.1.1
matplotlib-inline==0.1.6
numpy==1.23.5
oauthlib==3.2.2
opt-einsum==3.3.0
parso==0.8.3
pexpect==4.8.0
pickleshare==0.7.5
Pillow==9.3.0
prompt-toolkit==3.0.33
protobuf==3.19.6
ptyprocess==0.7.0
pure-eval==0.2.2
pyasn1==0.4.8
pyasn1-modules==0.2.8
Pygments==2.13.0
requests==2.28.1
requests-oauthlib==1.3.1
rsa==4.9
six==1.16.0
stack-data==0.6.1
tensorboard==2.8.0
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.1
tensorflow==2.8.2
tensorflow-estimator==2.8.0
tensorflow-io-gcs-filesystem==0.28.0
termcolor==2.1.1
traitlets==5.5.0
typing_extensions==4.4.0
urllib3==1.26.13
wcwidth==0.2.5
Werkzeug==2.2.2
wrapt==1.14.1
zipp==3.10.0
```
Memory Stays at Like 1GB
<img width=""1464"" alt=""Screenshot 2022-11-25 at 11 14 13 AM"" src=""https://user-images.githubusercontent.com/16509365/204013870-260bf5b0-27e9-48cd-bd3a-400e0fe68e0c.png"">

Here is the log output when you `import tensorflow as tf` on TF 2.8.2

```
2022-11-25 15:44:46.912225: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-11-25 15:44:46.912258: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```


#### TF 2.11
And here is the `pip freeze` for a higher version of TF 2.11

```
absl-py==1.3.0
asttokens==2.1.0
astunparse==1.6.3
backcall==0.2.0
cachetools==5.2.0
certifi==2022.9.24
charset-normalizer==2.1.1
decorator==5.1.1
executing==1.2.0
flatbuffers==22.11.23
gast==0.4.0
google-auth==2.14.1
google-auth-oauthlib==0.4.6
google-pasta==0.2.0
grpcio==1.50.0
h5py==3.7.0
idna==3.4
importlib-metadata==5.1.0
ipython==8.6.0
jedi==0.18.2
keras==2.11.0
libclang==14.0.6
Markdown==3.4.1
MarkupSafe==2.1.1
matplotlib-inline==0.1.6
numpy==1.23.5
oauthlib==3.2.2
opt-einsum==3.3.0
packaging==21.3
parso==0.8.3
pexpect==4.8.0
pickleshare==0.7.5
Pillow==9.3.0
prompt-toolkit==3.0.33
protobuf==3.19.6
ptyprocess==0.7.0
pure-eval==0.2.2
pyasn1==0.4.8
pyasn1-modules==0.2.8
Pygments==2.13.0
pyparsing==3.0.9
requests==2.28.1
requests-oauthlib==1.3.1
rsa==4.9
six==1.16.0
stack-data==0.6.1
tensorboard==2.11.0
tensorboard-data-server==0.6.1
tensorboard-plugin-wit==1.8.1
tensorflow==2.11.0
tensorflow-estimator==2.11.0
tensorflow-io-gcs-filesystem==0.28.0
termcolor==2.1.1
traitlets==5.5.0
typing_extensions==4.4.0
urllib3==1.26.13
wcwidth==0.2.5
Werkzeug==2.2.2
wrapt==1.14.1
zipp==3.10.0
```

The memory will keep growing to even over 15GB.
Here is a screen shot of it on its way growing over time
<img width=""1825"" alt=""Screenshot 2022-11-25 at 11 42 00 AM"" src=""https://user-images.githubusercontent.com/16509365/204018443-2a4a2468-77ee-422a-affa-56a1d9c56f4a.png"">


Here is the log output when `import tensorfow` on most recent version TF 2.11
```
2022-11-25 15:37:47.360066: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-25 15:37:47.498679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-11-25 15:37:47.498726: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-11-25 15:37:48.351066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-25 15:37:48.351130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-25 15:37:48.351143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
```"
58674,installing tensorflow 2.11.0 on windows using poetry fails to install tensorflow-intel dependency,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

After installing tensorflow 2.11.0 on windows using poetry, importing tensorflow fails with `ModuleNotFoundError: No module named 'tensorflow'`. You can see on the [pypi page of 2.11](https://pypi.org/project/tensorflow/2.11.0/#files) that all the windows wheels are empty (only 1.9kb) and so are the arm packages as [reported here](https://github.com/tensorflow/tensorflow/issues/58602#issuecomment-1326627053)

Installing with pip works as it seems to pick up on a `tensorflow-intel` dependency from somewhere (which then also contains tensorflow). We saw something like that in the Metadata file of the tensorflow wheel ~ however that seems not to be enough to give poetry that info.



### Standalone code to reproduce the issue

```shell
mkdir poetry-test
cd poetry-test
poetry init
poetry add tensorflow
python -c ""import tensorflow""
```
-> `ModuleNotFoundError: No module named 'tensorflow'`


### Relevant log output

_No response_</details>"
58673,Crashes with exit code 135 in model.fit,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 22.02

### Mobile device

_No response_

### Python version

Docker image

### Bazel version

Docker image

### GCC/Compiler version

Docker image

### CUDA/cuDNN version

Docker image

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Crashes in model.fit with no error message but exit code 135

Works fine in 2.9
```


### Standalone code to reproduce the issue

```shell
Calling model.fit() causes a crash
```


### Relevant log output

_No response_</details>"
58670,Feature request (TensorFlow Lite): Strip unneeded kernels when building Flex ops library on platforms other than Android,"### System information

-   **Have I written custom code**: no
-   **OS Platform and Distribution**: macOS Monterey 12.6
-   **TensorFlow installed from**: source
-   **TensorFlow version**: 2.10.0
-   **Python version**: 3.10.8
-   **Bazel version**: 5.1.1
-   **GCC/Compiler version**: Apple clang 14.0.0 (clang-1400.0.29.202)
-   **CUDA/cuDNN version**: Not using CUDA
-   **GPU model and memory**: Not using GPU acceleration
-   **Exact command to reproduce**: Feature request, no 

### Describe the problem

This is a feature request.

TensorFlow Lite 2.10 provides a [tool](https://www.tensorflow.org/lite/guide/ops_select#building_the_android_aar) that strips unneeded kernels when building the Flex library, but this is for Android only. On other platforms, the whole set of kernels gets built in, and the flex binary ends up being hundreds of MBs in size. Would you consider implementing a similar tool for other platforms, and, if not, would you accept PRs for it?"
58669,Feature request (TensorFlow Lite): Implement mechanism to load Flex ops in C for Android,"### System information

-   **Have I written custom code**: no
-   **OS Platform and Distribution**: macOS Monterey 12.6
-   **TensorFlow installed from**: source
-   **TensorFlow version**: 2.10.0
-   **Python version**: 3.10.8
-   **Bazel version**: 5.1.1
-   **GCC/Compiler version**: Apple clang 14.0.0 (clang-1400.0.29.202)
-   **CUDA/cuDNN version**: Not using CUDA
-   **GPU model and memory**: Not using GPU acceleration
-   **Exact command to reproduce**: Feature request, no 

### Describe the problem

This is a feature request.

In TensorFlow Lite 2.7 and higher, if a model contains Flex ops you must go through Java to load the Flex library (see [NativeInterpreterWrapper.java](https://github.com/tensorflow/tensorflow/blob/3c53121ab319ce3646d3cb5b0152e78ef02c3925/tensorflow/lite/java/src/main/java/org/tensorflow/lite/NativeInterpreterWrapper.java#L542) and [FlexDelegate.java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/java/src/main/java/org/tensorflow/lite/flex/FlexDelegate.java)).

We develop a cross-platform app where most of the ML inference logic runs in a separate C library. We test that library separately from the rest of the app using GTest, without going through the Android runtime. For our purposes, it would be much more convenient if we could load the Flex library directly in C.

As a tentative implementation, we could move the logic in `NativeInterpreterWrapper.java` to C, so that we could automatically load Flex ops when creating models from the C API with `TfLiteModelCreate`. The existing Java classes could be kept as shallow wrappers to the underlying C implementation. Java and C entry points could be toggled at build time through a flag.

Is this something that you would consider implementing, and, if not, would you accept PRs that go in that direction?"
58668,Have TensorFlow Lite convert keras.LSTM layers without requiring Flex ops,"**System information**
- OS Platform and Distribution: macOS Monterey 12.6
- TensorFlow installed from: binary
- TensorFlow version: 2.10.0
- Keras version: 2.10.0

**Provide the text output from tflite_convert**

```python
2022-11-24 12:05:13.342007: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-24 12:05:16.822583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.
2022-11-24 12:05:47.471765: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-11-24 12:05:47.471809: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-11-24 12:05:47.472616: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/sn/0dslr5js3rz6pht1s02qxbf00000gr/T/tmpl3_86lch
2022-11-24 12:05:47.484736: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }
2022-11-24 12:05:47.484760: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/sn/0dslr5js3rz6pht1s02qxbf00000gr/T/tmpl3_86lch
2022-11-24 12:05:47.528960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-11-24 12:05:47.536418: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.
2022-11-24 12:05:47.592653: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/sn/0dslr5js3rz6pht1s02qxbf00000gr/T/tmpl3_86lch
2022-11-24 12:05:47.635483: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 162893 microseconds.
2022-11-24 12:05:47.754083: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
loc(callsite(callsite(callsite(fused[""TensorListReserve:"", callsite(""TensorArrayV2_1@__inference_standard_lstm_639""(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1268:0) at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1232:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1249:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1319:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1339:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":908:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":930:0 at ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"":26:0))))))))] at fused[""PartitionedCall:"", callsite(""model/lstm/PartitionedCall@__inference__wrapped_model_912""(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1268:0) at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1232:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1249:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1319:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1339:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":908:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":930:0 at ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"":26:0))))))))]) at fused[""StatefulPartitionedCall:"", callsite(""StatefulPartitionedCall@__inference_signature_wrapper_2769""(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1268:0) at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1232:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1249:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1319:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1339:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":908:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":930:0 at ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"":26:0))))))))]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass
loc(callsite(callsite(callsite(fused[""TensorListReserve:"", callsite(""TensorArrayV2_1@__inference_standard_lstm_639""(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1268:0) at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1232:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1249:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1319:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1339:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":908:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":930:0 at ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"":26:0))))))))] at fused[""PartitionedCall:"", callsite(""model/lstm/PartitionedCall@__inference__wrapped_model_912""(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1268:0) at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1232:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1249:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1319:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1339:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":908:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":930:0 at ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"":26:0))))))))]) at fused[""StatefulPartitionedCall:"", callsite(""StatefulPartitionedCall@__inference_signature_wrapper_2769""(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1268:0) at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py"":1232:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1249:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"":205:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1319:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":1339:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":908:0 at callsite(""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"":930:0 at ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"":26:0))))))))]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n converter._experimental_lower_tensor_list_ops = False
Traceback (most recent call last):
  File ""/Users/andreasavio/yousician/dsp_research/tensorflow/test.py"", line 26, in <module>
    content = converter.convert()
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 930, in wrapper
    return self._convert_and_export_metrics(convert_func, *args, **kwargs)
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 908, in _convert_and_export_metrics
    result = convert_func(self, *args, **kwargs)
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 1339, in convert
    saved_model_convert_result = self._convert_as_saved_model()
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 1322, in _convert_as_saved_model
    self).convert(graph_def, input_tensors, output_tensors)
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/lite.py"", line 1132, in convert
    result = _convert_graphdef(
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"", line 212, in wrapper
    raise converter_error from None  # Re-throws the exception.
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py"", line 205, in wrapper
    return func(*args, **kwargs)
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert.py"", line 794, in convert_graphdef
    data = convert(
  File ""/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/lite/python/convert.py"", line 311, in convert
    raise converter_error
tensorflow.lite.python.convert_phase.ConverterError: /Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1268:0: error: 'tf.TensorListReserve' op requires element_shape to be static during TF Lite transformation pass
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from
/Users/andreasavio/yousician/tensorflow_distros/2.10.0/lib/python3.10/site-packages/tensorflow/python/saved_model/save.py:1268:0: error: failed to legalize operation 'tf.TensorListReserve' that was explicitly marked illegal
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from
<unknown>:0: error: Lowering tensor list ops is failed. Please consider using Select TF ops and disabling `_experimental_lower_tensor_list_ops` flag in the TFLite converter object. For example, converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n converter._experimental_lower_tensor_list_ops = False
```

**Standalone code to reproduce the issue** 

```python
import tensorflow as tf
import keras

num_rows = 10
num_cols = 10

model_input = keras.layers.Input(shape=(num_rows, num_cols))
model_output = keras.layers.LSTM(
    input_shape=(num_rows, num_cols),
    units=2,
    return_sequences=True,
    kernel_initializer=""glorot_uniform"",
    recurrent_initializer=""orthogonal"",
    unit_forget_bias=True,
    recurrent_activation=""sigmoid"",
    activation=""tanh"",
)(model_input)

model = keras.Model(inputs=[model_input], outputs=model_output)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS # Conversion fails without this line
]

content = converter.convert()
```

The model consists of a single Keras `LSTM` layer, other than the input.

**Any other info / logs**

In TensorFlow 2.10, models that contain `LSTM` layers from Keras require Flex ops when exported to TensorFlow Lite. Since TensorFlow Lite seems to have its own in-built [LSTM op](https://www.tensorflow.org/mlir/tfl_ops#tflbasic_lstm_mlirtflbasiclstmop), would it be possible to avoid Flex ops in the conversion above?"
58666,Regularizer loss out of scope in train step when loss includes conditional statements,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

Yes

### OS Platform and Distribution

CentOS Linux 7 (Core)

### Mobile device

_No response_

### Python version

3.7.5

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am currently implementing a custom model that splits a batch based on a flag in the data, using different loss definitions for given flags. This is done using an if-clause in a tf.function decorated method, model.conditional_loss_calculation.

The model is a composite model, using two other models as layers. The bug arises when these submodels include regularizers. When trying to add the regularizer loss to the calculated loss in the custom train step, an InaccessibleTensorError is produced stating that the tensors in self.losses are out of scope. This issue only occurs when model.conditional_loss_calculation is wrapped in a tf.function decorator, and dissappears when everything is run eagerly.

Based on the inclusion of regularization losses in the standard model.fit and model.train_step implementations, I would think this should work for graph mode in my custom implementation. I believe the issue is related to an interplay between the scope of the regularizers and the graph branching caused by the if-statements in model.conditional_loss_calculation.
```


### Standalone code to reproduce the issue

```shell
A minimum viable example using MNIST can be found here: https://colab.research.google.com/drive/1-p3uSWjMoY5D4eqkvdl168SMgUttS9Eb?usp=sharing
```


### Relevant log output

```shell
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in autograph_handler(*args, **kwargs)
   1125           except Exception as e:  # pylint:disable=broad-except
   1126             if hasattr(e, ""ag_error_metadata""):
-> 1127               raise e.ag_error_metadata.to_exception(e)
   1128             else:
   1129               raise

InaccessibleTensorError: in user code:

    File ""<ipython-input-1-7a5e175537ce>"", line 120, in train_step  *
        regularization_loss = sum(self.losses)

    InaccessibleTensorError: <tf.Tensor 'vae/encoder/dense/ActivityRegularizer/truediv:0' shape=() dtype=float32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it.
    Please see https://www.tensorflow.org/guide/function#all_outputs_of_a_tffunction_must_be_return_values for more information.
    
    <tf.Tensor 'vae/encoder/dense/ActivityRegularizer/truediv:0' shape=() dtype=float32> was defined here:
        File ""/usr/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
          ""__main__"", mod_spec)
        File ""/usr/lib/python3.7/runpy.py"", line 85, in _run_code
          exec(code, run_globals)
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py"", line 16, in <module>
          app.launch_new_instance()
        File ""/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py"", line 846, in launch_instance
          app.start()
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py"", line 612, in start
          self.io_loop.start()
        File ""/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py"", line 149, in start
          self.asyncio_loop.run_forever()
        File ""/usr/lib/python3.7/asyncio/base_events.py"", line 541, in run_forever
          self._run_once()
        File ""/usr/lib/python3.7/asyncio/base_events.py"", line 1786, in _run_once
          handle._run()
        File ""/usr/lib/python3.7/asyncio/events.py"", line 88, in _run
          self._context.run(self._callback, *self._args)
        File ""/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py"", line 690, in <lambda>
          lambda f: self._run_callback(functools.partial(callback, future))
        File ""/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py"", line 743, in _run_callback
          ret = callback()
        File ""/usr/local/lib/python3.7/dist-packages/tornado/gen.py"", line 787, in inner
          self.run()
        File ""/usr/local/lib/python3.7/dist-packages/tornado/gen.py"", line 748, in run
          yielded = self.gen.send(value)
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 365, in process_one
          yield gen.maybe_future(dispatch(*args))
        File ""/usr/local/lib/python3.7/dist-packages/tornado/gen.py"", line 209, in wrapper
          yielded = next(result)
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 268, in dispatch_shell
          yield gen.maybe_future(handler(stream, idents, msg))
        File ""/usr/local/lib/python3.7/dist-packages/tornado/gen.py"", line 209, in wrapper
          yielded = next(result)
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py"", line 545, in execute_request
          user_expressions, allow_stdin,
        File ""/usr/local/lib/python3.7/dist-packages/tornado/gen.py"", line 209, in wrapper
          yielded = next(result)
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py"", line 306, in do_execute
          res = shell.run_cell(code, store_history=store_history, silent=silent)
        File ""/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py"", line 536, in run_cell
          return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2855, in run_cell
          raw_cell, store_history, silent, shell_futures)
        File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 2881, in _run_cell
          return runner(coro)
        File ""/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py"", line 68, in _pseudo_sync_runner
          coro.send(None)
        File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 3058, in run_cell_async
          interactivity=interactivity, compiler=compiler, result=result)
        File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 3249, in run_ast_nodes
          if (await self.run_code(code, result,  async_=asy)):
        File ""/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py"", line 3326, in run_code
          exec(code_obj, self.user_global_ns, self.user_ns)
        File ""<ipython-input-1-7a5e175537ce>"", line 204, in <module>
          verbose=1
        File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
          return fn(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1409, in fit
          tmp_logs = self.train_function(iterator)
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1051, in train_function
          return step_function(self, iterator)
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1040, in step_function
          outputs = model.distribute_strategy.run(run_step, args=(data,))
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1030, in run_step
          outputs = model.train_step(data)
        File ""<ipython-input-1-7a5e175537ce>"", line 119, in train_step
          total_loss, reconstruction_loss, kl_loss = self.conditional_loss_calculation(data)
        File ""<ipython-input-1-7a5e175537ce>"", line 81, in conditional_loss_calculation
          (
        File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
          return fn(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 490, in __call__
          return super().__call__(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
          return fn(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py"", line 1014, in __call__
          outputs = call_fn(inputs, *args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
          return fn(*args, **kwargs)
        File ""<ipython-input-1-7a5e175537ce>"", line 163, in call
          z_mean_above, z_log_var_above, z_above = self.encoder(input_above)
        File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
          return fn(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 490, in __call__
          return super().__call__(*args, **kwargs)
        File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
```
</details>"
58663,TFlite IOS will not build when imported as part of a package. 100+ Undefined Symbols reported at link phase,"### Issue Type
Build/Install

### System information

Mac OS 12.6.1
XCode 14.1
TFLite 2.9.1

### Describe the problem

I am trying to add TFLite to a swift package that we have. Essentially our code runs its own tflite models, so it has a dependency on TFLite Swift, which depends on TFLiteC. Since this is a swift package, it is not an option to use pods.

Using information from [this thread](https://github.com/tensorflow/tensorflow/issues/44609), I was able to add the TFLite dependencies, and successfully build my swift package as a standalone package.

However, once I add my package into an actual project, the linking phase completely breaks, with over 100 undefined symbols.

<img width=""1920"" alt=""Screen Shot 2022-11-23 at 20 48 50 PM  1"" src=""https://user-images.githubusercontent.com/37613957/203625490-dcbf46ee-2238-4dfb-91ec-84a380155bb7.png"">

This also happens when using the examples at the end of the above thread.

For clarity, adding the package here, under Frameworks, Libraries, and Embeded content causes the linking failure. 
<img width=""1920"" alt=""Screen Shot 2022-11-23 at 20 55 02 PM  1"" src=""https://user-images.githubusercontent.com/37613957/203626093-07f9f1e8-cd1f-4059-b3b9-c31bc383ec7d.png"">


### Source code / logs

Here is a link to the test project that reproduces this error. (50mb so I cannot directly upload it here)

https://drive.google.com/file/d/1xV-qSxF7z94SqFSrf1QWBkwHesIug0wt/view?usp=sharing
"
58662,Type Inference Failure for LSTM with masking using Nvidia GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9.1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11/8

### GPU model and memory

Nvidia K80; 11GB

### Current Behaviour?

```shell
When using an Embedding layer with mask_zero=True, followed by an LSTM layer, we get an error message:

2022-11-23 17:53:38.745101: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_LEGACY_VARIANT
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_INT8
    }
  }
}
```


### Standalone code to reproduce the issue

```shell
# fetch data ...
# $ curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
# $ tar -xf aclImdb_v1.tar.gz
# $ rm -r aclImdb/train/unsup

import os, pathlib, shutil, random
from tensorflow import keras
from tensorflow.keras import layers

batch_size = 32
base_dir = pathlib.Path(""aclImdb"")
val_dir = base_dir / ""val""
train_dir = base_dir / ""train""
for category in (""neg"", ""pos""):
    os.makedirs(val_dir / category)
    files = os.listdir(train_dir / category)
    random.Random(1337).shuffle(files)
    num_val_samples = int(0.2 * len(files))
    val_files = files[-num_val_samples:]
    for fname in val_files:
        shutil.move(train_dir / category / fname, val_dir / category / fname)

train_ds = keras.utils.text_dataset_from_directory(""aclImdb/train"", batch_size=batch_size)
val_ds = keras.utils.text_dataset_from_directory(""aclImdb/val"", batch_size=batch_size)
text_only_train_ds = train_ds.map(lambda x, y: x)

max_length = 600
max_tokens = 20000
text_vectorization = layers.TextVectorization(
    max_tokens=max_tokens,
    output_mode=""int"",
    output_sequence_length=max_length,
)
text_vectorization.adapt(text_only_train_ds)

int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)
int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)

inputs = keras.Input(shape=(max_length,), dtype=""int64"")
embedded = layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero = True)(inputs)
x = layers.LSTM(32)(embedded)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation=""sigmoid"")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer=""rmsprop"", loss=""binary_crossentropy"", metrics=[""accuracy""])
model.summary()

model.fit(int_train_ds, validation_data=int_val_ds, epochs=1)
```


### Relevant log output

```shell
deeplearn@ML-RefVm-967342:~/example$ python example.py
Found 20000 files belonging to 2 classes.
2022-11-23 17:53:30.683578: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-23 17:53:31.265925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7
Found 5000 files belonging to 2 classes.
Model: ""model""
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 input_1 (InputLayer)        [(None, 600)]             0

 embedding (Embedding)       (None, 600, 256)          5120000

 lstm (LSTM)                 (None, 32)                36992

 dropout (Dropout)           (None, 32)                0

 dense (Dense)               (None, 1)                 33

=================================================================
Total params: 5,157,025
Trainable params: 5,157,025
Non-trainable params: 0
_________________________________________________________________
2022-11-23 17:53:38.745101: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_LEGACY_VARIANT
    }
  }
}
 is neither a subtype nor a supertype of the combined inputs preceding it:
type_id: TFT_OPTIONAL
args {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_TENSOR
    args {
      type_id: TFT_INT8
    }
  }
}

        while inferring type of node 'cond_40/output/_26'
2022-11-23 17:53:39.424474: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500
625/625 [==============================] - 40s 56ms/step - loss: 0.4242 - accuracy: 0.8154 - val_loss: 0.2995 - val_accuracy: 0.8812
deeplearn@ML-RefVm-967342:~/example$
```
</details>"
58661,Tensorflow Lite Swift iOS: Cocoapods Integration Broken - No such module 'TensorFlowLiteC',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

Latest from cocoapods

### Custom Code

No

### OS Platform and Distribution

XCode 13.2.1

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Take the image classification sample app for example:
 https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/ios/Podfile

Replace pod 'TensorFlowLiteTaskVision' with 'TensorFlowLiteSwift'

pod install.

Build for any ios device or try to archive the app.

Result: Compiler Error - No such module 'TensorFlowLiteC'

Expected Result: No Compiler Error.

This issue seems to have been introduced when Tensorflow Lite was distributed via cocoapods using  .XCFramework, it used to work with .framework, you can pin to version ""1.14.0"" and it works as expected.
```


### Standalone code to reproduce the issue

```shell
platform :ios, '12.0'

target 'SampleApp' do
   use_frameworks!

  pod 'TensorFlowLiteSwift'
end
```


### Relevant log output

_No response_</details>"
58660,TF Lite GPU Delegate not working on android for Movenet,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

Android

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When i select the accellerator as nnapi or cpu it works fine, but on gpu, the app crashes.
```


### Standalone code to reproduce the issue

```shell
Running tflite movenet single pose with gpu accellarator. The logs will clarify better.
```


### Relevant log output

```shell
TFLite Warning: Following operations are not supported by GPU delegate:
ARG_MAX: Operation is not supported.
CAST: Not supported Cast case. Input type: UINT8 and output type: FLOAT32
CONCATENATION: OP is supported, but tensor type/shape isn't compatible.
DEQUANTIZE: 
FLOOR_DIV: OP is supported, but tensor type/shape isn't compatible.
GATHER_ND: Operation is not supported.
MUL: OP is supported, but tensor type/shape isn't compatible.
PACK: OP is supported, but tensor type/shape isn't compatible.
RESHAPE: OP is supported, but tensor type/shape isn't compatible.
SUB: OP is supported, but tensor type/shape isn't compatible.
97 operations will run on the GPU, and the remaining 200 operations will run on the CPU.
UnityEngine.Debug:LogWarning (object)
TensorFlowLite.ErrorReporter:OnErrorReporter (intptr,string,intptr) 
TensorFlowLite.Interpreter:.ctor (byte[],TensorFlowLite.InterpreterOptions) 
TensorFlowLite.BaseImagePredictor`1<sbyte>:.ctor (string,TensorFlowLite.BaseImagePredictor`1/Accelerator<sbyte>)
TensorFlowLite.MoveNet.MoveNetSinglePose:.ctor (TensorFlowLite.MoveNet.MoveNetSinglePose/Options) (at Assets/MoveNet/MoveNetSinglePose.cs:26)
MoveNetSinglePoseSample:Start () (at Assets/MoveNet/MoveNetSinglePoseSample.cs:37)
```
</details>"
58656,How much FPS in iOS (Swift)?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

 pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly', :subspecs => ['CoreML', 'Metal']

### Custom Code

Yes

### OS Platform and Distribution

MacOS

### Mobile device

iPhone X

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Can I increase number of frames per second?
```


### Standalone code to reproduce the issue

```shell
How much FPS in iOS (Swift)?
```


### Relevant log output

_No response_</details>"
58655,Inconsistency in connection with setting both clipnorm and global_clipnorm attibute for an optimizer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


**Basic problem statement:** It is possible to set both the `clipnorm` and the `global_clipnorm` attributes for an optimizer. A model configured with this optimizer can be saved, but loading fails with a ValueError.

**Details:**

It is not possible to instantiate a Keras optimizer with both `clipnorm` and `global_clipnorm` kwargs set, since that produces a value error, e.g.

```shell
adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1, global_clipnorm=0.5)

ValueError: Cannot accept both `clipnorm` and `global_clipnorm`. Received: `clipnorm`=1, `global_clipnorm`=0.5.
```
However, it is possible to first instantiate the optimizer with just one of the two settings, and then, likely by accident, set the other via the optimizer's corresponding attribute:
```
adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1)
adam_opt.global_clipnorm = 0.5
```

This does not raise any exceptions. An optimizer with both `clipnorm` and `global_clipnorm` set can be set as the optimizer for a Keras model, and the model trains with this optimizer without any problems. The Keras model can also be **saved** along with this optimizer without any warning or error raised. However, when attempting to **load** a Keras model with such an optimizer, the same ValueError as mentioned above is raised as the saved optimizer is instantiated.

One possible solution would be to have the already existing `@clipnorm.setter` method check whether `self._global_clipnorm` is already set and delete the latter setting if it is. Same for `@global_clipnorm.setter` and checking `self._clipnorm`.

However, I believe that the best solution would be to replace this error with a warning. I don't quite understand what the point of raising this exception is in the first place, and why a similar exception is not raised when e.g. you try to assign a value to `clipvalue` when `clipnorm` is also set or vice versa. As far as I can tell, the only place these attributes are used is in `OptimizerV2._transform_gradients()`, which just makes the value of `self._clipnorm` override `self._clipvalue` and then `self._global_clipnorm` override both of these. So setting more than one of these seems to be harmless. It warrants a warning, but not an error.

As a matter of fact, it would be nice if the Keras documentation mentioned this overriding behavior explicitly. I mean, the way the documentation puts it is **technically** correct, but not terribly transparent: ""If clipvalue (float) is set, the gradient of each weight is clipped to be no higher than this value. If clipnorm (float) is set, the gradient of each weight is individually clipped so that its norm is no higher than this value. If global_clipnorm (float) is set the gradient of all weights is clipped so that their global norm is no higher than this value.""

### Standalone code to reproduce the issue

```shell
import tensorflow as tf

mnist = tf.keras.datasets.mnist

(x_train, y_train),(x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1)
adam_opt.global_clipnorm = 0.5

def create_model():
  return tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
  ])

model = create_model()
model.compile(optimizer=adam_opt, loss='sparse_categorical_crossentropy')

print(f""{model.optimizer.clipnorm=}, {model.optimizer.global_clipnorm=}"")
model.save('mnist_model.tf')

saved_model = tf.keras.models.load_model('mnist_model.tf')
```


### Relevant log output

```shell
model.optimizer.clipnorm=1, model.optimizer.global_clipnorm=0.5
INFO:tensorflow:Assets written to: mnist_model.tf/assets

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Input In [34], in <cell line: 24>()
     21 print(f""{model.optimizer.clipnorm=}, {model.optimizer.global_clipnorm=}"")
     22 model.save('mnist_model.tf')
---> 24 saved_model = tf.keras.models.load_model('mnist_model.tf')

File ~/anaconda3/envs/tf2/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File ~/anaconda3/envs/tf2/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py:427, in OptimizerV2.__init__(self, name, gradient_aggregator, gradient_transformers, **kwargs)
    425 self.global_clipnorm = kwargs.pop(""global_clipnorm"", None)
    426 if self.clipnorm is not None and self.global_clipnorm is not None:
--> 427     raise ValueError(
    428         ""Cannot accept both `clipnorm` and `global_clipnorm`. ""
    429         ""Received: `clipnorm`={}, `global_clipnorm`={}."".format(
    430             self.clipnorm, self.global_clipnorm
    431         )
    432     )
    433 self.clipvalue = kwargs.pop(""clipvalue"", None)

ValueError: Cannot accept both `clipnorm` and `global_clipnorm`. Received: `clipnorm`=1, `global_clipnorm`=0.5.
```
</details>"
58654,ios armv7 compile fail (cmake),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10 or 2.11

### Custom Code

No

### OS Platform and Distribution

ios

### Mobile device

ios

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happen
I compile ios armv7，can not compile ok.
armv7/xnnpack/src/qc8-dwconv/up8x3-minmax-fp32-aarch32-neonv8-mla8-cortex-a35.S:118:9: error: instruction requires: armv8
VCVTN.S32.F32 q12, q12
I find many  error like this.
Thank you very much!

In addition, xnnpack code has following part，
 SET_PROPERTY(SOURCE ${AARCH32_ASM_MICROKERNEL_SRCS} APPEND_STRING PROPERTY COMPILE_FLAGS "" -march=armv8.2-a+dotprod -mfpu=neon-fp-armv8 "")
```


### Standalone code to reproduce the issue

```shell
1
```


### Relevant log output

_No response_</details>"
58652,Want to train some actions yourself,"Want to train some actions yourself, compile the file of the boss and report an error

bug position：
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

bug information：Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, DIV, EXPAND_DIMS, FLOOR_DIV, FULLY_CONNECTED, GATHER, MAXIMUM, MUL, PACK, REDUCE_MAX, RESHAPE, SOFTMAX, SQRT, SQUEEZE, STRIDED_SLICE, SUB, SUM. Here is a list of operators for which you will need custom implementations: BroadcastTo, Size.

add： converter.allow_custom_ops=True

final：16:23converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.allow_custom_ops=True
tflite_model = converter.convert()

This compilation is successful, but the tflite file will not run on the AS,why?help me"
58651,Is there a way to use a tflite-runtime version higher than 2.5.0 on an armv7 development board,"### 1. System information

- Linux Ubuntu 18.04
- armv7 board
- python3.6

### 2. question description

I trained a model on my linux server **(ubuntu18.04，Intel(R) Xeon(R) W-2145 CPU)** and exported it to tflite mode, and the model on the server **(tflite-runtime=2.10.0)** works fine.

Now I want to run the model on an **armv7** development board of zynq7000. The operating system running on my board version is ubuntu18.04, and **python3.6** and **tflite-runtime=2.5.0** is installed (2.5.0 seems is the highest version I can get on armv7), but when I run `interpreter = tflite.Interpreter(model_path=my_model)`, it throws `Segmentation fault (core dumped)` error.

After my test, if I downgrade the tflite-runtime on my linux server to version 2.5.0, the same error will be thrown. So I think the reason for the error may be that the version of tflite-runtime is too low.

But I can't get a higher version of tflite-runtime on armv7 board, does anyone know a solution please?


"
58650,"Thanks for pinging @bhack .  There's one internal failure that's likely caused by bad test - but the test itself is protected/hidden, so I can't verify or fix it.  I've reached out to the affected team.","        Thanks for pinging @bhack .  There's one internal failure that's likely caused by bad test - but the test itself is protected/hidden, so I can't verify or fix it.  I've reached out to the affected team.

_Originally posted by @cantonios in https://github.com/tensorflow/tensorflow/issues/58332#issuecomment-1295298881_
      "
58648,unit test //tensorflow/python/kernel_tests/math_ops:batch_matmul_op_test_gpu fails on P100,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.12

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.3.2

### GCC/Compiler version

 9.4.0

### CUDA/cuDNN version

cuda-11.2

### GPU model and memory

P100  16GB

### Current Behaviour?

```shell
Unit test //tensorflow/python/kernel_tests/math_ops:batch_matmul_op_test_gpu fails.
```


### Standalone code to reproduce the issue

```shell
bazel  test --config=cuda  --local_test_jobs=1 -c opt //tensorflow/python/kernel_tests/math_ops:batch_matmul_op_test_gpu
```


### Relevant log output

```shell
Part of failure log.
2022-11-22 12:30:06.893702: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1381] INTERNAL: cublas error
INFO:tensorflow:time(__main__.BatchMatmulGradientTest.testBatchMatmulGradientWithBroadcasting_bfloat16_False_False): 1.37s
I1122 12:30:06.894024 139912657315648 test_util.py:2457] time(__main__.BatchMatmulGradientTest.testBatchMatmulGradientWithBroadcasting_bfloat16_False_False): 1.37s
[  FAILED  ] BatchMatmulGradientTest.testBatchMatmulGradientWithBroadcasting_bfloat16_False_False
[ RUN      ] BatchMatmulGradientTest.testBatchMatmulGradientWithBroadcasting_float64_False_False
2022-11-22 12:30:06.898636: I tensorflow/compiler/xla/stream_executor/stream.cc:1100] [stream=0x16f3fc70,impl=0x3e86b30] did not wait for [stream=0x16f3fd20,impl=0x3e87be0]
2022-11-22 12:30:06.898847: F tensorflow/core/common_runtime/gpu/gpu_util.cc:390] CPU->GPU Memcpy failed
Fatal Python error: Aborted
```
</details>"
58645,SigmoidGrad legalization,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

master

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

We had a legalization error with the MLIR bridge with the sigmoid in the focal loss:
https://github.com/keras-team/keras-cv/blob/master/keras_cv/losses/focal.py#L82


### Standalone code to reproduce the issue

https://colab.research.google.com/gist/ianstenbit/6cbcf6e034fbf63e22208f3d9a479297/sigmoid-loss-issue-retinanet-on-tpu.ipynb

See also:
https://github.com/keras-team/keras-cv/issues/1018


### Relevant log output

```python
(0) INVALID_ARGUMENT: {{function_node __inference_train_function_133447}} TF to XLA legalization failed: <unknown>:0: error: loc(fused[""SigmoidGrad:"", ""gradient_tape/FocalLoss/Sigmoid/SigmoidGrad""]): 'mhlo.constant' op result #0 must be statically shaped tensor of floating-point or pred (AKA boolean or 1-bit integer) or 8/16/32/64-bit signless integer or 8/16/32/64-bit unsigned integer or complex type with 32-bit float or 64-bit float elements values, but got 'tensor<?x?x20xf32>'
<unknown>:0: note: loc(fused[""SigmoidGrad:"", ""gradient_tape/FocalLoss/Sigmoid/SigmoidGrad""]): see current operation: %5996 = ""mhlo.constant""() {value = dense<1.000000e+00> : tensor<?x?x20xf32>} : () -> tensor<?x?x20xf32>
```
</details>"
58644,AttributeError: 'Tensor' object has no attribute 'ndim',"Hello,

I'm doing data augmentation on tensorflow. With tf.image it works, but when I add code with tf.keras.preprocessing I have this error:

AttributeError: 'Tensor' object has no attribute 'ndim'

Here is my code :
```
def process_single_sample_train(img_path, label):

    # 1. Read image
    img = tf.io.read_file(img_path)

    # 2. Decode and convert to grayscale
    img = tf.io.decode_png(img, channels=3) # channels = 1 for grayscale

    # 3. Convert to float32 in [0, 1] range
    img = tf.image.convert_image_dtype(img, tf.float32)

    # 4. Resize to the desired size
    img = tf.image.resize(img, [32, 128])
    
    # 5. Augment
    rand_ = tf.random.uniform(shape=(), minval=0, maxval=1)
    if rand_ < 0.8:
        img = tf.image.random_contrast(img, lower=0.7, upper=1)
        
        ## THIS LINE CAUSES THE BUG
        img = tf.convert_to_tensor(tf.keras.preprocessing.image.random_rotation(img, rg=5))
        
    return {""image"": img, ""label"": label}
```
Bug when I run this : 
```
train_dataset = (
    train_dataset.map(
        process_single_sample_train, num_parallel_calls=tf.data.experimental.AUTOTUNE
    )
    .batch(batch_size)
    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
)
```
"
58642,MoviNet has memory leak,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10 (recreated in Ubuntu 20.4)

### Mobile device

NA

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2 / 8.1

### GPU model and memory

_No response_

### Current Behaviour?

Repeated inference calls to MoviNet (loaded from SavedModel) continuously increase memory usage until a crash occurs.



### Standalone code to reproduce the issue


The process to recreate is somewhat long, so full code cannot be provided. The steps are:

1. Create movinet network:
```shell
    from official.projects.movinet.modeling import movinet, movinet_layers, movinet_model
    backbone = movinet.Movinet(model_id=model_id)   # output_states=False
    model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600, output_states=False)
    model.build([1, 1, 1, 1, 3])

    checkpoint_dir = download_and_extract_file(model_id=model_id)
    checkpoint_path = os.path.join(checkpoint_dir, 'ckpt-1')
    checkpoint = tf.train.Checkpoint(model=model)
    status = checkpoint.restore(checkpoint_path)
    status.assert_existing_objects_matched()

    model = build_classifier(backbone=backbone, input_shape= input_shape, num_classes=n_output_classes,
                             movinet_layers_to_freeze = movinet_layers_to_freeze)
```

2. Fine-tune the model

3. Convert to savedmodel:
```
tf.keras.models.save_model(self.net, path, signatures=None)
```

4. Load savedmodel:
```
model = tf.keras.models.load_model(savedmodel_path, custom_objects={'tf': tf, 'K': tf.keras.backend})
```

5. Perform inference in a for loop:
```
for i in range(n_samples):
    out[i] = model(input[i], training=training)
```


### Relevant log output

I have ran this from my Windows PC, as well as EC2 instances with and without a GPU. I used ClearML to log machine stats over iterations and saw the following:

CPU-Only:
![image](https://user-images.githubusercontent.com/19536781/203179971-490e64f6-b198-43c6-a2dc-500c8190ccae.png)

Note that in the beginning, there is alot of writing to disk (orange) while RAM stays constant (blue). After a certain amount of writing to disk, RAM starts being used until it is depleted and program crashes. 

GPU:
The same behavior appears on GPU machines, with the addition that when it starts writing to RAM, GPU starts filling up as well (top plot, blue/green lines):
![image](https://user-images.githubusercontent.com/19536781/203180382-19affc22-bd43-4dc0-8a48-e97e7e80422d.png)

I have tried this on my windows machine as well, and observed the same behavior (RAM usage increasing until crash occurs) in Task Manager. 

```
</details>"
58641,tf.io.gfile.rename cause UnicodeError on non-English Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tensorflow-2.9.1

### Custom Code

No

### OS Platform and Distribution

Windows 10 Family Chinese

### Mobile device

_No response_

### Python version

3.10.6 (conda)

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

The problem is first caused by the rename issue at https://github.com/tensorflow/tensorflow/issues/45980

Even when this rename error happen, it should produce 

```
tensorflow.python.framework.errors_impl.UnknownError: Failed to rename: <src> <tar> : Access is denied.
; Input/output error`
```

However, when the language of Windows is set to be non-English language, like Chinese, it cause `UnicodeError` like

```
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 143: invalid start byte
```

I guess the reason is that, the `""Access is denied""` is actually the error message formatted by Win32 `FormatError()` (https://learn.microsoft.com/en-us/windows/win32/api/winbase/nf-winbase-formatmessage). When `dwLanguageId` is set to be something like `MAKELANGID(NEUTRAL, SUBLANG_DEFAULT)`, it will produce a Chinese encoding error message `""拒绝访问""` in `cp936` (`gbk`) encoding when the system code page is `936` (Simplified Chinese with `gbk` encoding). When you want to decode it as python string using `utf-8` encoding, it cause this problem. 

Note `""拒绝访问""` in `gbk` is `""\xbe\xdc\xbe\xf8\xb7\xc3\xce\xca""`.


### Standalone code to reproduce the issue

Just follow the official tutorial at https://www.tensorflow.org/tutorials/images/data_augmentation

```
(train_ds, val_ds, test_ds), metadata = tfds.load(
    'tf_flowers',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)
```


### Relevant log output

```
WARNING:tensorflow:From <conda_env_path>\lib\site-packages\tensorflow_datasets\core\file_format_adapter.py:209: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.
Instructions for updating:
Use eager execution and: 
`tf.data.TFRecordDataset(path)`

---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
Cell In [2], line 3
      1 # Load Data
----> 3 (train_ds, val_ds, test_ds), metadata = tfds.load(
      4     'tf_flowers',
      5     split = ['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
      6     with_info = True,
      7     as_supervised = True,
      8 )

File <conda_env_path>\lib\site-packages\tensorflow_datasets\core\api_utils.py:52, in disallow_positional_args.<locals>.disallow_positional_args_dec(fn, instance, args, kwargs)
     50 _check_no_positional(fn, args, ismethod, allowed=allowed)
     51 _check_required(fn, kwargs)
---> 52 return fn(*args, **kwargs)

File <conda_env_path>\lib\site-packages\tensorflow_datasets\core\registered.py:300, in load(name, split, data_dir, batch_size, in_memory, shuffle_files, download, as_supervised, decoders, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)
    298 if download:
    299   download_and_prepare_kwargs = download_and_prepare_kwargs or {}
--> 300   dbuilder.download_and_prepare(**download_and_prepare_kwargs)
    302 if as_dataset_kwargs is None:
    303   as_dataset_kwargs = {}

File <conda_env_path>\lib\site-packages\tensorflow_datasets\core\api_utils.py:52, in disallow_positional_args.<locals>.disallow_positional_args_dec(fn, instance, args, kwargs)
     50 _check_no_positional(fn, args, ismethod, allowed=allowed)
     51 _check_required(fn, kwargs)
---> 52 return fn(*args, **kwargs)

File <conda_env_path>\lib\site-packages\tensorflow_datasets\core\dataset_builder.py:281, in DatasetBuilder.download_and_prepare(self, download_dir, download_config)
    278 self._log_download_bytes()
    280 # Create a tmp dir and rename to self._data_dir on successful exit.
--> 281 with file_format_adapter.incomplete_dir(self._data_dir) as tmp_data_dir:
    282   # Temporarily assign _data_dir to tmp_data_dir to avoid having to forward
    283   # it to every sub function.
    284   with utils.temporary_assignment(self, ""_data_dir"", tmp_data_dir):
    285     self._download_and_prepare(
    286         dl_manager=dl_manager,
    287         download_config=download_config)

File <conda_env_path>\lib\contextlib.py:142, in _GeneratorContextManager.__exit__(self, typ, value, traceback)
    140 if typ is None:
    141     try:
--> 142         next(self.gen)
    143     except StopIteration:
    144         return False

File <conda_env_path>\lib\site-packages\tensorflow_datasets\core\file_format_adapter.py:200, in incomplete_dir(dirname)
    198 try:
    199   yield tmp_dir
--> 200   tf.io.gfile.rename(tmp_dir, dirname)
    201 finally:
    202   if tf.io.gfile.exists(tmp_dir):

File <conda_env_path>\lib\site-packages\tensorflow\python\lib\io\file_io.py:620, in rename_v2(src, dst, overwrite)
    607 @tf_export(""io.gfile.rename"")
    608 def rename_v2(src, dst, overwrite=False):
    609   """"""Rename or move a file / directory.
    610 
    611   Args:
   (...)
    618     errors.OpError: If the operation fails.
    619   """"""
--> 620   _pywrap_file_io.RenameFile(
    621       compat.path_to_bytes(src), compat.path_to_bytes(dst), overwrite)

UnicodeDecodeError: 'utf-8' codec can't decode byte 0xbe in position 143: invalid start byte
```
</details>"
58636,CMake build system Tensorflow Lite v2.11.0 is broken,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11.0

### Custom Code

No

### OS Platform and Distribution

Android

### Mobile device

N/A

### Python version

3.9

### Bazel version

N/A

### GCC/Compiler version

Android NDK 24

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

Unable to cross compile TFLite 2.11.0 for Android, using CMake.

Here is the command I used to build:

```shell
mkdir tflite.build.android && cd tflite.build.android

cmake -G ""Unix Makefiles"" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite

make -j4
```
, and I get the following error:
```
 28%] Linking CXX executable flatc
cd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1
/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm 
Running scripts/generate_code.py...
cd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection
Traceback (most recent call last):
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 148, in <module>
    flatc(
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 82, in flatc
    result = subprocess.run(cmd, cwd=str(cwd), check=True)
  File ""/usr/lib/python3.9/subprocess.py"", line 505, in run
    with Popen(*popenargs, **kwargs) as process:
  File ""/usr/lib/python3.9/subprocess.py"", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File ""/usr/lib/python3.9/subprocess.py"", line 1821, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'
make[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1
make[2]: *** Deleting file '_deps/flatbuffers-build/flatc'
make[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2
make[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make: *** [Makefile:139: all] Error 2
```

The problem seems to be that Python tries to invoke the `flatbuffers/scripts/generate_code.py` script, which attempts to run `/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc`, which does not exist. 

TFLite v2.10.1 builds fine, but as far as I can tell, for v2.10.1m there is no attempt to invoke `generate_code.py` or `_deps/flatbuffers-build/flatc`

Based on [https://www.tensorflow.org/lite/guide/build_cmake#specifics_of_kernel_unit_tests_cross-compilation](url), I also tried building flatc separately, but I get the following CMake warning when running: `mkdir flatc-native-build && cd flatc-native-build && cmake ../tensorflow/tensorflow/lite/tools/cmake/native_tools/flatbuffers`

```
CMake Warning at CMakeLists.txt:43 (find_package):
  By not providing ""Findflatbuffers.cmake"" in CMAKE_MODULE_PATH this project
  has asked CMake to find a package configuration file provided by
  ""flatbuffers"", but CMake did not find one.

  Could not find a package configuration file provided by ""flatbuffers"" with
  any of the following names:

    flatbuffersConfig.cmake
    flatbuffers-config.cmake

  Add the installation prefix of ""flatbuffers"" to CMAKE_PREFIX_PATH or set
  ""flatbuffers_DIR"" to a directory containing one of the above files.  If
  ""flatbuffers"" provides a separate development package or SDK, be sure it
  has been installed.
```
subsequently running `cmake --build .` does not build the flatc executable.

### Standalone code to reproduce the issue

```shell
mkdir tflite.build.android && cd tflite.build.android

cmake -G ""Unix Makefiles"" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite

make -j4
```

### Relevant log output

```shell
28%] Linking CXX executable flatc
cd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1
/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm 
Running scripts/generate_code.py...
cd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection
Traceback (most recent call last):
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 148, in <module>
    flatc(
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 82, in flatc
    result = subprocess.run(cmd, cwd=str(cwd), check=True)
  File ""/usr/lib/python3.9/subprocess.py"", line 505, in run
    with Popen(*popenargs, **kwargs) as process:
  File ""/usr/lib/python3.9/subprocess.py"", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File ""/usr/lib/python3.9/subprocess.py"", line 1821, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'
make[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1
make[2]: *** Deleting file '_deps/flatbuffers-build/flatc'
make[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2
make[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make: *** [Makefile:139: all] Error 2
```
</details></details>"
58635,"Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter.","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04

### Mobile device

arm64-v8a

### Python version

3.7

### Bazel version

5.3.0

### GCC/Compiler version

7.5

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Got an error ""Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select. Node number 83 (FlexErf) failed to prepare.""
```


### Standalone code to reproduce the issue

```shell
Hi, I try to make inference with flex delegate supported tflite model in Android(arm64-v8a) using C++ language. 
I have build tensorflowlite_flex lib and TensorflowLite as below using bazel command on ubuntu system : 
'''
bazel build -c opt --cxxopt=--std=c++17 tensorflow/lite/delegates/flex:tensorflowlite_flex --config=monolithic --config=android_arm64 --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
bazel build -c opt --cxxopt=--std=c++17  //tensorflow/lite:tensorflowlite --config=android_arm64 --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
'''

I linked that two library using CMake on Android Studio(Windows 10). 
Sample CMake snippet:
'''
add_library(tensorflowlite SHARED IMPORTED)
set_target_properties( tensorflowlite PROPERTIES IMPORTED_LOCATION
                    ""${CMAKE_CURRENT_SOURCE_DIR}/tflite_cpp/lib/arm64-v8a/libtensorflowlite.so"")
add_library(tensorflowlite_flex SHARED IMPORTED)
set_target_properties( tensorflowlite_flex PROPERTIES IMPORTED_LOCATION
                        ""${CMAKE_CURRENT_SOURCE_DIR}/tflite_cpp/lib/arm64-v8a/libtensorflowlite_flex.so"")
target_link_libraries(
        privacy_cpp
        tensorflowlite
        -Wl,--no-as-needed # Need --no-as-needed to link tensorflowlite_flex
        tensorflowlite_flex
        android)
'''

But the error log shows ""Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter."" What am I doing wrong here? Thank you.
'''
AAsset *model_fp= AAssetManager_open(mgr, ""torch_bert.tflite"", AASSET_MODE_STREAMING );
size_t size = AAsset_getLength(model_fp);
char * buf = new char[size];
memmove(buf, AAsset_getBuffer(model_fp), size);
std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromBuffer((const char*)buf, size);
tflite::ops::builtin::BuiltinOpResolver resolver;
tflite::InterpreterBuilder(*model, resolver)(&interpreter);
'''
```


### Relevant log output

_No response_</details>
<img width=""908"" alt=""tflite_error"" src=""https://user-images.githubusercontent.com/105635332/203116570-e4b7a370-1f07-47c3-93c3-3cc47ec7db7b.png"">

"
58634,Wrong invert code in Keras Normalization Layer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The following code is an excerpt from `class Normalization` of `keras.layers.Normalization`.

    def call(self, inputs):
        inputs = self._standardize_inputs(inputs)
        # The base layer automatically casts floating-point inputs, but we
        # explicitly cast here to also allow integer inputs to be passed
        inputs = tf.cast(inputs, self.compute_dtype)
        if self.invert:
            return (inputs + self.mean) * tf.maximum(
                tf.sqrt(self.variance), backend.epsilon()
            )
        else:
            return (inputs - self.mean) / tf.maximum(
                tf.sqrt(self.variance), backend.epsilon()
            )

The code in the `self.invert == True` branch does not invert the code in the `self.invert == False` branch as it shall according to the API documentation, which states that ""... layer ... would turn a normalized input back into its original form"".
```


### Standalone code to reproduce the issue

```shell
The correct code is:

    def call(self, inputs):
        inputs = self._standardize_inputs(inputs)
        # The base layer automatically casts floating-point inputs, but we
        # explicitly cast here to also allow integer inputs to be passed
        inputs = tf.cast(inputs, self.compute_dtype)
        if self.invert:
            return self.mean + inputs * tf.maximum(
                tf.sqrt(self.variance), backend.epsilon()
            )
        else:
            return (inputs - self.mean) / tf.maximum(
                tf.sqrt(self.variance), backend.epsilon()
            )
```


### Relevant log output

_No response_</details>"
58633,TensorFlow Lite Quantization Debugger Issue,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.3 
- TensorFlow library (version, if pip package or github SHA, if built from source):tensorflow-gpu==2.10.0

### 2. Code

def dense_block(inputs, filters):

    y = Dense(units=filters,use_bias=False)(inputs)
    y = BatchNormalization()(y)
    return y

def model():
    inputs = Input(shape = (112, 112, 3))
    .
    .
    .
    .
    .
    .
    .
    x = dense_block(x, 1)  -> (input_size=1,1,1,256, output_size=1,1,1,1)
    return Model(inputs, x)

### 3. conversion is successful,but the predicted value of int8 tflite has a large error value with the .pb weights file
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and accuracy drop 7~15%.

### 5. (optional) Any other info / logs

Question1:
My weights .pb file is successfully quantized into an int8 tflite model.
When doing tf.lite.experimental.QuantizationDebugger, the rmse/scale value of the last layer(Conv2D) is 2, which is far more than 0.289, but the rmse/scale values ​​in other layers are all It is around 0.289, and if I change the output of the last layer to more nodes, the value of rmse/scale of the last layer will be closer to 0.289.

Does anyone know what could be causing this to happen?
thanks!"
58631,Spam,spam removed
58630,Bazel build failure,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.4.1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04.6 LTS

### Mobile device

_No response_

### Python version

3.6.9

### Bazel version

3.1.0

### GCC/Compiler version

7.5.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

Jetson Nano, 32GB of memory

### Current Behaviour?

Compiling Tensorflow fails at the end of the process without being able to compile the pooling_ops_gpu file. I am trying to compile Tensorflow in order to enable the tflite_with_xnnpack flag



### Standalone code to reproduce the issue

```shell
This is the Tensorflow configuration pre-build 

You have bazel 3.1.0- (@non-git) installed.
Please specify the location of python. [Default is /usr/bin/python3]: /usr/bin/python3


Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.6/dist-packages
  /usr/lib/python3.6/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]: /usr/lib/python3/dist-packages

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.

Found CUDA 10.2 in:
    /usr/local/cuda-10.2/targets/aarch64-linux/lib
    /usr/local/cuda-10.2/targets/aarch64-linux/include
Found cuDNN 8 in:
    /usr/lib/aarch64-linux-gnu
    /usr/include
Found TensorRT 7 in:
    /usr/lib/aarch64-linux-gnu
    /usr/include/aarch64-linux-gnu


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 5.3


Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/gcc


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: -Wno-sign-compare


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n

And this is the bezel build command used 

sudo bazel --host_jvm_args=-Xmx3278m build --config=opt --config=noaws --config=nogcp --config=nohdfs --config=nonccl --config=monolithic --config=cuda --config=v2 --local_cpu_resources=1 --define=tflite_pip_with_flex=true --copt=-ftree-vectorize --copt=-funsafe-math-optimizations --copt=-ftree-loop-vectorize --copt=-fomit-frame-pointer --define tflite_with_xnnpack=true //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
ERROR: /home/user/tensorflow/tensorflow/core/kernels/BUILD:4193:1: C++ compilation of rule '//tensorflow/core/kernels:pooling_ops_gpu' failed (Exit 4)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/user/tensorflow/tensorflow/python/tools/BUILD:226:1 C++ compilation of rule '//tensorflow/core/kernels:pooling_ops_gpu' failed (Exit 4)
INFO: Elapsed time: 165525.324s, Critical Path: 2097.12s
INFO: 13887 processes: 13887 local.
FAILED: Build did NOT complete successfully
```
</details>"
58629, Cannot build with CUDA support on Windows.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

TF 2.11

### Custom Code

No

### OS Platform and Distribution

Windows 11

### Mobile device

_No response_

### Python version

3.10

### Bazel version

5.3.2

### GCC/Compiler version

MSVC 14.34.31933

### CUDA/cuDNN version

11.8/8.6

### GPU model and memory

RTX3090 24GB

### Current Behaviour?

```shell
When I'm trying to build the latest stable version TensorFlow-GPU (2.11.0) with CUDA on windows as same as we used to do, I find the following Errors

`WARNING: Cannot build with CUDA support on Windows. Starting in TF 2.11, CUDA build is not supported for Windows. To use TensorFlow GPU on Windows, you will need to build/install TensorFlow in WSL2.`

This error prevents me to set further CUDA and GPU info, as the consequence, I cannot build GPU version but only CPU version.
```


### Standalone code to reproduce the issue

```shell
As a normal compiling procedure:


python .\configure.py
```


### Relevant log output

```shell
You have bazel 5.3.2- (@non-git) installed.
Please specify the location of python. [Default is C:\Users\<username>\miniconda3\envs\compile\python.exe]:

Found possible Python library paths:
  C:\Users\<username>\miniconda3\envs\compile\Lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\<username>\miniconda3\envs\compile\Lib\site-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.

WARNING: Cannot build with CUDA support on Windows.
Starting in TF 2.11, CUDA build is not supported for Windows. For using TensorFlow GPU on Windows, you will need to build/install TensorFlow in WSL2.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:
```
</details>"
58628,tf.distribute.experimental.rpc.Server memory leak on server,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2/8.1

### GPU model and memory

Nvidia GeForce RTX 2070 6233MB

### Current Behaviour?

```shell
RPC works fine with CPU but when switched to GPU, memory increases linearly.
(Memory stays constant after awhile with CPU)

When training model, memory will keep increasing until desktop freezes.

Code below to reproduce the issue on Google Colab.
```


### Standalone code to reproduce the issue

```shell
# import os
# os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""

import tensorflow as tf
import numpy as np
import portpicker
import matplotlib.pyplot as plt

import time
import os
import psutil
process = psutil.Process(os.getpid())


#tf.debugging.set_log_device_placement(True)


def test_simple():

    @tf.function(input_signature=[
        tf.TensorSpec([], tf.int32),
        tf.TensorSpec([], tf.int32)])
    @tf.autograph.experimental.do_not_convert  
    def remote_fn(a, b):
        return tf.add(a,b)

    port = portpicker.pick_unused_port()
    address = ""localhost:{}"".format(port)
    server = tf.distribute.experimental.rpc.Server.create(""grpc"", address)
    server.register(""addition"", remote_fn)
    server.start()

    client = tf.distribute.experimental.rpc.Client.create(""grpc"",
                address=address, name=""test_client"")

    a = np.ones(shape=[100, 256], dtype=np.int32)
    b = np.ones(shape=[100, 256], dtype=np.int32)

    hist = []
    for i in range(100000):
        result = client.call(
            args=[a,b],
            method_name=""addition"",
            output_specs=tf.TensorSpec((), tf.int32))
        if result.is_ok():
            result.get_value()
        # value = client.addition_blocking(a,b)
        # print(value)

        if i % 1000 == 0:
            print(i, "": "", process.memory_info().rss/1024/1024, ""MB"")
            hist.append(process.memory_info().rss/1024/1024)

    server.close()
    print(""After shutdown: "", process.memory_info().rss/1024/1024)
    plt.plot(hist)
    plt.show()


test_simple()
```


### Relevant log output

```shell
909000 :  1414.50390625 MB
910000 :  1414.5078125 MB
911000 :  1414.5078125 MB
912000 :  1414.5078125 MB
913000 :  1414.5078125 MB
914000 :  1414.5078125 MB
915000 :  1414.51171875 MB
916000 :  1414.51171875 MB
917000 :  1414.51171875 MB
918000 :  1414.515625 MB
919000 :  1415.6640625 MB
920000 :  1416.796875 MB
921000 :  1416.796875 MB
922000 :  1416.796875 MB
923000 :  1417.75 MB
924000 :  1418.7109375 MB
925000 :  1418.7109375 MB
926000 :  1418.7109375 MB
927000 :  1418.7109375 MB
928000 :  1418.71484375 MB
929000 :  1418.84765625 MB
930000 :  1418.84765625 MB
931000 :  1418.8515625 MB
932000 :  1418.85546875 MB
933000 :  1419.62890625 MB
934000 :  1419.87890625 MB
935000 :  1420.37890625 MB
936000 :  1420.53125 MB
937000 :  1420.65625 MB
938000 :  1421.83984375 MB
939000 :  1421.84375 MB
940000 :  1422.74609375 MB
941000 :  1422.84375 MB
942000 :  1422.84375 MB
943000 :  1423.3515625 MB
944000 :  1423.8984375 MB
945000 :  1423.91015625 MB
946000 :  1425.5078125 MB
947000 :  1426.109375 MB
948000 :  1426.34765625 MB
949000 :  1426.34765625 MB
950000 :  1426.3515625 MB
951000 :  1426.3515625 MB
952000 :  1427.05859375 MB
953000 :  1427.37890625 MB
954000 :  1427.3828125 MB
955000 :  1428.90234375 MB
956000 :  1429.69140625 MB
957000 :  1429.6953125 MB
958000 :  1430.3046875 MB
959000 :  1432.421875 MB
960000 :  1432.421875 MB
961000 :  1432.421875 MB
962000 :  1432.82421875 MB
963000 :  1432.82421875 MB
964000 :  1432.82421875 MB
965000 :  1433.1328125 MB
966000 :  1433.1328125 MB
967000 :  1433.1328125 MB
968000 :  1433.1328125 MB
969000 :  1434.60546875 MB
970000 :  1434.60546875 MB
971000 :  1434.640625 MB
972000 :  1435.08203125 MB
973000 :  1435.0859375 MB
974000 :  1435.59765625 MB
975000 :  1436.98828125 MB
976000 :  1436.9921875 MB
977000 :  1437.125 MB
978000 :  1437.98828125 MB
979000 :  1441.01953125 MB
980000 :  1441.96875 MB
981000 :  1441.96875 MB
982000 :  1441.97265625 MB
983000 :  1441.97265625 MB
984000 :  1441.97265625 MB
985000 :  1441.97265625 MB
986000 :  1441.97265625 MB
987000 :  1441.97265625 MB
988000 :  1441.97265625 MB
989000 :  1441.97265625 MB
990000 :  1441.9765625 MB
991000 :  1441.9765625 MB
992000 :  1441.98046875 MB
993000 :  1444.41796875 MB
994000 :  1444.78515625 MB
995000 :  1444.78515625 MB
996000 :  1444.78515625 MB
997000 :  1446.05078125 MB
998000 :  1446.05078125 MB
999000 :  1446.05078125 MB
After shutdown:  1447.05078125
```
</details>"
58627,Failed to load the native TensorFlow runtime.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
58624,Nesting keras.Models makes tf.gradients() not update while training,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Nesting a keras.model  inside another one makes analytic gradients computed with tf.gradients() not update with training. On the toy example presented bellow, the inside network consists of a single multiplication with a trainable variable (i.e. Dense(1, use_bias=False)), computes derivative, and concatenas all 3 so  for input [x] output should be [x,a*x,a] (a is the traibale variable). Training this independently works as expected. 
But if you nest that inside another keras.model(), even a trivial one that multiplies *2, devides /2 (i.e. no change) and then calls the inside model, the gradient computation is unchanged after training. so after you train, the output is [x,a*x,a0] where a0 is the initial weight (1.5 vs 2 in my toy example). 
Computing gradients with tf.GradientTape as in here also has the exact same behaviour  https://www.tensorflow.org/guide/advanced_autodiff

My 'real world' project involved solving a differential equation using https://github.com/titu1994/tf_SIREN  and switching bewteen training inside and outside model. As gradients dont work properly this way, my workaround was to inline the code of inside model to outside, keep 2 model instances and manual copy weights from one to the other which feels very hacky and I am sure is not indeded.

Tested on tf 2.6,2.8,2.10 , both Ubuntu/Windows and the behaviour is identical everywhere.
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
tf.random.set_seed(0)

from tensorflow.keras.optimizers import Adam,SGD
from tensorflow.keras import Input, Model,Sequential
from tensorflow.keras.initializers import Constant
from tensorflow.keras.layers import Layer, Dense
from tensorflow.keras.layers import Concatenate, concatenate


tf.compat.v1.disable_eager_execution()

#trivial network doing multiplication by a single trainable variable
def inside_network():
    x = Input(1)    
        
    layer=Dense(1,activation='linear',use_bias=False, kernel_initializer=Constant(value=1.5)) 
    y=layer(x)    

    dy=tf.gradients(y,[x])[0]  
    #for weight a, output should be [x, ax, a]
    out= concatenate([x, y, dy],axis=-1)
    
    network = Model(inputs = x, outputs = out, name='inside_network')
    
    return network

def outside_network():
    x = Input((1))      
    y=2*x
    y=y*0.5
    model=inside_network()
    y=model(y)
    
    outside_network = Model(inputs = x, outputs = y, name='outside_network')
    return outside_network
    
def get_first_weights(mod):
    for layer in mod.layers:
        w=layer.get_weights()
        if len(w)>0:
            return w

Ndata=1024
np.random.seed(0)
xdata=np.random.rand(Ndata,1)
xdata[0:4,0]=np.arange(0,4)
a=2.0

data_train_target=np.concatenate([xdata, a*xdata, a*np.ones((Ndata,1))],axis=-1)
print('input :4',xdata[:4,:])
print('target :4',data_train_target[:4,:])

model1=inside_network()

model1.compile(optimizer=Adam(1e-2),  loss='mae') #
print('dense layer weights before training',get_first_weights(model1))

model1.fit(xdata,data_train_target,verbose=1,epochs=2,shuffle=True) #,batch_size=bs
   
print('dense layer weights after training',get_first_weights(model1))
           
dataout=model1.predict(xdata)
print('dataout',dataout[0:4])
print('target',data_train_target[0:4,:])

model2=outside_network()

model2.compile(optimizer=Adam(1e-2),  loss='mae') #

print('dense layer weights before training',get_first_weights(model2))



model2.fit(xdata,data_train_target,verbose=1,epochs=2,shuffle=True)

print('dense layer weights after training',get_first_weights(model2))

dataout2=model2.predict(xdata)
print('dataout2',dataout2[0:4])
print(data_train_target[:4,:])
```


### Relevant log output

```shell
input :4 [[0.]
 [1.]
 [2.]
 [3.]]
target :4 [[0. 0. 2.]
 [1. 2. 2.]
 [2. 4. 2.]
 [3. 6. 2.]]
2022-11-20 18:27:50.249131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:50.295560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:50.295870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:50.298148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:50.298388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:50.298603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:51.014096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:51.014341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:51.014531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-20 18:27:51.014710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8946 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5
dense layer weights before training [array([[1.5]], dtype=float32)]
Train on 1024 samples
Epoch 1/2
1024/1024 [==============================] - 1s 927us/sample - loss: 0.1731
Epoch 2/2
1024/1024 [==============================] - 0s 43us/sample - loss: 0.0320
dense layer weights after training [array([[2.011962]], dtype=float32)]
/home/flogothetis/.local/lib/python3.8/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  updates=self.state_updates,
dataout [[0.       0.       2.011962]
 [1.       2.011962 2.011962]
 [2.       4.023924 2.011962]
 [3.       6.035886 2.011962]]
target [[0. 0. 2.]
 [1. 2. 2.]
 [2. 4. 2.]
 [3. 6. 2.]]
dense layer weights before training [array([[1.5]], dtype=float32)]
Train on 1024 samples
Epoch 1/2
1024/1024 [==============================] - 0s 142us/sample - loss: 0.2240
Epoch 2/2
1024/1024 [==============================] - 0s 58us/sample - loss: 0.1774
dense layer weights after training [array([[2.0133402]], dtype=float32)]
dataout2 [[0.        0.        1.5      ]
 [1.        2.0133402 1.5      ]
 [2.        4.0266805 1.5      ]
 [3.        6.040021  1.5      ]]
[[0. 0. 2.]
 [1. 2. 2.]
 [2. 4. 2.]
 [3. 6. 2.]]
```
</details>"
58623,Android 12 TensorFlow ML operations are not supported by GPU delegate,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.9

### Custom Code

Yes

### OS Platform and Distribution

Android 12 (API 31)

### Mobile device

Google Pixel 4

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensorflow lite pose estimation Crashed when switched to GPU.
It says some TF operations are not supported by GPU delegate.
Interestingly when the API is 30 (Android 11) the app runs fine when changing to GPU CPU or NNAPI. No matter what tf model, Movenet lightning or thunder, int 8 or float 16.

I tried it on the TF lite example post estimation APP, changed the compile and target sdk to 31, it crashed with the same error.
```


### Standalone code to reproduce the issue

```shell
fun create(context: Context, device: Device, modelType: ModelType): MoveNet {
            val options = Interpreter.Options()
            var gpuDelegate: GpuDelegate? = null
            options.setNumThreads(CPU_NUM_THREADS)
            when (device) {
                Device.CPU -> {
                }
                Device.GPU -> {
                    gpuDelegate = GpuDelegate()
                    options.addDelegate(gpuDelegate)
                }
                Device.NNAPI -> options.setUseNNAPI(true)
            }
            return MoveNet(
                Interpreter(
                    FileUtil.loadMappedFile(
                        context,
                        if (modelType == ModelType.Lightning) LIGHTNING_FILENAME
                        else THUNDER_FILENAME
                    ), options
                ),
                gpuDelegate
            )
        }
```


### Relevant log output

```shell
java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: Following operations are not supported by GPU delegate:
    ARG_MAX: Operation is not supported.
    CAST: Not supported cast case
    CONCATENATION: OP is supported, but tensor type isn't matched!
    FLOOR_DIV: OP is supported, but tensor type isn't matched!
    GATHER_ND: Operation is not supported.
    MUL: OP is supported, but tensor type isn't matched!
    PACK: OP is supported, but tensor type isn't matched!
    RESHAPE: OP is supported, but tensor type isn't matched!
    SUB: OP
```
</details>"
58622,Tensorflow lite dynamic input,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 11
- TensorFlow installation (pip package or built from source):
pip 2.10


### 2. Code
inputs = tf.keras.layers.Input(shape=(None, None, 3), name='input_image')
model = tf.keras.Model(inputs, inputs)

input_image - [(None, None, None,  3)]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

input_image - [1 1 1 3]"
58621,Invalid argument in example,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.04.1

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2

### GPU model and memory

RTX 3090 24GB

### Current Behaviour?

```shell
This example returns invalid argument message, but it still runs. I wonder if that is a warning or error.

https://www.tensorflow.org/tutorials/images/classification
```


### Standalone code to reproduce the issue

https://www.tensorflow.org/tutorials/images/classification



### Relevant log output

```shell
layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer
```
</details>"
58620,TF 2.11 Error: ModuleNotFoundError: No module named 'tensorflow.compat',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Windows 11

### Mobile device

_No response_

### Python version

3.10.04

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I tried training my model that used the functional API and got this error:

ModuleNotFoundError: No module named 'tensorflow.compat'
```


### Standalone code to reproduce the issue

```shell
Don't have it.
```


### Relevant log output

```shell
from keras.layers import MaxPooling1D
  File ""C:\Development\Python\Python3104\lib\site-packages\keras\__init__.py"", line 21, in <module>
    from keras import models
  File ""C:\Development\Python\Python3104\lib\site-packages\keras\models\__init__.py"", line 18, in <module>
    from keras.engine.functional import Functional
  File ""C:\Development\Python\Python3104\lib\site-packages\keras\engine\functional.py"", line 24, in <module>
    import tensorflow.compat.v2 as tf
ModuleNotFoundError: No module named 'tensorflow.compat'
```
</details>"
58619,The experimental lcm function gives wrong result,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Linux (Google Colab)

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi. The code below shows the lcm for 21 and 7 is output as 15 for TensorFlow while it should clearly be 21. NumPy and JAX give the correct result of 21. This is the case for int8 although the output value is certainly not high enough to be causing any overflows etc. The result in case of int16 or higher is accurate (21). However, if the values were 2100 and 70 the result would be inaccurate for int16 in tensorflow again as opposed to np and jax.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

at = tf.constant([21], dtype=tf.int8)
bt = tf.constant([7], dtype=tf.int8)

an = np.array([21], dtype=np.int8)
bn = np.array([7], dtype=jnp.int8)

print(""tensorflow: "", tf.experimental.numpy.lcm(at, bt))
print(""numpy: "", np.lcm(an,bn))
```


### Relevant log output

```shell
tensorflow:  tf.Tensor([15], shape=(1,), dtype=int8)
numpy:  [21]
```
</details>"
58618,Compiling libtensorflow for ios issues : can't fine Eigen/Core,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

MacOs ventura 13.0

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

5.3.2

### GCC/Compiler version

clang 14.0 (Xcode shipped)

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hello !

I am not able to build libtensorflow.so for ios.
I just `./configure` and accepted all defaults.

I can build for my mac:
`bazel build -c opt //tensorflow:libtensorflow.so`
but cross compiling for ios
`bazel build -c opt --config=ios //tensorflow:libtensorflow.so`

gives me this error

`
ERROR: /Users/SX/Documents/soundx-ai/vendor/tensorflow/tensorflow/cc/saved_model/BUILD:319:11: Compiling tensorflow/cc/saved_model/metrics.cc failed: (Aborted): wrapped_clang_pp failed: error executing command external/local_config_cc/wrapped_clang_pp '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 32 arguments skipped)
In file included from tensorflow/cc/saved_model/metrics.cc:16:
In file included from ./tensorflow/cc/saved_model/metrics.h:25:
In file included from ./tensorflow/core/lib/monitoring/counter.h:19:
In file included from ./tensorflow/tsl/lib/monitoring/counter.h:85:
In file included from ./tensorflow/tsl/lib/monitoring/collection_registry.h:109:
In file included from ./tensorflow/tsl/lib/monitoring/collected_metrics.h:28:
In file included from ./tensorflow/tsl/lib/monitoring/metric_def.h:24:
In file included from ./tensorflow/tsl/lib/monitoring/types.h:22:
In file included from ./tensorflow/tsl/platform/types.h:21:
In file included from ./tensorflow/tsl/platform/bfloat16.h:20:
./third_party/eigen3/Eigen/Core:1:10: fatal error: 'Eigen/Core' file not found
#include ""Eigen/Core""
```

I have a eigen3 lib installed with brew, in my `/opt/homebrew/Cellar/eigen/3.4.0_1/include/eigen3/Eigen/Core`, but I did not get how I could give this information to bazel. I'm not able to play with the path directly.

Any clue to solve this problem ?

Thank you!
```


### Standalone code to reproduce the issue

```shell
bazel build -c opt --config=ios //tensorflow:libtensorflow.so
```


### Relevant log output

_No response_</details>"
58616,ComputeH2D is more priority than FeaturesH2D,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux

### Mobile device

no

### Python version

2.7

### Bazel version

master

### GCC/Compiler version

10.2.0

### CUDA/cuDNN version

CUDA Version: 11.4

### GPU model and memory

yes

### Current Behaviour?

**BackGround 1**: CUDA only support once H2D in the same time .
**BackGround 2**: 
  1. **FeaturesAsyncH2D**: TrainingData H2D by `dataset.prefetch_to_device`
  2. **ComputeOpH2D**: Some small H2D in Op. for example: DynamicPartitionOpGPU:  compute output size on CPU, and then transfer size to GPU.

**BackGround 3**: **ComputeOpH2D** maybe block current compute, and **FeaturesAsyncH2D** is needed to next few steps, so **ComputeOpH2D** is more important than **FeaturesAsyncH2D**.

When lots of features need AsyncH2D, they maybe block ComputeOpH2D, because TF don't distinguish the priority of ComputeOpH2D and FeaturesAsyncH2D. 
we use nsys to recurrent this bug:
<img width=""1560"" alt=""image"" src=""https://user-images.githubusercontent.com/33950866/202851210-cb72e589-9dec-4a85-a35b-365b63ace052.png"">

</details>"
58614,Gradient return None,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I implement a model with a custom training loop and custom loss function. Loss function return a float value. But while calculate gradient tf.gradient(loss,model.trainable_weights), It gives None gradient.  I know the issue is way of calculate loss. I tried with custom mse loss. It works fine. I want to implement loss function like count_predition_0's+count_predition_1's/label_0's+label_1's. It's a binary classification problem. I set batch size is 100. So model return 100 batch output. I only consider few batch eg out of 100 batch i only consider or filter it out 40 based on input. Both label and prediction in same shape that is not issue here. That label and prediction pass to custom_loss function.
```


### Standalone code to reproduce the issue

```shell
def custom_loss(self,output,prediction):
        
     correct_count=tf.math.count_nonzero(tf.math.equal(tf.round(prediction),tf.cast(output,tf.float32)))
        incorrect_count=prediction.shape[0]-correct_count

        incorrect_label_count=tf.where(output==0.0).shape[0]
        correct_label_count=tf.where(output==1.0).shape[0]
            
        return tf.math.divide(tf.math.add(correct_count,incorrect_count),output.shape[0])
```


### Relevant log output

```shell
ValueError: No gradients provided for any variable: (['my_model/object/embeddings:0', 'my_model/dense/kernel:0', 'my_model/dense/bias:0', 'my_model/dense_1/kernel:0', 'my_model/dense_1/bias:0', 'my_model/dense_2/kernel:0', 'my_model/dense_2/bias:0', 'my_model/dense_3/kernel:0', 'my_model/dense_3/bias:0', 'my_model/dense_4/kernel:0', 'my_model/dense_4/bias:0', 'my_model/dense_5/kernel:0', 'my_model/dense_5/bias:0', 'my_model/dense_6/kernel:0', 'my_model/dense_6/bias:0', 'my_model/dense_7/kernel:0', 'my_model/dense_7/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'my_model/object/embeddings:0' shape=(263, 100) dtype=float32, numpy=
```
</details>"
58613,Tensorflow Lite C API works much slower than C++ API,"### Issue Type

Performance

### Source

source

### Tensorflow Version

tflite v2.4.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04.6 LTS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

CMake was used

### GCC/Compiler version

gcc 7.5.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I built TFLite v2.4.0 static library and used in our project using C++ API 

(we are using it cross-platform Ubuntu/Android/iOS). It shows inference time 5-10 ms on Ubuntu 18. 

We decided to switch to C API (iOS xcframework is available on C). But I see that on 

C API inference time becomes 45-50 ms. I tried to test using TFLite v2.10.0 C API 

and it shows 180-200 ms. The model tested in Ubuntu is a small OCR model 

with size smaller than 200 KB.
```


### Standalone code to reproduce the issue

```shell
I can't upload the whole files, so here is snippets:

class TextRecognizer {
    ...
    virtual TfLiteModel* getModel() = 0;
    TfLiteInterpreterOptions* options;
    TfLiteInterpreter* interpreter;
};
```

Cpp file:
```
vdoc::TextLinePrediction vdoc::TextRecognizer::predict(const cv::Mat &srcImage) {
    ...
    options = TfLiteInterpreterOptionsCreate();
    interpreter = TfLiteInterpreterCreate(getModel(), options);
    TfLiteInterpreterAllocateTensors(interpreter);
    ...
    TfLiteTensor *input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);
    TfLiteTensorCopyFromBuffer(input_tensor, convertedImage.data,
                                   convertedImage.total() * convertedImage.elemSize());
    TfLiteInterpreterInvoke(interpreter);
    const TfLiteTensor *output_tensor = TfLiteInterpreterGetOutputTensor(interpreter, 0);
    float *output = output_tensor->data.f;
    ...
}
```


### Relevant log output

```shell
Output is measured time of each TFLite method call:
Time taken to init interpreter: 0.00191s
Time taken to allocate tensors: 0.00060s
Time taken to copy buffer data: 0.00031s
Time taken to Invoke inference: 0.05476s

As I mentioned before on C++ API inference time is about 10 times faster 0.005s.
```
"
58612,Wrong barplot x-labels in https://www.tensorflow.org/tutorials/audio/simple_audio,"I think that in the notebook https://www.tensorflow.org/tutorials/audio/simple_audio this line:

`plt.bar(commands, tf.nn.softmax(prediction[0]))`

should be replaced with:

`x_labels = ['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']`
`plt.bar(x_labels, tf.nn.softmax(prediction[0]))`

As a result, the graph will correctly show the probabilities for all classes. 

"
58611,Tensorflow Lite 2.11.0-rc2 CMake build system broken,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11.0-rc2

### Custom Code

No

### OS Platform and Distribution

Android

### Mobile device

N/A

### Python version

3.9

### Bazel version

N/A

### GCC/Compiler version

Android NDK 24

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

Unable to cross compile TFLite 2.11.0-rc2 for Android, using CMake.
I understand that v2.11.0 is still a release candidate. But I want to bring this issue to your attention. We rely heavily on TFLite (and the CMake workflow) in our production and we are looking forward to upgrading to v2.11.0, once it is officially released, to take advantage of fixes to long standing bugs and issues.

Here is the command I used to build:

```shell
mkdir tflite.build.android && cd tflite.build.android

cmake -G ""Unix Makefiles"" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite

make -j4
```
, and I get the following error:
```
 28%] Linking CXX executable flatc
cd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1
/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm 
Running scripts/generate_code.py...
cd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection
Traceback (most recent call last):
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 148, in <module>
    flatc(
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 82, in flatc
    result = subprocess.run(cmd, cwd=str(cwd), check=True)
  File ""/usr/lib/python3.9/subprocess.py"", line 505, in run
    with Popen(*popenargs, **kwargs) as process:
  File ""/usr/lib/python3.9/subprocess.py"", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File ""/usr/lib/python3.9/subprocess.py"", line 1821, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'
make[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1
make[2]: *** Deleting file '_deps/flatbuffers-build/flatc'
make[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2
make[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make: *** [Makefile:139: all] Error 2
```

The problem seems to be that Python tries to invoke the `flatbuffers/scripts/generate_code.py` script, which attempts to run `/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc`, which does not exist. 

TFLite v2.10.1 builds fine, but as far as I can tell, for v2.10.1m there is no attempt to invoke `generate_code.py` or `_deps/flatbuffers-build/flatc`

### Standalone code to reproduce the issue

```shell
mkdir tflite.build.android && cd tflite.build.android

cmake -G ""Unix Makefiles"" -DCMAKE_SYSTEM_NAME=Android -DANDROID_ABI=arm64-v8a -DANDROID_STL=c++_shared -DANDROID_NATIVE_API_LEVEL=27 -DCMAKE_VERBOSE_MAKEFILE=ON -DCMAKE_TOOLCHAIN_FILE=$HOME/Android/Sdk/ndk/24.0.8215888/build/cmake/android.toolchain.cmake -DTFLITE_ENABLE_XNNPACK=ON -DTFLITE_ENABLE_GPU=ON -DTFLITE_ENABLE_NNAPI=ON -DCMAKE_BUILD_TYPE=Release -DBUILD_SHARED_LIBS=OFF ../tensorflow/tensorflow/lite

make -j4
```

### Relevant log output

```shell
28%] Linking CXX executable flatc
cd /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/flatc.dir/link.txt --verbose=1
/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/bin/clang++ --target=aarch64-none-linux-android27 --sysroot=/home/myname/Android/Sdk/ndk/24.0.8215888/toolchains/llvm/prebuilt/linux-x86_64/sysroot -DANDROID -fdata-sections -ffunction-sections -funwind-tables -fstack-protector-strong -no-canonical-prefixes -D_FORTIFY_SOURCE=2 -Wformat -Werror=format-security -fexceptions -frtti -stdlib=libc++ -O3 -DNDEBUG -Wl,--build-id=sha1 -Wl,--no-rosegment -Wl,--fatal-warnings -Qunused-arguments -Wl,--no-undefined  -Wl,--gc-sections CMakeFiles/flatc.dir/src/idl_parser.cpp.o CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o CMakeFiles/flatc.dir/src/reflection.cpp.o CMakeFiles/flatc.dir/src/util.cpp.o CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o CMakeFiles/flatc.dir/src/idl_gen_ts.cpp.o CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o CMakeFiles/flatc.dir/src/flatc.cpp.o CMakeFiles/flatc.dir/src/flatc_main.cpp.o CMakeFiles/flatc.dir/src/bfbs_gen_lua.cpp.o CMakeFiles/flatc.dir/src/code_generators.cpp.o CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o CMakeFiles/flatc.dir/grpc/src/compiler/ts_generator.cc.o -o flatc   -latomic -lm 
Running scripts/generate_code.py...
cd /home/myname/myworkingdir/tflite.build.android/flatbuffers && /usr/bin/python3.9 scripts/generate_code.py --flatc /home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc --skip-gen-reflection
Traceback (most recent call last):
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 148, in <module>
    flatc(
  File ""/home/myname/myworkingdir/tflite.build.android/flatbuffers/scripts/generate_code.py"", line 82, in flatc
    result = subprocess.run(cmd, cwd=str(cwd), check=True)
  File ""/usr/lib/python3.9/subprocess.py"", line 505, in run
    with Popen(*popenargs, **kwargs) as process:
  File ""/usr/lib/python3.9/subprocess.py"", line 951, in __init__
    self._execute_child(args, executable, preexec_fn, close_fds,
  File ""/usr/lib/python3.9/subprocess.py"", line 1821, in _execute_child
    raise child_exception_type(errno_num, err_msg, err_filename)
OSError: [Errno 8] Exec format error: '/home/myname/myworkingdir/tflite.build.android/_deps/flatbuffers-build/flatc'
make[2]: *** [_deps/flatbuffers-build/CMakeFiles/flatc.dir/build.make:566: _deps/flatbuffers-build/flatc] Error 1
make[2]: *** Deleting file '_deps/flatbuffers-build/flatc'
make[2]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make[1]: *** [CMakeFiles/Makefile2:4720: _deps/flatbuffers-build/CMakeFiles/flatc.dir/all] Error 2
make[1]: Leaving directory '/home/myname/myworkingdir/tflite.build.android'
make: *** [Makefile:139: all] Error 2
```
</details>"
58610,from keras.models import load_model raises no module named tensorflow.compat error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.11

### Custom Code

No

### OS Platform and Distribution

Windoes 11

### Mobile device

_No response_

### Python version

3.7.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When doing  keras.models import load_model, An error saying no module named tensorflow.compat appears
```


### Standalone code to reproduce the issue

```shell
Just open python 3.7 and type  keras.models import load_model
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""c:/Users/Noah Ryu/Coding/AI/Teachable Machine/Guesser3.py"", line 1, in <module>
    from keras.models import load_model # TensorFlow is needed for Keras to work
  File ""C:\Users\Noah Ryu\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 21, in <module>
    from keras import models
  File ""C:\Users\Noah Ryu\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\models\__init__.py"", line 18, in <module>  
    from keras.engine.functional import Functional
  File ""C:\Users\Noah Ryu\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\engine\functional.py"", line 24, in <module>
    import tensorflow.compat.v2 as tf
ModuleNotFoundError: No module named 'tensorflow.compat'
```
</details>"
58609,gpu metal  lack  ”inference_context_generated.h“,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10 or 2.11

### Custom Code

Yes

### OS Platform and Distribution

ios

### Mobile device

iphone

### Python version

3.7

### Bazel version

no 

### GCC/Compiler version

no

### CUDA/cuDNN version

no

### GPU model and memory

111

### Current Behaviour?

```shell
A bug happened!
#include ""tensorflow/lite/delegates/gpu/metal/inference_context_generated.h""
But I can not find the inference_context_generated.h.WHy?
Thanks
```


### Standalone code to reproduce the issue

```shell
111
```


### Relevant log output

_No response_</details>"
58607,Tflite GPU Delegate error for FULLY_CONNECTED,"### 1. System information

- OS Platform and Distribution: Ubuntu 20.4
- TensorFlow installation: pip package
- TensorFlow library: 2.10


### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

Model is successfully converted. However, during benchmark with GPU delegate (1. using latest benchmark binary: https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary 2. using older benchmark binary), following error appears: 
1. ERROR: TfLiteGpuDelegate Init: Unrecognized Write selector
2. ERROR: TfLiteGpuDelegate Init: FULLY_CONNECTED: Amount of input data should match weights width

What is more interesting, if i convert the model using tensorflow 2.3.4, everything works as expected - i can run the benchmark without any problems. 
It seems that starting from tf 2.4, some bug was introduced... 

"
58606,TensorFlow Dataset.from_generator leaks memory for randomly generated samples (correlated with 'cuda_malloc_async'),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10, 2.9 tested as well

### Custom Code

No

### OS Platform and Distribution

Ubuntu Linux 22.04 and Google Colab tested

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.8

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When dataset is generated via `Dataset.from_generator`, samples that have already been used are not removed from GPU memory (or at least this is what I presume), leading to an increased use of VRAM and finally an OOM error as the training proceeds.

This is an important bug, since very often (as in this case) someone might use `from_generator` to perform augmentation etc, and It can be easily seen by examining the `GPU_mem_usage`, that the memory usage indeed grows. For some reason, Colab allocates memory straight away to ~8 GB, so the growth is only noticeable after around 300-500 epochs. The problem is way worse when training on real, larger datasets.

For a simple summary, just view the graphs on the end of the notebook.


Notice (in the notebook), that even though total memory taken on the GPU grows, TensorFlow ""thinks"" it is consuming basically constant amount of memory, which points into the direction of a memory leak.


Also, it takes around 900 epochs to fill almost the whole memory (16 GB in case of Colab). Epochs consist of 1024 images of shape (64, 64, 3), float32 dtype, giving 1024*3*64*64*900*4 bytes allocated in total, which is around 45 GB, so I presume not all memory is leaked, OR leaking data is not the cause of the problem.

Notice, however, that MobileNetV3 (which I have used in this example) is roughly 18MB in size, and 18MB*900 epochs is basically the aforementioned 16 GB. This could possibly mean that the model's state is leaked somehow, but I have yet to test this hypothesis (for example by using a larger model and checking when the leak happens, i.e. if `num_epochs_until_crash*model_size==gpu_vram_capacity`).


Also, I have tested multiple scenarios locally, and this seems NOT to happen without the `os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'` set, however I have no relevant logs to prove it, since when the flag is absent, whole GPU memory is allocated, and I have no means of monitoring it relevantly, since it doesn't change. I have, however, performed 4 tests and none resulted in OOM error after 1500 epochs, while locally they would usually throw OOM after 400 epochs (RTX 3060Ti).
```


### Standalone code to reproduce the issue

```shell
I have provided a minimal example on google colab, can be viewed here:
https://colab.research.google.com/drive/1-ANVp8KF9irKvqdR390QNlop-pPhGMrU?usp=sharing
I think the example is self-explanatory.
```


### Relevant log output

_No response_</details>"
58604,TF2.11 Release Estimate?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

TF2.11

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Noticed that there has been activity on the TF2.11 branch for release, and wanted to inquire if there was an ETA on this particular release, or a timeline on when we should expect another RC for TF2.11?
```


### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_</details>"
58603,TFLite benchmark tool - example to use input_layer_value_files,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: Source
-   **TensorFlow version (use command below)**: 
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
I am trying to use the Android TFLite benchmark tool to run inference time analysis for my TFLite model. Going through the [repo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark), I am interested in passing custom inputs to the benchmark tool. I am specifically looking for how to use input_layer_value_files flag. Could you provide an example of a sample file? Thanks!

### Source code / logs
-
"
58602,Tensorflow 2.10 cannot be installed using `poetry` on linux aarch64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

linux aarch64

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Poetry parses the endpoint at `https://pypi.org/pypi/tensorflow/2.10.0/json` to get dependency metadata. The endpoint returns:
```shell
[
  ""absl-py (>=1.0.0)"",
  ""astunparse (>=1.6.0)"",
  ""flatbuffers (>=2.0)"",
  ""gast (<=0.4.0,>=0.2.1)"",
  ""google-pasta (>=0.1.1)"",
  ""h5py (>=2.9.0)"",
  ""keras-preprocessing (>=1.1.1)"",
  ""libclang (>=13.0.0)"",
  ""numpy (>=1.20)"",
  ""opt-einsum (>=2.3.2)"",
  ""packaging"",
  ""protobuf (<3.20,>=3.9.2)"",
  ""setuptools"",
  ""six (>=1.12.0)"",
  ""termcolor (>=1.1.0)"",
  ""typing-extensions (>=3.6.6)"",
  ""wrapt (>=1.11.0)"",
  ""tensorflow-io-gcs-filesystem (>=0.23.1)"",
  ""grpcio (<2.0,>=1.24.3)"",
  ""tensorboard (<2.11,>=2.10)"",
  ""tensorflow-estimator (<2.11,>=2.10.0)"",
  ""keras (<2.11,>=2.10.0)""
]
```

However, the linux aarch64 wheel has different dependencies, namely `tensorflow-cpu-aws`. Since the dependency metadata is split across wheels, package managers like `poetry` are unable to resolve them correctly. 

**The solution is to have a unified list of dependencies across wheels, with PEP508 environment markers to specify platform-specific dependencies.**

### Standalone code to reproduce the issue

```shell
poetry add tensorflow@2.10.0
poetry shell
python -c ""import tensorflow""
```


### Relevant log output

```shell
(app-py3.8) root@53e9f35d6529:/app# python -c ""import tensorflow""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow'
```
</details>"
58599,there is no operator to calculate the matrix's inverse using tflite,"tf.raw_ops.MatrixInverse and tf.linalg.svd is not supported in tflite 
BatchMatrixInverse is not available in GraphDef version 1205.

Hence， how to calculate the matrix's inverse using tflite?

I need some Op to calculate the  matrix's inverse


best wishes




"
58592,DNN library is not found.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
trying to use mixed precision and feature-extraction for an efficientNetB0 model under tensorflow 2.10 and had to install the tf-nightly in order to make it happen before , is there any solution without the must of decreasing the tensorflow version ??
```


### Standalone code to reproduce the issue

```shell
UnimplementedError: Graph execution error
Node: 'model_2/efficientnetb0/stem_conv/Conv2D'
DNN library is not found.
	 [[{{node model_2/efficientnetb0/stem_conv/Conv2D}}]] [Op:__inference_train_function_32933]
```


### Relevant log output

_No response_</details>"
58755,No speed improvements after TF-TRT optimizing on a tensorflow BERT model,"# Prerequisites

Please answer the following questions for yourself before submitting an issue.

- [ Y] I am using the latest TensorFlow Model Garden release and TensorFlow 2.
- [ Y] I am reporting the issue to the correct repository. (Model Garden official or research directory)
- [ Y] I checked to make sure that this issue has not been filed already.

## 1. The entire URL of the file you are using

https://github.com/tensorflow/models/blob/master/official/nlp/modeling/models/bert_classifier.py

## 2. Describe the bug

After optimizing the model with either FP32 or FP16 I don't get any speed improvements. for int8 I get error in optimization.

## 3. Steps to reproduce

1-optimize with tensorRT
2- test the new mode (no change in inference time

## 4. Expected behavior

The inference time should be decreased after the optimization

## 5. Additional context

![image](https://user-images.githubusercontent.com/38143776/201936813-462dca3f-03a0-450e-aa0b-9ee388845704.png)
## 6. System information
- on docker image: tensorflow/tensorflow:2.10.0-gpu
- 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon linux
- Mobile device name if the issue happens on a mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.10
- Python version: 3.X
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2.1/8.1.0.77-1
- GPU model and memory: T4

<!-- 
Collect system information using our environment capture script.
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can also obtain the TensorFlow version with:

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->
"
58588,BinaryFocalCrossentropy loss not working,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2

### GPU model and memory

NVIDIA Quadro T2000

### Current Behaviour?

```shell
I'm not able to declare BinaryFocalCrossentropy loss function when apply_class_balancing or alpha arguments are provided.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
loss = tf.keras.losses.BinaryFocalCrossentropy(
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0
)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""C:\Users\User\AppData\Roaming\Python\Python39\site-packages\IPython\core\interactiveshell.py"", line 3251, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-8-235cf9a4168d>"", line 1, in <module>
    loss = tf.keras.losses.BinaryFocalCrossentropy(
TypeError: __init__() got an unexpected keyword argument 'apply_class_balancing'
```
</details>"
58587,tf.random.uniform generates identical random numbers when used  both inside and outside tf.while_loop  in a decorated function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8.1

### Custom Code

No

### OS Platform and Distribution

Mac Os Monterey

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When tf.random.uniform is called both inside and outside a tf.while_loop in a function decorated with tf.function, its internal counter is the same for both calls generating the same number. The expected behavior (which occur without decoration) is the internal counter to change and, thus, tf.random.uniform to generate two different outputs.
```


### Standalone code to reproduce the issue

```shell
max_steps=1

def condition(index,  random_num):
    return index < max_steps
def body(index,  random_num):
    return index+1, tf.random.uniform([1],dtype='float32')
@tf.function   
def function():
    index = tf.constant(0, dtype=""int8"")
    
    a=tf.random.uniform([1],dtype='float32')    
  
    index, random_num=tf.while_loop(condition,body,[index, tf.zeros([1],dtype='float32')])
    
#    b = tf.random.uniform([1])
#    c = tf.random.uniform([1])
    return a, random_num

a, b=function()

print(a, b) 

# the same random number is assigned both to  a and b (without decoration a and b would be two different random numbers)
```


### Relevant log output

_No response_</details>"
58556,Ubuntu 20.04 based Tensorflow images don't include Python 3.9 as indicated in the dockerhub docs,"I believe there is either a build issue or the [dockerhub docs](https://hub.docker.com/r/tensorflow/tensorflow) need to be clarified.

My understanding is that the image for the tensorflow:2.10.0 release (and other recent releases) is guaranteed to include Python 3.9 based on the following excerpts from the dockerhub docs:
- ""Images built after Sept 2021 are based on Ubuntu 20.04""
- ""... [Python] 3.9 for Ubuntu 20-based images""

When using the 2.10.0 image I find that the OS is correctly Ubuntu 20.04 but that the Python version is 3.8. Running the following commands indicate the absence of Python 3.9:
```shell
root@4fbf1b14a2dd:/# cat /etc/issue
Ubuntu 20.04.5 LTS \n \l
root@4fbf1b14a2dd:/# python3 -V
Python 3.8.10
root@4fbf1b14a2dd:/# ls /usr/bin/python*
/usr/bin/python3  /usr/bin/python3-config  /usr/bin/python3.8  /usr/bin/python3.8-config
```

I looked through the issues/pull requests and through stackoverflow and found no reports of this issue which I find surprising. That most likely means that I am just misinterpreting the guarantees made by the docs - but maybe this is sufficient support to clarify the docs further if that is the case?


### Standalone code to reproduce the issue

```shell
run --rm -it tensorflow/tensorflow:2.10.0 /bin/bash
```"
58555,InputSpec update breaks working code,"Description: I'm running code that used to work before a tensorflow/keras update. It is not obvious how the error message can be used to fix the problem, here is code, error and system information. Thanks for your help.

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler

# Importing the training set
dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')
training_set = dataset_train.iloc[:, 1:2].values

# Feature Scaling
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)

# Creating a data structure with 60 timesteps and 1 output
X_train = []
y_train = []
window_size = 60

for i in range(window_size, training_set_scaled.size):
    X_train.append(training_set_scaled[i-window_size:i, 0])
    y_train.append(training_set_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)

# Reshaping - where you will add features.... also for compatibility later
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Importing the Keras libraries and packages
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout
from keras.engine.input_spec import InputSpec

# Initialising the RNN
regressor = Sequential()

# Adding the first LSTM layer and some Dropout regularization
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))



#ERROR:
Traceback (most recent call last):

  File ""C:\Users\***\AppData\Local\Temp\ipykernel_28784\1308929883.py"", line 45, in <module>
    regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))

  File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\keras\layers\rnn\lstm.py"", line 529, in __init__
    ""`implementation=0` has been deprecated, ""

  File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\keras\engine\base_layer.py"", line 2864, in __setattr__
    outputs = tf.nest.pack_sequence_as(outputs, outputs_copy)

  File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\tensorflow\python\trackable\base.py"", line 205, in _method_wrapper
    result = method(self, *args, **kwargs)

  File ""C:\ProgramData\Anaconda3\envs\tf\lib\site-packages\keras\engine\base_layer.py"", line 1152, in input_spec

TypeError: Layer input_spec must be an instance of InputSpec. Got: InputSpec(ndim=3)

------------------------

### System information

-   **OS: Windows 10**:
-   **TensorFlow installed from (pip install per instructions here: https://www.tensorflow.org/install/pip#windows-native)**:
-   **TensorFlow version (2.10.0)**:
-   **Python version 3.9.13**:
-   **CUDA/cuDNN version cudatoolkit=11.2 cudnn=8.1.0**:
-   **GPU model and memory RTX 4090**:
-   **Exact command to reproduce**:


"
58552,Add support for None values in tf.distribute.ReplicaContext.all_reduce(),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.distribute.ReplicaContext.all_reduce()` does not accept `None` for its `value` argument. This results with very long and repative code for removing `None` values, calling `all_reduce()` then adding the `None` values back to the result. This happens often when dealing with gradient calculations, see e.g., https://github.com/keras-team/keras/blob/v2.10.0/keras/optimizers/optimizer_v2/utils.py#L23
(Note that this code sample is private and cannot be used by external users.)

Returning `None` when value is `None` should be very simple to do inside `all_reduce()` and will greatly simplify the calling code.
```


### Standalone code to reproduce the issue

```shell
resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect("""")
strategy = tf.distribute.TPUStrategy(resolver)

@tf.function
def step_fn():
  ctx = tf.distribute.get_replica_context()
  values = [tf.constant(1.), None]
  return ctx.all_reduce(tf.distribute.ReduceOp.SUM, values)

strategy.experimental_local_results(strategy.run(step_fn))
```


### Relevant log output

```shell
ValueError: None values not supported.
```
</details>"
58551,difference between core/grappler/optimizers/graph_optimizer.h and core/common_runtime/graph_optimizer.h,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.6

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
This is not a bug report, just a question.
Now I'm learning the source code of tensorflow and I can't understand the difference between these two graph_optimizer.h(core/grappler/optimizers/graph_optimizer.h and core/common_runtime/graph_optimizer.h). Can anyone explain this for me? Thanks.
```


### Standalone code to reproduce the issue

```shell
none
```


### Relevant log output

_No response_</details>"
58550,TF Lite C library fails to build,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux Debian 11 (bullseye)

### Mobile device

_No response_

### Python version

3.9.2

### Bazel version

_No response_

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Trying to build the [TensorFlow Lite C library](https://www.tensorflow.org/lite/guide/build_cmake#build_tensorflow_lite_c_library) following the official guide

errors with:


CMake Error at CMakeLists.txt:63 (add_library):
  Cannot find source file:

    c_api.cc
```
```


### Standalone code to reproduce the issue

```shell
git clone --depth 1 https://github.com/tensorflow/tensorflow
mkdir tflite_build
cd tflite_build
cmake ../tensorflow/tensorflow/lite/c
```
```


### Relevant log output

```shell
CMake Error at CMakeLists.txt:63 (add_library):
  Cannot find source file:

    c_api.cc

  Tried extensions .c .C .c++ .cc .cpp .cxx .cu .mpp .m .M .mm .ixx .cppm .h
  .hh .h++ .hm .hpp .hxx .in .txx .f .F .for .f77 .f90 .f95 .f03 .hip .ispc


CMake Error at CMakeLists.txt:63 (add_library):
  No SOURCES given to target: tensorflowlite_c


CMake Generate step failed.  Build files cannot be regenerated correctly.
```
</details>"
58549,"Trying to train transformer like the NMT Keras Transformer, for passage summarization task. The model's masked accuracy goes upto ~30% but the transformer's output is very poor. Could you help me understand what I might be doing wrong?","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
NMT task on the keras transformer as showed in the tutorials (https://www.tensorflow.org/text/tutorials/transformer) performs well. But I'm unable to get decent performance on a passage summarization task on the `cnn_dailymail` dataset. I can't understand what I might be doing wrong.
```


### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/12sbAGKESj8qynO-pb1K6gh-CZIvCxzfo#scrollTo=TlOaOjwwWN4K
```


### Relevant log output

_No response_</details>"
58548,"`tf.identity` docs missing instructions, GPU to CPU","
 ### Issue Type

Documentation Feature Request

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

The [docs](https://www.tensorflow.org/api_docs/python/tf/identity) do not describe how `.cpu()` should be accomplished.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.constant(1.).cpu()
```


### Relevant log output

```shell
_EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.identity instead.
```"
58547,ModuleNotFoundError: No module named '_pywrap_tensorflow'   Failed to load the native TensorFlow runtime.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
Saying gpu problem
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
                         ^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""E:\Dev\flutter projects\mlh_cropance\python\app.py"", line 8, in <module>
    import keras
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\__init__.py"", line 20, in <module>
    from keras import distribute
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\distribute\__init__.py"", line 18, in <module>
    from keras.distribute import sidecar_evaluator
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\distribute\sidecar_evaluator.py"", line 17, in <module>
    import tensorflow.compat.v2 as tf
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\imp.py"", line 297, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\__init__.py"", line 66, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
                         ^^^^^^^^^^^^^^^^^^^^
  File ""C:\Users\rrvig\AppData\Local\Programs\Python\Python311\Lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow
ModuleNotFoundError: No module named '_pywrap_tensorflow'


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
</details>"
58546,Undefined symbol: _TfLiteXNNPackWeightsCacheDelete,"Environment:
OS/OS Version: 13.0.1 (22A400)
Source Version: master
Unity Version: 2021.3.12f1
bazel 5.3.2-homebrew

Problem:
When useing xcode project created by Unity to build ios, Xcode shows Undefined symbol: _TfLiteXNNPackWeightsCacheDelete.

my build steps:
bazel build -c opt --config=ios_fat --cxxopt=--std=c++17 //tensorflow/lite/ios:TensorFlowLiteC_framework
bazel build -c opt --config=ios_fat --cxxopt=--std=c++17 //tensorflow/lite/ios:TensorFlowLiteCMetal_framework
"
58545,tensorflow.python.framework.errors_impl.NotFoundError: libimf.so: cannot open shared object file: No such file or directory,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.5

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

10.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I reinstall Tensorflow 2.10 to try with GPU extension at the link https://www.tensorflow.org/install/gpu_plugins

However, Tensorflow broke now I can not run it even though I tried to reinstall it many times. It displays the error:

tensorflow.python.framework.errors_impl.NotFoundError: libimf.so: cannot open shared object file: No such file or directory

Please help
```


### Standalone code to reproduce the issue

```shell
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```


### Relevant log output

_No response_</details>"
58544,i have install tensorflow 2.4.1 for the gpu and now i want to install tensorflow_hub ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
Ubuntu 22.04.1 LTS - os 
64-bit                        - os type
genome-version       - 42.4
tensorflow version    - 2.4.1


these are the commands i used to install 
conda create -n tf-gpu tensorflow-gpu
!pip install --upgrade tensorflow_hub


when i tryed to import by 
import tensorflow_hub as hub

i'm getting the following command 
AttributeError: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'monitoring'"
58543,i have install tensorflow 2.4.1 for the gpu and now i wanto install tensorflow_hub,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
58541,<spam removed>,"- - [] ![image](https://user-images.githubusercontent.com/117676937/201435994-b4f6ce13-b383-4dc7-987a-4ebf08902011.png)

__Originally posted by @Twbent in https://github.com/Twbent/Family-Tree/issues/2__"
58540,CMake errors on building tflite,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

5b6f7e79a5feb61a993a19997fffa76654f82adb

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

MSVC 19.34.31933

### CUDA/cuDNN version

11.7/8.4.1.50

### GPU model and memory

_No response_

### Current Behaviour?

```shell
CMake error on building tflite. CMake completes without `TFLITE_ENABLE_INSTALL`.
```


### Standalone code to reproduce the issue

```shell
cmake -G ""Visual Studio 17"" -A x64 -D CMAKE_INSTALL_PREFIX:PATH=D:\tflite\install -D CMAKE_DEBUG_POSTFIX:STRING=d -D CMAKE_BUILD_TYPE=Debug -D TFLITE_ENABLE_GPU:BOOL=ON -D TFLITE_ENABLE_INSTALL:BOOL=ON -D BUILD_SHARED_LIBS:BOOL=ON -D GIT:FILEPATH=D:\Tools\GIT\bin\git.exe -D GITCOMMAND:FILEPATH=D:\Tools\GIT\bin\git.exe -D GIT_EXECUTABLE:FILEPATH=D:\Tools\GIT\bin\git.exe D:\tflite\src\tensorflow\lite
```


### Relevant log output

```shell
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_flags"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_hash"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_status"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_strings"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_synchronization"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_variant"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""ruy"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_any"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""absl_flat_hash_map"" that is not in any export set.
CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""XNNPACK"" that is not in any export set.
```
</details>"
58538,"interactive_graphviz reports error ""Unable to render graph as URL: FAILED_PRECONDITION: Can't render as URL; no URL renderer was registered""","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Mac OS with M1 

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When use interactive_graphviz tool in M1 Mac, it reports error:


Unable to render graph as URL: FAILED_PRECONDITION: Can't render as URL; no URL renderer was registered
Trying as HTML...
file:///var/folders/1g/kg1d5zdx5lb4mfqz0qfb5w_r0000gn/T/interactive_graphviz.1668173886537896.html
2022-11-11 21:38:06.543166: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
```

The generated html file is actually empty.
```


### Standalone code to reproduce the issue

```shell
interactive_graphviz --hlo-text
```


### Relevant log output

_No response_</details>"
58537,tf.io.decode_image fails to load certain PNG files,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0, also tested 2.11.0rc2

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 22.04.1

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2, also tested 11.6

### GPU model and memory

RTX 3090 24GB

### Current Behaviour?

```shell
I have two PNG files both created by PIL package, one of them upon opening with tf.io.decode_image is set to all zeros (dimensions are ok). The image can be opened in PIL, not in tensorflow. It can also be opened in a viewer or a simple python PNG decoder (https://pyokagan.name/blog/2019-10-14-png/). Happens both in eager mode and tf.function. I will upload the images mentioned in next post.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

p_works = ""LPPID_011119852.png""
p_not_working = ""LPPID_023863769.png""


def process_image(path):
    buffer = tf.io.read_file(path)
    image = tf.io.decode_image(buffer)
    tf.print(tf.shape(image))
    tf.print(image)


process_image(p_works)
process_image(p_not_working)
```


### Relevant log output

_No response_</details>"
58536,old versions of tflite native benchmark binaries,"Hi, is it possible to download old versions of tflite native benchmark binaries? I can find [here](https://www.tensorflow.org/lite/performance/measurement#download_or_build_the_binary) only the nightly version.
"
58535,No matching distribution found for numba==0.53,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.10

### Mobile device

n/a

### Python version

3.10.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Excessive version dependencies for tflite-model-maker
```


### Standalone code to reproduce the issue

```shell
Dependency errors even with the following statement:

python3 -m pip install -q --use-deprecated=legacy-resolver tflite-model-maker
```


### Relevant log output

```shell
Using cached neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)
ERROR: Ignored the following versions that require a different python version: 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10
ERROR: Could not find a version that satisfies the requirement numba==0.53 (from tflite-model-maker) (from versions: 0.1, 0.2, 0.3, 0.5.0, 0.6.0, 0.7.0, 0.7.1, 0.7.2, 0.8.0, 0.8.1, 0.9.0, 0.10.0, 0.10.1, 0.11.0, 0.12.0, 0.12.1, 0.12.2, 0.13.0, 0.13.2, 0.13.3, 0.13.4, 0.14.0, 0.15.1, 0.16.0, 0.17.0, 0.18.1, 0.18.2, 0.19.1, 0.19.2, 0.20.0, 0.21.0, 0.22.0, 0.22.1, 0.23.0, 0.23.1, 0.24.0, 0.25.0, 0.26.0, 0.27.0, 0.28.1, 0.29.0, 0.30.0, 0.30.1, 0.31.0, 0.32.0, 0.33.0, 0.34.0, 0.35.0, 0.36.1, 0.36.2, 0.37.0, 0.38.0, 0.38.1, 0.39.0, 0.40.0, 0.40.1, 0.41.0, 0.42.0, 0.42.1, 0.43.0, 0.43.1, 0.44.0, 0.44.1, 0.45.0, 0.45.1, 0.46.0, 0.47.0, 0.48.0, 0.49.0, 0.49.1rc1, 0.49.1, 0.50.0rc1, 0.50.0, 0.50.1, 0.51.0rc1, 0.51.0, 0.51.1, 0.51.2, 0.52.0rc2, 0.55.0rc1, 0.55.0, 0.55.1, 0.55.2, 0.56.0rc1, 0.56.0, 0.56.2, 0.56.3, 0.56.4)
ERROR: No matching distribution found for numba==0.53
(tflite_model_maker) reza@BeUlta:~/projects/tflite_mode
```
</details>"
58534,XlaRuntimeError: UNKNOWN: Failed to determine best cudnn convolution algorithm for,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.6.4

### Custom Code

Yes

### OS Platform and Distribution

Linux 524ec3303516 5.15.65+ #1 SMP Thu Nov 10 10:13:28 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

P100

### Current Behaviour?

```shell
Tried to use 1D convolution with JAX/Flax.
```


### Standalone code to reproduce the issue

```shell
import flax
from flax import linen as nn
from flax.training import train_state
from flax import jax_utils
from flax.core.frozen_dict import freeze, unfreeze
import jax
import jax.numpy as jnp
from jax import random, device_get
from typing import Sequence, Tuple, Optional, Callable, Any

ModuleDef = Any

class NN(nn.Module):
    features: Sequence[Sequence[int]]
    kernel_sizes: Sequence[Sequence[Tuple[int, int]]]
    used_rounds: Optional[int] = None
    act: Callable = nn.relu

    @nn.compact
    def __call__(self, x):
        n_rounds = len(self.kernel_sizes) if self.used_rounds == None else self.used_rounds
        if n_rounds < 0:
            round_range = range(len(self.kernel_sizes) + n_rounds)
        else:
            round_range = range(n_rounds)
        
        y_rounds = jnp.zeros((len(list(round_range)), x.shape[0], 1))
        for boosting_round in round_range:
            y = None
            for depth in range(len(self.features[boosting_round])):
                if depth == (len(self.features[boosting_round]) - 1) and boosting_round == (len(list(round_range)) - 1):
                    conv_name = ""conv_head""
                    dense_name = ""dense_head""
                else:
                    conv_name = f""conv_{boosting_round}_{depth}""
                    dense_name = f""dense_{boosting_round}_{depth}""
                if y is not None:
                    y = jnp.concatenate((x, y), axis=-1)
                else:
                    y = x
                f = self.features[boosting_round][depth]
                k = self.kernel_sizes[boosting_round][depth]
                y = nn.Conv(features=f, kernel_size=k, name=conv_name)(y)
                y = self.act(y)
            
            y_flat = y.reshape((y.shape[0], -1))  # flatten
            y_dense = nn.Dense(features=1, name=dense_name)(y_flat)
            y_rounds = y_rounds.at[boosting_round].set(y_dense)
        return jnp.sum(y_rounds, axis=0)

tree_trial = NN([[2, 3, 4], [2, 3]], [[(2,), (4,), (5,)], [(2,), (4,)]])
params = tree_trial.init(random.PRNGKey(0), jnp.ones([33, 8]))['params']
print(jax.tree_map(lambda x: x.shape, params))
```


### Relevant log output

```shell
---------------------------------------------------------------------------
XlaRuntimeError                           Traceback (most recent call last)
/tmp/ipykernel_23/3353521153.py in <module>
      1 tree_trial = NN([[2, 3, 4], [2, 3]], [[(2,), (4,), (5,)], [(2,), (4,)]])
----> 2 params = tree_trial.init(random.PRNGKey(0), jnp.ones([33, 8]))['params']
      3 print(jax.tree_map(lambda x: x.shape, params))

    [... skipping hidden 9 frame]

/tmp/ipykernel_23/1204994627.py in __call__(self, x)
     29                 f = self.features[boosting_round][depth]
     30                 k = self.kernel_sizes[boosting_round][depth]
---> 31                 y = nn.Conv(features=f, kernel_size=k, name=conv_name)(y)
     32                 y = self.act(y)
     33 

    [... skipping hidden 2 frame]

/opt/conda/lib/python3.7/site-packages/flax/linen/linear.py in __call__(self, inputs)
    442           dimension_numbers=dimension_numbers,
    443           feature_group_count=self.feature_group_count,
--> 444           precision=self.precision
    445       )
    446     else:

    [... skipping hidden 13 frame]


/opt/conda/lib/python3.7/site-packages/jax/_src/dispatch.py in backend_compile(backend, built_c, options, host_callbacks)
    992   # TODO(sharadmv): remove this fallback when all backends allow `compile`
    993   # to take in `host_callbacks`
--> 994   return backend.compile(built_c, compile_options=options)
    995 
    996 # TODO(phawkins): update users.

XlaRuntimeError: UNKNOWN: Failed to determine best cudnn convolution algorithm for:
%cudnn-conv = (f32[1,33,2]{1,2,0}, u8[0]{0}) custom-call(f32[1,34,8]{1,2,0} %copy.3, f32[2,8,2]{0,1,2} %copy.1), window={size=2}, dim_labels=b0f_0io->b0f, custom_call_target=""__cudnn$convForward"", metadata={op_name=""jit(conv_general_dilated)/jit(main)/conv_general_dilated[window_strides=(1,) padding=((0, 1),) lhs_dilation=(1,) rhs_dilation=(1,) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 2, 1), rhs_spec=(2, 1, 0), out_spec=(0, 2, 1)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 33, 8) rhs_shape=(2, 8, 2) precision=None preferred_element_type=None]"" source_file=""/opt/conda/lib/python3.7/site-packages/flax/linen/linear.py"" source_line=444}, backend_config=""{\""conv_result_scale\"":1,\""activation_mode\"":\""0\"",\""side_input_scale\"":0}""

Original error: UNIMPLEMENTED: DNN library is not found.

To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.
```
</details>"
58533,Enable c/c++ client for PluggableDevice,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
There is no TF_LoadPluggableDeviceLibrary defination in libtensorflow_cc.so.
TF_LoadPluggableDeviceLibrary is needed to load PluggableDevice library.
```


### Standalone code to reproduce the issue

```shell
Add """"//tensorflow/c:c_api_experimental"""" deps in ""tensorflow_cc"" build, tensorflow/BUILD
Refer to https://github.com/feng-intel/intel-itex/tree/main/enable_cc_example  -> 2. Build libtensorflow_cc.so
```


### Relevant log output

_No response_</details>"
58523,`tf.linalg.pinv` produces all-zero matrix instead of all-`nan` matrix when given `nan` input on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0, and nightly

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.3, 8.2.4

### GPU model and memory

_No response_

### Current Behaviour?

If any element in a matrix is `nan`, its pseudo inverse cannot be computed so an all-`nan` matrix should be returned, which is what `tf.linalg.pinv` does on CPU. But on GPU, when a tensor containing more than one matrices is given, it returns an all-zero tensor for a `nan` tensor instead. It is strange that GPU works well when there is only one matrix, even if it has `nan`.

### Standalone code to reproduce the issue

```shell
allnan = tf.convert_to_tensor([[[np.nan, np.nan], [np.nan, np.nan]]])
partialnan = tf.convert_to_tensor([[[1., 2.], [5., 7.]], [[np.nan, np.nan], [np.nan, np.nan]]])

with tf.device(""/cpu:0""):
    print(""CPU allnan"", tf.linalg.pinv(allnan))
    print(""CPU partialnan"", tf.linalg.pinv(partialnan))
with tf.device(""/gpu:0""):
    print(""GPU allnan"", tf.linalg.pinv(allnan))
    print(""GPU partialnan"", tf.linalg.pinv(partialnan))
```


### Relevant log output

```shell
CPU allnan tf.Tensor(
[[[nan nan]
  [nan nan]]], shape=(1, 2, 2), dtype=float32)
CPU partialnan tf.Tensor(
[[[-2.3333328   0.6666665 ]
  [ 1.6666664  -0.33333325]]

 [[        nan         nan]
  [        nan         nan]]], shape=(2, 2, 2), dtype=float32)
GPU allnan tf.Tensor(
[[[nan nan]
  [nan nan]]], shape=(1, 2, 2), dtype=float32)
GPU partialnan tf.Tensor(
[[[-2.333333    0.66666603]
  [ 1.6666664  -0.33333293]]

 [[ 0.          0.        ]
  [ 0.          0.        ]]], shape=(2, 2, 2), dtype=float32)
```
</details>"
58522,Parallel loading of nested ExtensionTypes produces shape mismatch,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Nvidia Geforce 1080 Ti

### Current Behaviour?

```shell
For some reason tensor `b2` has the shape of `a` and that does not match the definition. This happens not every time I run the exact same code but only sometimes. It seems to work with Tensorflow 2.9 though...
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf


class A(tf.experimental.ExtensionType):
    a1: tf.Tensor

    class Spec:
        def __init__(self):
            self.a1 = tf.TensorSpec(shape=[2, 1], dtype=tf.float16)


class B(tf.experimental.ExtensionType):
    b1: tf.Tensor
    b2: tf.Tensor
    a: A

    class Spec:
        def __init__(self):
            self.b1 = tf.TensorSpec(shape=[2, 5], dtype=tf.float16)
            self.b2 = tf.TensorSpec(shape=[2, 6], dtype=tf.float32)
            self.a = A.Spec()


def loading_fn():
    objects = B(
        tf.zeros(shape=[2, 5], dtype=tf.float16),
        tf.zeros(shape=[2, 6], dtype=tf.float32),
        A(tf.zeros(shape=[2, 1], dtype=tf.float16)),
    )

    return objects


def func(i):
    return tf.py_function(loading_fn, inp=[], Tout=B.Spec())


dataset = tf.data.Dataset.from_tensor_slices([i for i in range(10)])
dataset = dataset.map(func, num_parallel_calls=10)

for _ in range(10):
    for path in iter(dataset):
        pass
```


### Relevant log output

```shell
2022-11-10 14:44:32.830413: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: py_function: func=<function loading_fn at 0x7fc368151a60> returned [B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 6), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 6), dtype=float16, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float16)>))], which did not match Tout=[B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None)))].
In particular, B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 6), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 6), dtype=float16, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float16)>)) is not compatible with B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None))).
Traceback (most recent call last):

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 269, in __call__
    return func(device, token, args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 147, in __call__
    outputs = self._call(device, args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 154, in _call
    ret = self._func(*args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 824, in wrapped_func
    raise ValueError(

ValueError: py_function: func=<function loading_fn at 0x7fc368151a60> returned [B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 6), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 6), dtype=float16, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float16)>))], which did not match Tout=[B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None)))].
In particular, B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 6), dtype=float32, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 6), dtype=float16, numpy=
array([[0., 0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0., 0.]], dtype=float16)>)) is not compatible with B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None))).


2022-11-10 14:44:32.838758: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: ValueError: py_function: func=<function loading_fn at 0x7fc368151a60> returned [B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>))], which did not match Tout=[B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None)))].
In particular, B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>)) is not compatible with B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None))).
Traceback (most recent call last):

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 269, in __call__
    return func(device, token, args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 147, in __call__
    outputs = self._call(device, args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 154, in _call
    ret = self._func(*args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 824, in wrapped_func
    raise ValueError(

ValueError: py_function: func=<function loading_fn at 0x7fc368151a60> returned [B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>))], which did not match Tout=[B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None)))].
In particular, B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>)) is not compatible with B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None))).


Traceback (most recent call last):
  File ""test.py"", line 42, in <module>
    for path in iter(dataset):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 766, in __next__
    return self._next_internal()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 749, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3017, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 7209, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__IteratorGetNext_output_types_3_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: py_function: func=<function loading_fn at 0x7fc368151a60> returned [B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>))], which did not match Tout=[B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None)))].
In particular, B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>)) is not compatible with B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None))).
Traceback (most recent call last):

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 269, in __call__
    return func(device, token, args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 147, in __call__
    outputs = self._call(device, args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 154, in _call
    ret = self._func(*args)

  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/script_ops.py"", line 824, in wrapped_func
    raise ValueError(

ValueError: py_function: func=<function loading_fn at 0x7fc368151a60> returned [B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>))], which did not match Tout=[B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None)))].
In particular, B(b1=<tf.Tensor: shape=(2, 5), dtype=float16, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float16)>, b2=<tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[0.],
       [0.]], dtype=float32)>, a=A(a1=<tf.Tensor: shape=(2, 1), dtype=float16, numpy=
array([[0.],
       [0.]], dtype=float16)>)) is not compatible with B.Spec(b1=TensorSpec(shape=(2, 5), dtype=tf.float16, name=None), b2=TensorSpec(shape=(2, 6), dtype=tf.float32, name=None), a=A.Spec(a1=TensorSpec(shape=(2, 1), dtype=tf.float16, name=None))).


         [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]
```
</details>"
58520,How to build with RDMA in new version,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

master

### Custom Code

No

### OS Platform and Distribution

ubuntu 18.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

0.26.1

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensorflow supports gRPC+verbs and gRPC+MPI for distributed settings. I want to know how RDMA works in Tensorflow. So I build TensorFlow from the source.
But I can't find any documentation which shows how to do it. And I find a [repo](https://github.com/tensorflow/networking) which is relative to RDMA(verbs). I try to figure out how I can combine it with TensorFlow and the README confused me.
Then I review the git log in Tensorflow's repo and find the commit `7520b33` which supports verbs. In that commit, I can find how to configure the verbs support in `.bzaelc`. I try to find the same config in `master`'s `.bazelc` but I failed.
How can I build Tensorflow with verbs? Or may Tensorflow not support the verbs?
```


### Standalone code to reproduce the issue

```shell
./configure
```


### Relevant log output

_No response_</details>"
58517,`tf.round` on GPU rounds `-0.5` to `0.0` rather than `-0.0`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0, and nightly

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.3, 8.2.4

### GPU model and memory

_No response_

### Current Behaviour?

`np.round` and `tf.round` on CPU round `-0.5` to `-0.0`, but `tf.round` on GPU rounds to `0.0`.

### Standalone code to reproduce the issue

```shell
print(""numpy"", np.round([-2.5, -1.5, -0.5, 0.5, 1.5, 2.5]))
with tf.device(""/cpu:0""):
    print(""CPU"", tf.round([-2.5, -1.5, -0.5, 0.5, 1.5, 2.5]))
with tf.device(""/gpu:0""):
    print(""GPU"", tf.round([-2.5, -1.5, -0.5, 0.5, 1.5, 2.5]))
```


### Relevant log output

```shell
numpy [-2. -2. -0.  0.  2.  2.]
CPU tf.Tensor([-2. -2. -0.  0.  2.  2.], shape=(6,), dtype=float32)
GPU tf.Tensor([-2. -2.  0.  0.  2.  2.], shape=(6,), dtype=float32)
```
</details>"
58516,Removal of Experimental_IO Device in DTensor Causing Issues With Horovod Based Models,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.12

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.03

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.3.0

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When I run a Horovod based model, GPU devices should not be prematurely added.  They should only be added as each Horovod based process is spawned
```


### Standalone code to reproduce the issue

```shell
I don't have standalone code but here is an analysis of what happens:

The follow commit is relevant:

https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/commit/16ea0f8995a9b087ff7e50bbf5a03e58e3c5002e

In tensorflow/python/training/saving/saveable_object_util.py, the following change is causing the issue:

+  if context.is_custom_device(device_string):
+    return device_string

The reason is that inside the call to is_custom_device, there is another call to self.ensure_initialized() which causes all the GPUs in the system to be added as a result of the call to pywrap_tfe.TFE_NewContext(opts).

This causes issues with the Horovod based model that I am working with because the model subsequently makes additional calls pywrap_tfe.TFE_NewContext(opts) for 1 device per process.  However, this causes an error with adding the GPU devices because they have already been added as a result of the call to is_custom_device.
```


### Relevant log output

```shell
Here is the error (which is repeated):

2022-11-10 06:24:19.634825: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: INVALID_ARGUMENT: 'visible_device_list' listed an invalid Device id '6' but visible device count is 2
2022-11-10 06:24:19.634941: E tensorflow/c/c_api.cc:2209] INVALID_ARGUMENT: 'visible_device_list' listed an invalid Device id '6' but visible device count is 2
```
</details>"
58515,`tf.math.negative` negates only the last element in an all-zero 3x3 matrix on CPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0, and nightly

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

There is a difference between `0.0` and `-0.0` according to IEEE 754. Negate `0.0` and you should get `-0.0`. If we apply `tf.math.negative` to an all-zero 3x3 matrix, it only negates the last element to `-0.0` and leave the rest as `0.0`.

### Standalone code to reproduce the issue

```shell
with tf.device(""/cpu:0""):
  zeros = tf.zeros((3, 3), dtype=tf.float64)
  negs = tf.math.negative(zeros)
  infs = tf.math.reciprocal(negs)
  print(zeros, negs, infs)
```


### Relevant log output

```shell
tf.Tensor(
[[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]], shape=(3, 3), dtype=float64) tf.Tensor(
[[ 0.  0.  0.]
 [ 0.  0.  0.]
 [ 0.  0. -0.]], shape=(3, 3), dtype=float64) tf.Tensor(
[[ inf  inf  inf]
 [ inf  inf  inf]
 [ inf  inf -inf]], shape=(3, 3), dtype=float64)
```
</details>"
58507,Bug in MLP notebook ,"I have found a problem with a memory explosion on the MLP notebook, if it's configured to use non deterministic Nvidia cuda.

What I found is that the memory usage went up massively, when I last tested it I think using gelu activation functions, instead of relu.

When I tested this it resulted in memory usage increases, until it used up all my system memory (32GB), on Ubuntu 22.10.

This was using python 3.10 and tensorflow 2.10, Nvidia cuda 11.7

Is there any possibility of fixing this?"
58499,Pruning Example broken in TensorFlow 2.9.2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.6

### GPU model and memory

Nvidia Rtx 3090, 24 GB

### Current Behaviour?

```shell
The pruning example (https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras) is completely broken in TF 2.9.2 (tf-model-optimization 0.7.3). The error is shown in the log output. The error is reproducible using the exact same code provided in the pruning with keras guide.

N.B. For another model on the CIFAR10 dataset, I get an inaccessible tensor error. The error there happens in the first conv layer. I thought I did something wrong so tried the exact example code but looks like something is wrong inside Tensorflow itself.
```


### Standalone code to reproduce the issue

```shell
https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras
```


### Relevant log output

```shell
UnknownError                              Traceback (most recent call last)
Cell In [5], line 8
      1 logdir = tempfile.mkdtemp()
      3 callbacks = [
      4   tfmot.sparsity.keras.UpdatePruningStep(),
      5   tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),
      6 ]
----> 8 model_for_pruning.fit(train_images, train_labels,
      9                   batch_size=batch_size, epochs=epochs, validation_split=validation_split,
     10                   callbacks=callbacks)

File ~/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     65 except Exception as e:  # pylint: disable=broad-except
     66   filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67   raise e.with_traceback(filtered_tb) from None
     68 finally:
     69   del filtered_tb

File ~/swapnil_debug_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     52 try:
     53   ctx.ensure_initialized()
---> 54   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     55                                       inputs, attrs, num_outputs)
     56 except core._NotOkStatusException as e:
     57   if name is not None:

UnknownError: Graph execution error:

Detected at node 'sequential/prune_low_magnitude_conv2d/FloorMod' defined at (most recent call last):
    File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main
      return _run_code(code, main_globals, None,
    File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code
      exec(code, run_globals)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel_launcher.py"", line 17, in <module>
      app.launch_new_instance()
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/traitlets/config/application.py"", line 982, in launch_instance
      app.start()
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/kernelapp.py"", line 712, in start
      self.io_loop.start()
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tornado/platform/asyncio.py"", line 215, in start
      self.asyncio_loop.run_forever()
    File ""/usr/lib/python3.8/asyncio/base_events.py"", line 570, in run_forever
      self._run_once()
    File ""/usr/lib/python3.8/asyncio/base_events.py"", line 1859, in _run_once
      handle._run()
    File ""/usr/lib/python3.8/asyncio/events.py"", line 81, in _run
      self._context.run(self._callback, *self._args)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/kernelbase.py"", line 510, in dispatch_queue
      await self.process_one()
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/kernelbase.py"", line 499, in process_one
      await dispatch(*args)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/kernelbase.py"", line 406, in dispatch_shell
      await result
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/kernelbase.py"", line 730, in execute_request
      reply_content = await reply_content
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/ipkernel.py"", line 383, in do_execute
      res = shell.run_cell(
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/ipykernel/zmqshell.py"", line 528, in run_cell
      return super().run_cell(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 2940, in run_cell
      result = self._run_cell(
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 2995, in _run_cell
      return runner(coro)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/IPython/core/async_helpers.py"", line 129, in _pseudo_sync_runner
      coro.send(None)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3194, in run_cell_async
      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3373, in run_ast_nodes
      if await self.run_code(code, result, async_=asy):
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3433, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File ""/tmp/ipykernel_2426111/471826281.py"", line 8, in <module>
      model_for_pruning.fit(train_images, train_labels,
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/training.py"", line 1409, in fit
      tmp_logs = self.train_function(iterator)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/training.py"", line 1051, in train_function
      return step_function(self, iterator)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/training.py"", line 1040, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/training.py"", line 889, in train_step
      y_pred = self(x, training=True)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/training.py"", line 490, in __call__
      return super().__call__(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1014, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/sequential.py"", line 374, in call
      return super(Sequential, self).call(inputs, training=training, mask=mask)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/functional.py"", line 458, in call
      return self._run_internal_graph(
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/functional.py"", line 596, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1014, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py"", line 280, in call
      update_mask = utils.smart_cond(training, add_update, no_op)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/keras/utils.py"", line 50, in smart_cond
      if isinstance(pred, variables.Variable):
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/keras/utils.py"", line 54, in smart_cond
      pred, true_fn=true_fn, false_fn=false_fn, name=name)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py"", line 268, in add_update
      with tf.control_dependencies(
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py"", line 310, in conditional_mask_update
      return tf.distribute.get_replica_context().merge_call(
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py"", line 307, in mask_update_distributed
      return tf.cond(maybe_update_masks(), update_distributed, no_update)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py"", line 260, in maybe_update_masks
      if self._sparsity_m_by_n:
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py"", line 264, in maybe_update_masks
      return self._pruning_schedule(self._step_fn())[0]
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py"", line 246, in __call__
      sparsity)
    File ""/home/nesl/swapnil_debug_2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_schedule.py"", line 61, in _should_prune_in_step
      is_pruning_turn = tf.math.equal(
Node: 'sequential/prune_low_magnitude_conv2d/FloorMod'
JIT compilation failed.
	 [[{{node sequential/prune_low_magnitude_conv2d/FloorMod}}]] [Op:__inference_train_function_34086]
```
</details>"
58498,Feature request: tflite with GPU and Hexagon delegate support on Linux ARM64 platform,"From this link: https://www.tensorflow.org/lite/guide/build_arm , GPU delegate is ""only available for Android"" if I use bazel, so I have to use cmake in order to get GPU delegate.
However from this link: https://www.tensorflow.org/lite/guide/build_cmake , there's only TFLITE_ENABLE_GPU, no TFLITE_ENABLE_HEXAGON. I tried to use it in cmake and it's not recognized.
Wondering if tensorflow can either add GPU delegate to bazel build, or add hexagon to cmake? Which one is more appropriate, if I also want to use our own toolchain?"
58497,Unable to build Tensorflow 2.12.0 Open CL delegate for aarch64 platform,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.12.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

Khadas Vim 3

### Python version

3.8.10

### Bazel version

5.1.1

### GCC/Compiler version

10.3.1

### CUDA/cuDNN version

_No response_

### GPU model and memory

Mali G52

### Current Behaviour?

```shell
Downloaded the current source from GitHub and tried to compile and build the source.

It was causing build failure with GCC 8.3.0 (default) and the documentation - https://www.tensorflow.org/install/source seem to expect >= GCC 9.3.1. So, downloaded gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu compiler from Arm and tried to build Tensorflow from scratch using the compiler. Still, no change to the errors experienced with build the delegate shared library.
```


### Standalone code to reproduce the issue

```shell
Build using:

bazel --output_user_root=`pwd`/../build build --config=monolithic --config=elinux_aarch64 -c opt --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 --copt -DCL_DELEGATE_NO_GL tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so --verbose_failures
```


### Relevant log output

```shell
ERROR: /opt/Projects/vim3/current/tensorflow/tensorflow/lite/delegates/gpu/cl/BUILD:563:11: Compiling tensorflow/lite/delegates/gpu/cl/util.cc failed: (Exit 1): aarch64-none-linux-gnu-gcc failed: error executing command
  (cd /opt/Projects/vim3/current/build/8a8a750b08c8b6808e7e24e10efdeaac/execroot/org_tensorflow && \
  exec env - \
    PATH=/home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /opt/Projects/vim3/current/build/8a8a750b08c8b6808e7e24e10efdeaac/external/aarch64_linux_toolchain/bin/aarch64-none-linux-gnu-gcc -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -isystem /opt/Projects/vim3/current/build/8a8a750b08c8b6808e7e24e10efdeaac/external/aarch64_linux_toolchain/lib/gcc/aarch64-none-linux-gnu/10.3.1/include -isystem /opt/Projects/vim3/current/build/8a8a750b08c8b6808e7e24e10efdeaac/external/aarch64_linux_toolchain/lib/gcc/aarch64-none-linux-gnu/10.3.1/include-fixed -isystem /opt/Projects/vim3/current/build/8a8a750b08c8b6808e7e24e10efdeaac/external/aarch64_linux_toolchain/aarch64-none-linux-gnu/include/c++/10.3.1/ -isystem /opt/Projects/vim3/current/build/8a8a750b08c8b6808e7e24e10efdeaac/external/aarch64_linux_toolchain/aarch64-none-linux-gnu/libc/usr/include/ -isystem /usr/include/python3.5 -isystem /usr/include/ -MD -MF bazel-out/aarch64-opt/bin/tensorflow/lite/delegates/gpu/cl/_objs/util/util.pic.d '-frandom-seed=bazel-out/aarch64-opt/bin/tensorflow/lite/delegates/gpu/cl/_objs/util/util.pic.o' -fPIC -iquote . -iquote bazel-out/aarch64-opt/bin -iquote external/com_google_absl -iquote bazel-out/aarch64-opt/bin/external/com_google_absl -iquote external/opencl_headers -iquote bazel-out/aarch64-opt/bin/external/opencl_headers -iquote external/FP16 -iquote bazel-out/aarch64-opt/bin/external/FP16 -Ibazel-out/aarch64-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/opencl_headers -isystem bazel-out/aarch64-opt/bin/external/opencl_headers -isystem external/FP16/include -isystem bazel-out/aarch64-opt/bin/external/FP16/include -Wno-all -Wno-extra -Wno-deprecated -Wno-deprecated-declarations -Wno-ignored-attributes -Wno-unknown-warning -Wno-array-parameter -Wno-stringop-overflow -Wno-array-bounds -Wunused-result '-Werror=unused-result' -Wswitch '-Werror=switch' -DAUTOLOAD_DYNAMIC_KERNELS -DMESA_EGL_NO_X11_HEADERS -DEGL_NO_X11 -DCL_DELEGATE_NO_GL '-std=c++17' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c tensorflow/lite/delegates/gpu/cl/util.cc -o bazel-out/aarch64-opt/bin/tensorflow/lite/delegates/gpu/cl/_objs/util/util.pic.o)
# Configuration: af6158f7a268e712042d3dcc32a6d7e8e207b6ca0f529c25a9d7e84c111a5435
# Execution platform: @local_execution_config_platform//:platform
In file included from /usr/include/CL/cl.h:32,
                 from ./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:19,
                 from ./tensorflow/lite/delegates/gpu/cl/util.h:24,
                 from tensorflow/lite/delegates/gpu/cl/util.cc:16:
/usr/include/CL/cl_version.h:34:104: note: '#pragma message: cl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 220 (OpenCL 2.2)'
   34 | #pragma message(""cl_version.h: CL_TARGET_OPENCL_VERSION is not defined. Defaulting to 220 (OpenCL 2.2)"")
      |                                                                                                        ^
In file included from ./tensorflow/lite/delegates/gpu/cl/util.h:24,
                 from tensorflow/lite/delegates/gpu/cl/util.cc:16:
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:526:9: error: ISO C++ forbids declaration of 'cl_command_buffer_khr' with no type [-fpermissive]
  526 | typedef cl_command_buffer_khr(CL_API_CALL *PFN_clCreateCommandBufferKHR)(
      |         ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:526:9: error: typedef 'tflite::gpu::cl::cl_command_buffer_khr' is initialized (use 'decltype' instead)
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:526:44: error: 'PFN_clCreateCommandBufferKHR' was not declared in this scope; did you mean 'PFN_clCreateCommandQueue'?
  526 | typedef cl_command_buffer_khr(CL_API_CALL *PFN_clCreateCommandBufferKHR)(
      |                                            ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |                                            PFN_clCreateCommandQueue
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:531:29: error: typedef 'tflite::gpu::cl::PFN_clRetainCommandBufferKHR' is initialized (use 'decltype' instead)
  531 | typedef cl_int(CL_API_CALL *PFN_clRetainCommandBufferKHR)(
      |                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:532:5: error: 'cl_command_buffer_khr' was not declared in this scope
  532 |     cl_command_buffer_khr /*command_buffer*/);
      |     ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:534:29: error: typedef 'tflite::gpu::cl::PFN_clReleaseCommandBufferKHR' is initialized (use 'decltype' instead)
  534 | typedef cl_int(CL_API_CALL *PFN_clReleaseCommandBufferKHR)(
      |                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:535:5: error: 'cl_command_buffer_khr' was not declared in this scope
  535 |     cl_command_buffer_khr /*command_buffer*/);
      |     ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:537:29: error: typedef 'tflite::gpu::cl::PFN_clFinalizeCommandBufferKHR' is initialized (use 'decltype' instead)
  537 | typedef cl_int(CL_API_CALL *PFN_clFinalizeCommandBufferKHR)(
      |                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:538:5: error: 'cl_command_buffer_khr' was not declared in this scope
  538 |     cl_command_buffer_khr /*command_buffer*/);
      |     ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:542:5: error: 'cl_command_buffer_khr' has not been declared
  542 |     cl_command_buffer_khr /*command_buffer*/,
      |     ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:546:29: error: typedef 'tflite::gpu::cl::PFN_clCommandNDRangeKernelKHR' is initialized (use 'decltype' instead)
  546 | typedef cl_int(CL_API_CALL *PFN_clCommandNDRangeKernelKHR)(
      |                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:547:5: error: 'cl_command_buffer_khr' was not declared in this scope
  547 |     cl_command_buffer_khr /*command_buffer*/,
      |     ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:548:39: error: expected primary-expression before ',' token
  548 |     cl_command_queue /*command_queue*/,
      |                                       ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:549:5: error: expected primary-expression before 'const'
  549 |     const cl_ndrange_kernel_command_properties_khr * /*properties*/,
      |     ^~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:550:25: error: expected primary-expression before ',' token
  550 |     cl_kernel /*kernel*/, cl_uint /*work_dim*/,
      |                         ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:550:47: error: expected primary-expression before ',' token
  550 |     cl_kernel /*kernel*/, cl_uint /*work_dim*/,
      |                                               ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:551:5: error: expected primary-expression before 'const'
  551 |     const size_t * /*global_work_offset*/, const size_t * /*global_work_size*/,
      |     ^~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:551:44: error: expected primary-expression before 'const'
  551 |     const size_t * /*global_work_offset*/, const size_t * /*global_work_size*/,
      |                                            ^~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:552:5: error: expected primary-expression before 'const'
  552 |     const size_t * /*local_work_size*/,
      |     ^~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:553:45: error: expected primary-expression before ',' token
  553 |     cl_uint /*num_sync_points_in_wait_list*/,
      |                                             ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:554:5: error: expected primary-expression before 'const'
  554 |     const cl_sync_point_khr * /*sync_point_wait_list*/,
      |     ^~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:555:5: error: 'cl_sync_point_khr' was not declared in this scope
  555 |     cl_sync_point_khr * /*sync_point*/,
      |     ^~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:555:39: error: expected primary-expression before ',' token
  555 |     cl_sync_point_khr * /*sync_point*/,
      |                                       ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:556:5: error: 'cl_mutable_command_khr' was not declared in this scope
  556 |     cl_mutable_command_khr * /*mutable_handle*/);
      |     ^~~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:556:48: error: expected primary-expression before ')' token
  556 |     cl_mutable_command_khr * /*mutable_handle*/);
      |                                                ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:558:29: error: typedef 'tflite::gpu::cl::PFN_clGetCommandBufferInfoKHR' is initialized (use 'decltype' instead)
  558 | typedef cl_int(CL_API_CALL *PFN_clGetCommandBufferInfoKHR)(
      |                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:559:5: error: 'cl_command_buffer_khr' was not declared in this scope
  559 |     cl_command_buffer_khr /*command_buffer*/,
      |     ^~~~~~~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:560:5: error: 'cl_command_buffer_info_khr' was not declared in this scope; did you mean 'cl_command_queue_info'?
  560 |     cl_command_buffer_info_khr /*param_name*/, size_t /*param_value_size*/,
      |     ^~~~~~~~~~~~~~~~~~~~~~~~~~
      |     cl_command_queue_info
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:560:75: error: expected primary-expression before ',' token
  560 |     cl_command_buffer_info_khr /*param_name*/, size_t /*param_value_size*/,
      |                                                                           ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:561:5: error: expected primary-expression before 'void'
  561 |     void * /*param_value*/, size_t * /*param_value_size_ret*/);
      |     ^~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:561:36: error: expected primary-expression before '*' token
  561 |     void * /*param_value*/, size_t * /*param_value_size_ret*/);
      |                                    ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:561:62: error: expected primary-expression before ')' token
  561 |     void * /*param_value*/, size_t * /*param_value_size_ret*/);
      |                                                              ^
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:682:8: error: 'PFN_clCreateCommandBufferKHR' does not name a type; did you mean 'PFN_clEnqueueCommandBufferKHR'?
  682 | extern PFN_clCreateCommandBufferKHR clCreateCommandBufferKHR;
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |        PFN_clEnqueueCommandBufferKHR
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:683:8: error: 'PFN_clRetainCommandBufferKHR' does not name a type; did you mean 'PFN_clEnqueueCommandBufferKHR'?
  683 | extern PFN_clRetainCommandBufferKHR clRetainCommandBufferKHR;
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |        PFN_clEnqueueCommandBufferKHR
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:684:8: error: 'PFN_clReleaseCommandBufferKHR' does not name a type; did you mean 'PFN_clEnqueueCommandBufferKHR'?
  684 | extern PFN_clReleaseCommandBufferKHR clReleaseCommandBufferKHR;
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |        PFN_clEnqueueCommandBufferKHR
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:685:8: error: 'PFN_clFinalizeCommandBufferKHR' does not name a type; did you mean 'PFN_clEnqueueCommandBufferKHR'?
  685 | extern PFN_clFinalizeCommandBufferKHR clFinalizeCommandBufferKHR;
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |        PFN_clEnqueueCommandBufferKHR
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:687:8: error: 'PFN_clCommandNDRangeKernelKHR' does not name a type; did you mean 'PFN_clEnqueueNDRangeKernel'?
  687 | extern PFN_clCommandNDRangeKernelKHR clCommandNDRangeKernelKHR;
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |        PFN_clEnqueueNDRangeKernel
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:688:8: error: 'PFN_clGetCommandBufferInfoKHR' does not name a type; did you mean 'PFN_clGetCommandQueueInfo'?
  688 | extern PFN_clGetCommandBufferInfoKHR clGetCommandBufferInfoKHR;
      |        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |        PFN_clGetCommandQueueInfo
tensorflow/lite/delegates/gpu/cl/util.cc: In function 'std::string tflite::gpu::cl::CLErrorCodeToString(cl_int)':
tensorflow/lite/delegates/gpu/cl/util.cc:155:10: error: 'CL_INVALID_COMMAND_BUFFER_KHR' was not declared in this scope; did you mean 'CL_INVALID_COMMAND_QUEUE'?
  155 |     case CL_INVALID_COMMAND_BUFFER_KHR:
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |          CL_INVALID_COMMAND_QUEUE
tensorflow/lite/delegates/gpu/cl/util.cc:157:10: error: 'CL_INVALID_SYNC_POINT_WAIT_LIST_KHR' was not declared in this scope; did you mean 'CL_INVALID_EVENT_WAIT_LIST'?
  157 |     case CL_INVALID_SYNC_POINT_WAIT_LIST_KHR:
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      |          CL_INVALID_EVENT_WAIT_LIST
tensorflow/lite/delegates/gpu/cl/util.cc:159:10: error: 'CL_INCOMPATIBLE_COMMAND_QUEUE_KHR' was not declared in this scope
  159 |     case CL_INCOMPATIBLE_COMMAND_QUEUE_KHR:
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
At global scope:
cc1plus: note: unrecognized command-line option '-Wno-array-parameter' may have been intended to silence earlier diagnostics
cc1plus: note: unrecognized command-line option '-Wno-unknown-warning' may have been intended to silence earlier diagnostics
Target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build
INFO: Elapsed time: 56.712s, Critical Path: 5.83s
INFO: 233 processes: 197 internal, 36 local.
FAILED: Build did NOT complete successfully
```
</details>"
58496,`tf.experimental.numpy.sort` does not `nan` values to the end as numpy document says,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

According to the [numpy docs](https://numpy.org/doc/1.16/reference/generated/numpy.sort.html) for `np.sort` (which is mentioned in [tf docs](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/sort) for `tf.experimental.numpy.sort`), `nan`s should be sorted to the end of an array.

> Previous to numpy 1.4.0 sorting real and complex arrays containing nan values led to undefined behaviour. In numpy versions >= 1.4.0 nan values are sorted to the end. The extended sort order is:
> 
> - Real: [R, nan]
> - Complex: [R + Rj, R + nanj, nan + Rj, nan + nanj]
> 
> where R is a non-nan real value. Complex values with the same nan placements are sorted according to the non-nan part if it exists. Non-nan values are sorted as before.

The CPU and GPU implementations of tf violate this by placing `nan` in the front or in the middle of the array.


### Standalone code to reproduce the issue

```shell
print(""numpy"", np.sort([1, np.nan, 2, 3]))
with tf.device(""/cpu:0""):
  print(""CPU"", tf.experimental.numpy.sort([1, np.nan, 2, 3]))
with tf.device(""/gpu:0""):
  print(""GPU"", tf.experimental.numpy.sort([1, np.nan, 2, 3]))
```


### Relevant log output

```shell
numpy [ 1.  2.  3. nan]
CPU tf.Tensor([ 1. nan  2.  3.], shape=(4,), dtype=float64)
GPU tf.Tensor([nan  1.  2.  3.], shape=(4,), dtype=float64)
```
</details>"
58493,`tf.experimental.numpy.divmod` produces `nan` remainder for `1 % inf` on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

When computing the remainder `1 % inf`, both `np.divmod` and `tf.experimental.numpy.divmod` on CPU produces `1.0`, but `tf.experimental.numpy.divmod` on GPU produces `nan`.


### Standalone code to reproduce the issue

```shell
print(""numpy"", np.divmod(1.0, np.inf))
with tf.device(""/cpu:0""):
  print(""CPU"", tf.experimental.numpy.divmod(1.0, np.inf))
with tf.device(""/gpu:0""):
  print(""GPU"", tf.experimental.numpy.divmod(1.0, np.inf))
```


### Relevant log output

```shell
numpy (0.0, 1.0)
CPU (<tf.Tensor: shape=(), dtype=float64, numpy=0.0>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0>)
GPU (<tf.Tensor: shape=(), dtype=float64, numpy=0.0>, <tf.Tensor: shape=(), dtype=float64, numpy=nan>)
```
</details>"
58492,Can't build TensorFlowLiteSelectTfOps with -force_load linker flag,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I can't build fresh project after adding linker flag -force_load. I use CocoaPods,TensorFlowLiteSwift and TensorFlowLiteSelectTfOps (~> 0.0.1-nightly).
```


### Standalone code to reproduce the issue

```shell
Create a new Xcode project, install pods, add -force_load linker flag as described in the documentation.
```


### Relevant log output

_No response_</details>
![Screen Shot 2022-11-09 at 17 08 15](https://user-images.githubusercontent.com/15905313/200855987-be2f8b1f-fcff-4b8d-8da8-706c413dac71.png)
![Screen Shot 2022-11-09 at 17 09 12](https://user-images.githubusercontent.com/15905313/200856006-5170aec1-24f2-46d5-8c62-4aabae422ca1.png)
![Screen Shot 2022-11-09 at 17 09 47](https://user-images.githubusercontent.com/15905313/200856009-cc187455-6188-4ff5-a13b-13bd2e8e3818.png)
"
58491,Running TensorFlow on SHArC processors?,Are there any information on the possibility to compile TensorFlow (Lite C) targeting SHArC processor from Analog Devices? 
58490,Training takes much more time after load saved model(pretrained model),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Nvidia A10G x4

### Current Behaviour?

```
Hi all. I have started to train a custom model with my custom dataset. An epoch takes 20 minutes. When I save & load trained model and start training from pretrained model one epoch takes 1 hour to train. I am using multiple GPUs & Tensorflow Saved Model format(.pb). Why this is happening? I have encounter this issue many times and I assume that it is normal but is that normal?
```


### Standalone code to reproduce the issue

```shell
strategy = tf.distribute.MirroredStrategy()
    print(f'Number of devices: {strategy.num_replicas_in_sync}')
    
    with strategy.scope():
        model = model.create_model() # Call model

        # Compile model with 3 different loss with 3 different coeffs.
        model.compile(
            optimizer=Adam(learning_rate=1e-2),
            loss=[
                tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM),
                tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)
            ],
            loss_weights=[3.0,0.02],
            metrics=['accuracy']
        )
    callbacks = [tf.keras.callbacks.ModelCheckpoint(
                    filepath=model_save_path,
                    save_weights_only=True,
                    verbose=1,
                    monitor='loss',
                    mode='min',
                    save_best_only=False),
        tf.keras.callbacks.LearningRateScheduler(scheduler), 
        tf.keras.callbacks.CSVLogger('./model_save/training.log')]
    model.summary()
```

"
58489,`tf.exp` on GPU behaves differently from CPU and numpy when a complex input overflows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

When an input of `tf.complex64` is too big (say `100.+0.j`) and thus causes `np.exp` to overflow, it returns `inf+nanj` on GPU, while `np.exp` and `tf.exp` on CPU return `inf+0.j`. This may affect further computation on the result. 

Since `100+0.j` has zero image part, the overflow should only affect its real part.


### Standalone code to reproduce the issue

```shell
print(""numpy"")
input = np.array([100], dtype=np.complex64)
exp = np.exp(input)
abs = np.abs(exp)
print(input, exp, abs)

with tf.device(""/cpu:0""):
  print(""CPU"")
  input = tf.convert_to_tensor([100], tf.complex64)
  exp = tf.exp(input)
  abs = tf.abs(exp)
  print(input, exp, abs)

with tf.device(""/gpu:0""):
  print(""GPU"")
  input = tf.convert_to_tensor([100], tf.complex64)
  exp = tf.exp(input)
  abs = tf.abs(exp)
  print(input, exp, abs)
```


### Relevant log output

```shell
numpy
[100.+0.j] [inf+0.j] [inf]
CPU
tf.Tensor([100.+0.j], shape=(1,), dtype=complex64) tf.Tensor([inf+0.j], shape=(1,), dtype=complex64) tf.Tensor([inf], shape=(1,), dtype=float32)
GPU
tf.Tensor([100.+0.j], shape=(1,), dtype=complex64) tf.Tensor([inf+nanj], shape=(1,), dtype=complex64) tf.Tensor([nan], shape=(1,), dtype=float32)
/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp
  This is separate from the ipykernel package so we can avoid doing imports until
```
</details>"
58488,File system scheme 's3' not implemented,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Windows11

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
An error occurred when I ran tensorboard using s3 as logdir

tensorboard --logdir=s3://mnist/log --port=6123
```
I find this method is the cause of the problem
```
tf.io.gfile.exists(""s3://minst/log/xxxxxx"") 
```
```


### Standalone code to reproduce the issue


import os

os.environ.setdefault(""S3_ENDPOINT"", ""https://xxxx"")
os.environ.setdefault(""AWS_ACCESS_KEY_ID"", ""xxx"")
os.environ.setdefault(""AWS_SECRET_ACCESS_KEY"", ""xxxx"")
os.environ.setdefault(""AWS_REGION"", ""us-east-1"")

import tensorflow as tf
import tensorflow_io as tfio

gfile = tf.io.gfile.GFile(""s3://minst/log/xxxxxx"")
print(gfile)
# ↑ ↑ ↑ ---------it's ok

v = tf.io.read_file('s3://minst/log/xxxxx')
print(v) 
# ↑ ↑ ↑ ---------it's ok

tf.io.gfile.exists(""s3://minst/log/xxxxxx"")
# ↑ ↑ ↑ ---------error

tensorboard.run_main()
# ↑ ↑ ↑ ---------error

os.system(""tensorboard --logdir=s3://mnist/log --port=6123"")
# ↑ ↑ ↑ ---------error

# will got same error

```

```

### Relevant log output

Traceback (most recent call last):
  File ""D:\Users\xiaojunnuo\Desktop\tensorboard\venv\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 288, in file_exists_v2
    _pywrap_file_io.FileExists(compat.path_to_bytes(path))
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 's3' not implemented (file: 's3://minst/log/xxxxxxxxxxxxxxxx')

```
</details>"
58487,release variable memory api ?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
api can release memory variable
```


### Standalone code to reproduce the issue

```shell
no
```


### Relevant log output

_No response_</details>"
58485,"The tutorial Keras SavedModels from TF 2.7 do not load in TF 2.8, 2.9, 2.10","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

TF 2.7.0 to 2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I ran the official Keras tutorial ""[Structured data classification from scratch](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)"" in TF 2.7, and saved the model as a SavedModel.

This SavedModel successfully loads in TF 2.7, but cannot be loaded TF 2.8, 2.9, or 2.10. Error message:

```
File ~/.../regressor.py:337, in load_model(filepath, library)
--> 337             model = tf.keras.models.load_model(extract_dir)

File ~/.../env/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     65 except Exception as e:  # pylint: disable=broad-except
     66   filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67   raise e.with_traceback(filtered_tb) from None
     68 finally:
     69   del filtered_tb

File ~/.../env/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:56, in _SatisfiesTypeConstraint(dtype, attr_def, param_name)
     54 allowed_values = "", "".join(dtypes.as_dtype(x).name for x in allowed_list)
     55 if dtype not in allowed_list:
---> 56   raise TypeError(
     57       f""Value passed to parameter '{param_name}' has DataType ""
     58       f""{dtypes.as_dtype(dtype).name} not in list of allowed values: ""
     59       f""{allowed_values}"")

TypeError: Exception encountered when calling layer ""string_lookup"" (type StringLookup).

Value passed to parameter 'weights' has DataType string not in list of allowed values: int32, int64, float32, float64

Call arguments received:
  • inputs=tf.Tensor(shape=(None, 1), dtype=string)
```

Based my my tests, here's a compatibility table for saving/loading this model across TF versions:

|                    | Load with TF 2.6 | Load with TF 2.7 | Load with TF 2.8 | Load with TF 2.9 | Load with TF 2.10 |
|--------------------|------------------|------------------|------------------|------------------|-------------------|
| Saved with TF 2.6  | ✅                | ✅                | ❌                | ❌                | ❌                 |
| Saved with TF 2.7  | ❌                | ✅                | ❌                | ❌                | ❌                 |
| Saved with TF 2.8  | ❌                | ❌                | ✅                | ✅                | ✅                 |
| Saved with TF 2.9  | ❌                | ❌                | ✅                | ✅                | ✅                 |
| Saved with TF 2.10 | ❌                | ❌                | ✅                | ✅                | ✅                 |


### Standalone code to reproduce the issue

Colab to train and save the Keras tutorial model: https://colab.research.google.com/drive/1c-UDWPW0OQjbgItijs_4UB4sm-dQ7MdS?usp=sharing

Colab to load the Keras tutorial SavedModel: https://colab.research.google.com/drive/1KM9nUBdsqGFW5zXUuU7b2ZtcKA1BiUXz?usp=sharing

### Relevant log output

_No response_</details>"
58484,Document behavior of tf.keras.layers.Bidirectional with return_state=True,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

source

### Tensorflow Version

2.10

### Custom Code

No
</details>

It is unclear from the documentation how a `tf.keras.layers.Bidirectional` layer will behave if `return_state` is True; ie, in what order the hidden/cell states will be returned, and what, if any, interaction there is with `merge_mode`.

Per the source code, any states of forward layer are returned after the output(s), followed by any states of the backward layer. This should be documented. 

```
if self.return_state:
            states = y[1:] + y_rev[1:]
            y = y[0]
            y_rev = y_rev[0]

# ...

if self.return_state:
            if self.merge_mode is None:
                return output + states
            return [output] + states
        return output

```"
58481,cmake of tensorflowlite for aarch64 failed with EIGEN_STATIC_ASSERT,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

master

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
My workspace has tensorflow master, last commit:
commit 21b567d26ca4cfa5c02260acd77b8b5f2fd57d84 (HEAD -> master, origin/master, origin/HEAD)
Author: Emilio Cota <ecg@google.com>
Date:   Thu Sep 29 15:14:11 2022 -0700

    Update CMakeLists to reflect the Arithmetic->Arith dialect rename

After fixing https://github.com/tensorflow/tensorflow/issues/58476 I installed flatbuff to a directory and set PATH to include that. Then I can continue to build for the shared tensorflowlite lib, according to https://www.tensorflow.org/lite/guide/build_cmake_arm
Pls refer to the log output for the error logs. I think this commit caused problem but I don't know how to fix: https://github.com/tensorflow/tensorflow/commit/09d49d9f6c9c13679ab8181d1b15480ea8a88da1
```


### Standalone code to reproduce the issue

```shell
ARMCC_PREFIX=... (set to our own toolchain)
ARMCC_FLAGS=""-funsafe-math-optimizations""

cmake -DCMAKE_C_COMPILER=${ARMCC_PREFIX}gcc \
  -DCMAKE_CXX_COMPILER=${ARMCC_PREFIX}g++ \
  -DCMAKE_C_FLAGS=""${ARMCC_FLAGS}"" \
  -DCMAKE_CXX_FLAGS=""${ARMCC_FLAGS}"" \
  -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \
  -DCMAKE_SYSTEM_NAME=Linux \
  -DCMAKE_SYSTEM_PROCESSOR=aarch64 \
  ../tensorflow/lite/  -DTFLITE_ENABLE_GPU=ON
cmake --build . -j
```


### Relevant log output

```shell
/opt/workspace/tensorflow/tensorflow/lite/kernels/internal/optimized/multithreaded_conv.h:173:65:   required from here
/opt/workspace/tensorflow/tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1068:27: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE
 1068 |   EIGEN_STATIC_ASSERT((nr == 4), YOU_MADE_A_PROGRAMMING_MISTAKE)
      |                       ~~~~^~~~~
/opt/workspace/tensorflow/tflite_build/eigen/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/StaticAssert.h:26:50: note: in definition of macro 'EIGEN_STATIC_ASSERT'
   26 | #define EIGEN_STATIC_ASSERT(X,MSG) static_assert(X,#MSG);
      |                                                  ^
```
</details>"
58480,Issue created for Rollback of PR #57674: [NVIDIA TF] Enable BF16 Conv Ops,"Merged PR #57674 is rolled back in 3e8539cbca22e04e6e8f6ca30460d526fee4b5aa.
    Please follow up with the reviewer and close this issue once its resolved."
58479,`tf.math.pow()` is inaccurate with some small integer values presented by tf.float32 on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.math.pow() loses accuracy when computing squares of small integer values represented by tf.float32 on GPU, such as 5.0^2.0,  7.0^2.0 and 13.0^2.0. What make this strange are:

- This is not happening on CPU
- The integer values are very small
- This is not happening on tf.float64
```


### Standalone code to reproduce the issue

```shell
ints = tf.convert_to_tensor(np.arange(20, dtype=np.int32), dtype=tf.int32)
floats = tf.cast(ints, dtype=tf.float32)
doubles = tf.cast(ints, dtype=tf.float64)

with tf.device(""/cpu:0""):
  print(""cpu ints^2"", tf.math.pow(ints, 2))
  print(""cpu float32^2"", tf.math.pow(floats, 2.))
  print(""cpu float64^2"", tf.math.pow(doubles, 2.))

with tf.device(""/gpu:0""):
  print(""gpu ints^2"", tf.math.pow(ints, 2))
  print(""INACCURATE gpu float32^2"", tf.math.pow(floats, 2.))
  print(""gpu float64^2"", tf.math.pow(doubles, 2.))
```


### Relevant log output

```shell
cpu ints^2 tf.Tensor(
[  0   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289
 324 361], shape=(20,), dtype=int32)
cpu float32^2 tf.Tensor(
[  0.   1.   4.   9.  16.  25.  36.  49.  64.  81. 100. 121. 144. 169.
 196. 225. 256. 289. 324. 361.], shape=(20,), dtype=float32)
cpu float64^2 tf.Tensor(
[  0.   1.   4.   9.  16.  25.  36.  49.  64.  81. 100. 121. 144. 169.
 196. 225. 256. 289. 324. 361.], shape=(20,), dtype=float64)
gpu ints^2 tf.Tensor(
[  0   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289
 324 361], shape=(20,), dtype=int32)
INACCURATE gpu float32^2 tf.Tensor(
[  0.         1.         4.         9.        16.        24.999998
  36.        48.999996  64.        81.        99.99999  121.
 144.       169.       196.       225.       256.       288.99997
 324.       361.      ], shape=(20,), dtype=float32)
gpu float64^2 tf.Tensor(
[  0.   1.   4.   9.  16.  25.  36.  49.  64.  81. 100. 121. 144. 169.
 196. 225. 256. 289. 324. 361.], shape=(20,), dtype=float64)
```
</details>"
58476,cmake flatbuffer fail with Findflatbuffers.cmake,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tot, e.g. master

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Error message:
CMake Warning at CMakeLists.txt:49 (find_package):
  By not providing ""Findflatbuffers.cmake"" in CMAKE_MODULE_PATH this project
  has asked CMake to find a package configuration file provided by
  ""flatbuffers"", but CMake did not find one.

  Could not find a package configuration file provided by ""flatbuffers"" with
  any of the following names:

    flatbuffersConfig.cmake
    flatbuffers-config.cmake

Root cause:
I debugged this issue and the root cause is that:
- In this commit, flatbuffer is changed to Flatbuffer: # https://github.com/tensorflow/tensorflow/commit/539438c52dca142c13f244aa0a084698a978bcda
- However this file is not changed: tensorflow/lite/tools/cmake/native_tools/flatbuffers/CMakeLists.txt 
It still says: find_package(flatbuffers)
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/cmake/native_tools/flatbuffers/CMakeLists.txt#L43
```


### Standalone code to reproduce the issue

```shell
Followed the steps here: https://www.tensorflow.org/lite/guide/build_cmake
Error happens when you do:
mkdir flatc-native-build && cd flatc-native-build
cmake ../tensorflow_src/tensorflow/lite/tools/cmake/native_tools/flatbuffers
```


### Relevant log output

_No response_</details>"
58472,//tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test fails on high CPU count,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.10

### Bazel version

5.3.0

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
On a machine with a high CPU core count, //tensorflow/python/data/experimental/kernel_tests/service:cross_trainer_cache_test will fail due to prefetching more data than the test allows for.
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=500,900,-1,-1 --flaky_test_attempts=1 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --build_tests_only --test_lang_filters=cc,py -- //tensorflow/python/data/experimental/kernel_tests/service:cross_trainer_cache_test
```


### Relevant log output

```shell
======================================================================
FAIL: testConcurrentReaders_test_mode_graph_tfapiversion_2 (__main__.CrossTrainerCacheTest)
CrossTrainerCacheTest.testConcurrentReaders_test_mode_graph_tfapiversion_2
testConcurrentReaders_test_mode_graph_tfapiversion_2(mode='graph', tf_api_version=2)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.runfiles/absl_py/absl/testing/parameterized.py"", line 314, in bound_param_test
    return test_method(self, **testcase_params)
  File ""/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.runfiles/org_tensorflow/tensorflow/python/framework/test_combinations.py"", line 360, in decorated
    execute_test_method()
  File ""/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.runfiles/org_tensorflow/tensorflow/python/framework/test_combinations.py"", line 343, in execute_test_method
    test_method(**kwargs_to_pass)
  File ""/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.runfiles/org_tensorflow/tensorflow/python/data/experimental/kernel_tests/service/cross_trainer_cache_test.py"", line 136, in testConcurrentReaders
    self.assertEqual(self.evaluate(iterators[j]()), i)
AssertionError: 26 != 0

----------------------------------------------------------------------
Ran 9 tests in 4.935s

FAILED (failures=1)
2022-11-07 18:30:46.995018: I tensorflow/core/data/service/server_lib.cc:91] Shut down WorkerServer server running at port 46333
2022-11-07 18:30:46.995434: I tensorflow/core/data/service/server_lib.cc:91] Shut down DispatchServer server running at port 46249
================================================================================
```
</details>"
58469,`tf.raw_ops.SegmentMax` Behaves Differently Under CPU and GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

A test case for `tf.raw_ops.SegmentMax` behaves differently under CPU and GPU.
* Under CPU, the test reports an invalid argument error, with return code 1.
* Under GPU, the test terminates normally with return code 0. Additionally, we use compute sanitizer to run the GPU version and it reports an out-of-bound read error.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# This is the GPU version test. To use CPU, comment this line and uncomment the next line
device = '/GPU:0'
# device = '/CPU'

def test():
  with tf.device(f'{device}'):
    data_tensor = tf.random.uniform([3, 1, 2, 3], dtype=tf.float32)
    data = tf.identity(data_tensor)
    segment_ids_0 = -9
    segment_ids_1 = -1024
    segment_ids_2 = 0
    segment_ids = [segment_ids_0,segment_ids_1,segment_ids_2,]
    name = None
    _ = tf.raw_ops.SegmentMax(data=data,segment_ids=segment_ids,name=name,)

test()
```


### Relevant log output

```shell
# Under CPU, there's an invalid argument error:

tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__SegmentMax_device_/job:localhost/replica:0/task:0/device:CPU:0}} segment ids are not increasing [Op:SegmentMax]

# Under GPU, nothing happens.

# The error outputs from compute sanitizer are shown as follows:
========= COMPUTE-SANITIZER
========= Invalid __global__ read of size 4 bytes
=========     at 0x3b0 in void tensorflow::SortedSegmentReductionCustomKernel<float, int, (int)8, tensorflow::NonAtomicMaxOpGpu, tensorflow::AtomicMaxOpGpu>(T2, T2, T2, const T2 *, const T1 *, T1 *, T2, T1)
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x7fd033ffa700 is out of bounds
=========     and is 22,784 bytes before the nearest allocation at 0x7fd034000000 of size 13,682,147,328 bytes
=========
========= Invalid __global__ read of size 4 bytes
=========     at 0x3b0 in void tensorflow::SortedSegmentReductionCustomKernel<float, int, (int)8, tensorflow::NonAtomicMaxOpGpu, tensorflow::AtomicMaxOpGpu>(T2, T2, T2, const T2 *, const T1 *, T1 *, T2, T1)
=========     by thread (1,0,0) in block (0,0,0)
=========     Address 0x7fd033ffa704 is out of bounds
=========     and is 22,780 bytes before the nearest allocation at 0x7fd034000000 of size 13,682,147,328 bytes
=========
========= Invalid __global__ read of size 4 bytes
=========     at 0x3b0 in void tensorflow::SortedSegmentReductionCustomKernel<float, int, (int)8, tensorflow::NonAtomicMaxOpGpu, tensorflow::AtomicMaxOpGpu>(T2, T2, T2, const T2 *, const T1 *, T1 *, T2, T1)
=========     by thread (2,0,0) in block (0,0,0)
=========     Address 0x7fd033ffa708 is out of bounds
=========     and is 22,776 bytes before the nearest allocation at 0x7fd034000000 of size 13,682,147,328 bytes
=========
========= Invalid __global__ read of size 4 bytes
=========     at 0x3b0 in void tensorflow::SortedSegmentReductionCustomKernel<float, int, (int)8, tensorflow::NonAtomicMaxOpGpu, tensorflow::AtomicMaxOpGpu>(T2, T2, T2, const T2 *, const T1 *, T1 *, T2, T1)
=========     by thread (3,0,0) in block (0,0,0)
=========     Address 0x7fd033ffa70c is out of bounds
=========     and is 22,772 bytes before the nearest allocation at 0x7fd034000000 of size 13,682,147,328 bytes
=========
========= Invalid __global__ read of size 4 bytes
=========     at 0x3b0 in void tensorflow::SortedSegmentReductionCustomKernel<float, int, (int)8, tensorflow::NonAtomicMaxOpGpu, tensorflow::AtomicMaxOpGpu>(T2, T2, T2, const T2 *, const T1 *, T1 *, T2, T1)
=========     by thread (4,0,0) in block (0,0,0)
=========     Address 0x7fd033ffa710 is out of bounds
=========     and is 22,768 bytes before the nearest allocation at 0x7fd034000000 of size 13,682,147,328 bytes
=========
========= Invalid __global__ read of size 4 bytes
=========     at 0x3b0 in void tensorflow::SortedSegmentReductionCustomKernel<float, int, (int)8, tensorflow::NonAtomicMaxOpGpu, tensorflow::AtomicMaxOpGpu>(T2, T2, T2, const T2 *, const T1 *, T1 *, T2, T1)
=========     by thread (5,0,0) in block (0,0,0)
=========     Address 0x7fd033ffa714 is out of bounds
=========     and is 22,764 bytes before the nearest allocation at 0x7fd034000000 of size 13,682,147,328 bytes
=========
========= ERROR SUMMARY: 10 errors
```
</details>"
58468,Visualizing class activation maps with tflite weights,"I am able to visualize Grad-CAM using keras weights(H5). I am not able to find to visualize last CNN layer using tflite weights.

- https://pyimagesearch.com/2020/03/09/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning/
- https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759

Found a related link on TF discussion forum mentioning that this is not possible as of 2021.

- https://discuss.tensorflow.org/t/applying-grad-cam-to-a-model-that-was-converted-to-tensorflow-lite/3810/7

Can you please provide a sample code to execute this
OR guide me with a suitable documentation.
- To model.summary() equivalent for tflite
- Code to visualize last CNN feature map
"
58467,"I met an error: In[o] missmatch In[1] shape""3 vs/4:[1,4,4,3] [1,4,4,1]","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

tf 2.5

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
I wanna to matmul A[1,4,4,3] with B[1,4,4,1] then get C [1,4,4,3]
```


### Standalone code to reproduce the issue

```shell
input_size=[1,4,4,3]
input_feature=tf.random.normal(input_size)
signal=tf.random.normal([1,4,4,1])
input_feature_=tf.matmul(input_feature,signal)
```
```


### Relevant log output

_No response_</details>"
58466,tf.queue.FIFOQueue not savable by tf.saved_model.save in tf2.10,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

windows 10

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

8.2.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tensorflow cannot save successfully when there exists `tf.queue.FIFOQueue` variable in cumstum layers by `tf.saved_model.save`
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf

from tensorflow import keras as K


class HashtableEmb(K.Model):
    def __init__(self, training=True, key_dtype=tf.int64, value_dtype=tf.int32):
        K.Model.__init__(self)
        self.training = training
        self.key_dtype = key_dtype
        self.value_dtype = value_dtype

    def build(self, input_shape):
        self.DEFAULT_KEY = 0
        self.DEFAULT_VALUE = 0
        self.default_key = tf.constant(self.DEFAULT_KEY, dtype=self.key_dtype)
        self.empty_key = np.iinfo(np.int64).max
        self.deleted_key = np.iinfo(np.int64).min
        self.default_value = tf.constant(self.DEFAULT_VALUE, dtype=self.value_dtype)
        kw = dict(key_dtype=self.key_dtype, value_dtype=self.value_dtype,
                  default_value=self.default_value, empty_key=self.empty_key, deleted_key=self.deleted_key)
        self.index_table = tf.lookup.experimental.DenseHashTable(**kw)
        if self.training:
            self.index_table.insert(self.default_key, self.default_value)
        self.default_ids_queue = tf.queue.FIFOQueue(2_000_000, self.key_dtype, shapes=[],
                                                    name=f'default_ids_queue')
        self.built = True

    def call(self, ids, training=None):
        flatten_ids = tf.reshape(ids, [-1])
        ids_value = self.index_table.lookup(flatten_ids)
        if training: self.update_stat(flatten_ids)
        ids_index_orig = tf.reshape(ids_value, tf.shape(ids))
        return ids_index_orig

    def get_config(self):
        return dict(
            training=self.training,
            key_dtype=self.key_dtype,
            value_dtype=self.value_dtype,
            **(super(K.Model, self).get_config()))

    def update_stat(self, flatten_ids):
        flatten_ids = tf.identity(flatten_ids)
        self.default_ids_queue.enqueue_many(flatten_ids)  # comment this line, no exception


class TestModel(tf.keras.Model):
    def __init__(self):
        super(TestModel, self).__init__()

    def build(self, input_shape):
        self.hashemb = HashtableEmb()
        self.built = True

    def call(self, x, training=None):
        return {'y_click': self.hashemb(x['a'], training=training)}
 

if __name__ == '__main__':
    m = TestModel()
    print(m({'a': tf.convert_to_tensor([[2], [200]], dtype=tf.int64)}))
    signatures = {'serving_default': tf.function(m.call).get_concrete_function(
        x={'a': tf.TensorSpec([None, 1], dtype=tf.int64)}, training=False)}
    tf.saved_model.save(m, r'G:\t\test_model_save', signatures=signatures)
    m2 = tf.saved_model.load(r'G:\t\test_model_save')
    print(m2({'a': tf.convert_to_tensor([[2], [200]], dtype=tf.int64)}))
```


### Relevant log output

```shell
2022-11-07 13:43:01.371282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2824 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0
{'y_click': <tf.Tensor: shape=(2, 1), dtype=int32, numpy=
array([[0],
       [0]])>}
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\function_serialization.py"", line 60, in serialize_concrete_function
    bound_inputs.append(node_ids[capture])
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\util\object_identity.py"", line 135, in __getitem__
    return self._storage[self._wrap_key(key)]
KeyError: <_ObjectIdentityWrapper wrapping <tf.Tensor: shape=(), dtype=resource, value=<ResourceHandle(name=""28"", device=""/job:localhost/replica:0/task:0/device:CPU:0"", container=""localhost"", type=""class tensorflow::QueueInterface"", dtype and shapes : ""[  ]"")>>>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/code/save_queue_op_test.py"", line 71, in <module>
    tf.saved_model.save(m, r'G:\t\test_model_save', signatures=signatures)
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1232, in save
    save_and_return_nodes(obj, export_dir, signatures, options)
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1268, in save_and_return_nodes
    _build_meta_graph(obj, signatures, options, meta_graph_def))
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1441, in _build_meta_graph
    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\save.py"", line 1406, in _build_meta_graph_impl
    asset_info.asset_index)
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\save.py"", line 968, in _serialize_object_graph
    concrete_function, saveable_view.captured_tensor_node_ids)
  File ""C:\ProgramData\Anaconda3\envs\ai_tf2\lib\site-packages\tensorflow\python\saved_model\function_serialization.py"", line 63, in serialize_concrete_function
    f""Failed to add concrete function '{concrete_function.name}' to object-""
KeyError: 'Failed to add concrete function \'b\'__inference_test_model_layer_call_fn_262\'\' to object-based SavedModel as it captures tensor <tf.Tensor: shape=(), dtype=resource, value=<ResourceHandle(name=""28"", device=""/job:localhost/replica:0/task:0/device:CPU:0"", container=""localhost"", type=""class tensorflow::QueueInterface"", dtype and shapes : ""[  ]"")>> which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).'
```
</details>"
58465,tf.keras.utils.plot_model fails and outputs large byte string,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Nvidia Gtx 1070

### Current Behaviour?

```shell
I expect tf.keras.utils.plot_model to create a ong file that shows the model structure. I don't expect an error or a large byte string to be printed.
```


### Standalone code to reproduce the issue

```shell
def build_preprocessing_model(features):
    # Build the preprocessing model
    inputs = {}

    for name, column in features.items():
        dtype = column.dtype
        if dtype == object:
            dtype = tf.string
        else:
            dtype = tf.float32

        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)
    # print(inputs)
    
    # Concatenate numeric inputs
    numeric_inputs = {name: input for name, input in inputs.items() if input.dtype==tf.float32}
    # print(numeric_inputs)
    x = layers.Concatenate()(list(numeric_inputs.values()))
    norm = layers.Normalization()
    norm.adapt(np.array(features[numeric_inputs.keys()]))
    all_numeric_inputs = norm(x)
    # print(all_numeric_inputs)

    preprocessed_inputs = [all_numeric_inputs]

    for name, input in inputs.items():
        if input.dtype == tf.float32:
            continue

        output_sequence_length = get_output_sequence_length(features[name])
        text_vectorizer = layers.TextVectorization(output_sequence_length=output_sequence_length)
        text_vectorizer.adapt(features[name])
        x = text_vectorizer(input)
        print(x.shape)

        x = tf.cast(x, tf.float32)
        preprocessed_inputs.append(x)
    # print(preprocessed_inputs)
    
    # for preprocessed_input in preprocessed_inputs:
    #     print(preprocessed_input)

    # outputs = layers.Concatenate()(preprocessed_inputs)
    outputs = preprocessed_inputs

    mtg_preprocessing = tf.keras.Model(inputs, outputs)

    return mtg_preprocessing, inputs


def build_mtg_model(preprocessing_head, inputs):
    preprocessed_inputs = preprocessing_head(inputs)
    # print(preprocessed_inputs[1])

    x = layers.Concatenate()(preprocessed_inputs)

    x = layers.Dense(units=128, activation=""relu"")(x)

    outputs = layers.Dense(units=5, activation=""sigmoid"")(x)

    model = tf.keras.Model(inputs, outputs)

    model.compile(
        loss=tf.keras.losses.BinaryCrossentropy(),
        optimizer=tf.keras.optimizers.Adam(),
        metrics=[""acc""],
    )
    return model

# Build the preprocessing model
mtg_preprocessing, inputs = build_preprocessing_model(mtg_features)
# Build the training model model = build_mtg_model(mtg_preprocessing, inputs)    

model = build_mtg_model(mtg_preprocessing, inputs)

tf.keras.utils.plot_model(
    model=model,
    show_shapes=True,
    to_file=""training_model.png""
)
```


### Relevant log output

```shell
Model: ""model""
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 convertedManaCost (InputLayer)  [(None, 1)]         0           []

 is_creature (InputLayer)       [(None, 1)]          0           []

 type (InputLayer)              [(None, 1)]          0           []

 text (InputLayer)              [(None, 1)]          0           []

 name (InputLayer)              [(None, 1)]          0           []

 concatenate (Concatenate)      (None, 2)            0           ['convertedManaCost[0][0]',
                                                                  'is_creature[0][0]']

 text_vectorization (TextVector  (None, 5)           0           ['type[0][0]']
 ization)

 text_vectorization_1 (TextVect  (None, 126)         0           ['text[0][0]']
 orization)

 text_vectorization_2 (TextVect  (None, 25)          0           ['name[0][0]']
 orization)

 normalization (Normalization)  (None, 2)            5           ['concatenate[0][0]']

 tf.cast (TFOpLambda)           (None, 5)            0           ['text_vectorization[0][0]']

 tf.cast_1 (TFOpLambda)         (None, 126)          0           ['text_vectorization_1[0][0]']

 tf.cast_2 (TFOpLambda)         (None, 25)           0           ['text_vectorization_2[0][0]']

==================================================================================================
Total params: 5
Trainable params: 0
Non-trainable params: 5
__________________________________________________________________________________________________
None
Model: ""model_1""
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 convertedManaCost (InputLayer)  [(None, 1)]         0           []

 is_creature (InputLayer)       [(None, 1)]          0           []

 name (InputLayer)              [(None, 1)]          0           []

 text (InputLayer)              [(None, 1)]          0           []

 type (InputLayer)              [(None, 1)]          0           []

 model (Functional)             [(None, 2),          5           ['convertedManaCost[0][0]',
                                 (None, 5),                       'is_creature[0][0]',
                                 (None, 126),                     'name[0][0]',
                                 (None, 25)]                      'text[0][0]',
                                                                  'type[0][0]']

 concatenate_1 (Concatenate)    (None, 158)          0           ['model[0][0]',
                                                                  'model[0][1]',
                                                                  'model[0][2]',
                                                                  'model[0][3]']

 dense (Dense)                  (None, 128)          20352       ['concatenate_1[0][0]']

 dense_1 (Dense)                (None, 5)            645         ['dense[0][0]']

==================================================================================================
Total params: 21,002
Trainable params: 20,997
Non-trainable params: 5
__________________________________________________________________________________________________
None
""dot"" with args ['-Tpng', 'C:\\Users\\urkch\\AppData\\Local\\Temp\\tmpsyy85adl'] returned code: 1

stdout, stderr:
 b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x067\x00\x00\x01\xf7\x08\x06\x00\x00\x00\xf7\xf1\r\x05\x00\x00\x00\x06bKGD\x00\xff\x00\xff\x00\xff\xa0\xbd\xa7\x93\x00\x00 \x00IDATx\x9c\xec\xdd{pT\xe7}\xff\xf1\xcf""\t|E\xd8`.\x06\xc4\x1d\t\xc9F\xd4n]0\xae\x9d\x10\x9a\xd8\xd8+;\x0e\x0b\x88\x98\xf14\x05\x17\xd2\xe6N\x7f\x93!b<1L\x9aNE\xe2N<\xb1G""m]bK b\x8c\xe4Kb\x03\xae]\x1b)\x17\x07\t\xd0\x15\x10H`b\xc9v\x90l.\x02\x84\xce\xef\x0f\xf5,{\x95vW\xbb{\xf6\xec\xbe_3\x1a\xd0^\x9e}\xce9\xcf\xf3\xdds\xceW\xcf\xf38\x0c\xc30\x04\x00\x00\x00\x00\x00\x00\x00\x00`\x13\xc3\xac\xae\x00\x00\x00\x00\x00\x00\x00\x00\x00@8Hn\x00\x00\x00\x00\x00\x00\x00\x00\x00[!\xb9\x01\x00\x00\x00\x00\x00\x00\x00\x00l\x85\xe4\x06\x00\x00\x00\x00\x00\x00\x00\x00\xb0\x95t\xdf\x07\xaa\xab\xab\xf5\x93\x9f\xfc\xc4\x8a\xba\x00\x00\xfe\xcfw\xbf\xfb]-X\xb0 &e\x13\xe7\x01\xc4\xcb\x82\x05\x0b\xf4\xdd\xef~7&e\xff\xe4\'?QuuuL\xca\x06\x00O\xb1</s\xb9\\1)\x17\x00|UTT\xc4\xa4\\\xae/\x01\xc4K\xa0\xebK\xbf\x91\x1b\'O\x9e\xd4\xce\x9d;\xe3V) \x1av\xee\xdc\xa9S\xa7NY]\x8d\x84w\xea\xd4)\xfa\xb7\r\xec\xdc\xb9S\'O\x9e\x8cY\xf9\xc4\xf9\xc4USS\xa3\x9a\x9a\x1a\xab\xaba\x0b\xc4\xfd\xc4WSS\x13\xd3\xe4Cuu5\xfd%A\xd1?C\xc3y\x99=\xc4\xfa\xbc\x8c\xfe\x92\x98\xe8\x9f\xa1\xe3\xfc5\xf1\xc5\xba=s}\x99\xb8\xe8\x9f\xa1\xe3\xfb8\xf1\x05\xbb\xbe\xf4\x1b\xb9a\x8aUF\x17\x88\x05\x87\xc3\xa1\xef|\xe7;Z\xb6l\x99\xd5UIh;v\xec\xd0\xf2\xe5\xcb\xe9\xdf\t\xce\xe1p\xc4\xe5sh\x07\x89\xc7\xfc\xebM\x8e\xcd\xe0\x88\xfb\x89/\x1e\x7f\x8d<\x7f\xfe|\xfaK\x02\xa2\x7f\x86\x86\xf32{\x88\xc7y\x19\xfd%\xf1\xd0?C\xc7\xf9k\xe23\xdbs\xac\xd1\x06\x12\x0f\xfd3t\x9c\xbf&\xbe`\xd7\x97\xac\xb9\x01\x00\x00\x00\x00\x00\x00\x00\x00l\x85\xe4\x06\x00\x00\x00\x00\x00\x00\x00\x00\xb0\x15\x92\x1b\x00\x00\x00\x00\x00\x00\x00\x00\xc0VHn\x00\x00\x00\x00\x00\x00\x00\x00\x00[!\xb9\x01\x00\x00\x00\x00\x00\x00\x00\x00l\x85\xe4F\x8ctvv\xaa\xbc\xbc\\\x05\x05\x05VW\x05a\xd8\xb8q\xa36n\xdchu5\x12\x8a\xc3\xe1\xf0\xfa\t\xa4\xb3\xb3S[\xb6l\x89s\xcd\xac\xb5e\xcb\x16uww\x07|.\x94}f7\xf4\r\xfb\xe1\x98y#\x96\x05\x96j\xb1\x0c\xf6B\x1c\xf3G,\x0b\x8cX\x86DF,\xf3G,\x0b\x8cX\x86DF,\xf3F\x1c\x0b\xcc\x8a8Fr\xc3GwwwTv\xf0\x93O>\xa9\xc2\xc2BUUUI\xf2?\x80555A\xdf[SS\x93\x10_\\555\xda\xb8q\xa3\xbb\x0e\x1b7nT]]\x9d:;;cR\xa7h\xed{;K\xe4}`\x18\x86\x0c\xc3\xf0{\xbc\xb3\xb3SO>\xf9\xa4\xae\xbf\xfez\xaf\xb6\x12\x88o\xbbN\xd4m\x95\xfa\x8fEMM\x8dJKK\x03&)\x17/^\xacU\xabV\xa9\xb3\xb3\xd3\xef\xb9`\xfb\n\x89%\x91\xfb[2H\xd4\xfdK,\xf3F,\x03\x82K\xd48&\x11\xcb|\x11\xcbb#V} \x91\xfbV2J\xe4\xfdM,\xf3F,\x8b\x9eDn\xf7\x88L\xa2\x1eS\xe2\x987+\xe2Xz\xd4K\xb4\xb9w\xdey\'*\xe5<\xfb\xec\xb3z\xee\xb9\xe7\xdc\xbf\x1b\x86\xa1\xf6\xf6vM\x992E\x92\xf4\xfc\xf3\xcfk\xfe\xfc\xf9\x01\xdf\xfb\xfc\xf3\xcf\xbb\xff\xdf\xd1\xd1\xa1\xb1c\xc7F\xa5N\xe1\xd8\xb8q\xa3>\xfe\xf8c}\xe7;\xdf\xd1\xa6M\x9b$\xf5w\xcc\xdf\xfe\xf6\xb7\x9a7o^L>3Z\xfb~(\xccm\xb5J""\xec\x83ptwwk\xf5\xea\xd5\xda\xb0a\x83\xe6\xcf\x9f\xaf\xc2\xc2B\xbd\xfe\xfa\xeb*,,\x94\xe4\xbf?\r\xc3Pgg\xa7\xc6\x8d\x1bgY\xdb\x0eUqq\xb1$i\xf3\xe6\xcd\x01\x9f\xcf\xcf\xcf\xd7\x86\r\x1b\xb4z\xf5jm\xdb\xb6M\x99\x99\x99\xf1\xac^\xdcY\xdd7b\xc1n\xfd-\\V\x1f3;\xed_bY\xea\xc42\xd8\x0bq,<\xc42bY\xb4\xc5\xaa\x0f\xd8\xado\r\x15\xb1,<\xc42bY4\xd8\xad\xdd\xdb\x01\xb1,t\xc4\xb1\xf8\xc61Fnx\xe8\xee\xeeViii\xcc\xca\xcf\xca\xca\x92\xd4\xdf\x10\x9e{\xee9\xb5\xb7\xb7\xfb\xbd\xa6\xbd\xbd]3g\xcet\xffnUb\xa3\xae\xaeN\xcf>\xfb\xacf\xcf\x9e\xedU\x17\xa7\xd3\xa9\xea\xea\xea\xa8\x7ff\xac\xf7\xbd\x1d\xd8q\x1fl\xdd\xbaU\xf9\xf9\xf9\xeeD]ff\xa6V\xacX!\xa9?\xd0\x95\x97\x97\xfb\xbd\xc7l\xd3\x89\x1c\xac\xa5\xfe/\x9b\xc1\xbe\xbc\xe7\xcf\x9f\xaf\x89\x13\'j\xeb\xd6\xadq\xaa\x15\xa2\xc5\x8e\xfd\xcdN\xec\xb6\x7f\x89e\xc42\xc0\x97\xdd\xe2\x98D,#\x96EW\xac\xfa\x80\x1d\xfb\x96\x9d\xd9q\x7f\x13\xcb\x88eCe\xc7v\x8f\x81\xd9\xed\x98\x12\xc7\xe2\x1b\xc7\xa2\x96\xdc\xe8\xee\xeeVyy\xb9{\xf8L\xa0F\x17\xe85\x9e\xc3T|\xd7\xa9\xa8\xaa\xaa\x92\xc3\xe1PAA\x81\xda\xdb\xdb\x07\x9c\xaei\xcb\x96-\xee\xc7\xcc\xa4\x819\xb7\x99Y\xc6\xbe}\xfb\xdc\x8fWUU\xa9\xa0\xa0@\xdd\xdd\xddZ\xb7n\x9d6n\xdc\xa8\xe2\xe2b\xbfi\xa4<\xeb\x16\xa8\xac@\xdbVPP\xa0\x96\x96\x96\xa0\xfbj\xf1\xe2\xc5\x92\xa4\xfd\xfb\xf7\xfb=\xb7\x7f\xff~\xf7\xf3\x81\xf6_ii\xa9\xd7p&s\xff\r\xb6\xefB)C\xea\x9f\x8aj\xf3\xe6\xcd\xda\xb0aC\xd0\xfa\x07\x1aq2\xd8\xb15\x99\xfb\xd0|\xde\xdc\xc7\x03\xed\xfbx\xf1\xdd\x87\xa1\xecS\xcf\xb6$\xc9\xbdo\xd7\xad[\xe7\xd5\x06\x02\xb5Y\xdf\xc7\x82\xed\x83D\x9d\xd7\xb0\xb3\xb3S\xeb\xd7\xaf\xd7\xe7?\xff\xf9\x80\xcf\x17\x17\x17\xab\xb0\xb00`\xd0\x0ed\xa8\xf1\xc1\xb7n\x03\xf5\xd7hr\xb9\\Z\xbf~}\xc0\xf6\x9e,\x82\xad!\x14\xac?\x87k\xa0\xef\x8f`\xf1\xda\xf3\xf9`\xc7z\xa0x\x17\xa8\xbf\x85\xd2O\x87R\x9fx""\x9e\x85\x8eX\xd6/\x15bY\xb4E\xe3\xdc+X\x19\xeb\xd6\xads\x97a\xb6\'\xcf\xc7<\xeb\x90\x081\'\x16\x88c\xe1!\x96\xf5#\x96EO$\xd7\xc6\x81\xce\xa7|\x1fK\x84\xeb\xbex""\x96\x85\x87X\xd6\x8fX64\x83]\xeby\xae\x81\xe0y/\xf1\x0f\x7f\xf8CH}\xcf\x94\xcc\xe7a\xbe\x88e\xa1#\x8e\xf5\x8bk\x1c3|l\xdf\xbe\xdd\x08\xf0\xf0\xa0\x9cN\xa7QTT\xe4\xfe}\xed\xda\xb5^\xbf\x9b\xaf)))1\x0c\xc30:::\x0c\xa7\xd3i8\x9dN\xa3\xab\xab\xcb\xfd\xbc$C\x92Q]]m\x18\x86a\xb4\xb5\xb5\x19\x92\x8c\xb5k\xd7\x1a\x86a\x18{\xf7\xee5$\xf9\x95m\x18\x86QTTd\xd4\xd6\xd6z\x95_VV\xe6\xf5\xbe\xda\xdaZ\xbf\xcf\xa9\xad\xadu\x97o>\xeei\xa0\xb2<\xb7m\xed\xda\xb5\xeem)++\x0bX\x96\xf9\xfb\xda\xb5k\x03\xee\xe7\x81\xeaa\xbe\xa7\xa3\xa3\xc3o\xbf\x84\xb2\xef\x06+\xc3\xdc\x87\xe6\xf3\xe1\x18\xec\xd8\x1a\x86a\x14\x17\x17\x1bmmm\x86a\x18FWW\x97\xfb\xb3<\xf7M$m\xcf|\xef\xf6\xed\xdb#z\xaf\xc9s\x1f\xfa\xfe\x1el\x9f\x9a\xcf{\xbe\xa6\xab\xab\xcb\xbd\x9f\x9b\x9b\x9b\r\xc3\xe8\xdf\'\xbe\xdbg\x965\xd8>(**\n\xd8\xde#\x11I\xff\x0ev\\*++\rI\xeec\xea\xfb\x1e\xc3\xb8\xda\x9e<\xfb\x8a\xe7\xf3\x9e\xa2\x11\x1f<\xdf;P\x7f\r\xc7`\xed\xd2\xacCeee\xd8\xef\x1d\xe83\x87\xda\x9e\x07\x12n;\xf0\xed\x1b\x861x\x7f\x0e\xc7@\xdf\x1f\x03\xc5\xeb\xc1\x8e\xf5`\xf1\xcew\x9bB\xe9\xa7C\xa9O(\x96.]j,]\xba4\xf4\x9d\x17D*\xc4\xb3p\xfb\t\xb1,\xfe\xb1,Z\xed\xd9\xaa\xf2\x07\x13\x8ds/\xcf2\xccc[]]\xed~M<\xdbH4q^\x16\x1a\xce\xcb\xc2\x97\x8c\xe7e\xb1.\x7f(\x02\xed\xb3\xc1\x8eiII\x89;\xe6y\xbe\xde\xf3\x98Gz,\xe2)\xd2\xfb""\xbeR!\x96E\xf2}L,\x8bo,\x8bV{\xb6\xaa\xfcH\xf8\xee\'\xcf\xf3+_N\xa7\xd3\xab?\r\xd6\xf7\x0c#\xb1\xcf\xc3<q}\x19:\xae/\xc3\x93H\xd7\x97QIn\x987\xf2=o\x88WWW\x1bN\xa7\xd3\xfd\xbb\xb9\xd3|_#\xc9\xbdc\r#\xf0\x06\xfa>f6\x02\xcf\x1b\xe7\xe6\xcd5\xdf:\xf9\x96c\xbe\xc6,\xd3\xb3\x8c`\x9f?XYf\xc3\xf5\x0ct]]]A\xb7\xc5s\x7f\x98\r\xcf0\x0c\xa3\xb6\xb6\xd6\xd8\xbbwo\xd0z\x14\x15\x15\rxc.\xd4}\x17n\x19\x83\t\xe7\xd8z\xbe\xc6\x0c`C\xf9l\xcf\xf7F\xe3\xa2 \x92}\x1a\xe85\xb5\xb5\xb5\x86$\xa3\xb8\xb8x\xc8eES4/\xa2\x07\xba\x99m>\xde\xd5\xd5\xe5\x0e\xb4\x9e\xfd\xc3\xf7}\xd1\x8c\x0f\x83\xf5\xd7p\rvL\xcc\xbe\xeey\xacC}\xef@\x9f\x99H\xc9\r\xc3\x08\xdcV\x07\xea\xcf\xa1\n\xe5\xfb#X\xbc\x1e\xecXG#f\x0e\xf4\xbep\xeb\x13\x8ah\xde\xacM\xf6x\x16n?!\x96\xc5?\x96%{r\xc30bw\xeeeE\x1b\x89&\xce\xcbB\xc3yY\xf8\x92\xf1\xbc,\xd6\xe5\x0fE\xa0}\x16\xca1\xf5L\xea\x16\x17\x17\xfb\xfd\xe1\\\xac\xfbV4D\xf3fm\xb2\xc7\xb2h&7\x88e\xfd\xa2\x1d\xcbHn\xf4+..6$\xef\x9b\xce\xb5\xb5\xb5\x83\xb6\x87@}/\x91\xcf\xc3<q}\x19\xbap\xbf\x8f\x89c\x89s}\x19\x95\xe4\x86y@\x06\x12h\xa4\x82\xb9\xa1\x81nbyU\xd2\xe71\xb3#x\x1e\xc8\xbd{\xf7\xfa\x8d\xa40\xdf\xe7\xfb\x13\xecs\x82=>XY\xc1Fa\x04\xdb\x16\xcf\xff\xfb\x8e\x9a\x18\xe8\xbd\xa6\xb6\xb66wP\x0e7\xb0DR\xc6`B=\xb6\xe6\xeb\xca\xca\xca\xfcn\nF\xfa\xd9\x9e\xefM\xa4\x8b\xe8h\x97\x15-\xd1\xbc\x88\x1e\xa8\xae\x9e\x8f\x9b7\xbd\xcd\xbf\x86\xf0}\xde0\xa2\x1b\x1f\x06\xeb\xaf\xe1\n\xe5\xbd\x91\xec\xa3\xc1\xcaK\xf4\xe4\xc6`\xfd9T\xa1|\x7f\x04\xdb\x8f\xa1\x1e\xeb\xa1\xc6\xccP\xfbi4\xda^""\x9e|F\xbb\xach\t\xb7\x9f\x10\xcb\xe2\x1f\xcbHnx\x8bv,\x8av\x1b\x89\xa6h}\x8f%{\x1c\xe3\xbc,|V\xc4\xb2h\xb5g\xab\xca\x1f\x8a@\xfb,\x94c\xea\xd9\xce<o\xda\x0cTn\xa2I\xc4\xe4F\xb4\xcb\x8a\x96h&7\x88e\x83\xbf&\x92\xcf%\xb9\xd1\xcf\xbc\x97h\xfe\x15\xbcax\xcfH\x10\xec}\x81\x1eO\xe4\xf30O\\_\x86.\xdc\xefc\xe2X\xe2\\_\xfa\x95\x14\xcd\x93\xecP^\x13I\x836\x0c\xc3=\x0c\xc7\xe4\x9bi\x1a\xacN\xe1\xec\xe0h\x97e2\xb3fmmmFGG\xc7\xa0Y7\xc3\xe8\x1f\xe6k\x9e$F\xba\xef\x06*\xc3\xec8\xe1\xdc\xac\x0cu\xfb\x9b\x9b\x9b\xbd:\x93o\xf6n\xa8\x9d\x8a\x8b\xe8\xc1Yq\x11m\x18WO""\xcc\xa1s\xa1\xf6\xb1D\xd8\x87V\x04\xech\xb5\xe7`\xa2\xd1\x0e\x06\xeb\xcf\x91\x96\x1b\xcekByo4bf\xa4}>\x12\x9c|\x86.\xdc~B,K\x9c\x93\xcfh\xb1Sr#\x9e\xb1(\x11p^\x16\x1a\xce\xcb\xc2\x97\x8c\xe7e\xb1.\x7f(B\x8dO\x81\x98\xd7\xba\x9e3\x15\x84[\x86\x95Hn\x84\xce\x8a\xe4\x86a\x10\xcb\xc2Ar\xe3*\xcf{^\xe6\x14I\xa1\xbc\xcfN\xe7a\x9e\xb8\xbe\x0c]\xb8\xdf\xc7\xc4\xb1\xc4\xb9\xbe\x8c\xca\x82\xe2N\xa7S\x92TWW7\xe8k\x02-$\xb2v\xed\xda\xb0?s\xe5\xca\x95\xaa\xaa\xaaRMM\x8d\xda\xdb\xdbu\xd7]w\x05|\xdd@\x0b{\x87+\x9aeI\xd2\xddw\xdf-\xa9\x7f\x11\xf1}\xfb\xf6\xb9\x7f\x0f\xa6\xbc\xbc\\O<\xf1\x84\x9ey\xe6\x19\xcd\x9e=;\xa2\xcf\x1c\xac\x8c%K\x96H\x92N\x9c8\x11r\x99\xa1\x1e\xdb\xd9\xb3g\xab\xb2\xb2R\xb5\xb5\xb5Z\xbbv\xad\xd6\xaf_\xef\xb5\x90S2\x8a\xa4m\'\xa3\xfc\xfc|UVV\xaa\xaa\xaaJ\xc5\xc5\xc5~\xcfG;>H\xd1\xef\xaf\xf0\x16\xad\xfe\x1c\xca\xf7\xc7`\x82\x1d\xebh\xc4\xcch\xd6\xc7\xee\x88g\xc42D&\xd6\xb1\x886\x12:\xe2X?b\x19\xa2a\xa0c\xda\xd9\xd9\xa9\x0f>\xf8@\xc5\xc5\xc5Z\xb0`\x01\x8b""G\x19\xb1\xac\x1f\xb1\x0c\x910\x8f\xfd\xeb\xaf\xbf\xaew\xdeyG\x8f?\xfex\xd8\xef\xf5D\x9b\x88\x1c\xb1\x8c8\x16-QMn<\xf7\xdcs\xea\xee\xee\x96$\xb5\xb7\xb7k\xdd\xbau\xee\xd7\xac\\\xb9R\x92\xd4\xda\xda\xea~\xcc|\xad\xcb\xe5\n\xfb3\x17-Z$Iz\xfe\xf9\xe7\xb5\x7f\xff~\xdd{\xef\xbd^\xcf\x97\x94\x94H\x92\xb6m\xdb\xe6\xfe\x1csU\xf8p\rV\x96\xf9|\xb87\xe7\xb2\xb2\xb2TTT\xa4\xc2\xc2B}\xf0\xc1\x07\xca\xca\xca\x1a\xf0\xf5\x85\x85\x85\xee\xf7Ej\xb02\x9cN\xa7\x9cN\xa7\x9e{\xee\xb9\xa0e\xb4\xb7\xb7{\xed\xc7P\x8f\xad\xc3\xe1Pww\xb7\xf2\xf3\xf3\xf5\xec\xb3\xcf\xaa\xb6\xb6V\xeb\xd7\xaf\x8fx[\x12\x99\x19,\xccdQ22\x03\xafy\xac\x07\xe3t:UVV\xa6\xcd\x9b7\xfb=\x17\xcd\xf8\x10\xcd\xbe\x1f\x8e\xa2\xa2\xa2\x98\x96\x9fh\xa2\xd5\x9fC\xf9\xfe\x08f\xb0c\x1d\x8d\x98\x19\x0e\xab\xda^\xac%{<#\x96yK\xb5X\x16\x0f\xb1\x8aE\xc9\x1asb!\xd9\xe3\x98D,\xf3E,\x8b\x9dP\x8e\xe9\xb6m\xdb\xf4\xbd\xef}O\xabW\xaf\x96\xd3\xe9\xd4\x93O>iI]\x93\r\xb1\xcc\x1f\xb1\x0c\xe1\xca\xcf\xcf\xd7\xda\xb5kUXX\xa8\xd2\xd2R\xcd\x9f?\x7f\xd0\xf7\x04\xea{\x9c\x87E.\xd9c\x19q\xcc[\\\xe2\x98\xefP\x8eH\x86\x93\x99+\xae\xeb\xff\x86\x95H\xfdkI\xf8.\xb0mN%e\xce%VVV\xe6\xb7r\xbb\xf9~sZ$\xcf\x85\xb9}\x17""3\x17i\t4\x1d\x8agY\x9e?\xe6\x14P\n2\x04\xc6\xdc\x0es\xf1\xb3\xc1\xca2\x8c\xab+\xc0;\x9dN\xf7c\xe6\xa2/\xe6\xbe\xf0,\xc7s;\xcc!H\x9e\xeb\x85x~\x9e\xe7k\xcd\xba\xb5\xb5\xb5yMk\xd0\xd1\xd1\x11\xf2\xbe\x1b\xa8\x0c\xdf\xe3\xe9{\x0c\xcdm\xf5<\x86\xa1\x1e[\xc3\xe8\x1fvTTT\xe4\xb5\xdf<\x8f]\xa0}\x1f*\x859|,\x10\xdf\xfd\x1e\xea>5\x7f7\xa7\x153\x17\xb7\xf7\x9c6\xcd0\xae\x0e\x7f4\xf7\xa9\xb9\x08\x90g\x1b\t\xb4\x0f\x8a\x8a\x8a\xa2\xb6(U4\xa7?\xa8\xac\xac\xf4\xea\x07\xa6@\xed\xdcS\xa0\xc5\x95\xa2\x19\x1f\x06\xeb\xaf\xe6|\xe7\x9e}.\x18\xcf\xf2\x83M\xd5f\xf6\xff\xca\xcaJ\xbf\xe7\x82\xed\xbb\xc1D\xa3=\x0f$\xdcv\x10(&\r\xd6\x9f\xc3){\xa0\xef\x8f\x81\xe2\xf5`\xc7z\xb0x\x17\xa8\xbf\r\xd6O\x87R\x9fPDk\xd8p*\xc4\xb3p\xfb\t\xb1,\xfe\xb1,\xd9\xa7\xa5\x8a\xc6\xb9W\xa02\x02\xc5\xdc\xc1\x1e\x8b4\xe6\xc4\n\xe7e\xa1\xe1\xbc\xcc\x1e\xb1,\xd6\xe7e\xb1.\x7f(\xc2\xbd66\xfb\x9b\xe7\xf11\x8f\x9bg\xbf\x19\xcau_\xbcDk\x9a\x9dT\x88e\xd1\x9c\x96\x8aX\xd6/\xda\xb1,\x15\xa7\xa5\x1a(\xce\x98\xfd\xc4s\xed\rS\xa8}/\x91\xcf\xc3<q}\x19\xbap\xbf\x8f\x89c\x89s}\x19\x95\xe4\x86a\xf4\xef$\xf3@\x14\x15\x15\x05\\8\xac\xa3\xa3\xc3())\xf1j\xdc\x9e;\xc1w\x07\x07{\xccd&\x06\x02}\x96a\xf4\xefH\xb3Nk\xd7\xaeu\x1f0\xcf\xf2|;\x94YfQQ\x91W\x83\x0bV\x96\xe7\xf3fg4o\x809\x9dN\xa3\xac\xac,h\x032y6\xca@\xaf3_\xeb[\xb7\xa2\xa2""w]B\xddw\x03\x95\xe1\xa9\xab\xab\xcb\xa8\xac\xacto\x93\xb9\xafJJJ\x02\x06\xeb\xc1\x8e\xadY\x1f3\x08I\xfeI\xa9`\xfb>\x14\xe1\x06\xa1`e\x0c\xf4\x13\xe85\x9e\x8f\xd5\xd6\xd6\xba\x83mII\x89\xdf\xf6\x9b\x89!\xcf\xce\xed\xd9F\x82\xed\x83D\xbd\x886\xdb\xb5\xe7<\xba\x03\xb5sO\xbe\xfd\xce,/Z\xf1a\xa0\xfej\xb6\xf9@u\x08\xb4\xdd\x83m\x8f\xf9\xa5\x1b\xa8\xcdF\x1a\xb0\xa3\xd1\x9e\x07\x12n;\x08\xb6\xef\x07\xea\xcf\xe1\x18\xe8\xfbc\xa0xm\x18\x03\x1f\xeb\xc1\xe2]\xa0\xfe6X?\x1dJ}B\x11\xad\x93\xcfT\x88g\xe1\xf6\x13bY\xfccY\xb2\'7B=\x96\xd18\x7f\x8b\xa4\x8dX)\x1a\xdfc\xa9\x10\xc78/\xb3G,\x8bF{\xb6\xb2\xfc\xa1\x08\xf7\xda8\xd0\xb1\t%.&\xa2h\xdd\xacM\x85X\x16\xcd\xe4\x06\xb1\xac_\xb4cY*&7\x06\x8b3\xe6Zh\xbeB\xed{\x86\x91\xb8\xe7a\x9e\xb8\xbe\x0co\x1b\xb9\xbeL\xdc8f\x18\xc1\xdb\xb3\xe3\xff\nu\xdb\xb1c\x87\x96/_.\x9f\x87\x81\x84\xe6p8\xb4}\xfbv-[\xb6\xcc\x92\xcf\x96d\x8b>\x13I\xff\x1eh\xfb\xcc\xe1k\xdf\xfb\xde\xf7\xa2S\xc18*((Pee\xe5\x90\xcb\xd9\xb8q\xa3F\x8d\x1a\x15p\x1fD\xda6b\xdd\x9e\x89\xf3\x89\xcb\x1cZZQQa\xc9\xe7\xdb)\x9e\x85\xdbO\x88e\x03\x8bE,\x8bu{\xb6\xba\xbf 8\xce\xcbB\xc3y\xd9U\x89\x1c\xcbb\xdd\x9e\xad\xec/\x08\xce\xea\xf3e;\xc5\xb2H\xbe\x8f\x89e\x03\x8bv,\x8bu{\xb6\xba\xbf\x84\xab\xbb\xbb[\xdf\xff\xfe\xf7\xf5\xec\xb3\xcf\xfa=g\xa7\xbe\x17\n\xab\xcf\x97\xed\xb4?\xb9\xbe\xec\x97\xa8qL\n\xde\x9e\xa3\xb2\xe6\x06\x80\xd4\xb4z\xf5j\xbd\xfd\xf6\xdb\xaa\xa9\xa9\xb1\xba*a\xa9\xa9\xa9\xd1\x86\r\x1b\x86\\N]]\x9d\xea\xea\xea\xb4z\xf5\xea(\xd4\n\x80U\x88e\xc42 \x19\x10\xcb\x88e@2 \x96\x11\xcbbm\xc7\x8e\x1d\x11\xad\xfd\x0b\x84\x8a8\x16\xdf8Fr\x03\x18\x82\xce\xce\xce\x80\xffO\x15\x99\x99\x99\xda\xbau\xab~\xf4\xa3\x1f\xa9\xae\xae\xce\xea\xea\x84d\xdf\xbe}\xba\xf9\xe6\x9bCZ8l ---z\xee\xb9\xe7\xb4u\xebVeffF\xa9v\x80uR9\x9e\x11\xcb\x88eH\x0e\xa9\x1c\xc7$b\x19\xb1\x0c\xc9\x82XF,#\x96E\xdf\xc6\x8d\x1b\xe5p8\xe4p8\xd4\xde\xde\xaeE\x8b\x16\xf9\xbd&\xd5\xfb^\xb4\xa5\xf2\xfe$\x8e\xc57\x8e\x91\xdc\x00\x86`\xdc\xb8q\x01\xff\x9f\x8c\xcc\x13\x01_c\xc7\x8e\xd5\xb6m\xdb\xb4g\xcf\x1e\x0bj\x15\xbeE\x8b\x16i\xf6\xec\xd9C.\xa7\xaa\xaaJ?\xfc\xe1\x0f5v\xecX\xbf\xe7\x82\xed\xabTan\xff`?H,\xa9\x12\xcf\x88e\xde\x88eH&\xa9\x12\xc7$b\x99/b\x19\x92\t\xb1\x8cXF,\x8b\xbe\xac\xac,IRII\x896m\xda\x14\xf05\xa9\xd4\xf7\xe2!U\xf6\'q\xcc\x9b\x15q,=\xea%\x02)\xc4\x0e\xf3\x06\x0eU(\xdb\x98\x99\x99i\xcb\xb9\x04\x87b\xa0\xedM\x85v1\x90T\xdf~\xbbJ\xf6\xe3F,\x0b\x8cX\x86d\x92\nm\x96X\x16\x18\xb1\x0c\xc9$\x15\xda,\xb1,0bY\xec\xacY\xb3Fk\xd6\xac\x19\xf05\x
Traceback (most recent call last):
  File ""c:\Users\urkch\AppData\Local\Programs\Python\Python_Projects\MtG ML\main.py"", line 319, in <module>
    main()
  File ""c:\Users\urkch\AppData\Local\Programs\Python\Python_Projects\MtG ML\main.py"", line 38, in main
    tf.keras.utils.plot_model(
  File ""C:\Users\urkch\miniconda3\envs\MtGML\lib\site-packages\keras\utils\vis_utils.py"", line 471, in plot_model
    dot.write(to_file, format=extension)
  File ""C:\Users\urkch\miniconda3\envs\MtGML\lib\site-packages\pydot.py"", line 1828, in write
    s = self.create(prog, format, encoding=encoding)
  File ""C:\Users\urkch\miniconda3\envs\MtGML\lib\site-packages\pydot.py"", line 1956, in create
    assert process.returncode == 0, (
AssertionError: ""dot"" with args ['-Tpng', 'C:\\Users\\urkch\\AppData\\Local\\Temp\\tmpsyy85adl'] returned code: 1
```
</details>"
58464,1,
58463,`tf.constant(1)` maxes VRAM," ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.10.4

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cudatoolkit 11.3.1

### GPU model and memory

GTX 1070, 8GB

### Current Behaviour?

7.5GB VRAM used until kernel is restarted. Removing `import torch` fixes this.

`torch` installed with `conda`, `tensorflow-gpu` with `pip`.

<details>
  <summary><b>conda list</b></summary>

```
# Name                    Version                   Build  Channel
absl-py                   1.0.0              pyhd8ed1ab_0    conda-forge
aiohttp                   3.8.1           py310he2412df_1    conda-forge
aiosignal                 1.2.0              pyhd8ed1ab_0    conda-forge
alabaster                 0.7.12                     py_0    anaconda
aom                       3.3.0                h0e60522_1    conda-forge
appdirs                   1.4.4              pyh9f0ad1d_0    conda-forge
argh                      0.26.2          pyh9f0ad1d_1002    conda-forge
argon2-cffi               21.3.0             pyhd8ed1ab_0    conda-forge
argon2-cffi-bindings      21.2.0          py310he2412df_2    conda-forge
argunparse                0.1.2                    pypi_0    pypi
arrow                     1.2.2              pyhd8ed1ab_0    conda-forge
astroid                   2.11.2          py310h5588dad_1    conda-forge
asttokens                 2.0.5              pyhd8ed1ab_0    conda-forge
astunparse                1.6.3              pyhd8ed1ab_0    conda-forge
async-timeout             4.0.2              pyhd8ed1ab_0    conda-forge
atomicwrites              1.4.0              pyh9f0ad1d_0    conda-forge
attrs                     21.4.0             pyhd8ed1ab_0    conda-forge
audioread                 2.1.9           py310h5588dad_3    conda-forge
autopep8                  1.6.0              pyhd8ed1ab_1    conda-forge
babel                     2.9.1              pyh44b312d_0    conda-forge
backcall                  0.2.0              pyh9f0ad1d_0    conda-forge
backports                 1.1                pyhd3eb1b0_0    anaconda
backports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge
bcrypt                    3.2.0           py310he2412df_3    conda-forge
binaryornot               0.4.4                      py_1    conda-forge
black                     22.10.0         py310h5588dad_0    conda-forge
blas                      1.0                         mkl    anaconda
bleach                    4.1.0              pyhd8ed1ab_0    conda-forge
blinker                   1.4                        py_1    conda-forge
blosc                     1.21.0               h0e60522_0    conda-forge
brotli                    1.0.9                h8ffe710_7    conda-forge
brotli-bin                1.0.9                h8ffe710_7    conda-forge
brotlipy                  0.7.0           py310he2412df_1004    conda-forge
bzip2                     1.0.8                h8ffe710_4    conda-forge
c-blosc2                  2.0.4                h09319c2_1    conda-forge
ca-certificates           2022.9.24            h5b45459_0    conda-forge
cached-property           1.5.2                hd8ed1ab_1    conda-forge
cached_property           1.5.2              pyha770c72_1    conda-forge
cachetools                5.0.0              pyhd8ed1ab_0    conda-forge
cairo                     1.16.0            h15b3021_1010    conda-forge
certifi                   2022.9.24          pyhd8ed1ab_0    conda-forge
cffi                      1.15.0          py310hcbf9ad4_0    conda-forge
cfitsio                   4.1.0                h5a969a9_0    conda-forge
chardet                   4.0.0           py310h5588dad_3    conda-forge
charls                    2.3.4                h39d44d4_0    conda-forge
charset-normalizer        2.0.11             pyhd8ed1ab_0    conda-forge
click                     8.1.3           py310h5588dad_0    conda-forge
cloudpickle               2.0.0              pyhd8ed1ab_0    conda-forge
colorama                  0.4.4              pyh9f0ad1d_0    conda-forge
commonmark                0.9.1                      py_0    anaconda
conda                     4.12.0          py310h5588dad_0    conda-forge
conda-package-handling    1.8.1           py310h4f637d6_1    conda-forge
configparser              5.2.0              pyhd8ed1ab_0    conda-forge
contourpy                 1.0.5           py310h232114e_0    conda-forge
cookiecutter              1.7.3              pyh6c4a22f_1    conda-forge
coverage                  6.5.0                    pypi_0    pypi
cryptography              36.0.2          py310ha857299_1    conda-forge
cudatoolkit               11.3.1               h59b6b97_2    anaconda
cycler                    0.11.0             pyhd8ed1ab_0    conda-forge
cython                    0.29.32         py310h00ffb61_1    conda-forge
cytoolz                   0.11.2          py310he2412df_2    conda-forge
dask-core                 2022.4.0           pyhd8ed1ab_0    conda-forge
dataclasses               0.8                pyhc8e2a94_3    conda-forge
debugpy                   1.5.1           py310h8a704f9_1    conda-forge
decorator                 4.4.2                      py_0    anaconda
defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge
deprecated                1.2.13             pyh6c4a22f_0    conda-forge
diff-match-patch          20200713           pyh9f0ad1d_0    conda-forge
dill                      0.3.4              pyhd8ed1ab_0    conda-forge
doce                      0.2.dev0                  dev_0    <develop>
docker-pycreds            0.4.0                      py_0    anaconda
docutils                  0.17.1          py310h5588dad_1    conda-forge
dummm                     0.1.2                    pypi_0    pypi
dumspin                   0.1.2                    pypi_0    pypi
entrypoints               0.4                pyhd8ed1ab_0    conda-forge
exceptiongroup            1.0.0              pyhd8ed1ab_0    conda-forge
executing                 0.8.2              pyhd8ed1ab_0    conda-forge
expat                     2.5.0                h1537add_0    conda-forge
ffmpeg                    4.3.1                ha925a31_0    conda-forge
fire                      0.4.0              pyh44b312d_0    conda-forge
flake8                    4.0.1              pyhd8ed1ab_2    conda-forge
flatbuffers               2.0                      pypi_0    pypi
flit-core                 3.7.1              pyhd8ed1ab_0    conda-forge
font-ttf-dejavu-sans-mono 2.37                 hab24e00_0    conda-forge
font-ttf-inconsolata      3.000                h77eed37_0    conda-forge
font-ttf-source-code-pro  2.038                h77eed37_0    conda-forge
font-ttf-ubuntu           0.83                 hab24e00_0    conda-forge
fontconfig                2.14.0               hce3cb01_0    conda-forge
fonts-conda-ecosystem     1                             0    conda-forge
fonts-conda-forge         1                             0    conda-forge
fonttools                 4.29.1          py310he2412df_0    conda-forge
freetype                  2.12.1               h546665d_0    conda-forge
fribidi                   1.0.10               h8d14728_0    conda-forge
frozenlist                1.3.0           py310he2412df_1    conda-forge
fsspec                    2022.1.0           pyhd8ed1ab_0    conda-forge
future                    0.18.2          py310h5588dad_5    conda-forge
gast                      0.4.0                    pypi_0    pypi
getopt-win32              0.1                  h8ffe710_0    conda-forge
gettext                   0.19.8.1          ha2e2712_1008    conda-forge
giflib                    5.2.1                h8d14728_2    conda-forge
gin-config                0.5.0                    pypi_0    pypi
gitdb                     4.0.7              pyhd3eb1b0_0    anaconda
gitpython                 3.1.27             pyhd8ed1ab_0    conda-forge
google-auth               2.6.0              pyh6c4a22f_1    conda-forge
google-auth-oauthlib      0.4.6              pyhd8ed1ab_0    conda-forge
google-pasta              0.2.0              pyh8c360ce_0    conda-forge
gprof2dot                 2022.7.29                pypi_0    pypi
graphite2                 1.3.13                     1000    conda-forge
graphviz                  4.0.0                had6c3a3_0    conda-forge
grpcio                    1.43.0          py310ha05212b_0    conda-forge
gts                       0.7.6                h7c369d9_2    conda-forge
h5py                      3.6.0           nompi_py310h00cbb18_100    conda-forge
harfbuzz                  4.2.0                hc1763ed_0    conda-forge
hdf5                      1.12.1          nompi_h2a0e4a3_104    conda-forge
icu                       69.1                 h0e60522_0    conda-forge
idna                      3.3                pyhd8ed1ab_0    conda-forge
imagecodecs               2022.2.22       py310h7653d06_3    conda-forge
imageio                   2.15.0             pyhcf75d05_0    conda-forge
imageio-ffmpeg            0.4.5              pyhd8ed1ab_0    conda-forge
imagesize                 1.3.0              pyhd8ed1ab_0    conda-forge
importlib-metadata        4.11.3          py310h5588dad_1    conda-forge
importlib-resources       3.3.1              pyhd8ed1ab_0    conda-forge
importlib_metadata        4.11.3               hd8ed1ab_1    conda-forge
importlib_resources       5.6.0              pyhd8ed1ab_0    conda-forge
inflection                0.5.1              pyh9f0ad1d_0    conda-forge
iniconfig                 1.1.1              pyh9f0ad1d_0    conda-forge
intel-openmp              2022.0.0          h57928b3_3663    conda-forge
intervaltree              3.1.0                      py_0    anaconda
ipykernel                 6.12.1          py310hbbfc1a7_0    conda-forge
ipython                   7.32.0          py310h5588dad_0    conda-forge
ipython_genutils          0.2.0                      py_1    conda-forge
ipywidgets                7.6.5              pyhd8ed1ab_0    conda-forge
isort                     5.10.1             pyhd8ed1ab_0    conda-forge
jams                      0.3.4                    pypi_0    pypi
jbig                      2.1               h8d14728_2003    conda-forge
jedi                      0.18.1          py310h5588dad_1    conda-forge
jellyfish                 0.9.0           py310he2412df_1    conda-forge
jinja2                    3.0.3              pyhd8ed1ab_0    conda-forge
jinja2-time               0.2.0              pyhd8ed1ab_3    conda-forge
joblib                    1.1.0              pyhd8ed1ab_0    conda-forge
jpeg                      9e                   h8ffe710_0    conda-forge
jsonschema                4.4.0              pyhd8ed1ab_0    conda-forge
jupyter                   1.0.0           py310h5588dad_7    conda-forge
jupyter_client            7.2.2              pyhd8ed1ab_1    conda-forge
jupyter_console           6.4.3              pyhd8ed1ab_0    conda-forge
jupyter_core              4.9.2           py310h5588dad_0    conda-forge
jupyterlab_pygments       0.2.0              pyhd8ed1ab_0    conda-forge
jupyterlab_widgets        1.1.0              pyhd8ed1ab_0    conda-forge
jxrlib                    1.1                  hfa6e2cd_2    conda-forge
kaleido-core              0.2.1                h8ffe710_0    conda-forge
keras                     2.10.0                   pypi_0    pypi
keras-preprocessing       1.1.2                    pypi_0    pypi
keyring                   23.4.0          py310h5588dad_2    conda-forge
kiwisolver                1.3.2           py310h476a331_1    conda-forge
krb5                      1.19.3               h1176d77_0    conda-forge
lazy-object-proxy         1.7.1           py310he2412df_1    conda-forge
lcms2                     2.12                 h2a16943_0    conda-forge
lerc                      3.0                  h0e60522_0    conda-forge
libaec                    1.0.6                h39d44d4_0    conda-forge
libarchive                3.5.2                hb45042f_1    conda-forge
libavif                   0.10.0               h8ffe710_1    conda-forge
libblas                   3.9.0              12_win64_mkl    conda-forge
libbrotlicommon           1.0.9                h8ffe710_7    conda-forge
libbrotlidec              1.0.9                h8ffe710_7    conda-forge
libbrotlienc              1.0.9                h8ffe710_7    conda-forge
libcblas                  3.9.0              12_win64_mkl    conda-forge
libclang                  13.0.0                   pypi_0    pypi
libcurl                   7.82.0               h789b8ee_0    conda-forge
libdeflate                1.10                 h8ffe710_0    conda-forge
libffi                    3.4.2                h8ffe710_5    conda-forge
libflac                   1.3.4                h0e60522_0    conda-forge
libgd                     2.3.3                h217ff3b_2    conda-forge
libglib                   2.72.1               h3be07f2_0    conda-forge
libiconv                  1.16                 he774522_0    conda-forge
liblapack                 3.9.0              12_win64_mkl    conda-forge
libmamba                  0.22.1               h81a967f_1    conda-forge
libmambapy                0.22.1          py310hd80b381_1    conda-forge
libogg                    1.3.5                h2bbff1b_1    anaconda
libopus                   1.3.1                h8ffe710_1    conda-forge
libpng                    1.6.37               ha81a0f5_2    conda-forge
libprotobuf               3.19.4               h7755175_0    conda-forge
librosa                   0.9.0              pyhd8ed1ab_0    conda-forge
libsndfile                1.0.31               h0e60522_1    conda-forge
libsodium                 1.0.18               h62dcd97_1    conda-forge
libsolv                   0.7.20               h23ce68f_0    anaconda
libspatialindex           1.9.3                h39d44d4_4    conda-forge
libssh2                   1.10.0               h680486a_2    conda-forge
libtiff                   4.3.0                hc4061b1_3    conda-forge
libuv                     1.40.0               he774522_0    anaconda
libvorbis                 1.3.7                ha925a31_0    conda-forge
libwebp                   1.2.2                h57928b3_0    conda-forge
libwebp-base              1.2.2                h8ffe710_1    conda-forge
libxcb                    1.13              hcd874cb_1004    conda-forge
libxml2                   2.9.12               hf5bbc77_2    conda-forge
libzlib                   1.2.13               hcfcfb64_4    conda-forge
libzopfli                 1.0.3                ha925a31_0    anaconda
llvmlite                  0.38.0          py310h2c03ce5_1    conda-forge
locket                    0.2.1           py310haa95532_2    anaconda
lz4-c                     1.9.3                h8ffe710_1    conda-forge
lzo                       2.10              hfa6e2cd_1000    conda-forge
m2r2                      0.3.3              pyhd8ed1ab_0    conda-forge
m2w64-gcc-libgfortran     5.3.0                         6    conda-forge
m2w64-gcc-libs            5.3.0                         7    conda-forge
m2w64-gcc-libs-core       5.3.0                         7    conda-forge
m2w64-gmp                 6.1.0                         2    conda-forge
m2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge
mamba                     0.22.1          py310h9376f3e_1    conda-forge
markdown                  3.3.6              pyhd8ed1ab_0    conda-forge
markupsafe                2.0.1           py310he2412df_1    conda-forge
mathjax                   2.7.7                h57928b3_3    conda-forge
matplotlib                3.6.1           py310h5588dad_0    conda-forge
matplotlib-base           3.6.1           py310h51140c5_0    conda-forge
matplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge
mccabe                    0.6.1                      py_1    conda-forge
menuinst                  1.4.18          py310h5588dad_1    conda-forge
mido                      1.2.10             pyhd8ed1ab_0    conda-forge
mir-eval                  0.7                      pypi_0    pypi
mirdata                   0.3.6                    pypi_0    pypi
mistune                   0.8.4           py310he2412df_1005    conda-forge
mkl                       2021.4.0           h0e2418a_729    conda-forge
mkl-service               2.4.0           py310hcf6e17e_0    conda-forge
mkl_fft                   1.3.1           py310ha0764ea_0    anaconda
mkl_random                1.2.2           py310hc02be91_0    anaconda
moviepy                   1.0.1                      py_0    conda-forge
msys2-conda-epoch         20160418                      1    conda-forge
multidict                 6.0.2           py310he2412df_1    conda-forge
munkres                   1.1.4              pyh9f0ad1d_0    conda-forge
mypy_extensions           0.4.3           py310h5588dad_5    conda-forge
nbclient                  0.5.10             pyhd8ed1ab_1    conda-forge
nbconvert                 6.4.1           py310h5588dad_0    conda-forge
nbformat                  5.1.3              pyhd8ed1ab_0    conda-forge
nbsphinx                  0.8.9                    pypi_0    pypi
nest-asyncio              1.5.4              pyhd8ed1ab_0    conda-forge
networkx                  2.6.3              pyhd8ed1ab_1    conda-forge
nnaudio                   0.3.1                    pypi_0    pypi
notebook                  6.4.8              pyha770c72_0    conda-forge
numba                     0.55.0          py310h4ed8f06_0    anaconda
numexpr                   2.8.1           py310hb57aa6b_1    anaconda
numpy                     1.21.5                   pypi_0    pypi
numpydoc                  1.2.1              pyhd8ed1ab_2    conda-forge
oauthlib                  3.2.0              pyhd8ed1ab_0    conda-forge
opencv-python             4.6.0.66                 pypi_0    pypi
openjpeg                  2.4.0                hb211442_1    conda-forge
openssl                   1.1.1s               hcfcfb64_0    conda-forge
opt-einsum                3.3.0                    pypi_0    pypi
packaging                 21.3               pyhd8ed1ab_0    conda-forge
pandas                    1.4.0           py310hf5e1058_0    conda-forge
pandoc                    2.17.1.1             h57928b3_0    conda-forge
pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge
pango                     1.50.7               h66df5b2_0    conda-forge
paramiko                  2.10.3             pyhd8ed1ab_0    conda-forge
parso                     0.8.3              pyhd8ed1ab_0    conda-forge
partd                     1.2.0              pyhd8ed1ab_0    conda-forge
pathspec                  0.9.0              pyhd8ed1ab_0    conda-forge
pathtools                 0.1.2                      py_1    anaconda
patsy                     0.5.2              pyhd8ed1ab_0    conda-forge
pcre                      8.45                 h0e60522_0    conda-forge
pexpect                   4.8.0              pyh9f0ad1d_2    conda-forge
pickleshare               0.7.5                   py_1003    conda-forge
pillow                    9.0.1           py310h767b3fd_2    conda-forge
pip                       22.1.2             pyhd8ed1ab_0    conda-forge
pixman                    0.40.0               h8ffe710_0    conda-forge
platformdirs              2.4.1              pyhd8ed1ab_1    conda-forge
plotly                    5.10.0                     py_0    plotly
pluggy                    1.0.0           py310h5588dad_3    conda-forge
pooch                     1.6.0              pyhd8ed1ab_0    conda-forge
poyo                      0.5.0                      py_0    conda-forge
pretty-midi               0.2.9                    pypi_0    pypi
proglog                   0.1.9                      py_0    conda-forge
prometheus_client         0.14.1             pyhd8ed1ab_0    conda-forge
promise                   2.3             py310h5588dad_5    conda-forge
prompt-toolkit            3.0.27             pyha770c72_0    conda-forge
prompt_toolkit            3.0.27               hd8ed1ab_0    conda-forge
protobuf                  3.19.4          py310h8a704f9_0    conda-forge
psutil                    5.9.0           py310he2412df_1    conda-forge
pthread-stubs             0.4               hcd874cb_1001    conda-forge
ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge
py                        1.11.0             pyh6c4a22f_0    conda-forge
pyasn1                    0.4.8                      py_0    anaconda
pyasn1-modules            0.2.8                      py_0    anaconda
pybind11-abi              4                    hd8ed1ab_3    conda-forge
pycodestyle               2.8.0              pyhd8ed1ab_0    conda-forge
pycosat                   0.6.3           py310he2412df_1010    conda-forge
pycparser                 2.21               pyhd8ed1ab_0    conda-forge
pydeprecate               0.3.1              pyhd8ed1ab_0    conda-forge
pydocstyle                6.1.1              pyhd8ed1ab_0    conda-forge
pyflakes                  2.4.0              pyhd8ed1ab_0    conda-forge
pygments                  2.11.2             pyhd8ed1ab_0    conda-forge
pyjwt                     2.3.0              pyhd8ed1ab_1    conda-forge
pylint                    2.13.5             pyhd8ed1ab_0    conda-forge
pyls-spyder               0.4.0              pyhd8ed1ab_0    conda-forge
pynacl                    1.5.0           py310h4f637d6_1    conda-forge
pyopenssl                 22.0.0             pyhd8ed1ab_0    conda-forge
pyparsing                 3.0.7              pyhd8ed1ab_0    conda-forge
pyqt                      5.12.3          py310h5588dad_8    conda-forge
pyqt-impl                 5.12.3          py310h8a704f9_8    conda-forge
pyqt5-sip                 4.19.18         py310h8a704f9_8    conda-forge
pyqtchart                 5.12            py310h8a704f9_8    conda-forge
pyqtwebengine             5.12.1          py310h8a704f9_8    conda-forge
pyrsistent                0.18.1          py310he2412df_1    conda-forge
pysimplegui               4.60.3                   pypi_0    pypi
pysocks                   1.7.1           py310h5588dad_5    conda-forge
pysoundfile               0.10.3.post1       pyhd3deb0d_0    conda-forge
pytest                    7.2.0              pyhd8ed1ab_2    conda-forge
pytest-cov                4.0.0                    pypi_0    pypi
pytest-profiling          1.7.0                    pypi_0    pypi
python                    3.10.4          h9a09f29_0_cpython    conda-forge
python-dateutil           2.8.2              pyhd8ed1ab_0    conda-forge
python-kaleido            0.2.1              pyhd8ed1ab_0    conda-forge
python-lsp-black          1.2.1              pyhd8ed1ab_0    conda-forge
python-lsp-jsonrpc        1.0.0              pyhd8ed1ab_0    conda-forge
python-lsp-server         1.4.1              pyhd8ed1ab_1    conda-forge
python-slugify            6.1.1              pyhd8ed1ab_0    conda-forge
python_abi                3.10                    2_cp310    conda-forge
pythonmagick              0.9.19                   pypi_0    pypi
pytorch                   1.11.0          py3.10_cuda11.3_cudnn8_0    pytorch
pytorch-lightning         1.7.7              pyhd8ed1ab_0    conda-forge
pytorch-mutex             1.0                        cuda    pytorch
pytz                      2021.3             pyhd8ed1ab_0    conda-forge
pyu2f                     0.1.5              pyhd8ed1ab_0    conda-forge
pywavelets                1.2.0           py310h2873277_1    conda-forge
pywin32                   303             py310he2412df_0    conda-forge
pywin32-ctypes            0.2.0           py310h5588dad_1005    conda-forge
pywinpty                  2.0.5           py310h00ffb61_1    conda-forge
pyyaml                    6.0             py310he2412df_4    conda-forge
pyzmq                     22.3.0          py310h73ada01_2    conda-forge
qdarkstyle                3.0.2              pyhd8ed1ab_0    conda-forge
qstylizer                 0.2.1              pyhd8ed1ab_0    conda-forge
qt                        5.12.9               h556501e_6    conda-forge
qtawesome                 1.1.1              pyhd8ed1ab_0    conda-forge
qtconsole                 5.3.2              pyhd8ed1ab_0    conda-forge
qtconsole-base            5.3.2              pyha770c72_0    conda-forge
qtpy                      2.2.1              pyhd8ed1ab_0    conda-forge
reproc                    14.2.4               hd77b12b_1    anaconda
reproc-cpp                14.2.4               hd77b12b_1    anaconda
requests                  2.27.1             pyhd8ed1ab_0    conda-forge
requests-oauthlib         1.3.1              pyhd8ed1ab_0    conda-forge
resampy                   0.2.2                      py_0    conda-forge
rich                      12.2.0             pyhd8ed1ab_0    conda-forge
rope                      1.0.0              pyhd8ed1ab_0    conda-forge
rsa                       4.8                pyhd8ed1ab_0    conda-forge
rtree                     1.0.0           py310h1cbd46b_1    conda-forge
ruamel_yaml               0.15.100        py310h2bbff1b_0    anaconda
scikit-image              0.19.1          py310hf5e1058_0    conda-forge
scikit-learn              1.0.2           py310h4dafddf_0    conda-forge
scipy                     1.8.0           py310h33db832_1    conda-forge
seaborn                   0.11.2               hd8ed1ab_0    conda-forge
seaborn-base              0.11.2             pyhd8ed1ab_0    conda-forge
semver                    2.13.0             pyh9f0ad1d_0    conda-forge
send2trash                1.8.0              pyhd8ed1ab_0    conda-forge
sentry-sdk                1.5.6              pyhd8ed1ab_0    conda-forge
setproctitle              1.2.2           py310he2412df_1    conda-forge
setuptools                65.5.0             pyhd8ed1ab_0    conda-forge
shortuuid                 1.0.8           py310h5588dad_0    conda-forge
six                       1.16.0             pyh6c4a22f_0    conda-forge
smart-open                5.2.1                    pypi_0    pypi
smmap                     4.0.0              pyhd3eb1b0_0    anaconda
snappy                    1.1.8                ha925a31_3    conda-forge
snowballstemmer           2.2.0              pyhd8ed1ab_0    conda-forge
sortedcontainers          2.4.0              pyhd8ed1ab_0    conda-forge
sphinx                    4.5.0              pyh6c4a22f_0    conda-forge
sphinx-gallery            0.12.0.dev0              pypi_0    pypi
sphinx-rtd-theme          1.0.0                    pypi_0    pypi
sphinxcontrib-applehelp   1.0.2                      py_0    anaconda
sphinxcontrib-devhelp     1.0.2                      py_0    anaconda
sphinxcontrib-htmlhelp    2.0.0              pyhd8ed1ab_0    conda-forge
sphinxcontrib-jsmath      1.0.1                      py_0    anaconda
sphinxcontrib-qthelp      1.0.3                      py_0    anaconda
sphinxcontrib-serializinghtml 1.1.5              pyhd8ed1ab_2    conda-forge
spyder                    5.3.1           py310h5588dad_0    conda-forge
spyder-kernels            2.3.2           py310h5588dad_0    conda-forge
sqlite                    3.38.2               h2bbff1b_0    anaconda
statsmodels               0.13.2          py310h2873277_0    conda-forge
tables                    3.7.0                    pypi_0    pypi
tbb                       2021.5.0             h2d74725_1    conda-forge
tenacity                  8.0.1           py310haa95532_1
tensorboard               2.10.1             pyhd8ed1ab_0    conda-forge
tensorboard-data-server   0.6.1                    pypi_0    pypi
tensorboard-plugin-wit    1.8.1              pyhd8ed1ab_0    conda-forge
tensorflow                2.10.0                   pypi_0    pypi
tensorflow-estimator      2.10.0                   pypi_0    pypi
tensorflow-gpu            2.10.0                   pypi_0    pypi
tensorflow-io-gcs-filesystem 0.24.0                   pypi_0    pypi
termcolor                 1.1.0                      py_2    conda-forge
terminado                 0.13.1          py310h5588dad_0    conda-forge
testpath                  0.5.0              pyhd8ed1ab_0    conda-forge
texext                    0.6.7                    pypi_0    pypi
text-unidecode            1.3                        py_0    anaconda
textdistance              4.2.2              pyhd8ed1ab_0    conda-forge
tf-estimator-nightly      2.8.0.dev2021122109          pypi_0    pypi
threadpoolctl             3.1.0              pyh8a188c0_0    conda-forge
three-merge               0.1.1              pyh9f0ad1d_0    conda-forge
tifffile                  2022.2.9           pyhd8ed1ab_0    conda-forge
tinycss2                  1.1.1              pyhd8ed1ab_0    conda-forge
tk                        8.6.12               h8ffe710_0    conda-forge
toml                      0.10.2             pyhd8ed1ab_0    conda-forge
tomli                     1.2.2              pyhd8ed1ab_0    conda-forge
toolz                     0.11.2             pyhd8ed1ab_0    conda-forge
torchaudio                0.11.0              py310_cu113    pytorch
torchinfo                 1.6.5              pyhd8ed1ab_0    conda-forge
torchmetrics              0.9.2              pyhd8ed1ab_0    conda-forge
torchvision               0.12.0              py310_cu113    pytorch
tornado                   6.1             py310he2412df_3    conda-forge
tqdm                      4.62.3             pyhd8ed1ab_0    conda-forge
traitlets                 5.1.1              pyhd8ed1ab_0    conda-forge
typed-ast                 1.5.2           py310he2412df_0    conda-forge
typing-extensions         4.0.1                hd8ed1ab_0    conda-forge
typing_extensions         4.0.1              pyha770c72_0    conda-forge
tzdata                    2022a                h191b570_0    conda-forge
ucrt                      10.0.20348.0         h57928b3_0    conda-forge
ujson                     5.2.0           py310h8a704f9_1    conda-forge
unicodedata2              14.0.0          py310he2412df_1    conda-forge
unidecode                 1.3.4              pyhd8ed1ab_0    conda-forge
urllib3                   1.26.8             pyhd8ed1ab_1    conda-forge
vc                        14.2                 hc4473a8_6    conda-forge
version-query             1.1.0                    pypi_0    pypi
vs2015_runtime            14.29.30139          h890b9b1_8    conda-forge
wandb                     0.13.4             pyhd8ed1ab_0    conda-forge
watchdog                  2.1.7           py310h5588dad_1    conda-forge
wavespin                  0.1.2                    pypi_0    pypi
wcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge
webencodings              0.5.1                      py_1    conda-forge
werkzeug                  2.0.3              pyhd8ed1ab_1    conda-forge
wheel                     0.37.1             pyhd8ed1ab_0    conda-forge
widgetsnbextension        3.5.2           py310h5588dad_1    conda-forge
win_inet_pton             1.1.0           py310h5588dad_4    conda-forge
winpty                    0.4.3                         4    anaconda
wrapt                     1.13.3          py310he2412df_1    conda-forge
xorg-kbproto              1.0.7             hcd874cb_1002    conda-forge
xorg-libice               1.0.10               hcd874cb_0    conda-forge
xorg-libsm                1.2.3             hcd874cb_1000    conda-forge
xorg-libx11               1.7.2                hcd874cb_0    conda-forge
xorg-libxau               1.0.9                hcd874cb_0    conda-forge
xorg-libxdmcp             1.1.3                hcd874cb_0    conda-forge
xorg-libxext              1.3.4                hcd874cb_1    conda-forge
xorg-libxpm               3.5.13               hcd874cb_0    conda-forge
xorg-libxt                1.2.1                hcd874cb_2    conda-forge
xorg-xextproto            7.3.0             hcd874cb_1002    conda-forge
xorg-xproto               7.0.31            hcd874cb_1007    conda-forge
xz                        5.2.5                h62dcd97_1    conda-forge
yaml                      0.2.5                h8ffe710_2    conda-forge
yaml-cpp                  0.6.3                ha925a31_4    conda-forge
yapf                      0.32.0             pyhd8ed1ab_0    conda-forge
yarl                      1.7.2           py310he2412df_2    conda-forge
yaspin                    2.1.0              pyhd8ed1ab_0    conda-forge
zeromq                    4.3.4                h0e60522_1    conda-forge
zfp                       0.5.5                h0e60522_8    conda-forge
zipp                      3.7.0              pyhd8ed1ab_1    conda-forge
zlib                      1.2.13               hcfcfb64_4    conda-forge
zstd                      1.5.2                h6255e5f_0    conda-forge
```

</details>


### Standalone code to reproduce the issue

```shell
import torch
import tensorflow as tf
tf.constant(1)
```

### Relevant log output

_No response_"
58462,Memory Allocation - Training Bug,"<details><summary>Click to see bug report!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.5.2

### Custom Code

Yes

### OS Platform and Distribution

CentOS 7

### Python version

3.6.13

### CUDA/cuDNN version

11.6

### GPU model and memory

NVIDIA V100S - 32 GB

### Current Behaviour?

We are having a training problem while using maximum memory allocation on GPU. Weights of the TF and Keras based Convolutional-LSTM Neural Network model are updating but not training as expected on GPU.
We can train the model as expected on CPU only training and when we try with decreased memory allocation limit of GPU via the command `tf.config.experimental.set_virtual_device_configuration(tf.config.list_physical_devices('GPU')[0], [tf.config.experimental.VirtualDeviceConfiguration( memory_limit = 22400 )])`.


### Standalone code to reproduce the issue

All codes, versions and hardware info, documentation and running directions are in our GitHub repo: [github.com/ardamavi/PI-rCNN](https://github.com/ardamavi/PI-rCNN)
"
58461,TF 2.10 fails to build gpu support - inference crashes,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Debian 11

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.3.0

### GCC/Compiler version

9.3.0

### CUDA/cuDNN version

11.2,8.1

### GPU model and memory

RTX 3060/12G

### Current Behaviour?

```shell
Compiling from source does not produce a gpu based wheel like `tensorflow-gpu-2.10.0-cp38-cp38-linux_x86_64.whl` but a regular one `tensorflow-2.10.0-cp38-cp38-linux_x86_64.whl`

Installing the regular wheel and trying to perform inference with any model, the model is loaded on gpu but on `.predict` it crashes


Cuda and cudnn have been set up correctly. Have build from source many tf versions in the past (v1, 2.3,2.4) w/ Debian 10 and a GTX 1650 and worked perfectly.

Tensorflow configuration

build --action_env PYTHON_BIN_PATH=""/home/steve/.virtualenvs/mldev/bin/python3""
build --action_env PYTHON_LIB_PATH=""/home/steve/.virtualenvs/mldev/lib/python3.9/site-packages""
build --python_path=""/home/steve/.virtualenvs/mldev/bin/python3""
build --action_env TF_CUDA_VERSION=""11.2""
build --action_env TF_CUDNN_VERSION=""8.1""
build --action_env TF_NCCL_VERSION=""""
build --action_env TF_CUDA_PATHS=""/usr/local/cuda-11.2,/usr/local/cudnn,/usr/local/cuda-11.2/extras,/usr/local/cuda-11.2/targets/x86_64-linux/lib/,/usr/local/cuda-11.2/targets/x86_64-linux/include,/usr/include/x86_64-linux-gnu/""
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-11.2""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""8.6""
build --action_env LD_LIBRARY_PATH=""/usr/local/cuda-11.2/lib64:/usr/local/cudnn/lib64:""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-9""
build --config=cuda
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-Wno-sign-compare
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only

```
```


### Standalone code to reproduce the issue

```shell
import os
import pathlib

import matplotlib
import matplotlib.pyplot as plt

import io
import scipy.misc
import numpy as np
from six import BytesIO
from PIL import Image, ImageDraw, ImageFont
from six.moves.urllib.request import urlopen

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession

config = ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
config.gpu_options.per_process_gpu_memory_fraction = 0.75
config.gpu_options.allow_growth = True
# session = InteractiveSession(config=config)
InteractiveSession(config=config)
import tensorflow as tf
import tensorflow_hub as hub

tf.get_logger().setLevel('ERROR')

def load_image_into_numpy_array(path):
  """"""Load an image from file into a numpy array.

  Puts image into numpy array to feed into tensorflow graph.
  Note that by convention we put it into a numpy array with shape
  (height, width, channels), where channels=3 for RGB.

  Args:
    path: the file path to the image

  Returns:
    uint8 numpy array with shape (img_height, img_width, 3)
  """"""
  image = None
  if(path.startswith('http')):
    response = urlopen(path)
    image_data = response.read()
    image_data = BytesIO(image_data)
    image = Image.open(image_data)
  else:
    image_data = tf.io.gfile.GFile(path, 'rb').read()
    image = Image.open(BytesIO(image_data))

  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (1, im_height, im_width, 3)).astype(np.uint8)


ALL_MODELS = {
'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',
'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',
'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',
'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',
'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',
'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',
'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',
'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',
'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',
'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',
'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',
'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',
'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',
'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',
'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',
'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',
'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',
'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',
'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',
'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',
'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',
'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',
'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',
'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',
'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',
'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',
'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',
'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',
'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',
'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',
'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',
'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',
'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',
'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',
'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',
'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',
'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',
'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',
'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'
}

IMAGES_FOR_TEST = {
  'Beach' : 'models/research/object_detection/test_images/image2.jpg',
  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',
  # By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg
  'Naxos Taverna' : 'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg',
  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg
  'Beatles' : 'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',
  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg
  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',
  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg
  'Birds' : 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg',
}

from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.utils import ops as utils_ops


model_display_name = 'CenterNet HourGlass104 Keypoints 512x512' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']
model_handle = ALL_MODELS[model_display_name]

print('Selected model:'+ model_display_name)
print('Model Handle at TensorFlow Hub: {}'.format(model_handle))

print('loading model...')
hub_model = hub.load(model_handle)
print('model loaded!')

selected_image = 'Naxos Taverna' 

image_path = IMAGES_FOR_TEST[selected_image]
# running inference
results = hub_model(image_np)
```
```


### Relevant log output

```shell
2022-11-07 00:10:26.105351: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-07 00:10:26.725736: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-11-07 00:10:32.998841: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-07 00:10:33.039404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:33.056894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:33.057290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:33.989561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:33.989989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:33.990339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:33.990646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9039 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:02:00.0, compute capability: 8.6
loading model...
2022-11-07 00:10:36.369902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.370287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.370595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.371313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.371644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.371952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.372332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.372650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-07 00:10:36.372900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9039 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:02:00.0, compute capability: 8.6
model loaded!
2022-11-07 00:11:19.083914: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100
-- then crashes --
```
```
</details>"
58460,ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

1.19.2

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
Currently I am trying to reimplement a seq2seq model with GRU. When I was trying to run the code of decoder, then I encountered ""ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 9, 128), ndim=3), InputSpec(shape=(None, 128), ndim=2)]); however `cell.state_size` is [128]""
```


### Standalone code to reproduce the issue

```shell
### Brief description of bug
Currently I am trying to reimplement a seq2seq model with GRU. When I was trying to run the code of decoder, then I encountered ""ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 9, 128), ndim=3), InputSpec(shape=(None, 128), ndim=2)]); however `cell.state_size` is [128]""
#### Self-Diagnosis
- [x] I have reviewed the documentation.
- [x] I have reviewed the Wiki.
- [x] I have searched the issues for an answer to my question. 
- [x] I have searched the web for an answer to my question.

#### My configuration/Related code

def define_models(n_input, n_output, n_units):
    ay_seq = Input(shape=(n_input, 2),name = ""ay_seq_input"")
    ay_seq_input = Masking(mask_value = -99)(ay_seq)
#Embedding
    company_code_input = Input(shape = n_output, name = ""company_input"")
    company_code_embedding = Embedding(200, 49, input_length = 1 ,name = ""company_code_embedding"")(company_code_input)
    flatten = Flatten()(company_code_embedding)
    RepeatVector(9)

    encoder =  GRU(128, dropout=0.2, recurrent_dropout=0.2,return_sequences=True, return_state=True)
    state_h, state_c = encoder(ay_seq_input)
    encoder_states = [state_h, state_c]   #仅保留编码状态向量
    RepeatVector(9)

#训练模型中的decoder
    decoder_inputs = Input(shape=(None, n_output))
    decoder = GRU(128,  dropout=0.2, recurrent_dropout=0.2,return_sequences=True, return_state=True)
    decoder_output, _, _ = decoder(decoder_inputs, initial_state=encoder_states)
    lambd = Lambda(lambda x: concatenate(list(x, flatten)))
    outputs = lambd(decoder_output)

#FC
    decoder_dense1 =TimeDistributed(Dense(n_units, activation='relu'))
    dropout = Dropout(0.2)
    decoder_dense2 = TimeDistributed(Dense(n_output, activation='relu'))
    paid_output = decoder_dense2(dropout(decoder_dense1(outputs)))
    case_reserves_output = decoder_dense2(dropout(decoder_dense1(outputs)))

    model = Model([ay_seq_input, company_code_input,decoder_inputs], [paid_output,case_reserves_output])


#### Steps to Reproduce the Issue
---> 18 decoder_output, _, _ = decoder(decoder_inputs, initial_state=[state_h, state_c])
#### Current Result (Include screenshots where appropriate.)
ValueError: An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`=ListWrapper([InputSpec(shape=(None, 9, 128), ndim=3), InputSpec(shape=(None, 128), ndim=2)]); however `cell.state_size` is [128]
#### Expected Result
I want to know how to tackle this problem.
```


### Relevant log output

_No response_</details>"
58459,Getting Troubles when installing tf.2.10_gpu with anaconda virtual env.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

v2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

8.4.1.50

### GPU model and memory

NVIDIA GeForce RTX 2080 Ti

### Current Behaviour?

```shell
Thanks to your attention!
I'm trying to install tf2.10_gpu using anaconda env.
The following packages have been successfully installed in anaconda env.:

tensorflow-gpu -->2.10.0
cuda-nvcc -->11.8.89
cudatoolkit -->11.3.1
cudnn -->8.4.1.50

Under activated env., I have tested:
tf.test.is_built_with_cuda() --> True, 
tf.test.is_built_with_gpu_support() --> True

But when training model with GPU, it seems that GPU does not work:
""This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.""

Under windows OS, I guess the problems lie in the wrong environment variable establishment on cuda. Or any other things? So how to add environment variable about cuda in virtual env under windows OS system? What should be linked as environment variable?

Deeply appreciated to your help!
```


### Standalone code to reproduce the issue

```shell
None
```


### Relevant log output

_No response_</details>"
58458,tensorflow-gpu not working,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

windows 10 22h2

### Mobile device

_No response_

### Python version

3.10.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA v11.2.2 cuDNN v8.1.1

### GPU model and memory

Nvidia GTX 1650 4GB

### Current Behaviour?

```shell
i tried to install tensorflow gpu but it didnt work for reason
```


### Standalone code to reproduce the issue

```shell
python3 -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""
```


### Relevant log output

```shell
2022-11-05 13:57:59.539886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-11-05 13:57:59.541051: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-11-05 13:58:21.403776: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-11-05 13:58:21.404019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2022-11-05 13:58:21.404272: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2022-11-05 13:58:21.404457: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2022-11-05 13:58:21.404610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2022-11-05 13:58:21.404752: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2022-11-05 13:58:21.404893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2022-11-05 13:58:21.405038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2022-11-05 13:58:21.405087: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
```
</details>"
58454,Tensorflow inference slow down: Repeatedly load and delete Keras model,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

binary

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Mac OS M1 Pro

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am using Tensorflow-Macos together with Tensorflow-Metal on M1 Pro.
After loading the model and I run inference with . Everything goes well.
When I delete the model, re-build the model, re-load the weight, and re-run ```predict_on_batch```, the performance is 20% slower. What's the reason? How can I fix it?
```


### Standalone code to reproduce the issue

```shell
See descriptions above.
```


### Relevant log output

_No response_</details>"
58453,Download of fresh release of clang fails on TF 2.10.0-2.11.0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11.0-rc2

### Custom Code

No

### OS Platform and Distribution

MacOS 13.0

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

5.3.0

### GCC/Compiler version

XCode 14.1

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When requesting the option during `./configure`:


Do you wish to download a fresh release of clang? (Experimental) [y/N]: y
Clang will be downloaded and used to compile tensorflow.
```

Compilation fails immediately:

```
Starting local Bazel server and connecting to it...
ERROR: Config value 'download_clang' is not defined in any .rc file
```

The issue has been present since 2.5.0 at least, and it is present today in TF 2.10.0 and TF 2.11.0.
```


### Standalone code to reproduce the issue

```shell
When running `./configure`, select `y` when asked:


Do you wish to download a fresh release of clang? (Experimental) [y/N]: y
Clang will be downloaded and used to compile tensorflow.
```

Proceed with regular compilation after completing `.configure`:
`bazel build //tensorflow/tools/pip_package:build_pip_package`
```


### Relevant log output

```shell
The file `.tf_configure_bazelrc`:


build --action_env PYTHON_BIN_PATH=""/opt/local/bin/python3""
build --action_env PYTHON_LIB_PATH=""/opt/local/Library/Frameworks/Python.framework/Versions/3.10/li>
build --python_path=""/opt/local/bin/python3""
build --config=download_clang
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-Wno-sign-compare
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-nomac,-no_mac,-v1only
```
```
</details>"
58451,Not able to convert OpenAI hugging face TF Whisper model to int8 model ,"### 1. System information
- Linux Ubuntu 16.04:

### 2. Code
Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

 Reference [[TensorFlow Lite Model Colab](https://colab.research.google.com/drive/1rApSDy3KMoMMaK3SIQwvu21yPas2VFjx?usp=sharing)]

#### Option B: Paste your code here or provide a link to a custom end-to-end colab
https://colab.research.google.com/drive/1rApSDy3KMoMMaK3SIQwvu21yPas2VFjx?usp=sharing


### 3. Failure after conversion
- Model produces correct results with hybrid model.
- Colab session is getting crashed with int8 model  


"
58450,`tf.raw_ops.StatelessMultinomial` produces inconsistent results on CPU/GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

Stateless sampling produced different results on CPU/GPU with the same seed. 
Related: #58445 

### Standalone code to reproduce the issue

```python
with tf.device(""/cpu:0""):
  samples = tf.raw_ops.StatelessMultinomial(logits=tf.math.log([[0.5, 0.5]]), num_samples=10, seed=(7, 17))
  print(samples)

with tf.device(""/gpu:0""):
  samples = tf.raw_ops.StatelessMultinomial(logits=tf.math.log([[0.5, 0.5]]), num_samples=10, seed=(7, 17))
  print(samples)
```


### Relevant log output

```shell
tf.Tensor([[1 0 1 0 0 0 1 1 0 0]], shape=(1, 10), dtype=int64)
tf.Tensor([[0 0 0 1 0 1 0 1 1 1]], shape=(1, 10), dtype=int64)
```
</details>"
58448,How to read .csv file through mapping function of tf.data.dataset?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04 & Windows

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi all. I have a dataset that contains 3M images & labels. Labels are in format of both `jpg` and `csv`. I am trying to read all paths with `tf.data.dataset` and loading with map function both labels. I can decode JPGs with below function but I can not decode csv files because tensorflow has not a method to read csv. So, I wrote a py_function to read csv but it did not work. Is there any suggestion to read csv files through mapping function in `tf.data.dataset`?
```


### Standalone code to reproduce the issue

```shell
def image_reader(self, path,ch = 1, resize=(64,64)):
        kp = tf.io.read_file(path)
        kp = tf.image.decode_jpeg(kp, channels=ch)
        kp = tf.image.convert_image_dtype(kp, dtype=tf.float32)
        kp = tf.image.resize(kp, resize)
        return kp
def csv_reader(self, path):
        data = open(path.numpy())
        a_list = []
        for row in data:
            a_list.append(row.split(',')[1])
        a_list = tf.convert_to_tensor(a_list)
        return a_list

def load_ims(self, imagePath, LabelPath):

        image = self.image_reader(imagePath, 3, (160,128))
        
        kp = []
        for i in range(18):
            curr_kp = self.image_reader(LabelPath[0][i], resize=(160,128))
            kp.append(curr_kp)
        kp = tf.concat(kp,axis=2)
        

        presence = tf.py_function(func=self.csv_reader, inp=[LabelPath[1]], Tout=[tf.int32])
        
        return (image,(kp,presence))

trainDS = tf.data.Dataset.from_tensor_slices((image_paths[:train_size], (keypoint_paths[:train_size], presence_paths[:train_size])))
testDS = tf.data.Dataset.from_tensor_slices((image_paths[train_size:], (keypoint_paths[train_size:], presence_paths[train_size:])))

trainDS = (trainDS
            .map(self.load_ims, num_parallel_calls=AUTOTUNE)
            .batch(batch_size)
            .prefetch(AUTOTUNE))
        
 testDS = (testDS
         .map(self.load_ims, num_parallel_calls=AUTOTUNE)
         .batch(batch_size)
         .prefetch(AUTOTUNE))
```
```


### Relevant log output

```shell
File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\training.py"", line 1051, in train_function  *
        return step_function(self, iterator)
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\training.py"", line 1040, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\training.py"", line 1030, in run_step  **
        outputs = model.train_step(data)
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\training.py"", line 894, in train_step
        return self.compute_metrics(x, y, y_pred, sample_weight)
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\training.py"", line 987, in compute_metrics
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\compile_utils.py"", line 480, in update_state
        self.build(y_pred, y_true)
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\compile_utils.py"", line 393, in build
        self._metrics = tf.__internal__.nest.map_structure_up_to(
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\compile_utils.py"", line 526, in _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\compile_utils.py"", line 526, in <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    File ""C:\Users\dasmehdix\AppData\Local\Programs\Python\Python39\lib\site-packages\keras\engine\compile_utils.py"", line 547, in _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    ValueError: as_list() is not defined on an unknown TensorShape.
```
</details>"
58447,`tf.raw_ops.FakeQuantWithMinMaxArgs` loses extra precision with certain inputs,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

No

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
With same settings as docs (min=-6, max=6, num_bits=8, narrow_range=False, name=None), applying `tf.raw_ops.FakeQuantWithMinMaxArgs` to the number 2 will produce 1.9764706 on GPU but 2.0235295 on CPU. Both GPU and CPU get -1.9764706 for -2. It looks like CPU is losing precision especially for positive 2.
```


### Standalone code to reproduce the issue

```shell
with tf.device(""/cpu:0""):
  input = np.array([-6., -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6])
  output = tf.raw_ops.FakeQuantWithMinMaxArgs(inputs=input, min=-6, max=6, num_bits=8, narrow_range=False, name=None)
  print(output)

with tf.device(""/gpu:0""):
  input = np.array([-6., -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6])
  output = tf.raw_ops.FakeQuantWithMinMaxArgs(inputs=input, min=-6, max=6, num_bits=8, narrow_range=False, name=None)
  print(output)
```


### Relevant log output

```shell
tf.Tensor(
[-5.9764705 -4.9882355 -4.        -3.0117648 -1.9764706 -0.9882353
  0.         0.9882353  2.0235295  3.0117648  4.         4.9882355
  5.9764705], shape=(13,), dtype=float32)
tf.Tensor(
[-5.9764705 -4.9882355 -4.        -3.0117648 -1.9764706 -0.9882353
  0.         0.9882353  1.9764706  3.0117648  4.         4.9882355
  5.9764705], shape=(13,), dtype=float32)
```
</details>"
58446,Unit test nn_ops:pooling_ops_3d_test_cpu broken with oneDNN enabled,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.10

### Bazel version

5.3.0

### GCC/Compiler version

9.3.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/python/kernel_tests/nn_ops:pooling_ops_3d_test_cpu fails with
tensorflow.python.framework.errors_impl.AbortedError: {{function_node __wrapped____MklNativeAvgPool3DGrad_device_/job:localhost/replica:0/task:0/device:CPU:0}} Compute received an exception:Status: 2, message: could not create a descriptor for a pooling backward propagation primitive, in file tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc:298 [Op:AvgPool3DGrad]
```


### Standalone code to reproduce the issue

```shell
bazel --bazelrc=/usertools/cpu.bazelrc test --config=sigbuild_local_cache --cache_test_results=no --crosstool_top=""@sigbuild-r2.10_config_cuda//crosstool:toolchain"" --jobs=16 --test_timeout=30,50,-1,-1 --test_env=TF_ENABLE_ONEDNN_OPTS=1 -- //tensorflow/python/kernel_tests/nn_ops:pooling_ops_3d_test_cpu
```


### Relevant log output

```shell
======================================================================
ERROR: testAvgPool3dGradEmptyInput (__main__.PoolingTest)
PoolingTest.testAvgPool3dGradEmptyInput
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/e953b164f58eb4c9598ad736d787ff39/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test_cpu.runfiles/org_tensorflow/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test.py"", line 152, in testAvgPool3dGradEmptyInput
    t = gen_nn_ops.AvgPool3DGrad(
  File ""/root/.cache/bazel/_bazel_root/e953b164f58eb4c9598ad736d787ff39/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test_cpu.runfiles/org_tensorflow/tensorflow/python/util/tf_export.py"", line 422, in wrapper
    return f(**kwargs)
  File ""/root/.cache/bazel/_bazel_root/e953b164f58eb4c9598ad736d787ff39/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test_cpu.runfiles/org_tensorflow/tensorflow/python/ops/gen_nn_ops.py"", line 448, in avg_pool3d_grad
    _ops.raise_from_not_ok_status(e, name)
  File ""/root/.cache/bazel/_bazel_root/e953b164f58eb4c9598ad736d787ff39/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/nn_ops/pooling_ops_3d_test_cpu.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 7215, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.AbortedError: {{function_node __wrapped____MklNativeAvgPool3DGrad_device_/job:localhost/replica:0/task:0/device:CPU:0}} Compute received an exception:Status: 2, message: could not create a descriptor for a pooling backward propagation primitive, in file tensorflow/core/kernels/mkl/mkl_avgpooling_op.cc:298 [Op:AvgPool3DGrad]
```
</details>"
58445,`tf.random.stateless_categorical` produces inconsistent results on CPU/GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

No

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.152, 8.1.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.random.stateless_categorical`, the stateless version of `tf.random.categorical`, promises to produce the same result on CPU/GPU according to the docs:

> This is a stateless version of tf.categorical: if run twice with the same seeds and shapes, it will produce the same pseudorandom numbers. The output is consistent across multiple runs on the same hardware (and between CPU and GPU), but may change between versions of TensorFlow or on non-CPU/GPU hardware.

But even the doc example does not satisfy this.
```


### Standalone code to reproduce the issue

```shell
with tf.device(""/cpu:0""):
  cpuResult = tf.random.stateless_categorical(tf.math.log([[0.5, 0.5]]), 5, [7, 17])
  print(cpuResult)

with tf.device(""/gpu:0""):
  gpuResult = tf.random.stateless_categorical(tf.math.log([[0.5, 0.5]]), 5, [7, 17])
  print(gpuResult)
```


### Relevant log output

```shell
tf.Tensor([[1 0 1 0 0]], shape=(1, 5), dtype=int64)
tf.Tensor([[0 0 0 1 0]], shape=(1, 5), dtype=int64)
```
</details>"
58444,TFBertMainLayer cannot be loaded from .h5,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

tf2.9

### Custom Code

No

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I cannot load my saved model. I trained and saved bert and distilbert model but it gives me this issue, could you please help me fix this? I will also include link to the code file for your reference. 

please show how to load this model. I have trained the model for countless hours.
```


### Standalone code to reproduce the issue

```shell
https://github.com/prsatyal/issue_with_bert/blob/main/distilbert_third_try.ipynb
```


### Relevant log output

```shell
ValueError: Unknown layer: TFDistilBertModel. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details
```
</details>"
58443,Request Tensorflow Docker container be expanded to support running all models.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

tf 2.9.1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.04 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'm creating a Docker container in which I want to run the TensorFlow object detection code provided in the model zoo. I expected to be able to download the TensorFlow Docker container, clone the relevant source, and be off to the races.

Instead, I found that I was missing a lot of required packages. I found references which suggested to use the provided setup script located here:

https://github.com/tensorflow/models/blob/master/research/object_detection/packages/tf2/setup.py
Unfortunately, this led to a number of strange conflicts which I determined to be due to differing versions of opencv-python and opencv-python-headless, neither of which I'd manually installed. Everything was pulled in by the script and associated dependencies.

Given that both the TensorFlow Dockerfile and the models setup script are forcing versions of packages less than head-of-line, I request that a fuller and known-working Docker image be provided.

Thank you.
```


### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/models/blob/master/research/object_detection/packages/tf2/setup.py
```


### Relevant log output

```shell
pip3 list would end up showing
opencv-python                 4.6.0.66
opencv-python-headless        4.5.2.52

This results in the following backtrace:
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 31, in <module>
    from object_detection import model_lib_v2
  File ""/opt/models/research/object_detection/model_lib_v2.py"", line 29, in <module>
    from object_detection import eval_util
  File ""/opt/models/research/object_detection/eval_util.py"", line 36, in <module>
    from object_detection.metrics import lvis_evaluation
  File ""/opt/models/research/object_detection/metrics/lvis_evaluation.py"", line 23, in <module>
    from lvis import results as lvis_results
  File ""/usr/local/lib/python3.8/dist-packages/lvis/__init__.py"", line 5, in <module>
    from lvis.vis import LVISVis
  File ""/usr/local/lib/python3.8/dist-packages/lvis/vis.py"", line 1, in <module>
    import cv2
  File ""/usr/local/lib/python3.8/dist-packages/cv2/__init__.py"", line 181, in <module>
    bootstrap()
  File ""/usr/local/lib/python3.8/dist-packages/cv2/__init__.py"", line 175, in bootstrap
    if __load_extra_py_code_for_module(""cv2"", submodule, DEBUG):
  File ""/usr/local/lib/python3.8/dist-packages/cv2/__init__.py"", line 28, in __load_extra_py_code_for_module
    py_module = importlib.import_module(module_name)
  File ""/usr/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/usr/local/lib/python3.8/dist-packages/cv2/mat_wrapper/__init__.py"", line 33, in <module>
    cv._registerMatType(Mat)
AttributeError: partially initialized module 'cv2' has no attribute '_registerMatType' (most likely due to a circular import)
```
</details>"
58442,TIMEOUT while running the Bazel Tests on windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.11

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.10

### Bazel version

5.1

### GCC/Compiler version

MSVC

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
There are a few test cases that failed due to TIMEOUT 
Errors looks like this:
TIMEOUT: //tensorflow/examples/custom_ops_doc/multiplex_3:multiplex_3_test (Summary)
TIMEOUT: //tensorflow/examples/custom_ops_doc/multiplex_2:multiplex_2_test_cpu
TIMEOUT: //tensorflow/examples/adding_an_op:fact_test (Summary)

Expected behavior: The test cases should pass
```


### Standalone code to reproduce the issue

```shell
Run this bazel command to reproduce the issue:

bazel test --action_env=TEMP=/c/tmp --action_env=TMP=/c/tmp --test_env=TF2_BEHAVIOR=1 --experimental_cc_shared_library --enable_runfiles --nodistinct_host_configuration --dynamic_mode=off --config=xla --config=short_logs --announce_rc --build_tag_filters=-no_windows,-no_oss --build_tests_only --config=monolithic --config=opt -k --keep_going --test_output=errors --test_tag_filters=-no_windows,-no_oss,-gpu,-tpu,-v1only --test_size_filters=small,medium --jobs=64 --test_timeout=300,450,1200,3600 --verbose_failures --flaky_test_attempts=3 -- //tensorflow/... -//tensorflow/java/... -//tensorflow/lite/... -//tensorflow/compiler/xla/python/tpu_driver/... -//tensorflow/compiler/...
```


### Relevant log output

```shell
https://tensorflow-ci.intel.com/job/tf-win-testall/21/artifact/test_run.log
```
</details>"
58435,Unable to build Tensorflow lite OpenCL delegate for Open CL 1.2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

Khadas Vim 3

### Python version

3.8

### Bazel version

4.2.1

### GCC/Compiler version

8.3.0

### CUDA/cuDNN version

NA

### GPU model and memory

Vivante NPU (VIPNano-Q)

### Current Behaviour?

```shell
I am trying to build Tensorflow lite OpenCL delegate (.so) from source and it is successful with CL_TARGET_OPENCL_VERSION = 220. However, with CL_TARGET_OPENCL_VERSION = 120, the below mentioned error occurs during build process.
```


### Standalone code to reproduce the issue

```shell
Run build on TF 2.8 with the following command:

bazel build --config=monolithic --config=elinux_aarch64 -c opt --copt -DMESA_EGL_NO_X11_HEADERS --copt -DEGL_NO_X11 --copt -DCL_DELEGATE_NO_GL --copt -DCL_TARGET_OPENCL_VERSION=120 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
```


### Relevant log output

```shell
ERROR: /opt/Projects/vim3/tensorflow-2.8.0/tensorflow/lite/delegates/gpu/cl/BUILD:156:11: Compiling tensorflow/lite/delegates/gpu/cl/cl_context.cc failed: (Exit 1): aarch64-linux-gnu-gcc failed: error executing command
  (cd /opt/Projects/vim3/build_tf_gpu_vim3_opencl_120/9c78f894b16c6d60667b8c93d9dcce94/execroot/org_tensorflow && \
  exec env - \
    PATH=/home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  /opt/Projects/vim3/build_tf_gpu_vim3_opencl_120/9c78f894b16c6d60667b8c93d9dcce94/external/aarch64_linux_toolchain/bin/aarch64-linux-gnu-gcc -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -isystem /opt/Projects/vim3/build_tf_gpu_vim3_opencl_120/9c78f894b16c6d60667b8c93d9dcce94/external/aarch64_linux_toolchain/lib/gcc/aarch64-linux-gnu/8.3.0/include -isystem /opt/Projects/vim3/build_tf_gpu_vim3_opencl_120/9c78f894b16c6d60667b8c93d9dcce94/external/aarch64_linux_toolchain/lib/gcc/aarch64-linux-gnu/8.3.0/include-fixed -isystem /opt/Projects/vim3/build_tf_gpu_vim3_opencl_120/9c78f894b16c6d60667b8c93d9dcce94/external/aarch64_linux_toolchain/aarch64-linux-gnu/include/c++/8.3.0/ -isystem /opt/Projects/vim3/build_tf_gpu_vim3_opencl_120/9c78f894b16c6d60667b8c93d9dcce94/external/aarch64_linux_toolchain/aarch64-linux-gnu/libc/usr/include/ -isystem /usr/include/python3.5 -isystem /usr/include/ -MD -MF bazel-out/aarch64-opt/bin/tensorflow/lite/delegates/gpu/cl/_objs/cl_context/cl_context.pic.d '-frandom-seed=bazel-out/aarch64-opt/bin/tensorflow/lite/delegates/gpu/cl/_objs/cl_context/cl_context.pic.o' -fPIC -iquote . -iquote bazel-out/aarch64-opt/bin -iquote external/com_google_absl -iquote bazel-out/aarch64-opt/bin/external/com_google_absl -iquote external/opencl_headers -iquote bazel-out/aarch64-opt/bin/external/opencl_headers -iquote external/FP16 -iquote bazel-out/aarch64-opt/bin/external/FP16 -Ibazel-out/aarch64-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/opencl_headers -isystem bazel-out/aarch64-opt/bin/external/opencl_headers -isystem external/FP16/include -isystem bazel-out/aarch64-opt/bin/external/FP16/include -w -DAUTOLOAD_DYNAMIC_KERNELS -DMESA_EGL_NO_X11_HEADERS -DEGL_NO_X11 -DCL_DELEGATE_NO_GL '-DCL_TARGET_OPENCL_VERSION=120' '-std=c++14' -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -no-canonical-prefixes -fno-canonical-system-headers -c tensorflow/lite/delegates/gpu/cl/cl_context.cc -o bazel-out/aarch64-opt/bin/tensorflow/lite/delegates/gpu/cl/_objs/cl_context/cl_context.pic.o)
Execution platform: @local_execution_config_platform//:platform
In file included from ./tensorflow/lite/delegates/gpu/cl/cl_device.h:22,
                 from ./tensorflow/lite/delegates/gpu/cl/cl_context.h:19,
                 from tensorflow/lite/delegates/gpu/cl/cl_context.cc:16:
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:81:11: error: 'cl_queue_properties' does not name a type; did you mean 'cl_queue_properties_khr'?
     const cl_queue_properties * /* properties */,
           ^~~~~~~~~~~~~~~~~~~
           cl_queue_properties_khr
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:109:11: error: 'cl_pipe_properties' does not name a type; did you mean 'cl_context_properties'?
     const cl_pipe_properties * /* properties */,
           ^~~~~~~~~~~~~~~~~~
           cl_context_properties
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:129:24: error: 'cl_pipe_info' has not been declared
     cl_mem /* pipe */, cl_pipe_info /* param_name */,
                        ^~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:138:31: error: 'cl_svm_mem_flags' has not been declared
     cl_context /* context */, cl_svm_mem_flags /* flags */, size_t /* size */,
                               ^~~~~~~~~~~~~~~~
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:145:11: error: 'cl_sampler_properties' does not name a type; did you mean 'cl_context_properties'?
     const cl_sampler_properties * /* normalized_coords */,
           ^~~~~~~~~~~~~~~~~~~~~
           cl_context_properties
./tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h:223:29: error: 'cl_kernel_exec_info' has not been declared
     cl_kernel /* kernel */, cl_kernel_exec_info /* param_name */,
                             ^~~~~~~~~~~~~~~~~~~
Target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build
INFO: Elapsed time: 0.857s, Critical Path: 0.70s
INFO: 23 processes: 21 internal, 2 local.
FAILED: Build did NOT complete successfully
```
</details>"
58434,"Worker nodes exits early in MultiWorkerMirroredStrategy, causing error task reported on chief node.","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

5.1.1

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

11.8/8.6

### GPU model and memory

320G

### Current Behaviour?

```shell
The coordination service set the task on worker nodes to error after the training finishes. What is expected is that both chief and worker nodes should exit synchronously without error on tasks.
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_addons as tfa
import json
import os

tf_config = {
     'cluster': {
       'worker': ['localhost1:2222', 'localhost2:2222']
    },
      'task': {'type': 'worker', 'index': 0}
  }
os.environ['TF_CONFIG'] = json.dumps(tf_config)

communication_options = tf.distribute.experimental.CommunicationOptions(
    implementation=tf.distribute.experimental.CommunicationImplementation.NCCL)
strategy = tf.distribute.MultiWorkerMirroredStrategy(
    communication_options=communication_options)

with strategy.scope():
    num_classes = 100
    input_shape = (32, 32, 3)

    (x_tr, y_tr), (x_te, y_te) = keras.datasets.cifar100.load_data()

    x_train = tf.convert_to_tensor(x_tr)
    x_test = tf.convert_to_tensor(x_te)
    y_train = tf.convert_to_tensor(y_tr)
    y_test = tf.convert_to_tensor(y_te)

    print(f""x_train shape: {x_train.shape} - y_train shape: {y_train.shape}"")
    print(f""x_test shape: {x_test.shape} - y_test shape: {y_test.shape}"")

    learning_rate = 0.001
    weight_decay = 0.0001
    batch_size = 1000
    num_epochs = 5
    image_size = 72  # We'll resize input images to this size
    patch_size = 6  # Size of the patches to be extract from the input images
    num_patches = (image_size // patch_size) ** 2
    projection_dim = 64
    num_heads = 4
    transformer_units = [
        projection_dim * 2,
        projection_dim,
    ]  # Size of the transformer layers
    transformer_layers = 4
    mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier

    data_augmentation = keras.Sequential(
        [
            layers.Normalization(),
            layers.Resizing(image_size, image_size),
            layers.RandomFlip(""horizontal""),
            layers.RandomRotation(factor=0.02),
            layers.RandomZoom(
                height_factor=0.2, width_factor=0.2
            ),
        ],
        name=""data_augmentation"",
    )
    # Compute the mean and the variance of the training data for normalization.
    data_augmentation.layers[0].adapt(x_train)

    def mlp(x, hidden_units, dropout_rate):
        for units in hidden_units:
            x = layers.Dense(units, activation=tf.nn.gelu)(x)
            x = layers.Dropout(dropout_rate)(x)
        return x

    class Patches(layers.Layer):
        def __init__(self, patch_size):
            super(Patches, self).__init__()
            self.patch_size = patch_size

        def call(self, images):
            batch_size = tf.shape(images)[0]
            patches = tf.image.extract_patches(
                images=images,
                sizes=[1, self.patch_size, self.patch_size, 1],
                strides=[1, self.patch_size, self.patch_size, 1],
                rates=[1, 1, 1, 1],
                padding=""VALID"",
            )
            patch_dims = patches.shape[-1]
            patches = tf.reshape(patches, [batch_size, -1, patch_dims])
            return patches

    image = x_train[np.random.choice(range(x_train.shape[0]))]


    resized_image = tf.image.resize(
        tf.convert_to_tensor([image]), size=(image_size, image_size)
    )
    patches = Patches(patch_size)(resized_image)
    print(f""Image size: {image_size} X {image_size}"")
    print(f""Patch size: {patch_size} X {patch_size}"")
    print(f""Patches per image: {patches.shape[1]}"")
    print(f""Elements per patch: {patches.shape[-1]}"")


    class PatchEncoder(layers.Layer):
        def __init__(self, num_patches, projection_dim):
            super(PatchEncoder, self).__init__()
            self.num_patches = num_patches
            self.projection = layers.Dense(units=projection_dim)
            self.position_embedding = layers.Embedding(
                input_dim=num_patches, output_dim=projection_dim
            )

        def call(self, patch):
            positions = tf.range(start=0, limit=self.num_patches, delta=1)
            encoded = self.projection(patch) + self.position_embedding(positions)
            return encoded

    def create_vit_classifier():
        inputs = layers.Input(shape=input_shape)
        # Augment data.
        augmented = data_augmentation(inputs)
        # Create patches.
        patches = Patches(patch_size)(augmented)
        # Encode patches.
        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)

        # Create multiple layers of the Transformer block.
        for _ in range(transformer_layers):
            # Layer normalization 1.
            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
            # Create a multi-head attention layer.
            attention_output = layers.MultiHeadAttention(
                num_heads=num_heads, key_dim=projection_dim, dropout=0.1
            )(x1, x1)
            # Skip connection 1.
            x2 = layers.Add()([attention_output, encoded_patches])
            # Layer normalization 2.
            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)
            # MLP.
            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)
            # Skip connection 2.
            encoded_patches = layers.Add()([x3, x2])

        # Create a [batch_size, projection_dim] tensor.
        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
        representation = layers.Flatten()(representation)
        representation = layers.Dropout(0.5)(representation)
        # Add MLP.
        features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)
        # Classify outputs.
        logits = layers.Dense(num_classes)(features)
        # Create the Keras model.
        model = keras.Model(inputs=inputs, outputs=logits)
        return model

    def run_experiment(model):
        optimizer = tfa.optimizers.AdamW(
            learning_rate=learning_rate, weight_decay=weight_decay
        )

        model.compile(
            optimizer=optimizer,
            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=[
                keras.metrics.SparseCategoricalAccuracy(name=""accuracy""),
                keras.metrics.SparseTopKCategoricalAccuracy(5, name=""top-5-accuracy""),
            ]
        )

        history = model.fit(
            x=x_train,
            y=y_train,
            batch_size=batch_size,
            epochs=num_epochs,
            validation_split=0.1,
        )

        return history


    vit_classifier = create_vit_classifier()
    history = run_experiment(vit_classifier)
```


### Relevant log output

```shell
2022-10-25 23:49:00.673235: E tensorflow/core/distributed_runtime/coordination/coordination_service.cc:909] /job:worker/replica:0/task:1 has been set to ERROR in coordination service: UNAVAILABLE: Task /job:worker/replica:0/task:1 heartbeat timeout. This indicates that the remote task has failed, got preempted, or crashed unexpectedly. [type.googleapis.com/tensorflow.CoordinationServiceError='']
```
</details>"
58433,OperatorNotAllowedInGraphError: using random seed in tf.function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

tf 2.9.1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.1.74 / 8.0.5

### GPU model and memory

NVidia Tesla V100-SXM2-32GB

### Current Behaviour?

`tf.random.set_seed()` in a tf.function doesn't seem to do anything.


### Standalone code to reproduce the issue

For reproducible tests it might be useful to set seeds. When using a distributed strategy, it would be nice to have a different seed for each replica, hence set the seed **inside** the tf.function.

I've done tests (without a distributed strategy for sake of simplicity):

This works:

```python
@tf.function
def f(X):
    tf.random.set_seed(X)

f(tf.constant(1))
```

This works too:
```python
@tf.function
def f(X):
    tf.print(tf.random.normal((2,3)))

f(tf.constant(1))
```

But this fails:
```python
@tf.function
def f(X):
    tf.random.set_seed(X)
    tf.print(tf.random.normal((2,3)))

f(tf.constant(1))
```
... with this error: 

```
File ""<ipython-input-165-c6a6c2a4e4db>"", line 4, in f  *
        tf.print(tf.random.normal((2,3)))
OperatorNotAllowedInGraphError: Using a symbolic `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.
```

Note that setting a seed in a tf.function doesn't seem to work:

```python
@tf.function
def f():
    tf.random.set_seed(1)
    tf.print(tf.random.normal((2,3)))

f()
f()
``` 
prints different values for the two `f()` invocations

Using an externally provided seed for `tf.random.normal()` also results in a `OperatorNotAllowedInGraphError`:
```python
@tf.function
def f(X):
    tf.print(tf.random.normal((2,3), seed=X))

f(tf.constant(1))
```

Consider this last attempt:
```python
class MyModule(tf.Module):
    def __init__(self, seed):
        self.seed = seed
        self.strategy = tf.distribute.MirroredStrategy()

    def _train(self):
        # this works but all replicas have the same seed.
        tf.print(tf.random.normal((2,3), seed=self.seed))

        if False: # replace with True to test
            # the seed differs but this fails with OperatorNotAllowedInGraphError
            repl_id = tf.distribute.get_replica_context().replica_id_in_sync_group
            print(tf.random.normal((2,3), seed=self.seed + repl_id))
    
    @tf.function
    def distributed_train(self):
        self.strategy.run(self._train)

    
module = MyModule(seed=1)
module.distributed_train()
```


Again, this seems silly but the only purpose of using seeds **inside** a tf.function is to provide each replica with a different seed. 
```
"
58432,Issues with Tensorflow benchmark tool on OpenCL C 1.2,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: Khadas Vim3
-   **TensorFlow installed from (source or binary)**: Source
-   **TensorFlow version (use command below)**: 2.8.0
-   **Python version**: 3.8
-   **Bazel version (if compiling from source)**: 4.2.1
-   **GCC/Compiler version (if compiling from source)**: 9.4.0
-   **CUDA/cuDNN version**: NA
-   **GPU model and memory**: Vivante NPU (VIPNano-Q)
-   **Exact command to reproduce**: 

### Description of the problem
I have tried running the Tensorflow benchmark tool on Khadas Vim 3 (running Ubuntu 20.04) with OpenCL libraries for Vivante NPU. When I tried to run it on BlazePose model available provided by Mediapipe and Movenet model obtained from TF Hub, following error was obtained. Please note that Posenet model (which is another floating point model) worked fine and clinfo runs fine, thus, it is not that the library is corrupted.

### Source code / logs
**Error from Tensorflow benchmark tool:**
```
ERROR: Failed to build program executable - Build program failure(82:0) : error : syntax error at '[' (82:0) : error : syntax error at '[' 
ERROR: Falling back to OpenGL ERROR: TfLiteGpuDelegate Init: OpenGL-based API disabled
INFO: Created 0 GPU delegate kernels.
ERROR: TfLiteGpuDelegate Prepare: delegate is not initialized ERROR: Node number 157 (TfLiteGpuDelegateV2) failed to prepare. 
ERROR: Restored original execution plan after delegate application failure. 
Failed to apply GPU delegate. 
Benchmarking failed.
```
**Information from clinfo:**

	Number of platforms                               1
	  Platform Name                                   Vivante OpenCL Platform
	  Platform Vendor                                 Vivante Corporation
	  Platform Version                                OpenCL 3.0 V6.4.8.7.415784
	  Platform Profile                                FULL_PROFILE
	  Platform Extensions                             cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_il_program cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics
	  Platform Host timer resolution                  0ns
	
	  Platform Name                                   Vivante OpenCL Platform
	Number of devices                                 1
	  Device Name                                     Vivante OpenCL Device VIPNano-QI.7120.0000
	  Device Vendor                                   Vivante Corporation
	  Device Vendor ID                                0x564956
	  Device Version                                  OpenCL 3.0
	  Driver Version                                  OpenCL 3.0 V6.4.8.7.415784
	  Device OpenCL C Version                         OpenCL C 1.2
	  Device Type                                     GPU
	  Device Profile                                  FULL_PROFILE
	  Device Available                                Yes
	  Compiler Available                              Yes
	  Linker Available                                Yes
	  Max compute units                               1
	  Max clock frequency                             800MHz
	  Device Partition                                (core)
	    Max number of sub-devices                     0
	    Supported partition types                     None
	    Supported affinity domains                    (n/a)
	  Max work item dimensions                        3
	  Max work item sizes                             256x256x256
	  Max work group size                             256
	  Preferred work group size multiple              4
	  Max sub-groups per work group                   0
	  Preferred / native vector sizes
	    char                                                 4 / 4
	    short                                                4 / 4
	    int                                                  4 / 4
	    long                                                 4 / 4
	    half                                                 4 / 4        (cl_khr_fp16)
	    float                                                4 / 4
	    double                                               0 / 0        (n/a)
	  Half-precision Floating-point support           (cl_khr_fp16)
	    Denormals                                     No
	    Infinity and NANs                             Yes
	    Round to nearest                              Yes
	    Round to zero                                 Yes
	    Round to infinity                             No
	    IEEE754-2008 fused multiply-add               No
	    Support is emulated in software               No
	  Single-precision Floating-point support         (core)
	    Denormals                                     No
	    Infinity and NANs                             Yes
	    Round to nearest                              Yes
	    Round to zero                                 Yes
	    Round to infinity                             No
	    IEEE754-2008 fused multiply-add               No
	    Support is emulated in software               No
	    Correctly-rounded divide and sqrt operations  No
	  Double-precision Floating-point support         (n/a)
	  Address bits                                    32, Little-Endian
	  Global memory size                              268435456 (256MiB)
	  Error Correction support                        Yes
	  Max memory allocation                           134217728 (128MiB)
	  Unified memory for Host and Device              Yes
	  Shared Virtual Memory (SVM) capabilities        (core)
	    Coarse-grained buffer sharing                 No
	    Fine-grained buffer sharing                   No
	    Fine-grained system sharing                   No
	    Atomics                                       No
	  Minimum alignment for any data type             128 bytes
	  Alignment of base address                       2048 bits (256 bytes)
	  Preferred alignment for atomics
	    SVM                                           0 bytes
	    Global                                        0 bytes
	    Local                                         0 bytes
	  Max size for global variable                    0
	  Preferred total size of global vars             0
	  Global Memory cache type                        Read/Write
	  Global Memory cache size                        16384 (16KiB)
	  Global Memory cache line size                   64 bytes
	  Image support                                   Yes
	    Max number of samplers per kernel             16
	    Max size for 1D images from buffer            65536 pixels
	    Max 1D or 2D image array size                 8192 images
	    Max 2D image size                             8192x8192 pixels
	    Max 3D image size                             8192x8192x8192 pixels
	    Max number of read image args                 128
	    Max number of write image args                8
	    Max number of read/write image args           0
	  Max number of pipe args                         0
	  Max active pipe reservations                    0
	  Max pipe packet size                            0
	  Local memory type                               Global
	  Local memory size                               32768 (32KiB)
	  Max number of constant args                     9
	  Max constant buffer size                        65536 (64KiB)
	  Max size of kernel argument                     1024
	  Queue properties (on host)
	    Out-of-order execution                        Yes
	    Profiling                                     Yes
	  Queue properties (on device)
	    Out-of-order execution                        No
	    Profiling                                     No
	    Preferred size                                0
	    Max size                                      0
	  Max queues on device                            0
	  Max events on device                            0
	  Prefer user sync for interop                    Yes
	  Profiling timer resolution                      1000ns
	  Execution capabilities
	    Run OpenCL kernels                            Yes
	    Run native kernels                            No
	    Sub-group independent forward progress        No
	    IL version                                    SPIR-V_1.5
	  printf() buffer size                            1048576 (1024KiB)
	  Built-in kernels                                (n/a)
	  Device Extensions                               cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_il_program cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics
	
	NULL platform behavior
	  clGetPlatformInfo(NULL, CL_PLATFORM_NAME, ...)  No platform
	  clGetDeviceIDs(NULL, CL_DEVICE_TYPE_ALL, ...)   Success [P0]
	  clCreateContext(NULL, ...) [default]            Success [P0]
	  clCreateContextFromType(NULL, CL_DEVICE_TYPE_DEFAULT)  Success (1)
	    Platform Name                                 Vivante OpenCL Platform
	    Device Name                                   Vivante OpenCL Device VIPNano-QI.7120.0000
	  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CPU)  No devices found in platform
	  clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU)  Success (1)
	    Platform Name                                 Vivante OpenCL Platform
	    Device Name                                   Vivante OpenCL Device VIPNano-QI.7120.0000
	  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ACCELERATOR)  No devices found in platform
	  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CUSTOM)  No devices found in platform
	  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ALL)  Success (1)
	    Platform Name                                 Vivante OpenCL Platform
	    Device Name                                   Vivante OpenCL Device VIPNano-QI.7120.0000
	        NOTE:   your OpenCL library only supports OpenCL 2.2,
	                but some installed platforms support OpenCL 3.0.
	                Programs using 3.0 features may crash
	                or behave unexpectedly"
58431,Why my code get better f1_score on older versions,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0 , 2.7.0, 2.4.0 

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.7.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Hi, I adopt different tensorflow and keras versions with my code. But it return better f_1 Score on older versions. The reproduction results are as follows:
|Tensorflow|Keras|F1 Score|
|--|--|--|
|2.7.0|2.7.0|0.29846938775510207|
|2.4.0|2.4.0|0.7376928728875827|


I also test it with TensorFlow 2.10.0, and the f_1 score is 0.6031746031746031.



### Standalone code to reproduce the issue

I post the code on colad.[click me to reproduce](https://colab.research.google.com/drive/1BWZMI7uPmYfOgobBHRH0H2q3WXOSmdDn?usp=sharing)


### Relevant log output

_No response_</details>"
58429,Confusing Problems(Not a ndarray) occur when training wGAN with tensorflow.keras API : train_on_batch,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.4.0

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

Cuda compilation tools, release 11.1, V11.1.74;

### GPU model and memory

NVIDIA GeForce RTX 2080 Ti

### Current Behaviour?

```shell
Thanks to listen to my troubles!
It's my first time to call for help here.
I'm trying to train a wGAN with tensorflow.keras API.
It's confusing that the code seems to be able to work (loss can be correctly printed by epochs at the start).
But few epochs later, strange bug occurs as follow:(loss during training is remained)
--------------------------------
1 [D:-147.46, -46.00, -35.65, -138.93] [G:-481.90, 121.64, -221.78, -450.19] [L2_train:0.09970, 0.18841, 0.15391] [L2_val:0.07979, 0.07859, 0.04204] [L2_test:0.05952, 0.06244, 0.03242]
2 [D:-66.22, -26.87, -30.62, -29.14] [G:1.39, 206.37, 81.76, -345.29] [L2_train:0.09337, 0.14223, 0.13607] [L2_val:0.06910, 0.07733, 0.06625] [L2_test:0.06862, 0.08175, 0.07353]
3 [D:-54.95, -18.99, -16.84, -35.61] [G:235.31, 328.33, 220.04, -362.90] [L2_train:0.08394, 0.09853, 0.13101] [L2_val:0.04700, 0.05218, 0.04421] [L2_test:0.04917, 0.04784, 0.04229]
4 [D:-27.29, -11.39, -12.51, -9.55] [G:544.69, 333.72, 438.66, -258.71] [L2_train:0.04703, 0.06783, 0.06758] [L2_val:0.03517, 0.02774, 0.02109] [L2_test:0.03086, 0.02149, 0.01878]
5 [D:-91.86, -5.06, -46.21, -85.04] [G:33.63, 147.32, 290.38, -437.90] [L2_train:0.03059, 0.09686, 0.07675] [L2_val:0.04741, 0.10769, 0.09652] [L2_test:0.05370, 0.11032, 0.08847]
6 [D:-128.18, -37.26, -70.93, -83.93] [G:103.86, 301.46, 285.43, -505.10] [L2_train:0.02071, 0.05535, 0.05631] [L2_val:0.15789, 0.19782, 0.23549] [L2_test:0.15388, 0.18545, 0.21865]
7 [D:-133.02, -34.37, -73.45, -96.01] [G:-246.37, 155.21, 177.28, -604.51] [L2_train:0.02656, 0.05191, 0.07738] [L2_val:0.07032, 0.07954, 0.10540] [L2_test:0.12615, 0.10203, 0.17840]
8 [D:-40.16, -9.07, -24.21, -21.30] [G:19.53, 46.06, 206.59, -257.90] [L2_train:0.02747, 0.06426, 0.05750] [L2_val:0.02567, 0.04412, 0.02398] [L2_test:0.02138, 0.04012, 0.01959]
9 [D:-17.11, -5.28, -5.77, -11.56] [G:209.23, 72.47, 119.92, -9.19] [L2_train:0.03270, 0.05385, 0.06082] [L2_val:0.04001, 0.04625, 0.04980] [L2_test:0.03669, 0.03864, 0.08824]
10 [D:-46.63, -10.17, -22.81, -32.98] [G:244.32, -120.41, 301.34, 37.02] [L2_train:0.02382, 0.04930, 0.08281] [L2_val:0.01641, 0.04040, 0.04434] [L2_test:0.01816, 0.04293, 0.04300]
11 [D:-17.25, -3.89, -8.81, -8.89] [G:346.39, 128.02, 417.59, -222.40] [L2_train:0.02294, 0.07087, 0.04800] [L2_val:0.02236, 0.01953, 0.02654] [L2_test:0.05305, 0.04639, 0.07816]
Traceback (most recent call last):
  File ""Compound_Model_Novel.py"", line 504, in <module>
    sa_wgan_gp.train()
  File ""Compound_Model_Novel.py"", line 356, in train
    g_loss_train = self.gan_model.train_on_batch(
  File ""E:\anaconda\envs\cnnGAN\lib\site-packages\tensorflow\python\keras\engine\training_v1.py"", line 1088, in train_on_batch
    outputs = self.train_function(ins)  # pylint: disable=not-callable
  File ""E:\anaconda\envs\cnnGAN\lib\site-packages\tensorflow\python\keras\backend.py"", line 3956, in __call__
    fetched = self._callable_fn(*array_vals,
  File ""E:\anaconda\envs\cnnGAN\lib\site-packages\tensorflow\python\client\session.py"", line 1480, in __call__
    ret = tf_session.TF_SessionRunCallable(self._session._session,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Not a ndarray.
------------------------------------------------------
My doubts lie in the following points：
1. I do not understand why ""Not a ndarray"" will occur in my code in line ""g_loss_train = self.gan_model.train_on_batch(..."", which functions as gan_model training. In this function only inputs and target are fed self.gan_model.
2. Why this bug does not occur at the start of the training?
3. What will cause such bug during training process? ""Not a ndarray"" refers to what? My inputs, targets or others?
4. How to fix it

Deeply appreciated to your attention!
```


### Standalone code to reproduce the issue

```shell
None
```


### Relevant log output

_No response_</details>"
58428,"I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA Version: 11.6

### GPU model and memory

NVIDIA GeForce RTX 2060

### Current Behaviour?

I want to know why tensorflow always spamms that message in the official docker container (`tensorflow/tensorflow:2.10.0-gpu-jupyter`)?
`I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero`

This is probably not a problem at runtime, but it is still very annoying that the output is spammed every time.
I only found #56456 which is closed due to inactivity.

I tried https://github.com/tensorflow/tensorflow/issues/56456#issuecomment-1156008981, which I think means:

```py
gpus = tf.config.list_physical_devices('GPU')
if gpus:
  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
  try:
    tf.config.set_logical_device_configuration(
        gpus[0],
        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Virtual devices must be set before GPUs have been initialized
    print(e)
```
but that does not help.


### Standalone code to reproduce the issue

```py
import tensorflow as tf

print(tf.version.GIT_VERSION, tf.version.VERSION)
print(tf.config.list_physical_devices('GPU'))

print(tf.add(1, 1).numpy())
```


### Relevant log output

```shell
I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
v2.10.0-rc3-6-g359c3cdfc5f 2.10.0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4582 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:03:00.0, compute capability: 7.5
2
```
</details>"
58424,Deleting legacy Java client from TensorFlow main repository,"TensorFlow main repository still contains the old [Java client](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java) based on TF1.x that has been replaced a few years ago by the [new version](https://github.com/tensorflow/java) maintained by SIG-JVM.

This is very misleading for users who wants to discover the capabilities of running TensorFlow models on Java (just this week a new example of such [question](https://discuss.tensorflow.org/t/what-does-it-mean-for-the-java-api-that-warning-this-api-is-deprecated-and-will-be-removed-in-a-future-version-of-tensorflow-after-the-replacement-is-stable/12757) appeared on the forum).

This issue is to start the process of deleting this client for good in TF main repo. We could start by replacing this [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md) for simply saying that this client is deprecated and provide links to the new repo. Then we can proceed to the folder deletion, making sure it won't break any code, CI jobs or external scripts (like the documentation one).

If need be, we at SIG-JVM can take care of pushing a series of pull requests to achieve this goal. 

CC\ @bhack , @craigacp"
58423,Delete the old Java client from TensorFlow main repository,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
This is no bug but a change request.

TensorFlow main repository still contains the old [Java client](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/java) based on TF1.x that has been replaced a few years ago by the [new version](https://github.com/tensorflow/java) maintained by SIG-JVM.

This is very misleading for users who wants to discover the capabilities of running TensorFlow models on Java (just this week a new example of such [question](https://discuss.tensorflow.org/t/what-does-it-mean-for-the-java-api-that-warning-this-api-is-deprecated-and-will-be-removed-in-a-future-version-of-tensorflow-after-the-replacement-is-stable/12757) appeared on the forum).

This issue is to start the process of deleting this client for good in TF main repo. We could start by replacing this [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md) for simply saying that this client is deprecated and provide links to the new repo. Then we can proceed to the folder deletion, making sure it won't break any code, CI jobs or external scripts (like the documentation one).

If need be, we at SIG-JVM can take care of pushing a series of pull requests to achieve this goal. 

CC\ @bhack , @craigacp
```


### Standalone code to reproduce the issue

```shell
This is no bug but a change request.
```


### Relevant log output

_No response_</details>"
58421,Feature Request - Tensorflow Docker Extension,"
### Describe the problem
Feature request: Hi, I am the product manager for Docker Extensions. We've been getting some requests from Docker users to see a Tensorflow Docker Extension. The most common reason for this request is that the user does not want to install Tensorflow locally. I am opening this feature request so that the larger Tensorflow community can determine how helpful this would be and decide if it should be built. 

### Source code / logs
If it is decided that this Docker Extension should be built, documentation is available [here](https://docs.docker.com/desktop/extensions-sdk/) on how to build a Docker Extension.  If assistance or support is needed, please reach out as we are happy to help!
"
58419,TF 2.11.0-rc2 fails to compile on Linux with GPU support due to error related to CUDA tensorRT,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11.0-rc2

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

5.3.0

### GCC/Compiler version

11.3.0

### CUDA/cuDNN version

11.8

### GPU model and memory

NVidia GeForce 1080ti, 

### Current Behaviour?

```shell
Error with standard compilation following the directions as per TF documentation.

Using tensorrt library from NVidia, v.8.5.1.7-1+cuda11.8
```


### Standalone code to reproduce the issue

```shell
https://www.tensorflow.org/install/source
```


### Relevant log output

```shell
ERROR: /home/nicola/Software/tensorflow-dir/gpu/tensorflow/tensorflow/compiler/tf2tensorrt/BUILD:562:16: Compiling tensorflow/compiler/tf2tensorrt/convert/weights.cc failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/tf2tensorrt/_objs/trt_weights/weights.pic.d ... (remaining 182 arguments skipped)
tensorflow/compiler/tf2tensorrt/convert/weights.cc: In member function ‘size_t tensorflow::tensorrt::convert::TRT_ShapedWeights::size_bytes() const’:
tensorflow/compiler/tf2tensorrt/convert/weights.cc:61:10: error: enumeration value ‘kUINT8’ not handled in switch [-Werror=switch]
   61 |   switch (type_) {
      |          ^
At global scope:
cc1plus: note: unrecognized command-line option ‘-Wno-unknown-warning’ may have been intended to silence earlier diagnostics
cc1plus: some warnings being treated as errors
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 483.410s, Critical Path: 58.83s
INFO: 5043 processes: 2258 internal, 2785 local.
FAILED: Build did NOT complete successfully
```
</details>"
58413,crosstool_wrapper_driver_is_not_gcc failed: error executing command,"<details><summary>Click to expand!</summary> 
 
 Issue Type ：Build/Install
 Source ：source
 Tensorflow Version：tf 2.7-rc1
 OS Platform and Distribution：Linux Ubuntu18.06
 Python version：3.9
 Bazel version：3.7.2
 GCC/Compiler version：7.5
 CUDA/cuDNN version：CUDA version : 11.3   cuDNN version : 8.2.1
 GPU model and memory：RTX 3060Ti

### Current Behaviour?
Build keep failing with branch r2.7. 
I build C++ API on ubuntu18.04，the version of gcc is 7.5, but encountered the problem of ""crosstool_wrapper_driver_is_not_gcc failed: error executing command"", After I change the gcc version of 9.4，the error is still reported. I need your help, Thank you!

```shell
bazel build --config=opt --verbose_failures --local_ram_resources=3000 --config=cuda //tensorflow/tools/pip_package:build_pip_package
```

### Standalone code to reproduce the issue
```shell
ERROR: /home/dl/TestCode/tensorflow-2.7.0/tensorflow/compiler/mlir/tensorflow/BUILD:436:15: C++ compilation of rule '//tensorflow/compiler/mlir/tensorflow:tensorflow_ops_a_m' failed (Exit 4): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/dl/.cache/bazel/_bazel_dl/10bb052afa51776d577551d70bf8463a/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.3 \
    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 \
    PATH=/home/dl/software/anaconda3/bin:/home/dl/software/anaconda3/condabin:/home/dl/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/home/dl/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/dl/software/anaconda3/envs/tf27_python3/bin/python3 \
    PYTHON_LIB_PATH=/home/dl/software/anaconda3/envs/tf27_python3/lib/python3.9/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CUDA_COMPUTE_CAPABILITIES=8.6 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_a_m/tf_ops_a_m.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_a_m/tf_ops_a_m.pic.o' '-DLLVM_ON_UNIX=1' '-DHAVE_BACKTRACE=1' '-DBACKTRACE_HEADER=<execinfo.h>' '-DLTDL_SHLIB_EXT="".so""' '-DLLVM_PLUGIN_EXT="".so""' '-DLLVM_ENABLE_THREADS=1' '-DHAVE_SYSEXITS_H=1' '-DHAVE_UNISTD_H=1' '-DHAVE_STRERROR_R=1' '-DHAVE_LIBPTHREAD=1' '-DHAVE_PTHREAD_GETNAME_NP=1' '-DHAVE_PTHREAD_SETNAME_NP=1' '-DHAVE_PTHREAD_GETSPECIFIC=1' '-DHAVE_REGISTER_FRAME=1' '-DHAVE_DEREGISTER_FRAME=1' -D_GNU_SOURCE '-DHAVE_LINK_H=1' '-DHAVE_LSEEK64=1' '-DHAVE_MALLINFO=1' '-DHAVE_POSIX_FALLOCATE=1' '-DHAVE_SBRK=1' '-DHAVE_STRUCT_STAT_ST_MTIM_TV_NSEC=1' '-DLLVM_NATIVE_ARCH=""X86""' '-DLLVM_NATIVE_ASMPARSER=LLVMInitializeX86AsmParser' '-DLLVM_NATIVE_ASMPRINTER=LLVMInitializeX86AsmPrinter' '-DLLVM_NATIVE_DISASSEMBLER=LLVMInitializeX86Disassembler' '-DLLVM_NATIVE_TARGET=LLVMInitializeX86Target' '-DLLVM_NATIVE_TARGETINFO=LLVMInitializeX86TargetInfo' '-DLLVM_NATIVE_TARGETMC=LLVMInitializeX86TargetMC' '-DLLVM_NATIVE_TARGETMCA=LLVMInitializeX86TargetMCA' '-DLLVM_HOST_TRIPLE=""x86_64-unknown-linux-gnu""' '-DLLVM_DEFAULT_TARGET_TRIPLE=""x86_64-unknown-linux-gnu""' -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/k8-opt/bin -iquote external/llvm-project -iquote bazel-out/k8-opt/bin/external/llvm-project -iquote external/llvm_terminfo -iquote bazel-out/k8-opt/bin/external/llvm_terminfo -iquote external/llvm_zlib -iquote bazel-out/k8-opt/bin/external/llvm_zlib -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/k8-opt/bin/external/eigen_archive -iquote external/gif -iquote bazel-out/k8-opt/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -iquote external/double_conversion -iquote bazel-out/k8-opt/bin/external/double_conversion -iquote external/local_config_rocm -iquote bazel-out/k8-opt/bin/external/local_config_rocm -iquote external/local_config_tensorrt -iquote bazel-out/k8-opt/bin/external/local_config_tensorrt -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributeInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinDialectIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinLocationAttributesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinOpsIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypeInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/CastOpInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/SubElementInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorEncodingIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/DerivedAttributeOpInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -isystem external/llvm-project/mlir/include -isystem bazel-out/k8-opt/bin/external/llvm-project/mlir/include -isystem external/llvm-project/llvm/include -isystem bazel-out/k8-opt/bin/external/llvm-project/llvm/include -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem third_party/eigen3/mkl_include -isystem bazel-out/k8-opt/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_rocm/rocm -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm -isystem external/local_config_rocm/rocm/rocm/include -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include -isystem external/local_config_rocm/rocm/rocm/include/rocrand -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocrand -isystem external/local_config_rocm/rocm/rocm/include/roctracer -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/roctracer -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-sign-compare '-std=c++14' -c tensorflow/compiler/mlir/tensorflow/ir/tf_ops_a_m.cc -o bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_a_m/tf_ops_a_m.pic.o)
Execution platform: @local_execution_config_platform//:platform
x86_64-linux-gnu-gcc-7: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /home/dl/TestCode/tensorflow-2.7.0/tensorflow/lite/toco/python/BUILD:92:10 C++ compilation of rule '//tensorflow/compiler/mlir/tensorflow:tensorflow_ops_a_m' failed (Exit 4): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home/dl/.cache/bazel/_bazel_dl/10bb052afa51776d577551d70bf8463a/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.3 \
    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 \
    PATH=/home/dl/software/anaconda3/bin:/home/dl/software/anaconda3/condabin:/home/dl/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin:/home/dl/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/dl/software/anaconda3/envs/tf27_python3/bin/python3 \
    PYTHON_LIB_PATH=/home/dl/software/anaconda3/envs/tf27_python3/lib/python3.9/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CUDA_COMPUTE_CAPABILITIES=8.6 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_a_m/tf_ops_a_m.pic.d '-frandom-seed=bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_a_m/tf_ops_a_m.pic.o' '-DLLVM_ON_UNIX=1' '-DHAVE_BACKTRACE=1' '-DBACKTRACE_HEADER=<execinfo.h>' '-DLTDL_SHLIB_EXT="".so""' '-DLLVM_PLUGIN_EXT="".so""' '-DLLVM_ENABLE_THREADS=1' '-DHAVE_SYSEXITS_H=1' '-DHAVE_UNISTD_H=1' '-DHAVE_STRERROR_R=1' '-DHAVE_LIBPTHREAD=1' '-DHAVE_PTHREAD_GETNAME_NP=1' '-DHAVE_PTHREAD_SETNAME_NP=1' '-DHAVE_PTHREAD_GETSPECIFIC=1' '-DHAVE_REGISTER_FRAME=1' '-DHAVE_DEREGISTER_FRAME=1' -D_GNU_SOURCE '-DHAVE_LINK_H=1' '-DHAVE_LSEEK64=1' '-DHAVE_MALLINFO=1' '-DHAVE_POSIX_FALLOCATE=1' '-DHAVE_SBRK=1' '-DHAVE_STRUCT_STAT_ST_MTIM_TV_NSEC=1' '-DLLVM_NATIVE_ARCH=""X86""' '-DLLVM_NATIVE_ASMPARSER=LLVMInitializeX86AsmParser' '-DLLVM_NATIVE_ASMPRINTER=LLVMInitializeX86AsmPrinter' '-DLLVM_NATIVE_DISASSEMBLER=LLVMInitializeX86Disassembler' '-DLLVM_NATIVE_TARGET=LLVMInitializeX86Target' '-DLLVM_NATIVE_TARGETINFO=LLVMInitializeX86TargetInfo' '-DLLVM_NATIVE_TARGETMC=LLVMInitializeX86TargetMC' '-DLLVM_NATIVE_TARGETMCA=LLVMInitializeX86TargetMCA' '-DLLVM_HOST_TRIPLE=""x86_64-unknown-linux-gnu""' '-DLLVM_DEFAULT_TARGET_TRIPLE=""x86_64-unknown-linux-gnu""' -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/k8-opt/bin -iquote external/llvm-project -iquote bazel-out/k8-opt/bin/external/llvm-project -iquote external/llvm_terminfo -iquote bazel-out/k8-opt/bin/external/llvm_terminfo -iquote external/llvm_zlib -iquote bazel-out/k8-opt/bin/external/llvm_zlib -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/k8-opt/bin/external/eigen_archive -iquote external/gif -iquote bazel-out/k8-opt/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -iquote external/double_conversion -iquote bazel-out/k8-opt/bin/external/double_conversion -iquote external/local_config_rocm -iquote bazel-out/k8-opt/bin/external/local_config_rocm -iquote external/local_config_tensorrt -iquote bazel-out/k8-opt/bin/external/local_config_tensorrt -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributeInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinDialectIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinLocationAttributesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinOpsIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypeInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/CastOpInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/SubElementInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/TensorEncodingIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/DerivedAttributeOpInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -isystem external/llvm-project/mlir/include -isystem bazel-out/k8-opt/bin/external/llvm-project/mlir/include -isystem external/llvm-project/llvm/include -isystem bazel-out/k8-opt/bin/external/llvm-project/llvm/include -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem third_party/eigen3/mkl_include -isystem bazel-out/k8-opt/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_rocm/rocm -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm -isystem external/local_config_rocm/rocm/rocm/include -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include -isystem external/local_config_rocm/rocm/rocm/include/rocrand -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocrand -isystem external/local_config_rocm/rocm/rocm/include/roctracer -isystem bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/roctracer -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIC -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-sign-compare '-std=c++14' -c tensorflow/compiler/mlir/tensorflow/ir/tf_ops_a_m.cc -o bazel-out/k8-opt/bin/tensorflow/compiler/mlir/tensorflow/_objs/tensorflow_ops_a_m/tf_ops_a_m.pic.o)
Execution platform: @local_execution_config_platform//:platform
INFO: Elapsed time: 640.783s, Critical Path: 202.56s
INFO: 2524 processes: 629 internal, 1895 local.
FAILED: Build did NOT complete successfully
```"
58412,Inconsistent RMSProp implementation compared with Kingma and Ba paper,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

N/A

### Mobile device

N/A

### Python version

N/A

### Bazel version

N/A

### GCC/Compiler version

N/A

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
The Kingma and Ba paper uses the following line to update parameters when implementing Adam.
$\theta_t ←\theta_{t−1}−\frac{\alpha_t \cdot mt}{(\sqrt{v_t} +\hat{\epsilon})}$
In TensorFlow's documentation (https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop), RMSProp follows the same way to apply the epsilon $\epsilon$. However, I notice that the implementation of epsilon in RMSProp https://github.com/tensorflow/tensorflow/blob/57e18f3835c07a3dcdea1c4dcd1723e1b9c5dae3/tensorflow/core/kernels/training_ops.cc#L904 is $\sqrt{v_t+\hat{\epsilon}}$ instead of $\sqrt{v_t}+\hat{\epsilon}$ mentioned in the Adam paper. I cross-checked with TensorFlow's implementation in Adam (https://github.com/tensorflow/tensorflow/blob/57e18f3835c07a3dcdea1c4dcd1723e1b9c5dae3/tensorflow/core/kernels/training_ops.cc#L822) and PyTorch's implementation in RMSProp (https://github.com/pytorch/pytorch/blob/ccf6b558a4c58d1ae92689b2a5064916b42eff05/torch/optim/rmsprop.py#L257), they both use $\sqrt{v_t}+\hat{\epsilon}$ instead of $\sqrt{v_t+\hat{\epsilon}}$ implemented in TensorFlow's RMSProp. May I know if you have special handling about the place of epsilon in RMSProp? If it is possible, I guess it would be better to write $\sqrt{v_t}+\hat{\epsilon}$ instead of the current version: $\sqrt{v_t+\hat{\epsilon}}$.
```


### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_</details>"
58411,"Converting model to frozen pb causes original model to go into an ""Invalid State""","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.4

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


I currently am trying to convert a Tensorflow 2 Keras model into a Tensorflow 1 frozen pb. My code is able to accomplish this and freezes the model correctly. I do this by creating my model, then saving it as an h5, then load that models h5 as a separate model and freeze it.

However, if I try to load and freeze the model and then continue on to use the original model (the untouched one), it's put into an ""Invalid State"". I've tried looking to see if there is an issue with the keras backend session being confused or if the two models have the same reference but they are all separate. 

It's as if the original model and the loaded model are the same one. I'm not sure if this is a bug or more likely user error.



### Standalone code to reproduce the issue

```python
# create, compile, train original model | or load original model 

original_model.save('original_model.h5', save_format='h5')
convert_to_pb('original_model.h5')

original_model.predict(inp) # Error occurs here

-----------------------------------------
# Convert Script

import tensorflow as tf

def convert_to_pb(h5_file):
    with tf.compat.v1.keras.backend.get_session() as sess:
        model = tf.keras.models.load_model(h5_file)

        graph = sess.graph
        output_names = [out.op.name for out in model.outputs]
        input_graph_def = graph.as_graph_def()

        for node in input_graph_def.node:
            node.device = """"
        
        frozen_graph = tf.compat.v1.graph_util.convert_variables_to_constants(sess, input_graph_def, output_names)
        frozen_graph = tf.compat.v1.graph_util.remove_training_nodes(frozen_graph)

        tf.io.write_graph(frozen_graph, '.', 'frozen_model.pb', as_text=False)
```


### Relevant log output

```shell
ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with model/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalid$tes all layers/models you previously made outside of the graph. 
2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the implementation of <class 'tensorflow.python.keras.layers.convolutional.Conv2D'> and its bases.
```
</details>"
58407,How to catch XlaRuntimeError in python,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Trying to catch XlaRuntimeError in Python. But the error is not visible and the module that defined this exception is also not visible. We are unable to import the exception.
The presumed module that defined XlaRuntimeError is tensorflow.compiler.xla.xla_client.
```


### Standalone code to reproduce the issue

```shell
import tensorflow.compiler.xla.python.xla_client
```


### Relevant log output

```shell
>>>ModuleNotFoundError: No module named 'tensorflow.compiler.xla.python'
```
</details>"
58404,typo in https://www.tensorflow.org/datasets/catalog/big_patent ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
here is the statement in the link:
There are two features: - description: detailed description of patent. - summary: Patent abastract.

and I think the word ""abastract"" is a typo.
```


### Standalone code to reproduce the issue

```shell
and I think the word ""abastract"" is a typo in the link above.
```


### Relevant log output

_No response_</details>"
58402,"TFLite ""Unrecognized GetAddress selector""","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10.0, master

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

iOS

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The simple convolution net is not working with batch size > 1 on metal backend.
It works fine if convert with batch size = 1 and call multiply inferences or if inference on CPU
The problem exists on 2.10.0 and current master

It fails with log

VERBOSE: Replacing 62 node(s) with delegate (TfLiteMetalDelegate) node, yielding 1 partitions.
Unrecognized GetAddress selector
```
```


### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

_No response_</details>"
58398,Fail to build TensorFlowLiteC_framework on multiple computers. ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Mac

### Mobile device

iOS

### Python version

3.10.1

### Bazel version

5.1.1

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Cannot run the following command successfully: 

bazel build --config=ios_fat -c opt --cxxopt=--std=c++17 \
  //tensorflow/lite/ios:TensorFlowLiteC_framework

https://www.tensorflow.org/lite/guide/build_ios
```


### Standalone code to reproduce the issue

```shell
git clone git@github.com:tensorflow/tensorflow.git
cd tensorflow && git checkout v2.10.0
./configure (Select y for iOS)
bazel build --config=ios_fat -c opt --cxxopt=--std=c++17 //tensorflow/lite/ios:TensorFlowLiteC_framework

Have tried this on Mac Pro Intel and Mac Mini M1
```


### Relevant log output

```shell
bazel build -c opt --config=ios_fat //tensorflow/lite/ios:TensorFlowLiteC_framework
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=148
INFO: Reading rc options for 'build' from /Users/erikbylow/Code/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/erikbylow/Code/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'build' from /Users/erikbylow/Code/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Users/erikbylow/Code/moby-ios-example/venvs/dev/bin/python3 --action_env PYTHON_LIB_PATH=/Users/erikbylow/Code/moby-ios-example/venvs/dev/lib/python3.10/site-packages --python_path=/Users/erikbylow/Code/moby-ios-example/venvs/dev/bin/python3
INFO: Reading rc options for 'build' from /Users/erikbylow/Code/tensorflow/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /Users/erikbylow/Code/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/erikbylow/Code/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:ios_fat in file /Users/erikbylow/Code/tensorflow/.bazelrc: --config=ios --ios_multi_cpus=armv7,arm64,i386,x86_64
INFO: Found applicable config definition build:ios in file /Users/erikbylow/Code/tensorflow/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --define=with_xla_support=false
ERROR: /private/var/tmp/_bazel_erikbylow/48d16e4855355c1fcf73c749f0eb5b3f/external/XNNPACK/BUILD.bazel:10330:26: configurable attribute ""deps"" in @XNNPACK//:amalgam_microkernels doesn't match this configuration. Would a default condition help?

Conditions checked:
 @XNNPACK//:aarch32
 @XNNPACK//:aarch64
 @XNNPACK//:x86
 @XNNPACK//:emscripten_wasm
 @XNNPACK//:emscripten_wasmsimd
 @XNNPACK//:emscripten_wasmrelaxedsimd
 @XNNPACK//:riscv

To see a condition's definition, run: bazel query --output=build <condition label>.

This instance of @XNNPACK//:amalgam_microkernels has configuration identifier d43cb89. To inspect its configuration, run: bazel config d43cb89.

For more help, see https://docs.bazel.build/configurable-attributes.html#why-doesnt-my-select-choose-what-i-expect.

ERROR: Analysis of target '//tensorflow/lite/ios:TensorFlowLiteC_framework' failed; build aborted:
INFO: Elapsed time: 3.737s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (105 packages loaded, 7364 targets configured)
```
</details>"
58397,https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryFocalCrossentropy contains some information of https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!

in the link below:
https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryFocalCrossentropy
it should have introduced some info about the BinaryFocalCrossentropy, but it put some info of BinaryCrossentropy as below:


Binary cross-entropy loss is often used for binary (0 or 1) classification tasks. The loss function requires the following inputs:

y_true (true label): This is either 0 or 1.
y_pred (predicted value): This is the model's prediction, i.e, a single floating-point value which either represents a logit, (i.e, value in [-inf, inf] when from_logits=True) or a probability (i.e, value in [0., 1.] when from_logits=False).
```


### Standalone code to reproduce the issue

```shell
click on the link above
```


### Relevant log output

_No response_</details>"
58395,Can't build cocoapods TensorflowLite 2.10 on mac M1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Mac os 12.6

### Mobile device

iphone 12 pro max

### Python version

3.10

### Bazel version

5.3.2

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I can't build the project after import `TensorFlowLiteSwift` and `TensorFlowLiteSelectTfOps` `2.10` from cocoapods. And it only happens on M1 mac, my other intel mac works fine.
```


### Standalone code to reproduce the issue

```shell
There are a lot of ""Undefined symbol"" when I try to run on device like this 
https://www.dropbox.com/s/t35ef63rkjp9fwu/tensorflowlite_build_bug.png?raw=1

```


### Relevant log output

_No response_</details>
<img width=""391"" alt=""tensorflowlite_build_bug"" src=""https://user-images.githubusercontent.com/2063905/199160374-22461cfd-b219-4a9d-8f98-64eab93e87a8.png"">
"
58392,TFLite won't build using ccmake [vs cmake],"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

commit 50a22ec283d14a9142bbd77cac77750714500768

### Custom Code

No

### OS Platform and Distribution

Ubuntu 22.04.1 LTS

### Mobile device

_No response_

### Python version

3.10.6 [ubuntu default]

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
From a fresh clone of tensorflow. If I try to build the TFLite minimal example:
* If I use ccmake, I get an error
* If I use cmake, it compiles successfully

[This is an issue because I'm trying to build another tool that requires TFLite, and doing that without using ccmake or cmake-gui is problematic. I found this inconsistency within just-tensorflow while trying to create a minimal test case]
```


### Standalone code to reproduce the issue

```shell
1. Prepare a fresh clone and go to minimal example dir:

git clone https://github.com/tensorflow/tensorflow.git tensorflow_src
cd tensorflow_src/tensorflow/lite/examples/minimal/

2. Make a build dir, build using cmake:
rm -rf build
mkdir build
cd build
cmake ..
make
# Builds and runs without error

2. Make a build dir, build using ccmake:
rm -rf build
mkdir build
cd build
ccmake ..
[in-tui, hit ""c"" to configure. If it were to work without error, you would then hit ""g"" to create the Makefiles, then ""q"" to quit. But, ""g"" doesn't work because there are errors during configure]
make
```


### Relevant log output

```shell
CMake Error at build/cpuinfo/CMakeLists.txt:262 (ADD_SUBDIRECTORY):
   ADD_SUBDIRECTORY not given a binary directory but the given source
   directory
   ""/home/chunky/src/tensorflow_src/tensorflow/lite/examples/minimal/build/clog-source""
   is not a subdirectory of
   ""/home/chunky/src/tensorflow_src/tensorflow/lite/examples/minimal/build/cpuinfo"".
   When specifying an out-of-tree source a binary directory must be explicitly
   specified.

 CMake Error at build/cpuinfo/CMakeLists.txt:265 (SET_PROPERTY):
   SET_PROPERTY could not find TARGET clog.  Perhaps it has not yet been
   created.
```
</details>"
58387,Two unit test failures on high CPU core count machines,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.10

### Bazel version

5.3.0

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/python/data/experimental/kernel_tests/service:worker_tags_test and //tensorflow/python/data/experimental/kernel_tests/service:local_workers_test timeout which is down to the elements in the dataset being prefetched, one per CPU core. This can result in unexpected exceptions due to End of sequence causing the test to fail when the CPU core count is more than approximately 200.
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=30,50,-1,-1 --flaky_test_attempts=1 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64 --build_tests_only -- //tensorflow/python/data/experimental/kernel_tests/service:worker_tags_test //tensorflow/python/data/experimental/kernel_tests/service:local_workers_test
```


### Relevant log output

```shell
======================================================================
ERROR: testMultipleConsumers_test_mode_graph_tfapiversion_2 (__main__.LocalWorkersTest)
LocalWorkersTest.testMultipleConsumers_test_mode_graph_tfapiversion_2
testMultipleConsumers_test_mode_graph_tfapiversion_2(mode='graph', tf_api_version=2)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/local_workers_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1378, in _do_call
    return fn(*args)
  File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/local_workers_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1361, in _run_fn
    return self._call_tf_sessionrun(options, feed_dict, fetch_list,
  File ""/home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/python/data/experimental/kernel_tests/service/local_workers_test.runfiles/org_tensorflow/tensorflow/python/client/session.py"", line 1454, in _call_tf_sessionrun
    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,
tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence
	 [[{{node IteratorGetNext_6}}]]
```
</details>"
58383,"Misspelling of the word ""argument""",https://github.com/tensorflow/tensorflow/blob/cdf72454805f790b97ad731f5ea9a400ecbbc26d/tensorflow/lite/python/optimize/calibrator.py#L97
58380,Input details changed after converting tf model to tflite model ,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 , 64 bit
- TensorFlow installation (pip package or built from source): 2.10 and 2.5 
- TensorFlow library (version, if pip package or github SHA, if built from source): pip 

### 2. Code

> 
> converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
> converter.target_spec.supported_ops = [
>   tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
>   tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
> ]
> tflite_model = converter.convert()
> open(""converted_model.tflite"", ""wb"").write(tflite_model)
> 

#### Option A: Reference colab notebooks


### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

**After converting the model and printing  input details shows this:**

> input_details = interpreter.get_input_details()
> output_details = interpreter.get_output_details()


> print(input_details)
> 

> [{'name': 'serving_default_input_tensor:0', 'index': 0, 'shape': array([1, 1, 1, 3]), 'shape_signature': array([ 1, -1, -1,  3]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]



### 5. (optional) Any other info / logs
**the model is object detection model using Tensorflow object detection API, mobilenet v2 320*320** 

."
58379,"when running tflite model , the performance of GPU  is obviously slower than  cpu on PC","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

2.7

### Custom Code

No

### OS Platform and Distribution

win64

### Mobile device

no

### Python version

3.7

### Bazel version

no 

### GCC/Compiler version

no

### CUDA/cuDNN version

no

### GPU model and memory

111

### Current Behaviour?

```shell
device : AMD Ryzen 5 5600U with Radeon Graphics （notebook）
the notebook only has a Core graphics card.

I run a .tflite model on notebook PC , I find the time of inference time on GPU is 28ms, but on cpu by using xnnpack its time is 18ms. Why the performance of GPU  is obviously slower than  cpu? thanks！
```


### Standalone code to reproduce the issue

```shell
no
```


### Relevant log output

_No response_</details>"
58378,Video classification notebook is showing error in output when replicated using TF 2.9,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

TF 2.9

### Custom Code

No

### OS Platform and Distribution

Google Colab, Linux

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am getting an error in the last section of code in the Video classification notebook when I tried replicating the code with TF 2.9 using Google Colab. The code is not showing any error if I use TF 2.8 and TF 2.10 to execute the code.
https://www.tensoreflow.org/tutorials/load_data/video#next_steps
```


### Standalone code to reproduce the issue

```shell
net = tf.keras.applications.EfficientNetB0(include_top = False)
net.trainable = False

model = tf.keras.Sequential([
    tf.keras.layers.TimeDistributed(net),
    tf.keras.layers.Dense(10),
    tf.keras.layers.GlobalAveragePooling3D()
])

model.compile(optimizer = 'adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),
              metrics=['accuracy'])

model.fit(train_ds, 
          epochs = 10,
          validation_data = val_ds,
          callbacks = tf.keras.callbacks.EarlyStopping(patience = 2, monitor = 'val_loss'))
```


### Relevant log output

```shell
Please find this [gist](https://colab.research.google.com/gist/RenuPatelGoogle/f56e7e03cfc57f5293b6e6716d9ecbd3/video.ipynb) for your reference.
```
</details>"
58376,Failed to apply XNNPACK after quantization aware training,"### 1. System information

- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installation (pip package): 2.7.0
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.7.0

### 2. Code

The model has two inputs, where the range of first one is [0, 1.0] and then second one is [-1.0, 1.0].

```python
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(
    os.path.join(dir_name, ""model.pb""), inputs, outputs
)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,  tf.lite.OpsSet.SELECT_TF_OPS,
]

converter.inference_type = tf.int8
converter.default_ranges_stats = (-128, 127)
converter.quantized_input_stats = {
    inputs[0]: {128, 128},
    **({inputs[1]: {0, 128}} if len(inputs) == 2 else {}),
}
output_path = os.path.join(output_path, name + ""_quant.tflite"")

tflite_model = converter.convert()
open(output_path, ""wb"").write(tflite_model)
```

### 3. Failure after conversion

We use quantization-aware training to train our models, and the deploy as `tf.int8` TFLite models. 

Actually, the model is converted successful, and fully functional on Qualcomm's CPU and Hexagon. But it run into errors when using XNNPACK delegate.

We test the model with tflite benchmark with xnnpack enabled, and found the following error messages:

```bash
STARTING!
Log parameter values verbosely: [0]
Min num runs: [250]
Num threads: [3]
Graph: [/data/debug/model_quant.tflite]
Enable op profiling: [1]
#threads used for CPU inference: [3]
Use xnnpack: [1]
Loaded model /data/debug/model_quant.tflite
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
XNNPACK delegate created.
INFO: Replacing 132 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 10 partitions.
ERROR: failed to create XNNPACK Value for tensor 103
ERROR: Node number 147 (TfLiteXNNPackDelegate) failed to prepare.

ERROR: Restored original execution plan after delegate application failure.
Failed to apply XNNPACK delegate.
Benchmarking failed.
```

However, XNNPACK is not always failed. It can run normally in some case:

1. If we deploy the model directly without training, it works.
2. Basically we training the model for 40k steps. if we train it shortly, e.g. only 25k, it works.
3. The backbone of the model is HRNet, If we used another architecture, e.g. Hourglass, it works.

We have been haunted by this strange thing for a month, please kindly let us know what's wrong.

Thank you for your time."
58373,High Batch Size Exceeds Memory,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.8

### GPU model and memory

NVIDIA GTX 1080Ti

### Current Behaviour?

```shell
I'm trying to train a model on a large dataset (not a tf dataset) with a batch size of 1500. Linux then reports that the allocation exceeds available memory:
```


### Standalone code to reproduce the issue

```shell
from keras.layers.core import Dense, Dropout, Activation
from tensorflow.keras import optimizers, models, layers, callbacks

def build_classifier_model():
    text_input = tf.keras.layers.Input(shape = (), dtype = tf.string, name = 'text')
    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name = 'preprocessing')
    encoder_inputs = preprocessing_layer(text_input)
    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')
    outputs = encoder(encoder_inputs)
    net = outputs['pooled_output']
    net = Dropout(0.1)(net)
    net = Dense(1024, activation = 'relu', name = 'hidde')(net)
    net = Dense(256, activation = 'relu', name = 'hidden')(net)
    net = Dense(256, activation = 'relu', name = 'hidden_')(net)
    net = Dense(128, activation = 'relu', name = 'hidden_l')(net)
    net = Dense(64, activation = 'relu', name = 'hidden_la')(net)
    net = Dense(64, activation = 'relu', name = 'hidden_lay')(net)
    net = Dense(16, activation = 'relu', name = 'hidden_laye')(net)
    net = Dense(3, activation='softmax', name='output')(net)
    return tf.keras.Model(text_input, net)
    
def load_callbacks(patience_num, filename):
  return [
    callbacks.EarlyStopping(
        monitor = 'val_loss',
        patience = patience_num
    ),
    callbacks.ModelCheckpoint(
        filepath = f'{filename}.h5',
        monitor = 'val_loss',
        save_best_only = True,
        verbose = 1
    )
  ]

loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False)
metrics = tf.metrics.CategoricalAccuracy()
optimizer = optimizers.RMSprop(learning_rate = 0.001)
epochs = 5
batch_size = round(train_x.shape[0]/10)
batch_size = 1500

model = build_classifier_model()

model.compile(optimizer = optimizer, loss = loss, metrics = metrics)

print(""Training:"")
history = model.fit(x = train_x, y = train_y, epochs = epochs, validation_data = (val_x, val_y), callbacks = load_callbacks(10, 'model'), verbose = 1)
print(""Testing:"")
model.evaluate(test_x, test_y)
```
```


### Relevant log output

```shell
Epoch 1/5
2022-10-30 14:08:24.668673: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 375.00MiB (rounded to 393216000)requested by op model/BERT_encoder/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/bert_encoder/StatefulPartitionedCall/transformer/layer_0/self_attention/einsum_1/Einsum
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2022-10-30 14:08:24.668778: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc
2022-10-30 14:08:24.668825: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): 	Total Chunks: 90, Chunks in use: 89. 22.5KiB allocated for chunks. 22.2KiB in use in bin. 2.7KiB client-requested in use in bin.
2022-10-30 14:08:24.668864: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): 	Total Chunks: 3, Chunks in use: 3. 1.5KiB allocated for chunks. 1.5KiB in use in bin. 1.5KiB client-requested in use in bin.
2022-10-30 14:08:24.668900: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): 	Total Chunks: 7, Chunks in use: 7. 7.2KiB allocated for chunks. 7.2KiB in use in bin. 7.0KiB client-requested in use in bin.
2022-10-30 14:08:24.668938: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): 	Total Chunks: 162, Chunks in use: 162. 326.5KiB allocated for chunks. 326.5KiB in use in bin. 324.0KiB client-requested in use in bin.
2022-10-30 14:08:24.668976: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): 	Total Chunks: 10, Chunks in use: 10. 40.8KiB allocated for chunks. 40.8KiB in use in bin. 40.0KiB client-requested in use in bin.
...
2022-10-30 14:08:24.676197: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5492170d00 of size 32768 next 421
2022-10-30 14:08:24.676243: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5492178d00 of size 256 next 422
2022-10-30 14:08:24.676291: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 7f5492178e00 of size 65565184 next 18446744073709551615
2022-10-30 14:08:24.676338: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 2097152
2022-10-30 14:08:24.676387: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00000 of size 256 next 1
2022-10-30 14:08:24.676433: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00100 of size 1280 next 2
2022-10-30 14:08:24.676481: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00600 of size 256 next 3
2022-10-30 14:08:24.676528: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00700 of size 256 next 8
2022-10-30 14:08:24.676573: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00800 of size 256 next 9
2022-10-30 14:08:24.676620: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00900 of size 256 next 10
2022-10-30 14:08:24.676665: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00a00 of size 256 next 11
2022-10-30 14:08:24.676711: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c00b00 of size 2048 next 13
2022-10-30 14:08:24.676759: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c01300 of size 2048 next 14
2022-10-30 14:08:24.676806: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c01b00 of size 2048 next 15
2022-10-30 14:08:24.676851: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c02300 of size 2048 next 18
2022-10-30 14:08:24.676898: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c02b00 of size 2048 next 20
2022-10-30 14:08:24.676944: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c03300 of size 2048 next 21
2022-10-30 14:08:24.676992: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c03b00 of size 2048 next 22
2022-10-30 14:08:24.677038: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c04300 of size 8192 next 23
2022-10-30 14:08:24.677085: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c06300 of size 2048 next 25
2022-10-30 14:08:24.677129: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c06b00 of size 2048 next 26
2022-10-30 14:08:24.677177: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c07300 of size 4096 next 27
2022-10-30 14:08:24.677222: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c08300 of size 2048 next 28
2022-10-30 14:08:24.677269: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c08b00 of size 2048 next 30
2022-10-30 14:08:24.677315: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c09300 of size 2048 next 32
2022-10-30 14:08:24.677361: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c09b00 of size 2048 next 34
2022-10-30 14:08:24.677406: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0a300 of size 2048 next 35
2022-10-30 14:08:24.677483: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0ab00 of size 2048 next 36
2022-10-30 14:08:24.677531: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0b300 of size 2048 next 37
2022-10-30 14:08:24.677577: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0bb00 of size 2048 next 38
2022-10-30 14:08:24.677621: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0c300 of size 8192 next 41
2022-10-30 14:08:24.677666: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0e300 of size 2048 next 43
2022-10-30 14:08:24.677711: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0eb00 of size 2048 next 44
2022-10-30 14:08:24.677756: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0f300 of size 2048 next 45
2022-10-30 14:08:24.677801: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c0fb00 of size 2048 next 47
2022-10-30 14:08:24.677846: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c10300 of size 2048 next 49
2022-10-30 14:08:24.677891: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c10b00 of size 2048 next 50
2022-10-30 14:08:24.677936: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c11300 of size 2048 next 52
2022-10-30 14:08:24.677981: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c11b00 of size 2048 next 54
2022-10-30 14:08:24.678026: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c12300 of size 2048 next 55
2022-10-30 14:08:24.678070: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c12b00 of size 2048 next 56
2022-10-30 14:08:24.678119: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c13300 of size 3328 next 6
2022-10-30 14:08:24.678161: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 7f5526c14000 of size 120064 next 7
2022-10-30 14:08:24.678198: I tensorflow/core
...
2022-10-30 14:08:24.698266: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1309184 totalling 1.25MiB
2022-10-30 14:08:24.698292: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1536000 totalling 1.46MiB
2022-10-30 14:08:24.698317: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1773056 totalling 1.69MiB
2022-10-30 14:08:24.698343: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1858816 totalling 1.77MiB
2022-10-30 14:08:24.698370: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2092544 totalling 2.00MiB
2022-10-30 14:08:24.698396: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 2097152 totalling 6.00MiB
2022-10-30 14:08:24.698423: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 30 Chunks of size 4194304 totalling 120.00MiB
2022-10-30 14:08:24.698449: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 4862976 totalling 4.64MiB
2022-10-30 14:08:24.698475: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 5973760 totalling 5.70MiB
2022-10-30 14:08:24.698501: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 6291456 totalling 6.00MiB
2022-10-30 14:08:24.698528: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 62509056 totalling 119.23MiB
2022-10-30 14:08:24.698556: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 67108864 totalling 64.00MiB
2022-10-30 14:08:24.698583: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 143654912 totalling 137.00MiB
2022-10-30 14:08:24.698609: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 9 Chunks of size 393216000 totalling 3.30GiB
2022-10-30 14:08:24.698635: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 786432000 totalling 2.20GiB
2022-10-30 14:08:24.698661: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 6.03GiB
2022-10-30 14:08:24.698687: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 7449870336 memory_limit_: 7449870336 available bytes: 0 curr_region_allocation_bytes_: 8589934592
2022-10-30 14:08:24.698723: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: 
Limit:                      7449870336
InUse:                      6473138688
MaxInUse:                   6473138688
NumAllocs:                     1187339
MaxAllocSize:                786432000
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2022-10-30 14:08:24.698838: W tensorflow/core/common_runtime/bfc_allocator.cc:491] *************************************_____***************************_************___***************
2022-10-30 14:08:24.698902: W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at einsum_op_impl.h:598 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[1500,128,8,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File ""/home/mark/Documents/NLP/naive/naive_2.py"", line 314, in <module>
    history = model.fit(x = train_x, y = train_y, epochs = epochs, validation_data = (val_x, val_y), batch_size = batch_size, callbacks = load_callbacks(10, 'model'), verbose = 1)
  File ""/home/mark/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/mark/miniconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

OOM when allocating tensor with shape[1500,128,8,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
	 [[{{node transformer/layer_0/self_attention/einsum_1/Einsum}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_286118]
```
```
</details>"
58369,`tf.experimental.numpy.remainder` outputs nan for 0/inf on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0, 2.12.0-dev20221029

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

`tf.experimental.numpy.remainder` outputs `nan` for `0/inf` on GPU. In contrast, it outputs the correct result `0` on CPU.

remainder(0, np.inf):

- GPU: nan
- CPU: 0.0
- numpy: 0.0



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

with tf.device('/device:CPU:0'):
    print(tf.experimental.numpy.remainder(0, np.inf)) # 0.0
with tf.device('/device:GPU:0'):
    print(tf.experimental.numpy.remainder(0, np.inf)) # nan

print(np.remainder(0, np.inf)) # 0.0
```


### Relevant log output

```shell
tf.Tensor(0.0, shape=(), dtype=float64)
tf.Tensor(nan, shape=(), dtype=float64)
0.0
```
</details>"
58368,TF 2.11.0/2.12 fails to build in MacOS 13  - XCode 14.1 - issue with ld linker,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.11.0-rc

### Custom Code

No

### OS Platform and Distribution

MacOS 13.0

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

5.3.0

### GCC/Compiler version

clang - XCode 14.1-rc2

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Compilation fails (log below) under MacOS 13.0 (XCode 14.1-rc2). Compilation works just fine under MacOS 13.x (XCode 14.0.x). Note that compilation fails also for TF 2.10.0 under MacOS 13.0, while it works for MacOS 12.x.
```


### Standalone code to reproduce the issue

```shell
Follow standard compilation from source as indicated here:

https://www.tensorflow.org/install/source
```


### Relevant log output

```shell
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/4ce3e4da2e21ae4dfcee9366415e55f408c884ec.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/d8415b02a519f222ecf71b069c96cc85ac635de3.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/protocolbuffers/upb/archive/9effcbcb27f0a665f9f345030188c0b291e32482.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/openxla/stablehlo/archive/fdd47908468488cbbb386bb7fc723dc19321cb83.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/e8f74a9763aa36559980a0c2f37f587794995622.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (544 packages loaded, 39502 targets configured).
INFO: Found 1 target...
ERROR: /Users/feranick/Desktop/tensorflow/tensorflow/python/BUILD:358:27: Linking tensorflow/python/_pywrap_py_exception_registry.so [for host] failed: (Aborted): cc_wrapper.sh failed: error executing command 
  (cd /private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/execroot/org_tensorflow && \
  exec env - \
    APPLE_SDK_PLATFORM=MacOSX \
    APPLE_SDK_VERSION_OVERRIDE=13.0 \
    PATH=/opt/usr/local/bin/:/Users/feranick/Documents/Work/c/android-sdk/platform-tools:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/MacGPG2/bin:/opt/X11/bin:/Library/Apple/usr/bin \
    XCODE_VERSION_OVERRIDE=14.1.0.14B47b \
    ZERO_AR_DATE=1 \
  external/local_config_cc/cc_wrapper.sh @bazel-out/host/bin/tensorflow/python/_pywrap_py_exception_registry.so-2.params)
# Configuration: 41f578a38c65243e257ab9820de63672c4444f072d1cfdc2d17552cb31aa4b38
# Execution platform: @local_execution_config_platform//:platform
ld: malformed trie, node past end file 'bazel-out/host/bin/_solib_darwin_x86_64/libtensorflow_Spython_S_Upywrap_Utensorflow_Uinternal.so'
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Error in child process '/usr/bin/xcrun'. 1
external/local_config_cc/cc_wrapper.sh: line 69:  8962 Abort trap: 6           ""$(/usr/bin/dirname ""$0"")""/wrapped_clang ""$@""
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /Users/feranick/Desktop/tensorflow/tensorflow/python/tools/BUILD:81:10 Middleman _middlemen/tensorflow_Spython_Stools_Sfreeze_Ugraph-runfiles failed: (Aborted): cc_wrapper.sh failed: error executing command 
  (cd /private/var/tmp/_bazel_feranick/50b852099a3bf3aaa184abce166f8e34/execroot/org_tensorflow && \
  exec env - \
    APPLE_SDK_PLATFORM=MacOSX \
    APPLE_SDK_VERSION_OVERRIDE=13.0 \
    PATH=/opt/usr/local/bin/:/Users/feranick/Documents/Work/c/android-sdk/platform-tools:/opt/local/bin:/opt/local/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/MacGPG2/bin:/opt/X11/bin:/Library/Apple/usr/bin \
    XCODE_VERSION_OVERRIDE=14.1.0.14B47b \
    ZERO_AR_DATE=1 \
  external/local_config_cc/cc_wrapper.sh @bazel-out/host/bin/tensorflow/python/_pywrap_py_exception_registry.so-2.params)
# Configuration: 41f578a38c65243e257ab9820de63672c4444f072d1cfdc2d17552cb31aa4b38
# Execution platform: @local_execution_config_platform//:platform
INFO: Elapsed time: 13754.646s, Critical Path: 743.77s
INFO: 30482 processes: 7386 internal, 23096 local.
FAILED: Build did NOT complete successfully
```
</details>"
58365,tf.keras.layers.StringLookup() does not work within tf.keras.Sequential(),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.10.0-rc3-6-g359c3cdfc5f 2.10.0

### Custom Code

No

### OS Platform and Distribution

Windows 11

### Mobile device

_No response_

### Python version

3.9.9 (tags/v3.9.9:ccb0e6a, Nov 15 2021, 18:08:50) [MSC v.1929 64 bit (AMD64)]

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to train an embedding-based model. For this, I want to use a dataset consisting of strings, turn them into integers using tf.keras.layers.StringLookup() and then use an embedding layer.

However, I get an error then. The exact same logic with tf.keras.layers.**Integer**Lookup() works, however. Also, if I use the tf.keras.layers.StringLookup() outside of tf.keras.Sequential(), it works. If I manually do something like 


tmp = string_encoding(next(iter(dataset.map(lambda x: x[""strings""]))))
print(tf.keras.layers.Embedding(string_encoding.vocabulary_size(), 4)(tmp))


it works.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

data = {""numbers"": [111, 222, 333, 444], ""strings"": [""a"", ""b"", ""c"", ""d""]}
dataset = tf.data.Dataset.from_tensor_slices(data).batch(2)

number_encoding = tf.keras.layers.IntegerLookup()
number_encoding.adapt(dataset.map(lambda x: x[""numbers""]))

string_encoding = tf.keras.layers.StringLookup()
string_encoding.adapt(dataset.map(lambda x: x[""strings""]))

string_model = tf.keras.Sequential([
  string_encoding,
  tf.keras.layers.Embedding(string_encoding.vocabulary_size(), 4)
])

number_model = tf.keras.Sequential([
  number_encoding,
  tf.keras.layers.Embedding(number_encoding.vocabulary_size(), 4)
])

print(number_model(next(iter(dataset.map(lambda x: x[""numbers""]))))) # works

print(string_model(next(iter(dataset.map(lambda x: x[""strings""]))))) #fails

tmp = string_encoding(next(iter(dataset.map(lambda x: x[""strings""])))) # same as above, but works
print(tf.keras.layers.Embedding(string_encoding.vocabulary_size(), 4)(tmp)) # works
```

Observation: it also works with a pre-defined vocabulary. 

string_model = tf.keras.Sequential([
  tf.keras.layers.StringLookup(vocabulary=[""a"", ""b"", ""c"", ""d""]),
  tf.keras.layers.Embedding(string_encoding.vocabulary_size(), 4)
])

works


### Relevant log output

```shell
UnimplementedError: Exception encountered when calling layer ""sequential_35"" ""                 f""(type Sequential).

{{function_node __wrapped__Cast_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to int64 is not supported [Op:Cast]

Call arguments received by layer ""sequential_35"" ""                 f""(type Sequential):
  • inputs=tf.Tensor(shape=(2,), dtype=string)
  • training=None
  • mask=None
```
</details>"
58364,"'ValueError: Graph already contains one or more main ops under the collection saved_model_main_op'. this error occurred When `add_meta_graph_and_variables` method is called more than once, with argument `main_op`","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 1.15

### Custom Code

No

### OS Platform and Distribution

CentOS Linux release 7.7.1908

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

10.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import shutil
import tensorflow as tf
import tensorflow.compat.v1 as tf1
tf1.logging.set_verbosity(tf1.logging.ERROR)
print(tf.__version__)

export_dir = 'res/model'
name = tf1.placeholder(tf.string, name='name')
name_vocab_initializer = tf.lookup.KeyValueTensorInitializer(tf.constant(['a', 'b', 'c']), tf.constant([1, 2, 3]),)
name_vocab_table = tf.lookup.StaticHashTable(name_vocab_initializer, 0)
name_index = name_vocab_table.lookup(name)

name_emb_table = tf1.get_variable('name_emb_table', dtype=tf.float32, shape=[5, 5])
name_emb = tf.nn.embedding_lookup(name_emb_table, name_index, name='name_emb')
# training stage
with tf1.Session() as sess:
    sess.run(tf1.global_variables_initializer())
    sess.run(tf1.tables_initializer())
    print(sess.run(name_emb, feed_dict={name : ['a', 'b', 'c']}))
    # Saving a better model is a common operation in training stage, then simulate this scenario with iteration
    for _ in range(10):
        shutil.rmtree(export_dir, ignore_errors=True)
        builder = tf1.saved_model.builder.SavedModelBuilder(export_dir)
        predict_signature = tf1.saved_model.signature_def_utils.build_signature_def(
            inputs={
                'input' : tf1.saved_model.utils.build_tensor_info(name)
            },
            outputs={
                'output' : tf1.saved_model.utils.build_tensor_info(name_emb)
            },
            method_name=tf1.saved_model.signature_constants.PREDICT_METHOD_NAME
        )
        builder.add_meta_graph_and_variables(
            sess,
            [tf.saved_model.SERVING],
            signature_def_map = {
                tf1.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: predict_signature
            },
            main_op = tf.tables_initializer()
        )
        builder.save()

# inference stage
with tf1.Session() as sess:
    tf1.saved_model.loader.load(sess, [tf.saved_model.SERVING], export_dir)
    name = sess.graph.get_tensor_by_name('name:0')
    name_emb = sess.graph.get_tensor_by_name('name_emb:0')
    res = sess.run(name_emb, feed_dict={
        name : ['a', 'b', 'c']
    })
    print(res)
```


### Relevant log output

```shell
1.15.5
[[-0.61052984 -0.07456124  0.5581994   0.04198807 -0.49397054]
 [ 0.53618276  0.18003893  0.01871365 -0.4160051  -0.43389118]
 [ 0.01618445 -0.04085767 -0.3247591  -0.6272572  -0.75671464]]
Traceback (most recent call last):
  File ""test_main_op.py"", line 43, in <module>
    main_op = tf.tables_initializer()
  File ""/data/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/data/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/builder_impl.py"", line 585, in add_meta_graph_and_variables
    self._add_collections(assets_collection, main_op, None)
  File ""/data/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/builder_impl.py"", line 443, in _add_collections
    self._maybe_add_main_op(main_op)
  File ""/data/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/builder_impl.py"", line 490, in _maybe_add_main_op
    ""collection {}."".format(init_op_key))
ValueError: Graph already contains one or more main ops under the collection saved_model_main_op.
```
</details>"
58363,How to enable GSPMD?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.7

### Custom Code

No

### OS Platform and Distribution

Linux 

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
We are trying to utilize GSPMD on a server with 8 GPUS, we find the ut-test cases as follows:
https://github.com/tensorflow/tensorflow/blob/r2.7/tensorflow/compiler/xla/experimental/xla_sharding/xla_sharding_test.py

To dump the IRs, we enable the environment variables as: TF_DUMP_GRAPH_PREFIX=/tmp/generated \
  TF_XLA_FLAGS=""--tf_xla_clustering_debug --tf_xla_auto_jit=2"" \
  XLA_FLAGS=""--xla_dump_hlo_as_text --xla_dump_to=/tmp/generated"" \
    my/tensorflow/program"".

But, only 4 IRs are saved: mark_for_compilation.pbtxt, mark_for_compilation_annotated.pbtxt, before_mark_for_compilation.pbtxt, before_increase_dynamism_for_auto_jit_pass.pbtxt. None of them is related to SPMD pass.

It seems that our current run does NOT enable GSPMD functionality at all. Is there any tutorial or instructions for us to follow to enable GSPMD on multiple GPUS?
```


### Standalone code to reproduce the issue

```shell
from tensorflow.compiler.xla.experimental.xla_sharding import xla_sharding
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.framework import test_util
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
import numpy as np
from tensorflow.python.eager import def_function


class XlaShardingTest(test_util.TensorFlowTestCase):  
  def test_dot_split(self):
    @def_function.function
    def split_helper(tensor):
      device_mesh = np.array([[0, 1, 2, 3], [4, 5, 6, 7]])
      split_tensor = xla_sharding.mesh_split(tensor, device_mesh, [0, 1])
      self.assertIsInstance(split_tensor, ops.Tensor)
      split_sharding = xla_sharding.get_tensor_sharding(split_tensor)
      split_shape = xla_sharding.get_sharding_tile_shape(split_sharding)
      expected_shape = [2, 4]
      self.assertEqual(expected_shape, split_shape)

      y_tensor = array_ops.ones([8, 8], dtype=dtypes.float32)
      y_split = xla_sharding.mesh_split(y_tensor, device_mesh, [0, 1])
      result = math_ops.matmul(split_tensor, y_split)
      device_mesh = np.array([[0, 1], [2, 3], [4, 5], [6, 7]])
      result = xla_sharding.mesh_split(result, device_mesh, [0, 1])
      result = math_ops.sqrt(result)
      result = xla_sharding.mesh_split(result, device_mesh, [1, 0])
      return result

    in_tensor = 2 * np.sqrt(2) * array_ops.ones([8, 8], dtype=dtypes.float32)
    result = split_helper(
        array_ops.ones([8, 8], dtype=dtypes.float32))
    self.assertAllEqual(in_tensor, result)


if __name__ == ""__main__"":
    xlasharding = XlaShardingTest()
    xlasharding.test_dot_split()
```


### Relevant log output

_No response_</details>"
58355,Can't run in Python 3.11.0 env.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.11.0

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Error when run in python 3.11.0 env!
```


### Standalone code to reproduce the issue

```shell
None
```


### Relevant log output

_No response_</details>"
58354,`tf.dynamic_stitch` crash with segmentation fault,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

n/a

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.dynamic_stitch` crash with segmentation fault
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
print(tf.__version__)

indices_data = np.array([[4, 3, 1, 7], [1, 5, 1, 0]])
updates_data = np.array([9, 10, 11, 12])
indices = tf.Variable(indices_data, dtype=tf.int32)
updates = tf.Variable(updates_data, dtype=tf.int32)
stitch = tf.dynamic_stitch(indices, updates)
```


### Relevant log output

```shell
2.10.0
segmentation fault
```
</details>"
58352,RaggedTensorToVariant abort,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.raw_ops.RaggedTensorToVariant` crash with abort with `batched_input=True`.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
input_splits = [[0, 2, 3, 5, 6], [0, 1, 2], [0, 1, 2, 3, 4, 5]]
input_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
output_tensor = tf.raw_ops.RaggedTensorToVariant(rt_nested_splits=input_splits, rt_dense_values=input_values, batched_input=True)
```


### Relevant log output

```shell
F tensorflow/core/framework/tensor_shape.cc:186] Non-OK-status: InitDims(dim_sizes) status: INVALID_ARGUMENT: Expected shape dimensions to be non-negative, got -1
abort (core dumped)
```
</details>"
58351,tf.raw_ops.DepthwiseConv2dNative test error based on tensorflow 2.8.2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8.2

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

Linux Ubuntu 18.04

### Python version

3.8.2

### Bazel version

5.0.0

### GCC/Compiler version

9.6.0

### CUDA/cuDNN version

11.4

### GPU model and memory

3080ti 11g

### Current Behaviour?

```shell
tensorflow op tf.raw_ops.DepthwiseConv2dNative when dilation is not 1, result is error.
It is not suit description file. (https://www.tensorflow.org/api_docs/python/tf/raw_ops/DepthwiseConv2dNative?hl=zh-cn)
```


### Standalone code to reproduce the issue

```shell
Example 1:
'''
import numpy as np
import tensorflow as tf

x = tf.random.normal(shape=[8,2,5,1], dtype=tf.float32)
kernel = tf.random.normal(shape=[1,3,1,1], dtype=tf.float32)
print(""============kernel: "", kernel)
with tf.device(""CPU""):
    c = tf.raw_ops.DepthwiseConv2dNative(input = x, filter = kernel,
                                         strides=[1, 1, 1, 1], padding='VALID',
                                         data_format='NHWC',
                                         dilations=[1, 2, 3, 1])
print(c.shape)
'''
The shape of output(c) is error, it is default value.
```


### Relevant log output

_No response_</details>"
58350,Check failed in fixed_unigram_candidate_sampler,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Check failed: range == weights_.size() (10 vs. 3)
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
true_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
num_true = 2
num_sampled = 4
unique = True
range_max = 10
distortion = 1.0
num_reserved_ids = 0
num_shards = 1
shard = 0
unigrams = [0.1, 0.8, 0.1]
seed = None
sampler = tf.random.fixed_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, distortion=distortion, num_reserved_ids=num_reserved_ids, num_shards=num_shards, shard=shard, unigrams=unigrams, seed=seed)
```


### Relevant log output

```shell
F tensorflow/core/kernels/range_sampler.cc:264] Check failed: range == weights_.size() (10 vs. 3)
abort
```
</details>"
58349,`GenerateBoundingBoxProposals` does not have cpu implementation,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

n/a

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Cannot run Op:GenerateBoundingBoxProposals on CPU
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

scores = np.random.uniform(0.1, 0.9, size=(1, 100, 1))
bbox_deltas = np.random.uniform((- 0.5), 0.5, size=(1, 100, 4))
image_info = np.random.uniform(size=(1, 3))
anchors = np.random.uniform(size=(1, 100, 4))
proposals = tf.image.generate_bounding_box_proposals(scores, bbox_deltas, image_info, anchors, nms_threshold=0.7, pre_nms_topn=6000, min_size=16, post_nms_topn=300)
```


### Relevant log output

```shell
NotFoundError: Could not find device for node: {{node GenerateBoundingBoxProposals}} = GenerateBoundingBoxProposals[post_nms_topn=300]
All kernels registered for op GenerateBoundingBoxProposals:
  device='GPU'
 [Op:GenerateBoundingBoxProposals]
```
</details>"
58348,Failed to build TF with ROCm >=5.2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

5.3.0

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

AMD MI210

### Current Behaviour?

When I build TF from source with ROCm 5.3.0, the error happens:

```
ERROR: An error occurred during the fetch of repository 'local_config_rocm':
   Traceback (most recent call last):
	File ""/global/home/jzzeng/packages/tensorflow/tensorflow-2.10/third_party/gpus/rocm_configure.bzl"", line 869, column 38, in _rocm_autoconf_impl
		_create_local_rocm_repository(repository_ctx)
	File ""/global/home/jzzeng/packages/tensorflow/tensorflow-2.10/third_party/gpus/rocm_configure.bzl"", line 547, column 35, in _create_local_rocm_repository
		rocm_config = _get_rocm_config(repository_ctx, bash_bin, find_rocm_config_script)
	File ""/global/home/jzzeng/packages/tensorflow/tensorflow-2.10/third_party/gpus/rocm_configure.bzl"", line 395, column 30, in _get_rocm_config
		config = find_rocm_config(repository_ctx, find_rocm_config_script)
	File ""/global/home/jzzeng/packages/tensorflow/tensorflow-2.10/third_party/gpus/rocm_configure.bzl"", line 373, column 41, in find_rocm_config
		exec_result = _exec_find_rocm_config(repository_ctx, script_path)
	File ""/global/home/jzzeng/packages/tensorflow/tensorflow-2.10/third_party/gpus/rocm_configure.bzl"", line 369, column 19, in _exec_find_rocm_config
		return execute(repository_ctx, [python_bin, ""-c"", decompress_and_execute_cmd])
	File ""/global/home/jzzeng/packages/tensorflow/tensorflow-2.10/third_party/remote_config/common.bzl"", line 230, column 13, in execute
		fail(
Error in fail: Repository command failed

A bug happened!ERROR: #define ""ROCRAND_VERSION"" is either
not present in file /global/software/rocm/rocm-5.3.0/rocrand/include/rocrand_version.h OR
its value is not an integer literal
```

`/global/software/rocm/rocm-5.3.0/rocrand/include/rocrand_version.h` gives:

```
/*
    Copyright (c) 2022 Advanced Micro Devices, Inc. All rights reserved.
*/

#ifndef ROCM_WRAPPER_ROCRAND_VERSION_H
#define ROCM_WRAPPER_ROCRAND_VERSION_H

#if defined(ROCM_NO_WRAPPER_HEADER_WARNING) || defined(ROCM_WRAPPER_GAVE_WARNING)
/* include file */
#include ""../../include/rocrand/rocrand_version.h""
#else
/* give warning */
#if defined(_MSC_VER)
#pragma message("": warning:This file is deprecated. Use the header file from /opt/rocm-5.3.0/include/rocrand/rocrand_version.h by using #include <rocrand/rocrand_version.h>"")
#elif defined(__GNUC__)
#pragma message("": warning : This file is deprecated. Use the header file from /opt/rocm-5.3.0/include/rocrand/rocrand_version.h by using #include <rocrand/rocrand_version.h>"")
#endif
/* include file */
#define ROCM_WRAPPER_GAVE_WARNING
#include ""../../include/rocrand/rocrand_version.h""
#undef ROCM_WRAPPER_GAVE_WARNING
#endif /* defined(ROCM_NO_WRAPPER_HEADER_WARNING) || defined(ROCM_WRAPPER_GAVE_WARNING) */

#endif /* ROCM_WRAPPER_ROCRAND_VERSION_H */
```

So in ROCm >=5.2, the version should be read from `include/rocrand/rocrand_version.h` instead of `rocrand/include/rocrand_version.h`. It looks that TensorFlow does not handle this thing.

Note that in ROCm 5.1, `rocrand/include/rocrand_version.h` does have version information.


### Standalone code to reproduce the issue

```shell
Build from source against ROCm >=5.2
```


### Relevant log output

_No response_</details>"
58347,Conv2d with bfloat16: Incompatible type conversion requested to type 'float32' for AutoCastVariable which is casted to type 'bfloat16',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.9.1

### Custom Code

Yes

### OS Platform and Distribution

CentOS 7.9.2009

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.7/8

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In eager mode, obtain error on calling the layer.
In graph mode, run correctly. (use disable_eager_execution(), suggest in https://github.com/tensorflow/tensorflow/issues/57411)

Expected behaviour: 
is there a way to use conv2d layer with bfloat16 also in the eager mode ?
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras import mixed_precision
#from tensorflow.python.framework.ops import disable_eager_execution
#disable_eager_execution()

policy = mixed_precision.Policy('mixed_bfloat16')
mixed_precision.set_global_policy(policy)

input_shape = (4, 28, 28, 3)
x = tf.random.normal(input_shape)
layer = tf.keras.layers.Conv2D(2, 3, activation='relu', input_shape=input_shape[1:])
y = layer(x)
print(y.dtype, layer.dtype)
```


### Relevant log output

```shell
2022-10-27 17:31:17.863689: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-27 17:31:18.234594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78715 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0001:00:00.0, compute capability: 8.0
Traceback (most recent call last):
  File ""test_bfloat16.py"", line 35, in <module>
    y = layer(x)
  File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.8/dist-packages/keras/mixed_precision/autocast_variable.py"", line 140, in _dense_var_to_tensor
    raise ValueError(
ValueError: Exception encountered when calling layer ""conv2d"" (type Conv2D).

Incompatible type conversion requested to type 'float32' for AutoCastVariable which is casted to type 'bfloat16'

Call arguments received by layer ""conv2d"" (type Conv2D):
  • inputs=tf.Tensor(shape=(4, 28, 28, 3), dtype=bfloat16)
```
</details>"
58344,how to force a session to run on a virtual gpu,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.5 GPU

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04.6 LTS

### Mobile device

_No response_

### Python version

Python 3.6.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

 nvidia/cuda:11.2.2-cudnn8-devel-ubuntu18.04

### GPU model and memory

Quadro P620 computeCapability: 6.1 coreClock: 1.4425GHz coreCount: 4 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 89.53GiB/s

### Current Behaviour?

```shell
Hello,

I need help for fix this.

Initially, i updated a code in version v1 to use it in v2.5.0

to do this, I need to limit the vram consumption of my process but i don't found how to run  my session on virtualgpu


For this :

physical_devices = tf.config.list_physical_devices('GPU')
        print("""")
        print(""###### physical_devices"",physical_devices)

        tf.config.experimental.set_virtual_device_configuration(physical_devices[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512),tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)])
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(physical_devices), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"", logical_gpus)
        gpus = tf.config.experimental.get_virtual_device_configuration(physical_devices[0])
        print(len(gpus),""###virtual devices"",gpus)

2022-10-27 17:16:29.592054: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-10-27 17:16:29.592069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 512 MB memory) -> physical GPU (device: 0, name: Quadro P620, pci bus id: 0000:01:00.0, compute capability: 6.1)
1 Physical GPUs, 2 Logical GPUs [LogicalDevice(name='/device:GPU:0', device_type='GPU'), LogicalDevice(name='/device:GPU:1', device_type='GPU')]
2 ###virtual devices [LogicalDeviceConfiguration(memory_limit=512, experimental_priority=None), LogicalDeviceConfiguration(memory_limit=512, experimental_priority=None)]


I manage to load my model on a virtual gpu

 gst_python           | 27.10 17:16:30.752 | MainThread | Model (/home/workingsrc/frozen_inference_graph.pb) placed on /job:localhost/replica:0/task:0/device:GPU:1


with tf.device(f""/job:localhost/replica:0/task:0/device:GPU:1""):
        graph = tf.Graph()
        with graph.as_default():
            tf.import_graph_def(graph_def, name=name)
            return graph

but when i start session

with tf.device(f""/job:localhost/replica:0/task:0/device:GPU:1""):

   self._session = tf.compat.v1.Session( graph=graph, config=tf_config)

i can see in my logs this :

2022-10-27 17:16:30.753864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2263 MB memory) -> physical GPU (device: 0, name: Quadro P620, pci bus id: 0000:01:00.0, compute capability: 6.1)

devices = self._session.list_devices()
for d in devices:
           print(d.name)


/job:localhost/replica:0/task:0/device:CPU:0
/job:localhost/replica:0/task:0/device:GPU:0


2022-10-27 17:16:30.752807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-27 17:16:30.753020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: Quadro P620 computeCapability: 6.1
coreClock: 1.4425GHz coreCount: 4 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 89.53GiB/s
2022-10-27 17:16:30.753069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-27 17:16:30.753258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-27 17:16:30.753418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2022-10-27 17:16:30.753441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-10-27 17:16:30.753446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2022-10-27 17:16:30.753449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N 
2022-10-27 17:16:30.753506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-27 17:16:30.753696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-10-27 17:16:30.753864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2263 MB memory) -> physical GPU (device: 0, name: Quadro P620, pci bus id: 0000:01:00.0, compute capability: 6.1)


My session is dispatched to the physical device,consuming too much memory

/job:localhost/replica:0/task:0/device:GPU:0 with 2263 MB memory) -> physical GPU

How to force the session on my virtual device for consume 512Mb.

/job:localhost/replica:0/task:0/device:GPU:1
```


### Standalone code to reproduce the issue

```shell
How to force the session on my virtual device
```


### Relevant log output

```shell
How to force the session on my virtual device
```
</details>"
58341,Versioning scheme of CVE patches,"(I posted this questions first to the tensorflow forums, but I think it fits here better)

I'm using TF 2.7.2 and was wondering if the recently published CVEs (e.g. CVE-2022-36001) are fixed in 2.7.2? As far as I understood, they are fixed first in 2.7.4. The github security advisory is not complety obvious to me: https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g35r-369w-3fqp
It says patched versions are: 2.7.2, 2.8.1, 2.9.1, 2.10.0. While 2.10.0 is patched and doesn't contain the vulnerability, the other versions are not patched when looking at the code on github, corresponding to the tags. Also the release notes only mention the CVE in 2.7.4, 2.8.3, 2.9.2 and 2.10.0

Other projects, like nodeBB for example, just mention the fixed release versions under ""Patched versions"" which makes a clear split between affected and unaffected versions (e.g. https://github.com/NodeBB/NodeBB/security/advisories/GHSA-p4cc-w597-6cpm).

So is there a release tagged 2.7.2 with the cherry-picked fix included or are the secure releases only: >= 2.7.4, < 2.8 | >= 2.8.3, < 2.9 | >= 2.9.2 ?

If not, what is the rationale behind listing patched and unpatched version numbers together under ""Patched versions""?

<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

2.7.2

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
---
```


### Standalone code to reproduce the issue

```shell
---
```


### Relevant log output

_No response_</details>"
58339,PyPI tensorflow-macos wheels 2.9.[012] and 2.10.0 don't work on Apple silicon + Rosetta,"I'm supposed to be able to install and run [PyPI's tensorflow-macos](https://pypi.org/project/tensorflow-macos/) on Apple silicon with Rosetta, right? At least I was able to with 2.8.0. All versions in PyPI since then don't work because they are compiled with AVX extension which [Rosetta doesn't support](https://developer.apple.com/documentation/apple-silicon/about-the-rosetta-translation-environment). See details in ""Click to expand!"" below for repro and verification steps. I tested 2.9.[012] and 2.9.10. I suspect newer packages were compiled incorrectly with AVX.

In an x86 Rosetta-translated Python virtualenv, I expect to be able to

1. `pip install tensorflow-macos==AFFECTED_VERSIONS`
2. successfully run `python -c ""import tensorflow as tf; print('TensorFlow version:', tf.__version__)""` without getting SIGKILL (Illegal instruction) error

<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.0, 2.9.1, 2.9.2, 2.10.0

### Custom Code

No

### OS Platform and Distribution

Apple silicon, M1 Macbook Pro, macOS 12.6

### Mobile device

_No response_

### Python version

3.8.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
$ python -c ""import platform;print(platform.machine()); import tensorflow as tf; print('TensorFlow version:', tf.__version__)""
x86_64
Illegal instruction: 4
```


### Standalone code to reproduce the issue

```shell
# Install Rosetta 2
softwareupdate --install-rosetta

# Install a parallel x86_64 homebrew to /usr/local/bin/brew
arch -x86_64 /bin/bash -c ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)""

# Update environment variables to use x86_64 homebrew and libraries.
eval ""$(/usr/local/bin/brew shellenv)""

# Make sure which brew returns /usr/local/bin/brew instead of /opt/homebrew/bin/brew before continuing.

# Install Python 3.8
arch -x86_64 brew install openssl readline sqlite3 xz zlib pyenv pyenv-virtualenv

# Check brew installed packages are actually x86_64.
file $(brew --prefix openssl)/bin/openssl
# You should see x86_64 in the output string. Like so
# /usr/local/opt/openssl@3/bin/openssl: Mach-O 64-bit executable x86_64

# Configure pyenv.
export PATH=""$HOME/.pyenv/bin:$PATH""
eval ""$(pyenv init --path)""
eval ""$(pyenv init -)""
eval ""$(pyenv virtualenv-init -)""

# Check pyenv is configured correctly by running a few commands. pyenv should show you a help message. pyenv versions should show you the Python versions you have installed.

# We install Python 3.8.12 here, but any 3.8 version works.
# Install pyenv-alias to customize Python version names in case you want a 3.8.12 for arm64.
git clone https://github.com/s1341/pyenv-alias.git $(pyenv root)/plugins/pyenv-alias
VERSION_ALIAS=""3.8.12-x86"" arch -x86_64 pyenv install 3.8.12

# Check that the Python version is x86_64.
pyenv shell 3.8.12-x86
python -c ""import platform;print(platform.machine())""
# You should see x86_64 instead of arm64.

# create new virtual env from that x86 Python binary
pyenv virtualenv -p python3.8 3.8.12-x86 tf-macos-2.9.1

# activate the env
pyenv activate tf-macos-2.9.1

# We install tensorflow-macos 2.9.1 here but all affected versions (2.9.0, 2.9.1, 2.9.2, 2.10.0) have the same error
pip install tensorflow-macos==2.9.1

# try to import tensorflow. This should error with ""illegal instruction""
python -c ""import tensorflow as tf; print('TensorFlow version:', tf.__version__)""
```


### Relevant log output

```shell
pyenv virtualenv -p python3.8 3.8.12-x86 tf-macos-2.9.1
created virtual environment CPython3.8.12.final.0-64 in 327ms
  creator CPython3Posix(dest=/Users/dxia/.pyenv/versions/3.8.12-x86/envs/tf-macos-2.9.1, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/Users/dxia/Library/Application Support/virtualenv)
    added seed packages: pip==22.2.2, setuptools==65.4.1, wheel==0.37.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /var/folders/sr/ryl6yttx739282tn918mf3l00000gn/T/tmptufecni3
Requirement already satisfied: setuptools in /Users/dxia/.pyenv/versions/3.8.12-x86/envs/tf-macos-2.9.1/lib/python3.8/site-packages (65.4.1)
Requirement already satisfied: pip in /Users/dxia/.pyenv/versions/3.8.12-x86/envs/tf-macos-2.9.1/lib/python3.8/site-packages (22.2.2)

/tmp via 🐍 v3.8.12 (tf-macos-2.9.1) on ☁️  dxia@spotify.com took 2s
❯ pyenv activate tf-macos-2.9.1
pyenv-virtualenv: prompt changing not working for fish.

/tmp via 🐍 v3.8.12 (tf-macos-2.9.1) on ☁️  dxia@spotify.com
❯ pip install tensorflow-macos==2.9.1
Looking in indexes: https://pypi.spotify.net/simple/
Collecting tensorflow-macos==2.9.1
  Downloading https://artifactory.spotify.net/artifactory/api/pypi/pypi/packages/packages/9c/04/21d13a3fdaf9ec28cab6844e8a2b8c1993b04350d95f0edc6c17ea6d7588/tensorflow_macos-2.9.1-cp38-cp38-macosx_11_0_x86_64.whl (237.5 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 237.5/237.5 MB 6.1 MB/s eta 0:00:00
...
Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, zipp, wrapt, urllib3, typing-extensions, termcolor, tensorflow-estimator, tensorboard-data-server, six, rsa, pyparsing, pyasn1-modules, protobuf, oauthlib, numpy, MarkupSafe, idna, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, requests, packaging, opt-einsum, keras-preprocessing, importlib-metadata, h5py, grpcio, google-pasta, google-auth, astunparse, requests-oauthlib, markdown, google-auth-oauthlib, tensorboard, tensorflow-macos
Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 flatbuffers-1.12 gast-0.4.0 google-auth-2.13.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 h5py-3.7.0 idna-3.4 importlib-metadata-5.0.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 numpy-1.23.4 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-21.3 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-estimator-2.9.0 tensorflow-macos-2.9.1 termcolor-2.0.1 typing-extensions-4.4.0 urllib3-1.26.12 werkzeug-2.2.2 wrapt-1.14.1 zipp-3.10.0

[notice] A new release of pip available: 22.2.2 -> 22.3
[notice] To update, run: python -m pip install --upgrade pip

/tmp via 🐍 v3.8.12 (tf-macos-2.9.1) on ☁️  dxia@spotify.com took 1m23s
python -c ""import platform;print(platform.machine()); import tensorflow as tf; print('TensorFlow version:', tf.__version__)""
x86_64
fish: Job 1, 'python -c ""import platform;prin…' terminated by signal SIGILL (Illegal instruction)

# presence of vmovups means wheel was compiled with AVX which Rosetta doesn't support
/tmp via 🐍 v3.8.12 (tf-macos-2.9.1) on ☁️  dxia@spotify.com took 1m23s
❯ objdump -d /Users/dxia/.pyenv/versions/tf-macos-2.9.1/lib/python3.8/site-packages/tensorflow/core/platform/_cpu_feature_guard.so | grep vmovups | head
    50ed: c5 f8 10 00                  	vmovups	(%rax), %xmm0
    50fa: c5 f8 11 00                  	vmovups	%xmm0, (%rax)
    6114: c5 f8 11 07                  	vmovups	%xmm0, (%rdi)
    66c4: c5 fc 11 00                  	vmovups	%ymm0, (%rax)
    70ab: c5 fc 11 43 48               	vmovups	%ymm0, 72(%rbx)
    71a1: c5 fc 11 43 48               	vmovups	%ymm0, 72(%rbx)
    73b6: c5 f8 10 45 a8               	vmovups	-88(%rbp), %xmm0
    73bb: c5 f8 11 04 24               	vmovups	%xmm0, (%rsp)
    7792: c5 fc 11 40 10               	vmovups	%ymm0, 16(%rax)
    7797: c5 fc 11 00                  	vmovups	%ymm0, (%rax)
error: write on a pipe with no reader

/tmp via 🐍 v3.8.12 (tf-macos-2.9.1) on ☁️  dxia@spotify.com
❯ objdump -d /Users/dxia/.pyenv/versions/tf-macos-2.9.1/lib/python3.8/site-packages/tensorflow/python/util/_tf_stack.so | grep vmovups | head
    6165: c5 f8 11 40 10               	vmovups	%xmm0, 16(%rax)
    63f7: c5 fc 11 40 20               	vmovups	%ymm0, 32(%rax)
    63fc: c5 fc 11 40 40               	vmovups	%ymm0, 64(%rax)
    6401: c5 fc 11 40 60               	vmovups	%ymm0, 96(%rax)
    6406: c5 fc 11 80 80 00 00 00      	vmovups	%ymm0, 128(%rax)
    640e: c5 fc 11 80 c0 00 00 00      	vmovups	%ymm0, 192(%rax)
    6416: c5 fc 11 80 e0 00 00 00      	vmovups	%ymm0, 224(%rax)
    641e: c5 fc 11 80 38 01 00 00      	vmovups	%ymm0, 312(%rax)
    6426: c5 fc 11 80 20 01 00 00      	vmovups	%ymm0, 288(%rax)
    642e: c5 fc 11 80 00 01 00 00      	vmovups	%ymm0, 256(%rax)
error: write on a pipe with no reader
```
</details>"
58338,Support for C++ Builder 11.2 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

TF 2.8

### Custom Code

No

### OS Platform and Distribution

Windows 11 x64

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Is there anyway to support C++ Builder 11.2 ? current static libs are in a format not supported by C++ Builder. Static libs are only in COFF format so they cant be linked with in C++ builder , they need to be in OMF format for C++ builder to link the static libs. the only way i can solve this is to do a loadlibrary in code and get proc address of each function
```


### Standalone code to reproduce the issue

```shell
No able to link static libs only in MSVC not C++ builder.
```


### Relevant log output

_No response_</details>"
58337,@faheemirfan  I changed,"import tensorflow.compat.v2 as tf
from google3.image.understanding.object_detection.input_readers import input_reader_google_pb2  # pylint: disable=unused-import
from google.protobuf import text_format
from object_detection import export_tflite_graph_lib_tf2
from object_detection.protos import pipeline_pb2

how can ı change mine ı couldn't find"
58334,`tf.linalg.sqrtm` is slow for large matrices,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

No

### OS Platform and Distribution

Linux 9ded5992957c 5.10.133+ x86_64 GNU/Linux (Google Colab)

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.linalg.sqrtm is slow compared to scipy.linalg.sqrtm for large matrices.

For matrices of 512x512, scipy takes 4.2s while tf takes 40.1s on CPU.
```


### Standalone code to reproduce the issue

```shell
import timeit

import matplotlib.pyplot as plt
import scipy.linalg
import tensorflow as tf

print(""tensorflow version = {}"".format(tf.__version__))

sizes = 2 ** tf.range(1, 10)  # Matrix size.
functions = [tf.linalg.sqrtm, scipy.linalg.sqrtm]  # TF and scipy impl.

# Measure time.
result = dict()
for size in sizes:
    X = tf.eye(size, dtype=tf.float64) + 1e-2 * tf.random.normal((size, size), dtype=tf.float64)
    X = tf.cast(X, tf.complex128)
    for func in functions:
        elapsed = timeit.timeit(lambda: func(X), number=3)
        result.setdefault(func.__module__, []).append(elapsed)

# Plot results.
for key in result:
    plt.plot(sizes, result[key])
plt.legend([key.split(""."")[0] for key in result.keys()])
plt.title(""execution time"")
plt.ylabel(""seconds"")
plt.xlabel(""matrix size"")
plt.grid(True)
plt.show()
```


### Relevant log output

```shell
tensorflow version = 2.9.2

See notebook https://gist.github.com/kyamagu/e301b61f9931da0196afe457b4f87023
```
</details>"
58333,Tensorflow training not progressing,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Device

dell xps 9365

### Python version

3.9.5

### Bazel version

none

### GCC/Compiler version

none

### CUDA/cuDNN version

not using cuda

### GPU model and memory

none

### Current Behaviour?

```shell
Cloned and Followed this in repository folder: https://github.com/nicknochnack/TFODCourse

Left laptop to train 2000 steps overnight, with 7 classes each with 5 jpgs, next morning it is still not done.

I've tried it twice, one without a virtual environment (vs code) but with labelling, and one with a virtual environment (jupyter) but with no labelling.
```


### Standalone code to reproduce the issue

```shell
(tf) C:\Users\Darren\Desktop\tenwhy\whut\TFODCourse>python Tensorflow\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\my_ssd_mobnet\pipeline.config --num_train_steps=2000
```


### Relevant log output

```shell
using cmd to run from repository root:

2022-10-27 11:27:02.827952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-10-27 11:27:02.830530: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-27 11:27:22.622281: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2022-10-27 11:27:22.626665: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-27 11:27:22.699573: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-NSO5FAG
2022-10-27 11:27:22.707687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-NSO5FAG
2022-10-27 11:27:22.783262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W1027 11:27:22.848313 27716 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I1027 11:27:23.099462 27716 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: 2000
I1027 11:27:23.201676 27716 config_util.py:552] Maybe overwriting train_steps: 2000
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I1027 11:27:23.208915 27716 config_util.py:552] Maybe overwriting use_bfloat16: False
WARNING:tensorflow:From C:\Users\Darren\tf\lib\site-packages\object_detection-0.1-py3.9.egg\object_detection\model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W1027 11:27:23.625955 27716 deprecation.py:350] From C:\Users\Darren\tf\lib\site-packages\object_detection-0.1-py3.9.egg\object_detection\model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
INFO:tensorflow:Reading unweighted datasets: ['Tensorflow\\workspace\\annotations\\train.record']
I1027 11:27:23.741462 27716 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow\\workspace\\annotations\\train.record']
INFO:tensorflow:Reading record datasets for input file: ['Tensorflow\\workspace\\annotations\\train.record']
I1027 11:27:23.755829 27716 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow\\workspace\\annotations\\train.record']
INFO:tensorflow:Number of filenames to read: 1
I1027 11:27:23.769059 27716 dataset_builder.py:80] Number of filenames to read: 1
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W1027 11:27:23.772225 27716 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From C:\Users\Darren\tf\lib\site-packages\object_detection-0.1-py3.9.egg\object_detection\builders\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
W1027 11:27:23.878830 27716 deprecation.py:350] From C:\Users\Darren\tf\lib\site-packages\object_detection-0.1-py3.9.egg\object_detection\builders\dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
WARNING:tensorflow:From C:\Users\Darren\tf\lib\site-packages\object_detection-0.1-py3.9.egg\object_detection\builders\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W1027 11:27:23.980095 27716 deprecation.py:350] From C:\Users\Darren\tf\lib\site-packages\object_detection-0.1-py3.9.egg\object_detection\builders\dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From C:\Users\Darren\tf\lib\site-packages\tensorflow\python\util\dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W1027 11:27:57.583150 27716 deprecation.py:350] From C:\Users\Darren\tf\lib\site-packages\tensorflow\python\util\dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From C:\Users\Darren\tf\lib\site-packages\tensorflow\python\util\dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
W1027 11:28:09.523100 27716 deprecation.py:350] From C:\Users\Darren\tf\lib\site-packages\tensorflow\python\util\dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.
Instructions for updating:
`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.
WARNING:tensorflow:From C:\Users\Darren\tf\lib\site-packages\tensorflow\python\util\dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W1027 11:28:16.993245 27716 deprecation.py:350] From C:\Users\Darren\tf\lib\site-packages\tensorflow\python\util\dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2022-10-27 11:28:27.142082: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.
```
</details>"
58332,Issue created for Rollback of PR #58259: Range kenrel: align CPU and GPU impl,"Merged PR #58259 is rolled back in 006fb830512b6040ab4a653999a97794d941a0c5.
    Please follow up with the reviewer and close this issue once its resolved."
58323,Failed to compile tf2.11.0-rc1 on windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.11.0-rc1

### Custom Code

No

### OS Platform and Distribution

Windows 11 22H2 x64

### Mobile device

N/A

### Python version

3.10

### Bazel version

5.3.1

### GCC/Compiler version

MSVC v17.3.6

### CUDA/cuDNN version

cuda 11.8, cudnn 8.6

### GPU model and memory

NVIDIA GTX1650 Mobile

### Current Behaviour?

Failed to compile tf2.11.0-rc1. The same machine can compile tf2.10.0 without any issue.

I suspect the issue is coming from #54276, because I can cherrypick the commit 054fb0b61946b04eee5f26cddbd7abeca06e3691 to undo and the compilation can reach further until it hit with error ``command is longer than CreateProcessW's limit (32768 characters)`` which is a sperate issue

Tensorflow 2.11 rc1 wheel on pypi also did not contain anything (only 1.9kb in size): https://pypi.org/project/tensorflow/2.11.0rc1/#files


### Standalone code to reproduce the issue

```shell
(py310) C:\Users\{redacted}\Downloads\tensorflow-2.11.0-rc1>python ./configure.py
You have bazel 5.3.1 installed.
Please specify the location of python. [Default is C:\Users\{redacted}\miniconda3\envs\py310\python.exe]:


Found possible Python library paths:
  C:\Users\{redacted}\miniconda3\envs\py310\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Users\{redacted}\miniconda3\envs\py310\lib\site-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]:
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]:
No TensorRT support will be enabled for TensorFlow.

Found CUDA 11.8 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/include
Found cuDNN 8 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 7.5,8.6


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]: /arch:AVX2


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]:
Eigen strong inline overridden.

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]:
Not configuring the WORKSPACE for Android builds.

(py310) C:\Users\{redacted}\Downloads\tensorflow-2.11.0-rc1>bazel build //tensorflow/tools/pip_package:build_pip_package --define=no_tensorflow_py_deps=true --config=opt
```


### Relevant log output

https://astro.utoronto.ca/~hleung/shared/tf211_windows_msvccompile.log
</details>"
58322,tf.keras.layers.MultiHeadAttention causes a crash in tf.keras.layers.Softmax,"While working with the Multi Head Attention Layer I encountered a problem which seems to be an issue of the interplay between **tf.keras.layers.MultiHeadAttention** and  **tf.keras.layers.Softmax**.

Please check the following code piece to reproduce the error (which can be run standalone in a notebook):

```
import tensorflow as tf

start_number = [2.0]
output_array = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)
output_array = output_array.write(0, start_number)
x = tf.transpose(output_array.stack())

print(""x:"", x)

num_heads = 1
d_model = 1
dropout_rate = 0
mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model, dropout=dropout_rate)
mha(query=x, key=x, value=x, use_causal_mask=True)
```

It will crash and the issue, in my opinion, is that in **def _build_attention(self, rank):** in **tf.keras.layers.MultiHeadAttention** creates a wrong input for **tf.keras.layers.Softmax**.

In **tf.keras.layers.MultiHeadAttention**  at **self._softmax = activation.Softmax(axis=norm_axes)**  the value for _norm_axis_ will be _""()""_.

This will then later in **tf.keras.layers.Softmax** in **def call(self, inputs, mask=None):** cause the calculation of the softmax to crash at **return backend.softmax(inputs, axis=self.axis[0])**


Mac OS Montery
Python 3.8.14
Tensorflow Version 2.10.0 (installed from binary including GPU acceleration)"
58319,Random.stateless_binomial is not available on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux

### Mobile device

debian 

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuda11/cudnn8

### GPU model and memory

Tesla V100-PCIE-16GB

### Current Behaviour?

```shell
In distributed environnement  on  2 GPU 
python    -u mainTest2.py --n_gpu=2
generates a bug generating binomial random sample (works well with normal random)
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
import time
import sys, os
import argparse
import matplotlib

parser = argparse.ArgumentParser()
parser.add_argument('--n_gpus', type=int, default=1)
args = parser.parse_args()
n_gpus = args.n_gpus


device_type = ""GPU""
devices = tf.config.experimental.list_physical_devices(
          device_type)
devices_names = [d.name.split('e:')[1] for d in devices]
print(""DEVICES "", devices_names)
print(""NGPU USED"" , n_gpus)
strategy = tf.distribute.MirroredStrategy( devices=devices_names[:n_gpus])


with strategy.scope():   
    optimizerControl= tf.keras.optimizers.Adam(learning_rate = 1e-3)
    modelControl = tf.keras.Sequential([tf.keras.layers.Dense(8, activation = tf.nn.relu),
                                        tf.keras.layers.Dense(1 )])
    # CREATE the random generator under the strategy scope : then using distribute different streams are used
    gen = tf.random.Generator.from_seed(1)

@tf.function
def cal():
    #x= gen.normal( [])
    x= gen.binomial(shape=[1], counts= 100. , probs=0.2)
    return x

x= strategy.run(cal) 
print("" x val "", x)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/gpfsgaia/home/C97830/MASTEREQUATION1D/PYTHON/mainTest2.py"", line 36, in <module>
    x= strategy.run(cal) 
  File ""/home/C97830/ANACONDA_TF271/envs/TFNEWGPU/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 1315, 
in run
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/home/C97830/ANACONDA_TF271/envs/TFNEWGPU/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2891, 
in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/home/C97830/ANACONDA_TF271/envs/TFNEWGPU/lib/python3.10/site-packages/tensorflow/python/distribute/mirrored_strategy.py"", line 676
, in _call_for_each_replica
    return mirrored_run.call_for_each_replica(
  File ""/home/C97830/ANACONDA_TF271/envs/TFNEWGPU/lib/python3.10/site-packages/tensorflow/python/distribute/mirrored_run.py"", line 83, in c
all_for_each_replica
    return wrapped(args, kwargs)
  File ""/home/C97830/ANACONDA_TF271/envs/TFNEWGPU/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in err
or_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/C97830/ANACONDA_TF271/envs/TFNEWGPU/lib/python3.10/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execu
te
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation binomial: Could not satisfy explicit dev
ice specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job
:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU
] possible_devices_=[]
StatefulRandomBinomial: CPU 
_Arg: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  binomial_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  binomial (StatefulRandomBinomial) /job:localhost/replica:0/task:0/device:GPU:0

Op: StatefulRandomBinomial
Node attrs: S=DT_INT32, T=DT_FLOAT, dtype=DT_INT32
Registered kernels:
  device='CPU'; dtype in [DT_INT64]; T in [DT_DOUBLE]
  device='CPU'; dtype in [DT_INT64]; T in [DT_FLOAT]
  device='CPU'; dtype in [DT_INT64]; T in [DT_HALF]
  device='CPU'; dtype in [DT_INT32]; T in [DT_DOUBLE]
  device='CPU'; dtype in [DT_INT32]; T in [DT_FLOAT]
  device='CPU'; dtype in [DT_INT32]; T in [DT_HALF]
  device='CPU'; dtype in [DT_DOUBLE]; T in [DT_DOUBLE]
  device='CPU'; dtype in [DT_DOUBLE]; T in [DT_FLOAT]
  device='CPU'; dtype in [DT_DOUBLE]; T in [DT_HALF]
  device='CPU'; dtype in [DT_FLOAT]; T in [DT_DOUBLE]
  device='CPU'; dtype in [DT_FLOAT]; T in [DT_FLOAT]
  device='CPU'; dtype in [DT_FLOAT]; T in [DT_HALF]
  device='CPU'; dtype in [DT_HALF]; T in [DT_DOUBLE]
  device='CPU'; dtype in [DT_HALF]; T in [DT_FLOAT]
  device='CPU'; dtype in [DT_HALF]; T in [DT_HALF]

	 [[{{node binomial}}]] [Op:__inference_cal_68]
```
</details>"
58318,CHECK fail in `tf.raw_ops.AssignAddVariableOp` when  `value` has dtype of `float64`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When passing `value` that has dtype of `float64`, it will trigger CHECK fail result in Aborted (core dumped).
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.eager import context

input1 = tf.raw_ops.VarHandleOp(dtype=tf.int32, shape=[2, 3], shared_name=context.anonymous_name())
input2 = tf.constant([],dtype=tf.float64)

tf.raw_ops.AssignAddVariableOp(resource=input1, value=input2)
```


### Relevant log output

```shell
Aborted (core dumped)

2022-10-26 05:24:02.781619: F tensorflow/core/framework/tensor.cc:719] Check failed: dtype() == expected_dtype (3 vs. 2) double expected, got int32
--Type <RET> for more, q to quit, c to continue without paging--bt 10

Thread 1 ""python"" received signal SIGABRT, Aborted.
__GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50
50	../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) bt 10
#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50
#1  0x00007f316f18a859 in __GI_abort () at abort.c:79
#2  0x00007f3156020c5c in tensorflow::internal::LogMessageFatal::~LogMessageFatal (this=0x7fff07149690, 
    __in_chrg=<optimized out>, __vtt_parm=<optimized out>) at tensorflow/core/platform/default/logging.cc:375
#3  0x00007f312aa65733 in tensorflow::Tensor::CheckType (this=0x47ddb80, expected_dtype=tensorflow::DT_DOUBLE)
    at tensorflow/core/framework/tensor.cc:719
#4  0x00007f31477b0222 in tensorflow::Tensor::shaped<double, 1ul> (this=0x47ddb80, new_sizes=...)
    at ./tensorflow/core/framework/tensor.h:890
#5  0x00007f31477af708 in tensorflow::Tensor::flat<double> (this=0x47ddb80) at ./tensorflow/core/framework/tensor.h:564
#6  0x00007f314c308717 in tensorflow::Status tensorflow::PrepareToUpdateVariable<Eigen::ThreadPoolDevice, double>(tensorflow::OpKernelContext*, tensorflow::Tensor*, bool) ()
   from /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007f314c25eb12 in tensorflow::AssignUpdateVariableOp<Eigen::ThreadPoolDevice, double, (tensorflow::DenseUpdateType)0>::Compute(tensorflow::OpKernelContext*) ()
   from /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007f312ad60c82 in tensorflow::ThreadPoolDevice::Compute (this=0x230a7b0, op_kernel=0x50a2f10, context=0x7fff07149fe0)
    at tensorflow/core/common_runtime/threadpool_device.cc:184
#9  0x00007f312ac0d09c in tensorflow::(anonymous namespace)::SingleThreadedExecutorImpl::Run (this=0x4d91eb0, args=...)
    at tensorflow/core/common_runtime/single_threaded_executor.cc:445
```
</details>"
58317,Deep learning : test a small number of images,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.6.4

### Custom Code

Yes

### OS Platform and Distribution

on Kaggle

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2020 NVIDIA Corporation Built on Wed_Jul_22_19:09:09_PDT_2020 Cuda compilation tools, release 11.0, V11.0.221 Build cuda_11.0_bu.TC445_37.28845127_0

### GPU model and memory

GPU P100

### Current Behaviour?

```shell
A bug happened!
I have an error that I can't resolve
```


### Standalone code to reproduce the issue

```shell
####  https://drive.google.com/drive/folders/1RqZK3A5Njwp2um6AIxkXScIIlLfBUx71?usp=sharing

score = model.evaluate(test_dataset)
```


### Relevant log output

```shell
2022-10-22 16:44:04.147601: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 1 of dimension 2 out of bounds.
2022-10-22 16:44:04.148080: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 2 of dimension 2 out of bounds.
2022-10-22 16:44:04.170096: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 2 of dimension 2 out of bounds.
2022-10-22 16:44:04.170280: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 1 of dimension 2 out of bounds.
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/tmp/ipykernel_211/2208282377.py in <module>
----> 1 for data in test_dataset:
      2 
      3   image_cropped = data[0].numpy()
      4   label_cropped = data[1].numpy()
      5 

/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    759   def __next__(self):
    760     try:
--> 761       return self._next_internal()
    762     except errors.OutOfRangeError:
    763       raise StopIteration

/opt/conda/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    745           self._iterator_resource,
    746           output_types=self._flat_output_types,
--> 747           output_shapes=self._flat_output_shapes)
    748 
    749       try:

/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next(iterator, output_types, output_shapes, name)
   2726       return _result
   2727     except _core._NotOkStatusException as e:
-> 2728       _ops.raise_from_not_ok_status(e, name)
   2729     except _core._FallbackException:
   2730       pass

/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6939   message = e.message + ("" name: "" + name if name is not None else """")
   6940   # pylint: disable=protected-access
-> 6941   six.raise_from(core._status_to_exception(e.code, message), None)
   6942   # pylint: enable=protected-access
   6943 

/opt/conda/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: slice index 1 of dimension 2 out of bounds.
	 [[{{node strided_slice_1}}]] [Op:IteratorGetNext]
```
</details>"
58316,Unable to build 2.10 from source for GPU due to `absl::bit_cast`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

TF 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 16.04.7 LTS

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.2.0

### GCC/Compiler version

11.2

### CUDA/cuDNN version

11.3

### GPU model and memory

GeForce GTX 1050 Ti

### Current Behaviour?

When compiling version 2.10 from source for GPU, I get the attached error after issuing my `bazel build` command. It looks that the issue is the `absl::bit_cast` command and the compiler being unable to instantiate the templated functions. The problem maybe with my build setup but I am not able to further debug what exactly is wrong. With exactly the same setup I was able to build from source version the GPU variant of version 2.9.
 
### Standalone code to reproduce the issue

```shell
From source, issue:


bazel build --config=cuda \
    --copt=-ftree-vectorize \
    --copt=-fPIC \
    --copt=-fstack-protector-strong \
    --copt=-O2 \
    --copt=-DNO_CONSTEXPR_FOR_YOU=1 \
    --cxxopt=-fvisibility-inlines-hidden \
    --cxxopt=-fmessage-length=0 \
    --host_copt=-DNO_CONSTEXPR_FOR_YOU=1 \
    --linkopt=-zrelro \
    --linkopt=-znow \
    --verbose_failures \
    --config=opt \
    --strip=always \
    --color=yes \
    --curses=no \
    --python_path=""${PYTHON}"" \
    //tensorflow/tools/pip_package:build_pip_package
```
```


### Relevant log output

```shell
external/com_google_absl/absl/base/casts.h(164): error: type name is not allowed

external/com_google_absl/absl/base/casts.h(164): error: identifier ""__builtin_bit_cast"" is undefined
          detected during instantiation of ""Dest absl::lts_20220623::bit_cast<Dest,Source,<unnamed>>(const Source &) [with Dest=uint16_t, Source=int16_t, <unnamed>=0]""

external/com_google_absl/absl/base/internal/endian.h(143): here

external/com_google_absl/absl/base/internal/endian.h(143): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/casts.h(164): error: identifier ""__builtin_bit_cast"" is undefined
          detected during instantiation of ""Dest absl::lts_20220623::bit_cast<Dest,Source,<unnamed>>(const Source &) [with Dest=uint32_t, Source=int32_t, <unnamed>=0]""
external/com_google_absl/absl/base/internal/endian.h(146): here

external/com_google_absl/absl/base/internal/endian.h(146): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/casts.h(164): error: identifier ""__builtin_bit_cast"" is undefined
          detected during instantiation of ""Dest absl::lts_20220623::bit_cast<Dest,Source,<unnamed>>(const Source &) [with Dest=uint64_t, Source=int64_t, <unnamed>=0]""
external/com_google_absl/absl/base/internal/endian.h(149): here

external/com_google_absl/absl/base/internal/endian.h(149): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(153): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(156): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(159): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(233): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(236): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(239): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(243): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(246): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/internal/endian.h(249): error: no instance of function template ""absl::lts_20220623::bit_cast"" matches the argument list
            argument types are: (<error-type>)

external/com_google_absl/absl/base/casts.h(164): error: identifier ""__builtin_bit_cast"" is undefined
          detected during:
            instantiation of ""Dest absl::lts_20220623::bit_cast<Dest,Source,<unnamed>>(const Source &) [with Dest=const void *, Source=void (*)(int64_t, int64_t, int64_t
, const int64_t *, const int64_t *, const int64_t *, int64_t *), <unnamed>=0]""
./tensorflow/core/util/gpu_kernel_helper.h(108): here
            instantiation of ""tensorflow::Status tensorflow::GpuLaunchKernel(void (*)(Ts...), dim3, dim3, size_t, gpuStream_t, Args...) [with Ts=<int64_t, int64_t, int64
_t, const int64_t *, const int64_t *, const int64_t *, int64_t *>, Args=<tensorflow::int64, tensorflow::int64, tensorflow::int64, std::conditional_t<true, int64_t *, con
st int64_t *>, std::conditional_t<true, int64_t *, const int64_t *>, std::conditional_t<false, const int64_t *, const int64_t *>, std::conditional_t<true, int64_t *, con
st int64_t *>>]""
tensorflow/core/kernels/reshape_util_gpu.cu.cc(96): here

17 errors detected in the compilation of ""tensorflow/core/kernels/reshape_util_gpu.cu.cc"".
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 3247.325s, Critical Path: 413.40s
INFO: 27322 processes: 11188 internal, 16134 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```
</details>"
58315,CHECK fail in `tf.raw_ops.ResourceGather` when `dtype` value is mismatch with dtype value of `indices`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When passing `dtype` value to `tf.raw_ops.ResourceGather` that is not match with the dtype value of `indices`, it will trigger Aborted (core dumped) cause the program termination.
```


### Standalone code to reproduce the issue

```shell
from tensorflow.python.eager import context
import tensorflow as tf


input1 = tf.raw_ops.VarHandleOp(dtype=tf.int32, shape=[2, 3], shared_name=context.anonymous_name())
indice = tf.ones(dtype=tf.int32, shape=[1, 0])

tf.raw_ops.ResourceGather(resource=input1,indices=indice,dtype=tf.bool)
```


### Relevant log output

```shell
2022-10-26 02:57:29.368524: F tensorflow/core/framework/tensor.cc:719] Check failed: dtype() == expected_dtype (3 vs. 10) bool expected, got int32
--Type <RET> for more, q to quit, c to continue without paging--bt 10

Thread 1 ""python"" received signal SIGABRT, Aborted.
__GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50
50	../sysdeps/unix/sysv/linux/raise.c: No such file or directory.
(gdb) bt 10
#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50
#1  0x00007f175fc14859 in __GI_abort () at abort.c:79
#2  0x00007f1746aaac5c in tensorflow::internal::LogMessageFatal::~LogMessageFatal (this=0x7ffe3a2ccf90, 
    __in_chrg=<optimized out>, __vtt_parm=<optimized out>) at tensorflow/core/platform/default/logging.cc:375
#3  0x00007f171b4ef733 in tensorflow::Tensor::CheckType (this=0x1465150, expected_dtype=tensorflow::DT_BOOL)
    at tensorflow/core/framework/tensor.cc:719
#4  0x00007f173823a0ae in tensorflow::Tensor::shaped<bool, 1ul> (this=0x1465150, new_sizes=...)
    at ./tensorflow/core/framework/tensor.h:890
#5  0x00007f1738239660 in tensorflow::Tensor::flat<bool> (this=0x1465150) at ./tensorflow/core/framework/tensor.h:564
#6  0x00007f173ccf9361 in tensorflow::Status tensorflow::EnsureSparseVariableAccess<Eigen::ThreadPoolDevice, bool>(tensorflow::OpKernelContext*, tensorflow::Var*) ()
   from /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007f173cccf684 in tensorflow::ResourceGatherOp<Eigen::ThreadPoolDevice, bool, long>::Compute(tensorflow::OpKernelContext*) () from /usr/local/lib/python3.8/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007f171b7eac82 in tensorflow::ThreadPoolDevice::Compute (this=0x3e4ed40, op_kernel=0x50bf030, context=0x7ffe3a2cda40)
    at tensorflow/core/common_runtime/threadpool_device.cc:184
#9  0x00007f171b69709c in tensorflow::(anonymous namespace)::SingleThreadedExecutorImpl::Run (this=0x50ce2c0, args=...)
    at tensorflow/core/common_runtime/single_threaded_executor.cc:445
```
</details>"
58310,TF built from source produces different XLA compiler results,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

xla

### Source

source

### Tensorflow Version

tf.__git_version__ = v2.10.0-rc3-6-g359c3cdfc5f

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.3.0

### GCC/Compiler version

gcc (GCC) 7.3.1

### CUDA/cuDNN version

Cuda 11.8, cudnn 8.6

### GPU model and memory

Nvidia A100, 40gb

### Current Behaviour?

```shell
I'm seeing different XLA compiler output when I use the prebuilt binaries and when I built the tensorflow from source.

I followed the steps outlines here (https://www.tensorflow.org/install/source#install_gpu_support_optional_linux_only) to built the tf from source. Specifically I ran following commands to build tf from source:


$ git clone tensorflow
$ ./configure
$ bazelisk build --config=cuda --config=opt  //tensorflow/tools/pip_package:build_pip_package --verbose_failures
$ ./bazel-bin/tensorflow/tools/pip_package/build_pip_package --nightly_flag /tmp/tensorflow_pkg
$ pip install ./tf_nightly-2.12.0-cp39-cp39-linux_x86_64.whl
```


The code pasted below runs as expected with prebuilt binaries (tested with 2.10, 2.11.rc1, tf_nightly) and produces desired output (please see output below), however the tensorflow built from source gives several errors while compiling graph using XLA. I failed to understand why I get different results when I compile from source and what can I change to get same output as prebuilt binaries.


I need to upgrade cudnn library dependency (during compile time) in order to support `conv2d` op with `bfloat16` dtype. The binaries vended through pip are compiled with cudnn 8.1 and do not support this use case.
```


### Standalone code to reproduce the issue

```shell
I used following example to reproduce the issue. (The script does not use conv2d layer, hence it works as expected with prebuilt binaries.) 



import argparse
import gzip
import numpy
import os
import struct
import urllib.request
import numpy as np
import sys
import os
import time
import tensorflow as tf
import random


print(f""tf.__file__ = {tf.__file__}, tf.__git_version__ = {tf.__git_version__}"")

tf.keras.mixed_precision.set_global_policy('bfloat16')

# to achieve reproduceable numbers on GPU, please install: `pip install tensorflow-determinism`
# https://github.com/NVIDIA/framework-determinism
os.environ['TF_DETERMINISTIC_OPS'] = '1'


def download_file(url, dir,  rank=0):
    filename = dir + ""/"" + url.split('/')[-1]
    if not os.path.exists(filename):
        if rank == 0:
            # only rank 0 downloads the file
            print(f""Downloading {url} to {filename}"")
            urllib.request.urlretrieve(url, filename)
    return filename


def extract_images(filename):
    with gzip.open(filename, 'rb') as f:
        magic = struct.unpack("">i"", f.read(4))[0]  # convert to little endian
        if magic != 2051:
            raise ValueError(f'Invalid magic number {magic} in MNIST image file: {filename}')
        num_images = struct.unpack("">i"", f.read(4))[0]  # convert to little endian
        num_rows = struct.unpack("">i"", f.read(4))[0]  # convert to little endian
        num_cols = struct.unpack("">i"", f.read(4))[0]  # convert to little endian
        buf = f.read(num_rows * num_cols * num_images)
        data = numpy.frombuffer(buf, dtype=numpy.uint8)
        data = data.reshape(num_images, num_rows, num_cols)
        return data


def extract_labels(filename):
    with gzip.open(filename, 'rb') as f:
        magic = struct.unpack("">i"", f.read(4))[0]  # convert to little endian
        if magic != 2049:
            raise ValueError(f'Invalid magic number {magic} in MNIST image file: {filename}')
        num_images = struct.unpack("">i"", f.read(4))[0]  # convert to little endian
        buf = f.read(num_images)
        data = numpy.frombuffer(buf, dtype=numpy.uint8)
        data = data.reshape(num_images)
        return data


def flatten_normalize_images(data):
    assert data.shape[1] == 28 and data.shape[2] == 28
    data = data.reshape(data.shape[0], data.shape[1] * data.shape[2])
    output = numpy.array(data, dtype=numpy.float32)
    output = (output - 128.)/128.
    return output


def read_mnist_dataset(rank=0, size=1, local_rank=0, data_dir='/tmp/tensorflow/mnist/input_data'):
    """"""
    Downloads and extracts mnist dataset and returns data in numpy format
    """"""
    # yann.lecun.com website oftens report 503 http error
    # train_image_url = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'
    # train_label_url = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'
    # test_image_url = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'
    # test_label_url = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'
    train_image_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz'
    train_label_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz'
    test_image_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz'
    test_label_url = 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz'

    if local_rank == 0:
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)

    train_image_filename = download_file(train_image_url, data_dir, local_rank)
    train_label_filename = download_file(train_label_url, data_dir, local_rank)
    test_image_filename = download_file(test_image_url, data_dir, local_rank)
    test_label_filename = download_file(test_label_url, data_dir, local_rank)

    train_images = extract_images(train_image_filename)
    train_labels = extract_labels(train_label_filename)
    test_images = extract_images(test_image_filename)
    test_labels = extract_labels(test_label_filename)

    # filter data such that, first sample is picked from row with index `rank` and next samples are offsets of `size`
    train_images = train_images[rank::size]
    train_labels = train_labels[rank::size]
    test_images = test_images[rank::size]
    test_labels = test_labels[rank::size]
    return (train_images, train_labels), (test_images, test_labels)


@tf.function(jit_compile=True)
def training_step(model, loss, tape, opt, images, labels):
    with tape:
        probs = model(images, training=True)
        print(f""labels = {labels.shape}, probs = {probs.shape}"")
        loss_value = loss(labels, probs)
    grads = tape.gradient(loss_value, model.trainable_variables)
    opt.apply_gradients(zip(grads, model.trainable_variables))
    return loss_value


# @tf.function
# def run_eval(model, test_dataset):
#     num_correct = 0
#     for (images, labels) in test_dataset:
#         logits = model(images)
#         correct = tf.equal(tf.argmax(logits, 1), labels)
#         num_correct += tf.reduce_sum(tf.cast(correct, tf.int32))
#     return num_correct


def main(_):
    print(f""Tensorflow version : {tf.__version__}"")
    # get rank and size of current process
    rank = 0
    size = 1
    local_rank = 0
    # select unique gpu
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        device_id = local_rank
        tf.config.experimental.set_visible_devices(gpus[device_id], 'GPU')
        tf.config.experimental.set_memory_growth(gpus[device_id], True)
    # set random seed for consistent initialization of weights
    tf.random.set_seed(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)

    (x_train, y_train), (x_test, y_test) = read_mnist_dataset(rank, size, local_rank, args.data_dir)

    # flatten and normalize images
    x_train = flatten_normalize_images(x_train)
    x_test = flatten_normalize_images(x_test)
    # convert labels to int64
    y_train = y_train.astype(np.int64)
    y_test = y_test.astype(np.int64)

    # training dataset
    print(f""batch size: {args.batch_size}"")
    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
    train_dataset = train_dataset.batch(args.batch_size)
    # test dataset
    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(10000)

    mnist_model = tf.keras.Sequential([
        tf.keras.Input(shape=(28*28,)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    # # set model weights using numpy to ensure repeatability
    # weights = mnist_model.get_weights()
    # weights[:] = [np.random.normal(scale=1.0 / math.sqrt(float(w.shape[0])), size=w.shape).astype('float32')
    #               for w in weights]
    # for w in weights:
    #     if len(w.shape) == 1:
    #         # zero out baises
    #         w.fill(0.)
    # mnist_model.set_weights(weights)

    loss = tf.losses.SparseCategoricalCrossentropy()
    # loss = tf.losses.CategoricalCrossentropy()
    tape = tf.GradientTape()
    opt = tf.optimizers.SGD(0.01 * size)

    step = 0
    total_time_start = time.time()
    for epoch in range(1, int(args.num_epochs)+1):
        epoch_time_start = time.time()
        # train
        for (images, labels) in train_dataset:
            loss_value = training_step(mnist_model, loss, tape, opt, images, labels)
            loss_value = tf.cast(loss_value, tf.float32)
            if step == 0:
                for weight in mnist_model.trainable_variables:
                    print(f""weight name = {weight.name}, dtype = {weight.dtype}"")
            if step % 50 == 0 and rank == 0:
                print(f""Epoch {epoch} Step #{step} \tLoss: {loss_value:.6f}"")
            step += 1
        epoch_time_end = time.time()
        # if rank == 0:
        #     correct_count = run_eval(mnist_model, test_dataset)
        #     print(f""Epoch {epoch} Eval accuracy {float(correct_count)/10000.0*100.0:.2f}% \t""
        #           f""epoch time = {epoch_time_end - epoch_time_start:.3f}s"")

    total_time_end = time.time()
    if rank == 0:
        print(f""Execution time: {(total_time_end - total_time_start):.3f}s"")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--data-dir', type=str, help='Directory for storing input data',
                        dest=""data_dir"", default='/tmp/tensorflow/mnist/input_data')
    parser.add_argument('--batch-size', type=int, help='batch size used for training',
                        dest=""batch_size"", default=128)
    parser.add_argument('--seed', type=int, help='random seed', dest=""seed"", default=17)
    parser.add_argument('--num-epochs', type=int, help='Number of epochs', dest=""num_epochs"", default=1)
    parser.set_defaults(enable_chkpt=False)
    args, unparsed = parser.parse_known_args()

    main([sys.argv[0]] + unparsed)

```
```


### Relevant log output

```shell
Output with tensorflow built from source:


$ python example.py
2022-10-25 17:58:24.444147: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
tf.__file__ = /home/ec2-user/workspace/tensorflow/tensorflow/__init__.py, tf.__git_version__ = v1.12.1-83529-g3e25aa44bcc
Tensorflow version : 2.12.0
batch size: 128
2022-10-25 17:58:29.400442: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-25 17:58:30.151968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1614] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38210 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:10:1c.0, compute capability: 8.0
labels = (128,), probs = (128, 10)
Traceback (most recent call last):
  File ""/home/ec2-user/workspace/Radiate/Radiate/examples/tf_mnist_xla.py"", line 216, in <module>
    main([sys.argv[0]] + unparsed)
  File ""/home/ec2-user/workspace/Radiate/Radiate/examples/tf_mnist_xla.py"", line 186, in main
    loss_value = training_step(mnist_model, loss, tape, opt, images, labels)
  File ""/home/ec2-user/workspace/tensorflow/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/tmp/__autograph_generated_filefhbvrr0s.py"", line 13, in tf__training_step
    loss_value = ag__.converted_call(ag__.ld(loss), (ag__.ld(labels), ag__.ld(probs)), None, fscope)
  File ""/home/ec2-user/workspace/tensorflow/keras/losses.py"", line 151, in __call__
    losses = call_fn(y_true, y_pred)
  File ""/home/ec2-user/workspace/tensorflow/keras/losses.py"", line 271, in call
    return ag_fn(y_true, y_pred, **self._fn_kwargs)
  File ""/home/ec2-user/workspace/tensorflow/keras/losses.py"", line 2085, in sparse_categorical_crossentropy
    return backend.sparse_categorical_crossentropy(
  File ""/home/ec2-user/workspace/tensorflow/keras/backend.py"", line 5633, in sparse_categorical_crossentropy
    res = tf.nn.sparse_softmax_cross_entropy_with_logits(
ValueError: in user code:

    File ""/home/ec2-user/workspace/Radiate/Radiate/examples/tf_mnist_xla.py"", line 109, in training_step  *
        loss_value = loss(labels, probs)
    File ""/home/ec2-user/workspace/tensorflow/keras/losses.py"", line 151, in __call__  **
        losses = call_fn(y_true, y_pred)
    File ""/home/ec2-user/workspace/tensorflow/keras/losses.py"", line 271, in call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""/home/ec2-user/workspace/tensorflow/keras/losses.py"", line 2085, in sparse_categorical_crossentropy
        return backend.sparse_categorical_crossentropy(
    File ""/home/ec2-user/workspace/tensorflow/keras/backend.py"", line 5633, in sparse_categorical_crossentropy
        res = tf.nn.sparse_softmax_cross_entropy_with_logits(

    ValueError: Unexpected input_shape with unknown rank for '{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape_2, sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice/stack, sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice/stack_1, sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/strided_slice/stack_2)' with input shapes: [2], [1], [1], [1] and with computed input tensors: input[3] = <1>.
```

Output with prebuilt tensorflow:

```
$ python example.py
 2022-10-25 17:57:57.978782: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
 To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 2022-10-25 17:57:58.134458: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
 2022-10-25 17:57:58.638380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/openmpi/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:
 2022-10-25 17:57:58.638468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/openmpi/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:
 2022-10-25 17:57:58.638476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
 tf.__file__ = /usr/local/lib/python3.9/site-packages/tensorflow/__init__.py, tf.__git_version__ = v2.10.0-rc3-6-g359c3cdfc5f
 Tensorflow version : 2.10.0
 batch size: 128
 2022-10-25 17:58:02.897929: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
 To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 2022-10-25 17:58:03.600789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:10:1c.0, compute capability: 8.0
 2022-10-25 17:58:04.567559: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x20510010 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
 2022-10-25 17:58:04.567586: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
 2022-10-25 17:58:04.581599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
 2022-10-25 17:58:05.091994: I tensorflow/compiler/jit/xla_compilation_cache.cc:476] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
 weight name = dense/kernel:0, dtype = <dtype: 'bfloat16'>
 weight name = dense/bias:0, dtype = <dtype: 'bfloat16'>
 weight name = dense_1/kernel:0, dtype = <dtype: 'bfloat16'>
 weight name = dense_1/bias:0, dtype = <dtype: 'bfloat16'>
 weight name = dense_2/kernel:0, dtype = <dtype: 'bfloat16'>
 weight name = dense_2/bias:0, dtype = <dtype: 'bfloat16'>
 Epoch 1 Step #0        Loss: 2.765625
 Epoch 1 Step #50       Loss: 1.531250
 Epoch 1 Step #100      Loss: 1.039062
 Epoch 1 Step #150      Loss: 0.945312
 Epoch 1 Step #200      Loss: 0.656250
 Epoch 1 Step #250      Loss: 0.652344
 Epoch 1 Step #300      Loss: 0.566406
 Epoch 1 Step #350      Loss: 0.710938
 Epoch 1 Step #400      Loss: 0.679688
 Epoch 1 Step #450      Loss: 0.582031
 Execution time: 3.818s
```
```
</details>"
58298,Tensorflow on C++ Builder 11.2,"Is there any support to use C++ builder 11.2 with tensorflow , when i try to include the lib file it complains no symbols are included.

the command i use to add the library is #pragma comment(lib,""lib\\tensorflow.lib"") , or i add to the project it gets greyed out right away , the only include i have is #include ""include\tensorflow\c\c_api.h"" & just a simple call as a test ->
 { 
    TF_Status *status = NULL;
    status = TF_NewStatus();
}

Running 11.2 Version 28.0.46141.0937 ( Latest version) , project is X64

error when doing full build is (Path before lib removed.) -> [ilink64 Error] Fatal: Archive file 'LIB\TENSORFLOW.LIB' lists no symbols in its dictionary."
58297,Fail to cross-compile tflite for android on windows and ubuntu,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

latest

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I am following this [tutorial](https://www.tensorflow.org/lite/guide/build_cmake#cross-compilation) to cross-compile tflite for android on windows, I execute following command in powershell but got error:

```shell
PS D:\AI\repos\tensorflow\tflite_build_android> cmake -DCMAKE_TOOLCHAIN_FILE=C:/Users/user/AppData/Local/Android/Sdk/ndk/21.3.6528147/build/cmake/android.toolchain.cmake  -DANDROID_PLATFORM=30 -DANDROID_ABI=armeabi-v7a -DTFLITE_ENABLE_GPU=ON ../tensorflow/lite
-- Building for: Visual Studio 16 2019
-- Setting build type to Release, for debug builds use'-DCMAKE_BUILD_TYPE=Debug'.
CMake Error at CMakeLists.txt:40 (project):
  Failed to run MSBuild command:

    C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/MSBuild/Current/Bin/MSBuild.exe

  to get the value of VCTargetsPath:

    用于 .NET Framework 的 Microsoft (R) 生成引擎版本 16.11.2+f32259642
    版权所有(C) Microsoft Corporation。保留所有权利。

    生成启动时间为 2022/10/25 18:30:20。
    节点 1 上的项目“D:\AI\repos\tensorflow\tflite_build_android\CMakeFiles\3.23.2\VCTargetsPath.vcxproj”(默认目标)。
    C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Current\Bin\Microsoft.Common.CurrentVersion.targets(820,5): error : The BaseOutputPath/OutputPath property is not set for project 'VCTargetsPath.vcxproj'.  Please check to make sure that you have specified a valid combination of Configuration and Platform for this project.  Configuration='Debug'  Platform='x64'.  You may be seeing this message because you are trying to build a project without a solution file, and have specified a non-default Configuration or Platform that doesn't exist for this project. [D:\AI\repos\tensorflow\tflite_build_android\CMakeFiles\3.23.2\VCTargetsPath.vcxproj]
    已完成生成项目“D:\AI\repos\tensorflow\tflite_build_android\CMakeFiles\3.23.2\VCTargetsPath.vcxproj”(默认目标)的操作 - 失败。

    生成失败。

    “D:\AI\repos\tensorflow\tflite_build_android\CMakeFiles\3.23.2\VCTargetsPath.vcxproj”(默认目标) (1) ->
    (_CheckForInvalidConfigurationAndPlatform 目标) ->
      C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Current\Bin\Microsoft.Common.CurrentVersion.targets(820,5): error : The BaseOutputPath/OutputPath property is not set for project 'VCTargetsPath.vcxproj'.  Please check to make sure that you have specified a valid combination of Configuration and Platform for this project.  Configuration='Debug'  Platform='x64'.  You may be seeing this message because you are trying to build a project without a solution file, and have specified a non-default Configuration or Platform that doesn't exist for this project. [D:\AI\repos\tensorflow\tflite_build_android\CMakeFiles\3.23.2\VCTargetsPath.vcxproj]

        0 个警告
        1 个错误

    已用时间 00:00:00.11


  Exit code: 1



-- Configuring incomplete, errors occurred!
See also ""D:/AI/repos/tensorflow/tflite_build_android/CMakeFiles/CMakeOutput.log"".
```

the content in CMakeOutput.log is :
```
The target system is: Android - 1 - armv7-a 
The host system is: Windows - 10.0.19044 - AMD64
```
```


### Standalone code to reproduce the issue


execute 
`D:\AI\repos\tensorflow\tflite_build_android> cmake -DCMAKE_TOOLCHAIN_FILE=C:/Users/user/AppData/Local/Android/Sdk/ndk/21.3.6528147/build/cmake/android.toolchain.cmake -DANDROID_PLATFORM=30 -DANDROID_ABI=armeabi-v7a -DTFLITE_ENABLE_GPU=ON ../tensorflow/lite
`
on Windows
"
58296,WARNING:tensorflow:Using a while_loop,"tf.__version__ = 2.9.2  

`preprocessing_model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(scale=1.0/255),
    tf.keras.layers.RandomRotation(40),
])`

preprocessing_model(  #pass a single image#  ) -- no warning

preprocessing_model( #image_batch#  ) -- WARNING


`
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting Bitcast
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2
WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3
`
Please see the full code here:
[view the code](https://colab.research.google.com/gist/Ajay-user/cf87fc63d66331ee5e338262be83ca71/warning-tensorflow-using-a-while_loop.ipynb#scrollTo=-6N95-QBLbIz)

I tried the same code in tensorflow version 2.8.3 and there was no warning 
 "
58295,Supporting Gather_OP on GPU delegate,"**System information**
- OS Platform and Distribution: Ubuntu 20.04.5 LTS
- TensorFlow installed from: source
- TensorFlow version: v2.10.0-rc2 (https://github.com/tensorflow/tensorflow/tree/v2.10.0-rc2)

Hello,

For performance reason I was looking to support `gather_op` on GPU delegate.

After some investigation I've noticed that the shader for such op seems to be already written at 
`/tensorflow/lite/delegates/gpu/common/tasks/gather.cc`

Even tests seems to be already implemented, see:
`/tensorflow/lite/delegates/gpu/common/tasks/gather_test_util.cc`

Is there a particular reason why the support for this op on GPU is not included already? Is it bugged?

I tried to include such op by modifying `model_builder.cc` by adding the operation parser such as:

```
class GatherOperationParser : public TFLiteOperationParser {
 public:
  absl::Status IsSupported(const TfLiteContext* context,
                           const TfLiteNode* tflite_node,
                           const TfLiteRegistration* registration) final {
    return CheckGpuDelegateCompatibility(context, tflite_node, registration);
  }

  absl::Status Parse(const TfLiteNode* tflite_node,
                     const TfLiteRegistration* registration,
                     GraphFloat32* graph, ObjectReader* reader) final {
    Node* node = graph->NewNode();
    node->operation.type = ToString(OperationType::GATHER);
    RETURN_IF_ERROR(reader->AddInput(node, 0));
    RETURN_IF_ERROR(reader->AddInput(node, 1));
    GatherAttributes attr;
    attr.axis = Axis::WIDTH;
    node->operation.attributes = attr;
    return reader->AddOutputs(node);
  }
};
```
after this the gpu_delegate (open_cl) run the gather operations inside my model without complaining and I can even see a sharp increasing in performance in terms of inference time. Only problem is that numerical results are wrong (while they are correct if I run gather on CPU).

Any help, advice?
"
58293,"Error of reading model by ""from keras.models import load_model""","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.10.0-rc3-6-g359c3cdfc5f 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

Python 3.10.4

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I trained a model on  1 by ```tf 2.9.1```, ```keras 2.9.0``` and ```python 3.8.12```, and copied this model to ```server 2``` and want to load this model by ```from keras.models import load_model```. On ```server 2``` the tf is of 2.10.0, keras is of 2.9.10, python is of 3.10.4. However, by running following codes:

from keras.models import load_model
model1 = load_model('./best_optimized_model_2016')

I got following errors:

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
Input In [2], in <cell line: 1>()
----> 1 model1 = load_model('./best_optimized_model_2016')

File ~/.conda/envs/vegetation/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File ~/.conda/envs/vegetation/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     52 try:
     53   ctx.ensure_initialized()
---> 54   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     55                                       inputs, attrs, num_outputs)
     56 except core._NotOkStatusException as e:
     57   if name is not None:

InvalidArgumentError: {{function_node __wrapped__RestoreV2_dtypes_83_device_/job:localhost/replica:0/task:0/device:CPU:0}} best_optimized_model_2016/variables/variables.data-00000-of-00001; Bad address [Op:RestoreV2]


The model ```./best_optimized_model_2016``` is saved by function ```model.save(path_model)```. So we have ```assets,  keras_metadata.pb,  saved_model.pb,  variables``` under the folder ```./best_optimized_model_2016```.

Could you please help me with this issue? Thanks!
```


### Standalone code to reproduce the issue

```shell
I don't know but can I upload this model to a google drive? like this:
https://drive.google.com/drive/folders/1WBX9T431YJ2nBMZzIT3fEMpV_MdaQUDl?usp=sharing.

Then, just try with:

from keras.models import load_model
model1 = load_model('./best_optimized_model_2016')

with python 3.10.4 and tf 2.10.0.
```


### Relevant log output

```shell
My error log output

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
Input In [2], in <cell line: 1>()
----> 1 model1 = load_model('./best_optimized_model_2016')

File ~/.conda/envs/vegetation/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File ~/.conda/envs/vegetation/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     52 try:
     53   ctx.ensure_initialized()
---> 54   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     55                                       inputs, attrs, num_outputs)
     56 except core._NotOkStatusException as e:
     57   if name is not None:

InvalidArgumentError: {{function_node __wrapped__RestoreV2_dtypes_83_device_/job:localhost/replica:0/task:0/device:CPU:0}} best_optimized_model_2016/variables/variables.data-00000-of-00001; Bad address [Op:RestoreV2]
```

</details>"
58292,Feature request - support tif images in image_dataset_from_directory,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Mint

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Currently, `image_dataset_from_directory` supports only  `Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')`

So, if you have tif images it won't find them ` No images found in directory `
```


### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

_No response_</details>"
58291,ImportError,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

linux ubuntu 22.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

11.2.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tensorflow can't be imported in terminal, but can be imported in pycharm.
```


### Standalone code to reproduce the issue

```shell
import tensorflow
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow10DeviceNameIN5Eigen9GpuDeviceEE5valueB5cxx11E

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 36, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""/home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 77, in <module>
    raise ImportError(
ImportError: Traceback (most recent call last):
  File ""/home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: /home/zy/anaconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow10DeviceNameIN5Eigen9GpuDeviceEE5valueB5cxx11E
```
</details>"
58290,`tf.data.experimental.CsvDataset` cause IOT instruction crash,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10, tf-nightly

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Applying shuffle+repeat+batch on `tf.data.experimental.CsvDataset` causes check failed and IOT instruction (core dumped) crashes.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# The following code is from https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset
with open('/tmp/my_file0.csv', 'w') as f:
  f.write('abcdefg,4.28E10,5.55E6,12\n')
  f.write('hijklmn,-5.3E14,,2\n')
dataset = tf.data.experimental.CsvDataset(
  ""/tmp/my_file0.csv"",
  [tf.float32,  # Required field, use dtype or empty tensor
   tf.constant([0.0], dtype=tf.float32),  # Optional field, default to 0.0
   tf.int32,  # Required field, use dtype or empty tensor
  ],
  select_cols=[1,2,3]  # Only parse last three columns
)

# The following operation is causing Check Fail
for e in range(10):
    dataset = dataset.shuffle(1000).repeat().batch(512)
```


### Relevant log output

```shell
F tensorflow/core/framework/tensor_shape.cc:404] Check failed: 0 <= new_num_elements (0 vs. -9223372036854775808)
IOT instruction (core dumped)
```
</details>"
58287,Issue created for Rollback of PR #55941: Dynamic Pywrap - Refactor pywrap_tensorflow_internal to load TF symbols from libtensorflow_cc.so,"Merged PR #55941 is rolled back in 970c3b44ea8b0db78d92ada624f03aeacf2e4518.
    Please follow up with the reviewer and close this issue once its resolved."
58286,Upgrade Cudnn dependecy to newer version,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2, 8.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Current tensorflow binaries are compiled against cudnn 8.1 and this issue is to upgrade them to the newer version (e.g. 8.4). One of the primary reason is to support more ops from cudnn which are invoked by XLA compiler. E.g. newer cudnn supports `conv2d` op with `bfloat16` dtype which is required for my usecase. The current cudnn-8.1 lacks this support and it fails with error `Invalid DNN data type: 7`. Upgrading this dependency to newer cudnn will unblock several models to be trained with bfloat16.

E.g. Check out the condition here: https://github.com/tensorflow/tensorflow/blob/359e3ea1027bcf9b8547be4e8d9b5f47f230dbbc/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc#L1080-L1086

```


### Standalone code to reproduce the issue

```shell
This can be reproduced from following example (please pass `--use-bfloat16` arg while running):


import argparse
import tensorflow as tf
import sys
import time
import numpy as np
import math
print(tf.__file__)

tf.debugging.set_log_device_placement(True)
bfloat16_t = tf.bfloat16.as_numpy_dtype


def set_model_weights(model, use_bfloat16):
    model_weights = model.get_weights()
    new_weights = []
    dtype = bfloat16_t if use_bfloat16 else 'float32'
    for weight in model_weights:
        w = np.random.normal(scale=1.0 / math.sqrt(float(weight.shape[0])), size=weight.shape).astype(dtype)
        new_weights.append(w)
    model.set_weights(new_weights)
    return model


@tf.function(jit_compile=True)
def training_step(model, loss, opt, images, labels):
    with tf.GradientTape() as tape:
        probs = model(images, training=True)
        loss_value = loss(labels, probs)
    gradients = tape.gradient(loss_value, model.trainable_variables)
    opt.apply_gradients(zip(gradients, model.trainable_variables))
    return loss_value, gradients


def run_eval(model, test_dataset):
    num_correct = 0
    for (images, labels) in test_dataset:
        num_correct += eval_step(model, images, labels)
    return num_correct


@tf.function(jit_compile=True)
def eval_step(model, images, labels):
    logits = model(images, training=False)
    correct = tf.equal(tf.argmax(logits, 1), labels)
    return tf.reduce_sum(tf.cast(correct, tf.int32))


def main(_):
    print(f""Tensorflow version : {tf.__version__}"")
    tf.random.set_seed(args.seed)
    np.random.seed(args.seed)

    float_type = tf.float32
    if args.use_bfloat16:
        # tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')
        tf.keras.mixed_precision.set_global_policy('bfloat16')
        float_type = tf.bfloat16

    # get rank and size of current process
    rank = 0
    size = 1

    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        device_id = 0
        tf.config.experimental.set_visible_devices(gpus[device_id], 'GPU')
        tf.config.experimental.set_memory_growth(gpus[device_id], True)

    (mnist_images, mnist_labels), (test_images, test_labels) = \
        tf.keras.datasets.mnist.load_data(path='mnist-%d.npz' % rank)
    dataset = tf.data.Dataset.from_tensor_slices(
        (tf.cast(mnist_images[..., tf.newaxis] / 255.0, float_type),
         tf.cast(mnist_labels, tf.int64))
    )
    dataset = dataset.shard(size, rank).shuffle(10000).batch(args.batch_size)

    test_dataset = tf.data.Dataset.from_tensor_slices(
        (tf.cast(test_images[..., tf.newaxis] / 255.0, float_type),
         tf.cast(test_labels, tf.int64))
    ).batch(args.batch_size)
    # test_dataset = dataset.shard(size, rank).shuffle(10000).batch(args.batch_size)

    mnist_model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, [3, 3], activation='relu'),
        tf.keras.layers.Conv2D(64, [3, 3], activation='relu'),
        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
        tf.keras.layers.Dropout(0.25, seed=args.seed),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.5, seed=args.seed),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    loss = tf.losses.SparseCategoricalCrossentropy()
    opt = tf.optimizers.Adam(0.001 * size, epsilon=1e-3)
    ## model converges with SGD optimizer
    # opt = tf.optimizers.SGD(0.01)

    step = 0
    total_time_start = time.time()
    for epoch in range(1, int(args.num_epochs)+1):
        epoch_time_start = time.time()
        # train
        for (images, labels) in dataset:
            with tf.device('/GPU:0'):
                loss_value, grads = training_step(mnist_model, loss, opt, images, labels)
            # if step > 0:
            #     print(f""grad norms = {[tf.norm(g).numpy() for g in grads]}"")
            loss_value = tf.cast(loss_value, tf.float32)
            if step == 0:
                for weight in mnist_model.trainable_variables:
                    print(f""weight name = {weight.name}, dtype = {weight.dtype}"")
                mnist_model = set_model_weights(mnist_model, args.use_bfloat16)
                # broadcast variables from root to rest of the processes
            if step % 10 == 0 and rank == 0:
                print(f""Epoch {epoch} Step #{step} \tLoss: {loss_value:.6f}"")
            step += 1
            # if step == 10:
            #     exit()
        epoch_time_end = time.time()
        # eval
        if rank == 0:
            correct_count = run_eval(mnist_model, test_dataset)
            print(f""Epoch {epoch} Eval accuracy {float(correct_count)/10000.0*100.0:.2f}% \t""
                  f""epoch time = {epoch_time_end - epoch_time_start:.3f}s"")
    total_time_end = time.time()
    if rank == 0:
        print(f""Execution time: {(total_time_end - total_time_start):.3f}s"")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--batch-size', type=int, help='batch size used for training',
                        dest=""batch_size"", default=64)
    parser.add_argument('--num-epochs', type=int, help='Number of epochs', dest=""num_epochs"", default=1)
    parser.add_argument('--seed', type=int, help='random seed', dest=""seed"", default=17)
    parser.add_argument('--use-bfloat16', dest='use_bfloat16', action='store_true')
    parser.set_defaults(use_bfloat16=False)
    args, unparsed = parser.parse_known_args()
    print(f""args = {args}"")
    main([sys.argv[0]] + unparsed)

```
```


### Relevant log output

```shell
Tensorflow version : 2.10.0
 2022-10-24 19:24:11.030209: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
 To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
 2022-10-24 19:24:12.130831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38224 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:10:1c.0, compute capability: 8.0
 2022-10-24 19:24:14.481738: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x1bbde6b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
 2022-10-24 19:24:14.481806: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB, Compute Capability 8.0
 2022-10-24 19:24:14.504916: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
 2022-10-24 19:24:14.549675: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. sequential/dropout/dropout/random_uniform/RandomUniform
 2022-10-24 19:24:16.159656: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400
 2022-10-24 19:24:16.298710: F tensorflow/stream_executor/cuda/cuda_dnn.cc:1013] Invalid DNN data type: 7
```
</details>"
58281,Undefined symbol `xla::HloComputation::CollectUnreachableRoots() const` with tf-nightly pip package,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf-nightly-cpu==2.12.0.dev20221019 and newer

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Starting from version `2.12.0.dev20221019` Horovod cannot be built correctly with `tf-nightly`. `tf-nightly-cpu==2.12.0.dev20221018` and earlier are fine.

Upon import of `horovod.tensorflow` an undefined symbol error is encountered: 

```
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/horovod/tensorflow/mpi_lib.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK3xla14HloComputation23CollectUnreachableRootsEv
```

In demangled form that is `xla::HloComputation::CollectUnreachableRoots() const`. 

Has the implementation been moved to a different dynamic library recently? Horovod currently links to `libtensorflow_framework.so.2` and to `_pywrap_tensorflow_internal.so`.


### Standalone code to reproduce the issue

```shell
$ pip install tf-nightly-cpu
Collecting tf-nightly-cpu
  Downloading tf_nightly_cpu-2.12.0.dev20221024-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.0/225.0 MB 1.2 MB/s eta 0:00:00
# ...
$ pip install -v horovod
# ...
  Tensorflow_LIBRARIES := -L.../horovod-tf-nightly-venv/lib/python3.9/site-packages/tensorflow -l:libtensorflow_framework.so.2 .../horovod-tf-nightly-venv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
  -- Found Tensorflow: -L.../horovod-tf-nightly-venv/lib/python3.9/site-packages/tensorflow -l:libtensorflow_framework.so.2 .../horovod-tf-nightly-venv/lib/python3.9/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so (found suitable version ""2.12.0-dev20221024"", minimum required is ""1.15.0"")
# ...
$ python -c 'import horovod.tensorflow'
```

Error message quoted below under ""relevant log output"".


### Relevant log output

```shell
2022-10-24 16:12:49.274846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/__init__.py"", line 27, in <module>
    from horovod.tensorflow import elastic
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/elastic.py"", line 24, in <module>
    from horovod.tensorflow.functions import broadcast_object, broadcast_object_fn, broadcast_variables
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/functions.py"", line 24, in <module>
    from horovod.tensorflow.mpi_ops import allgather, broadcast, broadcast_
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/mpi_ops.py"", line 53, in <module>
    raise e
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/mpi_ops.py"", line 50, in <module>
    MPI_LIB = _load_library('mpi_lib' + get_ext_suffix())
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/mpi_ops.py"", line 45, in _load_library
    library = load_library.load_op_library(filename)
  File "".../horovod-tf-nightly-venv/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py"", line 54, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: .../horovod-tf-nightly-venv/lib/python3.9/site-packages/horovod/tensorflow/mpi_lib.cpython-39-x86_64-linux-gnu.so: undefined symbol: _ZNK3xla14HloComputation23CollectUnreachableRootsEv
```
</details>"
58280,Failed to allocate memory for input tensors - iOS,"Installed TensorflowLite on an example Xcode project I am using for tests with these version:
```
  - TensorFlowLiteC (2.10.0):
    - TensorFlowLiteC/Core (= 2.10.0)
  - TensorFlowLiteC/Core (2.10.0)
  - TensorFlowLiteSwift (2.10.0):
    - TensorFlowLiteSwift/Core (= 2.10.0)
  - TensorFlowLiteSwift/Core (2.10.0):
    - TensorFlowLiteC (= 2.10.0)
```

When I try to allocate the interpreter:
```
        do {
            try interpreter.allocateTensors()
        } catch {
            print(""Error: \(error.localizedDescription)"")
        }
```

I get this error:
`Error: Failed to allocate memory for input tensors.
`

The model I am trying to use is the one attached here.

[hifill_inpaint.tflite.zip](https://github.com/tensorflow/tensorflow/files/9852391/hifill_inpaint.tflite.zip)



"
58277,Tensorflow:AutoGraph could not transform function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Windows 10 Enterprise

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A function to find the value in one tensor closest to another tensor returns a warning. It also returns the output as expected.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

# Sampling function - randomly sample space pairs 
def space_sampler(nSim):
    S = tf.random.uniform(shape=[nSim,1], minval=0, maxval=2.0)
    V = tf.random.uniform(shape=[nSim,1], minval=-1.0, maxval=1.0)
    return S, V
   
# Find interior value closest to boundary value
@tf.function(experimental_relax_shapes=True)
def BoundaryPenalty(S_int, V_int, S_bound, V_bound):
    interior = tf.concat([S_int, V_int],1)
    bound = tf.concat([S_bound, V_bound],1)
    y_n = tf.ones([1,tf.shape(bound)[1]])

    for i in range(bound.shape[0]):
        tf.autograph.experimental.set_loop_options(shape_invariants=[(y_n, tf.TensorShape([None]))])
        tf.autograph.experimental.set_loop_options(shape_invariants=[(interior, tf.TensorShape([None]))])
        index = tf.argmin(tf.reduce_sum(tf.math.squared_difference(interior, bound[i]),1))
        y_n = tf.concat([y_n,interior[index,None]],0)
        interior = tf.concat([interior[:index], interior[index+1:]],0)
    
    y_n = y_n[1:]
    return y_n
    
# Call the functions
S_interior, V_interior = space_sampler(12)
S_boundary, V_boundary = space_sampler(6)
BoundaryPenalty(S_interior, V_interior, S_boundary, V_boundary)
```


### Relevant log output

```shell
WARNING:tensorflow:AutoGraph could not transform <function BoundaryPenalty at 0x0000022BDB6BA280> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: ""set_loop_options"" must be the first statement in the loop block
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function BoundaryPenalty at 0x0000022BDB6BA280> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: ""set_loop_options"" must be the first statement in the loop block
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```
</details>"
58275,TinyML (O'Reilly) error running test_hello_world_test,"Hi,

I cloned (successfully) the git repository (https://github.com/tensorflow/tensorflow.git) from ""TinyML"" (O'Reilly). But when I run the command:

make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test

I get the following answer:

make: tensorflow/lite/micro/tools/make/Makefile: No such file or directory
make: *** No rule to make target `tensorflow/lite/micro/tools/make/Makefile'.  Stop.

And if I look into the directory ""../micro/"" I find only a README.md file.

What do I have to do?

Thank you very much for your answer.

André Koller
"
58274,A check fail can be triggered in ParameterizedTruncatedNormal,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When execute on GPU, a crash due to check fail can be triggered in ParameterizedTruncatedNormal.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        seed = 0
        seed2 = 0
        shape_0 = 16
        shape_1 = 9
        shape_2 = 117
        shape_3 = 100
        shape_4 = 71
        shape_5 = 18
        shape = [shape_0, shape_1, shape_2, shape_3, shape_4, shape_5, ]
        means = tf.saturate_cast(tf.random.uniform([], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        stdevs = tf.saturate_cast(tf.random.uniform([], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        minvals = tf.saturate_cast(tf.random.uniform([1], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        maxvals = tf.saturate_cast(tf.random.uniform([], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        res = tf.raw_ops.ParameterizedTruncatedNormal(
            seed=seed,
            seed2=seed2,
            shape=shape,
            means=means,
            stdevs=stdevs,
            minvals=minvals,
            maxvals=maxvals,
        )
    except:
        pass
```


### Relevant log output

```shell
F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 (0 vs. -2141792896)
Aborted (core dumped)
```
</details>"
58273,A check fail can be triggered in MaxPoolV2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When execute on GPU, a crash due to check fail can be triggered in MaxPoolV2. It seems that the given data_format is not supported. Instead of throwing a check fail which causes a crash, I think an exception like `InvalidArgumentError` which can be catched by `try...catch...` would be better.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        padding = ""SAME""
        data_format = ""NCHW_VECT_C""
        input = tf.random.uniform([1, 1, 16, 2, 1], dtype=tf.float32)
        ksize = [1, 1, 1, 1]
        strides = [1, 1, 1, 1]
        res = tf.raw_ops.MaxPoolV2(
            padding=padding,
            data_format=data_format,
            input=input,
            ksize=ksize,
            strides=strides,
        )
    except:
        pass
```


### Relevant log output

```shell
F tensorflow/core/kernels/maxpooling_op.cc:1411] Check failed: data_format_ == FORMAT_NHWC MaxPool only supports NCHW or NHWC format
Aborted (core dumped)
```
</details>"
58272,A check fail can be triggered in MaxPoolGradWithArgmax,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A crash due to check fail can be triggered in MaxPoolGradWithArgmax.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        ksize_0 = 1
        ksize_1 = 2
        ksize_2 = 4
        ksize_3 = 1
        ksize = [ksize_0, ksize_1, ksize_2, ksize_3, ]
        strides_0 = 1
        strides_1 = 2
        strides_2 = 1
        strides_3 = 16
        strides = [strides_0, strides_1, strides_2, strides_3, ]
        padding = ""SAME""
        include_batch_in_index = False
        input = tf.saturate_cast(tf.random.uniform([16, 16, 1, 1], minval=0, maxval=64, dtype=tf.int64), dtype=tf.uint64)
        grad = tf.saturate_cast(tf.random.uniform([16, 8, 1, 1], minval=0, maxval=64, dtype=tf.int64), dtype=tf.uint64)
        argmax = tf.saturate_cast(tf.random.uniform([16, 8, 1, 1], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
        res = tf.raw_ops.MaxPoolGradWithArgmax(
            ksize=ksize,
            strides=strides,
            padding=padding,
            include_batch_in_index=include_batch_in_index,
            input=input,
            grad=grad,
            argmax=argmax,
        )
    except:
        pass
```


### Relevant log output

```shell
F tensorflow/core/kernels/maxpooling_op.cc:1065] Check failed: grad_out_index >= output_start && grad_out_index < output_end Invalid output gradient index: 263, 0, 256
Aborted (core dumped)
```
</details>"
58271,A check fail can be triggered in MapPeek,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A crash due to check fail can be triggered in MapPeek.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        capacity = 0
        memory_limit = 0
        dtypes_0 = tf.uint64
        dtypes_1 = tf.float32
        dtypes = [dtypes_0, dtypes_1, ]
        container = """"
        shared_name = """"
        key = tf.saturate_cast(tf.random.uniform([6, 14, 4], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
        indices = tf.saturate_cast(tf.random.uniform([2], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int32)
        res = tf.raw_ops.MapPeek(
            capacity=capacity,
            memory_limit=memory_limit,
            dtypes=dtypes,
            container=container,
            shared_name=shared_name,
            key=key,
            indices=indices,
        )
    except:
        pass
```


### Relevant log output

```shell
F tensorflow/core/framework/tensor.cc:733] Check failed: 1 == NumElements() (1 vs. 336)Must have a one element tensor
Aborted (core dumped)
```
</details>"
58270,A check fail can be triggered in LSTMBlockCell,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A crash due to check fail can be trigerred.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        forget_bias = 112.66590343649887
        cell_clip = 67.12389445926587
        use_peephole = False
        x = tf.saturate_cast(tf.random.uniform([2, 16], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        cs_prev = tf.saturate_cast(tf.random.uniform([2, 0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        h_prev = tf.saturate_cast(tf.random.uniform([2, 0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        w = tf.saturate_cast(tf.random.uniform([16, 0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        wci = tf.saturate_cast(tf.random.uniform([5], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        wcf = tf.saturate_cast(tf.random.uniform([16], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        wco = tf.saturate_cast(tf.random.uniform([13], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        b = tf.saturate_cast(tf.random.uniform([0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        res = tf.raw_ops.LSTMBlockCell(
            forget_bias=forget_bias,
            cell_clip=cell_clip,
            use_peephole=use_peephole,
            x=x,
            cs_prev=cs_prev,
            h_prev=h_prev,
            w=w,
            wci=wci,
            wcf=wcf,
            wco=wco,
            b=b,
        )
    except:
        pass
```


### Relevant log output

```shell
F tensorflow/core/kernels/rnn/lstm_ops_gpu.cu.cc:277] Non-OK-status: GpuLaunchKernel( lstm_gates<T, false, gate_layout>, grid_dim_2d, block_dim_2d, 0, cu_stream, gates.data(), b.data(), cs_prev.data(), wci.data(), wcf.data(), wco.data(), o.data(), h.data(), ci.data(), cs.data(), co.data(), i.data(), f.data(), forget_bias, cell_clip, batch_size, cell_size) status: INTERNAL: invalid configuration argument
Aborted (core dumped)
```
</details>"
58267,tflite_runtime.interpreter.Interpreter causes segfault when using delegate,"I am trying to run [label_image.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/python/label_image.py) using tflite-runtime. It works fine without any delegate. However, when I use a delegate, `tflite_runtime.interpreter.Interpreter()` causes a segfault (`tflite_runtime.interpreter.load_delegate()` doesn't cause any problem). I have tried it for the tflite gpu delegate and armnn delegate (for all combinations of backends) with multiple models from the [tflite examples](https://www.tensorflow.org/lite/examples) and it fails for all of them.
The output......

```
(env) odroid@odroid:~/Desktop/project/tflite_sample$ python3 label_image.py   --model_file lite-model_movenet_multipose_lightning_tflite_float16_1.tflite   --label_file labels.txt   --image grace_hopper.bmp -e ../aarch32_build/delegate/libarmnnDelegate.so -o ""backends:GpuAcc,CpuAcc,CpuRef;logging-severity:info"" 
Loading external delegate from ../aarch32_build/delegate/libarmnnDelegate.so with args: {'backends': 'GpuAcc,CpuAcc,CpuRef', 'logging-severity': 'info'}
Info: ArmNN v30.0.0
Info: Initialization time: 11.71 ms.
INFO: TfLiteArmnnDelegate: Created TfLite ArmNN delegate.
Segmentation fault
```
```
(env) odroid@odroid:~/Desktop/project/tflite_sample$ python3 label_image.py   --model_file lite-model_movenet_multipose_lightning_tflite_float16_1.tflite   --label_file labels.txt   --image grace_hopper.bmp -e ../libtensorflowlite_gpu_delegate.so 
Loading external delegate from ../libtensorflowlite_gpu_delegate.so with args: {}
INFO: Created TensorFlow Lite delegate for GPU.
Segmentation fault
```





I am using an Odroid XU4 board (armv7l) that has a Mali T628 GPU and 2GB RAM running Ubuntu Mate 22.04. I am running the latest version of tflite-runtime, however it fails for all the previous versions as well. Python version is 3.7.14 ."
58264,"pip install tflite-runtime fails on Fedora 36, possibly due to Python 3.10","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Linux Fedora 36

### Mobile device

_No response_

### Python version

3.10.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
$ cat /etc/os-release | head -2
NAME=""Fedora Linux""
VERSION=""36 (Workstation Edition)""

$ python --version
Python 3.10.7

$ python3 -m pip install tflite-runtime

ERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)
ERROR: No matching distribution found for tflite-runtime
```

NB that `python --version` on this Fedora Fedora 36 (Workstation) says `Python 3.10.7`...

... and a friend of mine pointed out that this could well be because on https://pypi.org/project/tflite-runtime/ we can see Python 3.7, 3.8, 3.9 - but not 3.10, yet. (Whereas e.g. https://pypi.org/project/numpy/ already has 3.10 and 3.11, and I CAN install that.)

Perhaps you would like to consider relaxing those version constraints, if that's possible? Or publish tflite for more recent Python versions already as well? Please let me know if this is easy enough to contribute a PR for an test - I'm happy to help! (Full disclosure: I'm a Googler  at work, playing with this on the weekend at home on a personal computer.)

In the mean time, I'll try to work around this with https://www.tensorflow.org/lite/guide/build_cmake_pip, or perhaps just use full Tensorflow instead of Lite and learn ;-) how to adapt project-keyword-spotter...

Background: I'm a new and noob user and wanted to figure out how to run e.g. https://github.com/google-coral/project-keyword-spotter/ on my workstation instead of on my Coral Dev board. https://www.tensorflow.org/lite/guide/python says that I should do `python3 -m pip install tflite-runtime` but this fails on Fedora 36 (Workstation), as described above.
```


### Standalone code to reproduce the issue

```shell
You would have to try on Fedora.

I could build a simple reproduce using a container, if that would of any use for CI of this project?
```


### Relevant log output

_No response_</details>"
58263,No graph trace in tensorboard when using @tf.function(jit_compile=True),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'm trying to trace a model inference. When I turn off jit_compile option, it works fine. However, when I turn it on, no inference graph appears on tensorboard. I wonder what might happen there. Thanks.
```


### Standalone code to reproduce the issue

```shell
logdir = ""./xla_dir""

input = np.random.rand(10,3,224,224).astype(""float32"")

@tf.function(jit_compile=True)
def inf(input):
    # tf_model is a resnet18 model imported from an onnx
    output = tf_model(input_1=input)
    return output

writer = tf.summary.create_file_writer(logdir)
tf.summary.trace_on(graph=True)

inf(input)
with writer.as_default():
    tf.summary.trace_export(
      name=""my_func_trace"",
      step=0,
      profiler_outdir=logdir)
```


### Relevant log output

_No response_</details>"
58262,A Check Fail can be triggered in GatherNd,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A check-fail can be triggered.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        params = tf.saturate_cast(tf.random.uniform([1, 16, 6, 15, 16, 16], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
        indices = tf.saturate_cast(tf.random.uniform([15, 5, 16, 15, 1, 1], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
        res = tf.raw_ops.GatherNd(
            params=params,
            indices=indices,
        )
    except:
        pass
```


### Relevant log output

```shell
F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 (0 vs. -1954414592)
Aborted (core dumped)
```
</details>"
58261,A Check Fail can be triggerred in GRUBlockCell,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A check fail can be triggerred in GRUBlockCell, which can lead to a crash.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
            x = tf.random.uniform([1, 0, 1], dtype=tf.float32)
            h_prev = tf.random.uniform([1, 1, 1], dtype=tf.float32)
            w_ru = tf.random.uniform([1, 2, 1, 1, 1, 1], dtype=tf.float32)
            w_c = tf.random.uniform([1, 1, 1], dtype=tf.float32)
            b_ru = tf.random.uniform([2], dtype=tf.float32)
            b_c = tf.random.uniform([1], dtype=tf.float32)
            res = tf.raw_ops.GRUBlockCell(
                x=x,
                h_prev=h_prev,
                w_ru=w_ru,
                w_c=w_c,
                b_ru=b_ru,
                b_c=b_c,
            )
    except:
        pass
```


### Relevant log output

```shell
F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (2 vs. 3)Asking for tensor of 2 dimensions from a tensor of 3 dimensions
Aborted (core dumped)
```
</details>"
58258,"Failing to fit an lstm model.fit(x=g,) with generator `g`, custom loss function and `run_eagerly` is False","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.10.0-rc3-6-g359c3cdfc5f 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux xxxxxx 5.10.0-19-amd64   SMP Debian 5.10.149-1 (2022-10-17) x86_64 GNU/Linux

### Mobile device

_No response_

### Python version

python  3.9.13   h9a8a25e_0_cpython    conda-forge

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cudatoolkit  11.2.2  hbe64b41_10  conda-forge,  cudnn  8.1.0.77  h90431f1_0  conda-forge

### GPU model and memory

Quadro RTX 4000, 8GB

### Current Behaviour?

I was trying to rerun some earlier work, that used to work on TF 2.6.0 I think (not sure). 

In a nutshell, extracted for a repro gist thereafter: 

```python
def create_and_fit(x, run_eagerly):
    model = new_model()
    model.compile(optimizer=Adam(learning_rate=1e-4), loss=mean_absolute_error_na, metrics=[some_metric], run_eagerly=run_eagerly)
    return model.fit(
        x,
        steps_per_epoch=steps_per_epoch,
        epochs=epochs,
        validation_data=None
    )
```

if x is a `<generator object train_generator_batch>` and `run_eagerly` is `False`, it seems that invalid ground truth observations `y_true` is passed to the custom loss function, which reports:

```text
Epoch 1/5
y_true = Tensor(""mean_absolute_error_na/remove_squeezable_dimensions/Squeeze:0"", shape=(None, None), dtype=float32)
y_pred = Tensor(""model_1/dense_1/BiasAdd:0"", shape=(16, 1), dtype=float32)
etc etc stack trace...
    ValueError: y_true and y_pred do not have compatible shapes: (None, None) and (16, 1). Respective types are <class 'tensorflow.python.framework.ops.Tensor'> and <class 'tensorflow.python.framework.ops.Tensor'>
```

Model fitting works however if `run_eagerly` is True, or if x is passed a dataset created with `tf.data.Dataset.from_generator`.

Note that I run the jupyter python kernel launched via `optirun` to access the GPU, in case this has relevance. The bug anyway occurs also if forcing the execution on the CPU.

### Standalone code to reproduce the issue

A self-contained notebook (python file obtained with jupytext) is available at [this gist](https://gist.github.com/jmp75/d55e5f73e337012ba610c72d20a4398f)


### Relevant log output

```shell
Epoch 1/5
y_true = Tensor(""mean_absolute_error_na/remove_squeezable_dimensions/Squeeze:0"", shape=(None, None), dtype=float32)
y_pred = Tensor(""model_1/dense_1/BiasAdd:0"", shape=(16, 1), dtype=float32)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
Cell In [40], line 1
----> 1 create_and_fit(train_gen, run_eagerly = False)

Cell In [37], line 4, in create_and_fit(x, run_eagerly)
      2 model = new_model()
      3 model.compile(optimizer=Adam(learning_rate=1e-4), loss=mean_absolute_error_na, metrics=[some_metric], run_eagerly=run_eagerly)
----> 4 return model.fit(
      5     x,
      6     steps_per_epoch=steps_per_epoch,
      7     epochs=epochs,
      8     validation_data=None
      9 )

File ~/miniconda/envs/my_env_name/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     67     filtered_tb = _process_traceback_frames(e.__traceback__)
     68     # To get the full stack trace, call:
     69     # `tf.debugging.disable_traceback_filtering()`
---> 70     raise e.with_traceback(filtered_tb) from None
     71 finally:
     72     del filtered_tb

File /tmp/__autograph_generated_file7kl24yk4.py:15, in outer_factory.<locals>.inner_factory.<locals>.tf__train_function(iterator)
     13 try:
     14     do_return = True
---> 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
     16 except:
     17     do_return = False

File /tmp/__autograph_generated_filexp4m9ubh.py:11, in outer_factory.<locals>.inner_factory.<locals>.tf__mean_absolute_error_na(y_true, y_pred)
      9 do_return = False
     10 retval_ = ag__.UndefinedReturnValue()
---> 11 (y_true_m, y_pred_m) = ag__.converted_call(ag__.ld(remove_items_missing_observations), (ag__.ld(y_true), ag__.ld(y_pred)), None, fscope)
     12 try:
     13     do_return = True

File /tmp/__autograph_generated_filei0twifpa.py:24, in outer_factory.<locals>.inner_factory.<locals>.tf__remove_items_missing_observations(y_true, y_pred)
     22 def else_body():
     23     pass
---> 24 ag__.if_stmt(ag__.ld(y_true).shape != ag__.ld(y_pred).shape, if_body, else_body, get_state, set_state, (), 0)
     25 try:
     26     do_return = True

File /tmp/__autograph_generated_filei0twifpa.py:20, in outer_factory.<locals>.inner_factory.<locals>.tf__remove_items_missing_observations.<locals>.if_body()
     18 ag__.ld(print)(f'y_true = {ag__.ld(y_true)}')
     19 ag__.ld(print)(f'y_pred = {ag__.ld(y_pred)}')
---> 20 raise ag__.converted_call(ag__.ld(ValueError), (f'y_true and y_pred do not have compatible shapes: {ag__.ld(y_true).shape} and {ag__.ld(y_pred).shape}. Respective types are {ag__.converted_call(ag__.ld(type), (ag__.ld(y_true),), None, fscope)} and {ag__.converted_call(ag__.ld(type), (ag__.ld(y_pred),), None, fscope)}',), None, fscope)

ValueError: in user code:

    File ""/home/xxxyyy/miniconda/envs/my_env_name/lib/python3.9/site-packages/keras/engine/training.py"", line 1160, in train_function  *
        return step_function(self, iterator)
    File ""/tmp/ipykernel_36702/144245855.py"", line 13, in mean_absolute_error_na  *
        y_true_m, y_pred_m = remove_items_missing_observations(y_true, y_pred)
    File ""/tmp/ipykernel_36702/144245855.py"", line 8, in remove_items_missing_observations  *
        raise ValueError(f""y_true and y_pred do not have compatible shapes: {y_true.shape} and {y_pred.shape}. Respective types are {type(y_true)} and {type(y_pred)}"")

    ValueError: y_true and y_pred do not have compatible shapes: (None, None) and (16, 1). Respective types are <class 'tensorflow.python.framework.ops.Tensor'> and <class 'tensorflow.python.framework.ops.Tensor'>
```
</details>"
58257,PLEASE TELL ME WHY THIS IS ERROR,"        PLEASE TELL ME WHY THIS IS ERROR

# Сконфигурируем другую модель, зададим слои
from tensorflow.keras.layers import Dense
model1 = tf.keras.Sequential([x_train_n, layers.Dense(128, activation='relu'), 
                                                 layers.Dense(128, activation='relu'),
                                                 layers.Dense(128, activation='relu'),
                                                 layers.Dense(64, activation='relu'),
                                                 layers.Dense(64, activation='relu'),
                                                 layers.Dense(32, activation='relu'),
                                                 layers.Dense(16, activation='relu'),
                                                 layers.Dense(1)
                           ])
model1.compile(optimizer = tf.keras.optimizers.Adam(0.001), loss = 'mean_squared_error',
               metrics = [tf.keras.metrics.RootMeanSquaredError()]) 
# Посмотрим на архитектуру модели
model1.summary()

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
Input In [108], in <cell line: 4>()
      2 from tensorflow.keras.layers import Dense
      3 from tensorflow.keras.layers import Dense
----> 4 model1 = tf.keras.Sequential([x_train_n, layers.Dense(128, activation='relu'), 
      5                                                  layers.Dense(128, activation='relu'),
      6                                                  layers.Dense(128, activation='relu'),
      7                                                  layers.Dense(64, activation='relu'),
      8                                                  layers.Dense(64, activation='relu'),
      9                                                  layers.Dense(32, activation='relu'),
     10                                                  layers.Dense(16, activation='relu'),
     11                                                  layers.Dense(1)
     12                            ])
     13 model1.compile(optimizer = tf.keras.optimizers.Adam(0.001), loss = 'mean_squared_error',
     14                metrics = [tf.keras.metrics.RootMeanSquaredError()]) 
     15 # Посмотрим на архитектуру модели

AttributeError: 'list' object has no attribute 'Dense'

_Originally posted by @inte1coin in https://github.com/tensorflow/tensorflow/issues/58068#issuecomment-1287618321_
      "
58248,TensorRT converted models are 2-3 times slower in TF 2.10.0 in comparison to TF 2.9.2 ," 
 ### Issue Type

Performance

### Source

binary pypi

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04


### Python version

3.7

### CUDA/cuDNN version

11.2.2 / 8.3.2.44

### TensorRT version

7.2.3

### GPU model and memory

Nvidia Tesla T4 16GB (aws g4dn.2xlarge)

### Current Behaviour?

Model: imagenet_mobilenet_v2_100_224_classification from tfhub.
I converted and run the model using TF-TRT 2.9.2 and 2.10.0. 

TF-TRT 2.10.0 is 2-3x times slower than TF-TRT 2.9.2. 

Results for imagenet_mobilenet_v2 are below

```
# imagenet_mobilenet_v2

# TF-TRT 2.9.2
P50 (ms): 0.87

# TF-TRT 2.10.0
P50 (ms): 1.87  (2.15x times slower)
```

Similar performance issue exist for other models such as inception_v3 and resnet_50 - 2-3x times slower in TF-TRT 2.10.0

### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt
import time
import numpy as np

m=tf.keras.applications.MobileNetV2()
tf.saved_model.save(m, ""saved_model"")

precision_mode=trt.TrtPrecisionMode.FP32
conversion_params = trt.TrtConversionParams(precision_mode=precision_mode)
converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=""saved_model"",
    conversion_params=conversion_params)
converter.convert()
converter.save(""saved_model_trt_32"")

m=tf.saved_model.load(""saved_model_trt_32"")
f=m.signatures['serving_default']
x=tf.random.uniform(shape=(1,224,224,3), dtype=""float32"")

# Warmup
N = 10
for i in range(N):
  y = f(x)

N = 100
TTT=[]
for i in range(N):
  t1 = time.time()
  y = f(x)
  t2 = time.time()
  TTT.append(t2-t1)

p50_time = np.percentile(TTT, 50) * 1000
print(""P50 (ms):"", p50_time)
```

"
58247,ModuleNotFoundError: No module named 'google.protobuf' under Ubuntu Jammy,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

v2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 22.04.1 LTS

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

5.1.1

### GCC/Compiler version

gcc (Ubuntu 11.2.0-19ubuntu1) 11.2.0

### CUDA/cuDNN version

cudnn-local-repo-ubuntu2204-8.6.0.163_1.0-1_amd64

### GPU model and memory

NVIDIA Corporation GM206 [GeForce GTX 950] (rev a1)

### Current Behaviour?

```shell
Followed the standard instruction to compile TF from source.
The command:
bazel build --config=cuda --local_ram_resources=8192 //tensorflow/tools/pip_package:build_pip_package
fails with:
ERROR: /home/bernd/tensorflow/tensorflow/BUILD:1397:19: Executing genrule //tensorflow:tf_python_api_gen_v2 failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)
2022-10-21 21:31:14.939452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-21 21:31:15.169373: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
Traceback (most recent call last):
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 22, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/core/framework/function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
ModuleNotFoundError: No module named 'google.protobuf'
Target //tensorflow/tools/pip_package:build_pip_package failed to build

If I just run that script:
python /home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/core/framework/function_pb2.py
Traceback (most recent call last):
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
ModuleNotFoundError: No module named 'tensorflow'
then protobuf can be found (my install) but not tensorflow which looks like a virtual environment issue.
```


### Standalone code to reproduce the issue

```shell
git checkout v2.10.0
./configure
Default but with cuda = y
bazel build --config=cuda --local_ram_resources=8192 //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
ERROR: /home/bernd/tensorflow/tensorflow/BUILD:1397:19: Executing genrule //tensorflow:tf_python_api_gen_v2 failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)
2022-10-21 21:31:14.939452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-21 21:31:15.169373: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
Traceback (most recent call last):
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 22, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/home/bernd/.cache/bazel/_bazel_bernd/2716ba2e215c041a26405d6ef9e43b69/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/core/framework/function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
ModuleNotFoundError: No module named 'google.protobuf'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/bernd/tensorflow/tensorflow/python/tools/BUILD:313:10 Middleman _middlemen/tensorflow_Spython_Stools_Ssaved_Umodel_Ucli-runfiles failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)
```
</details>"
58246,Typesec error: SineReLU advaced activation functions,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Google Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Previously, I had called SineReLU function in subclass model building method using string alias through get_custom_objects(), Unfortunately, BatchNormalization function failed in that method producing an interesting error of invalid tesnor rank.

Don't want to be carried out! I then swtiched to something called Sequential method, yada! Our favourite proven way!! But, this time, it shows a typesec error with the SineReLU function which is totally weird. Because, I have imprted and run the functional call in previous cell and all works perfectly fine except while I call the function within the core model architecture.

I am really adamant at this point, to get SineReLU function to work so much, I will even write custom code in the keras-contrib library or Tensorflow if that what takes to fix this error. (I could get away with Swish function but I won't)

If I'm not wrong, Tensorflow can't match Class Typsec from keras-contrib library
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Input, Dropout, CategoryEncoding, BatchNormalization, ReLU
from keras_contrib.layers.advanced_activations.sinerelu import SineReLU
from tensorflow.keras import Model
from keras.utils.generic_utils import get_custom_objects
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import Activation
from keras.layers.pooling.max_pooling2d import MaxPooling2D

# Calling custom functions
get_custom_objects().update({'SineReLU': Activation(SineReLU)})
```


### Relevant log output

```shell
891         3, ""Failed to convert %r to tensor: %s"" % (type(value).__name__, e))
    892 
--> 893   raise TypeError(f""Could not build a TypeSpec for {value} of ""
    894                   f""unsupported type {type(value)}."")
    895 

TypeError: Could not build a TypeSpec for <keras_contrib.layers.advanced_activations.sinerelu.SineReLU object at 0x7f4d5c575ad0> of unsupported type <class 'keras_contrib.layers.advanced_activations.sinerelu.SineReLU'>.
```
</details>"
58214,How to use non-zero values in sparse tensors for constructing graph in tensorflow 1.x,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

v1.14.0-rc1-22-gaf24dc91b5 1.14.0

### Custom Code

Yes

### OS Platform and Distribution

x86_64 GNU/Linux

### Mobile device

_No response_

### Python version

3.6.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How to use non-zero values in sparse tensors for constructing graph in tensorflow 1.x
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

# batch_size, slot_num, fea_num(not fixed) [2,3,4]
sparse = tf.sparse.placeholder(tf.float32)
def model(x):
    net_out = tf.layers.dense(
        inputs=x,
        units=10,
        activation=tf.sigmoid,
        name=""fc1"")
    net_out = tf.layers.dense(
        inputs=net_out,
        units=2,
        activation=tf.sigmoid,
        name='fc2')
    return net_out

def nothing(x):
    # fake because of 0
    return x[:,:,:,:2]

def model_cond(x):
    return tf.cond(tf.abs(tf.reduce_sum(x,axis=2)) < 1e-8, lambda: model(x), lambda: nothing(x))

# to dense
dense = tf.sparse.to_dense(sparse)

# fake encode
dense_ex = tf.expand_dims(dense, -1)
k = 10
dense_tile = tf.tile(dense_ex, [1,1,1,k])

# model
dense_re = tf.reshape(dense_tile, [2,3,-1,k])
#fc = model(dense_re)
fc = model_cond(dense_re)

# pooling
# batch_size, slot_num, dim [2,3,4,2]
fc_pool = tf.reduce_sum(fc, axis=2)

indices = np.array([[0, 0, 1], [0,1,0],[0,2,2],[1,0,0],[1,1,1],[1,2,2],[1,2,3]], dtype=np.int64)
values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], dtype=np.float32)
shape = np.array([2, 3, 4], dtype=np.int64)

init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)
res=sess.run([dense,dense_ex,dense_tile,fc,fc_pool], feed_dict={sparse:(indices, values, shape)})
for v in res:
    print(v)
    print(""----------"")
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1864, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 0 but is rank 3 for 'cond/Switch' (op: 'Switch') with input shapes: [2,3,10], [2,3,10].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test_sparse.py"", line 43, in <module>
    fc = model_cond(dense_re)
  File ""test_sparse.py"", line 24, in model_cond
    return tf.cond(tf.abs(tf.reduce_sum(x,axis=2)) < 1e-8, lambda: model(x), lambda: nothing(x))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1965, in cond
    p_2, p_1 = switch(pred, pred)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 308, in switch
    return gen_control_flow_ops.switch(data, pred, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_control_flow_ops.py"", line 935, in switch
    ""Switch"", data=data, pred=pred, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 2027, in __init__
    control_input_ops)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1867, in _create_c_op
    raise ValueError(str(e))
ValueError: Shape must be rank 0 but is rank 3 for 'cond/Switch' (op: 'Switch') with input shapes: [2,3,10], [2,3,10].
```
</details>"
58213,Deep learning : test a small number of images,"Hi everyone,
I work on segmentation of medical images (512 , 512 , 3) on Kaggle notebook.
My private  dataset contains 2 folders : images and labels. Each one is devided on train and test sets.
My U-net code runs correctly (training and testing) on the full dataset.

Now, I want to test the model on a folder containing only 27 images.  
When I execute evaluate function :  _ = model1.evaluate(test_dataset)

I meet this error :

InvalidArgumentError: 2 root error(s) found.
(0) Invalid argument: slice index 1 of dimension 2 out of bounds.
[[{{node strided_slice_1}}]]
[[IteratorGetNext]]
[[IteratorGetNext/_4]]
(1) Invalid argument: slice index 1 of dimension 2 out of bounds.
[[{{node strided_slice_1}}]]
[[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_12429]

Function call stack:
test_function -> test_function

thank you for helps"
58211,Input has undefined rank. Received: input_shape=<unknown>,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Google Colab

### Mobile device

_No response_

### Python version

3.7.15

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened! I have created a derived version of AlexNet, I think BatchNormalization layers might be the cuprit behind the error. As without BatchNormalization layer it works perfectly fine. 

I don't think it's relevant but I used some custom activation functions. with combination of ""relu"". Though those functions weren't that different from ""relu"" so, I don't expect any error. It'll be a great help, if someone can help me to solve this error :)

Relevant pointers and hints will also be appreciated!
```


### Standalone code to reproduce the issue

```shell
# input_shape=(256, 256, 3)
model.build(input_shape=(None, 220, 220, 3))
model.summary()
```


### Relevant log output

```shell
ValueError                                Traceback (most recent call last)
<ipython-input-16-a5158c5140ec> in <module>
      1 # input_shape=(256, 256, 3)
----> 2 model.build(input_shape=(None, 256, 256, 3))
      3 model.summary()

3 frames
/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py in validate_axis(axis, input_shape)
    241   if not rank:
    242     raise ValueError(
--> 243         f'Input has undefined rank. Received: input_shape={input_shape}')
    244 
    245   # Convert axis to list and resolve negatives

ValueError: Input has undefined rank. Received: input_shape=<unknown>
```
</details>"
58210,An error occurred during the fetch of repository 'local_config_cuda',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

4.2.1

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

CUDA 11.7 /cuDNN 8

### GPU model and memory

A100 80G

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
git clone https://github.com/tensorflow/tensorflow tensorflow -b v2.8.0 --depth=1
```


### Relevant log output

```shell
ERROR: An error occurred during the fetch of repository 'local_config_cuda':                                   
   Traceback (most recent call last):                                                                          
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1401, column 38
, in _cuda_autoconf_impl                                                                                       
                _create_local_cuda_repository(repository_ctx)                                                  
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1076, column 27
, in _create_local_cuda_repository                                                                             
                cuda_libs = _find_libs(repository_ctx, check_cuda_libs_script, cuda_config)                    
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 606, column 21,
 in _find_libs                                                                                                 
                _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())      
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 501, column 28,
 in _check_cuda_libs                                                                                           
                checked_paths = execute(repository_ctx, [python_bin, ""-c"", cmd]).stdout.splitlines()           
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/remote_config/common.bzl"", line 230, column 13
, in execute                                                                                                   
                fail(                                                                                          
Error in fail: Repository command failed
Expected even number of arguments
ERROR: Error fetching repository: Traceback (most recent call last):
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1401, column 38, in _cuda_autoconf_impl
                _create_local_cuda_repository(repository_ctx)
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1076, column 27, in _create_local_cuda_repository
                cuda_libs = _find_libs(repository_ctx, check_cuda_libs_script, cuda_config)        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 606, column 21, in _find_libs
                _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/gpus/cuda_configure.bzl"", line 501, column 28, in _check_cuda_libs
                checked_paths = execute(repository_ctx, [python_bin, ""-c"", cmd]).stdout.splitlines()
        File ""/home/xizhang/software/dpmd/tensorflow/third_party/remote_config/common.bzl"", line 230, column 13, in execute
                fail(
Error in fail: Repository command failed
Expected even number of arguments
INFO: Found applicable config definition build:cuda in file /home/xizhang/software/dpmd/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:cuda in file /home/xizhang/software/dpmd/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: @local_config_cuda//:enable_cuda :: Error loading option @local_config_cuda//:enable_cuda: Repository command failed
Expected even number of arguments
```
</details>"
58208,'tf.AddV2' op is neither a custom op nor a flex op,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WSL2 (Ubuntu)
- TensorFlow installation (pip package or built from source): 2.10.0
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

```python
import tensorflow as tf
import jax.numpy as jnp


def inc(x):
    return x + 1


x_input = jnp.zeros((1, 28, 28), dtype=jnp.int16)
converter = tf.lite.TFLiteConverter.experimental_from_jax(
    [inc], [[('input1', x_input)]])
tflite_model = converter.convert()
```


I'm getting the following:
```
2022-10-20 22:25:59.199307: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-10-20 22:25:59.199391: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-10-20 22:25:59.199400: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:371] Ignored change_concat_input_ranges.
loc(fused[""xla_computation(inc)/jit(main)/add"", ""/tmp/ipykernel_30536/2180026997.py"":6:0]): error: 'tf.AddV2' op is neither a custom op nor a flex op
error: failed while converting: 'main': 
Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select 
TF Select ops: AddV2
Details:
	tf.AddV2(tensor<1x28x28xi16>, tensor<1x28x28xi16>) -> (tensor<1x28x28xi16>)
```

Note that this doesn't happen if I use `dtype=jnp.float32` or `jnp.int32`.
Would appreciate any help here. Thanks!"
58206,Tensorflow Lite conversion output vs. Tensorflow output,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 20.04.4 LTS (GNU/Linux 5.4.0-128-generic x86_64)
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.9.1

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
import tensorflow as tf
from tensorflow import keras
import pickle
import numpy as np

with open(""genMat.pkl"", ""rb"") as f:
     gen_matrix = pickle.load(f)
# 14400x1800
xlen=14400
ylen=1800

def representative_dataset():
  for _ in range(100):
      data = np.random.randint(0, 2, (xlen,))
      yield [data.astype(np.float32)]

test_input = np.loadtxt(""input_msg.csv"",dtype=int,delimiter=',')
input = 0
generator = tf.convert_to_tensor(gen_matrix[input*xlen:(input+1)*xlen, :], dtype=tf.float32)

ldpc_enc_input = keras.Input(shape=(xlen,), name=""ldpc_enc_input"")
generator_input = tf.reshape(ldpc_enc_input, shape=(-1, xlen))
generator_output = tf.matmul(generator_input, generator)

ldpc_enc_output = tf.math.floormod(generator_output, 2)

ldpc_enc_model = keras.Model(inputs=ldpc_enc_input, outputs=ldpc_enc_output)

arr=ldpc_enc_model(test_input[input*xlen:(input+1)*xlen])
print(arr.numpy()[0])

converter = tf.lite.TFLiteConverter.from_keras_model(ldpc_enc_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.target_spec.supported_types = [tf.int8]
converter.inference_input_type = tf.int8 # or tf.uint8
converter.inference_output_type = tf.int8 # or tf.uint8

tflite_quant_model = converter.convert()
# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_data = np.array(test_input[input*xlen:(input+1)*xlen], dtype=np.int8, ndmin=2)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

# The function `get_tensor()` returns a copy of the tensor data.
# Use `tensor()` in order to get a pointer to the tensor.
arr = interpreter.get_tensor(output_details[0]['index'])
print(arr[0])
```  

[input_msg.csv](https://github.com/tensorflow/tensorflow/files/9834888/input_msg.csv)


### 3. Failure after conversion
[genMat.txt](https://github.com/tensorflow/tensorflow/files/9834891/genMat.txt)

If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results vs. the Tensorflow model. I have attached the pkl file as a text file which gets loaded and then the input csv gets loaded (input_msg.csv). The output of the TF invocation if correct and printed out ([0. 1. 0. ... 1. 0. 1.]). The TFLite invocation output is printed and is incorrect ([-128  127  127 ...  -48  -48  127]). Not sure if this is a quantization or scaling issue? The inputs are just 0 or 1, so the representative data set is just random 0 and 1's.


"
58192,TensorFlow Lite How to build NNAPI delegate for Android?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Android

### Mobile device

N/A

### Python version

N/A

### Bazel version

5.1.1

### GCC/Compiler version

Android NDK 21

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
I am trying to build TFLite with XNNPACK, GPU (OpenCL), and NNAPI delegate. Please see below for the command I used. The build succeeds, but I cannot find the .so file for the NNAPI delegate. I searched for all the created .so files under `bazel-bin` folder and I only see these:

./tensorflow/lite/libtensorflowlite.so
./tensorflow/lite/libtensorflowlite.so.runfiles/org_tensorflow/tensorflow/lite/libtensorflowlite.so
./tensorflow/lite/delegates/gpu/libtensorflowlite_gpu_delegate.so
./tensorflow/lite/delegates/gpu/libtensorflowlite_gpu_delegate.so.runfiles/org_tensorflow/tensorflow/lite/delegates/gpu/libtensorflowlite_gpu_delegate.so
```
I did `nm -D libtensorflowlite.so | grep Nnapi` to see if perhaps the symbols for NNAPI delegated got baked into libtensorflowlite.so. But that does not appear to be the case.

Am I building NNAPI delegate incorrectly?
```


### Standalone code to reproduce the issue

```shell
bazel build -c opt --config android_arm64 --config=monolithic --copt -DCL_DELEGATE_NO_GL --strip=never //tensorflow/lite:libtensorflowlite.so //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so //tensorflow/lite/delegates/nnapi:nnapi_delegate
```


### Relevant log output

```shell
N/A
```
</details>"
58190,Quantised fused custom op,"TensorFlow support [converting from composite op to a single fused TFLite custom operation](https://www.tensorflow.org/lite/models/convert/operation_fusion)

We have issues generating fully quantised model containing such fused custom Ops, generated TFLite models from TFLite Converter have fused custom Ops and operations remained as float operation, while have `Quantize` and `Dequantize` nodes in between.
Please review Colab below, we made models to illustrate these issues:
[custom op with multiple inputs and outputs](https://colab.research.google.com/drive/1kVBfxk39NOaWr02abWDeg458HFeyy_gE?usp=sharing)

Any suggestions that we can resolve these issues and make TFLite custom op able to be fully quantised?
"
58189,Mobile SSD model generates only 1 output,"### 1. System information

- Used Colab
- Used Jupyter under Ubuntu 22.04 to emulate same exercise (_i.e._ build ._tflite_ and ._txt_ files)

Running original Tensorflow Lite tutorial on **flowers** image classification with only one change in parameter for _model_spec_ as noted below.

### 2. Code

Total newbie here, sorry!

- Performed Android Studio development for the classification tutorial on flowers.
- Deployed to Pixel 2 XL
- The app runs fine
- Ran the flowers tutorial in Colab to generate the ._tflite_ and ._txt_ files.
- Deployed to another Android device (?) where the error message is:
_Mobile SSD models are expected to have exactly 4 outputs, found 1_

Don't have access to the source code for the another Android app. However, this app reads the COCO ._tflite_ model without errors. So the issue lies in my understanding of how I should specify the parameters to generate the .tflite model file in the expected format.

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://www.tensorflow.org/lite/models/modify/model_maker/image_classification): Demonstrate how to build your TF model.
2)  Reference [Image Classifier](https://github.com/lmoroney/odmlbook): Sample runs fine when built under Dolphin 2021.3.1 and ported to Pixel 2 XL.

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

How to change the following statement to meet the requirement: _Mobile SSD models are expected to have exactly 4 outputs, found 1_

```
model = image_classifier.create(train_data, model_spec=model_spec.get('mobilenet_v2'), validation_data=validation_data)
```
Don't know how what parameter to set to obtain a ._tflite_ model file that will meet the requirement. Did a cursory search for links to the documentation for **image_classifier.create** method but couldn't find anything owing to my inexperience.

### 3. Failure after conversion

Not performing any conversion. Would like to perform conversion if that approach is recommended but then I'm totally ignorant about conversion and some links to more detailed information on conversion would be helpful.

- Model cannot be read in a very simple end-user operation because Mobile SSD models are expected to have exactly 4 outputs, found 1

### 4. (optional) RNN conversion support
not applicable

### 5. (optional) Any other info / logs

The following will not be helpful (because I do not have access to the underlying source code and cannot provide it for further support purposes) but I have included it nevertheless for completeness:

```
2022-10-20 09:21:36.336 2300-2477/com.qualcomm.ftcrobotcontroller E/AndroidRuntime: FATAL EXCEPTION: VuforiaFrameGenerator
    Process: com.qualcomm.ftcrobotcontroller, PID: 2300
    java.lang.AssertionError: Error occurred when initializing ObjectDetector: Mobile SSD models are expected to have exactly 4 outputs, found 1
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.initJniWithByteBuffer(Native Method)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.access$100(ObjectDetector.java:86)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector$3.createHandle(ObjectDetector.java:211)
        at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:91)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.createFromBufferAndOptions(ObjectDetector.java:207)
        at org.firstinspires.ftc.robotcore.internal.tfod.TfodFrameManager2$RecognizerPipeline2.<init>(TfodFrameManager2.java:66)
        at org.firstinspires.ftc.robotcore.internal.tfod.TfodFrameManager2$RecognizerPipeline2.<init>(TfodFrameManager2.java:55)
        at org.firstinspires.ftc.robotcore.internal.tfod.TfodFrameManager2.createRecognizerPipeline(TfodFrameManager2.java:52)
        at org.firstinspires.ftc.robotcore.internal.tfod.TfodFrameManager$MainPipeline.init(TfodFrameManager.java:227)
        at org.firstinspires.ftc.robotcore.internal.tfod.VuforiaFrameGenerator.run(VuforiaFrameGenerator.java:147)
        at java.lang.Thread.run(Thread.java:761)

```
"
58186,Failed to load the native TensorFlow runtime,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Testing tensorflow
```


### Standalone code to reproduce the issue

```shell
(venv) C:\AMAZON\test>python -m pip install tensorflow
Requirement already satisfied: tensorflow in c:\amazon\test\venv\lib\site-packages (2.10.0)
Requirement already satisfied: astunparse>=1.6.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.6.3)
Requirement already satisfied: absl-py>=1.0.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.3.0)
Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.10.1)
Requirement already satisfied: libclang>=13.0.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (14.0.6)
Requirement already satisfied: flatbuffers>=2.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (22.9.24)
Requirement already satisfied: keras<2.11,>=2.10.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: numpy>=1.20 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.22.4)
Requirement already satisfied: setuptools in c:\amazon\test\venv\lib\site-packages (from tensorflow) (60.2.0)
Requirement already satisfied: packaging in c:\amazon\test\venv\lib\site-packages (from tensorflow) (21.3)
Requirement already satisfied: six>=1.12.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.16.0)
Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (0.4.0)
Requirement already satisfied: termcolor>=1.1.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.0.1)
Requirement already satisfied: google-pasta>=0.1.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (0.2.0)
Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.10.0)
Collecting keras-preprocessing>=1.1.1
  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)
Requirement already satisfied: opt-einsum>=2.3.2 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (3.3.0)
Requirement already satisfied: wrapt>=1.11.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.14.1)
Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.49.1)
Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (3.19.6)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (0.27.0)
Requirement already satisfied: typing-extensions>=3.6.6 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (4.4.0)
Requirement already satisfied: h5py>=2.9.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (3.7.0)
Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\amazon\test\venv\lib\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)
Requirement already satisfied: werkzeug>=1.0.1 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)
Requirement already satisfied: google-auth<3,>=1.6.3 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)       
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)
Requirement already satisfied: markdown>=2.6.8 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)
Requirement already satisfied: requests<3,>=2.21.0 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\amazon\test\venv\lib\site-packages (from packaging->tensorflow) (2.4.7)
Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\amazon\test\venv\lib\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)
Requirement already satisfied: rsa<5,>=3.1.4 in c:\amazon\test\venv\lib\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\amazon\test\venv\lib\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)
Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\amazon\test\venv\lib\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)
Requirement already satisfied: importlib-metadata>=4.4 in c:\amazon\test\venv\lib\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)
Requirement already satisfied: certifi>=2017.4.17 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)
Requirement already satisfied: idna<4,>=2.5 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)
Requirement already satisfied: charset-normalizer<3,>=2 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)
Requirement already satisfied: MarkupSafe>=2.1.1 in c:\amazon\test\venv\lib\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)
Requirement already satisfied: zipp>=0.5 in c:\amazon\test\venv\lib\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.9.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\amazon\test\venv\lib\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in c:\amazon\test\venv\lib\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)
Installing collected packages: keras-preprocessing
  Attempting uninstall: keras-preprocessing
    Found existing installation: Keras-Preprocessing 1.0.5
    Uninstalling Keras-Preprocessing-1.0.5:
      Successfully uninstalled Keras-Preprocessing-1.0.5
Successfully installed keras-preprocessing-1.1.2

(venv) C:\AMAZON\test>conda create --name tensorflow-env python=3.8 pip
'conda' is not recognized as an internal or external command,
operable program or batch file.

(venv) C:\AMAZON\test>conda activate tensorflow-env
'conda' is not recognized as an internal or external command,
operable program or batch file.

(venv) C:\AMAZON\test>pip install tensorflow
Requirement already satisfied: tensorflow in c:\amazon\test\venv\lib\site-packages (2.10.0)
Requirement already satisfied: opt-einsum>=2.3.2 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (3.3.0)
Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.49.1)
Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.1.2)
Requirement already satisfied: absl-py>=1.0.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.3.0)
Requirement already satisfied: termcolor>=1.1.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.0.1)
Requirement already satisfied: keras<2.11,>=2.10.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: flatbuffers>=2.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (22.9.24)
Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.10.0)
Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (3.19.6)
Requirement already satisfied: numpy>=1.20 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.22.4)
Requirement already satisfied: libclang>=13.0.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (14.0.6)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (0.27.0)
Requirement already satisfied: typing-extensions>=3.6.6 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (4.4.0)
Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (2.10.1)
Requirement already satisfied: packaging in c:\amazon\test\venv\lib\site-packages (from tensorflow) (21.3)
Requirement already satisfied: six>=1.12.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.16.0)
Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (0.4.0)
Requirement already satisfied: h5py>=2.9.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (3.7.0)
Requirement already satisfied: google-pasta>=0.1.1 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (0.2.0)
Requirement already satisfied: astunparse>=1.6.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.6.3)
Requirement already satisfied: setuptools in c:\amazon\test\venv\lib\site-packages (from tensorflow) (60.2.0)
Requirement already satisfied: wrapt>=1.11.0 in c:\amazon\test\venv\lib\site-packages (from tensorflow) (1.14.1)
Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\amazon\test\venv\lib\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)
Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)
Requirement already satisfied: werkzeug>=1.0.1 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)
Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)
Requirement already satisfied: requests<3,>=2.21.0 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)
Requirement already satisfied: google-auth<3,>=1.6.3 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)       
Requirement already satisfied: markdown>=2.6.8 in c:\amazon\test\venv\lib\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\amazon\test\venv\lib\site-packages (from packaging->tensorflow) (2.4.7)
Requirement already satisfied: rsa<5,>=3.1.4 in c:\amazon\test\venv\lib\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)
Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\amazon\test\venv\lib\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\amazon\test\venv\lib\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)
Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\amazon\test\venv\lib\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)
Requirement already satisfied: importlib-metadata>=4.4 in c:\amazon\test\venv\lib\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)
Requirement already satisfied: charset-normalizer<3,>=2 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)
Requirement already satisfied: certifi>=2017.4.17 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)
Requirement already satisfied: idna<4,>=2.5 in c:\amazon\test\venv\lib\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)
Requirement already satisfied: MarkupSafe>=2.1.1 in c:\amazon\test\venv\lib\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)
Requirement already satisfied: zipp>=0.5 in c:\amazon\test\venv\lib\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.9.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\amazon\test\venv\lib\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in c:\amazon\test\venv\lib\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)

(venv) C:\AMAZON\test>python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Traceback (most recent call last):
  File ""C:\AMAZON\test\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: %1 is not a valid Win32 application.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\AMAZON\test\venv\lib\site-packages\tensorflow\__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\AMAZON\test\venv\lib\site-packages\tensorflow\python\__init__.py"", line 36, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\AMAZON\test\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 77, in <module>
    raise ImportError(
ImportError: Traceback (most recent call last):
  File ""C:\AMAZON\test\venv\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: %1 is not a valid Win32 application.


Failed to load the native TensorFlow runtime.
```


### Relevant log output

_No response_</details>"
58184,"Trying to save a model compiled with tfa.MultiOptimizer | gives error saying `TypeError: ('Not JSON Serializable:', ...`","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.6.4

### Custom Code

Yes

### OS Platform and Distribution

Kaggle kernel

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

_No response_

### GCC/Compiler version

GCC 9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
class ModelSaverCallback(Callback):
    def on_epoch_end(self, epoch, logs=None):
        print('name: ' + self.model._name)
        self.model.save('epoch-' + str(epoch + 1) + '-' + self.model._name + '.h5',overwrite=True,
    include_optimizer=True,)
        
callbacks = [ModelSaverCallback()]

model_w_multioptimizer = tf.keras.Sequential([
    tf.keras.layers.Dense(12, activation = 'relu', input_shape=(len(xs[0]),)),
    tf.keras.layers.Dense(1, activation = 'tanh')
])

model_w_multioptimizer._name = ""model_w_multioptimizer""

optimizers = [
    SGD(learning_rate=3e-4),
    Adam(learning_rate=3e-4),
]
optimizers_and_layers = [(optimizers[0], model_w_multioptimizer.layers[:1]), (optimizers[1], model_w_multioptimizer.layers[1:])]
optimizer = MultiOptimizer(optimizers_and_layers)

model_w_multioptimizer.compile(
                optimizer = optimizer,      
                loss = tf.keras.losses.BinaryCrossentropy(),
                metrics=['accuracy']
    )
    
model_w_multioptimizer.fit(xs,ys,
        epochs = 50,
        batch_size=32,
      callbacks=callbacks,
        validation_data=(valid_xs, valid_ys))
```

It simply can't save the model when there are multiple optimizers.



### Standalone code to reproduce the issue

```shell
Kaggle kernel: https://www.kaggle.com/code/maifeeulasad/tfa-multioptimizer-model-save?scriptVersionId=108636090
```


### Relevant log output

```shell
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/tmp/ipykernel_20/1141714396.py in <module>
     24         batch_size=32,
     25       callbacks=callbacks,
---> 26         validation_data=(valid_xs, valid_ys))

/opt/conda/lib/python3.7/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1228           epoch_logs.update(val_logs)
   1229 
-> 1230         callbacks.on_epoch_end(epoch, epoch_logs)
   1231         training_logs = epoch_logs
   1232         if self.stop_training:

/opt/conda/lib/python3.7/site-packages/keras/callbacks.py in on_epoch_end(self, epoch, logs)
    411     logs = self._process_logs(logs)
    412     for callback in self.callbacks:
--> 413       callback.on_epoch_end(epoch, logs)
    414 
    415   def on_train_batch_begin(self, batch, logs=None):

/tmp/ipykernel_20/3193528328.py in on_epoch_end(self, epoch, logs)
      3         print('name: ' + self.model._name)
      4         self.model.save('epoch-' + str(epoch + 1) + '-' + self.model._name + '.h5',overwrite=True,
----> 5     include_optimizer=True,)
      6 
      7 callbacks = [ModelSaverCallback()]

/opt/conda/lib/python3.7/site-packages/keras/engine/training.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)
   2144     # pylint: enable=line-too-long
   2145     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 2146                     signatures, options, save_traces)
   2147 
   2148   def save_weights(self,

/opt/conda/lib/python3.7/site-packages/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)
    144           'or using `save_weights`.')
    145     hdf5_format.save_model_to_hdf5(
--> 146         model, filepath, overwrite, include_optimizer)
    147   else:
    148     with generic_utils.SharedObjectSavingScope():

/opt/conda/lib/python3.7/site-packages/keras/saving/hdf5_format.py in save_model_to_hdf5(model, filepath, overwrite, include_optimizer)
    112       if isinstance(v, (dict, list, tuple)):
    113         f.attrs[k] = json.dumps(
--> 114             v, default=json_utils.get_json_type).encode('utf8')
    115       else:
    116         f.attrs[k] = v

/opt/conda/lib/python3.7/json/__init__.py in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)
    236         check_circular=check_circular, allow_nan=allow_nan, indent=indent,
    237         separators=separators, default=default, sort_keys=sort_keys,
--> 238         **kw).encode(obj)
    239 
    240 

/opt/conda/lib/python3.7/json/encoder.py in encode(self, o)
    197         # exceptions aren't as detailed.  The list call should be roughly
    198         # equivalent to the PySequence_Fast that ''.join() would do.
--> 199         chunks = self.iterencode(o, _one_shot=True)
    200         if not isinstance(chunks, (list, tuple)):
    201             chunks = list(chunks)

/opt/conda/lib/python3.7/json/encoder.py in iterencode(self, o, _one_shot)
    255                 self.key_separator, self.item_separator, self.sort_keys,
    256                 self.skipkeys, _one_shot)
--> 257         return _iterencode(o, 0)
    258 
    259 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,

/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/json_utils.py in get_json_type(obj)
    140     return obj.value
    141 
--> 142   raise TypeError('Not JSON Serializable:', obj)

TypeError: ('Not JSON Serializable:', <tf.Tensor 'gradient_tape/model_w_multioptimizer/dense_2/MatMul:0' shape=(3, 12) dtype=float32>)
```
</details>"
58183,Keras load LSTM/GRU model with constant mask/initial_state will raise error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

TF 2.6.3

### Custom Code

Yes

### OS Platform and Distribution

RedHat 7

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Traceback (most recent call last):
  File ""/home/runner/work/sample_code/example.py"", line 28, in <module>
    dd = tf.keras.models.load_model(""./lstm.h5"", compile=False, options=load_options)
  File ""/home/runner/anaconda3/envs/latest_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/runner/anaconda3/envs/latest_env/lib/python3.8/site-packages/keras/backend.py"", line 1470, in int_shape
    shape = x.shape
AttributeError: 'float' object has no attribute 'shape'
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
import tensorflow.keras.backend as K

input_t = tf.keras.Input(shape=(28, 10), batch_size=2, dtype=""float32"")

rdm_value = np.ones([2, 28]).astype(np.float32)
rdm_value[:, 20:] = 0
mask_value = K.constant(np.array(rdm_value), dtype='bool')

m_state = tf.keras.initializers.GlorotUniform()(shape=[2, 6], dtype='float32')
c_state = tf.keras.initializers.GlorotUniform()(shape=[2, 6], dtype='float32')
init_state_value = [m_state, c_state]

# mask_value = tf.keras.Input(shape=(28), batch_size=2, dtype=""bool"")

lstm = tf.keras.layers.LSTM(6,
                            return_sequences=True,
                            return_state=True,
                            bias_initializer='random_uniform',
                            time_major=False)(inputs=input_t, mask=mask_value,
                                              training=False,
                                              initial_state=init_state_value)
keras_model = tf.keras.Model([input_t], lstm)
keras_model.save('./lstm.h5')

load_options = tf.saved_model.LoadOptions(allow_partial_checkpoint=True)
dd = tf.keras.models.load_model(""./lstm.h5"", compile=False, options=load_options)
print(dd.inputs)
```


### Relevant log output

_No response_</details>"
58181,A crash due to check-fail can be triggered in FixedUnigramCandidateSampler,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A crash due to check fail can be triggered when execute with both CPU and GPU
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            num_true = 12
            num_sampled = 53
            unique = True
            range_max = 105
            vocab_file = """"
            distortion = 15.07084518523925
            num_reserved_ids = 0
            num_shards = 1
            shard = 0
            unigrams_0 = 45.35209469768597
            unigrams_1 = 73.63755693482213
            unigrams_2 = 51.69763696074902
            unigrams = [unigrams_0, unigrams_1, unigrams_2, ]
            seed = 0
            seed2 = 0
            true_classes = tf.saturate_cast(tf.random.uniform([1, 12], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
            res = tf.raw_ops.FixedUnigramCandidateSampler(
                num_true=num_true,
                num_sampled=num_sampled,
                unique=unique,
                range_max=range_max,
                vocab_file=vocab_file,
                distortion=distortion,
                num_reserved_ids=num_reserved_ids,
                num_shards=num_shards,
                shard=shard,
                unigrams=unigrams,
                seed=seed,
                seed2=seed2,
                true_classes=true_classes,
            )
    except:
        pass
```


### Relevant log output

```shell
Check failed: range == weights_.size() (105 vs. 3)
```
</details>"
58180,A crash due to check-fail can be triggered in DepthwiseConv2dNativeBackpropFilter,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When execute on CPU with OneDNN enabled, a crash due to check-fail can be triggered in DepthwiseConv2dNativeBackpropFilter.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""CPU""):
            strides_0 = 1
            strides_1 = 1
            strides_2 = 128
            strides_3 = 128
            strides = [strides_0, strides_1, strides_2, strides_3, ]
            padding = ""VALID""
            explicit_paddings = []
            data_format = ""NCHW""
            dilations_0 = 96
            dilations_1 = 25
            dilations_2 = 10
            dilations = [dilations_0, dilations_1, dilations_2, ]
            input = tf.random.uniform([], dtype=tf.float32)
            filter_sizes = tf.saturate_cast(tf.random.uniform([0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int32)
            out_backprop = tf.random.uniform([16, 2], dtype=tf.float32)
            res = tf.raw_ops.DepthwiseConv2dNativeBackpropFilter(
                strides=strides,
                padding=padding,
                explicit_paddings=explicit_paddings,
                data_format=data_format,
                dilations=dilations,
                input=input,
                filter_sizes=filter_sizes,
                out_backprop=out_backprop,
            )
    except:
        pass
```


### Relevant log output

```shell
F ./tensorflow/core/util/tensor_format.h:427] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 1, 1, C
Aborted (core dumped)
```
</details>"
58179,A floating point exception can be triggered in DenseToCSRSparseMatrix,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.11.0-dev20221013

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A floating point exception can be triggered in DenseToCSRSparseMatrix, which leads to a crash.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            dense_input = tf.complex(tf.random.uniform([0, 1, 1], dtype=tf.float32),tf.random.uniform([0, 1, 1], dtype=tf.float32))
            indices = tf.saturate_cast(tf.random.uniform([1, 3], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
            res = tf.raw_ops.DenseToCSRSparseMatrix(
                dense_input=dense_input,
                indices=indices,
            )
    except:
        pass
```


### Relevant log output

```shell
Floating point exception (core dumped)
```
</details>"
58178,Crash due to check-fail in DenseBincount,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A check-fail can be triggered in DenseBincount, which leads to a crash
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            binary_output = False
            input = tf.saturate_cast(tf.random.uniform([0, 5], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
            size = 340
            weights = tf.random.uniform([13, 0], dtype=tf.float32)
            res = tf.raw_ops.DenseBincount(
                binary_output=binary_output,
                input=input,
                size=size,
                weights=weights,
            )
    except:
        pass
```


### Relevant log output

```shell
F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 (0 vs. 0)
Aborted (core dumped)
```
</details>"
58177,Crash due to check-fail in CropAndResize,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A check-fail can be triggered in CropAndResize.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            method = ""bilinear""
            extrapolation_value = -90.71406992626788
            image = tf.saturate_cast(tf.random.uniform([1, 4, 1, 8], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
            boxes = tf.random.uniform([4, 0], dtype=tf.float32)
            box_ind = tf.saturate_cast(tf.random.uniform([8, 0, 10, 4], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int32)
            crop_size = tf.saturate_cast(tf.random.uniform([2], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int32)
            res = tf.raw_ops.CropAndResize(
                method=method,
                extrapolation_value=extrapolation_value,
                image=image,
                boxes=boxes,
                box_ind=box_ind,
                crop_size=crop_size,
            )
    except:
        pass
```


### Relevant log output

```shell
F tensorflow/core/framework/tensor_shape.cc:45] Check failed: NDIMS == dims() (1 vs. 4)Asking for tensor of 1 dimensions from a tensor of 4 dimensions
```
</details>"
58176,Anthother Check Fail Can Be Triggered in BlockLSTM,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Another check-fail can be triggered. This seems to be different from https://github.com/tensorflow/tensorflow/issues/58175
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            forget_bias = -121.22699269620765
            cell_clip = -106.82307555235684
            use_peephole = False
            seq_len_max = tf.saturate_cast(tf.random.uniform([13, 11, 0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
            x = tf.random.uniform([1, 3, 15], dtype=tf.float32)
            cs_prev = tf.random.uniform([3, 0], dtype=tf.float32)
            h_prev = tf.random.uniform([3, 0], dtype=tf.float32)
            w = tf.random.uniform([15, 0], dtype=tf.float32)
            wci = tf.random.uniform([0], dtype=tf.float32)
            wcf = tf.random.uniform([0], dtype=tf.float32)
            wco = tf.random.uniform([0], dtype=tf.float32)
            b = tf.random.uniform([0], dtype=tf.float32)
            res = tf.raw_ops.BlockLSTM(
                forget_bias=forget_bias,
                cell_clip=cell_clip,
                use_peephole=use_peephole,
                seq_len_max=seq_len_max,
                x=x,
                cs_prev=cs_prev,
                h_prev=h_prev,
                w=w,
                wci=wci,
                wcf=wcf,
                wco=wco,
                b=b,
            )
    except:
        pass
```


### Relevant log output

```shell
** On entry to SGEMM_EX  parameter number 8 had an illegal value
2022-10-20 10:48:03.831248: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at blas_gemm.cc:52 : INTERNAL: cublas error
2022-10-20 10:48:03.831307: F tensorflow/core/kernels/rnn/lstm_ops_gpu.cu.cc:277] Non-OK-status: GpuLaunchKernel( lstm_gates<T, false, gate_layout>, grid_dim_2d, block_dim_2d, 0, cu_stream, gates.data(), b.data(), cs_prev.data(), wci.data(), wcf.data(), wco.data(), o.data(), h.data(), ci.data(), cs.data(), co.data(), i.data(), f.data(), forget_bias, cell_clip, batch_size, cell_size) status: INTERNAL: invalid configuration argument
Aborted (core dumped)
```
</details>"
58175,Check Fail Can Be Triggered in BlockLSTM,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A check-fail can be triggered.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            forget_bias = -121.22699269620765
            cell_clip = -106.82307555235684
            use_peephole = False
            seq_len_max = tf.saturate_cast(tf.random.uniform([13, 11, 0], minval=0, maxval=64, dtype=tf.int64), dtype=tf.int64)
            x = tf.random.uniform([1, 3, 15], dtype=tf.float32)
            cs_prev = tf.random.uniform([3, 0], dtype=tf.float32)
            h_prev = tf.random.uniform([3, 0], dtype=tf.float32)
            w = tf.random.uniform([15, 0], dtype=tf.float32)
            wci = tf.random.uniform([0], dtype=tf.float32)
            wcf = tf.random.uniform([0], dtype=tf.float32)
            wco = tf.random.uniform([0], dtype=tf.float32)
            b = tf.random.uniform([0], dtype=tf.float32)
            res = tf.raw_ops.BlockLSTM(
                forget_bias=forget_bias,
                cell_clip=cell_clip,
                use_peephole=use_peephole,
                seq_len_max=seq_len_max,
                x=x,
                cs_prev=cs_prev,
                h_prev=h_prev,
                w=w,
                wci=wci,
                wcf=wcf,
                wco=wco,
                b=b,
            )
    except:
        pass
```


### Relevant log output

```shell
2022-10-20 10:45:56.646548: F tensorflow/core/framework/tensor.cc:733] Check failed: 1 == NumElements() (1 vs. 0)Must have a one element tensor
Aborted (core dumped)
```
</details>"
58168,BUILD target visibility broken by upcoming Bazel 6.0 release," 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

Near-HEAD

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

pre-6.0

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Tensorflow's build will break in Bazel 6.0 due to a bugfix in the behavior of `package_group`. (See [Bazel CI run](https://buildkite.com/bazel/bazel-at-head-plus-downstream/builds/2693#0183ee6d-d2e0-4305-9e96-ad11089eb101))

The target `//tensorflow/compiler/xla/mlir/transforms/runtime:calling_convention` depends on `//tensorflow/compiler/xla/mlir/ir/runtime:rt`, and is granted visibility via the latter's `default_visibility` of [`@tf_runtime//:friends`](https://github.com/tensorflow/tensorflow/blob/87e65c2d55d8f3edac6fc7fec4c15b8d0dc7e67e/tensorflow/compiler/xla/mlir/ir/runtime/BUILD#L8). This `friends` package group [contains](https://github.com/tensorflow/runtime/blob/57fa01e0e17ead6faa2a98cfc985eff55380c393/BUILD#L19) `//...`, which under pre-6.0 behavior grants visibility to everyone (effectively public). The corrected behavior is that it grants visibility only to all packages within the same repo as that package group, i.e., to packages under @tf_runtime.

If you want the behavior of the package group to be ""visible to all packages, everywhere"", you can replace `//...` with the special string constant `public`, which is new to Bazel 6.0. This will break compatibility with prior Bazel versions. Note that there is no direct way for a package group to specify ""visible to the following packages that live outside of my own repo"".

Alternatively, you can rewrite the `default_visibility` in `tensorflow/compiler/xla/mlir/ir/runtime/BUILD` to `//visibility:public`, because that's effectively what it already is; or you can determine a more suitable narrower visibility definition.

Finally, you can opt out of this change for your build by passing `--incompatible_fix_package_group_reporoot_syntax=false` in Bazel 6.0. This is particularly helpful if you want to migrate to use `public` for any package groups in the meantime

See bazelbuild/bazel#16323 for more information.


### Standalone code to reproduce the issue

Build at head Bazel.


### Relevant log output

_No response_</details>"
58166,IOU3d and IOU3d pairwise,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

master

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

We are going to introduce c++ custom ops for pairwise IOU3D in Keras-cv with:

https://github.com/keras-team/keras-cv/pull/890

Analyzing also what we have in [TF 3d](https://github.com/google-research/google-research/blob/master/tf3d/object_detection/box_utils/box_ops.py#L26-L69) we are still relying on [numpy helper routines](https://github.com/google-research/google-research/blob/master/tf3d/object_detection/box_utils/np_box_ops.py)

Same thing for Pytorch 3d that has [c++/CUDA cusotm op](https://github.com/facebookresearch/pytorch3d/blob/main/docs/notes/iou3d.md)

I want to try to understand what kind of routines we could contribute here to support these new ops and to analyze if there is any limit, down to the stack, in the case we need to implement an HLO kernel to cover the XLA jit compilation.


### Standalone code to reproduce the issue

```shell
It is a FR.
```


### Relevant log output

_No response_</details>"
58165,Linking error when using tflite::StatefulNnApiDelegate ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04 - Android Studio for building

### Mobile device

Android ARM64

### Bazel version

5.1.1

### Current Behaviour?

Hi! I am trying to add a delegate to the interpreter from the C++ native side, but am unable to figure out how to make it work. Any help would be greatly appreciated!

I can successfully build the model, interpreter and tensors needed for inference, but attempting to initialize `tflite::StatefulNnApiDelegate` leads to a linking error when trying to build the apk

```C/C++: ld: error: undefined symbol: tflite::StatefulNnApiDelegate::Data::~Data()```

What confuses me is that all other tflite functions and objects I needed have been found, I can even declare `tflite::StatefulNnApiDelegate::Options` without issue.

1. Am I doing something wrong in the code, from the examples I could find, and looking at the jni code for the java side I believe the code provided should be correct. Could I be missing something completely, like querying for the Nnapi or setting something in the options before creating the delegate?

2. Could it be an issue happening while building `libtensorflowlite.so`? I followed the recipe to build it with bazel for ARM chips [Build TensorFlow Lite for ARM boards](https://www.tensorflow.org/lite/guide/build_arm) with the command:
```
bazel build --config=android_arm64 -c opt //tensorflow/lite:libtensorflowlite.so
```
and also tried 
```
bazel build -c opt --config=android_arm64 //tensorflow/lite/delegates/nnapi:nnapi_delegate
```
to no avail...

I also included the `CMakeLists.txt` to make sure I am not doing something wrong there.

Thank you in advance!



### Standalone code to reproduce the issue


Failing code.
```
//! 1) build model
model_ = tflite::FlatBufferModel::BuildFromBuffer(model_buffer_,
                                                  sizeof(char) * model_size_);

//! 2) resolving model
tflite::ops::builtin::BuiltinOpResolver resolver;
tflite::InterpreterBuilder builder(*model_, resolver);

//! 3) create NNApi delegate
tflite::StatefulNnApiDelegate::Options options = tflite::StatefulNnApiDelegate::Options();
tflite::StatefulNnApiDelegate nnapi_delegate(options); // fails with ld error
builder.AddDelegate(&nnapi_delegate);

//! 4) link to interpreter
builder(&interpreter_);
assert(interpreter_ != nullptr);
```

CMakeLists.txt
```
cmake_minimum_required(VERSION 3.4.1)

set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -std=gnu++17"")

# Specify where to find the header files for TF Lite C++
set(TF_LITE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/../../../../tflite-api)
set(INCLUDE_DIRS
        ${TF_LITE_DIR}/include
        ${TF_LITE_DIR}/include/flatbuffers/include)
include_directories(
        ${INCLUDE_DIRS})

add_library(tflite SHARED IMPORTED )
set_target_properties(tflite PROPERTIES IMPORTED_LOCATION
        ${TF_LITE_DIR}/lib/${ANDROID_ABI}/libtensorflowlite.so )

add_library(native-lib SHARED
            native-lib.cpp
            native-tf.cpp)

target_include_directories(native-lib
        PUBLIC
        ${CMAKE_CURRENT_SOURCE_DIR})

target_link_libraries(native-lib
        android
        camera2ndk
        mediandk
        log
        tflite
        )
```
"
58164,Significant increase in the size of macOS wheel,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf-nightly 2.11

### Custom Code

No

### OS Platform and Distribution

macOS

### Mobile device

_No response_

### Python version

3.7, 3.8, 3.9, 3.10

### Bazel version

5.3.0

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
[PR 55941](https://github.com/tensorflow/tensorflow/pull/55941) refactored and deduplicated TensorFlow C++ dependencies from _pywrap_tensorflow_internal.so into libtensorflow_cc.so. This change increased the size of macOS pip package from 240 MB to 350 MB.
```


### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/rel/macos/cpu_py310_pip.sh
```


### Relevant log output

_No response_</details>"
58163,Tensorflow TF2.10 C++ API Issue,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

TF2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.3.1

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am trying to use TF2.10 C++ API. I have the used the following to build TF2.10 C++ library.

bazel build --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=1"" --copt=""-O3"" -c opt --config=monolithic --copt=-march='znver1' --show_result 0 --noshow_progress //tensorflow:libtensorflow_cc.so  

After using this libtensorflow_cc.so to build TF-C++ examples. I am getting a compilation error. Error Message is following (I am not seeing this with TF2.9)
libtensorflow_framework.so.2, needed /lib/libtensorflow_cc.so, not found (try using -rpath or -rpath-link)

To resolve this, I have linked the libtensorflow_framework.so to libtensorflow_cc.so, and during the compilation of the TF-C++ example, I have linked this(libtensorflow_framework.so.2) too and the TF-C++ example is compiled. But the executable has the following runtime error.

2022-10-19 11:27:21 [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: google/protobuf/any.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
Aborted (core dumped)

Please help me understand this runtime error and why libtensorflow_cc.so needs libtensorflow_framework.so library.
```


### Standalone code to reproduce the issue

```shell
Steps to reproduce.
1. I have used the following TF-C++ example code with TF2.10 C++ API and libtensorflow_cc.so
link of code and pb file:  
           https://drive.google.com/file/d/1hadjr2f_wJ9DWXzEnpITWC55Cz8sYxZ5/view?usp=sharing
           https://drive.google.com/file/d/1NzhR52xHLfbuyztW2MkiZT9y3XT3dBQl/view?usp=sharing 

2. g++ -o resnet50 -std=c++14 -I$TF_CC_API_ROOT/include tf_cpp_resent50_test.cc -L$TF_CC_API_ROOT/lib -ltensorflow_cc;  [not able to build : libtensorflow_framework.so.2, needed /lib/libtensorflow_cc.so, not found (try using -rpath or -rpath-link)] [But able to build and run with TF2.9 C++ API using this command]

3. g++ -o resnet50 -std=c++14 -I$TF_CC_API_ROOT/include tf_cpp_%s_test.cc -L$TF_CC_API_ROOT/lib -ltensorflow_cc -ltensorflow_framework; [able to compile]

4. ./resnet50 resnet50_fp32_pretrained_model.pb  
[ Above has following runtime error:
   - 022-10-19 11:27:21 [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: google/protobuf/any.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
Aborted (core dumped)
]

Help me to resolve this error with TF.
```


### Relevant log output

```shell
2022-10-19 11:27:21 [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: google/protobuf/any.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):
Aborted (core dumped)

2022-10-19 11:27:21 Model resnet50 executed unsuccessful

2022-10-19 11:27:21 Some/All the Models Executed unsuccessfully
```
</details>"
58162,Crash due to illegal CUDA memory access in BiasAddGrad,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.12.0-dev20221018

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A crash due to illegal memory access in BiasAddGrad can be triggered.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            data_format = ""NCHW""
            out_backprop = tf.saturate_cast(tf.random.uniform([13, 6], minval=0, maxval=64, dtype=tf.int64), dtype=tf.half)
            res = tf.raw_ops.BiasAddGrad(
                data_format=data_format,
                out_backprop=out_backprop,
            )
    except:
        pass
```


### Relevant log output

```shell
2022-10-19 19:36:22.914823: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1014] failed to synchronize the stop event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2022-10-19 19:36:22.915093: E tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.cc:55] INTERNAL: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2022-10-19 19:36:22.915204: E tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.cc:60] INTERNAL: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2022-10-19 19:36:22.915920: E tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:788] failed to record completion event; therefore, failed to create inter-stream dependency
2022-10-19 19:36:22.915977: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1159] failed to enqueue async memcpy from device to host: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered; host dst: 0x7f7506a00000; GPU src: 0x7f7192000500; size: 8=0x8
2022-10-19 19:36:22.916009: E tensorflow/compiler/xla/stream_executor/stream.cc:321] Error recording event in stream: Error recording CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.
2022-10-19 19:36:22.916037: E tensorflow/compiler/xla/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered
2022-10-19 19:36:22.919197: F tensorflow/core/common_runtime/device/device_event_mgr.cc:221] Unexpected Event status: 1
Aborted (core dumped)
```
</details>"
58161,Halo exchange is only supported on TPU for DTensor,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

TensorFlow version: 2.12.0-dev20221019

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.9.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
It fails with ""Halo exchange is only supported on TPU"". When/if will it work on both CPU and GPU hardware?
```


### Standalone code to reproduce the issue

```shell
from tkinter import W
import tensorflow as tf
import numpy as np

from tensorflow.experimental import dtensor

# set logging
import logging
logger = tf.get_logger()
logger.setLevel(logging.DEBUG)



# ------------------------------------------- make sure is the latest TensorFlow version
print('\n\nTensorFlow version:', tf.__version__)




# ------------------------------- configure devices
DEV            = 'CPU'  # GPU
nDEVz          = 1  # z or batch for single channel images
nDEVy          = 2  # y
nDEVx          = 2  # x
nDEVs          = nDEVz*nDEVy*nDEVx


def configure_virtual_cpus(ncpus):
    phy_devices = tf.config.list_physical_devices(DEV)
    tf.config.set_logical_device_configuration(phy_devices[0], [tf.config.LogicalDeviceConfiguration(),] * ncpus)


def configure_virtual_gpus(ngpus):
    phy_devices = tf.config.list_physical_devices('CPU')
    tf.config.set_logical_device_configuration(phy_devices[0], [tf.config.LogicalDeviceConfiguration(),] * ngpus)

    phy_devices = tf.config.list_physical_devices(DEV)
    for n in range(ngpus):
        tf.config.set_logical_device_configuration(phy_devices[n], [tf.config.LogicalDeviceConfiguration(memory_limit=2000),])


if (DEV=='CPU'):
    configure_virtual_cpus(nDEVs)
    DEVICES = [f'CPU:{i}' for i in range(nDEVs)]

if (DEV == 'GPU'):
    configure_virtual_gpus(nDEVs)
    DEVICES = [f'GPU:{i}' for i in range(nDEVs)]


print(tf.config.list_logical_devices(DEV))


def dtensor_from_array(arr, layout, shape=None, dtype=None):
    """"""Convert a DTensor from something that looks like an array or Tensor.

    This function is convenient for quick doodling DTensors from a known,
    unsharded data object in a single-client environment. This is not the
    most efficient way of creating a DTensor, but it will do for this
    tutorial.
    """"""
    if shape is not None or dtype is not None:
        arr = tf.constant(arr, shape=shape, dtype=dtype)

    # replicate the input to the mesh
    a = dtensor.copy_to_mesh(arr, layout=dtensor.Layout.replicated(layout.mesh, rank=layout.rank))

    # shard the copy to the desirable layout
    return dtensor.relayout(a, layout=layout)








# -------------------------------------  tests ------------------------------------------
mesh = dtensor.create_mesh([(""batch"", nDEVz), (""y"", nDEVy), (""x"", nDEVx)], devices=DEVICES)

layout_img = dtensor.Layout([""batch"", ""y"", ""x"", dtensor.UNSHARDED], mesh)
layout_ker = dtensor.Layout([dtensor.UNSHARDED, dtensor.UNSHARDED, dtensor.UNSHARDED, dtensor.UNSHARDED], mesh)  #ex. 3x3x1x32

A = np.arange(2*28*28*1, dtype=""float32"")
A = np.reshape(A, (2,28,28,1))
A = tf.convert_to_tensor(A)
dA = dtensor_from_array(A, layout_img)

w = np.arange(3*3*1*32, dtype=""float32"")
w = np.reshape(w, (3,3,1,32))
w = tf.convert_to_tensor(w)
dw = dtensor_from_array(w, layout_ker)

x = tf.nn.conv2d(dA, dw, strides=[1, 1, 1, 1], padding=""VALID"", data_format=""NHWC"")

print(""\n"")
print(dA)

print(""\n"")
print(dw)

print(""\n"")
print(x)

exit()
```


### Relevant log output

Halo exchange is only supported on TPU."
58160,Tensorflow no library flags,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.2.0

### Custom Code

No

### OS Platform and Distribution

Rasbian Buster

### Mobile device

Raspberry Pi 4B

### Python version

3.7.3

### Bazel version

2.0.0- (@non-git)

### GCC/Compiler version

gcc (Raspbian 8.3.0+rpi1) 8.3.0

### CUDA/cuDNN version

not using cuda

### GPU model and memory

no gpu, 8.6gb free out of 28.9gb

### Current Behaviour?

```shell
Wanted to build tensorflow-io 0.14.0 from source as there wasn't a suitable wheel for it, when running configure.sh:

ERROR: Expected exactly one lib and one libdir in tf.sysconfig.get_link_flags() [] []
```
```


### Standalone code to reproduce the issue

```shell
Tensorflow resources used:
https://qengineering.eu/install-tensorflow-2.2.0-on-raspberry-pi-4.html   version 2.2.0
^built official source code with bazel and generated wheels a few times, problem was not solved

Any previous actions taken on this machine: none, it's a fresh os flash.


>>>import tensorflow as tf
>>>lib = tf.sysconfig.get_link_flags()
>>>lib
[]
```
```


### Relevant log output

_No response_</details>"
58156,LeakyRelu in Tensorflow lite with the Hexagon Delegate not supported,"When using a tflite model (8-bits quantized via TensorFlow lite conversion framework) that includes the activation function ""LeakyRelu"", the Hexagon delegate from tensorflow framework cannot perform the DNN inference on the whole graph, but rather it falls back to the CPU/XNNPack delegate. This is due to the fact that 'LeakyRelu' operation is not supported by the Hexagon Delegate (confirmed in TensorFlow doc: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/hexagon/README.md). When using Relu activation function (and Relu6 as well), we can see below that the TF Hexagon Delegate can process the whole DNN graph, unfortunately, the qualitative results I get are much worse, hence the need of having 'Leaky Relu' implemented in the Hexagon Delegate. We can easily reproduce this behavior by using TensorFlow Benchmark tool (see below)

Could we consider to implement Leaky Relu in tensorflow lite DSP delegate ?

**System information**
- OS Platform and Distribution): Android 10, NDK R21e
- TensorFlow installed from (source or binary): from source using the Release tag '2.9.1'
- TensorFlow version (or github SHA if from source):  2.9.1


**Provide the text output from tflite_convert**

```
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 23). These functions will not be directly callable after loading.
C:\Users\eelfahsi\Miniconda3\envs\ml\lib\site-packages\tensorflow\lite\python\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(""Statistics for quantized inputs were expected, but not ""
2022-10-13 18:13:16.990773: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-10-13 18:13:16.991046: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-10-13 18:13:16.998334: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: C:\Users\eelfahsi\AppData\Local\Temp\tmp731h7tgk
2022-10-13 18:13:17.027069: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }
2022-10-13 18:13:17.027795: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: C:\Users\eelfahsi\AppData\Local\Temp\tmp731h7tgk
2022-10-13 18:13:17.269741: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-10-13 18:13:17.291178: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2022-10-13 18:13:18.176412: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: C:\Users\eelfahsi\AppData\Local\Temp\tmp731h7tgk
2022-10-13 18:13:18.475762: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1477588 microseconds.
2022-10-13 18:13:19.015757: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
Found 7390 files belonging to 1 classes.
fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9

Process finished with exit code 0

```

**Standalone code to reproduce the issue** 
Here is a colab link with the code used to:
- generate the model that include leaky relu op.
- quantize and save the model in int8 ops.

Colab code Link: https://colab.research.google.com/drive/1xmktQACGQ6GnMmrwco3bNXcmJIDjt5PK?usp=sharing

**Link to the quantized model:**
[my_quant_model_leaky_relu.zip](https://github.com/tensorflow/tensorflow/files/9815061/my_quant_model_leaky_relu.zip)

The tool below from Tensorflow allow to run any model, when running the model above, it fails because 'LeakyRelu' is not supported.

**Link to TensorFlow Benchmark**:
https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model

tflite benchmark command line:
```
./tf_benchmark --graph=/data/local/tmp/my_quant_model_leaky_relu.tflite  --require_full_delegation=true --use_hexagon=true --hexagon_lib_path=/data/local/tmp/

```
When performing the inference on dsp using Tensorflow lite Benchmark tool for android, we get the following error message:
```
./tf_benchmark  --use_hexagon=true --graph=./my_quant_model_leaky_relu.tflite   --require_full_delegation=true --hexagon_lib_path=/data/local/tmp/          <
STARTING!
Log parameter values verbosely: [0]
Graph: [./my_quant_model_leaky_relu.tflite]
Require full delegation: [1]
Use Hexagon: [1]
Hexagon lib path: [/data/local/tmp/]
Loaded model ./my_quant_model_leaky_relu.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libcdsprpc.so
Hexagon delegate created.
INFO: TfLiteHexagonDelegate delegate: 6 nodes delegated out of 12 nodes with 5 partitions.

VERBOSE: Replacing 6 node(s) with delegate (TfLiteHexagonDelegate) node, yielding 6 partitions.
Disallowed CPU fallback detected.
Benchmarking failed.
```

If I disable the usage of the dsp, then it works properly
tflite benchmark command line:
```
./tf_benchmark --graph=/data/local/tmp/my_quant_model_leaky_relu.tflite 
```
Logs
```
./tf_benchmark  --graph=./my_quant_model_leaky_relu.tflite                                                                          
STARTING!
Log parameter values verbosely: [0]
Graph: [./my_quant_model_leaky_relu.tflite]
Loaded model ./my_quant_model_leaky_relu.tflite
INFO: Initialized TensorFlow Lite runtime.
The input model file size (MB): 0.038384
Initialized session in 0.57ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=1141 first=4613 curr=428 min=427 max=4613 avg=438.004 std=125

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=2311 first=433 curr=428 min=427 max=627 avg=432.374 std=14

Inference timings in us: Init: 570, First inference: 4613, Warmup (avg): 438.004, Inference (avg): 432.374
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=0 overall=3.09766
...
```

If I replace leakyRelu by Relu, then it works properly
Here is a colab link with the code used to:
- generate the model that include relu op.
- quantize and save the model in int8 ops.

Colab code Link: https://colab.research.google.com/drive/1PZjt4BkFDP5EXAcVEi5N3Q4mYlfaawQP?usp=sharing

**Link to the quantized model:**
[my_quant_model_relu.zip](https://github.com/tensorflow/tensorflow/files/9815007/my_quant_model_relu.zip)

tflite benchmark command line:
```
./tf_benchmark  --use_hexagon=true --graph=./my_quant_model_relu.tflite   --require_full_delegation=true --hexagon_lib_path=/data/local/tmp/
```
Logs
```
./tf_benchmark  --use_hexagon=true --graph=./my_quant_model_relu.tflite   --require_full_delegation=true --hexagon_lib_path=/data/local/tmp/                                                             <
STARTING!
Log parameter values verbosely: [0]
Graph: [./my_quant_model_relu.tflite]
Require full delegation: [1]
Use Hexagon: [1]
Hexagon lib path: [/data/local/tmp/]
Loaded model ./my_quant_model_relu.tflite
INFO: Initialized TensorFlow Lite runtime.
loaded libcdsprpc.so
Hexagon delegate created.
INFO: TfLiteHexagonDelegate delegate: 8 nodes delegated out of 8 nodes with 1 partitions.

VERBOSE: Replacing 8 node(s) with delegate (TfLiteHexagonDelegate) node, yielding 1 partitions.
Explicitly applied Hexagon delegate, and the model graph will be completely executed by the delegate.
The input model file size (MB): 0.0374
Initialized session in 174.22ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=918 first=796 curr=537 min=324 max=3378 avg=540.937 std=180

Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=1754 first=701 curr=537 min=443 max=2552 avg=565.409 std=136

Inference timings in us: Init: 174220, First inference: 796, Warmup (avg): 540.937, Inference (avg): 565.409
Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Memory footprint delta from the start of the tool (MB): init=3.48047 overall=3.48047


```
"
58155,Tensorflow does not build with incompatible_disallow_empty_glob,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

master

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

master + --incompatible_disallow_empty_glob

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensorflow does not build with incompatible_disallow_empty_glob

https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/1301#0183e377-b3bf-4648-8470-e7a0d37f4a04
```


### Standalone code to reproduce the issue

```shell
https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/1301#0183e377-b3bf-4648-8470-e7a0d37f4a04
```


### Relevant log output

```shell
https://buildkite.com/bazel/bazelisk-plus-incompatible-flags/builds/1301#0183e377-b3bf-4648-8470-e7a0d37f4a04
```
</details>"
58153,Op:HashTableV2 Support on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.8.0

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When I try to force either IntegerLookups or StringLookups to happen on the GPU, the program errors out. The issue seems to be that the Op:HashTableV2 isn't supported on GPUs. Is it possible to support their implementation on GPUs? If not, is it possible to provide some pointers on how I could create a PR to support GPU implementation myself? Thanks! Please let me know if I can provide any additional information to clarify. Thanks!
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.config.set_soft_device_placement(False)
tf.debugging.set_log_device_placement(True)
with tf.device('/GPU:0'):
    vocab = [""a"", ""b"", ""c"", ""d""]
    data = tf.constant([[""a"", ""c"", ""d"", ""d""], [""d"", ""z"", ""b"", ""z""]])
    layer = tf.keras.layers.StringLookup(
        vocabulary=vocab, output_mode='count')
    layer(data)


import tensorflow as tf
tf.config.set_soft_device_placement(False)
tf.debugging.set_log_device_placement(True)
with tf.device('/GPU:0'):
    vocab = [12, 36, 1138, 42]
    data = tf.constant([[12, 1138, 42, 42],[42, 7, 36, 7]]) # Note OOV tokens
    layer = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='count')
    layer(data)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""<stdin>"", line 4, in <module>
  File ""/home/jovyan/.local/lib/python3.8/site-packages/keras/layers/preprocessing/string_lookup.py"", line 326, in __init__
    super(StringLookup, self).__init__(
  File ""/home/jovyan/.local/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py"", line 289, in __init__
    self.set_vocabulary(vocabulary, idf_weights)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py"", line 485, in set_vocabulary
    self.lookup_table = self._lookup_table_from_tokens(tokens)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/keras/layers/preprocessing/index_lookup.py"", line 707, in _lookup_table_from_tokens
    return tf.lookup.StaticHashTable(initializer, self._default_value)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/resource.py"", line 104, in __call__
    return previous_getter(*args, **kwargs)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/resource.py"", line 99, in <lambda>
    previous_getter = lambda *a, **kw: default_resource_creator(None, *a, **kw)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/resource.py"", line 96, in default_resource_creator
    obj.__init__(*a, **kw)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/ops/lookup_ops.py"", line 348, in __init__
    super(StaticHashTable, self).__init__(default_value, initializer)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/ops/lookup_ops.py"", line 199, in __init__
    self._resource_handle = self._create_resource()
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/ops/lookup_ops.py"", line 358, in _create_resource
    table_ref = gen_lookup_ops.hash_table_v2(
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_lookup_ops.py"", line 466, in hash_table_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/jovyan/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 7186, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Could not satisfy device specification '/job:localhost/replica:0/task:0/device:GPU:0'. enable_soft_placement=0. Supported device types [CPU]. All available devices [/job:localhost/replica:0/task:0/device:GPU:0, /job:localhost/replica:0/task:0/device:CPU:0]. [Op:HashTableV2] name: hash_table
```
</details>"
58151,Keras model breaks upon saving and loading when input is broadcasted,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8.1

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18

### Mobile device

_No response_

### Python version

3.7.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

When defining a Keras model using functional API, the model accepts inputs that need to be broadcasted to the predefined input shape. But after saving and loading the model, it suddenly throws an error. 

This only appears if the input shape is defined ""wrongly"", i.e. Keras needs to broadcast the actual input to fit to the predefined input shape. Still, I would expect the model not to change behaviour after saving and loading at all. 

This bug can be quite devastating as during long training runs, you would not notice any problems. When loading the model later to evaluate, it would suddenly break, however.


### Standalone code to reproduce the issue

```shell
# Model works with an input, then breaks with the same input after you save and load it
# Must be related to the broadcasting happening with the language input (as it is wrongly set to (None,) instead of ())

import tensorflow as tf


class InnerModel(tf.keras.Model):
    def __init__(self) -> None:
        super().__init__()
        # Optionally some layers here

    def call(self, inputs: tf.Tensor, training: bool) -> tf.Tensor:
        audio, lang = inputs
        # Optionally some processing here
        return lang


def get_model():
    audio = tf.keras.Input(shape=(None, 1))
    lang = tf.keras.Input(shape=(None,), dtype=tf.string)  # Fixed by setting shape=()
    inner_model = InnerModel()
    out = inner_model([audio, lang])
    return tf.keras.Model(inputs=[audio, lang], outputs=[out])


model = get_model()
_ = model([tf.zeros((1, 1000, 1)), tf.constant([""fr""])], training=False)

# Save + load
model.save(""test"")  # Also breaks with tf.keras.models.save_model(model, ""test"")
model = tf.keras.models.load_model(""test"")

# Do inference again
_ = model([tf.zeros((1, 1000, 1)), tf.constant([""fr""])], training=False)
```


### Relevant log output

```shell
/Users/dstoller/.pyenv/versions/lyric-align-baseline/bin/python /Users/dstoller/IdeaProjects/lyric-align-baseline/lyric_align_baseline/keras_shape_bug.py
2022-10-15 15:27:20.163674: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2022-10-15 15:27:20.361789: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.
Traceback (most recent call last):
  File ""/Users/dstoller/IdeaProjects/lyric-align-baseline/lyric_align_baseline/keras_shape_bug.py"", line 31, in <module>
    _ = model([tf.zeros((1, 1000, 1)), tf.constant([""fr""])], training=False)
  File ""/Users/dstoller/.pyenv/versions/lyric-align-baseline/lib/python3.7/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/Users/dstoller/.pyenv/versions/lyric-align-baseline/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 284, in restored_function_body
    ""Could not find matching concrete function to call loaded from the ""
ValueError: Exception encountered when calling layer ""inner_model"" (type InnerModel).

Could not find matching concrete function to call loaded from the SavedModel. Got:
  Positional arguments (2 total):
    * [<tf.Tensor 'inputs:0' shape=(1, 1000, 1) dtype=float32>, <tf.Tensor 'inputs_1:0' shape=(1,) dtype=string>]
    * False
  Keyword arguments: {}

 Expected these arguments to match one of the following 4 option(s):

Option 1:
  Positional arguments (2 total):
    * [TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.string, name='inputs/1')]
    * False
  Keyword arguments: {}

Option 2:
  Positional arguments (2 total):
    * [TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.string, name='inputs/1')]
    * True
  Keyword arguments: {}

Option 3:
  Positional arguments (2 total):
    * [TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='input_1'), TensorSpec(shape=(None, None), dtype=tf.string, name='input_2')]
    * False
  Keyword arguments: {}

Option 4:
  Positional arguments (2 total):
    * [TensorSpec(shape=(None, None, 1), dtype=tf.float32, name='input_1'), TensorSpec(shape=(None, None), dtype=tf.string, name='input_2')]
    * True
  Keyword arguments: {}

Call arguments received:
  • args=(['tf.Tensor(shape=(1, 1000, 1), dtype=float32)', 'tf.Tensor(shape=(1,), dtype=string)'],)
  • kwargs={'training': 'False'}

Process finished with exit code 1
```
</details>"
58146,Incorrect output of LayerNormalization,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

MacOS 12.2.1

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
LayerNormalization doesn't output correct results for certain inputs.
```


### Standalone code to reproduce the issue

```shell
script:
 x = tf.constant([0.09484422, 0.16441762])
 layer = tf.keras.layers.LayerNormalization()
 layer(x)

output:
 <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.73995596,  0.73995596], dtype=float32)>

This result is incorrect, it should be close to [-1., 1.].
```


### Relevant log output

_No response_</details>"
58143,Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1024 != 1633876594),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf2.3/2.8

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

android

### Python version

3.6/3.7

### Bazel version

4.2.1

### GCC/Compiler version

gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) 

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Native crash.
```


### Standalone code to reproduce the issue

```shell
The code cannot be shared due to company privacy regulations and I would like to know the possible reasons for this type of issue.
```


### Relevant log output

```shell
For tflite2.3:
Abort message: 'Scudo ERROR: race on chunk header at address 0x007b45478370
/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+100)
...
FORTIFY: pthread_mutex_lock called on a destroyed mutex (0x7dc6aeab18)
...
Abort message: 'Scudo ERROR: race on chunk header at address 0x007b4546caf0
Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (1024 != 1633876594)

For tflite2.8:
Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/reshape.cc:85 num_input_elements != num_output_elements (1024 != 1407367860)
...
```
</details>"
58142,XLA CPU performance issues,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

2.10 and 2.11 branch

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.6

### Bazel version

5.3.0

### GCC/Compiler version

12.1

### CUDA/cuDNN version

None

### GPU model and memory

None

### Current Behaviour?

```shell
CPU only.

I try to enable xla on my models, but found it became slower.

I found: without xla, tf can use all cores(8 for my case), there are enough ops to distributed across multiple cores.
but when enable xla, critical path became `_XlaRun`, and it seems to run in single thread.

I tried `--tf_xla_max_cluster_size=10`, and still slower. 

I want to know if this result is as expected, and if there is anyway to make xla utilize all cores.
```
"
58141,"[[Func/training_2/SGD/gradients/gradients/batch_normalization_109/cond_grad/StatelessIf/else/_10305/input/_27305/_3781]]   (1) Failed precondition: Could not find variable batch_normalization_100/gamma. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status=Not found: Resource localhost/batch_normalization_100/gamma/N10tensorflow3VarE does not exist. 	 [[{{node ReadVariableOp}}]] 0 successful operations. 0 derived errors ignored","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

RTX2080

### Current Behaviour?

```shell
I expect the model training to begins
```


### Standalone code to reproduce the issue

```shell
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 112, 112, 64  9472        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 112, 112, 64  256        ['conv2d[0][0]']                 
 alization)                     )                                                                 
                                                                                                  
 activation (Activation)        (None, 112, 112, 64  0           ['batch_normalization[0][0]']    
                                )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['activation[0][0]']             
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 56, 56, 64)  256         ['max_pooling2d[0][0]']          
 rmalization)                                                                                     
                                                                                                  
 activation_1 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_1[0][0]']  
                                                                                                  
 conv2d_1 (Conv2D)              (None, 56, 56, 64)   4160        ['activation_1[0][0]']           
                                                                                                  
...
Total params: 47,705,989
Trainable params: 47,644,549
Non-trainable params: 61,440
```


### Relevant log output

_No response_</details>"
58140,"Increased memory usage while loading model graph  and observed a drop in performance throughput , When upgrade from TF version 2.8.0 to  either 2.8.1 or 2.9.1","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

2.9.1 , 2.8.1

### Custom Code

Yes

### OS Platform and Distribution

Red Hat Enterprise Linux release 8.6 (Ootpa)

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
we have a docker container with memory 1.5GB  where  we load our Custom RetinaNet Model and use it for inference.
We were using the Tensorflow version 2.8.0 and everything was working fine. 

Due to the vulnerabilities ,  we  tried upgrading to Minor version 2.9.1. But we are getting SIGKILL - out of memory error during the load of the model graph. When checked the Docker stats, we could see that the memory usage is crossing the existing 1.5GB.  There is no other code changes other than the version upgrade.

After increasing the pod memory to 4GB we are able to load the model graph and get the inference. The same behaviour is seen when we try to upgrade version 2.8.1 as well.

We also see the  time taken for inference has increased about 40% when we upgrade the version from 2.8 to 2.9.1

```


### Standalone code to reproduce the issue

```shell
1) Load a Retinanet Model  with Tensorflow version 2.8.0 in a docker container with memory 1.5GB
2) Load the same Retinanet model with Tensorflow version 2.8.1/2.9.1  in a docker container with the  memory 1.5GB
3) Load the same Retinanet model with Tensorflow version 2.8.1/2.9.1  in a docker container with the  memory 4GB

In this case you can see that the step1 will succeed and in step2 it will crash due to out of memory. Step3 will succeed.
```


### Relevant log output

```shell
2022-10-12 00:33:08.206766: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-10-12 00:33:08.894968: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28753920 exceeds 10% of free system memory.
2022-10-12 00:33:09.311896: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28753920 exceeds 10% of free system memory.
2022-10-12 00:33:12.049115: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28753920 exceeds 10% of free system memory.
2022-10-12 00:33:12.279661: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28753920 exceeds 10% of free system memory.
2022-10-12 00:33:13.079146: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28753920 exceeds 10% of free system memory.
2022-10-12 00:33:16,694 INFO reaped unknown pid 8697 (exit status 0)
Process 'ForkPoolWorker-1' pid:133 exited with 'signal 9 (SIGKILL)'
```
</details>"
58139,zeta gives inconsistent results with scipy,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.math.zeta` gives inconsistent results with numpy:
- on CPU: gives -148382460000000.0
- on GPU: gives 52.117622
- scipy: gives 74.58897854509347
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
x = 5.
q = -9.59183673
with tf.device('gpu'):
    print(tf.math.zeta(x=x, q=q)) # gives 52.117622
with tf.device('cpu'): 
    print(tf.math.zeta(x=x, q=q)) # gives -148382460000000.0
from scipy.special import zeta
print(zeta(x,q=q)) # gives 74.58897854509347
```


### Relevant log output

```shell
tf.Tensor(52.117622, shape=(), dtype=float32)
tf.Tensor(-148382460000000.0, shape=(), dtype=float32)
74.58897854509347
```
</details>"
58138,Support `bfloat16` without mixed precision,"### Describe the problem
I'm looking to train model with `bfloat16` datatype without having to use mixed precision on nvidia GPUs (A100 and beyond). This is important because directly using `bfloat16` datatype for all weights and intermediate tensors, I can reduce the memory by almost half compared to float32. I noticed I can set the float type using `tf.keras.backend.set_floatx()` API, however it currently does not support `bfloat16` datatype. 

Is this currently supported by tensorflow? If not, can this issue be considered as a feature request for the same?

Thanks
"
58135,XLA compiler error: left_branch_shape.rank() == right_branch_shape.rank(),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cudatoolkit=11.2 cudnn=8.1.0

### GPU model and memory

GTX 1080 TI

### Current Behaviour?


XLA compiler error for this model when `jit_compile=True`

It's very hard to determine the cause of the error, as the model works fine when running normally.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np


class Chooser(tf.keras.layers.Layer):
    @tf.function
    def call(self, options_input, choices_input_logits):
        choices = tf.nn.softmax(choices_input_logits, axis=2)

        result = tf.linalg.matmul(choices, options_input)
        return result

def get_model():
    options_input = tf.keras.layers.Input(shape=(10,3), name=""options"")
    choices_input = tf.keras.layers.Input(shape=(5,10), name=""choices"")

    net = Chooser()(options_input, choices_input)
    net = tf.keras.layers.Flatten()(net)
    net = tf.keras.layers.Dense(1)(net)

    return tf.keras.Model([options_input, choices_input], net)

model = get_model()
model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tf.keras.losses.MeanAbsoluteError(),
    jit_compile=True
)

def batch_gen():
    while True:
        o = np.random.uniform(low=-1.0, high=1.0, size=(10, 3))
        c = np.random.uniform(low=0.0, high=1.0, size=(5, 10))

        y = 1

        yield {""options"": o, ""choices"": c}, y

dataset = tf.data.Dataset.from_generator(batch_gen, output_types=({""options"": tf.float32, ""choices"": tf.float32}, tf.float32))
dataset = dataset.batch(32)

model.fit(dataset, steps_per_epoch=100, epochs=1)
```


### Relevant log output

```shell
tensorflow/compiler/xla/client/lib/dynamic_shaped_ops.cc:92] Check failed: left_branch_shape.rank() == right_branch_shape.rank() (1 vs. 2)left rank of (1) vs. right rank of (2)
```
</details>"
58134,AttributeError: module 'tensorflow._api.v2.train' has no attribute 'summary_iterator',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

window 11 22h

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
this is my code 

import tensorflow as tf

for e in tf.train.summary_iterator(""events.out.tfevents.1665558822.NIRAN.13044.0""):
    for v in e.summary.value:
        if v.tag == 'loss' or v.tag == 'accuracy':
            print(v.simple_value)

where i got the code : https://docs.w3cub.com/tensorflow~python/tf/train/summary_iterator
it like the same on this web. but i dont know why it error. i not found this error on internet
```


### Relevant log output

```shell
AttributeError: module 'tensorflow._api.v2.train' has no attribute 'summary_iterator'
```
</details>"
58133,`tf.range` have accumulate floating point error on CPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

`tf.range` have accumulate greater and greater floating point error on CPU. In the example below, `range(- 10, 10, 0.01)` gives `[... 9.980267 9.990267]` when the correct result should be `[... 9.98 9.99]`, and this deviation is too much in my opinion.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
with tf.device('cpu'):
    tensor1 = tf.range(- 10, 10, 0.01) # [-10., -9.99 ... 9.980267 9.990267]
    print(tensor1)
with tf.device('gpu'):
    tensor2 = tf.range(- 10, 10, 0.01) # [-10., -9.99 ... 9.98 9.99]
    print(tensor2)
assert np.allclose(tensor1, tensor2) # AssertionError
```


### Relevant log output

```shell
tf.Tensor([-10.        -9.99      -9.98     ...   9.970266   9.980267   9.990267], shape=(2000,), dtype=float32)
tf.Tensor([-10.        -9.99      -9.98     ...   9.969999   9.98       9.99    ], shape=(2000,), dtype=float32)
AssertionError
```
</details>"
58131,`tf.scan` has inconsistent result on CPU/GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.scan` has inconsistent result on CPU/GPU:
- on CPU: [[10 20 30] [ 0  0  0]]
- on GPU: [[10 20 30] [ 5332261958806667264 -8722786653543858176 -4459375070678089728]]
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
with tf.device('cpu'):
    input_data = np.array([[10, 20, 30], [11, 12, 13]])
    result = tf.scan((lambda a, x: (a ** (x ** 2))), input_data)
    o = result.numpy()
    print(o)
with tf.device('gpu'):
    input_data = np.array([[10, 20, 30], [11, 12, 13]])
    result = tf.scan((lambda a, x: (a ** (x ** 2))), input_data)
    o = result.numpy()
    print(o)
```


### Relevant log output

```shell
[[10 20 30] [ 0  0  0]]
[[10 20 30] [ 5332261958806667264 -8722786653543858176 -4459375070678089728]]
```
</details>"
58127,Inconsistent behavior of gpu /cpu/numpy in int32 casting ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.cast(nan, tf.int32)` has inconsistent behaviour on gpu and cpu:
- on cpu: -9223372036854775808, same as numpy
- on gpu: 0

related issue: https://github.com/tensorflow/tensorflow/issues/57883
```


### Standalone code to reproduce the issue

```shell
# For int64 casting, only gpu produces 0
with tf.device('cpu'):
    print(tf.cast(np.nan, np.int32)) 
with tf.device('gpu'):
    print(tf.cast(np.nan, np.int32))
print(np.array(np.nan).astype(np.int32))

# For int64 casting, all results are consistent -9223372036854775808
with tf.device('cpu'):
    print(tf.cast(np.nan, np.int64))
with tf.device('gpu'):
    print(tf.cast(np.nan, np.int64))
print(np.array(np.nan).astype(np.int64))
```


### Relevant log output

```shell
tf.Tensor(-2147483648, shape=(), dtype=int32)
tf.Tensor(0, shape=(), dtype=int32)
-2147483648
tf.Tensor(-9223372036854775808, shape=(), dtype=int64)
tf.Tensor(-9223372036854775808, shape=(), dtype=int64)
-9223372036854775808
```
</details>"
58126,TF Lite CMake Failes to Download neon2sse on Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When building TF Lite from Source via CMake on Windows, the download of neon2sse from storageapis.google.com (defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/cmake/modules/neon2sse.cmake)  fails with an SSL error (see log output below).

This failure appears to be specific to Windows, and reproduces in CMake 3.21 and 3.24 (latest stable), which suggests something changed in the googleapis endpoint. Changing the download from https to http works around the issue.
```


### Standalone code to reproduce the issue

```shell
Build TF Lite from source on Windows
```


### Relevant log output

```shell
status_code: 35
            status_string: ""SSL connect error""
            log:
            --- LOG BEGIN ---
            timeout on name lookup is not supported
      Trying 64.233.181.128:443...
  
    Connected to storage.googleapis.com (64.233.181.128) port 443 (#0)
  
    schannel: ALPN, offering h2
  
    schannel: ALPN, offering http/1.1
  
    schannel: next InitializeSecurityContext failed: SEC_E_ILLEGAL_MESSAGE
    (0x80090326) - This error usually occurs when a fatal SSL/TLS alert is
    received (e.g.  handshake failed).  More detail may be available in the
    Windows System event log.
  
    Closing connection 0
  
    schannel: shutting down SSL/TLS connection with storage.googleapis.com port
    443
```
</details>"
58125,Kernel crash/restart during conversion with `tf.lite.TFLiteConverter.experimental_from_jax`: Segmentation fault [...] Address not mapped,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installation (pip package or built from source): Google Colab pre-installed
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.9.2

### 2. Code

Minimal end-to-end Colab: https://colab.research.google.com/gist/josephrocca/bbfff037f21a81661e92ff2b46494c04

### 5. (optional) Any other info / logs
The Colab doesn't output any logs before crashing, but I ran this on a cloud machine with 200GB RAM to ensure it wasn't a memory capacity issue, and it gave these logs:

<details>
<summary>Full logs from large machine (200GB RAM)</summary>

```
WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
--------------------------------------------------------------------------
WARNING: No preset parameters were found for the device that Open MPI
detected:

  Local host:            129-213-21-140
  Device name:           mlx5_0
  Device vendor ID:      0x02c9
  Device vendor part ID: 4126

Default device parameters will be used, which may result in lower
performance.  You can edit any of the files specified by the
btl_openib_device_param_files MCA parameter to set values for your
device.

NOTE: You can turn off this warning by setting the MCA parameter
      btl_openib_warn_no_device_params_found to 0.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
No OpenFabrics connection schemes reported that they were able to be
used on a specific port.  As such, the openib BTL (OpenFabrics
support) will be disabled for this port.

  Local host:           129-213-21-140
  Local device:         mlx5_0
  Local port:           1
  CPCs attempted:       udcm
--------------------------------------------------------------------------
[129-213-21-140:01747] *** Process received signal ***
[129-213-21-140:01747] Signal: Segmentation fault (11)
[129-213-21-140:01747] Signal code: Address not mapped (1)
[129-213-21-140:01747] Failing at address: 0x18
[129-213-21-140:01747] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x43090)[0x7f9d4326e090]
[129-213-21-140:01747] [ 1] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.cpython-38-x86_64-linux-gnu.so(+0x1232da64)[0x7f994b45ea64]
[129-213-21-140:01747] [ 2] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.cpython-38-x86_64-linux-gnu.so(_ZN10tensorflow28ConvertJaxToTFLiteFlatBufferERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKN4toco10ModelFlagsERKNS8_9TocoFlagsEPS5_+0x113a)[0x7f993d976d6a]
[129-213-21-140:01747] [ 3] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.cpython-38-x86_64-linux-gnu.so(_ZN4toco11TocoConvertEP7_objectS1_S1_bS1_b+0x488)[0x7f993d817cf8]
[129-213-21-140:01747] [ 4] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_toco_api.cpython-38-x86_64-linux-gnu.so(+0xac76)[0x7f9d21dadc76]
[129-213-21-140:01747] [ 5] /usr/lib/python3/dist-packages/tensorflow/python/_pywrap_toco_api.cpython-38-x86_64-linux-gnu.so(+0x12b91)[0x7f9d21db5b91]
[129-213-21-140:01747] [ 6] python3(PyCFunction_Call+0x59)[0x5f6929]
[129-213-21-140:01747] [ 7] python3(_PyObject_MakeTpCall+0x296)[0x5f74f6]
[129-213-21-140:01747] [ 8] python3(_PyEval_EvalFrameDefault+0x5dc4)[0x571164]
[129-213-21-140:01747] [ 9] python3(_PyFunction_Vectorcall+0x1b6)[0x5f6cd6]
[129-213-21-140:01747] [10] python3(_PyEval_EvalFrameDefault+0x5786)[0x570b26]
[129-213-21-140:01747] [11] python3(_PyEval_EvalCodeWithName+0x26a)[0x569dba]
[129-213-21-140:01747] [12] python3(_PyFunction_Vectorcall+0x393)[0x5f6eb3]
[129-213-21-140:01747] [13] python3(_PyEval_EvalFrameDefault+0x187f)[0x56cc1f]
[129-213-21-140:01747] [14] python3(_PyEval_EvalCodeWithName+0x26a)[0x569dba]
[129-213-21-140:01747] [15] python3(_PyFunction_Vectorcall+0x393)[0x5f6eb3]
[129-213-21-140:01747] [16] python3(PyObject_Call+0x62)[0x5f6082]
[129-213-21-140:01747] [17] python3(_PyEval_EvalFrameDefault+0x1f35)[0x56d2d5]
[129-213-21-140:01747] [18] python3(_PyEval_EvalCodeWithName+0x26a)[0x569dba]
[129-213-21-140:01747] [19] python3(_PyFunction_Vectorcall+0x393)[0x5f6eb3]
[129-213-21-140:01747] [20] python3(PyObject_Call+0x62)[0x5f6082]
[129-213-21-140:01747] [21] python3(_PyEval_EvalFrameDefault+0x1f35)[0x56d2d5]
[129-213-21-140:01747] [22] python3(_PyFunction_Vectorcall+0x1b6)[0x5f6cd6]
[129-213-21-140:01747] [23] python3(PyObject_Call+0x62)[0x5f6082]
[129-213-21-140:01747] [24] python3(_PyEval_EvalFrameDefault+0x1f35)[0x56d2d5]
[129-213-21-140:01747] [25] python3(_PyEval_EvalCodeWithName+0x26a)[0x569dba]
[129-213-21-140:01747] [26] python3(_PyFunction_Vectorcall+0x393)[0x5f6eb3]
[129-213-21-140:01747] [27] python3[0x50bc2c]
[129-213-21-140:01747] [28] python3(PyObject_Call+0x62)[0x5f6082]
[129-213-21-140:01747] [29] python3(_PyEval_EvalFrameDefault+0x1f35)[0x56d2d5]
[129-213-21-140:01747] *** End of error message ***
Segmentation fault (core dumped)
```
</details>
"
58124,Failed to compile TF 2.10.0 from source on Ubuntu 20.04: symbol lookup error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

5.1.1

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

-

### GPU model and memory

128 GB

### Current Behaviour?

```shell
Hi folks,

I've been trying to compile TF C++ API from source using bazel 5.1.1 and gcc 9.4.0 on Ubuntu 20.04 with newer ABI and then I ran into an error about symbol lookup error shown below. I also tried compiling TF 2.9.0 using bazel 5.0.0 but and always get the same error. Any ideas to solve the issue?
```


### Standalone code to reproduce the issue

```shell
bazel build --jobs=24 --local_ram_resources=""HOST_RAM*.50"" --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=1"" -c opt  --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow:libtensorflow.so //tensorflow:libtensorflow_cc.so //tensorflow:libtensorflow_framework.so //tensorflow:install_headers
```
```


### Relevant log output

```shell
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=102
INFO: Reading rc options for 'build' from /home/ubuntu/tensorflow-2.10.0/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/ubuntu/tensorflow-2.10.0/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:noaws in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --define=no_aws_support=true
INFO: Found applicable config definition build:nogcp in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --define=no_gcp_support=true
INFO: Found applicable config definition build:nohdfs in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --define=no_hdfs_support=true
INFO: Found applicable config definition build:nonccl in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:linux in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/ubuntu/tensorflow-2.10.0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/6ca793b5d862ef6c50f242d77a811f06cce9b60a.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/0538e5431afdb1fa05bdcedf70ee502ccfcd112a.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
INFO: Analyzed 4 targets (272 packages loaded, 20804 targets configured).
INFO: Found 4 targets...
ERROR: /home/ubuntu/tensorflow-2.10.0/tensorflow/cc/BUILD:677:22: Executing genrule //tensorflow/cc:control_flow_ops_genrule failed: (Exit 127): bash failed: error executing command /bin/bash bazel-out/k8-opt/bin/tensorflow/cc/control_flow_ops_genrule.genrule_script.sh
bazel-out/k8-opt/bin/tensorflow/cc/ops/control_flow_ops_gen_cc: symbol lookup error: bazel-out/k8-opt/bin/tensorflow/cc/ops/control_flow_ops_gen_cc: undefined symbol: _ZN4absl12lts_202206239ByAnyCharC1ESt17basic_string_viewIcSt11char_traitsIcEE
ERROR: /home/ubuntu/tensorflow-2.10.0/tensorflow/cc/BUILD:677:22: Executing genrule //tensorflow/cc:parsing_ops_genrule failed: (Exit 127): bash failed: error executing command /bin/bash bazel-out/k8-opt/bin/tensorflow/cc/parsing_ops_genrule.genrule_script.sh
bazel-out/k8-opt/bin/tensorflow/cc/ops/parsing_ops_gen_cc: symbol lookup error: bazel-out/k8-opt/bin/tensorflow/cc/ops/parsing_ops_gen_cc: undefined symbol: _ZN4absl12lts_202206239ByAnyCharC1ESt17basic_string_viewIcSt11char_traitsIcEE
INFO: Elapsed time: 1482.746s, Critical Path: 227.21s
INFO: 8330 processes: 654 internal, 7676 local.
FAILED: Build did NOT complete successfully
```
</details>"
58123,segment max does not output zero for empty segment,"### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
According to document, if the max is empty for a given segment ID i, output[i] = 0. However, on gpu it gives a large negative value for empty segment ID.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [4, 3, 2, 1], [8, 7, 6, 5]])
segment_ids = [1, 2, 3, 4]
segment_ids = tf.constant(segment_ids, dtype=tf.int32)
data = tf.constant(data, dtype=tf.float32)
with tf.device('gpu'):
    output = tf.raw_ops.SegmentMax(data=data, segment_ids=segment_ids)
    print(output.numpy())
    output = tf.math.segment_max(data=data, segment_ids=segment_ids)
    print(output.numpy())
with tf.device('cpu'):
    output = tf.raw_ops.SegmentMax(data=data, segment_ids=segment_ids)
    print(output.numpy())
    output = tf.math.segment_max(data=data, segment_ids=segment_ids)
    print(output.numpy())
```


### Relevant log output

```shell
[[-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 -3.4028235e+38]
 [ 1.0000000e+00  2.0000000e+00  3.0000000e+00  4.0000000e+00]
 [ 5.0000000e+00  6.0000000e+00  7.0000000e+00  8.0000000e+00]
 [ 4.0000000e+00  3.0000000e+00  2.0000000e+00  1.0000000e+00]
 [ 8.0000000e+00  7.0000000e+00  6.0000000e+00  5.0000000e+00]]
[[-3.4028235e+38 -3.4028235e+38 -3.4028235e+38 -3.4028235e+38]
 [ 1.0000000e+00  2.0000000e+00  3.0000000e+00  4.0000000e+00]
 [ 5.0000000e+00  6.0000000e+00  7.0000000e+00  8.0000000e+00]
 [ 4.0000000e+00  3.0000000e+00  2.0000000e+00  1.0000000e+00]
 [ 8.0000000e+00  7.0000000e+00  6.0000000e+00  5.0000000e+00]]
[[0. 0. 0. 0.]
 [1. 2. 3. 4.]
 [5. 6. 7. 8.]
 [4. 3. 2. 1.]
 [8. 7. 6. 5.]]
[[0. 0. 0. 0.]
 [1. 2. 3. 4.]
 [5. 6. 7. 8.]
 [4. 3. 2. 1.]
 [8. 7. 6. 5.]]
```
"
58122,tf.nn.local_response_normalization lack validation for depth_radius on cpu,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.nn.local_response_normalization lack validation for depth_radius on cpu. depth_radius needs to be an integer as it is the half-width of the 1-D normalization window. However, on cpu it accepts value `0.1`. By contrast, on gpu it can throw error: `requires depth_radius in [1, 7]`.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
input = tf.constant([[[[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0], [9.0, 10.0, 11.0, 12.0], [13.0, 14.0, 15.0, 16.0]]]])
depth_radius = 0.1
bias = 1.0
alpha = 0.5
beta = 0.5
with tf.device(""cpu""):
    output = tf.nn.local_response_normalization(input=input, depth_radius=depth_radius, bias=bias, alpha=alpha, beta=beta)
    print(output) # pass

with tf.device(""gpu""):
    output = tf.nn.local_response_normalization(input=input, depth_radius=depth_radius, bias=bias, alpha=alpha, beta=beta)
    print(output) # error
```


### Relevant log output

```shell
tf.Tensor(
[[[[0.8164966 1.1547005 1.2792044 1.3333334]
   [1.3608277 1.3764944 1.3862065 1.3926213]
   [1.3970708 1.40028   1.4026688 1.4044938]
   [1.405919  1.4070529 1.4079696 1.4087214]]]], shape=(1, 1, 4, 4), dtype=float32)
tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__LRN_device_/job:localhost/replica:0/task:0/device:GPU:0}} cuDNN requires depth_radius in [1, 7], got: 0 [Op:LRN]
```
</details>"
58120,model.fit()  is loading entire data even after providing batch_size,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.4.1

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I have two numpy arrays ([[512 dim vector],[512 dim vector],..,[512 dim vector]] - array looks like this) of shape (55M * 512) which are being used as features in my model.I am not able to train the model because of memory error.I put batch_size = 1024.But model.fit() is loading the entire data to the memory.
```


### Standalone code to reproduce the issue

```shell
def create_model():

    all_inputs = []
    output = []   
    text_input_1 = layers.Input(shape=(512,),name='text_1')
    
    mul = 0.56
    num_neuron = int(512*mul)
    text_output_1=layers.Dense(num_neuron, input_dim=(512), activation='relu')(text_input_1)
    all_inputs.append(text_input_1)
    
    text_input_2 = layers.Input(shape=(512,),name='text_2')
    text_output_2=layers.Dense(128, input_dim=(512), activation='relu')(text_input_2)    
    all_inputs.append(text_input_2)
    
    embedding_power= 0.49

    for c in cat_feat:
        num_unique_values = int(df_train[c].nunique())
        embed_dim = int(num_unique_values**embedding_power)#int(min(np.ceil((num_unique_values)/2), 50))
        inp = layers.Input(shape=(1,))
        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)
        out = layers.SpatialDropout1D(0.3)(out)
        out = layers.Reshape(target_shape=(embed_dim, ))(out)
        all_inputs.append(inp)
        output.append(out)    

    conc = layers.Concatenate()(output)
    x = layers.concatenate([conc, text_output_1,text_output_2],name='concat_of_text_and_cat_feat')
    
    
    # layer 0
    l = x.shape[1]
    num_hidden = int(0.553*l)
    x = layers.Dense(num_hidden,kernel_initializer='he_uniform',activation='relu')(x)
    x = layers.BatchNormalization()(x)
    
    # layer 1

    l = x.shape[1]
    num_hidden = int(0.483*l)
    x = layers.Dense(num_hidden,kernel_initializer='he_uniform',activation='relu')(x)
    x = layers.Dropout(0.15)(x)
    x = layers.BatchNormalization()(x)
    
    # layer 2

    l = x.shape[1]
    num_hidden = int(0.590*l)
    x = layers.Dense(num_hidden,kernel_initializer='he_uniform',activation='relu')(x)
    x = layers.Dropout(0.3)(x)
    x = layers.BatchNormalization()(x)
    
    preds = layers.Dense(1, activation=""sigmoid"")(x)
    model = Model(inputs=all_inputs, outputs=preds)

    # compile our model with a sampled learning rate.
    lr = 0.00012
    
    model.compile(
        loss=""binary_crossentropy"",
        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
        metrics=[""AUC""],run_eagerly=True
    )  
    return model

model = create_model()

model.fit([text_train_1,text_train_2,[df_train.loc[:,f].values for f in cat_feat_nn]],
          df_train[""target""].values,epochs=60,verbose=1,batch_size=1024)
#The last step is giving me error

How would I provide chunk of data (batch size) to the model for training instead of loading entire data to the memory ?
```


### Relevant log output

_No response_</details>"
58119,Some questions about the converted tflite model,"Hi, I can successfully convert model to tflite model, i just have some quesitons about the converted model.
1. The conversion log has `fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3`, What do these numbers (0, 6, 3) mean ?
2. Can we determine the order of model output head or how tflite determine the order of model output head ? Imagine the model have two output heads: `cls-head` and `reg-head`, I find the converted float16 and float 32 model is `cls-head` **first** `reg-head` second, but the converted uint8 model is `reg-head` **first** `cls-head` second.
3. I find the precision metric of uint8 model is better than int8 model, is there any ""scientific sense"" behind this ?
"
58117,Android (Kotlin) In Pose detection when I use front camera it display opposite mirror how to resolve it.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

a

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
facing front camera issue in Android kotlin, it's display mirror in camera. How to resolve this issue.
```


### Standalone code to reproduce the issue

```shell
facing front camera issue in Android kotlin, it's display mirror in camera. How to resolve this issue.
```


### Relevant log output

_No response_</details>"
58115,The distribution package in pypi does not match the official tensorflow website.,"As you can see in the image below, tensorflow-1.15.0 requires python version 2.7,3.3-3.7, while pypi only has python version 2.7,3.5-3.7 packages on its website.Did you forget to upload the appropriate version,how can I install tensorflow-1.15.0 by pip on python3.4？

<img width=""577"" alt=""图片1"" src=""https://user-images.githubusercontent.com/60139005/196108404-d4b8cb1b-d0e8-426a-80eb-bf641a249f95.png"">

![图片2](https://user-images.githubusercontent.com/60139005/196108846-a17a75ec-b0ec-4047-83c9-cd8145873b27.png)
"
58114,while processing Pruning by using Densely connected Layer...,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf.2.9.1

### Custom Code

Yes

### OS Platform and Distribution

window, jupyter Lab

### Mobile device

_No response_

### Python version

.3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'm trying to bring in the model and proceed with pruning and weight sharing, but I get an error saying  `ValueError: A merge layer should be called on a list of inputs. Received: inputs=Tensor(""Placeholder:0"", shape=(None, 64), dtype=float32) (not a list of tensors)`
```


### Standalone code to reproduce the issue

```shell
# weight sharing

cluster = tfmot.clustering.keras.cluster_weights

centeroid = tfmot.clustering.keras.CentroidInitialization

cluster_params = {
    'number_of_clusters' : 16,
    'cluster_centroids_init' : centeroid.LINEAR
}

cluster_model = cluster(model,**cluster_params) # Error!
```


### Relevant log output

_No response_</details>"
58112,Make EIGEN_MAX_ALIGN_BYTES available from C API,"### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

N/A

### Python version

N/A

### Bazel version

5.3.0

### GCC/Compiler version

GCC 12

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?


Is there a way to access `EIGEN_MAX_ALIGN_BYTES` from C at runtime (e.g., for use via FFI)?

I am asking because I would like to manage the memory passed in to `TF_NewTensor()` myself (for sharing between libraries), but if `data` is not aligned, it uses `memcpy()` and calls the deallocator. I can use this information to figure out the value of `EIGEN_MAX_ALIGN_BYTES` myself, but it would be nice to not have to do this.

This request is similar to <https://github.com/tensorflow/tensorflow/issues/9690> and Python's `tf.sysconfig.get_compile_flags()`.



### Standalone code to reproduce the issue

```shell
N/A
```


### Relevant log output

_No response_"
58111,Troubles with set of imports,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.2

### Custom Code

No

### OS Platform and Distribution

Collab

### Mobile device

_No response_

### Python version

3.7.14

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Some of the functionality is incompatible when using followed imports style:
- from tensorflow.keras... import ...
- from tensorflow.python.keras... import ...

When I want to import without ""python"" suffix some optimizer classes there is Value error while model compilation
```


### Standalone code to reproduce the issue

```shell
from tensorflow.keras.optimizers import Adam
from tensorflow.python.keras.optimizers import Adam

###########################
model.compile(optimizer=Adam(learning_rate=0.001), loss=""mean_squared_error"")
```


### Relevant log output

```shell
ImportError: cannot import name 'Adam' from 'tensorflow.python.keras.optimizers' (/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizers.py)

#######################################

ValueError: Could not interpret optimizer identifier: <keras.optimizers.optimizer_v2.adam.Adam object at 0x7f97d3696c90>
```
</details>"
58109,How can I make the dataset accept sequences or matrices? PLZ :),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.9

### Custom Code

Yes

### OS Platform and Distribution

MACOS

### Mobile device

_No response_

### Python version

Python 3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell

- Thank you for your contributions to TensorFlow, your work is remarkable, you are great.

- I am accustomed to using dataframe to perform certain data cleaning work first, and then create a data set through the Dataset.from_tensor_slices() method, which is very efficient.
- Today I was working with a data containing sequences and matrices, and when I used the original method, I would get an error (ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray). I understand this is because the data types in my Dataframe is not one of Int, str or float, but some sequence or matrix. I will give the data head in Dataframe below.

- Limited by my code level, I still can't solve this problem after a long time of trying. I really want to be able to solve this problem, can anyone give me some pointers? Thank you very much!

```


### Standalone code to reproduce the issue

```shell
df.head()

         A                  B                     C                   D(target)
0   [2,3,4,5]      [[0.2,-0.1 ...]...]   [[0.3,1.1 ...]...]               1

1    [6,7,8]       [[0.2,-0.1 ...]...]   [[0.3,1.1 ...]...]               0 

2 [9,10,11,12,13]  [[0.2,-0.1 ...]...]   [[0.3,1.1 ...]...]               1
```


### Relevant log output

_No response_</details>"
58108,Adding Augumentation Layer extremely slow on Tensorflow 2.9 and 2.10,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.9, tf2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
This code for adding Agumentation Layers:
        
data_augmentation = tf.keras.Sequential(
        [
            # preprocessing.RandomCrop(34, 20),
            # preprocessing.Resizing(40, 24),  
            preprocessing.RandomFlip(""horizontal""),
            preprocessing.RandomFlip(""vertical""),
            # preprocessing.RandomZoom(0.2,0.2),
            preprocessing.RandomTranslation(0.2,0.2),
            # preprocessing.RandomRotation(0.1),
            # preprocessing.RandomContrast(0.2)
```


### Standalone code to reproduce the issue

```shell
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.
WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.
```


### Relevant log output

_No response_</details>"
58107,Floating Point Exception in AvgPool3DGrad,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.11.0-dev20221013

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A Floating Point Exception can be triggerred in AvgPool3DGrad.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            ksize_0 = 1
            ksize_1 = 1
            ksize_2 = 32
            ksize_3 = 36
            ksize_4 = 128
            ksize = [ksize_0, ksize_1, ksize_2, ksize_3, ksize_4, ]
            strides_0 = 1
            strides_1 = 1
            strides_2 = 128
            strides_3 = 128
            strides_4 = 128
            strides = [strides_0, strides_1, strides_2, strides_3, strides_4, ]
            padding = ""SAME""
            data_format = ""NCDHW""
            orig_input_shape_0 = 39
            orig_input_shape_1 = 104
            orig_input_shape_2 = 57
            orig_input_shape_3 = 0
            orig_input_shape_4 = 61
            orig_input_shape = [orig_input_shape_0, orig_input_shape_1, orig_input_shape_2, orig_input_shape_3, orig_input_shape_4, ]
            grad = tf.random.uniform([0, 4, 1, 1, 1], dtype=tf.float32)
            res = tf.raw_ops.AvgPool3DGrad(
                ksize=ksize,
                strides=strides,
                padding=padding,
                data_format=data_format,
                orig_input_shape=orig_input_shape,
                grad=grad,
            )
    except:
        pass
```


### Relevant log output

```shell
tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101
Floating point exception (core dumped)
```
</details>"
58106,Check Fail in AvgPool3DGrad,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.11.0-dev20221013

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A check-fail can be triggered in AvgPool3DGrad, which leads to a crash.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            ksize_0 = 1
            ksize_1 = 1
            ksize_2 = 32
            ksize_3 = 32
            ksize_4 = 128
            ksize = [ksize_0, ksize_1, ksize_2, ksize_3, ksize_4, ]
            strides_0 = 1
            strides_1 = 1
            strides_2 = 128
            strides_3 = 128
            strides_4 = 128
            strides = [strides_0, strides_1, strides_2, strides_3, strides_4, ]
            padding = ""VALID""
            data_format = ""NCDHW""
            orig_input_shape_0 = 111
            orig_input_shape_1 = 24
            orig_input_shape_2 = 43
            orig_input_shape_3 = 77
            orig_input_shape_4 = 89
            orig_input_shape = [orig_input_shape_0, orig_input_shape_1, orig_input_shape_2, orig_input_shape_3, orig_input_shape_4, ]
            grad = tf.random.uniform([0, 4, 1, 1, 1], dtype=tf.float32)
            res = tf.raw_ops.AvgPool3DGrad(
                ksize=ksize,
                strides=strides,
                padding=padding,
                data_format=data_format,
                orig_input_shape=orig_input_shape,
                grad=grad,
            )
    except:
        pass
```


### Relevant log output

```shell
Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 111 feature_map_count: 24 spatial: 1 1 0  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}
Aborted (core dumped)
```
</details>"
58105,Segment Fault in AudioSpectrogram,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9 and 2.11.0-dev20221013

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A **Segment Fault** can be triggered in `AudioSpectrogram`, whether executed with CPU or GPU.
Maybe more checks are needed.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import tensorflow as tf
import numpy as np
print(tf.__version__)
for _ in range(20):
    try:
        with tf.device(""GPU:0""):
            window_size = -94
            stride = 83
            magnitude_squared = False
            input = tf.random.uniform([12, 4], dtype=tf.float32)
            res = tf.raw_ops.AudioSpectrogram(
                window_size=window_size,
                stride=stride,
                magnitude_squared=magnitude_squared,
                input=input,
            )
    except:
        pass
```


### Relevant log output

```shell
Segmentation fault (core dumped)
```
</details>"
58102,inference scipt for custom pose classification model ? for both .tflite a5 hdf5 format,"im using window 10

i tried the blog to train pose  model ,but there is no any inference script ,can you guys please provide script
https://github.com/tensorflow/tensorflow/issues/58101"
58101,i trained custom pose classification model but its giving error at the time of inference,"im using windows 10 system
getting this error, i followed the official blog of Tensorflow 
https://www.tensorflow.org/lite/tutorials/pose_classification  for model training  

this blog hasn't provided inference script
so I tried official https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/raspberry_pi for .tflite inference but getting isse

```Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 0, name: serving_default_input:0```

"
58100,I encountered a problem in upgrading the code from 1. X to 2.0.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.1.0

### Custom Code

No

### OS Platform and Distribution

windows RS 12

### Mobile device

_No response_

### Python version

version 3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
I'm upgrading the code
reg=tf.contrib.layers.apply_regulation（tf.contlib.layers.l2_regularizer（scale），tf.trainable_variables（））
tf.contrib.layers.l2_regularizer(scale)，Rewrite as tf.keras.regularizers.l2(scale)

tf.contrib.layers.apply_regulation，Don't know how to rewrite。
```


### Standalone code to reproduce the issue

```shell
reg=tf.contrib.layers.apply_regulation（tf.contlib.layers.l2_regularizer（scale），tf.trainable_variables（））
I rewrote it as
reg = tf.keras.layers(tf.keras.regularizers.l2(scale),tf.trainable_variables())
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""C:/Users/Administrator/PycharmProjects/pythonProject1/stock/LSTM.py"", line 240, in <module>
    two_up(""2019012"",""zhong"")
  File ""C:/Users/Administrator/PycharmProjects/pythonProject1/stock/LSTM.py"", line 180, in two_up
    reg = tf.keras(tf.keras.regularizers.l2(scale),tf.trainable_variables())
TypeError: 'LazyLoader' object is not callable
```
</details>"
58098,Changes to metrics passed to on_batch_end(...),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.2+

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 22.04.1

### Mobile device

Linux Ubuntu 22.04.1

### Python version

3.7.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.7

### GPU model and memory

_No response_

### Current Behaviour?

I recently updated code from TensorFlow 1 and was getting strange results for my callbacks. I eventually found [issue #36400](https://github.com/tensorflow/tensorflow/issues/36400) and decided to test that. I discovered that in tf 2.2+ on_batch_end is now provided a moving average of all losses so far in the current epoch, while in previous versions only the loss for the current batch is provided.

This matters when using the learning rate finder callback described in [Cyclical Learning Rates for Training Neural Networks by Leslie N. Smith](https://arxiv.org/pdf/1506.01186.pdf).  When using the moving average losses, the suggested range of learning rate values is shifted to the right, resulting in learning rates that are much higher than the optimal range, and leading to poorer performance than when the loss for only the current batch is used correctly.

### Standalone code to reproduce the issue

```python
import sys

from tensorflow import keras
from tensorflow.keras import layers

EPOCHS = 3
STEPS_PER_EPOCH = 10
BATCH_SIZE = 64
SAMPLES = BATCH_SIZE * STEPS_PER_EPOCH


inputs = keras.Input(shape=(784,), name='digits')
x = layers.Dense(4*4096, activation='relu', name='dense_1')(inputs)
x = layers.Dense(4*4096, activation='relu', name='dense_2')(x)
x = layers.Dense(4*4096, activation='relu', name='dense_3')(x)
outputs = layers.Dense(10, activation='softmax', name='predictions')(x)

model = keras.Model(inputs=inputs, outputs=outputs)
(x_train, y_train), _ = keras.datasets.mnist.load_data()
x_train = x_train[:SAMPLES].reshape(SAMPLES, 784).astype('float32') / 255
y_train = y_train[:SAMPLES].astype('float32')

class PrintStatsCallback(keras.callbacks.Callback):
    def on_batch_end(self, batch, logs=None):
        print('\nON_BATCH_END: loss: {loss:.4f} acc: {accuracy:.4f}'.format_map(logs), file=sys.stderr)
    def on_epoch_end(self, epoch, logs=None):
        print('\nON_EPOCH_END: loss: {loss:.4f} acc: {accuracy:.4f}'.format_map(logs), file=sys.stderr)

# Specify the training configuration (optimizer, loss, metrics)
model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
              loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train,
          epochs=EPOCHS,
          steps_per_epoch=STEPS_PER_EPOCH,
          batch_size=BATCH_SIZE,
          callbacks=[PrintStatsCallback()])
```


### Relevant log output

```shell
Epoch 1/3

ON_BATCH_END: loss: 2.3025 acc: 0.0938
 1/10 [==>...........................] - ETA: 0s - loss: 2.3025 - accuracy: 0.0938
ON_BATCH_END: loss: 2.2634 acc: 0.1484
 2/10 [=====>........................] - ETA: 17s - loss: 2.2634 - accuracy: 0.1484
ON_BATCH_END: loss: 2.2258 acc: 0.1771
 3/10 [========>.....................] - ETA: 19s - loss: 2.2258 - accuracy: 0.1771
ON_BATCH_END: loss: 2.1891 acc: 0.2656
 4/10 [===========>..................] - ETA: 19s - loss: 2.1891 - accuracy: 0.2656
ON_BATCH_END: loss: 2.1599 acc: 0.3031
 5/10 [==============>...............] - ETA: 16s - loss: 2.1599 - accuracy: 0.3031
ON_BATCH_END: loss: 2.1139 acc: 0.3516
 6/10 [=================>............] - ETA: 14s - loss: 2.1139 - accuracy: 0.3516
ON_BATCH_END: loss: 2.0604 acc: 0.4062
 7/10 [====================>.........] - ETA: 10s - loss: 2.0604 - accuracy: 0.4062
ON_BATCH_END: loss: 2.0273 acc: 0.4258
 8/10 [=======================>......] - ETA: 7s - loss: 2.0273 - accuracy: 0.4258
ON_BATCH_END: loss: 2.0036 acc: 0.4306
 9/10 [==========================>...] - ETA: 3s - loss: 2.0036 - accuracy: 0.4306
ON_BATCH_END: loss: 1.9565 acc: 0.4547
10/10 [==============================] - ETA: 0s - loss: 1.9565 - accuracy: 0.4547
ON_EPOCH_END: loss: 1.9565 acc: 0.4547
10/10 [==============================] - 38s 4s/step - loss: 1.9565 - accuracy: 0.4547
Epoch 2/3

ON_BATCH_END: loss: 1.4679 acc: 0.7969
 1/10 [==>...........................] - ETA: 0s - loss: 1.4679 - accuracy: 0.7969
ON_BATCH_END: loss: 1.3991 acc: 0.7734
 2/10 [=====>........................] - ETA: 16s - loss: 1.3991 - accuracy: 0.7734
ON_BATCH_END: loss: 1.3518 acc: 0.7604
 3/10 [========>.....................] - ETA: 19s - loss: 1.3518 - accuracy: 0.7604
ON_BATCH_END: loss: 1.2953 acc: 0.7852
 4/10 [===========>..................] - ETA: 19s - loss: 1.2953 - accuracy: 0.7852
ON_BATCH_END: loss: 1.2575 acc: 0.7906
 5/10 [==============>...............] - ETA: 16s - loss: 1.2575 - accuracy: 0.7906
ON_BATCH_END: loss: 1.2541 acc: 0.7708
 6/10 [=================>............] - ETA: 14s - loss: 1.2541 - accuracy: 0.7708
ON_BATCH_END: loss: 1.2084 acc: 0.7701
 7/10 [====================>.........] - ETA: 10s - loss: 1.2084 - accuracy: 0.7701
ON_BATCH_END: loss: 1.1886 acc: 0.7578
 8/10 [=======================>......] - ETA: 7s - loss: 1.1886 - accuracy: 0.7578
ON_BATCH_END: loss: 1.1727 acc: 0.7587
 9/10 [==========================>...] - ETA: 3s - loss: 1.1727 - accuracy: 0.7587
ON_BATCH_END: loss: 1.1418 acc: 0.7609
10/10 [==============================] - ETA: 0s - loss: 1.1418 - accuracy: 0.7609
ON_EPOCH_END: loss: 1.1418 acc: 0.7609
10/10 [==============================] - 38s 4s/step - loss: 1.1418 - accuracy: 0.7609
Epoch 3/3

ON_BATCH_END: loss: 0.7979 acc: 0.8125
 1/10 [==>...........................] - ETA: 0s - loss: 0.7979 - accuracy: 0.8125
ON_BATCH_END: loss: 0.8240 acc: 0.7812
 2/10 [=====>........................] - ETA: 16s - loss: 0.8240 - accuracy: 0.7812
ON_BATCH_END: loss: 0.8083 acc: 0.7865
 3/10 [========>.....................] - ETA: 19s - loss: 0.8083 - accuracy: 0.7865
ON_BATCH_END: loss: 0.8098 acc: 0.7891
 4/10 [===========>..................] - ETA: 19s - loss: 0.8098 - accuracy: 0.7891
ON_BATCH_END: loss: 0.8060 acc: 0.7781
 5/10 [==============>...............] - ETA: 16s - loss: 0.8060 - accuracy: 0.7781
ON_BATCH_END: loss: 0.8370 acc: 0.7578
 6/10 [=================>............] - ETA: 14s - loss: 0.8370 - accuracy: 0.7578
ON_BATCH_END: loss: 0.8413 acc: 0.7411
 7/10 [====================>.........] - ETA: 10s - loss: 0.8413 - accuracy: 0.7411
ON_BATCH_END: loss: 0.8072 acc: 0.7500
 8/10 [=======================>......] - ETA: 7s - loss: 0.8072 - accuracy: 0.7500
ON_BATCH_END: loss: 0.7843 acc: 0.7604
 9/10 [==========================>...] - ETA: 3s - loss: 0.7843 - accuracy: 0.7604
ON_BATCH_END: loss: 0.7861 acc: 0.7594
10/10 [==============================] - ETA: 0s - loss: 0.7861 - accuracy: 0.7594
ON_EPOCH_END: loss: 0.7861 acc: 0.7594
10/10 [==============================] - 38s 4s/step - loss: 0.7861 - accuracy: 0.7594
```
</details>"
58096,Nested call from a tf.function decorated method behaves differently on Tensorarray depending if nested method is also decorated,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When I am calling test method,in this method tensor_array_with_tf_dec variable has type of Tensor and tensor_array variable has type of TensorArray,so this method gets assertion error,but I think they should have the same type.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf


@tf.function
def return_tensor_array_with_tf_dec():
    ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=True)
    return ta


def return_tensor_array():
    ta = tf.TensorArray(tf.float32, size=0, dynamic_size=True, clear_after_read=True)
    return ta


@tf.function
def test():
    tensor_array_with_tf_dec = return_tensor_array_with_tf_dec()
    tensor_array = return_tensor_array()
    assert type(tensor_array_with_tf_dec) == type(tensor_array)

test()
```


### Relevant log output

_No response_</details>"
58093,Unexpected value of variable protected by mutex on aarch64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

5.3.0

### GCC/Compiler version

9.3.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/core/common_runtime:direct_session_test_cpu fails often with an assertion used to check sanity. This is the 2nd of a pair of assertions and should not be able to fail given that the first on the previous line just passed. The two variables being checked are only changed under protection of a mutex and are done one after the other so having the second one be the wrong value should not be possible.

While researching this issue I came across a previous issue https://github.com/tensorflow/tensorflow/issues/38096 that was never resolved. Taking code from that issue and updating it for TF2, I got a similar failure as reported in that issue. Again a variable that should be protected by a mutex is not the correct value.

So far I have only been able to reproduce on machine with 224 cores and running in a Docker container.
```


### Standalone code to reproduce the issue

```shell
To run the unit test
`bazel --bazelrc=/usertools/aarch64.bazelrc test --config=sigbuild_local_cache --config=ambe --cache_test_results=no --test_timeout=100,200,-1,-1 --flaky_test_attempts=1 --jobs=35 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only -- //tensorflow/core/common_runtime:direct_session_test_cpu`

The updated code from the previous issue
`#include ""tensorflow/core/platform/unbounded_work_queue.h""
#include ""tensorflow/core/platform/env.h""

#include <thread>
#include <functional>

using tsl::UnboundedWorkQueue;
using std::thread;
using WorkFunction = std::function<void()>;
using tsl::Env;

const static WorkFunction work = [](){};

void ScheduleTask(UnboundedWorkQueue& manager) {
    for (int i = 0; i < 10000000; i++) {
        manager.Schedule(work);
    }
}

int main() {
    int i = 0;
    while (true) {
        i++;
        UnboundedWorkQueue manager(Env::Default(), ""bugfix"");
        thread t1([&manager]() {ScheduleTask(manager);});
        thread t2([&manager]() {ScheduleTask(manager);});
        thread t3([&manager]() {ScheduleTask(manager);});
        thread t4([&manager]() {ScheduleTask(manager);});
        thread t5([&manager]() {ScheduleTask(manager);});
        thread t6([&manager]() {ScheduleTask(manager);});
        thread t7([&manager]() {ScheduleTask(manager);});
        thread t8([&manager]() {ScheduleTask(manager);});

        t1.join();
        t2.join();
        t3.join();
        t4.join();
        t5.join();
        t6.join();
        t7.join();
        t8.join();
    }
}
`
This code fails after running for a while with
`terminate called after throwing an instance of 'std::bad_function_call'
  what():  bad_function_call
`
```


### Relevant log output

```shell
2022-10-14 09:07:17.810439: F tensorflow/core/framework/run_handler.cc:96] Check failed: waiter->prev == waiter (0xfff40b7ef5f0 vs. 0xfff568f9f5f0)
*** Received signal 6 ***
*** BEGIN MANGLED STACK TRACE ***
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/direct_session_test_cpu.runfiles/org_tensorflow/tensorflow/core/common_runtime/direct_session_test_cpu(+0x17cf08)[0xaaaae266cf08]
linux-vdso.so.1(__kernel_rt_sigreturn+0x0)[0xffff86a207a0]
/lib/aarch64-linux-gnu/libc.so.6(gsignal+0xe0)[0xffff7ed63d78]
/lib/aarch64-linux-gnu/libc.so.6(abort+0x114)[0xffff7ed50aac]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZTv0_n24_N3tsl8internal15LogMessageFatalD1Ev+0x0)[0xffff85462048]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZN10tensorflow8internal12WaitOnWaiterEPNS0_6WaiterES2_PN3tsl5mutexEi+0x1c8)[0xffff85d003e4]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZN10tensorflow8internal16ThreadWorkSource11WaitForWorkEi+0x60)[0xffff85d004d8]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZN10tensorflow8internal20RunHandlerThreadPool11WaitForWorkEbii+0x15c)[0xffff85d00694]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZN10tensorflow8internal20RunHandlerThreadPool10WorkerLoopEib+0xaf0)[0xffff85d020c8]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(+0x1182130)[0xffff85d02130]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZNKSt8functionIFvvEEclEv+0x18)[0xffff85449be0]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(+0x117f8a8)[0xffff85cff8a8]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(_ZNKSt8functionIFvvEEclEv+0x18)[0xffff85449be0]
/root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/core/common_runtime/../../../_solib_local/_U_S_Stensorflow_Score_Scommon_Uruntime_Cdirect_Usession_Utest_Ucpu___Utensorflow/libtensorflow_framework.so.2(+0x134aab0)[0xffff85ecaab0]
/lib/aarch64-linux-gnu/libpthread.so.0(+0x7624)[0xffff7f1c7624]
/lib/aarch64-linux-gnu/libc.so.6(+0xd149c)[0xffff7ee0149c]
*** END MANGLED STACK TRACE ***

*** Begin stack trace ***
	tsl::CurrentStackTrace[abi:cxx11]()
	
	__kernel_rt_sigreturn
	gsignal
	abort
	virtual thunk to tsl::internal::LogMessageFatal::~LogMessageFatal()
	tensorflow::internal::WaitOnWaiter(tensorflow::internal::Waiter*, tensorflow::internal::Waiter*, tsl::mutex*, int)
	tensorflow::internal::ThreadWorkSource::WaitForWork(int)
	tensorflow::internal::RunHandlerThreadPool::WaitForWork(bool, int, int)
	tensorflow::internal::RunHandlerThreadPool::WorkerLoop(int, bool)
	
	std::function<void ()>::operator()() const
	
	std::function<void ()>::operator()() const
	
	
	
*** End stack trace ***
================================================================================
Target //tensorflow/core/common_runtime:direct_session_test_cpu up-to-date:
  bazel-bin/tensorflow/core/common_runtime/direct_session_test_cpu
INFO: Elapsed time: 2.193s, Critical Path: 1.62s
INFO: 2 processes: 2 local.
INFO: Build completed, 1 test FAILED, 2 total actions
//tensorflow/core/common_runtime:direct_session_test_cpu                 FAILED in 1.6s
  /root/.cache/bazel/_bazel_root/fbac33eb30dbfb6b11b15a7ff5ac830d/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/core/common_runtime/direct_session_test_cpu/test.log

INFO: Build completed, 1 test FAILED, 2 total actions
```
</details>"
58091,Warnings about ambiguous reversed operator in C++20 due do lacking const,"### Issue Type

Bug

### Source

source

### Tensorflow Version

master

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### GCC/Compiler version

Clang 13

### Current Behaviour?

When I use TensorFlow in my C++ code, I will get warnings from within TensorFlow of this kind:

```
[46/62] Building CXX object tests/pytest/CMakeFiles/tensorflow_ops.dir/tensorflow_device.cc.o
/xxx/tests/pytest/tensorflow_device.cc:13:29: warning: ISO C++20 considers use of overloaded operator '!=' (with operand types 'tensorflow::TensorShapeIter<tensorflow::TensorShape>' and 'tensorflow::TensorShapeIter<tensorflow::TensorShape>') to be ambiguous despite there being a unique best viable function with non-reversed arguments [-Wambiguous-reversed-operator]
  for (tf::TensorShapeDim s : t.shape())
                            ^
/xxx/lib/python3.9/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:457:8: note: candidate function with non-reversed arguments
  bool operator!=(const TensorShapeIter& rhs) {
       ^
/xxx/lib/python3.9/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:453:8: note: ambiguous candidate function with reversed arguments
  bool operator==(const TensorShapeIter& rhs) {
       ^
1 warning generated.
```

These stem from comparison operators not being const, see [this Stack Overflow answer](https://stackoverflow.com/a/60387060/653152). In `master` as of today this is still an issue with at least `TensorShapeIter`, but there might be more classes like this, possibly also `OpArgIterator`.

### Standalone code to reproduce the issue

Just take a single stand-alone C++ file `mwe.cpp` like this:

```cpp
class TensorShapeIter {
 public:
  TensorShapeIter(int d) : d_(d) {}
  bool operator==(const TensorShapeIter& rhs) {
    return d_ == rhs.d_;
  }
  bool operator!=(const TensorShapeIter& rhs) {
    return d_ != rhs.d_;
  }

 private:
  int d_;
};

int main() {
    TensorShapeIter iter_1(1);
    TensorShapeIter iter_2(2);
    
    return iter_1 == iter_2;
}
```

Then compile that with `clang++ --std=c++20 -Wall mwe.cpp` and you will get the warning:

```
❯ clang++ --std=c++20 -Wall mwe.cpp
mwe.cpp:19:19: warning: ISO C++20 considers use of overloaded operator '==' (with operand types 'TensorShapeIter' and 'TensorShapeIter') to be ambiguous despite there being a unique best viable function [-Wambiguous-reversed-operator]
    return iter_1 == iter_2;
           ~~~~~~ ^  ~~~~~~
mwe.cpp:4:8: note: ambiguity is between a regular call to this operator and a call with the argument order reversed
  bool operator==(const TensorShapeIter& rhs) {
       ^
1 warning generated.
```

If you however make them `const`, the issue is gone. So the operators need to look like this:

```
  bool operator==(const TensorShapeIter& rhs) const {
    return d_ == rhs.d_;
  }
  bool operator!=(const TensorShapeIter& rhs) const {
    return d_ != rhs.d_;
  }
```

And then there are no more warnings."
58088,Fail to serialize EfficientNet model using to_json() method,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

ubuntu 18.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.2, cudnn 8.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Calling to_json() method fails on EfficientNet's when using imagenet weights.

It seems the problem occurs when serializing the following layer of efficientnet:

x = layers.Rescaling(1.0 / tf.math.sqrt(IMAGENET_STDDEV_RGB))(x)

The scale parameter seems to be some of type tensorflow.python.framework.ops.EagerTensor, which is not serializable.

The problem was most likely introduced in https://github.com/tensorflow/tensorflow/issues/49930.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from keras.applications import EfficientNetB3

m1 = EfficientNetB3(weights='imagenet')
m1.to_json()
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/tom/whaat.py"", line 5, in <module>
    m1.to_json()
  File ""/home/.virtualenvs/pypotato-py39/lib/python3.9/site-packages/keras/engine/training.py"", line 3087, in to_json
    return json.dumps(
  File ""/usr/lib/python3.9/json/__init__.py"", line 234, in dumps
    return cls(
  File ""/usr/lib/python3.9/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python3.9/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
  File ""/home/.virtualenvs/pypotato-py39/lib/python3.9/site-packages/keras/saving/saved_model/json_utils.py"", line 221, in get_json_type
    raise TypeError(
TypeError: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.

Process finished with exit code 1
```
</details>"
58087,`tf.keras.Model()` behaves incorrectly if `inputs` is a dictionary view,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.5 LTS

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
As demonstrated in the code example below, the ability to correctly map input tensors to model input layers by layer name stops working silently as soon as (i) the `inputs` argument of `tf.keras.Model()` is a dictionary-value view and (ii) the inputs are not provided in ascending order (by layer name).

The expectation was that either all cases covered in the code example pass without error or that `tf.keras.Model()` fails when receiving unsupported inputs.
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf


def run_test(*, use_plain_list: bool, sort_dict: bool):
    data_in = {
        ""a"": np.array([1, 3], dtype=np.float64).reshape((1, 2,)),
        ""b"": np.array([1, 2, 3], dtype=np.float64).reshape((1, 3)),
    }

    input_a = tf.keras.layers.Input((2,), name=""a"")
    input_b = tf.keras.layers.Input((3,), name=""b"")
    output = tf.keras.layers.Dense(1, name=""output"")(input_b)

    inputs = {}
    # Note how input layer names (= dict keys) are not in ascending order
    inputs[""b""] = input_b
    inputs[""a""] = input_a
    if sort_dict:
        inputs = {
            key: inputs[key]
            for key in sorted(inputs.keys())
        }
    model = tf.keras.Model(
        inputs=(
            list(inputs.values()) if use_plain_list else inputs.values()
        ),
        outputs=output,
    )
    model.compile(loss=""mse"", optimizer=""adam"")

    print(model(data_in).numpy().item())


if __name__ == ""__main__"":
    print(""[PASSES] Passing inputs as plain list and sorted by name"")
    run_test(use_plain_list=True, sort_dict=True)
    print(""[PASSES] Passing inputs as plain list, although not sorted by name"")
    run_test(use_plain_list=True, sort_dict=False)
    print(""[PASSES] Passing inputs as dict-value view, but sorted by name"")
    run_test(use_plain_list=False, sort_dict=True)
    print(""[FAILS] Passing inputs as dict-value view and not sorted by name"")
    run_test(use_plain_list=False, sort_dict=False)
```


### Relevant log output

```shell
2022-10-13 15:32:01.051111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-13 15:32:01.163823: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-10-13 15:32:01.163876: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-13 15:32:01.186457: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-13 15:32:01.631140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-10-13 15:32:01.631221: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-10-13 15:32:01.631248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
[PASSES] Passing inputs as plain list and sorted by name
2022-10-13 15:32:02.104453: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-10-13 15:32:02.104524: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-13 15:32:02.104549: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-URBMT3GM): /proc/driver/nvidia/version does not exist
2022-10-13 15:32:02.104892: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
-1.3255137205123901
[PASSES] Passing inputs as plain list, although not sorted by name
2.081906318664551
[PASSES] Passing inputs as dict-value view, but sorted by name
1.242689609527588
[FAILS] Passing inputs as dict-value view and not sorted by name
Traceback (most recent call last):
  File ""/home/marek/src/debug-tf/test_view_issue.py"", line 43, in <module>
    run_test(use_plain_list=False, sort_dict=False)
  File ""/home/marek/src/debug-tf/test_view_issue.py"", line 32, in run_test
    print(model(data_in).numpy().item())
  File ""/home/marek/.local/share/virtualenvs/debug-tf-TD15A9yo/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/marek/.local/share/virtualenvs/debug-tf-TD15A9yo/lib/python3.9/site-packages/keras/engine/input_spec.py"", line 277, in assert_input_compatibility
    raise ValueError(
ValueError: Exception encountered when calling layer ""model_3"" ""                 f""(type Functional).

Input 0 of layer ""output"" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (1, 2)

Call arguments received by layer ""model_3"" ""                 f""(type Functional):
  • inputs={'a': 'tf.Tensor(shape=(1, 2), dtype=float64)', 'b': 'tf.Tensor(shape=(1, 3), dtype=float64)'}
  • training=None
  • mask=None
```
</details>"
58086,Custom layer with tf.extract_image_patches extremely slow,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Google Colab

### Mobile device

_No response_

### Python version

3.7.14

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'm new to tensorflow. I'm trying to implement a custom pooling layer, using owa operators (https://github.com/jiforcen/ordered-weighted-pooling). For that I'm using tf.extract_image_patches, but this operation is extremely slow when the input data dimensions are large, as raised in issue #13017. 

I believe that the pooling layer that I implemented has a behavior very similar to what is performed by the tf.keras.layers.MaxPooling2D layer. Inspecting the code of MaxPooling2D I saw that it calls the gen_nn_ops.max_pool method. 

I tried to take a look at what's inside gen_nn_ops.max_pool, but I can't find it in the repository. From what I've googled I can't find the source code because it's automatically generated by bazel. If I build from source, I'll see this file inside bazel-genfiles, right? This file contains automatically generated Python wrappers to underlying C++ implementations.

Is it possible to create a custom pooling operation in C++ and use it in my Python code? I'm adding the custom layer code that I implemented.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

from keras import backend as K
from tensorflow.keras.constraints import Constraint
from tensorflow.python.util.tf_export import keras_export
from tensorflow.python.keras.utils import conv_utils
# import skimage.measure

@keras_export('keras.constraints.UnitSumNonNeg', 'keras.constraints.unit_sum_non_neg')
class UnitSumNonNeg(Constraint):
    """"""Limits weights to be non-negative and with sum equal to one

    Also available via the shortcut function `keras.constraints.unit_sum_non_neg`.
    """"""
    def __call__(self, w):
        aux =  w * tf.cast(tf.math.greater_equal(w, 0.), w.dtype)

        return aux/(K.epsilon() + tf.reduce_sum(aux, axis=[0], keepdims=True))

class OWAPoolingNew(tf.keras.layers.Layer):
    def __init__(self,
               pool_size=(2, 2),
               strides=None,
               padding='valid',
               data_format=None,
               name=None,
               sort=True,
               train=True, 
               seed=None,
               all_channels=False,
               **kwargs):
        super(OWAPoolingNew, self).__init__(name=name, **kwargs)

        self.pool_size = pool_size
        self.strides = pool_size if strides == None else strides
        self.padding = padding
        self.data_format = conv_utils.normalize_data_format('channels_last')
        self.sort = sort
        self.train = train
        self.seed = seed if seed != None else 10
        self.all_channels = all_channels
        
    def build(self, input_shape):
      
      if self.all_channels:
        weights_shape = (self.pool_size[0] * self.pool_size[1], input.shape[-1])
      else:
        weights_shape = (self.pool_size[0] * self.pool_size[1], 1)
      
      tf.random.set_seed(self.seed)
      kernel = tf.random.uniform(shape=weights_shape)
      kernel /= tf.reduce_sum(kernel, axis=[0], keepdims=True)
      
      self.kernel = tf.Variable(initial_value = kernel, trainable=self.train, dtype='float32', constraint=UnitSumNonNeg())

    def call(self, inputs):

        _, height, width, channels = inputs.get_shape().as_list()

        # Extract pooling regions
        stride = [1, self.strides[0], self.strides[1], 1]
        ksize = [1, self.pool_size[0], self.pool_size[1], 1]

        inputs = tf.image.extract_patches(inputs, sizes = ksize, strides = stride,
                            rates = [1, 1, 1, 1], padding='SAME')

        _, pool_height, pool_width, elems = inputs.get_shape().as_list()

        # Extract pooling regions for each channel
        elems =  int(elems / channels)
        inputs = tf.reshape(inputs, [-1, pool_height, pool_width, elems, channels]) # Reshape tensor

        # Sort values for pooling
        if self.sort:
            inputs = tf.sort(inputs, axis=-2, direction='DESCENDING', name=None)

        outputs = tf.reduce_sum(tf.math.multiply(self.kernel, inputs), axis=-2)

        return outputs
```


### Relevant log output

_No response_</details>"
58085,TFLite Interpreter.invoke()- gather index out of boundsNode number 935 (GATHER) failed to invoke.,"Getting this error with the following sample code for prediction: 

Model weights: [https://drive.google.com/file/d/1SXbMtxQKiU-Iavh6U7lwzEZS0lYYNpJy/view?usp=sharing](url)

```
import tensorflow as tf


def run_tflite_model(tflite_file,image_data,y_inp):
    #print('image_data',image_data)
    #print('y_inp',y_inp)
    #feed_f = dict(zip(['input_2', 'input_shape'], (image_data, y_inp)))
    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))
    interpreter.allocate_tensors()
    #print(interpreter.get_input_details())
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    print(input_details)
    print(output_details)
    print(image_data.shape)
    print(y_inp.shape)
    interpreter.set_tensor(input_details[0][""index""],image_data)
    interpreter.set_tensor(input_details[1][""index""],y_inp)
    print('tensor details:',interpreter.get_tensor_details())
    interpreter.resize_tensor_input(input_details[1]['index'], [1,2])
    interpreter.invoke()
    t1=time.time()
    print('yes:',interpreter)
    output = interpreter.get_tensor(output_details[0][""index""])[0]
    print(output)
    t2=time.time()
    print('time:',t2-t1)
    pred = torch.Tensor(output)
    prediction = output.argmax()
    #print(len(prediction))
    return prediction,pred
```


`import cv2
if __name__ == '__main__':


    converted_model = ""kvp_converted_model_fp16.tflite""
    image_path = ""kvp_test/test_1.png""
    seg_image_path=""kvp_test/seg_test_1.png""
    #good_image_path = ""datasets/experiment/good/g.png""
    img1 = cv2.imread(image_path)
    img2=cv2.imread(seg_image_path)
    #img = img[None, :, :, :]
    #resized=img
    resized_img = cv2.resize(img1, (608,608)).astype('float32')
    resized_seg_img = cv2.resize(img2, (608,608)).astype('float32')
    #resized=img.astype('float32')
    resized_img = resized_img / 255.
    resized_seg_img = resized_seg_img / 255.
    input_image = np.expand_dims(resized_img, axis=0)
    seg_image= np.expand_dims(resized_seg_img, axis=0)
    #print(test_img)
    image_data = np.concatenate([input_image,seg_image], axis = -1).astype(np.float32)
    y_inp = np.expand_dims(np.array([img1.shape[0], img1.shape[1]]), axis = 0).astype(np.float32)
    
    prediction,pred = run_tflite_model(converted_model,image_data,y_inp)
    print(pred)`


**Error**:
![gather](https://user-images.githubusercontent.com/25703066/195579619-36ab83cc-13d0-4223-b930-5920de2a367e.jpg)
"
58084, got this issue when I run the emotion detection program,"
<img width=""956"" alt=""Capture1"" src=""https://user-images.githubusercontent.com/75195908/195511477-b86cd1b7-dc65-4b3c-93d7-8551a5c86af0.PNG"">
<img width=""931"" alt=""Capture"" src=""https://user-images.githubusercontent.com/75195908/195511521-f482006b-613c-4852-96d5-45bfdbd84600.PNG"">

"
58077,ONEDNN - Layer Normalization error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2 v2.9.1-132-g18960c44ad3 2.9.2

### Custom Code

No

### OS Platform and Distribution

ubuntu 18, ubuntu 20,redhat 7

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

7.5.0 

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
the model predicts without errors
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'
import tensorflow as tf
import numpy as np

input_layer = tf.keras.layers.Input(shape=(3,24), dtype=np.float32)
data = tf.quantization.fake_quant_with_min_max_vars(inputs=input_layer, min=0, max=3.5, num_bits=8)
data = tf.keras.layers.LayerNormalization(axis=[-2,-1], center=True,scale=True)(data)
data = tf.quantization.fake_quant_with_min_max_vars(inputs=data, min=0, max=3.5, num_bits=8)
model = tf.keras.Model(inputs=input_layer, outputs=data)
model.compile()
model.summary()

data = np.random.rand(1,3,24)
res = model.predict(data)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/path/to/python/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'model/layer_normalization/add' defined at (most recent call last):
    File ""<stdin>"", line 1, in <module>
    File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/engine/training.py"", line 2033, in predict
      tmp_batch_outputs = self.predict_function(iterator)
    File ""/path/to/python/python3.8/site-packages/keras/engine/training.py"", line 1845, in predict_function
      return step_function(self, iterator)
    File ""/path/to/python/python3.8/site-packages/keras/engine/training.py"", line 1834, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/path/to/python/python3.8/site-packages/keras/engine/training.py"", line 1823, in run_step
      outputs = model.predict_step(data)
    File ""/path/to/python/python3.8/site-packages/keras/engine/training.py"", line 1791, in predict_step
      return self(x, training=False)
    File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/engine/training.py"", line 490, in __call__
      return super().__call__(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/engine/base_layer.py"", line 1014, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/engine/functional.py"", line 458, in call
      return self._run_internal_graph(
    File ""/path/to/python/python3.8/site-packages/keras/engine/functional.py"", line 596, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/engine/base_layer.py"", line 1014, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/path/to/python/python3.8/site-packages/keras/layers/normalization/layer_normalization.py"", line 324, in call
      outputs = outputs + tf.cast(offset, outputs.dtype)
Node: 'model/layer_normalization/add'
scale must be 1D tensor[1,3,24]
	 [[{{node model/layer_normalization/add}}]] [Op:__inference_predict_function_217]
```
</details>"
58075,_MklBatchMatMulV2 performs even worse than normal BatchMatMul,"
### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 3.10
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: No
-   **TensorFlow installed from (source or binary)**: Source
-   **TensorFlow version (use command below)**: 2.5
-   **Python version**: py3.6
-   **Bazel version (if compiling from source)**:  2.0
-   **GCC/Compiler version (if compiling from source)**:7.3
-   **CUDA/cuDNN version**: N/A
-   **GPU model and memory**: N/A
-   **Exact command to reproduce**: N/A

_MklBatchMatMulV2 performs even worse than normal BatchMatMul.
I installed tensorflow2.5 from source code without any special config. when I set TF_ENABLE_ONEDNN_OPTS=1, tf performed better than baseline(with TF_ENABLE_ONEDNN_OPTS=0) on my recommendation model. Though I found it performed better on some ops like _MklMatMul, _MklNativeFusedMatMul, it worked worse on _MklBatchMatMulV2(160ms vs 110ms on total 150 _MklBatchMatMulV2 ops). Does this result is expected?

I also tried set --config=mkl when I compliled tensorflow2.5 but get the same result. 

I also tried set --config=mkl when I compiled tensorflow2.2, MklBatchMatMul performed better than normal tf2.2(without --config=mkl). The result is 70ms vs 110ms. 

Is there any way to allow me to get better performance on BatchMatMul op using tf2.5? or is there any way to use normal BatchMatMul op rather than _MklBatchMatMulV2 when seting TF_ENABLE_ONEDNN_OPTS=1 because _MklBatchMatMulV2 performed worse but _MklMatMul and _MklNativeFusedMatMul performed much better. 




"
58074,Cross-build failed tensorflow lite demo minimal,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04

### Mobile device

arm32

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

clang 10

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
* I follow the document[https://github.com/tensorflow/tensorflow/blob/v2.10.0/tensorflow/lite/examples/minimal/README.md] to build the minimal demo

mkdir build_minimal
cd build_minimal
cmake  -DCMAKE_TOOLCHAIN_FILE=/home/yons/data/ohos-sdk/linux/native/build/cmake/ohos.toolchain.cmake ../tensorflow/lite/examples/minimal/
cmake --build . -j 20
```

* I got error 
```
Building CXX object CMakeFiles/minimal.dir/minimal.cc.obj
clang++: warning: argument unused during compilation: '--gcc-toolchain=/home/yons/data/ohos-sdk/linux/native/llvm' [-Wunused-command-line-argument]
In file included from /home/yons/data/tensorflow/tensorflow/lite/examples/minimal/minimal.cc:17:
In file included from /home/yons/data/tensorflow/tensorflow/lite/kernels/register.h:18:
In file included from /home/yons/data/tensorflow/tensorflow/lite/model.h:21:
/home/yons/data/tensorflow/tensorflow/lite/interpreter_builder.h:26:10: fatal error: 'flatbuffers/flatbuffers.h' file not found
#include ""flatbuffers/flatbuffers.h""  // from @flatbuffers
         ^~~~~~~~~~~~~~~~~~~~~~~~~~~
1 error generated.
CMakeFiles/minimal.dir/build.make:62: recipe for target 'CMakeFiles/minimal.dir/minimal.cc.obj' failed
make[2]: *** [CMakeFiles/minimal.dir/minimal.cc.obj] Error 1
CMakeFiles/Makefile2:1295: recipe for target 'CMakeFiles/minimal.dir/all' failed
make[1]: *** [CMakeFiles/minimal.dir/all] Error 2
Makefile:129: recipe for target 'all' failed
make: *** [all] Error 2
```
* Please guide me to configure the include directory!
* thanks for your time!
```


### Standalone code to reproduce the issue

```shell
https://github.com/tensorflow/tensorflow/tree/v2.10.0/tensorflow/lite/examples/minimal


```
* I change the `CMakeLists.txt`
```
cmake_minimum_required(VERSION 3.16)
project(minimal C CXX)

set(TENSORFLOW_SOURCE_DIR """" CACHE PATH
  ""Directory that contains the TensorFlow project""
)
if(NOT TENSORFLOW_SOURCE_DIR)
  get_filename_component(TENSORFLOW_SOURCE_DIR
    ""${CMAKE_CURRENT_LIST_DIR}/../../../../""
    ABSOLUTE
  )
endif()

add_subdirectory(
  ""${TENSORFLOW_SOURCE_DIR}/tensorflow/lite""
  ""${CMAKE_CURRENT_BINARY_DIR}/tensorflow-lite""
  EXCLUDE_FROM_ALL
)

message(TARCE ""TuT "" ${TENSORFLOW_SOURCE_DIR})
include_directories(${TENSORFLOW_SOURCE_DIR}/)
#include_directories(${CMAKE_CURRENT_LIST_DIR}/flatbuffers/include)
set(CMAKE_CXX_STANDARD 17)
add_executable(minimal
  minimal.cc
)
add_library(tf-lite STATIC IMPORTED )
set_target_properties(
    tf-lite
    PROPERTIES IMPORTED_LOCATION
    /home/yons/data/tensorflow/build_lite/libtensorflow-lite.a
    )
target_link_libraries(minimal
  tf-lite
)
```

### Relevant log output

_No response_</details>"
58073,Remove all uses of distutils,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

N/A

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensorflow uses distutils, which will be removed in Python 3.12. This currently causes a `DeprecationWarning` to be printed in Python 3.10.
```


### Standalone code to reproduce the issue

```shell
import tensorflow
```


### Relevant log output

```shell
/home/ramrachum/.venvs/ray_env/lib/python3.10/site-packages/tensorflow/python/compiler/tensorrt/utils.py:21: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12
. Use setuptools or check PEP 632 for potential alternatives
```
</details>"
58072,Error while finding module specification for 'model.recommendation_model_launcher_keras',"I followed this document [Firebase_ML_on_device_recommentations](https://colab.research.google.com/github/FirebaseExtended/codelab-contentrecommendation-android/blob/master/Firebase_ML_on_device_recommentations.ipynb)

I got error in the step:
``` 
!python -m model.recommendation_model_launcher_keras \
  --run_mode ""train_and_eval"" \
  --encoder_type ""cnn"" \
  --training_data_filepattern ""data/examples/train_movielens_1m.tfrecord"" \
  --testing_data_filepattern ""data/examples/test_movielens_1m.tfrecord"" \
  --model_dir ""model/model_dir"" \
  --params_path ""model/sample_config.json""\
  --batch_size 64 \
  --learning_rate 0.1 \
  --steps_per_epoch 1000 \
  --num_epochs 10 \
  --num_eval_steps 1000 \
  --gradient_clip_norm 1.0 \
  --max_history_length 10
```
Error message: `/usr/bin/python3: Error while finding module specification for 'model.recommendation_model_launcher_keras' (ModuleNotFoundError: No module named 'model')`

Tensorflow version `2.8.2`

I found a similar [issue](https://github.com/tensorflow/tensorflow/issues/56112)  but it was closed and it's solution is not working with me so I created this once
"
58070,"When training the TensorFlow Lite model after loading it in C++, the logit/probabllites size is different from the number of y labels.","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.9.1

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?
When I ran the python model, as a result of predict, the size of logit and probablites was the same as the size of y label.  
But, in C++, 
The size of logits is 0, and the size of proba is 6. Am I using C++ Code wrong?

### Standalone code to reproduce the issue

```shell
import pickle
import tensorflow as tf
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.utils import get_custom_objects

tf.keras.backend.clear_session()

class Relu(Activation):
    def __init__(self, activation, **kwargs):
        super(Relu, self).__init__(activation, **kwargs)
        self.__name__ = 'Relu'

def _relu(tensor):
    return tf.maximum(tensor,0)

get_custom_objects().update({'_relu': Relu(_relu)})

class PredictedDestination(tf.Module):
    def __init__(self):
        self.model = tf.keras.Sequential([
            tf.keras.layers.Dense(16, input_shape=(18, ), name='input'),
            tf.keras.layers.Dense(5),
        ])
    
        self.model.compile(
            optimizer='sgd',
            loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
            run_eagerly=True)

    # The `train` function takes a batch of input images and labels.
    @tf.function(input_signature=[
      tf.TensorSpec([None, 18], tf.float32),
      tf.TensorSpec([None, 5], tf.float32),
    ])
    def train(self, x, y):
        epochs = 100
        for i in range(epochs):
            with tf.GradientTape() as tape:
              prediction = self.model(x)
              loss = self.model.loss(y, prediction)
            gradients = tape.gradient(loss, self.model.trainable_variables)
            self.model.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))
            result = {""loss"": loss}
        return result

    @tf.function(input_signature=[
      tf.TensorSpec([None, 18], tf.float32),
    ])
    def predict(self, x): 
        logits = self.model(x)
        probabilities = tf.nn.softmax(logits, axis=-1)
        print(probabilities)
        print(logits)
        return {
            ""output"": probabilities,
            ""logits"": logits
        }

model = PredictedDestination()
```


```python
SAVED_MODEL_DIR = ""predicted_destination_model""

tf.saved_model.save(
    model,
    SAVED_MODEL_DIR,
    signatures={
        'train':
            model.train.get_concrete_function(),
        'predict':
            model.predict.get_concrete_function(),
    })

converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS
]
converter.experimental_enable_resource_variables = True
tflite_model = converter.convert()

f = open('predicted_destination.tflite', 'wb')
f.write(tflite_model)
f.close()
```


```c++
tflite::SignatureRunner* trainSignatureRunner = m_interpreter->GetSignatureRunner( ""train"" );

trainSignatureRunner->ResizeInputTensor( ""x"", { batchSize, 18 } );
trainSignatureRunner->ResizeInputTensor( ""y"", { batchSize, 5 } );

trainSignatureRunner->AllocateTensors()

TfLiteTensor* x_input_tensor = trainSignatureRunner->input_tensor( ""x"" );
// fill x_input_tensor

TfLiteTensor* y_input_tensor = trainSignatureRunner->input_tensor( ""y"" );
// fill y_input_tensor

trainSignatureRunner->Invoke();

tflite::SignatureRunner* predictSignatureRunner = m_interpreter->GetSignatureRunner(""predict"");

predictSignatureRunner->ResizeInputTensor( ""x"", { batchSize, 18 } );
TfLiteTensor* predict_x_input_tensor = predictSignatureRunner->input_tensor( ""x"" );
// fill predict_x_input_tensor

predictSignatureRunner->Invoke();

const TfLiteTensor* logit_output = predictSignatureRunner->output_tensor( ""logits"" );

std::vector<FLOAT> logitsResult;
FLOAT* tempLogits = logit_output->data.f;

while ( 0 < *tempLogits )
{
	std::cout << ""[TFLiteModelManager::Predict] logit : "" << *tempLogits << std::endl;
	logitsResult.push_back( *tempLogits );
	tempLogits++;
}

const TfLiteTensor* probabilities_output = predictSignatureRunner->output_tensor( ""output"" );
std::vector<FLOAT> probabilities;
FLOAT* tempProbabilities = probabilities_output->data.f;

while ( 0 < *tempProbabilities )
{
	std::cout << ""[TFLiteModelManager::Predict] proba : "" << *tempProbabilities << std::endl;
	probabilities.push_back( *tempProbabilities );
	tempProbabilities++;
}
```


### Relevant log output

```shell
[TFLiteModelManager::Predict] proba : 0.112619
[TFLiteModelManager::Predict] proba : 0.170277
[TFLiteModelManager::Predict] proba : 0.224098
[TFLiteModelManager::Predict] proba : 0.301938
[TFLiteModelManager::Predict] proba : 0.191067
[TFLiteModelManager::Predict] proba : 0.252747

logits size is zero, but proba size size is 6....
```
</details>"
58068,Tensorflow Keras Model with customer loss returns error: AttributeError: 'method' object has no attribute '_from_serialized',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.3/8.2.1

### GPU model and memory

Nvidia GeForce GTX 1060 SUPER

### Current Behaviour?

```shell
I've run models with Tensorflow and keras before, but when I try to run a new model that has custom metrics I get the error:

Tensorflow Keras Model with customer loss returns error: AttributeError: 'method' object has no attribute '_from_serialized'

This is code I've copied from a video series I'm following along to. I thought maybe I mistyped something so I copied his code from GITHUB and still get the same error. Here is a link:
https://www.youtube.com/watch?v=A6mdOEPGM1E&list=PL-wATfeyAMNpEyENTc-tVH5tfLGKtSWPp&index=11&ab_channel=ValerioVelardo-TheSoundofAI
```


### Standalone code to reproduce the issue

```shell
import os
import pickle

from tensorflow.keras import Model
from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \
    Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda
from tensorflow.keras import backend as K
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import numpy as np
import tensorflow as tf


tf.compat.v1.disable_eager_execution()


class VAE:
    """"""
    VAE represents a Deep Convolutional variational autoencoder architecture
    with mirrored encoder and decoder components.
    """"""

    def __init__(self,
                 input_shape,
                 conv_filters,
                 conv_kernels,
                 conv_strides,
                 latent_space_dim):
        self.input_shape = input_shape # [28, 28, 1]
        self.conv_filters = conv_filters # [2, 4, 8]
        self.conv_kernels = conv_kernels # [3, 5, 3]
        self.conv_strides = conv_strides # [1, 2, 2]
        self.latent_space_dim = latent_space_dim # 2
        self.reconstruction_loss_weight = 1000

        self.encoder = None
        self.decoder = None
        self.model = None

        self._num_conv_layers = len(conv_filters)
        self._shape_before_bottleneck = None
        self._model_input = None

        self._build()

    def summary(self):
        self.encoder.summary()
        self.decoder.summary()
        self.model.summary()

    def compile(self, learning_rate=0.0001):
        optimizer = Adam(learning_rate=learning_rate)
        self.model.compile(optimizer=optimizer,
                           loss=self._calculate_combined_loss,
                           metrics=[self._calculate_reconstruction_loss,
                                    self._calculate_kl_loss])

    def train(self, x_train, batch_size, num_epochs):
        self.model.fit(x_train,
                       x_train,
                       batch_size=batch_size,
                       epochs=num_epochs,
                       shuffle=True)

    def save(self, save_folder="".""):
        self._create_folder_if_it_doesnt_exist(save_folder)
        self._save_parameters(save_folder)
        self._save_weights(save_folder)

    def load_weights(self, weights_path):
        self.model.load_weights(weights_path)

    def reconstruct(self, images):
        latent_representations = self.encoder.predict(images)
        reconstructed_images = self.decoder.predict(latent_representations)
        return reconstructed_images, latent_representations

    @classmethod
    def load(cls, save_folder="".""):
        parameters_path = os.path.join(save_folder, ""parameters.pkl"")
        with open(parameters_path, ""rb"") as f:
            parameters = pickle.load(f)
        autoencoder = VAE(*parameters)
        weights_path = os.path.join(save_folder, ""weights.h5"")
        autoencoder.load_weights(weights_path)
        return autoencoder

    def _calculate_combined_loss(self, y_target, y_predicted):
        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)
        kl_loss = self._calculate_kl_loss(y_target, y_predicted)
        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\
                                                         + kl_loss
        return combined_loss

    def _calculate_reconstruction_loss(self, y_target, y_predicted):
        error = y_target - y_predicted
        reconstruction_loss = K.mean(K.square(error), axis=[1, 2, 3])
        return reconstruction_loss

    def _calculate_kl_loss(self, y_target, y_predicted):
        kl_loss = -0.5 * K.sum(1 + self.log_variance - K.square(self.mu) -
                               K.exp(self.log_variance), axis=1)
        return kl_loss

    def _create_folder_if_it_doesnt_exist(self, folder):
        if not os.path.exists(folder):
            os.makedirs(folder)

    def _save_parameters(self, save_folder):
        parameters = [
            self.input_shape,
            self.conv_filters,
            self.conv_kernels,
            self.conv_strides,
            self.latent_space_dim
        ]
        save_path = os.path.join(save_folder, ""parameters.pkl"")
        with open(save_path, ""wb"") as f:
            pickle.dump(parameters, f)

    def _save_weights(self, save_folder):
        save_path = os.path.join(save_folder, ""weights.h5"")
        self.model.save_weights(save_path)

    def _build(self):
        self._build_encoder()
        self._build_decoder()
        self._build_autoencoder()

    def _build_autoencoder(self):
        model_input = self._model_input
        model_output = self.decoder(self.encoder(model_input))
        self.model = Model(model_input, model_output, name=""autoencoder"")

    def _build_decoder(self):
        decoder_input = self._add_decoder_input()
        dense_layer = self._add_dense_layer(decoder_input)
        reshape_layer = self._add_reshape_layer(dense_layer)
        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)
        decoder_output = self._add_decoder_output(conv_transpose_layers)
        self.decoder = Model(decoder_input, decoder_output, name=""decoder"")

    def _add_decoder_input(self):
        return Input(shape=self.latent_space_dim, name=""decoder_input"")

    def _add_dense_layer(self, decoder_input):
        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8
        dense_layer = Dense(num_neurons, name=""decoder_dense"")(decoder_input)
        return dense_layer

    def _add_reshape_layer(self, dense_layer):
        return Reshape(self._shape_before_bottleneck)(dense_layer)

    def _add_conv_transpose_layers(self, x):
        """"""Add conv transpose blocks.""""""
        # loop through all the conv layers in reverse order and stop at the
        # first layer
        for layer_index in reversed(range(1, self._num_conv_layers)):
            x = self._add_conv_transpose_layer(layer_index, x)
        return x

    def _add_conv_transpose_layer(self, layer_index, x):
        layer_num = self._num_conv_layers - layer_index
        conv_transpose_layer = Conv2DTranspose(
            filters=self.conv_filters[layer_index],
            kernel_size=self.conv_kernels[layer_index],
            strides=self.conv_strides[layer_index],
            padding=""same"",
            name=f""decoder_conv_transpose_layer_{layer_num}""
        )
        x = conv_transpose_layer(x)
        x = ReLU(name=f""decoder_relu_{layer_num}"")(x)
        x = BatchNormalization(name=f""decoder_bn_{layer_num}"")(x)
        return x

    def _add_decoder_output(self, x):
        conv_transpose_layer = Conv2DTranspose(
            filters=1,
            kernel_size=self.conv_kernels[0],
            strides=self.conv_strides[0],
            padding=""same"",
            name=f""decoder_conv_transpose_layer_{self._num_conv_layers}""
        )
        x = conv_transpose_layer(x)
        output_layer = Activation(""sigmoid"", name=""sigmoid_layer"")(x)
        return output_layer

    def _build_encoder(self):
        encoder_input = self._add_encoder_input()
        conv_layers = self._add_conv_layers(encoder_input)
        bottleneck = self._add_bottleneck(conv_layers)
        self._model_input = encoder_input
        self.encoder = Model(encoder_input, bottleneck, name=""encoder"")

    def _add_encoder_input(self):
        return Input(shape=self.input_shape, name=""encoder_input"")

    def _add_conv_layers(self, encoder_input):
        """"""Create all convolutional blocks in encoder.""""""
        x = encoder_input
        for layer_index in range(self._num_conv_layers):
            x = self._add_conv_layer(layer_index, x)
        return x

    def _add_conv_layer(self, layer_index, x):
        """"""Add a convolutional block to a graph of layers, consisting of
        conv 2d + ReLU + batch normalization.
        """"""
        layer_number = layer_index + 1
        conv_layer = Conv2D(
            filters=self.conv_filters[layer_index],
            kernel_size=self.conv_kernels[layer_index],
            strides=self.conv_strides[layer_index],
            padding=""same"",
            name=f""encoder_conv_layer_{layer_number}""
        )
        x = conv_layer(x)
        x = ReLU(name=f""encoder_relu_{layer_number}"")(x)
        x = BatchNormalization(name=f""encoder_bn_{layer_number}"")(x)
        return x

    def _add_bottleneck(self, x):
        """"""Flatten data and add bottleneck with Guassian sampling (Dense
        layer).
        """"""
        self._shape_before_bottleneck = K.int_shape(x)[1:]
        x = Flatten()(x)
        self.mu = Dense(self.latent_space_dim, name=""mu"")(x)
        self.log_variance = Dense(self.latent_space_dim,
                                  name=""log_variance"")(x)

        def sample_point_from_normal_distribution(args):
            mu, log_variance = args
            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,
                                      stddev=1.)
            sampled_point = mu + K.exp(log_variance / 2) * epsilon
            return sampled_point

        x = Lambda(sample_point_from_normal_distribution,
                   name=""encoder_output"")([self.mu, self.log_variance])
        return x


if __name__ == ""__main__"":
    autoencoder = VAE(
        input_shape=(28, 28, 1),
        conv_filters=(32, 64, 64, 64),
        conv_kernels=(3, 3, 3, 3),
        conv_strides=(1, 2, 2, 1),
        latent_space_dim=2
    )
    autoencoder.summary()


LEARNING_RATE = 0.0005
BATCH_SIZE = 32
EPOCHS = 100


def load_mnist():
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    x_train = x_train.astype(""float32"") / 255
    x_train = x_train.reshape(x_train.shape + (1,))
    x_test = x_test.astype(""float32"") / 255
    x_test = x_test.reshape(x_test.shape + (1,))

    return x_train, y_train, x_test, y_test


def train(x_train, learning_rate, batch_size, epochs):
    autoencoder = VAE(
        input_shape=(28, 28, 1),
        conv_filters=(32, 64, 64, 64),
        conv_kernels=(3, 3, 3, 3),
        conv_strides=(1, 2, 2, 1),
        latent_space_dim=2
    )
    autoencoder.summary()
    autoencoder.compile(learning_rate)
    autoencoder.train(x_train, batch_size, epochs)
    return autoencoder


if __name__ == ""__main__"":
    x_train, _, _, _ = load_mnist()
    autoencoder = train(x_train[:10000], LEARNING_RATE, BATCH_SIZE, EPOCHS)
    autoencoder.save(""model"")
```


### Relevant log output

```shell
File ""c:\users\connor\appdata\local\programs\python\python39\lib\site-packages\spyder_kernels\py3compat.py"", line 356, in compat_exec
    exec(code, globals, locals)

  File ""c:\python\autoencoder\train.py"", line 38, in <module>
    autoencoder = train(x_train[:10000], LEARNING_RATE, BATCH_SIZE, EPOCHS)

  File ""c:\python\autoencoder\train.py"", line 31, in train
    autoencoder.compile(learning_rate)

  File ""C:\Python\Autoencoder\Variational_Autoencoder.py"", line 53, in compile
    self.model.compile(optimizer=optimizer,

  File ""C:\Users\Connor\AppData\Roaming\Python\Python39\site-packages\tensorflow\python\trackable\base.py"", line 205, in _method_wrapper
    result = method(self, *args, **kwargs)

  File ""C:\Users\Connor\AppData\Roaming\Python\Python39\site-packages\keras\engine\training_v1.py"", line 477, in compile
    self._cache_output_metric_attributes(metrics, weighted_metrics)

  File ""C:\Users\Connor\AppData\Roaming\Python\Python39\site-packages\keras\engine\training_v1.py"", line 2010, in _cache_output_metric_attributes
    training_utils_v1.collect_per_output_metric_info(

  File ""C:\Users\Connor\AppData\Roaming\Python\Python39\site-packages\keras\engine\training_utils_v1.py"", line 1041, in collect_per_output_metric_info
    metric_fn._from_serialized = from_serialized

AttributeError: 'method' object has no attribute '_from_serialized'
```
</details>"
58053,tf.saturate_cast errors for tf.complex type tensor,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.5 LTS

### Mobile device

_No response_

### Python version

 3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
From code below, the tf.saturate_cast need to check dtype's min
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L713-L743

However, from code below, min is not support for complex64 or complex128
https://github.com/tensorflow/tensorboard/blob/master/tensorboard/compat/tensorflow_stub/dtypes.py#L188-L194

The documentation for tf.saturate_cast said it support any tensor or dtype desired. Therefore, either code or documentation need to be changed
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/math_ops.py#L716-L729
```


### Standalone code to reproduce the issue

```shell
Code like: 

import tensorflow as tf
arg_0_tensor = tf.complex(tf.random.uniform([2, 1], dtype=tf.float32),tf.random.uniform([2, 1], dtype=tf.float32))
arg_0_tensor = tf.saturate_cast(arg_0_tensor,dtype=tf.float32)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/dtypes.py"", line 110, in min
    raise TypeError(f""Cannot find minimum value of {self} with ""
TypeError: Cannot find minimum value of <dtype: 'complex64'> with type <dtype: 'complex64'>.
```
</details>"
58052,How to build tflite-runtime .whl with XNNPACK?,The pre-buit wheels for armv7l don't seem to use XNNPACK. Is there a way to build tflite-runtime such that it uses XNNPACK delegate (like it does on Colab)?
58051,[XLA] b/243182930 LiteralBase::Reshape,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

master

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Can you expand a little bit over `b/243182930`?
In OSS we don't see the details of this ticket:

https://github.com/tensorflow/tensorflow/blob/3d32b9fea61196254fde629e86a52193e781a76f/tensorflow/compiler/xla/literal.cc#L967-L970

What is required?


### Standalone code to reproduce the issue

Do you have any expected failing test to add in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/literal_test.cc?


### Relevant log output

_No response_</details>"
58050,How to disable logging to the standard output in C++?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 22.04LTS

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc 11.2.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

How to disable logging to the standard output in C++? E.g. the message ""INFO: Created TensorFlow Lite XNNPACK delegate for CPU."" There are a plethora of questions about this. Most of them concern Python, and some C/C++. All of them boil down to setting an environment variable as:
`TF_CPP_MIN_LOG_LEVEL=3`
Sometimes together with:
`TF_CPP_MAX_VLOG_LEVEL=0`

I set these environment variables with setenv() or putenv(). I checked with getenv() at the start of main() whether they were set correctly, and they are. See code provied with this issue.

I also tried:
`export TF_CPP_MIN_LOG_LEVEL=3`
`export TF_CPP_MAX_VLOG_LEVEL=0`
`./my_executable`

And tried:
`TF_CPP_MIN_LOG_LEVEL=3 ./my_executable`

Yet I keep seeing ""INFO: Created TensorFlow Lite XNNPACK delegate for CPU."" on the standard output. This is driving me crazy. A solution is therefore warmly welcomed.


### Standalone code to reproduce the issue

```shell
#include ""tensorflow/lite/model.h""
#include ""tensorflow/lite/interpreter.h""
#include ""tensorflow/lite/kernels/register.h""
#include <iostream>

using namespace tflite;
using namespace std;

int main() {
	//setenv(""TF_CPP_MIN_LOG_LEVEL"", ""3"", 1);

	char env[] = ""TF_CPP_MIN_LOG_LEVEL=3"";
	putenv(env);

	char* check_env;
	check_env = getenv (""TF_CPP_MIN_LOG_LEVEL"");
	if (check_env == NULL)
		cout << ""TF_CPP_MIN_LOG_LEVEL not set\n"";
	else
		cout << ""TF_CPP_MIN_LOG_LEVEL = "" << check_env << ""\n"";

	std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(""my_network.tflite"");
	tflite::ops::builtin::BuiltinOpResolver resolver;

	std::unique_ptr<tflite::Interpreter> interpreter;
	tflite::InterpreterBuilder(*model, resolver)(&interpreter);
	interpreter->SetNumThreads(1);

	interpreter->AllocateTensors();

	return EXIT_SUCCESS;
}
```


### Relevant log output

_No response_</details>"
58048,`Rsqrt` missing in `tensorflow/lite/kernels/internal/reference`,"**System information**
- Linux Ubuntu 16.04
- TensorFlow 2.9.1

Hello,

I converted `tf.keras.layers.LayerNormalization` to `tflite and got the following:

![image](https://user-images.githubusercontent.com/76564442/195016843-088aea0f-6301-4d6e-9ea9-3bbc36a3d744.png)

The code I used is as follows:

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8  # or tf.uint8
tflite_quant_model = converter.convert()

tflite_models_dir = pathlib.Path(""./tflite_models/"")
tflite_models_dir.mkdir(exist_ok=True, parents=True)

tflite_model_quant_file = tflite_models_dir/""model_layer1_encoder.tflite""
tflite_model_quant_file.write_bytes(tflite_quant_model)
```

As you can see I specified that only `tf.lite.OpsSet.TFLITE_BUILTINS_INT8` should be supported and I got a `tflite` without any error. My understanding was that `rsqrt` was not yet supported in int8 (see this [issue](https://github.com/tensorflow/tensorflow/issues/57906)). 

1. Is `rsqrt` supported in `tf.lite.OpsSet.TFLITE_BUILTINS_INT8` spec?

2. I could not find the implementation of `rsqrt` in `tensorflow/lite/kernels/internal/reference`. Can you share a link to the tflite int8 implementation for `rsqrt`?

Thank you for taking the time to answer this. Really appreciate your help. Thanks."
58047,tf.nn.conv2d failed to activate TF-32 mode,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

2.6.2

### Custom Code

Yes

### OS Platform and Distribution

18.04

### Mobile device

_No response_

### Python version

3.7.5

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA-11.6/cuDNN version 8300

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I tried to test convolution's accuracy under TF-32 mode on my A100 chips by comparing TF-32's and FP-32's computaitonal results.

Firstly, I tested a simple MatMul example (as given here:https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_tensor_float_32_execution). TF-32's and FP-32's results are indeed different as expected. It indicates my environment supports TF-32 mode by default.

Then I used tf.nn.conv2d() method fed with randomly generated float32 data(feature map[1,16,7,7], weight(16,16,3,3)), to test acc of convolution under TF-32 mode, but TF-32's and FP-32's results turned to be identical. It seems like tf.nn.conv2d() failed to activate TF-32, and convlution is done in full-precision mode?
```


### Standalone code to reproduce the issue

```shell
fm = np.fromfile(input_fm_bin,dtype=np.float32).reshape([1,16,7,7]).transpose((0,2,3,1))
w = np.fromfile(filter_bin,dtype=np.float32).reshape([16,16,3,3]).transpose(2, 3, 1, 0)
bias = np.fromfile(bias_bin,dtype=np.float32)


fm = tf.convert_to_tensor(fm)
w = tf.convert_to_tensor(w)
bias = tf.convert_to_tensor(bias)
res_tf32 = tf.nn.conv2d(fm, w, [1, 1],[[0, 0], [0, 0], [0, 0], [0, 0]],""NHWC"", [1, 2, 2, 1])
res_tf32 = tf.nn.bias_add(res_tf32, bias, data_format=""NHWC"")

tf.config.experimental.enable_tensor_float_32_execution(False)
res_full = tf.nn.conv2d(fm, w, [1, 1],[[0, 0], [0, 0], [0, 0], [0, 0]],""NHWC"", [1, 2, 2, 1])
res_full = tf.nn.bias_add(res_full, bias, data_format=""NHWC"")
```


### Relevant log output

_No response_</details>"
58041,Issues running tensorflow 2.10.0 on azure nc4as_t4_v3 Virtual machine with Tesla T4 GPU attached to Ubuntu 20.04,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

Cuda 11.2, cuDNN 8.1.1.33 (compatible with Cuda 11.2)

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Unable to run tensor-flow on GPU on ubuntu 20.04.
```


### Standalone code to reproduce the issue

```shell
python3 -c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""
```

Output:
```
2022-10-10 14:59:58.295395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-10 14:59:59.964199: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-10 15:00:01.498706: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:
2022-10-10 15:00:01.498789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:
2022-10-10 15:00:01.498802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2022-10-10 15:00:03.290844: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2022-10-10 15:00:03.290882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ml-testserver-1): /proc/driver/nvidia/version does not exist
[]

```


Nvidia 460 is installed using
```
sudo apt install nvidia-driver-460
```

Output:
```
mlserver1@ml-testserver-1:~$ dpkg --list | grep nvidia
ii  libnvidia-cfg1-460:amd64                 460.27.04-0ubuntu1                amd64        NVIDIA binary OpenGL/GLX configuration library
ii  libnvidia-common-460                     460.27.04-0ubuntu1                all          Shared files used by the NVIDIA libraries
ii  libnvidia-compute-460:amd64              460.27.04-0ubuntu1                amd64        NVIDIA libcompute package
ii  libnvidia-decode-460:amd64               460.27.04-0ubuntu1                amd64        NVIDIA Video Decoding runtime libraries
ii  libnvidia-encode-460:amd64               460.27.04-0ubuntu1                amd64        NVENC Video Encoding runtime library
ii  libnvidia-extra-460:amd64                460.27.04-0ubuntu1                amd64        Extra libraries for the NVIDIA driver
ii  libnvidia-fbc1-460:amd64                 460.27.04-0ubuntu1                amd64        NVIDIA OpenGL-based Framebuffer Capture runtime library
ii  libnvidia-gl-460:amd64                   460.27.04-0ubuntu1                amd64        NVIDIA OpenGL/GLX/EGL/GLES GLVND libraries and Vulkan ICD
ii  libnvidia-ifr1-460:amd64                 460.27.04-0ubuntu1                amd64        NVIDIA OpenGL-based Inband Frame Readback runtime library
ii  nvidia-compute-utils-460                 460.27.04-0ubuntu1                amd64        NVIDIA compute utilities
iF  nvidia-dkms-460                          460.27.04-0ubuntu1                amd64        NVIDIA DKMS package
iU  nvidia-driver-460                        460.27.04-0ubuntu1                amd64        NVIDIA driver metapackage
ii  nvidia-kernel-common-460                 460.27.04-0ubuntu1                amd64        Shared files used with the kernel module
ii  nvidia-kernel-source-460                 460.27.04-0ubuntu1                amd64        NVIDIA kernel source package
ii  nvidia-modprobe                          460.27.04-0ubuntu1                amd64        Load the NVIDIA kernel driver and create device files
ii  nvidia-prime                             0.8.16~0.20.04.2                  all          Tools to enable NVIDIA's Prime
ii  nvidia-settings                          460.27.04-0ubuntu1                amd64        Tool for configuring the NVIDIA graphics driver
ii  nvidia-utils-460                         460.27.04-0ubuntu1                amd64        NVIDIA driver support binaries
ii  screen-resolution-extra                  0.18build1                        all          Extension for the nvidia-settings control panel
ii  xserver-xorg-video-nvidia-460            460.27.04-0ubuntu1                amd64        NVIDIA binary Xorg driver

```

Cuda is installed using (Ref: https://developer.nvidia.com/cuda-11.2.0-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=2004&target_type=deblocal)

```
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda-repo-ubuntu2004-11-2-local_11.2.0-460.27.04-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-11-2-local_11.2.0-460.27.04-1_amd64.deb
sudo apt-key add /var/cuda-repo-ubuntu2004-11-2-local/7fa2af80.pub
sudo apt-get update
sudo apt-get -y install cuda
```

I tried couple of ways installing tensorflow 2.7.0 and nvidia drivers 515, cuda 11.6 all of them are in vain. 

Looks like tensorflow only supports Cuda 11.2.
However nvidia-460 does not seem to be run on ubuntu 20.04.

Output of nvidia-smi
```
NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.

```

I have tried couple of weays to fix it on ubuntu 20.04 from nvidia developer forums but in vain. 

Kernel details: 
```
Linux ml-testserver-1 5.15.0-1020-azure #25~20.04.1-Ubuntu SMP Thu Sep 1 19:20:56 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux

```

I am pretty sure the error
```
2022-10-10 15:00:03.290844: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2022-10-10 15:00:03.290882: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ml-testserver-1): /proc/driver/nvidia/version does not exist

```
is because nvidia drivers is not running. Any help over here would be great.

However the other errors,
```
Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:
2022-10-10 15:00:01.498789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:/usr/local/cuda/lib64:/usr/local/cuda-11.2/lib64:
```
the shared libraries are not isntalled along with Cuda 11.2, how should i be fixing them. ??


Any help is highly appreicated. Kind of stuck since 2 days. Looking for a help.
```


### Relevant log output

_No response_</details>"
58040,Softlayer Operation with Tflite,"Does Tflite support softlayer operation or need to implement custom Ops as my model is using softlayer as a custom operation and when i'm loading the model that time i'm facing the error. 
![error1](https://user-images.githubusercontent.com/25703066/194878693-694ebed9-d180-45ce-99b0-9072f0feec7c.jpg)
"
58038,PyLint incorrectly identifies `tf.concat` function signature,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

When running [`pylint -E check.py`](https://pylint.pycqa.org/en/latest/index.html) on the code snippet below, the following errors are raised:
```shell
check.py:18:10: E1123: Unexpected keyword argument 'axis' in function call (unexpected-keyword-arg)
check.py:18:10: E1120: No value for argument 'values' in function call (no-value-for-parameter)
```
which is unexpected, since the usage is correct as per [the documentation](https://www.tensorflow.org/api_docs/python/tf/concat). The version of PyLint that I'm currently using is the latest: `2.16.0`.

I've raised [a similar issue](https://github.com/tensorflow/tensorflow/issues/43038) in the past, which has been successfully resolved. Indeed, when running `pylint` on the snippet (as also indicated), doesn't raise this issue anymore.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf


def previously_not_working():
    """"""This failed before, but it works now, see also https://github.com/tensorflow/tensorflow/issues/43038""""""
    tensor = tf.random.uniform((2, 4), minval=0, maxval=256)
    tf.split(tensor, num_or_size_splits=2, axis=-1)


def failing():
    tensor = tf.random.uniform((2, 4), minval=0, maxval=256)
    print(tf.concat([tensor, tensor], axis=1).shape)
```


### Relevant log output

```shell
check.py:18:10: E1123: Unexpected keyword argument 'axis' in function call (unexpected-keyword-arg)
check.py:18:10: E1120: No value for argument 'values' in function call (no-value-for-parameter)
```
</details>"
58037,when will import the alpha tensor's fast matrix mutiplication.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.9

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
https://www.nature.com/articles/s41586-022-05172-4
faster matrix multiplication algorithms has been Discovered by alpha tensor. when will tensorflow import these multiplicatio algorithms
```


### Standalone code to reproduce the issue

```shell
https://www.nature.com/articles/s41586-022-05172-4
```


### Relevant log output

_No response_</details>"
58035,[TFLite] Slice-Conv2d Crash,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf-nightly

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Running the following model compiled by `tflite` will crash given `rlim` is `2**31`, but it works perfectly in other settings including TF eager mode. Given that the model is valid and deployable, I think it is worth fixing to make tensorflow lite more secure.

```python
class Model(tf.Module):
    @tf.function
    def __call__(self, x, rlim):
        return tf.raw_ops.Conv2D(
            # `rlim` > index_max means `min(index_max, rlim)` which is still valid in slicing.
            input=x[:, :, :rlim, :],
            filter=tf.zeros([1, 1, 1, 1]),
            strides=[1, 2, 2, 1],
            padding=""SAME"",
        )
```

Please find the [gist](https://colab.research.google.com/drive/1i2gfQw4Wf218b0uDMSqhBiRvGYfjRh61#scrollTo=oaesGqskdCqw).

Also note that the general slicing semantic in Python allows end > len(a) in a[begin:end] and in such a case a[begin:end] will be regarded as a[begin:min(len(a), end)].

```python
[1,2,3][:2**31] == [1,2,3] # True
```


### Standalone code to reproduce the issue

```shell
!pip install tf-nightly
import tensorflow as tf

class Model(tf.Module):
    @tf.function
    def __call__(self, x, rlim):
        return tf.raw_ops.Conv2D(
            # `rlim` > index_max means `min(index_max, rlim)` in Python.
            input=x[:, :, :rlim, :],
            filter=tf.zeros([1, 1, 1, 1]),
            strides=[1, 2, 2, 1],
            padding=""SAME"",
        )

model = Model()
inputs = {
    ""x"": tf.zeros([1, 1, 1, 1]),
    ""rlim"": tf.constant(2**31, dtype=tf.int64) # 2**31 < int64::max()
}
out = model(**inputs)  # Pass

tflite_bytes = tf.lite.TFLiteConverter.from_concrete_functions(
    funcs=[model.__call__.get_concrete_function(**inputs)], trackable_obj=model
).convert()
interpreter = tf.lite.Interpreter(model_content=tflite_bytes)
runner = interpreter.get_signature_runner()
print(""----- TFLite output shape: "", runner(**inputs))  # Crash!!!
```


### Relevant log output

```shell
Crash.
```
</details>"
58034,"XLA JIT compile failing on TF 2.9.2, A100 GPUs (on GCP VMs)","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9.2

### Custom Code

Yes

### OS Platform and Distribution

Debian GNU/Linux 10 (buster)

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.3/8

### GPU model and memory

A100, 80GB

### Current Behaviour?

```shell
Till a few weeks ago, I was able to successfully use XLA compilation when training with GPUs on GCP VMs.
Specifically, I used `compile_jit=True` when doing a model.compile() for a TF Keras model. Having trained my models, I didn't run any TF training jobs for a while. Recently (a week ago) I tried running the same models, but the code now complains that it cannot find libcudnn.so.8. The same code works without `compile_jit=True`, but that does require a slightly smaller batch size to fit in memory.

The log with `compile_jit=True` says ""Could not load library libcudnn_cnn_train.so.8"", but that library is most definitely present, since the same code does work without using XLA JIT compilation.
```


### Standalone code to reproduce the issue

```shell
Unable to provide a small case, haven't been able to reproduce on small models.
```


### Relevant log output

```shell
Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/bin/../lib/./libcudnn_ops_train.so.8: symbol _Z22cudnnGenericOpTensorNdILi3EE13cudnnStatus_tP12cudnnContext16cudnnGeneric
Op_t21cudnnNanPropagation_tPKdPKvPK17cudnnTensorStructS8_S8_SB_S8_S8_SB_Pv version libcudnn_ops_infer.so.8 not defined in file libcudnn_ops_infer.so.8 with link time reference
Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/bin/../lib/./libcudnn_ops_train.so.8: symbol _Z22cudnnGenericOpTensorNdILi3EE13cudnnStatus_tP12cudnnContext16cudnnGeneric
Op_t21cudnnNanPropagation_tPKdPKvPK17cudnnTensorStructS8_S8_SB_S8_S8_SB_Pv version libcudnn_ops_infer.so.8 not defined in file libcudnn_ops_infer.so.8 with link time reference
Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/bin/../lib/./libcudnn_ops_train.so.8: symbol _Z22cudnnGenericOpTensorNdILi3EE13cudnnStatus_tP12cudnnContext16cudnnGeneric
Op_t21cudnnNanPropagation_tPKdPKvPK17cudnnTensorStructS8_S8_SB_S8_S8_SB_Pv version libcudnn_ops_infer.so.8 not defined in file libcudnn_ops_infer.so.8 with link time reference
Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/bin/../lib/./libcudnn_ops_train.so.8: symbol _Z22cudnnGenericOpTensorNdILi3EE13cudnnStatus_tP12cudnnContext16cudnnGeneric
Op_t21cudnnNanPropagation_tPKdPKvPK17cudnnTensorStructS8_S8_SB_S8_S8_SB_Pv version libcudnn_ops_infer.so.8 not defined in file libcudnn_ops_infer.so.8 with link time reference
Could not load library libcudnn_cnn_train.so.8. Error: /opt/conda/bin/../lib/./libcudnn_ops_train.so.8: symbol _Z22cudnnGenericOpTensorNdILi3EE13cudnnStatus_tP12cudnnContext16cudnnGeneric
Op_t21cudnnNanPropagation_tPKdPKvPK17cudnnTensorStructS8_S8_SB_S8_S8_SB_Pv version libcudnn_ops_infer.so.8 not defined in file libcudnn_ops_infer.so.8 with link time reference
Please make sure libcudnn_cnn_train.so.8 is in your library path!
Please make sure libcudnn_cnn_train.so.8 is in your library path!
Please make sure libcudnn_cnn_train.so.8 is in your library path!
Please make sure libcudnn_cnn_train.so.8 is in your library path!
Please make sure libcudnn_cnn_train.so.8 is in your library path!
Please make sure libcudnn_cnn_train.so.8 is in your library path!
Please make sure libcudnn_cnn_train.so.8 is in your library path!


  (0) UNKNOWN:  Failed to determine best cudnn convolution algorithm for:
%cudnn-conv-bw-filter = (f32[1,1,768,1664]{1,0,2,3}, u8[0]{0}) custom-call(f32[2,768,90,180]{3,2,1,0} %add.19138, f32[2,1664,90,180]{3,2,1,0} %multiply.19168), window={size=1x1}, dim_labe
ls=bf01_01io->bf01, custom_call_target=""__cudnn$convBackwardFilter"", metadata={op_type=""Conv2DBackpropFilter"" op_name=""gradient_tape/model/decode/Conv2D_1/Conv2DBackpropFilter"" source_fil
e=""/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"" source_line=176}, backend_config=""{\""conv_result_scale\"":1,\""activation_mode\"":\""0\"",\""side
_input_scale\"":0}""

Original error: INTERNAL: All algorithms tried for %cudnn-conv-bw-filter = (f32[1,1,768,1664]{1,0,2,3}, u8[0]{0}) custom-call(f32[2,768,90,180]{3,2,1,0} %add.19138, f32[2,1664,90,180]{3,2
,1,0} %multiply.19168), window={size=1x1}, dim_labels=bf01_01io->bf01, custom_call_target=""__cudnn$convBackwardFilter"", metadata={op_type=""Conv2DBackpropFilter"" op_name=""gradient_tape/mod
el/decode/Conv2D_1/Conv2DBackpropFilter"" source_file=""/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_experimental/optimizer.py"" source_line=176}, backend_config=""{\""con
v_result_scale\"":1,\""activation_mode\"":\""0\"",\""side_input_scale\"":0}"" failed. Falling back to default algorithm.  Per-algorithm errors:

To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.
         [[{{node while/replica_3/StatefulPartitionedCall}}]]
         [[while/loop_body_control/_3358/_36]]
```
</details>"
58032,Support Python 3.11,"Currently Python 3.11 isn't fully supported in TensorFlow yet, including testing in CI and publishing wheels to PyPI.

Python 3.11 is currently in Release Candidate state and will be released in about two weeks. Major packages like NumPy, Pandas, SciPy and Matplotlib have already uploaded their Python 3.11 wheels to PyPI. 

Python 3.11 new features include:

> - [PEP 657](https://www.python.org/dev/peps/pep-0657/) -- Include Fine-Grained Error Locations in Tracebacks
> - [PEP 654](https://www.python.org/dev/peps/pep-0654/) -- Exception Groups and except*
> - [PEP 673](https://www.python.org/dev/peps/pep-0673/) -- Self Type
> - [PEP 646](https://www.python.org/dev/peps/pep-0646/)-- Variadic Generics
> - [PEP 680](https://www.python.org/dev/peps/pep-0680/)-- tomllib: Support for Parsing TOML in the Standard Library
> - [PEP 675](https://www.python.org/dev/peps/pep-0675/)-- Arbitrary Literal String Type
> - [PEP 655](https://www.python.org/dev/peps/pep-0655/)-- Marking individual TypedDict items as required or potentially-missing
> - [bpo-46752](https://bugs.python.org/issue46752)-- Introduce task groups to asyncio
> - The [Faster Cpython Project](https://github.com/faster-cpython) is already yielding some exciting results: this version of CPython 3.11 is ~ 19% faster on the geometric mean of the [PyPerformance benchmarks](https://speed.python.org/), compared to 3.10.0.

TensorFlow is an import package in the deep learning stack, so support at release will help speed up Python 3.11 adoption.

It would be great to have full Python 3.11 support in TensorFlow by the time Python 3.11.0 gets released, ([expected](https://peps.python.org/pep-0664/) Monday October 6th, 2022). This includes testing in CI and publishing wheels to PyPI.

This issue can be used as a tracking issue. This includes:

- [ ] TensorFlow builds fully on Python 3.11
- [x] All TensorFlow tests pass on Python 3.11
- [ ] All CI is run and green on Python 3.11
- [ ] Wheels are uploaded to PyPI for [tf-nightly](https://pypi.org/project/tf-nightly/#files)
  - [x] Linux
  - [x] macOS
  - [ ] Windows
- [ ] Wheels are uploaded to PyPI for at least one TensorFlow release"
58031,CosineSimilarity outputs result smaller than -1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0-dev20221009

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.7.14

### Bazel version

N/A

### GCC/Compiler version

N/A

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
Following the documentation: https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity, the output of `tf.keras.losses.CosineSimilarity` should be within the range: [-1, 1]. However, when I calculate the cosine similarity loss between two arrays: `[[0,2,3]]` and `[[0,2,3]]`, it outputs `-1.0000001`.

I notice that this issue appeals when the array contains `0.`. I guess it is caused by the computation underflow, but I still don't know why a value smaller than -1 would be outputted. Maybe you can try to do clamping after the computation of cosine similarity?
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
y_true = [[0.,2.,3.]]
y_pred = [[0.,2.,3.]]
cosine_loss = tf.keras.losses.CosineSimilarity()
res = cosine_loss(y_true, y_pred).numpy()
print(""tensorflow: "", res)
```


### Relevant log output

```shell
tensorflow:  -1.0000001
```
</details>"
58030,tf.keras.metrics.CategoricalAccuracy crash with xla on cuda when dtype is set to complex,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.keras.metrics.CategoricalAccuracy crash with xla on cuda when dtype is set to copmlex
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
CategoricalAccuracy_class = tf.keras.metrics.CategoricalAccuracy(dtype=tf.complex64)

@tf.function(jit_compile=True)
def f(x0, x1, x2):
    return CategoricalAccuracy_class(x0, x1, x2)
x0 = [[0,0,1],[0,1,0]]
x1 = [[0.1, 0.1, 0.8], [0.05, 0, 0.95]]
x2 = [[0.5], [0.2]]
f(x0, x1, x2)
```


### Relevant log output

```shell
F tensorflow/compiler/xla/literal_util.cc:200] No min value for given type. 
 abort (core dumped)
```
</details>"
58028,tf.experimental.numpy.argmax/argmin crash with xla with complex input,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10, tf-nightly

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.experimental.numpy.argmax/argmin crash with xla with complex input
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

def f(x):
    return tf.experimental.numpy.argmax(x)

f_jitted = tf.function(jit_compile=True)(f)
a = tf.complex([0.],[2.])
f_jitted(a)
```


### Relevant log output

```shell
F tensorflow/compiler/xla/literal_util.cc:200] No min value for given type.  
abort (core dumped)
```
</details>"
58027,`tf.reverse_sequence` crash with abort when seq_axis is negative,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.reverse_sequence` crash with abort when seq_axis is negative
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

def f(input):
    seq_lengths = [7,2,3,5]
    seq_axis = -1
    batch_axis = 0
    return tf.reverse_sequence(input, seq_lengths, seq_axis=seq_axis, batch_axis=batch_axis)

f_jitted = tf.function(jit_compile=True)(f)
input=[[0]*8,[0]*8, [0]*8, [0]*8]
f_jitted(input)
# segfault
```


### Relevant log output

```shell
segmentation fault (core dumped)
```
</details>"
58026,Tensorflow CUDA A100 compatibility issue,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tensorflow-gpu==1.12.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 16.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

Nvidia A100

### Current Behaviour?

```shell
The compatibility table given in the tensorflow site does not contain specific minor versions for cuda and cuDNN. However, if the specific versions are not met, there is an compatibility error when I try to use tensorflow. For example for, tensorflow-gpu==1.12.0 and cuda==9.0, the compatible cuDNN version is 7.1.4 and if I have A100, tensorflow is not compatible. I can use them on a V100 GPU but not on A100 GPU.
```


### Standalone code to reproduce the issue

```shell
pip install --upgrade pip
pip install tensorflow-gpu==1.12.0
```


### Relevant log output

_No response_</details>"
58025,Node: 'IteratorGetNext' Input dataset was expected to contain 1152 elements but contained at least 1153 elements.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 22.0

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Node: 'IteratorGetNext'
Input dataset was expected to contain 1152 elements but contained at least 1153 elements.

While training the model after some epochs this error is encountered. I tried with different batch sizes but this still prevails.
```


### Standalone code to reproduce the issue

```shell
def get_dataset(dataset_path, img_size, batch_size, buffer_size):    
    
    all_dataset = tf.data.Dataset.list_files(dataset_path + ""*.png"")
    test_dataset = all_dataset.take(288) 
    train_dataset = all_dataset.skip(290)

    TRAINSET_SIZE = len(train_dataset)
    VALSET_SIZE= len(test_dataset)
        
    train_dataset = train_dataset.map(parse.parse_image)
    test_dataset = test_dataset.map(parse.parse_image)

    dataset = {""train"": train_dataset, ""val"": test_dataset}

    dataset['train'] = dataset['train'].map(parse.load_image_train)
    dataset['train'] = dataset['train'].shuffle(buffer_size=buffer_size, seed=42)
    dataset['train'] = dataset['train'].repeat()
    dataset['train'] = dataset['train'].batch(batch_size)
    dataset['train'] = dataset['train'].prefetch(buffer_size=tf.data.experimental.AUTOTUNE)


    dataset['val'] = dataset['val'].map(parse.load_image_test)
    dataset['val'] = dataset['val'].repeat()
    dataset['val'] = dataset['val'].batch(batch_size)
    dataset['val'] = dataset['val'].prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset['train'].apply(tf.data.experimental.assert_cardinality(1152)), dataset['val'].apply(tf.data.experimental.assert_cardinality(288))

train_dataset, val_dataset = get_dataset(args.dataset_root, 128, 12, 1000)

results = args.std_model.fit(train_dataset, epochs=100, steps_per_epoch = len(train_dataset) // args.batch_size, validation_steps= len(val_dataset) // args.batch_size,
          validation_data=val_dataset, callbacks=callbacks)
```


### Relevant log output

```shell
File ""/scripts/../src/main.py"", line 68, in <module>
    main()
  File ""/scripts/../src/main.py"", line 54, in main
    Std_train.train(args, train_dataset, val_dataset)
  File ""/src/models/Std_train.py"", line 32, in train
    results = args.std_model.fit(train_dataset, epochs=100, steps_per_epoch = len(train_dataset) // args.batch_size, validation_steps= len(val_dataset) // args.batch_size,
  File ""/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:

Detected at node 'IteratorGetNext' defined at (most recent call last):
    File ""/scripts/../src/main.py"", line 68, in <module>
      main()
    File ""/scripts/../src/main.py"", line 54, in main
      Std_train.train(args, train_dataset, val_dataset)
    File ""/src/models/Std_train.py"", line 32, in train
      results = args.std_model.fit(train_dataset, epochs=100, steps_per_epoch = len(train_dataset) // args.batch_size, validation_steps= len(val_dataset) // args.batch_size,
    File ""/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1384, in fit
      tmp_logs = self.train_function(iterator)
    File ""/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1021, in train_function
      return step_function(self, iterator)
    File ""/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1009, in step_function
      data = next(iterator)
Node: 'IteratorGetNext'
Input dataset was expected to contain 1152 elements but contained at least 1153 elements.
         [[{{node IteratorGetNext}}]] [Op:__inference_train_function_13520]
```
</details>"
58021,AMD GPU's support for Tensorflow,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 16.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: NA
-   **TensorFlow installed from (source or binary)**: Source
-   **TensorFlow version (use command below)**: 2.4
-   **Python version**: 3.9
-   **Bazel version (if compiling from source)**: NA
-   **GCC/Compiler version (if compiling from source)**: NA
-   **CUDA/cuDNN version**:
-   **GPU model and memory**: AMD ROCm
-   **Exact command to reproduce**: NA

### Describe the problem
Does Tensorflow officially support AMD GPU's ROCm framework? If yes, is the support mature for production use cases at large scale?
"
58019,tf.raw_ops.TruncateDiv documentation is not consistent,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

binary

### Tensorflow Version

2.9.1

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.raw_ops.TruncateDiv` is only supporting integer values, while it is written in the first line in the documentation. The parameters section is saying that all numeric dtypes are allowed.
```


### Standalone code to reproduce the issue

```shell
tf.raw_ops.TruncateDiv(x=np.array(1.), y=np.array(1.))
```


### Relevant log output

```shell
>>> tf.raw_ops.TruncateDiv(x=np.array(1.), y=np.array(1.))
2022-10-07 22:46:30.214942: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-10-07 22:46:30.214981: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-07 22:46:30.214999: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (653368f87bf1): /proc/driver/nvidia/version does not exist
2022-10-07 22:46:30.215221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Traceback (most recent call last):
  File ""/usr/lib/python3.8/code.py"", line 90, in runcode
    exec(code, self.locals)
  File ""<input>"", line 1, in <module>
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/tf_export.py"", line 400, in wrapper
    return f(**kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 11558, in truncate_div
    return truncate_div_eager_fallback(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 11603, in truncate_div_eager_fallback
    _result = _execute.execute(b""TruncateDiv"", 1, inputs=_inputs_flat,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError: Could not find device for node: {{node TruncateDiv}} = TruncateDiv[T=DT_DOUBLE]
All kernels registered for op TruncateDiv:
  device='GPU'; T in [DT_UINT64]
  device='GPU'; T in [DT_UINT32]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_UINT16]
  device='GPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_UINT64]
  device='CPU'; T in [DT_UINT32]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_UINT8]
 [Op:TruncateDiv]
```
</details>"
58018,Problems Spotted in Curl.BUILD,"Hello, wonderful TensorFlow team!

I happened to be looking at your [BUILD file for CURL](https://github.com/tensorflow/tensorflow/blame/master/third_party/curl.BUILD), since I was looking to build curl with bazel myself. (I'm not currently a TensorFlow user.) Along the way, I noticed some issues that might cause problems. I figured you all might want a heads up, so that's what this is.

The first thing that jumped out is that it hardcodes the SIZEOF defines to 8 for various sizes, which is gonna break on 32-bit systems. (Older Android, iOS, etc.) See `#  define SIZEOF_SIZE_T 8`. The defines for long, size_t, and time_t seem to be depended on fairly heavily from the code, so I'd be worried about memory errors.

More minorly, it looks like frameworks are missing from iOS (and there are maybe some easier and more compact ways of expressing that code). And there are just more generally some ways I think the code could probably be simplified. Like you could skip the genrule and get bash-free Windows compatibility and just use local_defines. Or I'm finding that globs work just fine for getting source and headers, rather than maintaining a constantly changing list. Finally, some things are potentially problematic, but unused in libcurl, like HAVE_FORK on iOS. I'm sure there are more things I missed, but that's a quick list of what I saw.

Thanks for reading!
Chris
(ex-Googler)

P.S. I'm writing a less problematic BUILD file to replace it. LMK if you'd be interested in collaborating!"
58013,Tensorflow Build Fail with `config=asan/msan/ubsan`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.13

### Bazel version

5.3.0

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
TensorFlow cannot be successfully built from source with address/memory/undefined
behavior sanitizers.
```


### Standalone code to reproduce the issue

```shell
bazel build --config=asan //tensorflow/tools/pip_package:build_pip_package
bazel build --config=msan //tensorflow/tools/pip_package:build_pip_package
bazel build --config=ubsan //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
For ubsan, the building gets stuck at linking:
[12,750 / 12,808] .../python:_pywrap_tensorflow_internal.so; 15247s local  // cannot terminate

For asan/msan, the building fails with the following message:
ERROR: /home/yuyao/.cache/bazel/_bazel_yuyao/ccc1279be1ec9be064e98d7fead8e6f8/external/libjpeg_turbo/BUILD.bazel:227:8: Executing genrule @libjpeg_turbo//:simd_x86_64_assemblage23 failed: (Exit 1): bash failed: error executing command 
  (cd /home/yuyao/.cache/bazel/_bazel_yuyao/ccc1279be1ec9be064e98d7fead8e6f8/execroot/org_tensorflow && \
  exec env - \
    PATH=/home/yuyao/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-x86_64/bin:/home/yuyao/.local/bin:/usr/local/cuda/compute-sanitizer:/usr/local/cuda/bin:/home/yuyao/.vscode-server/bin/74b1f979648cc44d385a2286793c226e611f59e7/bin/remote-cli:/home/yuyao/.conda/envs/ten-sanitizer/bin:/opt/miniconda3/condabin:/home/yuyao/.local/bin:/usr/local/cuda/compute-sanitizer:/usr/local/cuda/bin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PYTHON_BIN_PATH=/opt/miniconda3/bin/python3 \
    PYTHON_LIB_PATH=/opt/miniconda3/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for out in bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jchuff-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcphuff-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctflt-sse.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctfst-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctflt-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctfst-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctred-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jquantf-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jsimdcpu.o; do
  bazel-out/k8-opt/bin/external/nasm/nasm -f elf64    -DELF -DPIC -D__x86_64__    -I $(dirname bazel-out/k8-opt/bin/external/libjpeg_turbo/jconfig.h)/    -I $(dirname bazel-out/k8-opt/bin/external/libjpeg_turbo/jconfigint.h)/    -I $(dirname external/libjpeg_turbo/simd/nasm/jsimdcfg.inc.h)/    -I $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/    -o $out    $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.o}.asm)
done')
# Configuration: 014280d9fadad28e5975c79178a18398bf834eb4a872c13f9a858491aca2ea7f
# Execution platform: @local_execution_config_platform//:platform

=================================================================
==3375800==ERROR: LeakSanitizer: detected memory leaks

Direct leak of 14584 byte(s) in 360 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd4a17 in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236ccd4a17 in nasm_strcat external/nasm/nasmlib/malloc.c:123
    #3 0x56236cc7505a in find_label external/nasm/asm/labels.c:227
    #4 0x56236cc7535c in is_extern external/nasm/asm/labels.c:285
    #5 0x56236cc6ba70 in expr6 external/nasm/asm/eval.c:937
    #6 0x56236cc6be81 in expr5 external/nasm/asm/eval.c:567
    #7 0x56236cc6cf94 in expr4 external/nasm/asm/eval.c:542
    #8 0x56236cc6d107 in expr3 external/nasm/asm/eval.c:508
    #9 0x56236cc6d577 in expr2 external/nasm/asm/eval.c:482
    #10 0x56236cc6da47 in expr1 external/nasm/asm/eval.c:456
    #11 0x56236cc6df1b in expr0 external/nasm/asm/eval.c:430
    #12 0x56236cc6fa3c in evaluate external/nasm/asm/eval.c:988
    #13 0x56236cc7acf8 in parse_line external/nasm/asm/parser.c:879
    #14 0x56236cc54c8a in assemble_file external/nasm/asm/nasm.c:1502
    #15 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #16 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Direct leak of 14584 byte(s) in 360 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd4a17 in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236ccd4a17 in nasm_strcat external/nasm/nasmlib/malloc.c:123
    #3 0x56236cc7505a in find_label external/nasm/asm/labels.c:227
    #4 0x56236cc75286 in lookup_label external/nasm/asm/labels.c:268
    #5 0x56236cc6ba23 in expr6 external/nasm/asm/eval.c:918
    #6 0x56236cc6be81 in expr5 external/nasm/asm/eval.c:567
    #7 0x56236cc6cf94 in expr4 external/nasm/asm/eval.c:542
    #8 0x56236cc6d107 in expr3 external/nasm/asm/eval.c:508
    #9 0x56236cc6d577 in expr2 external/nasm/asm/eval.c:482
    #10 0x56236cc6da47 in expr1 external/nasm/asm/eval.c:456
    #11 0x56236cc6df1b in expr0 external/nasm/asm/eval.c:430
    #12 0x56236cc6fa3c in evaluate external/nasm/asm/eval.c:988
    #13 0x56236cc7acf8 in parse_line external/nasm/asm/parser.c:879
    #14 0x56236cc54c8a in assemble_file external/nasm/asm/nasm.c:1502
    #15 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #16 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Direct leak of 8409 byte(s) in 207 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd4a17 in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236ccd4a17 in nasm_strcat external/nasm/nasmlib/malloc.c:123
    #3 0x56236cc7505a in find_label external/nasm/asm/labels.c:227
    #4 0x56236cc75b5e in define_label external/nasm/asm/labels.c:452
    #5 0x56236cc7a75d in parse_line external/nasm/asm/parser.c:489
    #6 0x56236cc54c8a in assemble_file external/nasm/asm/nasm.c:1502
    #7 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #8 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Direct leak of 5632 byte(s) in 32 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd485c in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236cc8fd04 in do_directive external/nasm/asm/preproc.c:3062
    #3 0x56236cc9bd6f in pp_getline external/nasm/asm/preproc.c:5216
    #4 0x56236cc54c38 in assemble_file external/nasm/asm/nasm.c:1488
    #5 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #6 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Direct leak of 768 byte(s) in 192 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd485c in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236cc84113 in new_Token external/nasm/asm/preproc.c:1222
    #3 0x56236cc9d1ed in expand_mmacro external/nasm/asm/preproc.c:4901
    #4 0x56236cc9d1ed in pp_getline external/nasm/asm/preproc.c:5255
    #5 0x56236cc54c38 in assemble_file external/nasm/asm/nasm.c:1488
    #6 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #7 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Direct leak of 312 byte(s) in 3 object(s) allocated from:
    #0 0x7fc521520a06 in __interceptor_calloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:153
    #1 0x56236ccd4894 in nasm_zalloc external/nasm/nasmlib/malloc.c:85
    #2 0x56236ccae79f in elf_make_section external/nasm/output/outelf.c:396
    #3 0x56236ccae79f in elf_section_names external/nasm/output/outelf.c:463
    #4 0x56236cc678f9 in process_directives external/nasm/asm/directiv.c:249
    #5 0x56236cc54c6e in assemble_file external/nasm/asm/nasm.c:1498
    #6 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #7 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Direct leak of 128 byte(s) in 4 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd485c in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236cc87f4b in pp_reset external/nasm/asm/preproc.c:5031
    #3 0x56236cc54a08 in assemble_file external/nasm/asm/nasm.c:1481
    #4 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #5 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Indirect leak of 1536 byte(s) in 64 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd485c in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236cc9c9fb in pp_getline external/nasm/asm/preproc.c:5227
    #3 0x56236cc54c38 in assemble_file external/nasm/asm/nasm.c:1488
    #4 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #5 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

Indirect leak of 24 byte(s) in 2 object(s) allocated from:
    #0 0x7fc521520808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
    #1 0x56236ccd492f in nasm_malloc external/nasm/nasmlib/malloc.c:75
    #2 0x56236ccd492f in nasm_strdup external/nasm/nasmlib/malloc.c:104
    #3 0x56236ccae846 in elf_make_section external/nasm/output/outelf.c:407
    #4 0x56236ccae846 in elf_section_names external/nasm/output/outelf.c:463
    #5 0x56236cc678f9 in process_directives external/nasm/asm/directiv.c:249
    #6 0x56236cc54c6e in assemble_file external/nasm/asm/nasm.c:1498
    #7 0x56236cc527c8 in main external/nasm/asm/nasm.c:617
    #8 0x7fc520f14082 in __libc_start_main ../csu/libc-start.c:308

SUMMARY: AddressSanitizer: 45977 byte(s) leaked in 1224 allocation(s).
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /home/yuyao/dev/tensorflow/tensorflow/python/framework/BUILD:598:27 Linking tensorflow/python/framework/_op_def_util.so failed: (Exit 1): bash failed: error executing command 
  (cd /home/yuyao/.cache/bazel/_bazel_yuyao/ccc1279be1ec9be064e98d7fead8e6f8/execroot/org_tensorflow && \
  exec env - \
    PATH=/home/yuyao/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-x86_64/bin:/home/yuyao/.local/bin:/usr/local/cuda/compute-sanitizer:/usr/local/cuda/bin:/home/yuyao/.vscode-server/bin/74b1f979648cc44d385a2286793c226e611f59e7/bin/remote-cli:/home/yuyao/.conda/envs/ten-sanitizer/bin:/opt/miniconda3/condabin:/home/yuyao/.local/bin:/usr/local/cuda/compute-sanitizer:/usr/local/cuda/bin:/opt/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PYTHON_BIN_PATH=/opt/miniconda3/bin/python3 \
    PYTHON_LIB_PATH=/opt/miniconda3/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; for out in bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jccolor-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcgray-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jchuff-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcphuff-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jcsample-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdcolor-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdmerge-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jdsample-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctflt-sse.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctfst-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jfdctint-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctflt-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctfst-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctint-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jidctred-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jquantf-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-avx2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jquanti-sse2.o bazel-out/k8-opt/bin/external/libjpeg_turbo/simd/x86_64/jsimdcpu.o; do
  bazel-out/k8-opt/bin/external/nasm/nasm -f elf64    -DELF -DPIC -D__x86_64__    -I $(dirname bazel-out/k8-opt/bin/external/libjpeg_turbo/jconfig.h)/    -I $(dirname bazel-out/k8-opt/bin/external/libjpeg_turbo/jconfigint.h)/    -I $(dirname external/libjpeg_turbo/simd/nasm/jsimdcfg.inc.h)/    -I $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/    -o $out    $(dirname external/libjpeg_turbo/simd/x86_64/jccolext-sse2.asm)/$(basename ${out%.o}.asm)
done')
# Configuration: 014280d9fadad28e5975c79178a18398bf834eb4a872c13f9a858491aca2ea7f
# Execution platform: @local_execution_config_platform//:platform
```
</details>"
58009,Using nested loss functions in graph-mode,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I have a custom loss function in the following form:

def outer_loss(lambda1, lambda2, lambda3):
    def inner_loss(y_true, y_pred):
        # compute loss in loop
        return tf.convert_to_tensor(loss)
    return inner_loss
```
While this syntax works while in eager execution, graphmode throws an error.

However, I need this function to be able to accept parameters (i.e. in outer_loss) so that I can complete a proper hyperparameter execution. Is it possible to write a loss function that accepts both the true and predicted tensor, in addition to multiple parameters, while in graph-mode?
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

def MSE(lambda1, lambda2):
    def mse(y_true, y_pred):
        sq_diff = tf.pow(y_true-y_pred, lambda1)*lambda2
        return tf.reduce_mean(sq_diff)
model = keras.models.Sequential(
    [
        keras.layers.Conv2D(32, (3, 3), activation=""relu"", input_shape=input_shape),
        keras.layers.Conv2D(64, (3, 3), activation=""relu""),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation=""relu""),
        keras.layers.Dense(10, activation=""softmax""),
    ]
)
loss_f = MSE(lambda1=2, lambda2=3)
model.compile(loss=loss_f,optimizer=tf.keras.optimizers.Adam(0.01))

history = model.fit(x=x_train, y=y_train, epochs=10)
```

### Relevant log output
```
TypeError: To be compatible with tf.eager.defun, Python functions must return zero or more Tensors; in compilation of <function GBETA at 0x2af817ab4dc0>, found return value of type <class 'function'>, which is not a Tensor.
```
"
58007,transpose_op_test.py fails with rank 1 complex input on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tests fails for cases(Same was observed for complex64).

def testComplex128(self):
  self._testBoth(np.array(1 + 2j).astype(np.complex128))
  self._testBoth((1 + 2j) * np.arange(0, 21).astype(np.complex128))
```
It's unclear if it's necessary to conjugate a rank-1 complex input with conjugate=True. Even if passing input to output is the default case, the imag part became 1.999023 instead of 2.0 which could also fail 
`assertAllEqual`.
```


### Standalone code to reproduce the issue

```shell
python tensorflow/python/kernel_tests/math_ops/transpose_op_test.py
```


### Relevant log output

```shell
not equal lhs = array(1.-2.j)
not equal rhs = array(1.+1.99902344j)
Mismatched elements: 1 / 1 (100%)
Max absolute difference: 3.99902344
Max relative difference: 1.78911649
 x: array(1.-2.j)
 y: array(1.+1.999023j)
```
</details>"
58006,Running TF with Compute Sanitizer Results in Deadlock,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When I use compute sanitizer to execute python tests, invocation of certain APIs 
will trigger a deadlock and eventually lead to ""out-of-memory"" exception.
```


### Standalone code to reproduce the issue

```shell
Command: compute-sanitizer --tool memcheck python3 test.py

# Normal test code: tf.config.list_physical_devices('GPU') won't trigger deadlock

import tensorflow as tf

if __name__ = '__main__':
    _ = tf.config.list_physical_devices('GPU')

# Failed test code: tf.abs() will trigger deadlock
import tensorflow as tf

if __name__ == '__main__':
    _ = tf.abs(1)
```


### Relevant log output

```shell
========= Program hit cudaErrorMemoryAllocation (error 2) due to ""out of memory"" on CUDA API call to cudaDeviceGetStreamPriorityRange.
=========     Saved host backtrace up to driver entry point at error
=========     Host Frame: [0x350283]
=========                in /lib/x86_64-linux-gnu/libcuda.so.1
=========     Host Frame:cudaDeviceGetStreamPriorityRange [0x4513e]
=========                in /usr/local/cuda-11.6/targets/x86_64-linux/lib/libcudart.so.11.0
=========     Host Frame:cudaDeviceGetStreamPriorityRange [0x7dc35e]
=========                in /home/yuyao/.local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
=========     Host Frame:tensorflow::BaseGPUDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) [0x166f52a]
=========                in /home/yuyao/.local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
=========     Host Frame:tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) [0x1249c8f]
=========                in /home/yuyao/.local/lib/python3.8/site-packages/tensorflow/python/../libtensorflow_framework.so.2
=========     Host Frame:TFE_NewContext [0x51fff03]
=========                in /home/yuyao/.local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
=========     Host Frame:pybind11::cpp_function::initialize<pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(TFE_ContextOptions const*)#9}, pybind11::object, TFE_ContextOptions const*, pybind11::name, pybind11::scope, pybind11::sibling, pybind11::return_value_policy>(pybind11_init__pywrap_tfe(pybind11::module_&)::{lambda(TFE_ContextOptions const*)#9}&&, pybind11::object (*)(TFE_ContextOptions const*), pybind11::name const&, pybind11::scope const&, pybind11::sibling const&, pybind11::return_value_policy const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) [0x91bd9]
=========                in /home/yuyao/.local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so
=========     Host Frame:pybind11::cpp_function::dispatcher(_object*, _object*, _object*) [0x952e1]
=========                in /home/yuyao/.local/lib/python3.8/site-packages/tensorflow/python/_pywrap_tfe.so
=========     Host Frame:PyCFunction_Call [0x1f6929]
=========                in /usr/bin/python3
=========     Host Frame:_PyObject_MakeTpCall [0x1f74f6]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x171164]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6cd6]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16bbfa]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16bacd]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6cd6]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16bacd]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16cc1f]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16cc1f]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16cc1f]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:PyObject_Call [0x1f6082]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16d2d5]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16cc1f]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:PyObject_Call [0x1f6082]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16d2d5]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:PyObject_Call [0x1f6082]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x16d2d5]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:_PyFunction_Vectorcall [0x1f6eb3]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalFrameDefault [0x170b26]
=========                in /usr/bin/python3
=========     Host Frame:_PyEval_EvalCodeWithName [0x169dba]
=========                in /usr/bin/python3
=========     Host Frame:PyEval_EvalCode [0x2902a7]
=========                in /usr/bin/python3
=========     Host Frame: [0x27f951]
=========                in /usr/bin/python3
=========     Host Frame: [0x27f9cf]
=========                in /usr/bin/python3
=========     Host Frame: [0x27fa71]
=========                in /usr/bin/python3
=========     Host Frame:PyRun_SimpleFileExFlags [0x281b97]
=========                in /usr/bin/python3
=========     Host Frame:Py_RunMain [0x2b9d32]
=========                in /usr/bin/python3
=========     Host Frame:Py_BytesMain [0x2ba0bd]
=========                in /usr/bin/python3
=========     Host Frame:../csu/libc-start.c:342:__libc_start_main [0x24083]
=========                in /lib/x86_64-linux-gnu/libc.so.6
=========     Host Frame:_start [0x1fc5fe]
=========                in /usr/bin/python3
========= 
^Cterminate called after throwing an instance of 'std::system_error'

  what():  Resource deadlock avoided
```
</details>"
58004,Failed to build libtensorflowlite_c.so on M1 mac,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

darwin_arm64

### Mobile device

_No response_

### Python version

3.9.12

### Bazel version

5.3.0

### GCC/Compiler version

Apple clang version 14.0.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When attempting to build `libtensorflowlite_c.so` on an M1 mac using the commands:


bazel build --config=monolithic --cpu=darwin_arm64 -c opt //tensorflow/lite/c:libtensorflowlite_c.so --verbose_failures --jobs=4
```

```
bazel build --config=macos_arm64 --cpu=darwin_arm64 -c opt //tensorflow/lite/c:libtensorflowlite_c.so --verbose_failures --jobs=4
```

```
bazel build --config=monolithic -c opt //tensorflow/lite/c:libtensorflowlite_c.so --verbose_failures --jobs=4
```

I get the following error:

```
ERROR: /private/var/tmp/_bazel_jason.white/5d9bcbdac1f97eda46b1818c207beabc/external/flatbuffers/BUILD.bazel:84:10: Linking external/flatbuffers/flatc [for host] failed: (Exit 1): cc_wrapper.sh failed: error executing command
  (cd /private/var/tmp/_bazel_jason.white/5d9bcbdac1f97eda46b1818c207beabc/execroot/org_tensorflow && \
  exec env - \
    PATH='/Users/jason.white/Library/Caches/bazelisk/downloads/bazelbuild/bazel-5.3.0-darwin-arm64/bin:/usr/local/opt/llvm/bin:/opt/homebrew/opt/llvm/bin:/opt/homebrew/opt/llvm/bin:/Users/jason.white/anaconda3/bin:/Users/jason.white/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/jason.white/.cargo/bin:/Applications/CMake.app/Contents/bin
' \
    PWD=/proc/self/cwd \
  external/local_config_cc/cc_wrapper.sh @bazel-out/host/bin/external/flatbuffers/flatc-2.params)
# Configuration: bb154819987dda44281f89fe0a702c318c5f92b418ba76d644851296222133e1
# Execution platform: @local_execution_config_platform//:platform
clang: error: invalid linker name in argument '-fuse-ld=-debugger-tuning=lldb'
Target //tensorflow/lite/c:libtensorflowlite_c.so failed to build
INFO: Elapsed time: 0.187s, Critical Path: 0.04s
INFO: 5 processes: 5 internal.
FAILED: Build did NOT complete successfully
```

Expected behavior: the `libtensorflowlite_c.so` object is built.
```


### Standalone code to reproduce the issue

```shell
From the root TensorFlow directory:


bazel build --config=monolithic --cpu=darwin_arm64 -c opt //tensorflow/lite/c:libtensorflowlite_c.so --verbose_failures --jobs=4
```
```


### Relevant log output

```shell
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=160
INFO: Reading rc options for 'build' from /Users/jason.white/workspace/p21-library-builder/tensorflow_src/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/jason.white/workspace/p21-library-builder/tensorflow_src/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /Users/jason.white/workspace/p21-library-builder/tensorflow_src/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/jason.white/workspace/p21-library-builder/tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:monolithic in file /Users/jason.white/workspace/p21-library-builder/tensorflow_src/.bazelrc: --define framework_shared_object=false --experimental_link_static_libraries_once=false
INFO: Found applicable config definition build:macos in file /Users/jason.white/workspace/p21-library-builder/tensorflow_src/.bazelrc: --apple_platform_type=macos --copt=-DGRPC_BAZEL_BUILD --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/0fb2676c248ef1b76a4ef86c934e69ff80796ba7.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/6c8cdbbdb02f2ec36e3440d6edc34006368f0ba3.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_go/releases/download/v0.34.0/rules_go-v0.34.0.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found
INFO: Analyzed target //tensorflow/lite/c:libtensorflowlite_c.so (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: /private/var/tmp/_bazel_jason.white/5d9bcbdac1f97eda46b1818c207beabc/external/flatbuffers/BUILD.bazel:84:10: Linking external/flatbuffers/flatc [for host] failed: (Exit 1): cc_wrapper.sh failed: error executing command
  (cd /private/var/tmp/_bazel_jason.white/5d9bcbdac1f97eda46b1818c207beabc/execroot/org_tensorflow && \
  exec env - \
    PATH='/Users/jason.white/Library/Caches/bazelisk/downloads/bazelbuild/bazel-5.3.0-darwin-arm64/bin:/usr/local/opt/llvm/bin:/opt/homebrew/opt/llvm/bin:/opt/homebrew/opt/llvm/bin:/Users/jason.white/anaconda3/bin:/Users/jason.white/anaconda3/condabin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/jason.white/.cargo/bin:/Applications/CMake.app/Contents/bin
' \
    PWD=/proc/self/cwd \
  external/local_config_cc/cc_wrapper.sh @bazel-out/host/bin/external/flatbuffers/flatc-2.params)
# Configuration: bb154819987dda44281f89fe0a702c318c5f92b418ba76d644851296222133e1
# Execution platform: @local_execution_config_platform//:platform
clang: error: invalid linker name in argument '-fuse-ld=-debugger-tuning=lldb'
Target //tensorflow/lite/c:libtensorflowlite_c.so failed to build
INFO: Elapsed time: 0.187s, Critical Path: 0.04s
INFO: 5 processes: 5 internal.
FAILED: Build did NOT complete successfully
```
</details>"
58003,[XLA] Can not compile XLA program using JitRtExecutable after removing BefExecutable,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.11

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

5.1.1

### GCC/Compiler version

g++ (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0

### CUDA/cuDNN version

 Driver Version: 510.68.02  CUDA Version: 11.6

### GPU model and memory

Nvidia 1030,2G

### Current Behaviour?

Tensorflow ends with 2 kinds of Internal Errors

one is:
```log
I tensorflow/compiler/xla/util.cc:70] INTERNAL: Unknown platform.
I tensorflow/compiler/xla/util.cc:71] *** Begin stack trace ***
	
	xla::WithLogBacktrace(tsl::Status const&)
	tsl::Status xla::InternalError<>(absl::lts_20220623::str_format_internal::FormatSpecTemplate<> const&)
	xla::gpu::GpuConvAlgorithmPicker::PickBestAlgorithm(xla::HloCustomCallInstruction const*)
	xla::gpu::GpuConvAlgorithmPicker::RunOnInstruction(xla::HloInstruction*)
	xla::gpu::GpuConvAlgorithmPicker::RunOnComputation(xla::HloComputation*)
	xla::gpu::GpuConvAlgorithmPicker::Run(xla::HloModule*, absl::lts_20220623::flat_hash_set<std::basic_string_view<char, std::char_traits<char> >, absl::lts_20220623::container_internal::StringHash, absl::lts_20220623::container_internal::StringEq, std::allocator<std::basic_string_view<char, std::char_traits<char> > > > const&)
	tsl::StatusOr<bool> xla::HloPassPipeline::RunPassesInternal<xla::HloModule>(xla::HloModule*, xla::DebugOptions const&, absl::lts_20220623::flat_hash_set<std::basic_string_view<char, std::char_traits<char> >, absl::lts_20220623::container_internal::StringHash, absl::lts_20220623::container_internal::StringEq, std::allocator<std::basic_string_view<char, std::char_traits<char> > > > const&)
	xla::HloPassPipeline::Run(xla::HloModule*, absl::lts_20220623::flat_hash_set<std::basic_string_view<char, std::char_traits<char> >, absl::lts_20220623::container_internal::StringHash, absl::lts_20220623::container_internal::StringEq, std::allocator<std::basic_string_view<char, std::char_traits<char> > > > const&)
	xla::gpu::GpuCompiler::OptimizeHloPostLayoutAssignment(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*)
	xla::gpu::NVPTXCompiler::OptimizeHloPostLayoutAssignment(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*)
	xla::gpu::GpuCompiler::OptimizeHloModule(xla::HloModule*, stream_executor::StreamExecutor*, stream_executor::DeviceMemoryAllocator*)
	xla::gpu::GpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule> >, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&)
	xla::Service::BuildExecutable(xla::HloModuleProto const&, std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, xla::Backend*, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&, bool)
	xla::LocalService::CompileExecutables(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
	xla::LocalClient::Compile(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
	tensorflow::XlaCompilationCache::BuildExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&, std::unique_ptr<xla::LocalExecutable, std::default_delete<xla::LocalExecutable> >*)
	tensorflow::XlaCompilationCache::CompileStrict(tensorflow::XlaCompilationCache::Signature const&, tensorflow::XlaCompilationCache::Entry*, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::OpKernelContext*, tensorflow::XlaCompilationCache::CompileScope)
	tensorflow::XlaCompilationCache::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::OpKernelContext*, tensorflow::XlaCompilationCache::CompileScope, tensorflow::XlaCompilationCache::CompileMode, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)
	tensorflow::XlaCompilationCache::Compile(tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompilationCache::CompileMode, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)
	
	tensorflow::XlaCompileOp::Compute(tensorflow::OpKernelContext*)
	tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*)
```

the other is

```log
I tensorflow/compiler/xla/util.cc:71] *** Begin stack trace ***
	
	xla::WithLogBacktrace(tsl::Status const&)
	xla::gpu::GpuCompiler::CompileAheadOfTime(std::unique_ptr<xla::HloModuleGroup, std::default_delete<xla::HloModuleGroup> >, xla::AotCompilationOptions const&)
	xla::Service::BuildAotResults(std::vector<xla::HloModuleProto const*, std::allocator<xla::HloModuleProto const*> > const&, std::vector<std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> >, std::allocator<std::unique_ptr<xla::HloModuleConfig, std::default_delete<xla::HloModuleConfig> > > >, xla::Backend*, std::vector<std::vector<stream_executor::StreamExecutor*, std::allocator<stream_executor::StreamExecutor*> >, std::allocator<std::vector<stream_executor::StreamExecutor*, std::allocator<stream_executor::StreamExecutor*> > > >, xla::Compiler::CompileOptions const&, bool)
	xla::LocalService::CompileAotResults(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
	xla::LocalClient::CompileAheadOfTime(xla::XlaComputation const&, absl::lts_20220623::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&)
	tensorflow::XlaCompilationCache::BuildSerializedExecutable(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationResult const&)
	tensorflow::XlaCompilationCache::SerializeEntry(tensorflow::XlaCompiler::Options const&, tensorflow::XlaCompilationCache::Signature const&, tensorflow::XlaCompilationCache::Entry const&)
	tensorflow::XlaCompilationCache::CompileStrict(tensorflow::XlaCompilationCache::Signature const&, tensorflow::XlaCompilationCache::Entry*, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::NameAttrList const&, tensorflow::OpKernelContext*, tensorflow::XlaCompilationCache::CompileScope)
	tensorflow::XlaCompilationCache::CompileImpl(tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::OpKernelContext*, tensorflow::XlaCompilationCache::CompileScope, tensorflow::XlaCompilationCache::CompileMode, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)
	tensorflow::XlaCompilationCache::Compile(tensorflow::XlaCompiler::Options const&, tensorflow::NameAttrList const&, std::vector<tensorflow::XlaArgument, std::allocator<tensorflow::XlaArgument> > const&, tensorflow::XlaCompiler::CompileOptions const&, tensorflow::XlaCompilationCache::CompileMode, tensorflow::XlaCompilationResult const**, xla::LocalExecutable**)
	
	tensorflow::XlaCompileOp::Compute(tensorflow::OpKernelContext*)
	tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*)
```

for this type of error, the log said ""failed to parse the mlir source""


### Standalone code to reproduce the issue

#### Please check my branch to build tensorflow with cuda.

I have forked repo under my github account. There are 2 branches , one is ""amoschenyq-debug"", it is the old one using Bef and it can export xla executable files to the folder I specify. The other one ""xla-jit-to-aot"" rebases on newer commit from main branch of tensorflow which has removed bef in gpu_compiler.cc, it can not export xla executable files now.

And to be able to export executable files, I set debug options of `xla_gpu_bef_executable` to true in amoschenyq-debug and `xla_gpu_enable_xla_runtime_executable` to true respectively in `xla_compilation_cache.cc`.

And this is my python script:
```python
import tensorflow as tf
import numpy as np
import time
import os

tf.compat.v1.disable_eager_execution()
tf.compat.v1.reset_default_graph()
input_node = tf.compat.v1.placeholder(
    shape=[None, 100, 100, 3], dtype=tf.float32, name='input_node')
net = tf.compat.v1.layers.conv2d(
    input_node, 32, (5, 5), strides=(2, 2), padding='same', name='conv_1')
net = tf.compat.v1.layers.batch_normalization(net, name='bn')
net = tf.compat.v1.layers.conv2d(
    net, 32, (3, 3), strides=(2, 2), padding='same', name='conv_2')
net = tf.compat.v1.layers.dropout(net, rate=0.6, name='dropout')
net = tf.compat.v1.layers.conv2d(
    net, 32, (2, 2), strides=(1, 1), padding='same', name='conv_3')

net = tf.identity(net, name='final')
input_batch_1 = np.random.rand(1, 100, 100, 3)
input_batch_128 = np.random.rand(128, 100, 100, 3)
input_batch_256 = np.random.rand(256, 100, 100, 3)


# optimizer_options = tf.compat.v1.OptimizerOptions(global_jit_level=tf.compat.v1.OptimizerOptions.ON_2)
# graph_options = tf.compat.v1.GraphOptions(optimizer_options=optimizer_options)
# config = tf.compat.v1.ConfigProto(graph_options=graph_options)

# with tf.compat.v1.Session(config=config) as sess:
with tf.compat.v1.Session() as sess:
    sess.run(tf.compat.v1.global_variables_initializer())
    sess.run(tf.compat.v1.local_variables_initializer())

    for i in range(3):
        start_time = time.time()
        result = sess.run(net, feed_dict={input_node: input_batch_1})
        end_time = time.time()
        print((end_time - start_time)*1000)

    for i in range(3):
        start_time = time.time()
        result = sess.run(net, feed_dict={input_node: input_batch_128})
        end_time = time.time()
        print((end_time - start_time)*1000)


    # frozen_graph = tf.compat.v1.graph_util.convert_variables_to_constants(
    #    sess, tf.compat.v1.get_default_graph().as_graph_def(), ['final'])
    # tf.compat.v1.summary.FileWriter(""events/bn-and-dropout/"", graph=frozen_graph)
    # tf.io.write_graph(frozen_graph, ""../pb/"", ""bn_dropout_model.pbtxt"", as_text=True)
```

And this is my env variables to use xla dump file:

```shell
export XLA_FLAGS=""--xla_dump_to=/home/amoschenyq/hard-disk/code-repo/bench-kernel/xla-logs --xla_dump_hlo_as_html""
export TF_DUMP_GRAPH_PREFIX=""/home/amoschenyq/hard-disk/code-repo/bench-kernel/dump-graph""
export TF_CPP_VMODULE=""nvptx_compiler=2,xla_compilation_cache=1""
export TF_CPP_MIN_LOG_LEVEL=""0""
export TF_CPP_MAX_VLOG_LEVEL=""3""
export TF_XLA_FLAGS=""--tf_xla_auto_jit=2 --tf_xla_clustering_debug --tf_xla_persistent_cache_directory=/home/amoschenyq/hard-disk/code-repo/bench-kernel/xla-cache""
```


### Relevant log output
https://drive.google.com/file/d/1LY_cwochqIUS8cCtAyngws-rHEps84KB/view?usp=sharing
"
58002,Making tensorflow.tile similar to numpy.tile and torch.tile,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Running this code:
`tf.tile(tf.ones((3,)),(2,1))` will currently give an error for TensorFlow since the dimension length of the input and the multiples is different. Numpy and Pytorch handle this by modifying the dimension of the multiples or the input argument. I believe it would be nice if TensorFlow did this too.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.tile(tf.ones((3,)),(2,1))
```


### Relevant log output

```shell
tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected multiples argument to be a vector of length 1 but got length 2 [Op:Tile]
```
</details>"
58001,model created in TF 1.15.4 won't run on TF 1.15.5,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

1.15.5

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu tegra Linux [Linux agx 5.10.65-tegra #1 SMP PREEMPT Mon May 16 20:58:07 PDT 2022 aarch64 aarch64 aarch64 GNU/Linux]

### Mobile device

nvidia jetson AGX

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!python3 test_frozen_model_TF1.py 
2022-10-06 04:37:09.362368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/importer.py"", line 500, in _import_graph_def_internal
    results = c_api.TF_GraphImportGraphDefWithResults(
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef mentions attr 'explicit_paddings' not in Op<name=MaxPool; signature=input:T -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_UINT8, DT_INT16, DT_INT8, DT_UINT16, DT_QINT8]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=[""SAME"", ""VALID""]; attr=data_format:string,default=""NHWC"",allowed=[""NHWC"", ""NCHW"", ""NCHW_VECT_C""]>; NodeDef: {{node maxpool0}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test_frozen_model_TF1.py"", line 22, in <module>
    tf.compat.v1.import_graph_def(graph_def, name="""")
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/util/deprecation.py"", line 513, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/importer.py"", line 399, in import_graph_def
    return _import_graph_def_internal(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/framework/importer.py"", line 505, in _import_graph_def_internal
    raise ValueError(str(e))
ValueError: NodeDef mentions attr 'explicit_paddings' not in Op<name=MaxPool; signature=input:T -> output:T; attr=T:type,default=DT_FLOAT,allowed=[DT_HALF, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_INT32, DT_INT64, DT_UINT8, DT_INT16, DT_INT8, DT_UINT16, DT_QINT8]; attr=ksize:list(int),min=4; attr=strides:list(int),min=4; attr=padding:string,allowed=[""SAME"", ""VALID""]; attr=data_format:string,default=""NHWC"",allowed=[""NHWC"", ""NCHW"", ""NCHW_VECT_C""]>; NodeDef: {{node maxpool0}}. (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).
root@agx:/home/cortexia# exit
exit
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt
with tf.Session() as sess:
    # First deserialize your frozen graph:
    with tf.gfile.GFile(“/path/to/your/frozen/graph.pb”, ‘rb’) as f:
        frozen_graph = tf.GraphDef()
        frozen_graph.ParseFromString(f.read())
    # Now you can create a TensorRT inference graph from your
    # frozen graph:
    converter = trt.TrtGraphConverter(
	    input_graph_def=frozen_graph,
	    nodes_blacklist=['logits', 'classes']) #output nodes
    trt_graph = converter.convert()
    # Import the TensorRT graph into a new graph and run:
    output_node = tf.import_graph_def(
        trt_graph,
        return_elements=['logits', 'classes'])
    sess.run(output_node)
```


### Relevant log output

_No response_</details>"
58000,Incorrect behavior at elementwise calculation(MUL) between different dimension when use GPU DELEGATE,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): __Linux Ubuntu 20.04 & Android 8.1__
- TensorFlow installed from (source or binary): __build from source using bazel.__
- TensorFlow version (or github SHA if from source): __github release tag v2.10.0__

**Provide the text output from tflite_convert**
```

2022-10-06 09:48:28.924862: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-10-06 09:48:28.924885: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-10-06 09:48:28.925549: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: ./mask_template_Expand_18_deleted
2022-10-06 09:48:28.926345: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }
2022-10-06 09:48:28.926366: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: ./mask_template_Expand_18_deleted
2022-10-06 09:48:28.928680: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-10-06 09:48:28.929107: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.
2022-10-06 09:48:28.972699: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: ./mask_template_Expand_18_deleted
2022-10-06 09:48:28.984487: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 58945 microseconds.
2022-10-06 09:48:29.007699: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
Estimated count of arithmetic ops: 1.203 G  ops, equivalently 0.602 G  MACs
2022-10-06 09:48:29.043914: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1989] Estimated count of arithmetic ops: 1.203 G  ops, equivalently 0.602 G  MACs

```
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

----------------------------------------------------------------------------------------------------------------------------------------------------------------

I'm have been run my own tflite model file using c api. And __results of CPU and GPU DELEGATE are very very different.__
Ths problem is occured at GPU Delegate based OpenCL API.

In more detail, my model has Mul layer. and the output results are different from here.

The MUL layer calculate between different width/height ([1x64x1x1] x [1x64x56x56]) 
The results are shown in the figure below. The output result at gpu delegate has worng.

![image](https://user-images.githubusercontent.com/22662343/194196072-46393a79-88fb-4ea5-a536-fa782bc7eea5.png)

I think this is occur because of dimension type (CHW / HWC). and other elementwise calculation will be also.
Is there any way to get correct result in this situation?

__I attach my model file for test and sample c++ code for test__

[tflite file download link](https://drive.google.com/file/d/1MsEDcLXwTSptWPqqzhaORNNGiZ4a1uxC/view?usp=sharing)
[sample code download link](https://drive.google.com/file/d/13-KN61vOl5pdo2XTGmgN81HCX3-oYIUc/view?usp=sharing)
[android dependency file download link](https://drive.google.com/file/d/1xCJDeBHrcuWeM9YMXkN67ChDhFhhrN6n/view?usp=sharing)

input shape : [1 x 3 x 112 x 112]
output shape : [1 x 64 x 56 x 56]

```
#include ""stdio.h""
#include <iostream>
#include <chrono>
#include <vector>

#include <opencv2/opencv.hpp>
#include ""tensorflow/lite/c/c_api.h""
#include ""tensorflow/lite/delegates/gpu/delegate.h""

#include <unistd.h>

int main(int argc, char* argv[])
{

    std::cout << ""argv 1 : model file path"" << std::endl;
    std::cout << ""argv 2 : sample image"" << std::endl;
    std::string model_path = argv[1];
    std::string img_path = argv[2];

    // Create the model and interpreter options.
    TfLiteModel *model = TfLiteModelCreateFromFile(model_path.c_str());
    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
    TfLiteInterpreterOptionsSetNumThreads(options, 1);
    std::cout << std::endl << ""Complete prepare options"" << std::endl << std::endl;

    // Create Delegate options
    auto options_gpu = TfLiteGpuDelegateOptionsV2Default();
    options_gpu.inference_priority1 = TFLITE_GPU_INFERENCE_PRIORITY_MIN_LATENCY;
    options_gpu.is_precision_loss_allowed = 1;
    std::cout << std::endl << ""Complete set delegate options"" << std::endl << std::endl;

    auto delegate = TfLiteGpuDelegateV2Create(&options_gpu);
    std::cout << std::endl << "" Complete create delegate"" << std::endl << std::endl;

    TfLiteInterpreterOptionsAddDelegate(options, delegate);
    std::cout << std::endl << ""Complete add delegates"" << std::endl << std::endl;

    // Create the interpreter.
    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
    std::cout << std::endl << "" Complete prepare interpreter"" << std::endl << std::endl;

    // Allocate tensors and populate the input tensor data.
    TfLiteInterpreterAllocateTensors(interpreter);

    // Prepare input
    cv::Mat img = cv::imread(img_path);
    cv::resize(img, img, cv::Size(112, 112));
    cv::Mat img_rgb;
    cv::cvtColor(img, img_rgb, cv::COLOR_BGR2RGB);

    cv::Mat fimg;
    std::vector<cv::Mat> inputImage;

    img_rgb.convertTo(fimg, CV_32FC3, 0.0078125, -127.5 * 0.0078125);
    split(fimg, inputImage);

    int size_img = 112 * 112;
    std::vector<float> input(1 * size_img * 3);
    for (int i = 0; i < 3; i++)
        std::memcpy(input.data() + i * size_img, inputImage[i].data, sizeof(float) * size_img);
    std::cout << ""Complete prepare input data"" << std::endl;

    TfLiteTensor* input_tensor = TfLiteInterpreterGetInputTensor(interpreter, 0);
    TfLiteTensorCopyFromBuffer(input_tensor, input.data(), input.size() * sizeof(float));
    std::cout << ""Complete Set input"" << std::endl;

    // Execute inference.
    TfLiteInterpreterInvoke(interpreter);
    std::cout << ""Complete invoke"" << std::endl;

    // Extract the output tensor data.
    const TfLiteTensor *output_tensor = TfLiteInterpreterGetOutputTensor(interpreter, 0);
    int output_size = 1;
    int dim_size = TfLiteTensorNumDims(output_tensor);
    std::vector<int> bchw(dim_size);
    printf(""\noutput shape [1"");
    for (int i = 1; i < dim_size; i++)
    {
        bchw[i] = TfLiteTensorDim(output_tensor, i);
        printf("", %d"", bchw[i]);
        output_size *= bchw[i];
    }
    printf(""] >> "");
    std::vector<float> output(output_size);
    TfLiteTensorCopyToBuffer(output_tensor, output.data(), output_size * sizeof(float));
    for(int i=0; i<64; i++)
        printf(""%f, "", output[i]);
    printf(""\n"");

    // Dispose of the model and interpreter objects.
    TfLiteInterpreterDelete(interpreter);
    TfLiteInterpreterOptionsDelete(options);
    TfLiteGpuDelegateV2Delete(delegate);
    TfLiteModelDelete(model);
    std::cout << ""Complete delete"" << std::endl;

    return 0;
}

```"
57999,`tf.gather` outputs wrong result with jit_compile," 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10, tf-nightly

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04


### Current Behaviour?

According to documentation, `tf.gather` should return `0` when `indices` is out of bound on GPU. However, in the code below, the jit compiled function returns `0.2` instead of `0`.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
v = tf.constant([[0.1], [0.2]])
i = tf.constant([[3]])
def f(p):
    return tf.gather(v, indices=i, validate_indices=None, axis=None, batch_dims=0)

print(f(v)) # [[[0. ]]]
f_jitted = tf.function(jit_compile=True)(f)
print(f_jitted(v)) # [[[0.2]]]
```


### Relevant log output
```
tf.Tensor([[[0.]]], shape=(1, 1, 1), dtype=float32)
tf.Tensor([[[0.2]]], shape=(1, 1, 1), dtype=float32)
```"
57990,"is there any ways I can embed my self-implemented FP8 format (C/C++) into tensorflow, and support current ops automatically?","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
It looks like there is no way to include a self-implemented data format (eg. FP8) to support current ops automatically.
```


### Standalone code to reproduce the issue

```shell
It looks like there is no way to include a self-implemented data format (eg. FP8) to support current ops automatically.
```


### Relevant log output

_No response_</details>"
57988,[RNN/LSTM]concatenation error during invoke(),"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source):

### 2. Code

I converted pytorch model to tensorflow using onnx. The output of converted tensorflow model is exactly as expected.
The following is the pytorch model code:


        def __init__(self, device: Union[str, torch.device]=None, verbose=True, weights_fpath: Union[Path, str]=None):
        super().__init__()
        self.lstm = nn.LSTM(mel_n_channels, model_hidden_size, model_num_layers, batch_first=True)
        self.linear = nn.Linear(model_hidden_size, model_embedding_size)
        self.relu = nn.ReLU()
        if device is None:
            device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")
        elif isinstance(device, str):
            device = torch.device(device)
        self.device = device

        # Load the pretrained model'speaker weights
        if weights_fpath is None:
            weights_fpath = Path(__file__).resolve().parent.joinpath(""pretrained.pt"")
        else:
            weights_fpath = Path(weights_fpath)

        if not weights_fpath.exists():
            raise Exception(""Couldn't find the voice encoder pretrained model at %s."" %
                            weights_fpath)
        start = timer()
        checkpoint = torch.load(weights_fpath, map_location=""cpu"")
        self.load_state_dict(checkpoint[""model_state""], strict=False)
        self.to(device)

        if verbose:
            print(""Loaded the voice encoder model on %s in %.2f seconds."" %
                  (device.type, timer() - start))

    def forward(self, mels: torch.FloatTensor):
        _, (hidden, _) = self.lstm(mels)
        embeds_raw = self.relu(self.linear(hidden[-1]))
        return embeds_raw / torch.norm(embeds_raw, dim=1, keepdim=True)

I then converted the tesorflow .pb model to tensorflow lite using the code:

```
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(""test_new1"")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter=True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]
tfmodel = converter.convert()
open('test_new1/saved_lite.tflite', 'wb').write(tfmodel)
```

I then tried to infer using the tflite model using the following code:

```
import tensorflow as tf
interpreter = tf.lite.Interpreter(r'test_new1/saved_lite.tflite')
input_details = interpreter.get_input_details()
output_details= interpreter.get_output_details()
interpreter.set_tensor(input_details[0]['index'],dummy_input)
interpreter.invoke()
```



The output of the input_details and output_details is:
```
[{'name': 'serving_default_actual_input_1:0',
  'index': 0,
  'shape': array([  1, 160,  40], dtype=int32),
  'shape_signature': array([ -1, 160,  40], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0),
  'quantization_parameters': {'scales': array([], dtype=float32),
   'zero_points': array([], dtype=int32),
   'quantized_dimension': 0},
  'sparsity_parameters': {}}]
[{'name': 'StatefulPartitionedCall:0',
  'index': 154,
  'shape': array([  1, 256], dtype=int32),
  'shape_signature': array([ -1, 256], dtype=int32),
  'dtype': numpy.float32,
  'quantization': (0.0, 0),
  'quantization_parameters': {'scales': array([], dtype=float32),
   'zero_points': array([], dtype=int32),
   'quantized_dimension': 0},
  'sparsity_parameters': {}}]
```
  
 The size of the dummy_input is [1,160,40]
 
 The error I am getting is:
` tensorflow/lite/kernels/concatenation.cc:158 t->dims->data[d] != t0->dims->data[d] (296 != 1)Node number 3 (CONCATENATION) failed to prepare.Node number 48 (WHILE) failed to invoke.`
 
 
Can anyone help me out with the this issue as I am converting a pretrained pytorch model to tflite. The issue I am facing is during the conversion of tensorflow to tflite because till tensorflow it is perfectly working fine.
 
 

"
57982,"Ram memory leak when using tf.function at tf 2.8,2.9 and 2.10, doesn't happen with tf 2.5","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu, also on Windows

### Mobile device

_No response_

### Python version

3.10 and 3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Every time I use a tf.function decorator there is a memory leak in the ram, that keeps growing every iteration, I observed this in ubuntu and windows, it didn't happen with tf 2.5 but I had the server updated to python 3.10 and all the version compatible with python 3.10 (tf 2.8,2.9,2.10) have this issue. 
I tried with python 3.9 in my personal device and the issue still occurs. The leak is small but in an RL setting this is a critical issue in RL since we have to call a tf.function to take actions in the environment millions of times during training and without the decorator things go like 10 times slower.

Note that it is not an issue about not passing tensorflow objects to the wrapper, neither about having the shape of the tensor changing.

Please I need this to be fixed as soon as possible.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

@tf.function
def operate(img):
    return img

img = tf.zeros((6,6,7))
for i in range (100000000):
    s= operate(img)
```


### Relevant log output

```shell
just monitor the ram, you will see it growing constantly if you are using tf>=2.8 with tf 2.5.0 ram remains constant for the code above
```
</details>"
57981,Another Check-fail in Conv2DBackpropFilter,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10 and 2.11.0-dev20221005

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In current implementation of Conv2DBackpropFilter, arguments' shapes are not checked carefully. As a result, a check-fail can be triggered, which can lead to crash and DoS.
The bug is similar to #57980, but has different inputs and outputs. So they might have different causes.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'
import tensorflow as tf
print(tf.__version__)
with tf.device(""GPU:0""):
    input = tf.random.uniform([1, 1, 1, 1, 1], dtype=tf.bfloat16)
    filter_sizes = tf.saturate_cast(tf.random.uniform([1], minval=-128, maxval=129, dtype=tf.int64), dtype=tf.int32)
    out_backprop = tf.random.uniform([1, 1, 1, 1], dtype=tf.bfloat16)
    strides = [1, 1, 1]
    use_cudnn_on_gpu = True
    padding = ""SAME""
    explicit_paddings = []
    data_format = ""NHWC""
    dilations = [1, 1, 1, 1]
    res = tf.raw_ops.Conv2DBackpropFilter(
        input=input,
        filter_sizes=filter_sizes,
        out_backprop=out_backprop,
        strides=strides,
        use_cudnn_on_gpu=use_cudnn_on_gpu,
        padding=padding,
        explicit_paddings=explicit_paddings,
        data_format=data_format,
        dilations=dilations,
    )
```


### Relevant log output

```shell
2022-10-05 16:56:46.002944: F ./tensorflow/core/util/tensor_format.h:427] Check failed: index >= 0 && index < num_total_dims Invalid index from the dimension: 3, 0, C
Aborted (core dumped)
```
</details>"
57980,Check-fail in Conv2DBackpropFilter,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10 and 2.11.0-dev20221005

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In current implementation of Conv2DBackpropFilter, arguments' shapes are not checked carefully. As a result, a Check-fail can be triggered, which can lead to a crash and DoS.
The bug can be replicated when running with GPU.
```


### Standalone code to reproduce the issue

```shell
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'
import tensorflow as tf
print(tf.__version__)
with tf.device(""GPU:0""):
    input = tf.random.uniform([1, 1, 1, 1, 1, 1], dtype=tf.bfloat16)
    filter_sizes = tf.saturate_cast(tf.random.uniform([1], minval=-128, maxval=129, dtype=tf.int64), dtype=tf.int32)
    out_backprop = tf.random.uniform([], dtype=tf.bfloat16)
    strides = [1, 1, 1, 1, 1, 1]
    use_cudnn_on_gpu = True
    padding = ""VALID""
    explicit_paddings = []
    data_format = ""NHWC""
    dilations = [1, 1, 1, 1]
    res = tf.raw_ops.Conv2DBackpropFilter(
        input=input,
        filter_sizes=filter_sizes,
        out_backprop=out_backprop,
        strides=strides,
        use_cudnn_on_gpu=use_cudnn_on_gpu,
        padding=padding,
        explicit_paddings=explicit_paddings,
        data_format=data_format,
        dilations=dilations,
    )
```


### Relevant log output

```shell
2022-10-05 16:49:28.663172: F tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:671] Check failed: TensorShapeUtils::MakeShape(filter_tensor.vec<int32>(), &filter_tf_shape) .ok() == true (0 vs. 1)
Aborted (core dumped)
```
</details>"
57978,Undocumented explicit padding exceptions in tf.nn.max_pool and tf.nn.max_pool2d,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Microsoft Windows 11

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.nn.max_pool raises 2 exceptions that are not mentioned in the documentation.
https://www.tensorflow.org/api_docs/python/tf/nn/max_pool

1. For 'input' tensor of rank 5, explicit padding is not supported.
This requirement is likely to be inferred by most users but maybe a mention in `Raises` section might be useful for some.


2. NCHW_VECT_C is not supported with explicit padding.
This is also the case for tf.nn.max_pool1d and tf.nn.max_pool2d. NCHW_VECT_C is mentioned as a valid option in a 'data_format' docstring of tf.nn.max_pool2d.

For max_pool1d, the documentation is probably ok as it is because users are unlikely to set `data_format` to NCHW_VECT_C.

For max_pool and max_pool2d, a suggestion is to revise the docstring of 'data_format', or add this requirement in a 'Raises' section, or remove NCHW_VECT_C from the documentation if it is not allowed in general.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.ops import array_ops

x = array_ops.ones([2, 2, 2, 2, 2])
tf.nn.max_pool(x, ksize=2, strides=2, padding=[[0, 0], [1, 1], [1, 1], [0, 0]])
```

### Relevant log output

```shell
ValueError: Explicit padding is not supported with an input tensor of rank 5. Received: padding=[[0, 0], [1, 1], [1, 1], [0, 0]]
```

### Standalone code to reproduce the issue

```shell
# Modified from max_pool's API doc example
import tensorflow as tf
from tensorflow.python.ops import array_ops

matrix = tf.constant([
    [0, 0, 1, 7],
    [0, 2, 0, 0],
    [5, 2, 0, 0],
    [0, 0, 9, 8],
])
reshaped = tf.reshape(matrix, (1, 4, 4, 1))
result = tf.nn.max_pool2d(reshaped, ksize=2, strides=2, padding=[[0, 0], [1, 1], [1, 1], [0, 0]], data_format=""NCHW_VECT_C"")
```


### Relevant log output

```shell
ValueError: `data_format='NCHW_VECT_C'` is not supported with explicit padding. Received: padding=[[0, 0], [1, 1], [1, 1], [0, 0]]
```
</details>"
57977,[RNN] GRU conversion/performance issues on CPU on Windows machines,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11 Home Single Language, ver 21H2
- CPU: AMD Ryzen 7 6800H
- Python: 3.10.4
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.0

### 2. Code
Please note that the issue is only noticeable on Windows machines (tested on 3 different PCs). In Colab and on a Linux machine I saw little to no decline in performance.
https://colab.research.google.com/drive/1d6E3VjbN57ojDd1X0sfG2KA3x7wTMf5N?usp=sharing

### 3. Failure after conversion
Model fails to convert with default operation set.
Conversion is successful with the extended operation set, however I saw about x3 decline in performance during inference on CPU.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
The conversion error traceback can be seen in the Colab notebook above.
The issue is also present in TF 2.9.1, and it happens for both Intel and AMD CPUs.
"
57976,Supporting int32 value type in TextFileInitializer.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.9

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
In [TextFileInitializer](https://github.com/tensorflow/tensorflow/blob/359c3cdfc5fabac82b3c70b3b6de2b0a8c16874f/tensorflow/python/ops/lookup_ops.py#L731) we have a validation to check whether the value_dtype is of type tf.int64, wondering why do we have such constraints? 

The context is that, we are trying to initialize a vocabulary lookup table in the TensorFlow model and would like to save memory for the HashTable, both the key and value type can be of int32 type, but seems that the value type is restricted to int64. 
```


### Standalone code to reproduce the issue

```shell
initializer = tf.lookup.TextFileInitializer(
                    vocab_file,
                    key_dtype=tf.int64, key_index=0,
                    value_dtype=tf.int32, value_index=1,
                    delimiter="" "")
```


### Relevant log output

```shell
[0]<stderr>:    vocab_table = tf.lookup.StaticVocabularyTable(initializer=initializer, num_oov_buckets=1)
[0]<stderr>:  File ""/home/coder/ads-ai-offline/build/scin-azkaban/environments/development-venv/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py"", line 1235, in __init__
[0]<stderr>:    (dtypes.int64, initializer.value_dtype))
[0]<stderr>:TypeError: Invalid value dtype, expected <dtype: 'int64'> but got <dtype: 'int32'>.
```
</details>"
57975,Grappler error when Softmax is used in a custom layer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.6

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Error/Warning from Grappler: `Error in PredictCost() for the op: op: ""Softmax"" attr { key: ""T"" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: ""GPU"" vendor: ""NVIDIA"" model: ""NVIDIA GeForce GTX 1080 Ti"" frequency: 1670 num_cores: 28 environment { key: ""architecture"" value: ""6.1"" } environment { key: ""cuda"" value: ""11020"" } environment { key: ""cudnn"" value: ""8100"" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 2883584 shared_memory_size_per_multiprocessor: 98304 memory_size: 10099490816 bandwidth: 484440000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }`
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

class Chooser(tf.keras.layers.Layer):
    @tf.function
    def call(self, options_input, choices_input_logits):
        choices = tf.nn.softmax(choices_input_logits, axis=2)

        result = tf.linalg.matmul(choices, options_input)
        return result

def get_model():
    options_input = tf.keras.layers.Input(shape=(10,3), name=""options"")
    choices_input = tf.keras.layers.Input(shape=(5,10), name=""choices"")

    net = Chooser()(options_input, choices_input)
    net = tf.keras.layers.Flatten()(net)
    net = tf.keras.layers.Dense(1)(net)

    return tf.keras.Model([options_input, choices_input], net)

model = get_model()
model.compile(
    optimizer=tf.keras.optimizers.Adam(0.001),
    loss=tf.keras.losses.MeanAbsoluteError(),
)

def batch_gen():
    while True:
        o = np.random.uniform(low=-1.0, high=1.0, size=(10, 3))
        c = np.random.uniform(low=0.0, high=1.0, size=(5, 10))

        y = 1

        yield {""options"": o, ""choices"": c}, y

dataset = tf.data.Dataset.from_generator(batch_gen, output_types=({""options"": tf.float32, ""choices"": tf.float32}, tf.float32))
dataset = dataset.batch(32)

model.fit(dataset, steps_per_epoch=100, epochs=1)
```
```


### Relevant log output

```shell
`Error in PredictCost() for the op: op: ""Softmax"" attr { key: ""T"" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: ""GPU"" vendor: ""NVIDIA"" model: ""NVIDIA GeForce GTX 1080 Ti"" frequency: 1670 num_cores: 28 environment { key: ""architecture"" value: ""6.1"" } environment { key: ""cuda"" value: ""11020"" } environment { key: ""cudnn"" value: ""8100"" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 2883584 shared_memory_size_per_multiprocessor: 98304 memory_size: 10099490816 bandwidth: 484440000 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }`
```
</details>"
57972,[XLA] Slow compilation,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

binary

### Tensorflow Version

2.7.0-rc0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.4

### GPU model and memory

_No response_

### Current Behaviour?

```shell
XLA's compilation time became a bottleneck for my model. It might take few minutes and be longer than actual calculations that happens afterwards. Without the compilation the model is also slow, therefore I believe XLA is the way to go.

I also got the following message:

> Very slow compile?  If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results. Compiling module a_inference_run_chain_compiled_520494__XlaMustCompile_true_config_proto_8589078909834744431_executor_type_11160318154034397263_.136564 

If there are no plans to improve performance in such cases as mine, I would be very happy to learn about possibilities of tweaking the compilation's behaviour with e.g. some env variable and to learn what is the right way to analyze compiler's logs.

Thanks!
```


### Standalone code to reproduce the issue

```shell
Given the size of the codebase a reproducible example wouldn't help much, but I'm happy to share the logs of the XLA compiler:

https://mdg365-my.sharepoint.com/:u:/g/personal/m_susik_biotype_de/EVxXXDJ0uUlGtAYACluCLdoBLFPInZpbn8vIY08Tuprnxg?e=B9woC3
```


### Relevant log output

_No response_</details>"
57971,ValueError: Tensor data is null. Run allocate_tensors() first,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04.5 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Getting all the weights of a TFLite model as numpy arrays raises `ValueError: Tensor data is null. Run allocate_tensors() first` after getting some of them, even though `allocate_tensors()` is indeed called first.

I expect to get all weights without an error.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

print(""TF version:"", tf.__version__)

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(units=1, input_shape=[1]),
    tf.keras.layers.Dense(units=16, activation='relu'),
    tf.keras.layers.Dense(units=1)
])

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

tensor_details = interpreter.get_tensor_details()
print(""Found"", len(tensor_details), ""tensors:"")
for tensor in tensor_details:
    print(f""Tensor {tensor['index']}: {tensor['name']}"")
    numpy_tensor = interpreter.get_tensor(tensor[""index""])
    print(""numpy shape:"", numpy_tensor.shape)
```


### Relevant log output

```shell
# python test_tflite_bug.py 
2022-09-30 18:48:49.190440: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
TF version: 2.10.0
2022-09-30 18:48:50.700174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-30 18:48:51.386990: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-09-30 18:48:51.387051: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-09-30 18:48:51.387815: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp9zntcxg8
2022-09-30 18:48:51.388897: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }
2022-09-30 18:48:51.388941: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp9zntcxg8
2022-09-30 18:48:51.391959: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-09-30 18:48:51.393032: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.
2022-09-30 18:48:51.409210: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp9zntcxg8
2022-09-30 18:48:51.415109: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 27301 microseconds.
2022-09-30 18:48:51.428541: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
Found 7 tensors:
Tensor 0: serving_default_dense_input:0
numpy shape: (1, 1)
Tensor 1: sequential/dense/MatMul1
numpy shape: (1, 1)
Tensor 2: sequential/dense_1/MatMul
numpy shape: (16, 1)
Tensor 3: sequential/dense_2/MatMul
numpy shape: (1, 16)
Tensor 4: sequential/dense/MatMul2
Traceback (most recent call last):
  File ""test_tflite_bug.py"", line 23, in <module>
    numpy_tensor = interpreter.get_tensor(tensor[""index""])
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/interpreter.py"", line 852, in get_tensor
    return self._interpreter.GetTensor(tensor_index, subgraph_index)
ValueError: Tensor data is null. Run allocate_tensors() first
```
</details>"
57970,Update the Android NDK to r25b LTS,"Currently the Android build of TensorFlow and TensorFlow Lite use an older NDK, either 19 or 21. The latest LTS release of the [Android NDK](https://developer.android.com/ndk) is r25b (the exact version is currently `25.1.8937393`), and [supports](https://github.com/android/ndk/wiki/Changelog-r25) the latest features and compilers (LLVM 14). 

See earlier NDK updates:

- https://github.com/tensorflow/tensorflow/commit/63e7c149d7817edb63adc085c9650e1659f3b699 Update TFLite to use Android NDK r18b
- https://github.com/tensorflow/tensorflow/commit/60bbb7c240580e79ad157e41c7c8058147e5085d Update the TFLite Android Dockerfile to use NDK r19c
- https://github.com/tensorflow/tensorflow/commit/1a0b21e16b08ab0bb1c15f9b5ec040bfbdee2685 Update NDK version to r19c
- https://github.com/tensorflow/tensorflow/commit/f4a65d74eb49eace09483df48b4ce2d94b6b354d [tf.lite] Update stale doc reference to recommended NDK version
- https://github.com/tensorflow/tensorflow/pull/34419"
57968,//tensorflow/python/tools:aot_compiled_test fails to build on aarch64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.10

### Bazel version

5.3.0

### GCC/Compiler version

10.3.0

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
Build of test fails static assertion.
`./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1068:27: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE`
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=2 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --build_tests_only -- //tensorflow/python/tools:aot_compiled_test
```


### Relevant log output

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=2 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --build_tests_only -- //tensorflow/python/tools:aot_compiled_test
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=162
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 --action_env PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages --python_path=/home/builder/1/tensorflow_build/venv_py38/bin/python3
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium
INFO: Found applicable config definition build:short_logs in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition test:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
INFO: Found applicable config definition build:nonccl in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:mkl_aarch64_threadpool in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=build_with_mkl_aarch64=true -c opt
INFO: Found applicable config definition build:linux in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-unknown-warning --copt=-Wno-array-parameter --copt=-Wno-stringop-overflow --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --copt=-Wswitch --copt=-Werror=switch --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/c6c79c4d98f6c74bb0005d7bc750bae2a19bb117.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
INFO: Analyzed target //tensorflow/python/tools:aot_compiled_test (0 packages loaded, 0 targets configured).
INFO: Found 1 test target...
ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/compiler/tf2xla/BUILD:247:11: Compiling tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc failed: (Exit 1): gcc failed: error executing command 
  (cd /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib \
    PATH=/home/builder/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-arm64/bin:/home/builder/1/tensorflow_build/venv_py38/bin:/home/builder/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 \
    PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /usr/local/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/aarch64-opt/bin/tensorflow/compiler/tf2xla/_objs/xla_compiled_cpu_runtime_standalone/runtime_single_threaded_conv2d.d '-frandom-seed=bazel-out/aarch64-opt/bin/tensorflow/compiler/tf2xla/_objs/xla_compiled_cpu_runtime_standalone/runtime_single_threaded_conv2d.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/aarch64-opt/bin -iquote external/com_google_absl -iquote bazel-out/aarch64-opt/bin/external/com_google_absl -iquote external/eigen_archive -iquote bazel-out/aarch64-opt/bin/external/eigen_archive -iquote external/nsync -iquote bazel-out/aarch64-opt/bin/external/nsync -isystem third_party/eigen3/mkl_include -isystem bazel-out/aarch64-opt/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/aarch64-opt/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/aarch64-opt/bin/external/nsync/public -Wno-all -Wno-extra -Wno-deprecated -Wno-deprecated-declarations -Wno-ignored-attributes -Wno-unknown-warning -Wno-array-parameter -Wno-stringop-overflow -Wno-array-bounds -Wunused-result '-Werror=unused-result' -Wswitch '-Werror=switch' -DAUTOLOAD_DYNAMIC_KERNELS '-mtune=generic' '-march=armv8-a' -O3 '-std=c++17' -DEIGEN_AVOID_STL_ARRAY -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc -o bazel-out/aarch64-opt/bin/tensorflow/compiler/tf2xla/_objs/xla_compiled_cpu_runtime_standalone/runtime_single_threaded_conv2d.o)
# Configuration: a8b71e5d0520f76083588e67158baf434d2d7485ee1864295a297beef7093c66
# Execution platform: @local_execution_config_platform//:platform
In file included from external/eigen_archive/Eigen/Core:162,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:21,
                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h: In instantiation of 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>, 8, 0, false, false>':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:250:5:   required from 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, true, 0, Eigen::MakePointer>]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:896:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:789:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:726:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >; RightArgType = const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:705:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:162:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:154:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:191:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, Vectorizable, Eigen::internal::On>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> > >; bool Vectorizable = true]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:39:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; DeviceType = Eigen::DefaultDevice]'
./tensorflow/compiler/xla/service/cpu/runtime_conv_impl.h:92:68:   required from 'void tensorflow::xla::EigenConv2DImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'
tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:58:26:   required from here
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1068:27: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE
 1068 |   EIGEN_STATIC_ASSERT((nr == 4), YOU_MADE_A_PROGRAMMING_MISTAKE)
      |                       ~~~~^~~~~
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h: In instantiation of 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>, 8, 0, false, false>':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:250:5:   required from 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:896:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:789:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:726:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = true; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >; RightArgType = const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:705:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:162:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:154:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:191:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, Vectorizable, Eigen::internal::On>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> > >; bool Vectorizable = true]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:39:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; DeviceType = Eigen::DefaultDevice]'
./tensorflow/compiler/xla/service/cpu/runtime_conv_impl.h:92:68:   required from 'void tensorflow::xla::EigenConv2DImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'
tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:58:26:   required from here
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1068:27: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h: In instantiation of 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>, 8, 0, false, false>':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:250:5:   required from 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, true, 0, Eigen::MakePointer>]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:896:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:789:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:726:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = true; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >; RightArgType = const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:705:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:162:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:154:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:191:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, Vectorizable, Eigen::internal::On>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> > >; bool Vectorizable = true]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:39:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; DeviceType = Eigen::DefaultDevice]'
./tensorflow/compiler/xla/service/cpu/runtime_conv_impl.h:92:68:   required from 'void tensorflow::xla::EigenConv2DImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'
tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:58:26:   required from here
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1068:27: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h: In instantiation of 'struct Eigen::internal::gemm_pack_rhs<float, long int, Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>, 8, 0, false, false>':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:250:5:   required from 'void Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::packRhs(RhsScalar**, const typename RhsMapper::SubMapper&, StorageIndex, StorageIndex) [with ResScalar = float; LhsScalar = float; RhsScalar = float; StorageIndex = long int; OutputMapper = Eigen::internal::blas_data_mapper<float, long int, 0, 0, 1>; LhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 1, Eigen::TensorEvaluator<const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, true, false, 0, Eigen::MakePointer>; RhsMapper = Eigen::internal::TensorContractionInputMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>; Eigen::internal::TensorContractionKernel<ResScalar, LhsScalar, RhsScalar, StorageIndex, OutputMapper, LhsMapper, RhsMapper>::RhsBlock = float*; typename RhsMapper::SubMapper = Eigen::internal::TensorContractionSubMapper<float, long int, 0, Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, Eigen::DefaultDevice>, Eigen::array<long int, 1>, Eigen::array<long int, 1>, 4, false, false, 0, Eigen::MakePointer>]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:896:25:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemmPartial(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*, Eigen::TensorContractionEvaluatorBase<Derived>::Index, Eigen::TensorContractionEvaluatorBase<Derived>::Index, int) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; bool use_output_kernel = true; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float; Eigen::TensorContractionEvaluatorBase<Derived>::Index = long int]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:789:52:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalGemm(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:726:66:   required from 'void Eigen::TensorContractionEvaluatorBase<Derived>::evalProductSequential(Eigen::TensorContractionEvaluatorBase<Derived>::Scalar*) const [with bool lhs_inner_dim_contiguous = true; bool rhs_inner_dim_contiguous = false; bool rhs_inner_dim_reordered = false; int Alignment = 0; Derived = Eigen::TensorEvaluator<const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>, Eigen::DefaultDevice>; Eigen::TensorContractionEvaluatorBase<Derived>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:1015:5:   required from 'void Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::evalProduct(Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar*) const [with int Alignment = 0; Indices = const Eigen::array<Eigen::IndexPair<long int>, 1>; LeftArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >; RightArgType = const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >; OutputKernelType = const Eigen::NoOpOutputKernel; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorContractionOp<Dimensions, LhsXprType, RhsXprType, OutputKernelType>, Device_>::Scalar = float]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContraction.h:705:70:   [ skipping 2 instantiation contexts, use -ftemplate-backtrace-limit=0 to disable ]
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:162:39:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType) [with NewDimensions = const Eigen::DSizes<long int, 4>; ArgType = const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel>; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorReshapingOp<NewDimensions, XprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:154:44:   required from 'bool Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::evalSubExprsIfNeeded(Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType) [with LeftArgType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; RightArgType = const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; Device = Eigen::DefaultDevice; Eigen::TensorEvaluator<const Eigen::TensorAssignOp<LhsXprType, RhsXprType>, Device>::EvaluatorPointerType = float*]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:191:61:   required from 'static void Eigen::internal::TensorExecutor<Expression, Eigen::DefaultDevice, Vectorizable, Eigen::internal::On>::run(const Expression&, const Eigen::DefaultDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> > >; bool Vectorizable = true]'
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:39:62:   required from 'Eigen::TensorDevice<ExpressionType, DeviceType>& Eigen::TensorDevice<ExpressionType, DeviceType>::operator=(const OtherDerived&) [with OtherDerived = Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 4>, const Eigen::TensorContractionOp<const Eigen::array<Eigen::IndexPair<long int>, 1>, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 2>, const Eigen::TensorImagePatchOp<-1, -1, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > > > >, const Eigen::TensorChippingOp<-1, const Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 3>, const Eigen::TensorMap<Eigen::Tensor<const float, 4, 1, long int>, 16, Eigen::MakePointer> > >, const Eigen::NoOpOutputKernel> >; ExpressionType = Eigen::TensorChippingOp<-1, Eigen::TensorReshapingOp<const Eigen::DSizes<long int, 5>, Eigen::TensorMap<Eigen::Tensor<float, 4, 1, long int>, 16, Eigen::MakePointer> > >; DeviceType = Eigen::DefaultDevice]'
./tensorflow/compiler/xla/service/cpu/runtime_conv_impl.h:92:68:   required from 'void tensorflow::xla::EigenConv2DImpl(const EigenDevice&, ScalarType*, ScalarType*, ScalarType*, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index, Eigen::Index) [with EigenDevice = Eigen::DefaultDevice; ScalarType = float; Eigen::Index = long int]'
tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:58:26:   required from here
./tensorflow/core/kernels/eigen_spatial_convolutions-inl.h:1068:27: error: static assertion failed: YOU_MADE_A_PROGRAMMING_MISTAKE
cc1plus: note: unrecognized command-line option '-Wno-array-parameter' may have been intended to silence earlier diagnostics
cc1plus: note: unrecognized command-line option '-Wno-unknown-warning' may have been intended to silence earlier diagnostics
Target //tensorflow/python/tools:aot_compiled_test failed to build
INFO: Elapsed time: 9.513s, Critical Path: 7.19s
INFO: 62 processes: 37 internal, 25 local.
FAILED: Build did NOT complete successfully
//tensorflow/python/tools:aot_compiled_test                     FAILED TO BUILD

FAILED: Build did NOT complete successfully
```
</details>"
57967,Issue with saving a network,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu

### Mobile device

_No response_

### Python version

3․8․10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


When I try to save EfficietNetB0 from tf.keras.applications.efficientnet locally, I receive a TypeError. I got the same error with B1 too, so I assume there's an issue with the whole Efnet Family (and maybe some other models too)

I had no issues with saving ResNet models from tf.keras.applications. 

UPD: There's no such problem in tf 2.9.1 



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
efnet = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, input_shape=(540,540,3), pooling=""avg"")
efnet.save(""tmp/efnet"")
```


### Relevant log output

```shell
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 115). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: tmp/efnet/assets
INFO:tensorflow:Assets written to: tmp/efnet/assets
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/mayis/.virtualenvs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/lib/python3.8/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python3.8/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
TypeError: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.
```
</details>"
57966,tf_sentencepiece problem with tensorflow 2.10.0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.10.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Mint

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I need a tf version that is dependent on scipy>=1.6.3 (at the moment, I have tf version 2.2.0 that depends on scipy==1.4.1). That's why I wanted to check if upgrading tf to version 2.10.0 would work, but now I have the following error message:


File ~/.local/share/virtualenvs/.spark-kernel-7xI1WBLh/lib/python3.8/site-packages/tf_sentencepiece/__init__.py:5, in <module>
      2 from __future__ import division
      3 from __future__ import print_function
----> 5 from tf_sentencepiece.sentencepiece_processor_ops import *

File ~/.local/share/virtualenvs/.spark-kernel-7xI1WBLh/lib/python3.8/site-packages/tf_sentencepiece/sentencepiece_processor_ops.py:47, in <module>
     44   warnings.warn('use the latest version %s' % (latest))
     45   so_file = so_base + '.' + latest
---> 47 _gen_sentencepiece_processor_op = tf.load_op_library(so_file)
     50 def piece_size(model_file=None, model_proto=None, name=None):
     51   """"""Returns the piece size (vocabulary size).
     52 
     53   Args:
   (...)
     60     A scalar representing the vocabulary size.
     61   """"""

File ~/.local/share/virtualenvs/.spark-kernel-7xI1WBLh/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py:54, in load_op_library(library_filename)
     31 @tf_export('load_op_library')
     32 def load_op_library(library_filename):
     33   """"""Loads a TensorFlow plugin, containing custom ops and kernels.
     34 
     35   Pass ""library_filename"" to a platform-specific mechanism for dynamically
   (...)
     52     RuntimeError: when unable to load the library or get the python wrappers.
     53   """"""
---> 54   lib_handle = py_tf.TF_LoadLibrary(library_filename)
     55   try:
     56     wrappers = _pywrap_python_op_gen.GetPythonWrappers(
     57         py_tf.TF_GetOpList(lib_handle))

NotFoundError: /home/jovyan/.local/share/virtualenvs/.spark-kernel-7xI1WBLh/lib/python3.8/site-packages/tf_sentencepiece/_sentencepiece_processor_ops.so.2.2.0: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb
```
```


### Standalone code to reproduce the issue

```shell
Please have a look at the above section.
```


### Relevant log output

_No response_</details>"
57965,tf.nn.gelu raises an exception when 'features'.dtype is not a floating point tensor,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.nn.gelu raises an exception when 'features'.dtype is not a floating point tensor. The documentation does not mention this requirement.
https://www.tensorflow.org/api_docs/python/tf/nn/gelu

A suggestion is to revise the docstring of 'features', or add a 'Raises' section to tf.nn.gelu documentation.
```
Issue[#54475](https://github.com/tensorflow/tensorflow/issues/54475) and PR[#54550](https://github.com/tensorflow/tensorflow/pull/54550) previously discussed about input types. A change was made in the code but not in the documentation.



### Standalone code to reproduce the issue

```shell
x = tf.constant([-3, -1, 0, 1, 3])
y = tf.nn.gelu(x)
```


### Relevant log output

```shell
ValueError: `features.dtype` must be a floating point tensor.Received:features.dtype=<dtype: 'int32'>
```
</details>"
57964,tf.nn.ctc_loss documentation does not mention that 'blank_index' must be provided when 'labels' is a SparseTensor,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Microsoft Windows 11

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.nn.ctc_loss raises an exception when 'labels' is a SparseTensor and 'blank_index' is not provided. The documentation does not mention this.
https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss

A suggestion is to revise the docstring for either 'labels' or 'blank_index', or add a 'Raises' section to tf.nn.ctc_loss documentation.

The code below is modified from /python/kernel_tests/nn_ops/ctc_loss_op_test.py
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.python.ops import random_ops
from tensorflow.python.framework import dtypes
from tensorflow.python.ops import array_ops

batch_size = 8
num_labels = 6
max_label_length = 5
num_frames = 12

labels = random_ops.random_uniform([batch_size, max_label_length], minval=1, maxval=num_labels, dtype=dtypes.int64)
logits = random_ops.random_uniform([num_frames, batch_size, num_labels])
label_length = random_ops.random_uniform([batch_size], minval=2, maxval=max_label_length, dtype=dtypes.int64)
label_mask = array_ops.sequence_mask(label_length, maxlen=max_label_length, dtype=label_length.dtype)
labels *= label_mask
logit_length = [num_frames] * batch_size

sp_labels = tf.sparse.from_dense(labels)
tf.nn.ctc_loss(sp_labels, logits, label_length, logit_length)
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""...\tftesting.py"", line 23, in <module>
    tf.nn.ctc_loss(sp_labels, logits, label_length, logit_length)
  File ""...\tensorflow\python\util\traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""C:\...\tensorflow\python\ops\ctc_ops.py"", line 937, in ctc_loss_v3
    raise ValueError(
ValueError: Argument `blank_index` must be provided when labels is a SparseTensor.
```
</details>"
57963,tensorflow.keras.layers has no attribute Normalization,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

Microsoft Windows 10 Home ersion 10.0.19043 Build 19043

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA-11.2.2 cuDNN-8.1.0.77

### GPU model and memory

GeForce GTX 1070

### Current Behaviour?

```shell
Following along with this tutorial from the TensorFlow website. https://www.tensorflow.org/tutorials/load_data/csv

This tutorial references a preprocessing layer called Normalization from tensorflow.keras.layers. Does this layer not exist anymore? Was the layer renamed? Maybe the tutorial is outdated?
```


### Standalone code to reproduce the issue

```shell
from tensorflow.keras import layers
normalize = layers.Normalization()
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""c:\Users\urkch\AppData\Local\Programs\Python\Python_Projects\tensorflow\Load CSV data\abalone.py"", line 39, in <module>
    normalize = layers.Normalization()
AttributeError: module 'tensorflow.keras.layers' has no attribute 'Normalization'
```
</details>"
57962,App attribute missing ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.9.1

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
File ""resnet_main.py"", line 18, in <module>
    FLAGS = tf.app.flags.FLAGSAttributeError: module 'tensorflow' has no attribute 'app'
```


### Standalone code to reproduce the issue

```shell
File ""resnet_main.py"", line 18, in <module>
    FLAGS = tf.app.flags.FLAGSAttributeError: module 'tensorflow' has no attribute 'app'
```


### Relevant log output

_No response_</details>"
57961,tf.signal.inverse_stft has inconsistent results with or without @tf.function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.signal.inverse_stft has inconsistent results with or without @tf.function for the following input
```


### Standalone code to reproduce the issue

```shell
# Colab Link: https://colab.research.google.com/drive/1MhNfkZgltqQqHw8kKG2zQi8ivwvKfRoj?usp=sharing


import tensorflow as tf
import numpy as np

print(tf.__version__)

input = {'frame_step': 29343, 'frame_length': 61, 'stfts': np.array([[]], dtype=np.complex64)}

output1 = tf.signal.inverse_stft(**input)

@tf.function
def fun_wrapper(x):
    return tf.signal.inverse_stft(**x)

output2 = fun_wrapper(input)

print(np.allclose(output1, output2))
```
```


### Relevant log output

```shell
2.10.0
False
```
</details>"
57960,tf.signal.stft has different results with or without @tf.function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.signal.stft has different results with or without @tf.function with the following input.
```


### Standalone code to reproduce the issue

```shell
# Colab Link: https://colab.research.google.com/drive/1WleKXby71iZXOL12r8nIN8B_jd2wJQks?usp=sharing


import tensorflow as tf
import numpy as np

print(tf.__version__)

input = {'fft_length': 46, 'frame_step': 19, 'frame_length': 0, 'signals': np.array([[[[-8.75314539e+307, -4.03838038e+307,  8.23775798e+307, -1.32627219e+307,  1.19815521e+307,  4.57117750e+307],
                                                                              [-4.74761327e+307, -4.71580522e+307, -5.88832102e+307, -6.48759076e+307, -4.36028464e+307, -4.77775171e+307],
                                                                              [ 1.20113701e+307, -7.60106094e+307,  7.22716917e+307, 2.17687950e+307, -5.25271143e+306,  5.41182394e+307]]]])}

output1 = tf.signal.stft(**input)

@tf.function
def fun_wrapper(x):
    return tf.signal.stft(**x)

output2 = fun_wrapper(input)

print(np.allclose(output1, output2))
```
```


### Relevant log output

```shell
2.10.0
False
```
</details>"
57959,tf.linalg.matrix_rank has different results with or without @tf.function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.linalg.matrix_rank has different results with or without @tf.function
```


### Standalone code to reproduce the issue

```shell
# Colab Link: https://colab.research.google.com/drive/1x7GZDd9hyaBA0S6tnUT0QjKdRu0eSFiK?usp=sharing


import numpy as np
import tensorflow as tf

print(tf.__version__)

input = {'name': 'matrix_rank', 'a': np.array([[-7.24721292e+307,  4.66389010e+307, -5.40181227e+307,
         7.28793100e+307,  5.19885794e+307],
       [-5.74381106e+307,  2.21923437e+307,  4.96898538e+307,
         4.26402766e+307,  7.42174751e+307],
       [-2.62810171e+307,  1.71425915e+307, -6.99349881e+307,
        -8.11519519e+307,  4.04358640e+307],
       [-8.52726304e+307,  1.44214314e+307, -4.53927548e+307,
        -4.79571993e+307, -4.59672928e+307]])}

output1 = tf.linalg.matrix_rank(**input)
print(output1)

@tf.function
def fun_wrapper(x):
    return tf.linalg.matrix_rank(**x)

output2 = fun_wrapper(input)
print(output2)
```
```


### Relevant log output

```shell
2.10.0
tf.Tensor(0, shape=(), dtype=int32)
tf.Tensor(4, shape=(), dtype=int32)
```
</details>"
57958,tf.nn.conv2d_transpose abort with large `output_shape`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.nn.conv2d_transpose crash with abort with large `output_shape`
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
tf.nn.conv2d_transpose(input=np.ones((2,2,2,2)), output_shape=[114078056, 179835296], strides=[10], filters=1)
```


### Relevant log output

```shell
2022-10-03 23:45:34.556541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-10-03 23:45:34.556569: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-03 23:45:34.556596: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2022-10-03 23:45:34.556893: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-03 23:45:34.595200: F tensorflow/core/framework/tensor_shape.cc:201] Non-OK-status: InitDims(dim_sizes) status: INVALID_ARGUMENT: Encountered overflow when multiplying 41030521935729152 with 22001, result: -1
Aborted (core dumped)
```
</details>"
57951,Couldn't install cuda 11.2 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

windows

### Mobile device

_No response_

### Python version

3.10.5

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Whenever I try to install the nvidia cuda 11.2 it always showing that you have the better version of nvidia sdk installed due to which i couldn't install cuda 11.2 and when i can't remove the cuda 11.6 because it is inbuilt in my nvidia graphics card and i can't grow my project. Please help give me any solution
```


### Standalone code to reproduce the issue

```shell
2022-10-03 20:28:00.694845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-10-03 20:28:00.695210: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-03 20:28:04.308452: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found
2022-10-03 20:28:04.309372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found
2022-10-03 20:28:04.311678: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found
2022-10-03 20:28:04.318107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2022-10-03 20:28:04.319331: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2022-10-03 20:28:04.320297: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusolver64_11.dll'; dlerror: cusolver64_11.dll not found
2022-10-03 20:28:04.321148: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found
2022-10-03 20:28:04.325541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found
2022-10-03 20:28:04.325872: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
```


### Relevant log output

_No response_</details>"
57950,F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf-gpu 2.6

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

NVIDIA RTX A4000, 16GB, 4DP

### Current Behaviour?

```shell
i want to use hyperband to get the best hyperparameter of a autoencoder-CNN. But after several trails, it always notice that problems:F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 . i try to find some solutions but not work.

There is no this problem in cpu but occur in gpu.

Any solution?
```


### Standalone code to reproduce the issue

```shell
   import kerastuner as kt #from google.colab import drive import pandas as pd import glob import pdb import numpy as np import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers import os import subprocess import h5py from tensorflow.keras import Sequential, layers, Model   #drive.mount(""/content/gdrive"") data_path=r'C:\\Users\\q75714hz\\New folder\\UVLIF\\PLAIR_HK\\Processed\\'  """"""1) Define custom generators that will load the data from multiple CSV files in batches during the training phase. """"""  from tensorflow.keras.utils import Sequence  class DataGenerator(Sequence):     """"""Generates data for Keras     Sequence based data generator. Suitable for building data generator for training and prediction.     CONTAINS SPECIFIC INFO FOR AUTOENCODERS     """"""     def __init__(self, list_files, to_fit=True, mini_batch = 1000, batch_size=1, shuffle=True):         """"""Initialization         :param data_path: path to datafiles         :param list_files: list of image labels (file names)         :param to_fit: True to return X and y, False to return X only         :param batch_size: batch size at each iteration         :param dim: tuple indicating image dimension         :param shuffle: True to shuffle label indexes after every epoch         """"""          # We have to create a mapping to the file name and the subset of data         # extracted from that file as a dictionary or list.         # To do this we need to count the number of lines in each file         # and then divide that by the mini_batch and loop through each         # chunck and define a starting point to extract the data          self.list_files = list_files         self.mini_batch = mini_batch         self.data_path = data_path         #self.mask_path = mask_path         self.to_fit = to_fit         self.batch_size = batch_size         #self.dim = dim         #self.n_channels = n_channels         #self.n_classes = n_classes         self.shuffle = shuffle         self.on_epoch_end()      def __len__(self):         """"""Denotes the number of batches per epoch         :return: number of batches per epoch         """"""         return int(np.floor(len(self.list_files) / self.batch_size))      def __getitem__(self, index):         """"""Generate one batch of data         :param index: index of the batch         :return: X and y when fitting. X only when predicting         """"""         # Generate indexes of the batch         indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]          # Find list of IDs         list_files_temp = [self.list_files[k] for k in indexes]          # Generate data         X = self._generate_X(list_files_temp)          #return X          if self.to_fit:             y = X             return (X, y)         else:             return X      def on_epoch_end(self):         """"""Updates indexes after each epoch         """"""         self.indexes = np.arange(len(self.list_files))         if self.shuffle == True:             np.random.shuffle(self.indexes)      def _generate_X(self, list_files_temp):         """"""Generates data containing batch_size images         :param list_IDs_temp: list of label ids to load         :return: batch of images         """"""         # Initialization         #X = np.empty((self.batch_size, *self.dim, self.n_channels))           if len(list_files_temp) == 1:           path = list_files_temp[0][0]           start_loc = list_files_temp[0][1]           end_loc = list_files_temp[0][2]           stop_point = min(start_loc+self.mini_batch,end_loc)            #info_df=pd.read_csv(path,skiprows=start_loc+1,nrows=min(self.mini_batch,end_loc-start_loc))           #Scattering_df = info_df.iloc[:, 34::][(info_df.iloc[:, 34::].T != 0).any()]           #Scattering_df[Scattering_df < 0] = 0           #Scattering_df=Scattering_df.div(Scattering_df.max(axis=1), axis=0)           ## extract the numpy array and then reshape back to the original size.           #images = Scattering_df.loc[:, Scattering_df.columns != 'label'].to_numpy()           #X = np.reshape(images, (images.shape[0], 80, 24, 1))            hf = h5py.File(path, 'r')           data=hf['test']['block0_values'][start_loc:stop_point, 33::]            #info_df=pd.read_hdf(filename, ""test"",start=start_loc,stop=stop_point)           #data=info_df.iloc[:, 33::].to_numpy()           data = data[~np.all(data == 0, axis=1)]           data=data[~np.isnan(data).all(axis=1)]           data=data[np.isfinite(data).all(axis=1)]            # basic stratgey here is to convert the image into a sharpened replica           data=data/np.max(data,axis=1)[:,None]           #std=np.std(data,axis=1)[:,None]           #mean=np.mean(data,axis=1)[:,None]           #data[data >= 0.001]=1.0           #data[data < 0.001]=0.0            #X = info_df.iloc[:, 33::].to_numpy().reshape(info_df.shape[0],80,24,1)           #data[data > 0.0001]=1.0           X=data.reshape(data.shape[0],80,24,1)          else:           Scattering_list=[None] * len(list_files_temp)           step=0           for entry in list_files_temp:             path = entry[0]             start_loc = entry[1]             end_loc = entry[2]             stop_point = min(start_loc+self.mini_batch,end_loc)             #info_df=pd.read_csv(path,na_filter=False,header=None,skiprows=start_loc+1,nrows=min(self.mini_batch,end_loc-start_loc))             #Scattering_df = info_df.iloc[:, 34::][(info_df.iloc[:, 34::].T != 0).any()]             #Scattering_df[Scattering_df < 0] = 0             #Scattering_df=Scattering_df.div(Scattering_df.max(axis=1), axis=0)             #Scattering_df = Scattering_df.dropna()             #info_df=pd.read_hdf(filename, ""test"",start=start_loc,stop=stop_point)             hf = h5py.File(path, 'r')             Scattering_list[step]=hf['test']['block0_values'][start_loc:stop_point, 33::]             #Scattering_list.append(info_df)             step+=1           #Scattering_df2=pd.concat(Scattering_list,axis=0) #pd.DataFrame.from_dict(Scattering_dict, orient='index')           #extract the numpy array and then reshape back to the original size.           #images = Scattering_df2.loc[:, Scattering_df2.columns != 'label'].to_numpy()           #pdb.set_trace()           #data=Scattering_df2.iloc[:, 33::].to_numpy()           data = Scattering_list[~np.all(Scattering_list == 0, axis=1)]           data=data[~np.isnan(data).all(axis=1)]           data=data[np.isfinite(data).all(axis=1)]           data=data/np.max(data,axis=1)[:,None]           #data[data >= 0.001]=1.0           #data[data < 0.001]=0.0           #data[data > 0.0001]=1.0           #X = Scattering_df2.iloc[:, 33::].to_numpy().reshape(Scattering_df2.shape[0],80,24,1)           X=data.reshape(data.shape[0],80,24,1)          return X  list_files = glob.glob(data_path+'*.hdf')  # define a minibatch which would normally be used in the standard training method minibatch = 1000  list_of_mappings = []  for filename in list_files:     # lines = int(subprocess.getoutput(""sed -n '$=' "" + filename))     hf=pd.read_hdf(filename,mode='r')     lines=int(hf.shape[0])     #pdb.set_trace()     chunks = int(np.ceil(lines / minibatch))     for step in range(chunks):         sublist=[]         sublist.append(filename)         sublist.append(step*minibatch)         sublist.append(min((step + 1)*minibatch,lines-2))         list_of_mappings.append(sublist) print(list_of_mappings[0:10]) print(list_of_mappings[11:20]) # pdb.set_trace()  training_generator = DataGenerator(list_of_mappings[:]) validation_generator = DataGenerator(list_of_mappings[:]) print(len(list_of_mappings[:])) print(len(training_generator))   # define tunner of ae  def model(hp):      original_inputs = keras.Input(shape=(80, 24, 1), name='encoder_input')     variance_scale = 0.3     init = tf.keras.initializers.VarianceScaling(scale=variance_scale, mode='fan_in', distribution='uniform')     layer= layers.Conv2D(filters=hp.Choice(""num_filters_layer_1"", values=[8, 32], default=8), kernel_size=3,                                activation='relu', kernel_initializer=init, padding='same',                                strides=1)(original_inputs)     layer1 = layers.Conv2D(filters=hp.Int(""num_filters_layer_2"", min_value=16, max_value=64, step=16), kernel_size=3,                           activation='relu', kernel_initializer=init, padding='same',                           strides=1)(layer)     layer2 = layers.Conv2D(filters=hp.Int(""num_filters_layer_3"", min_value=16, max_value=96, step=16), kernel_size=3,                           activation='relu', kernel_initializer=init, padding='same',                           strides=1)(layer1)     layer3 = layers.Conv2D(filters=hp.Int(""num_filters_layer_4"", min_value=16, max_value=112, step=16), kernel_size=3,                           activation='relu', kernel_initializer=init, padding='same',                           strides=1)(layer2)        layer_flatten = layers.Flatten()(layer3)     h = layers.Dense(hp.Int(""num_Dense"", 0, 600, 200), activation='relu', name=""encoding_5"")(layer_flatten)     latent_layer = layers.Dense(hp.Int(""latent_space"", 20, 40, 10), activation='relu')(h)      #decoder     latent_inputs_cnn = keras.Input(shape=(latent_layer.shape[1],), name='latent_input')     dec_layer1_cnn = layers.Dense(h.shape[1], activation='relu')(latent_inputs_cnn)     dec_layer2_cnn = layers.Dense(layer_flatten.shape[1], activation='relu')(dec_layer1_cnn)     dec_layer = layers.Reshape((layer3.shape[1], layer3.shape[2], layer3.shape[3]))(dec_layer2_cnn)      dec_layer3_cnn = layers.Conv2DTranspose(hp.Int(""num_filters_layer_3"", min_value=16, max_value=96, step=16),                                             kernel_size=3, activation='relu', kernel_initializer=init,                                             padding='same', strides=1)(dec_layer)      dec_layer4_cnn = layers.Conv2DTranspose(filters=hp.Int(""num_filters_layer_2"", min_value=16, max_value=64, step=16), kernel_size=3,                            activation='relu', kernel_initializer=init, padding='same',                            strides=1)(dec_layer3_cnn)       dec_layer5_cnn=layers.Conv2DTranspose(filters=hp.Choice(""num_filters_layer_1"",values=[8,32],default=8), kernel_size=3, activation='relu', kernel_initializer=init,                                             padding='same', strides=1)(dec_layer4_cnn)     dec_layer6_cnn = layers.Conv2DTranspose(original_inputs.shape[3], (3, 3), activation='sigmoid',                                             kernel_initializer=init, padding='same', strides=1)(dec_layer5_cnn)     dec_cnn = Model(inputs=latent_inputs_cnn, outputs=dec_layer6_cnn, name='decoder_cnn')     outputs = dec_cnn(latent_layer)      cnn_ae = Model(inputs=original_inputs, outputs=outputs, name='cnn_ae')      cnn_ae.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-5])),                    loss='binary_crossentropy', metrics=['accuracy'])      return cnn_ae  tuner = kt.Hyperband(model,                      objective='loss',                      max_epochs=5,                      factor=3,                      directory='my_dir_SE',                      project_name='intro_to_kt_se' ,overwrite=True)    tuner.search(training_generator, epochs=4, workers=4)  # Get the optimal hyperparameters best_hps =tuner.get_best_hyperparameters(num_trials=1)[0]   # Now we can train the AE and save it, if needs be, for later use. # Build the model with the optimal hyperparameters and train it on the data for 30 epochs model = tuner.hypermodel.build(best_hps) history = model.fit(training_generator, epochs=40, workers=4) model.save('ae_sequence_scattering_40epochs.h5') val_acc_per_epoch = history.history['val_loss'] best_epoch = val_acc_per_epoch.index(min(val_acc_per_epoch)) + 1 print('Best epoch: %d' % (best_epoch,)) hypermodel = tuner.hypermodel.build(best_hps) # Retrain the model history_new = hypermodel.fit(training_generator, epochs=best_epoch,workers=4) hypermodel.save('ae_sequence_scattering.h5')
```


### Relevant log output

_No response_</details>"
57949,https://stackoverflow.com/questions/73934844/issue-with-y-true-argument-that-in-passed-into-customloss-class-while-running,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

Yes

### OS Platform and Distribution

ALL

### Mobile device

ALL

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I expected the code to run flawlessly. But the y_true argument in call method of CustomLoss class gave tensor of shape (None, None, None, None).
```


### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1TCE2UZ0buwesGbkh2dhlUEiMfLnR8F88?usp=sharing
```


### Relevant log output

_No response_</details>"
57947,Extension file 'tensorflow/core/platform/default/rules_cc.bzl' has errors when install tflite-support-0.4.2 using Bazel 4.2.2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2

### Custom Code

No

### OS Platform and Distribution

Raspbian Buster

### Mobile device

_No response_

### Python version

3.7

### Bazel version

4.2.2

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I tried to install tflite-support-0.4.2 using bazel on my Raspberry Pi (Raspbian Buster) since I can't install it directly using pip3. I expected that installing from bazel will result in complete installation of tflite-support. However when I try to build the package it gives me this error. I tried several time but the result is still the same.
 
`
ERROR: Traceback (most recent call last):
        File ""/home/pi/.cache/bazel/_bazel_pi/e377461fba63f25ab8757a7080bd56fe/external/org_tensorflow/tensorflow/core/platform/default/rules_cc.bzl"", line 6, column 28, in <toplevel>
                _cc_shared_library = native.cc_shared_library
Error: no native function or rule 'cc_shared_library'
ERROR: Analysis of target '//tensorflow_lite_support/tools/pip_package:build_pip_package' failed; build aborted: error loading package '@org_tensorflow//tensorflow': in /home/pi/.cache/bazel/_bazel_pi/e377461fba63f25ab8757a7080bd56fe/external/org_tensorflow/tensorflow/tensorflow.bzl: in /home/pi/.cache/bazel/_bazel_pi/e377461fba63f25ab8757a7080bd56fe/external/org_tensorflow/tensorflow/core/platform/rules_cc.bzl: Extension file 'tensorflow/core/platform/default/rules_cc.bzl' has errors`

The code in 'tensorflow/core/platform/default/rules_cc.bzl' is:

`""""""Provides an indirection layer to bazel cc_rules""""""

load(
    ""//tensorflow/core/platform/default:rules_cc.bzl"",
    _cc_binary = ""cc_binary"",
    _cc_import = ""cc_import"",
    _cc_library = ""cc_library"",
    _cc_shared_library = ""cc_shared_library"",
    _cc_test = ""cc_test"",
)

cc_binary = _cc_binary
cc_import = _cc_import
cc_library = _cc_library
cc_shared_library = _cc_shared_library
cc_test = _cc_test`
```


### Standalone code to reproduce the issue

```shell
I just use this command (no custom code):

`bazel build -c opt tensorflow_lite_support/tools/pip_package:build_pip_package` that I learned from https://github.com/tensorflow/tflite-support/issues/755

The command runs OK but eventually FAILED: Build did NOT complete successfully (7 packages loaded, 10 targets configured).

Thanks
```


### Relevant log output

_No response_</details>"
57946,Wrong Shape Signature Output after Conversion to TFLite,"Hello,

Having problems with the conversion of a keras model to tflite (CNN + BLSTM) I replaced the recursive layers by simple Dense. The model works and converges well.

Here is the summary:

==================================================================================================
 image (InputLayer)             [(None, 32, 128, 3)  0           []                               
                                ]                                                                 
                                                                                                  
 conv2d_7 (Conv2D)              (None, 32, 128, 32)  896         ['image[0][0]']                  
                                                                                                  
 max_pooling2d_4 (MaxPooling2D)  (None, 16, 64, 32)  0           ['conv2d_7[0][0]']               
                                                                                                  
 conv2d_8 (Conv2D)              (None, 16, 64, 64)   18496       ['max_pooling2d_4[0][0]']        
                                                                                                  
 max_pooling2d_5 (MaxPooling2D)  (None, 8, 64, 64)   0           ['conv2d_8[0][0]']               
                                                                                                  
 conv2d_9 (Conv2D)              (None, 8, 64, 128)   73856       ['max_pooling2d_5[0][0]']        
                                                                                                  
 conv2d_10 (Conv2D)             (None, 8, 64, 128)   147584      ['conv2d_9[0][0]']               
                                                                                                  
 max_pooling2d_6 (MaxPooling2D)  (None, 4, 64, 128)  0           ['conv2d_10[0][0]']              
                                                                                                  
 conv2d_11 (Conv2D)             (None, 4, 64, 256)   295168      ['max_pooling2d_6[0][0]']        
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 4, 64, 256)  1024        ['conv2d_11[0][0]']              
 rmalization)                                                                                     
                                                                                                  
 conv2d_12 (Conv2D)             (None, 4, 64, 256)   590080      ['batch_normalization_2[0][0]']  
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 4, 64, 256)  1024        ['conv2d_12[0][0]']              
 rmalization)                                                                                     
                                                                                                  
 max_pooling2d_7 (MaxPooling2D)  (None, 2, 64, 256)  0           ['batch_normalization_3[0][0]']  
                                                                                                  
 conv2d_13 (Conv2D)             (None, 1, 63, 64)    65600       ['max_pooling2d_7[0][0]']        
                                                                                                  
 lambda_1 (Lambda)              (None, 63, 64)       0           ['conv2d_13[0][0]']              
                                                                                                  
 dense_crazy_1 (Dense)          (None, 63, 256)      16640       ['lambda_1[0][0]']               
                                                                                                  
 dropout_1 (Dropout)            (None, 63, 256)      0           ['dense_crazy_1[0][0]']          
                                                                                                  
 dense_crazy_2 (Dense)          (None, 63, 128)      32896       ['dropout_1[0][0]']              
                                                                                                  
 label (InputLayer)             [(None, None)]       0           []                               
                                                                                                  
 dense (Dense)                  (None, 63, 48)       6192        ['dense_crazy_2[0][0]']          
                                                                                                  
 ctc_loss (CTCLayer)            (None, 63, 48)       0           ['label[0][0]',                  
                                                                  'dense[0][0]']                  
                                                                                                  
==================================================================================================

On the other hand, if I keep a part (before CTC) and I convert to tflite, I have an output dimension error, I would like to have [1, 63, 48] but I have this : 

'shape': array([ 1, 1, 48], dtype=int32),
'shape_signature': array([-1, -1, 48], dtype=int32),

CODE : 

prediction_model = keras.models.Model(
    model.get_layer(name=""image"").input, model.get_layer(name=""dense"").output
)

tf.saved_model.save(prediction_model, ""prediction_model"")
loaded = tf.saved_model.load(""prediction_model"")
infer = loaded.signatures[""serving_default""]
converter = tf.lite.TFLiteConverter.from_saved_model(""prediction_model"") # path to the SavedModel directory
tflite_model = converter.convert()
with open('prediction_model.tflite', 'wb') as f:
    f.write(tflite_model)
    
p = ""prediction_model.tflite""
interpreter = tf.lite.Interpreter(model_path=p)
output_details = interpreter.get_output_details()

Thanks for your help"
57945,Error loading fashion_mnist dataset,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

Yes

### OS Platform and Distribution

Microsoft Windows 10 Home ersion 10.0.19043 Build 19043

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA-11.2.2 cuDNN-8.1.0.77

### GPU model and memory

GeForce GTX 1070

### Current Behaviour?

```shell
I expected to be able to load the `fashion_mnist` data. This might be an issue with converting `:` to `%3A` in the urls on `fashion_mnist.py`.
Here is the code from `fashion_mnist.py` that I think is relevant.

    dirname = os.path.join(""datasets"", ""fashion-mnist"")
    base = ""https://storage.googleapis.com/tensorflow/tf-keras-datasets/""
    files = [
        ""train-labels-idx1-ubyte.gz"",
        ""train-images-idx3-ubyte.gz"",
        ""t10k-labels-idx1-ubyte.gz"",
        ""t10k-images-idx3-ubyte.gz"",
    ]

    paths = []
    for fname in files:
        paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))

As you can see, `base` and `fname` are getting combined using string concatenation instead of something like urljoin. 
Relevant stackoverflow question: https://stackoverflow.com/questions/27115803/urllib-error-urlerror-urlopen-error-unknown-url-type-https
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```


### Relevant log output

```shell
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz
Traceback (most recent call last):
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\site-packages\keras\utils\data_utils.py"", line 296, in get_file
    urlretrieve(origin, fpath, DLProgbar())
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\site-packages\keras\utils\data_utils.py"", line 84, in urlretrieve
    response = urlopen(url, data)
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\urllib\request.py"", line 214, in urlopen
    return opener.open(url, data, timeout)
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\urllib\request.py"", line 517, in open
    response = self._open(req, data)
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\urllib\request.py"", line 539, in _open
    return self._call_chain(self.handle_open, 'unknown',
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\urllib\request.py"", line 494, in _call_chain
    result = func(*args)
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\urllib\request.py"", line 1417, in unknown_open
    raise URLError('unknown url type: %s' % type)
urllib.error.URLError: <urlopen error unknown url type: https>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Users\urkch\AppData\Local\Programs\Python\Python_Projects\tensorflow\Basic classification Classify images of clothing\classify.py"", line 12, in <module>
    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\site-packages\keras\datasets\fashion_mnist.py"", line 93, in load_data
    paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))
  File ""C:\Users\urkch\miniconda3\envs\tf\lib\site-packages\keras\utils\data_utils.py"", line 300, in get_file
    raise Exception(error_msg.format(origin, e.errno, e.reason))
Exception: URL fetch failure on https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz: None -- unknown url type: https
```
</details>"
57943,Incorrect Output in windows for few quant models in windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.10

### Bazel version

4.2.2

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
python output and Linux output were matching.
But windows output is different from Linux and producing incorrect results.
Attached the models producing incorrect results
```


### Standalone code to reproduce the issue

```shell
Run label image example for both models and get the output.
```


### Relevant log output

```shell
https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/default/1


https://tfhub.dev/iree/lite-model/mobilenet_v2_100_224/uint8/1
```
</details>"
57941,Build Failed   for CUDA 11.7 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2

### Custom Code

No

### OS Platform and Distribution

Linux mint 21

### Mobile device

_No response_

### Python version

3.10

### Bazel version

3.1.0

### GCC/Compiler version

Ubuntu clang version 14.0.0-1ubuntu1 Target: x86_64-pc-linux-gnu Thread model: posix InstalledDir: /usr/bin

### CUDA/cuDNN version

11.7/8.5

### GPU model and memory

RTX 3050 Ti

### Current Behaviour?

```shell
WARNING: The following configs were expanded more than once: [cuda_clang, using_cuda, v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=238
INFO: Reading rc options for 'build' from /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --copt=-DTFLITE_WITH_RUY_GEMV --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/dlock/anaconda3/bin/python3 --action_env PYTHON_LIB_PATH=/home/dlock/anaconda3/lib/python3.9/site-packages --python_path=/home/dlock/anaconda3/bin/python3 --config=xla --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.7 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.6 --action_env LD_LIBRARY_PATH=/usr/local/cuda-11.7/lib64: --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/bin/clang --config=cuda_clang --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:cuda_clang in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_clang=true --define=using_clang=true --action_env TF_CUDA_CLANG=1
INFO: Found applicable config definition build:using_cuda in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:cuda_clang in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_clang=true --define=using_clang=true --action_env TF_CUDA_CLANG=1
INFO: Found applicable config definition build:using_cuda in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.tf_configure.bazelrc: --copt=-march=native --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true
INFO: Found applicable config definition build:cuda in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:v2 in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:linux in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Repository local_config_cuda instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule cuda_configure defined at:
  /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl:1399:18: in <toplevel>
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
Expected even number of arguments
INFO: Repository rules_cc instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule tf_http_archive defined at:
  /home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/repo.bzl:136:19: in <toplevel>
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
Expected even number of arguments
WARNING: Target pattern parsing failed.
ERROR: no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/dlock/deepSpeech-proj/DeepSpeech/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
Expected even number of arguments
INFO: Elapsed time: 0.363s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package
```


### Standalone code to reproduce the issue

```shell
azel build --config=opt --config=cuda --config=v2 //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

_No response_</details>"
57940,C++ compilation of rule '@boringssl//:ssl' failed,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf r2.3

### Custom Code

Yes

### OS Platform and Distribution

linux ubuntu 22.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

3.1.0

### GCC/Compiler version

11.2.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Bazel Build did NOT complete successfully
```


### Standalone code to reproduce the issue

```shell
bazel build --config=opt //tensorflow:libtensorflow_cc.so -j 4
```


### Relevant log output

```shell
/home/zy/.cache/bazel/_bazel_zy/5935bdb2f2c9da386ddbe8aec185b7fc/external/boringssl/BUILD:130:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)
external/boringssl/src/third_party/fiat/curve25519.c:511:57: error: argument 2 of type 'const uint8_t[32]' {aka 'const unsigned char[32]'} with mismatched bound [-Werror=array-parameter=]
  511 | int x25519_ge_frombytes_vartime(ge_p3 *h, const uint8_t s[32]) {
      |                                           ~~~~~~~~~~~~~~^~~~~
In file included from external/boringssl/src/third_party/fiat/curve25519.c:41:
external/boringssl/src/third_party/fiat/internal.h:117:58: note: previously declared as 'const uint8_t *' {aka 'const unsigned char *'}
  117 | int x25519_ge_frombytes_vartime(ge_p3 *h, const uint8_t *s);
      |                                           ~~~~~~~~~~~~~~~^
external/boringssl/src/third_party/fiat/curve25519.c:831:57: error: argument 2 of type 'const uint8_t *' {aka 'const unsigned char *'} declared as a pointer [-Werror=array-parameter=]
  831 | void x25519_ge_scalarmult_base(ge_p3 *h, const uint8_t *a) {
      |                                          ~~~~~~~~~~~~~~~^
In file included from external/boringssl/src/third_party/fiat/curve25519.c:41:
external/boringssl/src/third_party/fiat/internal.h:125:56: note: previously declared as an array 'const uint8_t[32]' {aka 'const unsigned char[32]'}
  125 | void x25519_ge_scalarmult_base(ge_p3 *h, const uint8_t a[32]);
      |                                          ~~~~~~~~~~~~~~^~~~~
cc1: all warnings being treated as errors
Target //tensorflow:libtensorflow_cc.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
```
</details>"
57939,tf.io.gfile.glob is extremely slow,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.9 and 2.10

### Custom Code

No

### OS Platform and Distribution

macOS 12

### Mobile device

-

### Python version

3.9

### Bazel version

-

### GCC/Compiler version

-

### CUDA/cuDNN version

-

### GPU model and memory

_No response_

</details>


### Current Behaviour?

In my environments, `tf.io.gfile` APIs are extremely slow.



### Standalone code to reproduce the issue

For instance:

```
>>> import tensorflow.io.gfile as gfile  # type: ignore
>>> gfile.glob('gs://tfds-data/*.jsonl')
2022-10-01 22:59:07.324892: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""NOT_FOUND: Could not locate the credentials file."". Retrieving token from GCE failed with ""FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata"".
['gs://tfds-data/community-datasets-list.jsonl']
```


The above takes around 70 seconds to query. Note that `gs://tfds-data/` bucket has only ~7 files on the root directory. Would `glob` walk the entire subtree recursively?

In contrast, `gsutil` commands are quite fast.
```
❯❯❯ time noglob gsutil ls gs://tfds-data/*.jsonl
gs://tfds-data/community-datasets-list.jsonl
noglob gsutil ls gs://tfds-data/*.jsonl  0.62s user 0.16s system 78% cpu 0.997 total
```


### Relevant log output

_No response_"
57937,"Getting ""OSError: [WinError 6] The handle is invalid"" after epoch ends in Tensorflow","
I'm running a U-net model in Tensorflow with GPU enhancement. After the 2nd or 3rd epoch, I get several error messages stating: ""OSError: [WinError 6] The handle is invalid."" I did not have this issue come up when I ran it with CPU only.

I'm using an Anaconda environment created with conda-forge. These are the package/software versions I'm using:

Python: 3.10.6, Tensorflow: 2.10.0, cudatoolkit 11.2, cudnn 8.1.0  

Here is a sampling of the error message:

```
  (1) UNKNOWN:  OSError: [WinError 6] The handle is invalid
Traceback (most recent call last):

  File ""C:\Users\Administrator\anaconda3\envs\spyder-gpu7\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 269, in __call__
    return func(device, token, args)

  File ""C:\Users\Administrator\anaconda3\envs\spyder-gpu7\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 147, in __call__
    outputs = self._call(device, args)

  File ""C:\Users\Administrator\anaconda3\envs\spyder-gpu7\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 154, in _call
    ret = self._func(*args)

  File ""C:\Users\Administrator\anaconda3\envs\spyder-gpu7\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 642, in wrapper
    return func(*args, **kwargs)

  File ""C:\Users\Administrator\AppData\Local\Temp\2\ipykernel_904\876533028.py"", line 3, in extract_mask
    mask = tf.keras.utils.img_to_array(Image.open(mask_path))

  File ""C:\Users\Administrator\anaconda3\envs\spyder-gpu7\lib\site-packages\PIL\Image.py"", line 3092, in open
    fp = builtins.open(filename, ""rb"")

OSError: [WinError 6] The handle is invalid


	 [[{{node EagerPyFunc}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_77188]

Restarting kernel...
```
Does anyone know why this is happening, or what I can do to fix it?

"
57936,impossibility to build from source  Mac M1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

macOS 12.6

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/Compiler version

Apple clang version 14.0.0 (clang-1400.0.29.102) Target: arm64-apple-darwin21.6.0 Thread model: posix InstalledDir: /Library/Developer/CommandLineTools/usr/bin

### CUDA/cuDNN version

_No response_

### GPU model and memory

M1 Max 64Go

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
Benjamin@macbook-pro tensorflow % bazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /Users/Benjamin/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/Benjamin/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'build' from /Users/Benjamin/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/opt/homebrew/opt/python@3.10/bin/python3.10 --action_env PYTHON_LIB_PATH=/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages --python_path=/opt/homebrew/opt/python@3.10/bin/python3.10
INFO: Reading rc options for 'build' from /Users/Benjamin/tensorflow/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /Users/Benjamin/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/Benjamin/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:macos_arm64 in file /Users/Benjamin/tensorflow/.bazelrc: --cpu=darwin_arm64 --macos_minimum_os=11.0
INFO: Found applicable config definition build:macos in file /Users/Benjamin/tensorflow/.bazelrc: --apple_platform_type=macos --copt=-DGRPC_BAZEL_BUILD --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
[7,212 / 9,178] 10 actions running
[7,215 / 9,178] 10 actions running
[7,216 / 9,178] 10 actions running
[7,219 / 9,178] 10 actions running
[7,220 / 9,178] 10 actions running
[7,221 / 9,178] 10 actions running
[7,225 / 9,178] 10 actions running
[7,231 / 9,182] 10 actions, 9 running
[7,231 / 9,182] 10 actions running
[7,233 / 9,184] 10 actions, 9 running
[7,242 / 9,192] 9 actions running
[7,242 / 9,192] 10 actions running
[7,247 / 9,276] 10 actions running
ERROR: /Users/Benjamin/tensorflow/tensorflow/python/util/BUILD:154:27: Linking tensorflow/python/util/_pywrap_determinism.so [for host] failed: (Exit 1): cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh @bazel-out/host/bin/tensorflow/python/util/_pywrap_determinism.so-2.params
ld: malformed trie, childNodeOffset==0 file 'bazel-out/host/bin/_solib_darwin_arm64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/lib_pywrap_tensorflow_internal.dylib'
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /Users/Benjamin/tensorflow/tensorflow/lite/python/BUILD:68:10 Middleman _middlemen/tensorflow_Slite_Spython_Stflite_Uconvert-runfiles failed: (Exit 1): cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh @bazel-out/host/bin/tensorflow/python/util/_pywrap_determinism.so-2.params
INFO: Elapsed time: 1416,966s, Critical Path: 178,71s
INFO: 6320 processes: 112 internal, 6208 local.
FAILED: Build did NOT complete successfully
```


### Relevant log output

_No response_</details>"
57935,Wrong result in `tf.experimental.numpy.floor_divide` and `tf.experimental.numpy.remainder` when divide 0 by 0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0-dev20221001

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

`tf.experimental.numpy.floor_divide(0, 0)` gives `-1` on CUDA (which is totally wrong), raises `InvalidArgumentError` on CPU. For reference, `np.floor_divide(0, 0)` gives `0`.

Similarly `np.remainder(0, 0)` gives `0`, `tf.experimental.numpy.remainder(0, 0)` also gives `0` on CUDA, but raises `InvalidArgumentError` on CPU.

I think 0/0 results should be `0` on both CPU and CUDA, which is consistent with numpy.


### Standalone code to reproduce the issue
For `floor_divide`: 
```shell
import tensorflow as tf
import numpy as np
x = np.arange(10)
y = np.arange(10) 
print(np.floor_divide(0, 0)) # 0
with tf.device(""gpu""):
  print(tf.experimental.numpy.floor_divide(0, 0)) # -1
with tf.device(""cpu""):
  print(tf.experimental.numpy.floor_divide(0, 0)) # InvalidArgumentError
```


### Relevant log output

```shell
0
tf.Tensor(-1, shape=(), dtype=int64)
InvalidArgumentError: {{function_node __wrapped__FloorDiv_device_/job:localhost/replica:0/task:0/device:CPU:0}} Integer division by zero [Op:FloorDiv]
```

For `remainder`:

### Code
```
import tensorflow as tf
import numpy as np
print(np.remainder(0, 0)) # 0
with tf.device(""gpu""):
  print(tf.experimental.numpy.remainder(0, 0)) # 0
with tf.device(""cpu""):
  print(tf.experimental.numpy.remainder(0, 0)) # InvalidArgumentError
```
### Outputs
```
0
tf.Tensor(0, shape=(), dtype=int64)
InvalidArgumentError: {{function_node __wrapped__FloorMod_device_/job:localhost/replica:0/task:0/device:CPU:0}} Integer division by zero [Op:FloorMod]
```
</details>"
57934,Class GpuDelegateFactory missing in Tensorflow Lite Java,"It looks like the `GpuDelegateFactory` is missing in the latest version of tflite on Android.

When ipmorting with `org.tensorflow.lite.gpu.GpuDelegateFactory`, compilation fails with `Unresolved reference: GpuDelegateFactory`.

I have imported the following packages:

```
    implementation 'org.tensorflow:tensorflow-lite:2.10.0'
    implementation 'org.tensorflow:tensorflow-lite-api:2.10.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.10.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu-delegate-plugin:0.4.2'
    implementation 'org.tensorflow:tensorflow-lite-support:0.4.2'
```

But none of these seem to contain `GpuDelegateFactory`.


<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
It looks like the `GpuDelegateFactory` is missing in the latest version of tflite on Android.

When ipmorting with `org.tensorflow.lite.gpu.GpuDelegateFactory`, compilation fails with `Unresolved reference: GpuDelegateFactory`.

I have imported the following packages:


    implementation 'org.tensorflow:tensorflow-lite:2.10.0'
    implementation 'org.tensorflow:tensorflow-lite-api:2.10.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.10.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu-delegate-plugin:0.4.2'
    implementation 'org.tensorflow:tensorflow-lite-support:0.4.2'
```

But none of these seem to contain `GpuDelegateFactory`.
```


### Standalone code to reproduce the issue

```shell
import org.tensorflow.lite.gpu.GpuDelegateFactory
```


### Relevant log output

_No response_</details>"
57933,Import error Mac M1 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

TensorFlow-macos 

### Custom Code

No

### OS Platform and Distribution

macOS Monterey 

### Mobile device

_No response_

### Python version

3.10.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
see below
```


### Standalone code to reproduce the issue

```shell
3.10.6 (main, Aug 30 2022, 04:58:14) [Clang 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/opt/homebrew/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/opt/homebrew/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/opt/homebrew/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/opt/homebrew/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 47, in <module>
    from google.protobuf.pyext import _message
ImportError: dlopen(/opt/homebrew/lib/python3.10/site-packages/google/protobuf/pyext/_message.cpython-310-darwin.so, 0x0002): symbol not found in flat namespace (__ZNK6google8protobuf10TextFormat21FastFieldValuePrinter19PrintMessageContentERKNS0_7MessageEiibPNS1_17BaseTextGeneratorE)
```


### Relevant log output

```shell
No
```
</details>"
57931,Modelmaker: input/output shapes gets altered when converting from .pb to .tflite,"### 1. System information

- Colab environment
- tflite-model-maker-nightly
- tflite-support


### 2. Issue
- Train a model using,
model = object_detector.create()

- Export to tflite using FP16 quantization
config = QuantizationConfig.for_float16()
model.export(export_dir='./', tflite_filename='check_fp16.tflite', quantization_config=config)

- Check for input shape, input type, out shape, output type
Input Shape: [  1 320 320   3]
Input Type: <class 'numpy.float32'>
Output Shape: []
Output Type: <class 'numpy.float32'>

Next, create a tflite file through .pb file and then check for input / output shapes.

- Export to .pb format
model.export(export_dir='.', saved_model_filename='android_wts', export_format=ExportFormat.SAVED_MODEL)
OR
model._export_saved_model('android_wts_saved')


- Convert .pb format to tflite using fp16 quantization
file_path = './android_wts'
tf_lite_converter = tf.lite.TFLiteConverter.from_saved_model(file_path, signature_keys=['serving_default'])

tf_lite_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]

tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]   # Have tried enabling this parameter as well
tf_lite_converter.target_spec.supported_types = [tf.float16]
tflite_model = tf_lite_converter.convert()

TF_LITE_MODEL_FILE_NAME = ""/currdrive/road_hero/model_noquant.tflite""

with tf.io.gfile.GFile(TF_LITE_MODEL_FILE_NAME, 'wb') as f:
  f.write(tflite_model)

- Check for input shape, input type, out shape, output type
Input Shape: [1 1 1 3]
Input Type: <class 'numpy.uint8'>
Output Shape: [1 1]
Output Type: <class 'numpy.float32'>


To summarize, there is a mismatch in [input shape, input type, out shape, output type]. Suspect, some information is lost, while creating a file with .pb format.

Can you please look into this.



### 3. Reference colab notebooks

1)  Access to Colab notebook
[Colab Notebook Link](https://colab.research.google.com/drive/1QlXjo3aXsOVBbr6uTTbHC2qECceMO_5V#scrollTo=pSidbHq4Pt6w)

Have given required access to colab notebook.


2) Attaching the colab file for your reference.
[modelmaker_quantize.zip](https://github.com/tensorflow/tensorflow/files/9690409/modelmaker_quantize.zip)



"
57930,AssertionError: Tried to export a function which references 'untracked' resource Tensor:tf.train.ExponentialMovingAverage,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.8.2

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I have created ResNet Network using custom layers. It runs successfully on CIFAR Dataset.
But when I try to save it i get the following error:

AssertionError: Tried to export a function which references 'untracked' resource Tensor(""103247:0"", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.

 Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):
<tf.Variable 'Variable/ExponentialMovingAverage_99:0' shape=(64,) dtype=float32>

So the problem is in my custom Layer Batch_Normalization . It seems like tf.train.ExponentialMovingAverage is not assigned.

I found this post https://stackoverflow.com/questions/69040420/assertionerror-tried-to-export-a-function-which-references-untracked-resource

But it didn't help me, because problem was different: I didn't define any class variables. What is exactly meant by ""must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly."" ? How can I fix that?
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import Layer
from tensorflow.keras import Model


class Convolution_Layer(tf.keras.layers.Layer):
    
    def __init__(self,kernel_height,kernel_width,channel_in,channel_out,stride,padding):
        super(Convolution_Layer,self).__init__()
        self.kernel_height = kernel_height
        self.kernel_width = kernel_width
        self.channel_in = channel_in
        self.channel_out = channel_out
        self.stride = stride
        self.padding = padding
        self.initializer = tf.initializers.GlorotUniform()
        
        #weights:
        self.W = tf.Variable(self.initializer(shape = (kernel_height,kernel_width,channel_in,channel_out)))
        self.b = tf.Variable(self.initializer(shape = (channel_out,)))
        
    
    def call(self,x):
        x = tf.nn.conv2d(x,self.W,strides = self.stride,padding = self.padding) + self.b
        return x
    
    
class Batch_Normalization(tf.keras.layers.Layer):
    def __init__(self,depth,decay,convolution):
        super(Batch_Normalization,self).__init__()
        self.mean = tf.Variable(tf.constant(0.0,shape = [depth]),trainable = False)
        self.var = tf.Variable(tf.constant(1.0,shape = [depth]),trainable = False)
        self.beta = tf.Variable(tf.constant(0.0,shape = [depth]))
        self.gamma = tf.Variable(tf.constant(1.0,shape = [depth]))
        #exponentiall moving average object
        self.mov_avg = tf.train.ExponentialMovingAverage(decay = decay)
        self.epsilon = 0.001
        self.convolution = convolution
        
    def call(self,x,training = True):
        
        if training:
            if self.convolution:
                batch_mean,batch_var = tf.nn.moments(x, axes=[0, 1, 2],keepdims = False)
            else:
                batch_mean,batch_var = tf.nn.moments(x, axes=[0],keepdims = False)

            as_mean = self.mean.assign(batch_mean)
            as_variance = self.var.assign(batch_var)
            #ensured argument to be evaluated before anything you define in the with block
            with tf.control_dependencies([as_mean,as_variance]):
                ma =self.mov_avg.apply([self.mean,self.var])
                x = tf.nn.batch_normalization(x = x,mean = batch_mean,variance = batch_var,offset = self.beta,scale = self.gamma,variance_epsilon = self.epsilon)
                
        else:
            mean = self.mov_avg.average(self.mean)
            var = self.mov_avg.average(self.var)
            local_beta = tf.identity(self.beta)
            local_gamma = tf.identity(self.gamma)
            x = tf.nn.batch_normalization(x,mean,var,local_beta,local_gamma,self.epsilon)
            
        return x
            


class MaxPool(tf.keras.layers.Layer):
    def __init__(self,kernel_size,strides,padding):
        super(MaxPool,self).__init__()
        self.kernel_size = kernel_size
        self.strides = strides
        self.padding = padding
        
        
    def call(self,x):
        return tf.nn.max_pool2d(x,ksize = [1,self.kernel_size,self.kernel_size,1],strides = [1,self.strides,self.strides,1],padding = self.padding)



class Dense_layer(tf.keras.layers.Layer):
    def __init__(self,dim_out):
        super(Dense_layer,self).__init__()
        self.initializer = tf.initializers.GlorotUniform()
        self.dim_out = dim_out
        
    def build(self, input_shape):
        self.W = self.add_weight(shape=(input_shape[-1], self.dim_out),initializer = self.initializer,trainable=True,name='w')
        self.b = self.add_weight(shape=(self.dim_out,), initializer = self.initializer, trainable=True,name='b')
        
    def call(self,x):
        return x @ self.W + self.b
    

class Global_Average_Pooling(tf.keras.layers.Layer):
    def __init__(self,axis):
        super(AvgPooling,self).__init__()
        self.axis = axis


    def call(self,x):
        return tf.reduce_mean(x, axis = self.axis)
    


class Flatten_layer(tf.keras.layers.Layer):
    def __init__(self):
        super(Flatten_layer,self).__init__()
        
    def call(self,x,shape = False):
        return tf.reshape(x, [x.shape[0],-1])
 


class Softmax_layer(tf.keras.layers.Layer):
    def __init__(self,dim_out):
        super(Softmax_layer,self).__init__()
        self.initializer = tf.initializers.GlorotUniform()
        self.dim_out = dim_out
        
    
    def build(self, input_shape):
        self.W = self.add_weight(shape=(input_shape[-1], self.dim_out),initializer = self.initializer,trainable=True,name='w_s')
        self.b = self.add_weight(shape=(self.dim_out,), initializer = self.initializer, trainable=True,name='b_s')
        
    def call(self,x):
        return tf.nn.softmax(tf.matmul(x,self.W) + self.b)



class AvgPooling(tf.keras.layers.Layer):
    def __init__(self,kernel_height,kernel_width,strides,padding):
        super(AvgPooling,self).__init__()
        self.kernel_height = kernel_height
        self.kernel_width = kernel_width
        self.strides = strides
        self.padding = padding
        
        
    def call(self,x):
        return tf.nn.avg_pool(input = x,ksize = [self.kernel_height,self.kernel_width],strides = self.strides,padding = self.padding)



class Dropout_layer(Layer):
    def __init__(self,rate):
        super(Dropout_layer,self).__init__()
        self.rate = rate

    def call(self,x,training = None):
        if training:
            return tf.nn.dropout(x,self.rate)
        return x
    
    
class Identity(tf.keras.layers.Layer):
    def __init__(self,filters):
        super(Identity,self).__init__()
        self.initializer = tf.initializers.GlorotUniform()
        
        #Block one
        self.conv_1 = Convolution_Layer(1,1,filters[0],filters[1],1,padding = 'VALID')
        self.batch_norm_1 = Batch_Normalization(filters[1],0.99,convolution = True)

        
        #Block two
        self.conv_2 = Convolution_Layer(3,3,filters[1],filters[2],1,padding = 'SAME')
        self.batch_norm_2 = Batch_Normalization(filters[2],0.99,convolution = True)

        #Block two
        self.conv_3 = Convolution_Layer(1,1,filters[2],filters[3],1,padding = 'VALID')
        self.batch_norm_3 = Batch_Normalization(filters[3],0.99,convolution = True)
        
        #Dimension adjustment variable:
        #self.dimension = Convolution_Layer(1,1,channel_in,channel_out,1,padding = 'valid')
        
    def call(self,x,training = None):
        #Block one
        fx = self.conv_1(x)
        fx = self.batch_norm_1(fx,training)
        fx = tf.nn.relu(fx)
        
        #Block two
        fx = self.conv_2(fx)
        fx = self.batch_norm_2(fx,training)
        fx = tf.nn.relu(fx)

        #Block three
        fx = self.conv_3(fx)
        fx = self.batch_norm_3(fx,training)

        #add input:
        #fx = tf.nn.relu(fx + self.dimension(x))
        fx = tf.nn.relu(fx + x)
        
        return fx



class Convolution_Block(tf.keras.layers.Layer):
    def __init__(self,filters,stride):
        super(Convolution_Block,self).__init__()
        self.initializer = tf.initializers.GlorotUniform()
        
        #Block one
        self.conv_1 = Convolution_Layer(1,1,filters[0],filters[1],stride,padding = 'VALID')
        self.batch_norm_1 = Batch_Normalization(filters[1],0.99,convolution = True)
        
        #Block two
        self.conv_2 = Convolution_Layer(3,3,filters[1],filters[2],1,padding = 'SAME')
        self.batch_norm_2 = Batch_Normalization(filters[2],0.99,convolution = True)

        #Block three
        self.conv_3 = Convolution_Layer(1,1,filters[2],filters[3],1,padding = 'VALID')
        self.batch_norm_3 = Batch_Normalization(filters[3],0.99,convolution = True)
        
        #Dimension adjustment variable:
        self.dimension = Convolution_Layer(1,1,filters[0],filters[3],stride,padding = 'VALID')
        
    def call(self,x,training = None):
        #Block one
        fx = self.conv_1(x)
        fx = self.batch_norm_1(fx,training)
        fx = tf.nn.relu(fx)
        
        #Block two
        fx = self.conv_2(fx)
        fx = self.batch_norm_2(fx,training)
        fx = tf.nn.relu(fx)

        #Block three
        fx = self.conv_3(fx)
        fx = self.batch_norm_3(fx,training)

        #Skip connection
        fx = tf.nn.relu(fx + self.dimension(x))
        return fx
    
class Global_Average_Pooling(tf.keras.layers.Layer):
    def __init__(self,axis):
        super(Global_Average_Pooling,self).__init__()
        self.axis = axis


    def call(self,x):
        return tf.reduce_mean(x, axis = self.axis)
    


    
class Resnet(tf.keras.Model):

    def __init__(self,num_classes = 10):
        super(Resnet,self).__init__()

        #1st stage: convolution with max pooling

        self.zero_padding = tf.keras.layers.ZeroPadding2D(padding=(3, 3))
        self.conv_1 = Convolution_Layer(kernel_height = 7,kernel_width = 7,channel_in = 3,channel_out = 64,stride = 2,padding = 'VALID')
        self.batch_norm_1 = Batch_Normalization(depth = 64,decay = 0.99,convolution = True)
        self.max_pool_1 = MaxPool(kernel_size = 3,strides = 2,padding = 'VALID')

        '''
        self.identity_layers = []
        for f in identity_blocks_filters:
            #self.identity_layers.append(Identity(kernel_height = 3,kernel_width = 3,channel_in = f[0],channel_out = f[1],stride = 1,decay = 0.99))
        '''

        #2nd stage:
        self.block_2_res_conv_1 = Convolution_Block(filters = [64,64,64,256],stride = 1)
        self.block_2_res_ident_1 = Identity(filters = [256,64,64,256])
        self.block_2_res_ident_2 = Identity(filters = [256,64,64,256])


        #3rd stage:
        self.block_3_res_conv_1 = Convolution_Block(filters = [256,128,128,512],stride = 2)
        self.block_3_res_ident_1 = Identity(filters = [512,128,128,512])
        self.block_3_res_ident_2 = Identity(filters = [512,128,128,512])
        self.block_3_res_ident_3 = Identity(filters = [512,128,128,512])

        #4th stage:
        self.block_4_res_conv_1 = Convolution_Block(filters = [512,256,256,1024],stride = 2)
        self.block_4_res_ident_1 = Identity(filters = [1024,256,256,1024])
        self.block_4_res_ident_2 = Identity([1024,256,256,1024])
        self.block_4_res_ident_3 = Identity([1024,256,256,1024])
        self.block_4_res_ident_4 = Identity([1024,256,256,1024])
        self.block_4_res_ident_5 = Identity([1024,256,256,1024])

        #5th stage:
        self.block_5_res_conv_1 = Convolution_Block(filters = [1024,512,512,2048],stride = 2)
        self.block_5_res_ident_1 = Identity(filters = [1024,512,512,2048])
        self.block_5_res_ident_2 = Identity(filters = [1024,512,512,2048])



        self.global_avg_pool = Global_Average_Pooling(axis = [1,2])
        self.avg_pool = AvgPooling(kernel_height = 2,kernel_width = 2,strides = 1,padding = 'SAME')
        self.flatten = Flatten_layer()
        self.dense_1 = Dense_layer(512)
        self.softmax = Softmax_layer(num_classes)

    def call(self,x,training = None):

        #1st stage: convolution with max pooling
        x = self.zero_padding(x)
        x = self.conv_1(x)
        x = self.batch_norm_1(x,training)
        x = tf.nn.relu(x)
        x = self.max_pool_1(x)
        

        #2nd stage: 
        '''
        for i in range(len(self.identity_layers)):
            x = self.identity_layers[i](x)
        '''
        x = self.block_2_res_conv_1(x)
        x = self.block_2_res_ident_1(x)
        x = self.block_2_res_ident_2(x)


        #3rd stage:
        x = self.block_3_res_conv_1(x)
        x = self.block_3_res_ident_1(x)
        x = self.block_3_res_ident_2(x)
        x = self.block_3_res_ident_3(x)

        #4th stage:
        x = self.block_4_res_conv_1(x)
        x = self.block_4_res_ident_1(x) 
        x = self.block_4_res_ident_2(x) 
        x = self.block_4_res_ident_3(x) 
        x = self.block_4_res_ident_4(x) 
        x = self.block_4_res_ident_5(x) 

        #5th stage:
        x = self.block_5_res_conv_1(x) 
        x = self.block_5_res_ident_1(x) 
        x = self.block_5_res_ident_2(x) 

        
        x = self.global_avg_pool(x)
        #x = self.avg_pool(x)
        #x = self.flatten(x)
        x = self.dense_1(x)
        x = tf.nn.relu(x)
        
        x = self.softmax(x)
        
        return x

# Load Cifar-10 data-set
dataset_train, dataset_eval = tf.keras.datasets.cifar10.load_data()
dataset_train = tf.data.Dataset.from_tensor_slices(dataset_train)
dataset_eval = tf.data.Dataset.from_tensor_slices(dataset_eval)


def normalize_img(image, label):
  """"""Normalizes images: `uint8` -> `float32`.""""""
  return tf.cast(image, tf.float32) / 255., label


dataset_train = dataset_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
dataset_train = dataset_train.cache()
dataset_train = dataset_train.shuffle(60000)
dataset_train = dataset_train.batch(256)
dataset_train = dataset_train.prefetch(tf.data.AUTOTUNE)

dataset_eval = dataset_eval.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
dataset_eval = dataset_eval.batch(256)
dataset_eval = dataset_eval.cache()
dataset_eval = dataset_eval.prefetch(tf.data.AUTOTUNE)



epochs = 5

#model = Resnet(len(class_names_eval))
model = Resnet(num_classes=10)

loss_object = tf.keras.losses.SparseCategoricalCrossentropy()#used in backprop


num_train_steps = len(dataset_train) * epochs

optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3)

train_loss = tf.keras.metrics.Mean(name='train_loss')#mean of the losses per observation
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')

test_loss = tf.keras.metrics.Mean(name='test_loss')
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')


@tf.function
def training(X,y):
    with tf.GradientTape() as tape:#Trainable variables (created by tf.Variable or tf.compat.v1.get_variable, where trainable=True is default in both cases) are automatically watched. 
        predictions = model(X,training = True)
        loss = loss_object(y,predictions)

    gradients = tape.gradient(loss,model.trainable_variables)
    optimizer.apply_gradients(zip(gradients,model.trainable_variables))
    train_loss(loss) 
    train_accuracy(y,predictions)



@tf.function
def testing(X,y):
    predictions = model(X,training = False)
    loss = loss_object(y,predictions)
    test_loss(loss)
    test_accuracy(y,predictions)





for epoch in range(epochs):
    for X,y in dataset_train:
        training(X,y)

    for X,y in dataset_eval:
        testing(X,y)

    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
    print(template.format(epoch+1,
                        train_loss.result(),
                        train_accuracy.result()*100,
                        test_loss.result(),
                        test_accuracy.result()*100))



  # Reset the metrics for the next epoch
    train_loss.reset_states()
    train_accuracy.reset_states()
    test_loss.reset_states()
    
    test_accuracy.reset_states()


tf.saved_model.save(model, '/content/model')
```


### Relevant log output

_No response_</details>"
57928,Broken `tensorflow/compiler/xla/mlir_hlo/CMakeLists.txt` after `stablehlo` move out of `mlir_hlo`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.11.0 (commit 4247ad4d497157eeb526e6aeeb5ecd15503955aa)

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04.3 

### Mobile device

_No response_

### Python version

3.8

### Bazel version

not using bazel

### GCC/Compiler version

10.0

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
The `tensorflow/compiler/xla/mlir_hlo/CMakeLists.txt` includes the `stablehlo` subdirectory and various includes from it, assuming it's local. Needs to be updated to reflect the move out `stablehlo` out of the `mlir_hlo` subtree.
```


### Standalone code to reproduce the issue

```shell
Building with cmake as part of llvm (this worked fine prior to the `stablehlo` move):

cmake -G Ninja ../llvm \
		-DLLVM_ENABLE_PROJECTS=mlir \
		-DLLVM_EXTERNAL_PROJECTS=""mlir-hlo"" \
		-DLLVM_EXTERNAL_MLIR_HLO_SOURCE_DIR=/path/to/tensorflow/tensorflow/compiler/xla/mlir_hlo \
		-DCMAKE_BUILD_TYPE=RelWithDebInfo \
		-DLLVM_ENABLE_ASSERTIONS=ON \
		-DLLVM_TARGETS_TO_BUILD=""RISCV;X86"" \
		-DMLIR_ENABLE_BINDINGS_PYTHON=ON \
		-DMHLO_ENABLE_BINDINGS_PYTHON=ON 
```
```


### Relevant log output

```shell
Using cmake to build `mlir-hlo` following the README:

CMake Error at <mypath>/tensorflow/tensorflow/compiler/xla/mlir_hlo/CMakeLists.txt:165 (add_subdirectory):
  add_subdirectory given source ""stablehlo"" which is not an existing
  directory.
```
```
</details>"
57926,Markdown Failure for TF Dialect Documentation,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

N/A

### Custom Code

No

### OS Platform and Distribution

N/A

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The bottom part of this documentation is completely a mess now. Looks like a Markdown failure. Link: https://www.tensorflow.org/mlir/tf_ops
```
The syntax error is somewhere in the tf.TensorArrayConcatV3 (::mlir::TF::TensorArrayConcatV3Op) op

### Standalone code to reproduce the issue

```shell
- Open your Chrome.
- https://www.tensorflow.org/mlir/tf_ops 
- Scroll to the very bottom
```


### Relevant log output

_No response_</details>"
57924,random.set_seed() does not work on tensorflow-macos,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

MacOS 13.0 Ventura Beta 7

### Mobile device

_No response_

### Python version

3.9.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

M1 Metal

### Current Behaviour?

```shell
using tf.random.set_seed works perfectly on google colab environment, yet using tensorflow-macos version, it does not seem to work at all. It's not giving me an error either. Everytime I run my code, I get different results.

Code I gave as an example uses numpy but even using data imported from pandas as DataFrames do not work. Which work on google colab.

My miniconda installation and python installation is all fresh. I was using python version 3.10 but the apple website does not mention that, so uninstalled miniconda and reinstalled it using an older version, effectively downgrading python, but that did not fix the problem either.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])
y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])

tf.random.set_seed(42)

model = tf.keras.Sequential([
  tf.keras.layers.Dense(1)
])

model.compile(loss=tf.keras.losses.mae,
              optimizer=tf.keras.optimizers.SGD(),
              metrics=[""mae""])

model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)
```


### Relevant log output

**First Time:**

Epoch 1/5
2022-09-30 18:25:08.200023: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
1/1 [==============================] - 1s 583ms/step - loss: 15.3376 - mae: 15.3376
Epoch 2/5
1/1 [==============================] - 0s 18ms/step - loss: 15.0563 - mae: 15.0563
Epoch 3/5
1/1 [==============================] - 0s 21ms/step - loss: 14.8426 - mae: 14.8426
Epoch 4/5
1/1 [==============================] - 0s 17ms/step - loss: 14.7101 - mae: 14.7101
Epoch 5/5
1/1 [==============================] - 0s 38ms/step - loss: 14.5776 - mae: 14.5776
<keras.callbacks.History at 0x2a0960730>

**Second Time**

Epoch 1/5
1/1 [==============================] - 0s 222ms/step - loss: 11.3347 - mae: 11.3347
Epoch 2/5
1/1 [==============================] - 0s 10ms/step - loss: 11.2022 - mae: 11.2022
Epoch 3/5
1/1 [==============================] - 0s 15ms/step - loss: 11.0697 - mae: 11.0697
Epoch 4/5
1/1 [==============================] - 0s 16ms/step - loss: 10.9372 - mae: 10.9372
Epoch 5/5
1/1 [==============================] - 0s 19ms/step - loss: 10.8047 - mae: 10.8047
2022-09-30 18:28:03.323935: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.
<keras.callbacks.History at 0x2a09f6c40>"
57923,XLA compile enable an option to not fail fast,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

When a `tf.function` is jit compiled with XLA the graph validation is failing fast so we don't have the full overview of the invalid/uncovered node.


### Standalone code to reproduce the issue

https://github.com/tensorflow/tensorflow/blob/02d5a7dcd0d7ad12b040c465f96d7a91e6b162f1/tensorflow/compiler/tf2xla/xla_compiler.cc#L1277-L1297


### Relevant log output

_No response_</details>

/cc @paynecl"
57922,Don't show correct formula ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!

Definition:
$$ \mathcal{L}({y}, {s}) =

\sum_i y_i \cdot \log\left(\frac{exp(s_i)}{\sum_j exp(s_j)}\right) $$

https://www.tensorflow.org/ranking/api_docs/python/tfr/keras/losses/SoftmaxLoss
```


### Standalone code to reproduce the issue

```shell
A bug happened!

Definition:
$$ \mathcal{L}({y}, {s}) =

\sum_i y_i \cdot \log\left(\frac{exp(s_i)}{\sum_j exp(s_j)}\right) $$

https://www.tensorflow.org/ranking/api_docs/python/tfr/keras/losses/SoftmaxLoss
```


### Relevant log output

_No response_</details>"
57921,Template code does not work,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

colab

### Mobile device

colab

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/keras/landingpage_example.ipynb

https://www.tensorflow.org/ranking
```


### Standalone code to reproduce the issue

```shell
A bug happened!
https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/keras/landingpage_example.ipynb

https://www.tensorflow.org/ranking
```


### Relevant log output

```shell
Input 0 of layer ""batch_normalization"" is incompatible with the layer: expected axis 2 of input shape to have value 1, but received input with shape (None, None, 136)
    
    Call arguments received by layer ""model"" ""                 f""(type Functional):
      • inputs={'_mask': 'tf.Tensor(shape=(None, None), dtype=bool)', 'float_features': 'tf.Tensor(shape=(None, None, 136), dtype=float64)'}
      • training=True
      • mask=None
```
</details>"
57920,TF board does not show keras metrics. ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.10.1

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I use ""self.add_metric(some value)"" in customized keras layers and call these layers in customized train_step, but metrics do not appear on TF board. 

Actually, I remember it works in some old versions like 1.x or 2.1.
```


### Standalone code to reproduce the issue

```shell
class some_customized_keras_layers(tf.keras.layers.Layer):
    def call():
         self.add_metric(some value)
```


### Relevant log output

_No response_</details>"
57919,How do I specify the device of an operator when I load the model using the C API?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How do I specify the device of an operator when I load the model using the C API?
If I have an operator, especially a custom operator, that has both GPU and CPU versions, how do I specify which device it should run on?
I know it's easy to use tf.device, but I'm using the C API loaded SavedModel for model reasoning, so I can't call the Python API.
```


### Standalone code to reproduce the issue

```shell
Using C API load any savedmodel.
```


### Relevant log output

_No response_</details>"
57918,Unit test float8_test fails to build on AARCH64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

5.3.0

### GCC/Compiler version

10.3.0

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/core/framework:float8_test fails to build on aarch64
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=2 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --build_tests_only -- //tensorflow/core/framework:float8_test
```


### Relevant log output

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=2 --test_output=all --cache_test_results=no --config=nonccl --config=mkl_aarch64_threadpool --copt=-mtune=generic --copt=-march=armv8-a --copt=-O3 --test_env=TF_ENABLE_ONEDNN_OPTS=1 --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --build_tests_only -- //tensorflow/core/framework:float8_test
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=162
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 --action_env PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages --python_path=/home/builder/1/tensorflow_build/venv_py38/bin/python3
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium
INFO: Found applicable config definition build:short_logs in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition test:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
INFO: Found applicable config definition build:nonccl in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:mkl_aarch64_threadpool in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=build_with_mkl_aarch64=true -c opt
INFO: Found applicable config definition build:linux in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --host_copt=-w --copt=-Wno-all --copt=-Wno-extra --copt=-Wno-deprecated --copt=-Wno-deprecated-declarations --copt=-Wno-ignored-attributes --copt=-Wno-unknown-warning --copt=-Wno-array-parameter --copt=-Wno-stringop-overflow --copt=-Wno-array-bounds --copt=-Wunused-result --copt=-Werror=unused-result --copt=-Wswitch --copt=-Werror=switch --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/core/framework:float8_test (1 packages loaded, 1405 targets configured).
INFO: Found 1 test target...
ERROR: /home/builder/1/tensorflow_build/tensorflow-git/tensorflow/core/framework/BUILD:631:11: Compiling tensorflow/core/framework/float8.cc failed: (Exit 1): gcc failed: error executing command 
  (cd /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/lib64:/usr/local/lib \
    PATH=/home/builder/.cache/bazelisk/downloads/bazelbuild/bazel-5.3.0-linux-arm64/bin:/home/builder/1/tensorflow_build/venv_py38/bin:/home/builder/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 \
    PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /usr/local/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/aarch64-opt/bin/tensorflow/core/framework/_objs/float8/float8.pic.d '-frandom-seed=bazel-out/aarch64-opt/bin/tensorflow/core/framework/_objs/float8/float8.pic.o' -fPIC -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -iquote . -iquote bazel-out/aarch64-opt/bin -iquote external/eigen_archive -iquote bazel-out/aarch64-opt/bin/external/eigen_archive -isystem third_party/eigen3/mkl_include -isystem bazel-out/aarch64-opt/bin/third_party/eigen3/mkl_include -isystem external/eigen_archive -isystem bazel-out/aarch64-opt/bin/external/eigen_archive -Wno-all -Wno-extra -Wno-deprecated -Wno-deprecated-declarations -Wno-ignored-attributes -Wno-unknown-warning -Wno-array-parameter -Wno-stringop-overflow -Wno-array-bounds -Wunused-result '-Werror=unused-result' -Wswitch '-Werror=switch' -DAUTOLOAD_DYNAMIC_KERNELS '-mtune=generic' '-march=armv8-a' -O3 '-std=c++17' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/framework/float8.cc -o bazel-out/aarch64-opt/bin/tensorflow/core/framework/_objs/float8/float8.pic.o)
# Configuration: a8b71e5d0520f76083588e67158baf434d2d7485ee1864295a297beef7093c66
# Execution platform: @local_execution_config_platform//:platform
In file included from external/eigen_archive/Eigen/Core:170,
                 from ./third_party/eigen3/Eigen/Core:1,
                 from ./tensorflow/core/framework/float8.h:24,
                 from tensorflow/core/framework/float8.cc:16:
external/eigen_archive/Eigen/src/Core/MathFunctions.h: In instantiation of 'std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> Eigen::internal::isinf_impl(const T&) [with T = tensorflow::float8_internal::float8_e4m3; std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> = bool]':
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1433:97:   required from 'bool Eigen::numext::isinf(const T&) [with T = tensorflow::float8_internal::float8_e4m3]'
tensorflow/core/framework/float8.cc:110:29:   required from 'static To tensorflow::float8_internal::{anonymous}::ConvertImpl<From, To, kSaturate, kTruncate, typename std::enable_if<(is_base_of_v<tensorflow::float8_internal::float8_base<From>, From> && (sizeof (From) < sizeof (To))), void>::type>::run(const From&) [with From = tensorflow::float8_internal::float8_e4m3; To = double; bool kSaturate = false; bool kTruncate = false]'
tensorflow/core/framework/float8.cc:415:61:   required from 'static To tensorflow::float8_internal::float8_base<Derived>::ConvertTo(const Derived&) [with To = double; bool kSaturate = false; bool kTruncate = false; Derived = tensorflow::float8_internal::float8_e4m3]'
./tensorflow/core/framework/float8.h:94:68:   required from here
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: error: no match for 'operator>' (operand types are 'const tensorflow::float8_internal::float8_e4m3' and 'tensorflow::float8_internal::float8_e4m3')
 1061 |     return x>NumTraits<T>::highest() || x<NumTraits<T>::lowest();
      |            ~^~~~~~~~~~~~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(float, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(float, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(double, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(double, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: error: no match for 'operator<' (operand types are 'const tensorflow::float8_internal::float8_e4m3' and 'tensorflow::float8_internal::float8_e4m3')
 1061 |     return x>NumTraits<T>::highest() || x<NumTraits<T>::lowest();
      |                                         ~^~~~~~~~~~~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(float, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(float, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(double, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(double, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e4m3' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h: In instantiation of 'std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> Eigen::internal::isnan_impl(const T&) [with T = tensorflow::float8_internal::float8_e4m3; std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> = bool]':
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1432:97:   required from 'bool Eigen::numext::isnan(const T&) [with T = tensorflow::float8_internal::float8_e4m3]'
tensorflow/core/framework/float8.cc:110:59:   required from 'static To tensorflow::float8_internal::{anonymous}::ConvertImpl<From, To, kSaturate, kTruncate, typename std::enable_if<(is_base_of_v<tensorflow::float8_internal::float8_base<From>, From> && (sizeof (From) < sizeof (To))), void>::type>::run(const From&) [with From = tensorflow::float8_internal::float8_e4m3; To = double; bool kSaturate = false; bool kTruncate = false]'
tensorflow/core/framework/float8.cc:415:61:   required from 'static To tensorflow::float8_internal::float8_base<Derived>::ConvertTo(const Derived&) [with To = double; bool kSaturate = false; bool kTruncate = false; Derived = tensorflow::float8_internal::float8_e4m3]'
./tensorflow/core/framework/float8.h:94:68:   required from here
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: error: no match for 'operator!=' (operand types are 'const tensorflow::float8_internal::float8_e4m3' and 'const tensorflow::float8_internal::float8_e4m3')
 1076 |     return x != x;
      |            ~~^~~~
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(float, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e4m3' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(float, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e4m3' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(double, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e4m3' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(double, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e4m3' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h: In instantiation of 'std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> Eigen::internal::isinf_impl(const T&) [with T = tensorflow::float8_internal::float8_e5m2; std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> = bool]':
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1433:97:   required from 'bool Eigen::numext::isinf(const T&) [with T = tensorflow::float8_internal::float8_e5m2]'
tensorflow/core/framework/float8.cc:110:29:   required from 'static To tensorflow::float8_internal::{anonymous}::ConvertImpl<From, To, kSaturate, kTruncate, typename std::enable_if<(is_base_of_v<tensorflow::float8_internal::float8_base<From>, From> && (sizeof (From) < sizeof (To))), void>::type>::run(const From&) [with From = tensorflow::float8_internal::float8_e5m2; To = double; bool kSaturate = false; bool kTruncate = false]'
tensorflow/core/framework/float8.cc:415:61:   required from 'static To tensorflow::float8_internal::float8_base<Derived>::ConvertTo(const Derived&) [with To = double; bool kSaturate = false; bool kTruncate = false; Derived = tensorflow::float8_internal::float8_e5m2]'
./tensorflow/core/framework/float8.h:124:68:   required from here
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: error: no match for 'operator>' (operand types are 'const tensorflow::float8_internal::float8_e5m2' and 'tensorflow::float8_internal::float8_e5m2')
 1061 |     return x>NumTraits<T>::highest() || x<NumTraits<T>::lowest();
      |            ~^~~~~~~~~~~~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(float, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(float, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(double, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note: candidate: 'operator>(double, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:13: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: error: no match for 'operator<' (operand types are 'const tensorflow::float8_internal::float8_e5m2' and 'tensorflow::float8_internal::float8_e5m2')
 1061 |     return x>NumTraits<T>::highest() || x<NumTraits<T>::lowest();
      |                                         ~^~~~~~~~~~~~~~~~~~~~~~~
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(float, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(float, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(double, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note: candidate: 'operator<(double, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1061:42: note:   no known conversion for argument 2 from 'tensorflow::float8_internal::float8_e5m2' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h: In instantiation of 'std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> Eigen::internal::isnan_impl(const T&) [with T = tensorflow::float8_internal::float8_e5m2; std::enable_if_t<((! std::is_integral<_Tp>::value) && (! Eigen::NumTraits<T>::IsComplex)), bool> = bool]':
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1432:97:   required from 'bool Eigen::numext::isnan(const T&) [with T = tensorflow::float8_internal::float8_e5m2]'
tensorflow/core/framework/float8.cc:110:59:   required from 'static To tensorflow::float8_internal::{anonymous}::ConvertImpl<From, To, kSaturate, kTruncate, typename std::enable_if<(is_base_of_v<tensorflow::float8_internal::float8_base<From>, From> && (sizeof (From) < sizeof (To))), void>::type>::run(const From&) [with From = tensorflow::float8_internal::float8_e5m2; To = double; bool kSaturate = false; bool kTruncate = false]'
tensorflow/core/framework/float8.cc:415:61:   required from 'static To tensorflow::float8_internal::float8_base<Derived>::ConvertTo(const Derived&) [with To = double; bool kSaturate = false; bool kTruncate = false; Derived = tensorflow::float8_internal::float8_e5m2]'
./tensorflow/core/framework/float8.h:124:68:   required from here
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: error: no match for 'operator!=' (operand types are 'const tensorflow::float8_internal::float8_e5m2' and 'const tensorflow::float8_internal::float8_e5m2')
 1076 |     return x != x;
      |            ~~^~~~
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(float, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e5m2' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(float, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e5m2' to 'double'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(double, float)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e5m2' to 'float'
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note: candidate: 'operator!=(double, double)' (built-in)
external/eigen_archive/Eigen/src/Core/MathFunctions.h:1076:14: note:   no known conversion for argument 2 from 'const tensorflow::float8_internal::float8_e5m2' to 'double'
cc1plus: note: unrecognized command-line option '-Wno-array-parameter' may have been intended to silence earlier diagnostics
cc1plus: note: unrecognized command-line option '-Wno-unknown-warning' may have been intended to silence earlier diagnostics
Target //tensorflow/core/framework:float8_test failed to build
INFO: Elapsed time: 5.381s, Critical Path: 4.31s
INFO: 70 processes: 63 internal, 7 local.
FAILED: Build did NOT complete successfully
//tensorflow/core/framework:float8_test                         FAILED TO BUILD

FAILED: Build did NOT complete successfully
```
</details>"
57917,Information gets lost when saving and loading a model,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: pip
-   **TensorFlow version (use command below)**: v2.7.0-rc1-69-gc256c071bb2 2.7.0
-   **Python version**: Python 3.8.10
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

### Describe the problem
I create a keras model, train it, then save it. Documentation says that I can load the model and resume training right where I left off. That is not the case for me. My training loss always increases sharply on resuming training. Therefore I suspect that somewhere information about some state is lost.

### Source code / logs
I am training a model for few epochs, then save it. Now I expect training the same model another epochs gives the exact same results as loading the saved model and training another epoch there. I added some RNG seeding and other stuff to make training deterministic.
Here is a modified version of the keras MNIST example code that reproduces the behavior:

```python
#try making training deterministic

import os
os.environ[""CUDA_VISIBLE_DEVICES""] = """"
seed_value= 123
os.environ['PYTHONHASHSEED']=str(seed_value)
import random
import numpy as np
import tensorflow as tf
tf.config.threading.set_intra_op_parallelism_threads(1)
tf.config.threading.set_inter_op_parallelism_threads(1)

def seed():
    random.seed(seed_value)
    np.random.seed(seed_value)
    tf.random.set_seed(seed_value)
seed()

# taken from MNIST example code (https://github.com/keras-team/keras-io/blob/master/examples/vision/mnist_convnet.py)

from tensorflow import keras
from tensorflow.keras import layers

""""""
## Prepare the data
""""""

# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# Load the data and split it between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

""""""
## Build the model
""""""

model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation=""relu""),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(3, 3), activation=""relu""),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()

""""""
## Train the model
""""""

batch_size = 128

model.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""])

model.fit(x_train, y_train, batch_size=batch_size, epochs=5)
model.save('model')
print('these two runs should be identical')
seed()
model.fit(x_train, y_train, batch_size=batch_size, epochs=1)
reloaded_model = keras.models.load_model('model')
seed()
reloaded_model.fit(x_train, y_train, batch_size=batch_size, epochs=1)
```
Which outputs on my machine:
```
...
these two runs should be identical
469/469 [==============================] - 33s 71ms/step - loss: 0.0509 - accuracy: 0.9842
469/469 [==============================] - 33s 69ms/step - loss: 0.0522 - accuracy: 0.9837
```"
57916,How to hide: failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.10.0

### Custom Code

No

### OS Platform and Distribution

3.10.0-1160.71.1.el7.x86_64

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I do not have a GPU and TF is showing me:

failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected

how do I hide this message?
```


### Standalone code to reproduce the issue

```shell
It's not a issue with the code, I cannot give you anything standalone.
```


### Relevant log output

_No response_</details>"
57914,Unable to build tensorflow from source on Apple M1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

macOS 12.6

### Mobile device

None

### Python version

3.9

### Bazel version

5.1.1-homebrew

### GCC/Compiler version

Apple clang version 14.0.0 (clang-1400.0.29.102)

### CUDA/cuDNN version

None

### GPU model and memory

None

### Current Behaviour?

I need to use `tensorflow-text`, because `tensorflow` does not provide pre-compiled packages for Apple silicon, `text` compiled by `tensorflow-macos` has a symbol error, so now I need to compile `tensorflow` myself, and then go to compile `text`. I'm a newbie to `bazel`, and this is my first time compiling `tensorflow`, I have tried reinstalling `Xcode` and using `conda` and `virtualenv` virtual environments respectively, but all have this error.


### Standalone code to reproduce the issue

Default settings used for all options.
```shell
 bazel build //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /Users/sunruiqi/Desktop/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/sunruiqi/Desktop/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=false
INFO: Reading rc options for 'build' from /Users/sunruiqi/Desktop/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Users/sunruiqi/tf/bin/python3 --action_env PYTHON_LIB_PATH=/Users/sunruiqi/tf/lib/python3.9/site-packages --python_path=/Users/sunruiqi/tf/bin/python3
INFO: Reading rc options for 'build' from /Users/sunruiqi/Desktop/tensorflow/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /Users/sunruiqi/Desktop/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/sunruiqi/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:macos in file /Users/sunruiqi/Desktop/tensorflow/.bazelrc: --apple_platform_type=macos --copt=-DGRPC_BAZEL_BUILD --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++17 --host_cxxopt=-std=c++17
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (1 packages loaded, 4 targets configured).
INFO: Found 1 target...
ERROR: /Users/sunruiqi/Desktop/tensorflow/tensorflow/python/profiler/internal/BUILD:80:27: Linking tensorflow/python/profiler/internal/_pywrap_traceme.so failed: (Aborted): cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh @bazel-out/darwin_arm64-opt/bin/tensorflow/python/profiler/internal/_pywrap_traceme.so-2.params
ld: malformed trie, childNodeOffset==0 file 'bazel-out/darwin_arm64-opt/bin/_solib_darwin_arm64/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal_Umacos___Utensorflow_Spython/lib_pywrap_tensorflow_internal.dylib'
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Error in child process '/usr/bin/xcrun'. 1
external/local_config_cc/cc_wrapper.sh: line 69:  2048 Abort trap: 6           ""$(/usr/bin/dirname ""$0"")""/wrapped_clang ""$@""
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2939.365s, Critical Path: 233.21s
INFO: 13427 processes: 141 internal, 13286 local.
FAILED: Build did NOT complete successfully
```
</details>"
57913,pre-trained yolov5s quantized: inference time is very high,"### 1. System information

- Colab environment
- Quantization of pre-trained yolov5s weights
- Successfully generated tflite files with,
     - No quantization
     - Floating Point 16 quantization
     - Dynamic range quantization (no representative_dataset option)
- Inference time using weights from dynamic range quantization is extremely high


### 2. Code

file_path = './yolov5s_saved_model'
tf_lite_converter = tf.lite.TFLiteConverter.from_saved_model(file_path, signature_keys=['serving_default'])

tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = tf_lite_converter.convert()

TF_LITE_MODEL_FILE_NAME = ""dynamic1.tflite""

with tf.io.gfile.GFile(TF_LITE_MODEL_FILE_NAME, 'wb') as f:
  f.write(tflite_model)



#### Option A: attachments for reference

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/drive/12t4TOjMvWnFDyRi9A2xhXtg_b_ITamXn#scrollTo=EukHdiAM-Mt9)

2) Attaching the colab file for your reference.
[yolov5_quantize.zip](https://github.com/tensorflow/tensorflow/files/9671818/yolov5_quantize.zip)

3) Attaching the yolov5s weights used for conversion
[yolov5s.pt.zip](https://github.com/tensorflow/tensorflow/files/9672062/yolov5s.pt.zip)

4) Attaching a spreadsheet that shows inference time for noquant, fp16-quant, dynamic range quant (no representative_dataset option) for comparison.
[perf.xlsx](https://github.com/tensorflow/tensorflow/files/9679762/perf.xlsx)


### 3. Execution Log

NO errors. Please observe the inference time taken for each image.
For image 1/13,
- with fp16 quantization, inference time is 382.1ms
- with dynamic range quantization, inference time is 21853.0ms

This is true for CPU and GPU-enabled options.


FP16 quantization
detect: weights=['fp16.tflite'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v6.2-178-g799e3d0 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)

Loading fp16.tflite for TensorFlow Lite inference...
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
image 1/13 /content/gdrive/MyDrive/yolov5/data/images/NYstreet.jpg: 640x640 2 persons, 4 cars, 1 motorcycle, 382.1ms
image 2/13 /content/gdrive/MyDrive/yolov5/data/images/NYstreet2.jpg: 640x640 3 persons, 6 cars, 292.1ms
image 3/13 /content/gdrive/MyDrive/yolov5/data/images/bus.jpg: 640x640 4 persons, 1 bus, 289.5ms
image 4/13 /content/gdrive/MyDrive/yolov5/data/images/fruits.png: 640x640 6 apples, 6 oranges, 289.7ms
image 5/13 /content/gdrive/MyDrive/yolov5/data/images/market.jpg: 640x640 3 persons, 1 handbag, 1 bowl, 1 banana, 1 dining table, 291.2ms
image 6/13 /content/gdrive/MyDrive/yolov5/data/images/market2.jpg: 640x640 7 persons, 3 handbags, 1 banana, 293.9ms
image 7/13 /content/gdrive/MyDrive/yolov5/data/images/scene1.png: 640x640 1 person, 1 car, 1 dog, 1 skateboard, 292.1ms
image 8/13 /content/gdrive/MyDrive/yolov5/data/images/scene2.jpg: 640x640 6 persons, 4 dogs, 1 handbag, 1 frisbee, 290.8ms
image 9/13 /content/gdrive/MyDrive/yolov5/data/images/scene3.jpg: 640x640 12 persons, 1 sports ball, 297.7ms
image 10/13 /content/gdrive/MyDrive/yolov5/data/images/tennis.jpg: 640x640 2 persons, 1 sports ball, 1 tennis racket, 289.6ms
image 11/13 /content/gdrive/MyDrive/yolov5/data/images/zidane.jpg: 640x640 2 persons, 2 ties, 287.2ms
image 12/13 /content/gdrive/MyDrive/yolov5/data/images/zoo1.jpg: 640x640 1 person, 1 bench, 1 elephant, 301.1ms
image 13/13 /content/gdrive/MyDrive/yolov5/data/images/zoo2.jpg: 640x640 4 persons, 1 giraffe, 288.4ms
Speed: 169.8ms pre-process, 298.9ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)





Dynamic range quantization
detect: weights=['dynamic1.tflite'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v6.2-178-g799e3d0 Python-3.7.14 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)

Loading dynamic1.tflite for TensorFlow Lite inference...
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
image 1/13 /content/gdrive/MyDrive/yolov5/data/images/NYstreet.jpg: 640x640 2 persons, 4 cars, 1 motorcycle, 21853.0ms
image 2/13 /content/gdrive/MyDrive/yolov5/data/images/NYstreet2.jpg: 640x640 3 persons, 7 cars, 21944.4ms
image 3/13 /content/gdrive/MyDrive/yolov5/data/images/bus.jpg: 640x640 4 persons, 1 bus, 21801.1ms
image 4/13 /content/gdrive/MyDrive/yolov5/data/images/fruits.png: 640x640 6 apples, 5 oranges, 21895.5ms
image 5/13 /content/gdrive/MyDrive/yolov5/data/images/market.jpg: 640x640 3 persons, 1 handbag, 1 banana, 1 dining table, 22131.7ms
image 6/13 /content/gdrive/MyDrive/yolov5/data/images/market2.jpg: 640x640 7 persons, 3 handbags, 1 banana, 22004.5ms
image 7/13 /content/gdrive/MyDrive/yolov5/data/images/scene1.png: 640x640 1 person, 1 car, 1 dog, 1 skateboard, 21858.2ms
image 8/13 /content/gdrive/MyDrive/yolov5/data/images/scene2.jpg: 640x640 6 persons, 4 dogs, 1 handbag, 1 frisbee, 21810.9ms
image 9/13 /content/gdrive/MyDrive/yolov5/data/images/scene3.jpg: 640x640 12 persons, 1 sports ball, 21925.1ms
image 10/13 /content/gdrive/MyDrive/yolov5/data/images/tennis.jpg: 640x640 2 persons, 1 sports ball, 1 tennis racket, 21963.1ms
image 11/13 /content/gdrive/MyDrive/yolov5/data/images/zidane.jpg: 640x640 2 persons, 1 tie, 21960.4ms
image 12/13 /content/gdrive/MyDrive/yolov5/data/images/zoo1.jpg: 640x640 1 person, 1 bench, 1 elephant, 21673.8ms
image 13/13 /content/gdrive/MyDrive/yolov5/data/images/zoo2.jpg: 640x640 4 persons, 1 giraffe, 21861.5ms
Speed: 165.6ms pre-process, 21898.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 640)

"
57915,MoveNet Multipose lightning model cannot be converted to tflite int8 format,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow.js): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11 with WSL2
- TensorFlow.js installed from (npm or script link): pip
- TensorFlow.js version (use command below): 2.10.0
- Browser version: N/A
- Tensorflow.js Converter Version: Not sure how to get this



**Describe the current behavior**
I am using a python script to convert the [MoveNet **multipose** lightning model](https://tfhub.dev/google/movenet/multipose/lightning/1) to a tflite int8 format.

I am getting this error message:
```
Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select
TF Select ops: StridedSlice
```

I have tried many solutions (including the one linked in the error), but I am still unable to compile the MoveNet model.

**Describe the expected behavior**
The MoveNet model should compile to a tflite int8 format.


**Standalone code to reproduce the issue**

```py
import tensorflow as tf
import numpy as np


def representative_dataset():
  for _ in range(100):
  #data = random.randint(0, 1)
  #yield [data]
    data = np.random.rand(32)*2
    yield [data.astype(np.float32)]

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model('./movenet_multipose_lightning_1') # path to the SavedModel directory
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS_INT8
]
converter.target_spec.supported_types = [tf.int8]
converter.inference_input_type = tf.int8 # or tf.uint8 
converter.inference_output_type = tf.int8 # or tf.uint8 
converter.experimental_new_converter = True
converter.experimental_new_quantizer = False

tflite_model = converter.convert()

# Save the model.
with open('model_converted.tflite', 'wb') as f:
  f.write(tflite_model)
```
"
57910,Function to disable tf.data debug mode,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.10

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Currently you can enable tf.data debug mode using: `tf.data.experimental.enable_debug_mode`.

However there is no option to disable it after it has been set.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

dataset = tf.data.Dataset.from_tensors([2.])

tf.data.experimental.enable_debug_mode()
# All datasets defined after this point will be in debug mode.
```


### Relevant log output

_No response_</details>"
57907,Missing ops on using movenet/singlepose/lightning model ,"**System information**
- Linux (armv7l) with Mali G31 GPU
- TensorFlow installed from (source or binary): Source
- TensorFlow version (or github SHA if from source): 2.6.0

Following is the output on trying to run the movenet singlpose lightning model (FP16 - taken from TFHub) on the device:
```
ERROR: Following operations are not supported by GPU delegate: 
ARG_MAX: Operation is not supported. 
CAST: Not supported cast case
CONCATENATION: OP is supported, but tensor type/shape doesn't supported. 
DEQUANTIZE: 
FLOOR_DIV: OP is supported, but tensor type/shape doesn't supported. 
GATHER_ND: Operation is not supported. 
MUL: OP is supported, but tensor type/shape doesn't supported. 
PACK: OP is supported, but tensor type/shape doesn't supported. 
RESHAPE: OP is supported, but tensor type/shape doesn't supported. 
SUB: OP is supported, but tensor type/shape doesn't supported. 
UNPACK: Operation is not supported. 

97 operations will run on the GPU, and the remaining 200 operations will run on the CPU.
```

On trying to run FP32 model available from TF Hub, following is observed:
```
ERROR: Following operations are not supported by GPU delegate: 

ARG_MAX: Operation is not supported. 
CAST: Not supported cast case 
FLOOR_DIV: OP is supported, but tensor type/shape doesn't supported. 
GATHER_ND: Operation is not supported. 
MUL: OP is supported, but tensor type/shape doesn't supported. 
PACK: OP is supported, but tensor type/shape doesn't supported. 
RESHAPE: OP is supported, but tensor type/shape doesn't supported. 
SUB: OP is supported, but tensor type/shape doesn't supported. 
UNPACK: Operation is not supported. 

97 operations will run on the GPU, and the remaining 45 operations will run on the CPU.
```

**Standalone code to reproduce the issue** 
    Used `TfLiteGpuDelegateCreate `to create TF lite OpenGL delegate with default options and the model is built with `FlatBufferModel::BuildFromFile`.

 Able to run the model though there are missing ops. The model runs slower with single digit FPS. 
1. Could you please confirm if the aforementioned ops are not supported by TF lite?
2. Is it due to the use of OpenGL and/or Mali GPU, or it is unavailable for all backend/platforms?
3. In case if custom ops are to be implemented, are there any references (code segment/doc) you can suggest which implements ops using GPU with OpenGL backend?"
57906,Tensorflow Lite does not support tf.math.rsqrt() operation conversion.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64bit
- TensorFlow installed from (source or binary): Python 3.8.2, pip: 22.1, pip package
- TensorFlow version (or github SHA if from source): TF version:'2.9.0'


**Provide the text output from tflite_convert**

```
# Copy and paste here
2022-09-29 14:49:40.084984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-29 14:49:40.575045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2807 MB memory:  -> device: 0, name: NVIDIA GeForce MX230, pci bus id: 0000:01:00.0, compute capability: 6.1
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
C:\Python38\lib\site-packages\tensorflow\lite\python\convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(""Statistics for quantized inputs were expected, but not ""
2022-09-29 14:49:40.988706: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.
2022-09-29 14:49:40.989008: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.
2022-09-29 14:49:40.990306: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: C:\Users\DELL\AppData\Local\Temp\tmpv6cmtx6m
2022-09-29 14:49:40.993266: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }
2022-09-29 14:49:40.993545: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: C:\Users\DELL\AppData\Local\Temp\tmpv6cmtx6m
2022-09-29 14:49:40.997743: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
2022-09-29 14:49:40.998221: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2022-09-29 14:49:41.024607: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: C:\Users\DELL\AppData\Local\Temp\tmpv6cmtx6m
2022-09-29 14:49:41.030886: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 40573 microseconds.
2022-09-29 14:49:41.037367: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-09-29 14:49:41.053320: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1972] Estimated count of arithmetic ops: 0  ops, equivalently 0  MACs

Estimated count of arithmetic ops: 0  ops, equivalently 0  MACs
fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9
error: illegal scale: INF
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

# code:
```
import tensorflow as tf
import numpy as np
import pathlib

def make_model():
    data = tf.constant(np.arange(60000).reshape(200,10,10,3) /60000, dtype=tf.float32)
    input_var=tf.keras.Input(shape=[10,10,3])
    out_var=tf.math.rsqrt(input_var)
    model=tf.keras.models.Model(input_var,out_var)
    model(data)
    return model,data

def save_model(model,path=""output/sqrt_H5/""):
    tf.keras.models.save_model(model,path+""H5/SQRT.h5"")
    
def convert_model(model,data):
    def representative_data_gen():
            for input_value in data:
                input_value = input_value[np.newaxis, ...]
                yield [input_value] # shape should be (1, <data point size))
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = representative_data_gen
    # Ensure that if any ops can't be quantized, the converter throws an error
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8

    tflite_model = converter.convert()
    tflite_models_dir = pathlib.Path(""output/tflite_models/"")
    tflite_models_dir.mkdir(exist_ok=True, parents=True)
    tflite_model_file = tflite_models_dir/""rsqrt_int.tflite""
    tflite_model_file.write_bytes(tflite_model)

  

def Execute():
    holder,data=make_model()
    save_model(holder)
    convert_model(holder,data)

```
Also, please include a link to a GraphDef or the model if possible.


**Any other info / logs**

tried to create  a single rsqrt operation containing model saved its .h5 with no problem and then convert it to its int8 .tflite but got the above error.
netron of hdf5 save is as follows
![image](https://user-images.githubusercontent.com/94594473/192996189-61804d56-a704-4abf-a380-81eae0a4340e.png)


Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

"
57905,Tensorflow Lite edgetpu compilation error: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.,"Hello, I am having an issue when compiling an image segmentation (U-net) model to run it on edge TPU (Coral Board). 
The model is converted and quantized as .tflite.
Edgetpu compiler error:  Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.

I have inspected the model with Netron and I did not find any dynamic sized tensors nor control-flow ops. 
Kindly check the Netron image and see if I missed out anything? As per the Netron visualization, the model seems to have no dynamic tensors.
Is there anything else I can do to resolve this issue? Please help.

The updated code and netron image is pasted on stackoverflow: https://stackoverflow.com/questions/73874287/how-do-i-resolve-the-error-attempting-to-use-a-delegate-that-only-supports-stat
The model is based on the oxford_pets model: https://keras.io/examples/vision/oxford_pets_image_segmentation/
I have read some closed issues on the similar error and have tried several ways to resolve it but it didnt work. 

Here is the model summary:
![image](https://user-images.githubusercontent.com/103208562/192989304-d4afd320-471a-4340-a66c-be918ea3256e.png)
![image](https://user-images.githubusercontent.com/103208562/192989537-cd92562e-fa83-4827-851f-eca0a68225b4.png)
![image](https://user-images.githubusercontent.com/103208562/192989653-3292f75a-3f54-4cc3-aced-b3df2051edd2.png)
![image](https://user-images.githubusercontent.com/103208562/192989748-2206378a-9709-472b-9c04-c3b27bf520d1.png)
![image](https://user-images.githubusercontent.com/103208562/192989827-ce89f5b6-bc06-4572-897a-7459ea3d6f5d.png)
![image](https://user-images.githubusercontent.com/103208562/192989960-4bb84d2b-8218-4056-9606-c9918d0b2d10.png)
![image](https://user-images.githubusercontent.com/103208562/192990054-4a0fdb9f-5bfc-4314-9608-e0fd789cbb24.png)
![image](https://user-images.githubusercontent.com/103208562/192990151-4379e83c-7a26-4d17-8d54-13363dd5b683.png)

Kindly help me resolve the error. Thank you in advance."
57904,representative_dataset error for TFlite converter quantization,"### 1. System information

- Colab environment
- Quantization of yolov5s weights
- Successfully generated tflite files with,
     - No quantization
     - Floating Point 16
     - Dynamic range (no representative_dataset option)
- Fails when representative_dataset option is provided
- 

### 2. Code
-# https://github.com/tensorflow/tensorflow/issues/30861
tf.executing_eagerly()

train = []
path = '/currdrive/road_hero/android_figurine/validate/'
for i in range(1, 11):
    filename = os.path.join(path, 'IMG_0501.jpg')
    im = cv2.imread(filename)
    im = im.astype(np.float32, copy=False)
    #input_image = im - mc.BGR_MEANS
    train.append(im)

train = tf.convert_to_tensor(np.array(train, dtype='float32'))
my_ds = tf.data.Dataset.from_tensor_slices((train)).batch(1)

def representative_data_gen():
    for input_value in my_ds.take(10):
        yield [input_value]


file_path = './yolov5s_saved_model'
tf_lite_converter = tf.lite.TFLiteConverter.from_saved_model(file_path, signature_keys=['serving_default'])


tf_lite_converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tf_lite_converter._experimental_lower_tensor_list_ops = False

tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]
tf_lite_converter.representative_dataset = representative_data_gen

tflite_model = tf_lite_converter.convert()

TF_LITE_MODEL_FILE_NAME = ""dynamic2.tflite""


with tf.io.gfile.GFile(TF_LITE_MODEL_FILE_NAME, 'wb') as f:
  f.write(tflite_model)



#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/drive/12t4TOjMvWnFDyRi9A2xhXtg_b_ITamXn#scrollTo=EukHdiAM-Mt9)

2) Attaching the colab file for your reference.
[yolov5_quantize.zip](https://github.com/tensorflow/tensorflow/files/9671818/yolov5_quantize.zip)

3) Attaching the yolov5s weights used for conversion
[yolov5s.pt.zip](https://github.com/tensorflow/tensorflow/files/9672062/yolov5s.pt.zip)



### 3. Error Log

Importing a function (__inference_pruned_6862) with ops with unsaved custom gradients. Will likely fail if a gradient is requested.

---------------------------------------------------------------------------

RuntimeError                              Traceback (most recent call last)

<ipython-input-23-7cfa8e603e42> in <module>
     41 tf_lite_converter.representative_dataset = representative_data_gen
     42 
---> 43 tflite_model = tf_lite_converter.convert()
     44 
     45 TF_LITE_MODEL_FILE_NAME = ""dynamic2.tflite""

11 frames

/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/optimize/calibrator.py in _feed_tensors(self, dataset_gen, resize_input)
    127                                      signature_key)
    128           else:
--> 129             self._calibrator.Prepare([list(s.shape) for s in input_array])
    130         else:
    131           if signature_key is not None:


RuntimeError: tensorflow/lite/kernels/concatenation.cc:158 t->dims->data[d] != t0->dims->data[d] (189 != 40)Node number 123 (CONCATENATION) failed to prepare.

"
57903,"why my 'workers=4,use_multiprocessing=True' do not work while training?","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf2.4

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.utils import Sequence
from math import ceil
import numpy as np
import numpy as np
import math
import os

class DataGenerator(Sequence):
 
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size

    def __len__(self):
        return ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        end = min(self.x.shape[0], (idx + 1)*batch_size)
        return self.x[idx*batch_size:end], self.y[idx*batch_size:end]

batch_size = 32
epochs = 100

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0
training_generator = DataGenerator(train_images, train_labels, batch_size)


model = models.Sequential()
model.add(layers.Conv2D(320, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(x=training_generator,
                    steps_per_epoch=train_images.shape[0]//batch_size,
                    validation_data=(train_images, train_labels),
                    epochs=epochs,
                    verbose=1,
                    use_multiprocessing=True,
                    workers=4)
```


### Relevant log output

_No response_</details>"
57902,`tf.compat.v1.nn.embedding_lookup` computes wrong forward gradient when indices are out of bound,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9.1

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

`tf.compat.v1.nn.embedding_lookup` computes wrong forward gradient when indices are out of bound. In the example code below, `ids=[4]` is out of bound, so the output is all zero. The jacobian therefore is all zeros. However, the forward gradient is wrongly computed as`1.0` w.r.t. to `params[1,0]`.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf

params = tf.constant([[0.4], [0.6]], dtype=tf.float32)
ids = tf.constant([4], dtype=tf.int32)

def f(params):
    partition_strategy = ""mod""
    validate_indices = False
    max_norm = None
    return tf.compat.v1.nn.embedding_lookup(params, ids, 
    partition_strategy=partition_strategy, 
    validate_indices=validate_indices, 
    max_norm=max_norm, )

with tf.GradientTape(persistent=True) as tape:
    tape.watch(params)
    out = f(params)
print(""input params: \n"", params)
print(""outputs: "", out)


jac = tape.jacobian(out, [params])
print(""jacobian: "", jac)

tangents = tf.constant([[0.], [1.]])
with tf.autodiff.ForwardAccumulator(params,tangents) as acc:
  out = f(params)
print(""forward outputs: "", out)
jvp = acc.jvp(params)
print(""forward gradient: "", jvp)

```


### Relevant log output

```shell
WARNING:tensorflow:Converting IndexedSlices(indices=Tensor(""gradient_tape/Reshape_2:0"", shape=(1,), dtype=int32), values=Tensor(""gradient_tape/Reshape_1:0"", shape=(1, 1), dtype=float32), dense_shape=Tensor(""gradient_tape/Cast:0"", shape=(2,), dtype=int32, device=/job:localhost/replica:0/task:0/device:GPU:0)) to a dense representation may make it slow. Alternatively, output the indices and values of the IndexedSlices separately, and handle the vectorized outputs directly.
input params: 
 tf.Tensor(
[[0.42328522]
 [0.47058594]], shape=(2, 1), dtype=float32)
outputs:  tf.Tensor([[0.]], shape=(1, 1), dtype=float32)
jacobian:  [<tf.Tensor: shape=(1, 1, 2, 1), dtype=float32, numpy=
array([[[[0.],
         [0.]]]], dtype=float32)>]
forward outputs:  tf.Tensor([[0.]], shape=(1, 1), dtype=float32)
forward gradient:  tf.Tensor(
[[0.]
 [1.]], shape=(2, 1), dtype=float32)
```
</details>"
57898,[TF] `tf.image.resize_with_crop_or_pad` constfolding issue with variable batch size.,"### TF Version
TF 2.10

## Gist of the issue

Similar problem was found with `tf.image.resize_with_crop_or_pad` as reported in https://github.com/keras-team/tf-keras/issues/411 and https://github.com/tensorflow/tensorflow/issues/57853.

Long story short `tf.image.resize_with_crop_or_pad` does not behave the same when batch_size is fixed (e.g. batch_size=32) and when it's variable (e.g. batch_size=None). The problem seems to reside in the way `constant_folding` is working or in the way `height` and `width` are managed.

## Google Colab for Repro

Full repro case in detail: https://colab.research.google.com/drive/1JlGYCiD-oDwXBaumxoLfZqUSj_KbXuUE?usp=sharing

## A picture is worth a thousands word

### 1. Let's create the model

Picture the most basic model using `Conv2DTranspose`

```python
def create_model(batch_size=None):
  inputs = keras.layers.Input((128, 128, 3), dtype=tf.float32, batch_size=batch_size)

  net = tf.image.resize_with_crop_or_pad(inputs, 100, 100)
  net = keras.layers.Conv2D(filters=32, kernel_size=(3, 3))(net)

  model = keras.models.Model(inputs=inputs, outputs=net)
  return model
```

**Fixed BS:**
![image](https://user-images.githubusercontent.com/10923599/192889217-dde657b8-7b78-49e4-8fea-e3cdc3d2538f.png)


**Variable BS:**
![image](https://user-images.githubusercontent.com/10923599/192889268-6e12d5ae-a99a-48b8-8405-3fc2662f6418.png)


So far so good, everything looks the same ...

### 2. Freeze + ConstFold + Plot

Now let's freeze the graph and plot the resulting graphdef:

**Fixed BS:**
![image](https://user-images.githubusercontent.com/10923599/192889358-cc87a30f-bb7b-4e67-9bc8-eb274768af03.png)

**Variable BS:**
![image](https://user-images.githubusercontent.com/10923599/192889315-b9a932c3-8a1e-4c58-878f-fd517ddfd708.png)

## Conclusion

I hope the difference is fairly self explanatory, and that's a problem because that's a very different graph for inference and a lot more complicated graph to optimize by compilers (e.g. TF-TRT, XLA, TF Lite, TVM, etc).

Anything upstream of the `Slice` OP  **should** have been const folded, it's perfectly independent of input batch size. There's no reason to the best of my knowledge that the const folding behavior changes by changing the BS value. 

My guess is that the shape tensor is seen as variable because of one value being None, however the None dimension is not being used and therefore the slice of the Shape tensor is perfectly static in this case and should have been const folded.

## To go further

It should not be runtime computed when the shapes are perfectly static, we should not need to constfold this graph in the first place. This could be perfectly computed in python when all the shapes are defined. This is very expensive to compute over and over at each iteration even in training.

A very similar issue was fixed with a different layer here, we should consider a similar fix here: https://github.com/tensorflow/tensorflow/pull/31450/files"
57897,tf.image.resize crash with abort when `antialias` is set to True,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0-dev20220921

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

`tf.image.resize` crash with abort when `antialias` is set to True. It doesn't not abort when `antialias=False`

Also reproduced in this [gist](https://colab.research.google.com/drive/1W3ZKTuk3eaPRCc88HHv_9vwftUhHE1oA?usp=sharing)


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf 
tf.image.resize(images=np.ones((2,2,2,2)), size=[1801181592, 1846789676], antialias=True)
```


### Relevant log output

```shell
2022-09-28 20:12:18.701544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-09-28 20:12:18.701595: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-28 20:12:18.701648: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2022-09-28 20:12:18.702226: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-28 20:12:19.021252: F tensorflow/core/framework/tensor_shape.cc:186] Non-OK-status: InitDims(dim_sizes) status: INVALID_ARGUMENT: Encountered overflow when multiplying 6652807137413688384 with 2, result: -5141129798882174848
Aborted (core dumped)
```
</details>"
57896,tf.histogram_fixed_width crash with segmentation fault,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.11.0-dev20220916

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04.4 LTS (x86_64)

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

N/A

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.histogram_fixed_width` crash with segmentation fault
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
tf.histogram_fixed_width(values=np.array([3e+38,100], dtype=np.float32), value_range=np.array([-1e+38,  3e+38]), nbins=1)
```


### Relevant log output

```shell
2022-09-28 19:23:13.760398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-09-28 19:23:13.760444: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2022-09-28 19:23:13.760518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2022-09-28 19:23:13.761047: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Segmentation fault (core dumped)
```
</details>"
57893,`Nan` errors multiple-gpu training with `MirroredStrategy` - RTX A5000 PCIe4.0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA11.0 & cuDNN8.1.0

### GPU model and memory

RTX A5000 24GB

### Current Behaviour?

```shell
I moved 8 Nvidia RTX A5000 from an old server (ASRockRack 3U8G-C612 : 2 Intel Xeon E5-2640 v4 with 8 PCIe3.0 lanes. Details here https://www.asrockrack.com/general/productdetail.asp?Model=3U8G-C612#Specifications) to a more recent server populated with 10 Nvidia RTX A5000 (including the 8 ones from the former server + 2 new RTX A5000) (Supermicro SYS-420GP-TNR : 2 Intel Xeon Gold 5317 with 12 PCIe4.0 lanes. Details here https://www.supermicro.com/en/products/system/gpu/4u/sys-420gp-tnr). 


I kept the same OS version (Ubuntu 20.04, with kernel=5.13.0-52-generic) and same driver version 515.57.
All the 10 RTX A5000 are visible with `nvidia-smi`, but when I start to execute my code I have `nan` in losses and model's outputs after few iterations (less than 10, sometimes at the second iteration). It happens only when I use multiple GPUs. 


I wrote code that reproduces the errors.

I used docker image provided by Tensorflow : `tensorflow/tensorflow:2.10.0-gpu-jupyter` (SHA `[tensorflow/tensorflow@sha256:a72deb34d32e26cf4253608b0e86ebb4e5079633380c279418afb5a131c499d6]`). 

Choice of `cross_device_ops=tf.distribute.ReductionToOneDevice(reduce_to_device=""/cpu:0"")` ? 
* If I use `tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())`, the call to `distributed_train_step()` is hanging on the new server .. Need to `docker stop` the container. 
* Whatever the `cross_device_ops` the script is working properly on the old server. 

What you can see in the outputs : 
* Everything is OK for the first replicate, no `nan` in his inputs, `per_samples_losses`
* But for the second replicate (if 2 GPUs) we have `nan` values in `images` used in `train_step()` and `nan` 


What is strange ? 
* `images` from the distributed dataset does not contain `nan` values whiles `images` collected after the train steps contains `nan`
* And these `nan` values are only present on the second replica (or more if more than 2 GPUs) never on the 1st replica. 


After searching on past issues and StackOverflow, as first actions:
* I disabled 'Intel VMX' within BIOS options. Same errors after. 
* Re-install drivers (even to 515.76). Same errors after. I roll-back to 515.57



Also, I added old Nvidia TitanX (Pascal) into the older server to test the code. 
And before, when the 8 RTX A5000 were in the old server, everything was working well with my experiments. 


Feel free to ask me any questions or more details. 

Best regards
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
import os
from pprint import pprint


def main():
    print(f""tf.version.GIT_VERSION : {tf.version.GIT_VERSION}"")
    print(f""tf.version.VERSION : {tf.version.VERSION}"")

    print(""tf.config.list_physical_devices() : "")
    pprint(tf.config.list_physical_devices())

    fashion_mnist = tf.keras.datasets.fashion_mnist

    (train_images, train_labels), (_, _) = fashion_mnist.load_data()
    # create 4D np.ndarray [N,H,W] -> [N,H,W,1]
    train_images = train_images[..., np.newaxis]

    # scale pixels to [0, 1]
    train_images = train_images / np.float32(255)

    # get the tf.distribute.Strategy
    # strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.NcclAllReduce())  # tested
    strategy = tf.distribute.MirroredStrategy(
        cross_device_ops=tf.distribute.ReductionToOneDevice(reduce_to_device=""/cpu:0"")
    )
    print(f""Strategy : {strategy}"")
    print(f""Number of devices: {strategy.num_replicas_in_sync}"")

    # some training arguments
    buffer_size = len(train_images)
    batch_size_per_replica = 64
    global_batch_size = batch_size_per_replica * strategy.num_replicas_in_sync

    # create tf.data.Dataset
    train_dataset = (
        tf.data.Dataset.from_tensor_slices((train_images, train_labels))
        .shuffle(buffer_size)
        .batch(global_batch_size)
    )
    # extend to a distributed one version
    train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)

    with strategy.scope():
        # Set reduction to `NONE` so you can do the reduction afterwards and divide by
        # global batch size.
        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
            from_logits=True, reduction=tf.keras.losses.Reduction.NONE
        )

        def compute_loss(_labels, _predictions):
            _per_example_loss = loss_object(_labels, _predictions)
            _averaged_loss = tf.nn.compute_average_loss(
                _per_example_loss, global_batch_size=global_batch_size
            )
            return _averaged_loss, _per_example_loss

    with strategy.scope():
        model = create_model()
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)

    def train_step(inputs):
        _images, _labels = inputs
        with tf.GradientTape() as tape:
            _predictions = model(_images, training=True)
            _averaged_loss, _per_example_loss = compute_loss(_labels, _predictions)

        gradients = tape.gradient(_averaged_loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

        # return : averaged loss on all example, per_example_loss ([batch_size,] Tensor) and input images
        return _averaged_loss, _per_example_loss, _images

    @tf.function
    def distributed_train_step(dataset_inputs):
        _per_replica_averaged_losses, _per_replica_per_example_loss, _per_replica_images = strategy.run(
            train_step, args=(dataset_inputs,)
        )
        return (
            strategy.reduce(tf.distribute.ReduceOp.SUM, _per_replica_averaged_losses, axis=None),
            _per_replica_per_example_loss,
            _per_replica_images,
        )

    train_dist_iter = iter(train_dist_dataset)
    iteration = 0
    for _ in range(10):
        # get next (images, labels) from the dataset
        images, labels = next(train_dist_iter)
        # do we have nan in these images ?
        print(f""iteration={iteration}"")
        if strategy.num_replicas_in_sync > 1:
            print(
                ""\t nan in per_replica_images from dataset : "",
                {replica: np.isnan(images.numpy()).any() for replica, images in enumerate(images.values)},
            )
        else:
            # if single replica (CPU or mono-GPU) : specific print statements
            print(
                ""\t nan in per_replica_images from dataset : "",
                {0: np.isnan(images.numpy()).any()},
            )

        averaged_loss, per_replica_per_sample_losses, per_replica_images = distributed_train_step(
            (images, labels)
        )
        print(f""\t averaged_loss = {averaged_loss}"")

        if strategy.num_replicas_in_sync > 1:
            # do we have nan in images returned by train_step() and distributed_train_step() ?
            print(
                ""\t nan in per_replica_images              : "",
                {
                    replica: np.isnan(images.numpy()).any()
                    for replica, images in enumerate(per_replica_images.values)
                },
            )
            # do we have nan in losses per samples per replica ?
            print(
                ""\t nan in per_replica_per_sample_losses   : "",
                {
                    replica: np.isnan(per_sample_losses.numpy()).any()
                    for replica, per_sample_losses in enumerate(per_replica_per_sample_losses.values)
                },
            )
            print(""\n"")
        else:
            # if single replica (CPU or mono-GPU) : specific print statements.
            # do we have nan in images returned by train_step() and distributed_train_step() ?
            print(
                ""\t nan in per_replica_images              : "",
                {0: np.isnan(per_replica_images.numpy()).any()},
            )
            # do we have nan in losses per samples per replica ?
            print(
                ""\t nan in per_replica_per_sample_losses   : "",
                {0: np.isnan(per_replica_per_sample_losses.numpy()).any()},
            )
            print(""\n"")

        iteration += 1


def create_model():
    model = tf.keras.Sequential(
        [
            tf.keras.layers.Conv2D(32, 3, activation=""relu""),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(64, 3, activation=""relu""),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(64, activation=""relu""),
            tf.keras.layers.Dense(10),
        ]
    )

    return model


if __name__ == ""__main__"":
    main()
```


### Relevant log output

```shell
On new server with 2 GPUs : nan in `images` used in the `train_step()` after 1 iteration

CUDA_VISIBLE_DEVICES=""0,1"" python nan_error_tf.py
[...logs...]
iteration=0
	 nan in per_replica_images from dataset :  {0: False, 1: False}
	 averaged_loss = 2.320328712463379
	 nan in per_replica_images              :  {0: False, 1: False}
	 nan in per_replica_per_sample_losses   :  {0: False, 1: False}

iteration=1
	 nan in per_replica_images from dataset :  {0: False, 1: False}
	 averaged_loss = nan
	 nan in per_replica_images              :  {0: False, 1: True}
	 nan in per_replica_per_sample_losses   :  {0: False, 1: False}

iteration=2
	 nan in per_replica_images from dataset :  {0: False, 1: False}
	 averaged_loss = nan
	 nan in per_replica_images              :  {0: False, 1: True}
	 nan in per_replica_per_sample_losses   :  {0: True, 1: False}

iteration=3
	 nan in per_replica_images from dataset :  {0: False, 1: False}
	 averaged_loss = nan
	 nan in per_replica_images              :  {0: False, 1: True}
	 nan in per_replica_per_sample_losses   :  {0: True, 1: False}


On new server with 1 GPU : No `nan`, no issue. 
```shell
CUDA_VISIBLE_DEVICES=""0"" python nan_error_tf.py
[... logs ...]
iteration=0
	 nan in per_replica_images from dataset :  {0: False}
	 averaged_loss = 2.3019003868103027
	 nan in per_replica_images              :  {0: False}
	 nan in per_replica_per_sample_losses   :  {0: False}

iteration=1
	 nan in per_replica_images from dataset :  {0: False}
	 averaged_loss = 2.2981200218200684
	 nan in per_replica_images              :  {0: False}
	 nan in per_replica_per_sample_losses   :  {0: False}


iteration=2
	 nan in per_replica_images from dataset :  {0: False}
	 averaged_loss = 2.0697689056396484
	 nan in per_replica_images              :  {0: False}
	 nan in per_replica_per_sample_losses   :  {0: False}

iteration=3
	 nan in per_replica_images from dataset :  {0: False}
	 averaged_loss = 1.8743340969085693
	 nan in per_replica_images              :  {0: False}
	 nan in per_replica_per_sample_losses   :  {0: False}

```
If I use the same script, with 1 or 2 (or more) GPUs on the old server, everything is working well.
```
</details>"
57890,MultiWorkerMirroredStrategy overhead time,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.9

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am trying to train tensorflow recommender , When I run in on single machine with 32K batch size every steps take 4 sec, But then when I run it with 2 machines (64k global batch size) it took 7 sec. So the overhead is 3 sec.

Now if I increase my batch size to 64K then step time is increased to 10 sec for single machine and 2 machine it's 17 sec, now overhead is 7 sec. 

So with this way I am not actually reducing the training time by adding more machine. Tried with 4, 8, 12 machine it's just take same time it takes for single machine. 

Not sure if I am missing anything

Here is my code :
        strategy = tf.distribute.MultiWorkerMirroredStrategy()
        tf.debugging.set_log_device_placement(True)
        global_batch_size = self.batch_size * strategy.num_replicas_in_sync
        train_batches = self.train_dataset.batch(global_batch_size).prefetch(
            tf.data.AUTOTUNE
        )
        test_batches = self.test_dataset.batch(global_batch_size).prefetch(
            tf.data.AUTOTUNE
        )
        options = tf.data.Options()
        options.experimental_distribute.auto_shard_policy = (
            tf.data.experimental.AutoShardPolicy.DATA
        )
        train_batches = train_batches.with_options(options)
        test_batches = test_batches.with_options(options)
        with strategy.scope():
            self.model = self.get_model_with_state()

        self.history = self.model.fit(
            train_batches,
            validation_data=test_batches,
            epochs=self.num_epochs,
            callbacks=self.custom_callbacks,
            verbose=1,
        )
```


### Standalone code to reproduce the issue

```shell
strategy = tf.distribute.MultiWorkerMirroredStrategy()        
        tf.debugging.set_log_device_placement(True)
        # tf_config = json.loads(os.environ[""TF_CONFIG""])
        # num_workers = len(tf_config[""cluster""][""worker""])
global_batch_size = self.batch_size * strategy.num_replicas_in_sync
        train_batches = self.train_dataset.batch(global_batch_size).prefetch(
            tf.data.AUTOTUNE
        )
        test_batches = self.test_dataset.batch(global_batch_size).prefetch(
            tf.data.AUTOTUNE
        )
        options = tf.data.Options()
        options.experimental_distribute.auto_shard_policy = (
            tf.data.experimental.AutoShardPolicy.DATA
        )
        train_batches = train_batches.with_options(options)
        test_batches = test_batches.with_options(options)
        with strategy.scope():
            self.model = self.get_model_with_state()

        self.history = self.model.fit(
            train_batches,
            validation_data=test_batches,
            epochs=self.num_epochs,
            callbacks=self.custom_callbacks,
            verbose=1,
        )
```


### Relevant log output

_No response_</details>"
57889,GradientTape gives error message >= tf2.9,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf2.9 tf2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 22.04 20.04

### Mobile device

_No response_

### Python version

3.8 3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When training the same nn working on tf2.8, it's broken on tf2.9 and 2.10. 
The error messages from `GradientTape` are attached. I'm not sure if it's a bug, 
or it's something not supposed to be back compatible and I can avoid with my code. 
Can I get some idea/suggestion/advice where to start guessing the cause?
```


### Standalone code to reproduce the issue

```shell
I don't have a simple code to reproduce the issue
since I can't understand what it's related to after one day debug
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/ubuntu/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'gradients/rnn_13/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack' defined at (most recent call last):
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1409, in fit
      tmp_logs = self.train_function(iterator)
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1051, in train_function
      return step_function(self, iterator)
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1040, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/engine/training.py"", line 893, in train_step
      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 537, in minimize
      grads_and_vars = self._compute_gradients(
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 590, in _compute_gradients
      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)
    File ""/home/ubuntu/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py"", line 471, in _get_gradients
      grads = tape.gradient(loss, var_list, grad_loss)
Node: 'gradients/rnn_13/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack'
Operation expected a list with 1 elements but got a list with 3 elements.
         [[{{node gradients/rnn_13/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack}}]] [Op:__inference_train_function_33044]
```
</details>"
57888,FusedBatchNormV3 does not work on bfloat16,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Documentation states that FusedBatchNormV3 should be able to work on bfloat16 input. However, if given bfloat16 input, the results are empty.

Minimal reproduction script that shows this OP works on float32 but does not work on bfloat16

Note that according to documentation, scale, offset, mean and variance have to be float32 and in fact TF throws an error if they are not, so the only variable that is bfloat16 is the input data x.

Results show that for bfloat16 output is an empty tensor of type float32.
This is similar to the task reported here https://github.com/tensorflow/tensorflow/issues/56680
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

for dtype in [tf.float32, tf.bfloat16]:
    x = tf.constant([[[[1],[5],[9],[13]]]], dtype=dtype)
    m_e = tf.constant([], dtype=tf.float32)
    v_e = tf.constant([], dtype=tf.float32)
    [y, m, v, _, _, _] = tf.raw_ops.FusedBatchNormV3(
        x=x, scale=[1.0], offset=[0.0], mean=m_e, variance=v_e
    )
    print(""-----------------------------------------"")
    print(""dtype = "", dtype)
    print(""in    = "", x)
    print(""out y = "", y)
    print(""out m = "", m)
    print(""out v = "", v)
    print("""")
```


### Relevant log output

```shell
-----------------------------------------
dtype =  <dtype: 'float32'>
in    =  tf.Tensor(
[[[[ 1.]
   [ 5.]
   [ 9.]
   [13.]]]], shape=(1, 1, 4, 1), dtype=float32)
out y =  tf.Tensor(
[[[[-1.3416375]
   [-0.4472125]
   [ 0.4472125]
   [ 1.3416375]]]], shape=(1, 1, 4, 1), dtype=float32)
out m =  tf.Tensor([7.], shape=(1,), dtype=float32)
out v =  tf.Tensor([26.666668], shape=(1,), dtype=float32)
-----------------------------------------
dtype =  <dtype: 'bfloat16'>
in    =  tf.Tensor(
[[[[1]
   [5]
   [9]
   [13]]]], shape=(1, 1, 4, 1), dtype=bfloat16)
out y =  tf.Tensor([], shape=(0,), dtype=float32)
out m =  tf.Tensor([], shape=(0,), dtype=float32)
out v =  tf.Tensor([], shape=(0,), dtype=float32)
```
</details>"
57886,dlopen _tensor_forest_ops.so failed cause dead lock,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 1.14

### Custom Code

Yes

### OS Platform and Distribution

Linux 4.9.70-040970-generic #201712161132 SMP Sat Dec 16 16:33:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

### Mobile device

_No response_

### Python version

3.7.2

### Bazel version

unknown 

### GCC/Compiler version

gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609

### CUDA/cuDNN version

no

### GPU model and memory

no 

### Current Behaviour?

```shell
I got a hang, and gdb got stack trace like bellow, I thought it may be dead lock, why?

#0  __lll_lock_wait_private () at ../sysdeps/unix/sysv/linux/x86_64/lowlevellock.S:95
#1  0x00007ff3657fa0f1 in __new_exitfn (listp=0x7ff365b86050 <lock>, listp@entry=0x7ff365b845f8 <__exit_funcs>) at cxa_atexit.c:79
#2  0x00007ff3657fa2a9 in __internal_atexit (listp=0x7ff365b845f8 <__exit_funcs>, d=0x7ff2a5904000, arg=0x7ff2a5905798 <std::__ioinit>, func=0x7ff33dc88830 <std::ios_base::Init::~Init()>)
    at cxa_atexit.c:35
#3  __GI___cxa_atexit (func=0x7ff33dc88830 <std::ios_base::Init::~Init()>, arg=0x7ff2a5905798 <std::__ioinit>, d=0x7ff2a5904000) at cxa_atexit.c:58
#4  0x00007ff2a54b19aa in _GLOBAL__sub_I_generic_tree_model_extensions.pb.cc () from /usr/lib/python3.7/site-packages/tensorflow/contrib/tensor_forest/python/ops/../../libforestprotos.so
#5  0x00007ff3665456fa in call_init (l=<optimized out>, argc=argc@entry=15, argv=argv@entry=0x7ffca53a7848, env=env@entry=0x7ff364844180) at dl-init.c:72
#6  0x00007ff36654580b in call_init (env=0x7ff364844180, argv=0x7ffca53a7848, argc=15, l=<optimized out>) at dl-init.c:30
#7  _dl_init (main_map=main_map@entry=0x7ff2a6d35700, argc=15, argv=0x7ffca53a7848, env=0x7ff364844180) at dl-init.c:120
#8  0x00007ff36654a922 in dl_open_worker (a=a@entry=0x7ffca539b280) at dl-open.c:575
#9  0x00007ff3665455a4 in _dl_catch_error (objname=objname@entry=0x7ffca539b270, errstring=errstring@entry=0x7ffca539b278, mallocedp=mallocedp@entry=0x7ffca539b26f,
    operate=operate@entry=0x7ff36654a510 <dl_open_worker>, args=args@entry=0x7ffca539b280) at dl-error.c:187
#10 0x00007ff366549de9 in _dl_open (file=0x7ff2a6cd1710 ""/usr/lib/python3.7/site-packages/tensorflow/contrib/tensor_forest/python/ops/_tensor_forest_ops.so"", mode=-2147483646,
    caller_dlopen=0x7ff345bc2fca <tensorflow::internal::LoadLibrary(char const*, void**)+26>, nsid=-2, argc=<optimized out>, argv=<optimized out>, env=0x7ff364844180) at dl-open.c:660
#11 0x00007ff3655bcf09 in dlopen_doit (a=a@entry=0x7ffca539b4b0) at dlopen.c:66
#12 0x00007ff3665455a4 in _dl_catch_error (objname=0x7ff36480e590, errstring=0x7ff36480e598, mallocedp=0x7ff36480e588, operate=0x7ff3655bceb0 <dlopen_doit>, args=0x7ffca539b4b0) at dl-error.c:187
#13 0x00007ff3655bd571 in _dlerror_run (operate=operate@entry=0x7ff3655bceb0 <dlopen_doit>, args=args@entry=0x7ffca539b4b0) at dlerror.c:163
#14 0x00007ff3655bcfa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87
#15 0x00007ff345bc2fca in tensorflow::internal::LoadLibrary(char const*, void**) () from /usr/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1
#16 0x00007ff345bc14f7 in tensorflow::(anonymous namespace)::PosixEnv::LoadLibrary(char const*, void**) () from /usr/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1
#17 0x00007ff34582708d in tensorflow::LoadLibrary(char const*, void**, void const**, unsigned long*) () from /usr/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.1
#18 0x00007ff34d710557 in TF_LoadLibrary () from /usr/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#19 0x00007ff34894a758 in _wrap_TF_LoadLibrary () from /usr/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#20 0x00007ff365e40ff9 in _PyMethodDef_RawFastCallKeywords (method=0x7ff35dc6ce00 <SwigMethods+14944>, self=<optimized out>, args=0x7ff2f84e3998, nargs=1, kwnames=<optimized out>) at Objects/call.c:694
#21 0x00007ff365e410b5 in _PyCFunction_FastCallKeywords (func=0x7ff35dca85e8, args=<optimized out>, nargs=<optimized out>, kwnames=<optimized out>) at Objects/call.c:730
#22 0x00007ff365e183b4 in call_function (kwnames=0x0, oparg=<optimized out>, pp_stack=<synthetic pointer>) at Python/ceval.c:4568
#23 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3093
#24 0x00007ff365e0fec0 in function_code_fastcall (co=<optimized out>, args=<optimized out>, nargs=1, globals=<optimized out>) at Objects/call.c:283
#25 0x00007ff365e40bef in _PyFunction_FastCallKeywords (func=<optimized out>, stack=<optimized out>, nargs=<optimized out>, kwnames=<optimized out>) at Objects/call.c:415
#26 0x00007ff365e195e6 in call_function (kwnames=0x0, oparg=<optimized out>, pp_stack=<synthetic pointer>) at Python/ceval.c:4616
#27 _PyEval_EvalFrameDefault (f=<optimized out>, throwflag=<optimized out>) at Python/ceval.c:3093
#28 0x00007ff365e0fec0 in function_code_fastcall (co=<optimized out>, args=<optimized out>, nargs=1, globals=<optimized out>) at Objects/call.c:283
#29 0x00007ff365e40bef in _PyFunction_FastCallKeywords (func=<optimized out>, stack=<optimized out>, nargs=<optimized out>, kwnames=<optimized out>) at Objects/call.c:415
#30 0x00007ff365e195e6 in call_function (kwnames=0x0, oparg=<optimized out>, pp_stack=<synthetic pointer>) at Python/ceval.c:4616
```


### Standalone code to reproduce the issue

```shell
no code
```


### Relevant log output

_No response_</details>"
57885,"Use custom tflite model in flutter, select ops doesn't work on emulator x86","I'm following this : https://www.tensorflow.org/lite/guide/ops_select , in order to convert a model to tflite and use it in flutter (android). 

I added the necessary dependencies but it doesn't work on emulator. I wanted to know if it was only for real devices or if was supposed to work on emulator too?

dependencies {
    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly-SNAPSHOT'
    // This dependency adds the necessary TF op support.
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly-SNAPSHOT'
}

Error : 
[Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference]"
57883,Inconsistent behavior of TF eager and XLA in int64 casting,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

'2.11.0-dev20220927' (nightly)

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.cast(nan, tf.int64)` has inconsistent behaviour in eager mode and XLA:

- `eager`: -9223372036854775808 (same as numpy)
- `xla`: 0

`xla` should be consistent with TensorFlow eager's behaviour IMO.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np


def fn(x):
    return tf.cast(x, tf.int64)


with tf.device(""/GPU:0""):
    print(""eager"", fn(np.array(np.nan)).numpy())

with tf.device(""/GPU:0""):
    print(""xla"", tf.function(jit_compile=True)(fn)(np.array(np.nan)).numpy())

print(""numpy"", np.array(np.nan).astype(np.int64))
```


### Relevant log output

```shell
eager -9223372036854775808
xla 0
numpy -9223372036854775808
```
```
</details>"
57882,TFLite runner crashes with XOR and squeeze in the model,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.4 LTS
- TensorFlow installation (pip package or built from source): pip package
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0.dev20220921

### 2. Code

Reproduced on 2.11.0.dev20220921 and CoLab default environment.

https://colab.research.google.com/drive/157-FX1oSNsdu3gKMoDawFLj_t46ayk35?usp=sharing

```python
import tensorflow as tf
print(tf.__version__)


def get_tflite_callable(model, inp_dict):
    converter = tf.lite.TFLiteConverter.from_concrete_functions(
        funcs=[model.__call__.get_concrete_function(**inp_dict)],
        trackable_obj=model,
    )
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
        tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
    ]
    tflite_bytes = converter.convert()
    interpreter = tf.lite.Interpreter(model_content=tflite_bytes)
    runner = interpreter.get_signature_runner()
    return runner

class MyModule(tf.Module):
    def __init__(self):
        super().__init__()
        self.const = tf.constant(True, shape=[1,1,2,2,1], dtype=tf.bool)

    @tf.function # (jit_compile=True)
    def __call__(self, x):
        x = tf.math.logical_xor(x, self.const)
        x = tf.squeeze(x, axis=0)
        return x

inp = {
    ""x"": tf.constant(True, shape=[2,2,2], dtype=tf.bool),
}
m = MyModule()
print(m(**inp))
runner = get_tflite_callable(m, inp)
print(runner(**inp))
```

### 3. Failure after conversion

Conversion can be finished, but running the model leads to crash.

```python
[1]    2071551 abort (core dumped)  python bug.py
```
"
57880,Computing jacobian for `tf.image.resize` cause Check Failed on cuda,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9, 2.11.0-dev20220927

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Computing jacobian for `tf.image.resize` cause Check Failed on cuda and session crashes.


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
images = tf.zeros([1, 1, 1], dtype=tf.float32)

def f(images):
    size = [224, 224,]
    method = ""nearest""
    preserve_aspect_ratio = False
    antialias = False
    return tf.image.resize(images, size, method=method, preserve_aspect_ratio=preserve_aspect_ratio, antialias=antialias, )


with tf.GradientTape(persistent=True) as tape:
    tape.watch(images)
    output = f(images)
print(output.shape) # (222, 224, 1)
g = tape.jacobian(output, [images]) #  Check failed
```


### Relevant log output

```shell
(222, 224, 1)
WARNING:tensorflow:Using a while_loop for converting ResizeNearestNeighborGrad
F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 (0 vs. -1822093312)
abort (core dumped)
```
</details>"
57877,`Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error` at fork,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

'2.11.0-dev20220927' (nightly)

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

A6000

### Current Behaviour?

```shell
When running `tf.function` in a forked process, the program crashed as ""Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error"". The forked subprocess will crash with an exit code `-6`.
```


### Standalone code to reproduce the issue

```shell
import multiprocessing as mp
import tensorflow as tf


@tf.function
def div(x):
    return (x + x) / (x + x)


with tf.device(""/GPU:0""):
    div(tf.ones((100, 100)))


def run():
    with tf.device(""/GPU:0""):
        print(div(tf.ones((100, 100))))


process = mp.Process(target=run)
process.start()
process.join()
print(f""Sub-process exited with {process.exitcode}"")
```


### Relevant log output

```shell
""""""
...
2022-09-27 13:45:15.709933: F tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:148] Failed setting context: CUDA_ERROR_NOT_INITIALIZED: initialization error
""""""
```
</details>"
57872,How to build TensorFlow from source with Clang?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

v2.10.0

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.1.1

### GCC/Compiler version

clang 14

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am trying to build TensorFlow with clang and add options for generating coverage information (https://clang.llvm.org/docs/SourceBasedCodeCoverage.html). However, it fails with clang build.
```


### Standalone code to reproduce the issue

```shell
bazel build --verbose_failures //tensorflow/tools/pip_package:build_pip_package --repo_env=CC=clang --copt=-fprofile-instr-generate --copt=-fcoverage-mapping


Removing `--copt=-fprofile-instr-generate --copt=-fcoverage-mapping` also fails.
```


### Relevant log output

```shell
""""""
ERROR: /home/jiawei/.cache/bazel/_bazel_jiawei/b619a772dd31287f179cb3c11ac7f523/external/llvm-project/mlir/BUILD.bazel:3204:11: Compiling mlir/lib/Support/IndentedOstream.cpp failed: undeclared inclusion(s) in rule '@llvm-project//mlir:Support':
this rule is missing dependency declarations for the following files included by 'mlir/lib/Support/IndentedOstream.cpp':
  'bazel-out/k8-opt/bin/external/llvm-project/llvm/config.cppmap'
  'bazel-out/k8-opt/bin/external/llvm-project/llvm/Demangle.cppmap'
  'bazel-out/k8-opt/bin/external/llvm_terminfo/terminfo.cppmap'
  'bazel-out/k8-opt/bin/external/llvm_zlib/zlib.cppmap'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 138.453s, Critical Path: 63.33s
INFO: 7649 processes: 4288 internal, 3361 local.
FAILED: Build did NOT complete successfull
""""""
```
</details>"
57863,`tf.experimental.numpy.isposinf` has wrong output when input is integer.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.10

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

When integer tensor with +/- inf values, is passed to `tf.experimental.numpy.isposinf`, it has different results on cpu/cuda, and is different from numpy outputs. 

In the example, the input is [-inf,0,inf] for `int32` data type. On cpu, `tf.experimental.numpy.isposinf` wrongly output `True` for `-inf`.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
with tf.device('cpu'):
    x = tf.constant([-2147483648,0,2147483647], dtype=tf.int32)
    result = tf.experimental.numpy.isposinf(x)
    print(""cpu:"", result)

    
with tf.device('gpu'):
    x = tf.constant([-2147483648,0,2147483647], dtype=tf.int32)
    result = tf.experimental.numpy.isposinf(x)
    print(""cuda:"", result)

import numpy as np

x = np.array([-2147483648,0,2147483647], dtype=np.int32)
print(""numpy:"", np.isposinf(x))
```


### Relevant log output

```shell
cpu: tf.Tensor([ True False False], shape=(3,), dtype=bool)
cuda: tf.Tensor([False False  True], shape=(3,), dtype=bool)
numpy: [False False False]
```
</details>"
57862,XLA tests fail with compute-sanitizer due to CAS operation on small dtype,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

master branch

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

not relevant

### Bazel version

5.1.1

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

V100-16G

### Current Behaviour?

```shell
Some XLA tests fail with compute-sanitizer. There is one example in the repro section bellow.

There is one issue in the function EmitAtomicOperationUsingCAS that can trigger this. Mostly, it always read 4 bytes, even if only 1 was allocated.
One simple solution would be to always allocate at least 4 bytes. This won't changes anything as internally, the memory is allocated by block of more then 4 bytes.
```


### Standalone code to reproduce the issue

```shell
bazel test --verbose_failures -c opt --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=1 --java_runtime_version=remotejdk_11 --run_under=compute-sanitizer //tensorflow/compiler/xla/tests:scatter_test_gpu
```


### Relevant log output

```shell
========= Invalid __global__ read of size 4 bytes
=========     at 0x200 in fusion_1
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x7f79a5c00800 is out of bounds
=========     and is inside the nearest allocation at 0x7f79a5c00800 of size 1 bytes
=========     Saved host backtrace up to driver entry point at kernel launch time
...
```
</details>"
57861,Tensorflow lite Vulkan delegate,"I have built TF lite GPU delegate to work with Open GL using the following target: `tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_gl.so`

How exactly am I supposed to enable Vulkan support? I have seen some references to Vulkan under `tensorflow/lite/delegates/gpu/gl` such as compiler options. Please suggest the steps to follow in enabling Vulkan support.

Also, is this comparison still valid: https://blog.tensorflow.org/2020/08/faster-mobile-gpu-inference-with-opencl.html which says:
`OpenCL-based mobile GPU inference engine for Android, which offers up to ~2x speedup over our existing OpenGL backend`

Are similar optimizations available for Vulkan/OpenGL or using them will compromise the speed in comparison with OpenCL?"
57860,ERROR: Node number 7 (FlexRaggedTensorToTensor) failed to prepare.,"

```
func setupInterpreter() {
        var options = Interpreter.Options()
        options.threadCount = 1
        do {
            interpreter = try Interpreter(modelPath: tfModelUrl.path)
            try interpreter.allocateTensors()
        } catch let error {
            return
        }
    }
```
```
let outputTensor: Tensor
        do {
            let inputTensor = try interpreter.input(at: 0)
            try interpreter.copy(data, toInputAt: 0)
            try interpreter.invoke()
            outputTensor = try interpreter.output(at: 0)
        } catch {
            print(""Error"", error.localizedDescription)
        }
```

Error Must call allocateTensors().

ERROR: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select

Use instruction https://www.tensorflow.org/lite/guide/ops_select"
