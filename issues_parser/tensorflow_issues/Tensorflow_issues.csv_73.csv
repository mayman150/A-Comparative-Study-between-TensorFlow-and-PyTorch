Issue Number,Issue Title,Issue Body
2546,"""bazel test --config=cuda"" can't find ""libcurand.so.7.5""","For instance (today's head, Bazel 0.2.3 on Ubuntu)
`
bazel test -c opt --config=cuda tensorflow/contrib/distributions:chi2_test
I tensorflow/stream_executor/dso_loader.cc:102] Couldn't open CUDA library libcurand.so.7.5. LD_LIBRARY_PATH: 
`

I'm setting `LD_LIBRARY_PATH=/usr/local/cuda/lib64`, but `bazel test` starts own environment where `LD_LIBRARY_PATH` is empty. Strangely though, it finds libcublas/libcudnn/libcufft which are in the same directory as `libcurand.so.7.5`

A work-around it to set `LD_LIBRARY_PATH`, and run the test harness through Python stub rather than through blaze test

```
export LD_LIBRARY_PATH=""/usr/local/cuda/lib64:$LD_LIBRARY_PATH""
bazel test -c opt --config=cuda tensorflow/contrib/distributions:chi2_test
bazel-bin/tensorflow/contrib/distributions/chi2_test

I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally

```
"
2540,tf.select unnecessarily propagates NaNs in gradients,"tf.select() will give NaN gradients even if the source of the NaNs is not selected. See example script below.

import tensorflow as tf
x = tf.placeholder(tf.float32)
y = tf.select(x>0, 0., tf.exp(x))
z = tf.gradients(y,x)[0]

with tf.Session() as sess:
    yv,zv = sess.run([y,z],{x: 1e10})
    print(yv) # correctly outputs 0
    print(zv) # this is NaN, but should be 0
"
2536,"zlib.h error when compiling tutorials_example_trainer, but zlib is there","### Environment info

Operating System: Red Hat Enterprise Linux Server release 7.2

Installed version of CUDA and cuDNN: CUDA 7, cuDNN 4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

-rw-r--r-- 1 root root 179466 Jan 26 22:19 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jan 26 22:19 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.0
lrwxrwxrwx 1 root root     19 Jan 26 22:19 /usr/local/cuda/lib/libcudart.so.7.0 -> libcudart.so.7.0.28
-rwxr-xr-x 1 root root 303052 Jan 26 22:19 /usr/local/cuda/lib/libcudart.so.7.0.28
-rw-r--r-- 1 root root 546514 Jan 26 22:19 /usr/local/cuda/lib/libcudart_static.a

cuDNN is installed for the local user only.

If installed from sources, provide the commit hash:

b289bc7a50fc0254970c60aaeba01c33de61a728
### Steps to reproduce

I have followed the instructions at: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#requirements 

Since I am not root, I had to install everything for the local user, but it seems to have worked. 

I get an error at this line:

bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

Saying:

ERROR: [...]/vlad/.cache/bazel/_bazel_vlad/6607a39fc04ec931b523fac975ff3100/external/png_archive/BUILD:23:1: Executing genrule @png_archive//:configure failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
[...]/vlad/.cache/bazel/_bazel_vlad/6607a39fc04ec931b523fac975ff3100/tensorflow/external/png_archive/libpng-1.2.53 [...]/vlad/.cache/bazel/_bazel_vlad/6607a39fc04ec931b523fac975ff3100/tensorflow
/tmp/tmp.pCUaj9eIKr [...]/vlad/.cache/bazel/_bazel_vlad/6607a39fc04ec931b523fac975ff3100/tensorflow/external/png_archive/libpng-1.2.53 [...]/vlad/.cache/bazel/_bazel_vlad/6607a39fc04ec931b523fac975ff3100/tensorflow

... a bunch more lines until:

checking for pow... no
checking for pow in -lm... yes
checking for zlibVersion in -lz... no
**configure: error: zlib not installed**
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 57.196s, Critical Path: 22.12s
### What have you tried?

I installed zlib, and the following program compiles with g++

```
#include <cstdio>
#include <zlib.h>

int main()
{
    printf(""Hello world"");
    return 0;
}
```

I have the following in my .bashrc:

export LD_LIBRARY_PATH=""$HOME/local/cuda/lib64:$LD_LIBRARY_PATH""
export LD_LIBRARY_PATH=""$HOME/bin/zlibdev/lib:$LD_LIBRARY_PATH""
export CPATH=""$HOME/local/cuda/include:$CPATH""
export CPATH=""$HOME/bin/zlibdev/include:$CPATH""
export LIBRARY_PATH=""$HOME/local/cuda/lib64:$LIBRARY_PATH""

export PKG_CONFIG_PATH=""$HOME/bin/zlibdev/lib/pkgconfig""

Why can't bazel / tensorflow find zlib.h? It's there and accessible.
"
2535,seq2seq running problem,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Ubuntu 14 
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce
1. copy all files in models/rnn/translate/ to ~/myworkfold/ 
2. run the translate.py like this: python translate.py --data_dir ./ --train_dir ./   ... (it works well )
3. But, when i change the code from ""from tensorflow.model.rnn.translate import seq2seq_model"" to ""import seq2seq_model"" in translate.py (in order to use the file seq2seq.py in myworkfold, note that all files are copied form models/rnn/translate/ wothout any change ) 
   it errors like this:
   Traceback (most recent call last):
   File ""my_translate.py"", line 279, in <module>
     tf.app.run()
   File ""/home/ubuntu/yangqichuan/my_tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
     sys.exit(main(sys.argv))
   File ""my_translate.py"", line 276, in main
     train()
   File ""my_translate.py"", line 142, in train
     model = create_model(sess, False)
   File ""my_translate.py"", line 121, in create_model
     forward_only=forward_only)
   File ""/home/ubuntu/yangqichuan/my_tensorflow/my_seq2seq/my_seq2seq_model.py"", line 152, in **init**
     softmax_loss_function=softmax_loss_function)
   File ""/home/ubuntu/yangqichuan/my_tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 961, in model_with_buckets
     decoder_inputs[:bucket[1]])
   File ""/home/ubuntu/yangqichuan/my_tensorflow/my_seq2seq/my_seq2seq_model.py"", line 151, in <lambda>
     lambda x, y: seq2seq_f(x, y, False),
   File ""/home/ubuntu/yangqichuan/my_tensorflow/my_seq2seq/my_seq2seq_model.py"", line 115, in seq2seq_f
     feed_previous=do_decode)
   TypeError: embedding_attention_seq2seq() takes at least 6 arguments (7 given)
## What have you tried?

1.i do the same operation for model  LSTM models/rnn/ptb . tensorflow works well
2. if i change back the translate.py file it also works well

What happened ?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2533,The docker image of gcr.io/tensorflow/tensorflow-full does not exist,"We follow the [official docs](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker) and try to pull this image but it doesn't exist.

```
root@do:~# docker pull gcr.io/tensorflow/tensorflow-full
Using default tag: latest
Pulling repository gcr.io/tensorflow/tensorflow-full
Tag latest not found in repository gcr.io/tensorflow/tensorflow-full
```

After searching in StackOverflow and we found `b.gcr.io/tensorflow/tensorflow-full` works.
### Environment info

Operating System: Ubuntu 16.10
### Steps to reproduce
1. docker pull gcr.io/tensorflow/tensorflow-full(not work)
### What have you tried?
1. docker pull b.gcr.io/tensorflow/tensorflow-full(work)
"
2532,Tensorflow Anaconda Import Module Error,"1. I installed Anaconda Environment Installation with Python 3.5 for 64-bit on Ubuntu 16.04 LTS
2. I created the conda environment for tensorflow in 3.4 and installed tensorflow 0.8.0 version for python 3. 
3. After activating tensorflow source, I typed in python and imported sklearn & skflow. But it gives me an import error. 
   When I install both sklearn & skflow using pip within activated tensorflow environment. It does work for that session only. After I deactivate and activate again, it starts giving an error again. 
"
2531,Running model failed: executing graph using C++ API,"Hi,

I trained a model using Python API, and saved a standalone GraphDef model using freeze_graph.
And then I execute the graph in C++ enviornment

However, after building the binary file using bazel, it's cannot running correctly:
`E tensorflow/examples/facenet/main.cc:309] Running model failed: Invalid argument: Input 0 of node incept5b/in4_conv1x1_55/batch_norm/cond/ExponentialMovingAverage/AssignMovingAvg_1/Switch was passed float from incept5b/in4_conv1x1_55/batch_norm/cond/incept5b/in4_conv1x1_55/batch_norm/moments/moments_1/variance/ExponentialMovingAverage:0 incompatible with expected float_ref.`

Is there any reason for this failure? Does anyone know how to fix this?
Maybe should add some detailed explanation in C++ API documentation....
Thanks,

The structure of the graph (in python) can be simplified as: (it's used for face recognition).

```
images_placeholder = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, FLAGS.image_size, FLAGS.image_size, 3), name='input')

phase_train_placeholder = tf.placeholder(tf.bool, name='phase_train')

embeddings = faceRecog.inference_nn4_max_pool_96(images_placeholder, phase_train=phase_train_placeholder)



def inference_nn4_max_pool_96(images, phase_train=True):

  conv1 = _conv(images, 3, 64, 7, 7, 2, 2, 'SAME', 'conv1_7x7', phase_train=phase_train, use_batch_norm=True)
  pool1 = _mpool(conv1,  3, 3, 2, 2, 'SAME')
  conv2 = _conv(pool1,  64, 64, 1, 1, 1, 1, 'SAME', 'conv2_1x1', phase_train=phase_train, use_batch_norm=True)
  conv3 = _conv(conv2,  64, 192, 3, 3, 1, 1, 'SAME', 'conv3_3x3', phase_train=phase_train, use_batch_norm=True)
  pool3 = _mpool(conv3,  3, 3, 2, 2, 'SAME')

  incept3a = _inception(pool3,    192, 1, 64, 96, 128, 16, 32, 3, 32, 1, 'max', 'incept3a', phase_train=phase_train, use_batch_norm=True)
  incept3b = _inception(incept3a, 256, 1, 64, 96, 128, 32, 64, 3, 64, 1, 'max', 'incept3b', phase_train=phase_train, use_batch_norm=True)
  incept3c = _inception(incept3b, 320, 2, 0, 128, 256, 32, 64, 3, 0, 2, 'max', 'incept3c', phase_train=phase_train, use_batch_norm=True)

  incept4a = _inception(incept3c, 640, 1, 256, 96, 192, 32, 64, 3, 128, 1, 'max', 'incept4a', phase_train=phase_train, use_batch_norm=True)
  incept4b = _inception(incept4a, 640, 1, 224, 112, 224, 32, 64, 3, 128, 1, 'max', 'incept4b', phase_train=phase_train, use_batch_norm=True)
  incept4c = _inception(incept4b, 640, 1, 192, 128, 256, 32, 64, 3, 128, 1, 'max', 'incept4c', phase_train=phase_train, use_batch_norm=True)
  incept4d = _inception(incept4c, 640, 1, 160, 144, 288, 32, 64, 3, 128, 1, 'max', 'incept4d', phase_train=phase_train, use_batch_norm=True)
  incept4e = _inception(incept4d, 640, 2, 0, 160, 256, 64, 128, 3, 0, 2, 'max', 'incept4e', phase_train=phase_train, use_batch_norm=True)

  incept5a = _inception(incept4e,    1024, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5a', phase_train=phase_train, use_batch_norm=True)
  incept5b = _inception(incept5a, 896, 1, 384, 192, 384, 0, 0, 3, 128, 1, 'max', 'incept5b', phase_train=phase_train, use_batch_norm=True)
  pool6 = _apool(incept5b,  3, 3, 1, 1, 'VALID')

  resh1 = tf.reshape(pool6, [-1, 896])
  affn1 = _affine(resh1, 896, 128)
  if FLAGS.keep_probability<1.0:
    affn1 = control_flow_ops.cond(phase_train,
                                  lambda: tf.nn.dropout(affn1, FLAGS.keep_probability), lambda: affn1)
  norm = tf.nn.l2_normalize(affn1, 1, 1e-10, name='embeddings')

  return norm

```

And in C++, I edit the ""lable_image"" example in tensorflow, and here's the code:

```
#include <fstream>

#include ""tensorflow/cc/ops/const_op.h""
#include ""tensorflow/cc/ops/image_ops.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/core/framework/graph.pb.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/graph/default_device.h""
#include ""tensorflow/core/graph/graph_def_builder.h""
#include ""tensorflow/core/lib/core/errors.h""
#include ""tensorflow/core/lib/core/stringpiece.h""
#include ""tensorflow/core/lib/core/threadpool.h""
#include ""tensorflow/core/lib/io/path.h""
#include ""tensorflow/core/lib/strings/stringprintf.h""
#include ""tensorflow/core/platform/init_main.h""
#include ""tensorflow/core/platform/logging.h""
#include ""tensorflow/core/platform/types.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/util/command_line_flags.h""

// These are all common classes it's handy to reference with no namespace.
using tensorflow::Flag;
using tensorflow::Tensor;
using tensorflow::Status;
using tensorflow::string;
using tensorflow::int32;

// Given an image file name, read in the data, try to decode it as an image,
// resize it to the requested size, and then scale the values as desired.
Status ReadTensorFromImageFile(string file_name, const int input_height,
                               const int input_width, const float input_mean,
                               const float input_std,
                               std::vector<Tensor>* out_tensors) {
  tensorflow::GraphDefBuilder b;
  string input_name = ""file_reader"";
  string output_name = ""normalized"";
  tensorflow::Node* file_reader =
      tensorflow::ops::ReadFile(tensorflow::ops::Const(file_name, b.opts()),
                                b.opts().WithName(input_name));
  // Now try to figure out what kind of file it is and decode it.
  const int wanted_channels = 3;
  tensorflow::Node* image_reader;
  if (tensorflow::StringPiece(file_name).ends_with("".png"")) {
    image_reader = tensorflow::ops::DecodePng(
        file_reader,
        b.opts().WithAttr(""channels"", wanted_channels).WithName(""png_reader""));
  } else {
    // Assume if it's not a PNG then it must be a JPEG.
    image_reader = tensorflow::ops::DecodeJpeg(
        file_reader,
        b.opts().WithAttr(""channels"", wanted_channels).WithName(""jpeg_reader""));
  }
  // Now cast the image data to float so we can do normal math on it.
  tensorflow::Node* float_caster = tensorflow::ops::Cast(
      image_reader, tensorflow::DT_FLOAT, b.opts().WithName(""float_caster""));
  // The convention for image ops in TensorFlow is that all images are expected
  // to be in batches, so that they're four-dimensional arrays with indices of
  // [batch, height, width, channel]. Because we only have a single image, we
  // have to add a batch dimension of 1 to the start with ExpandDims().
  tensorflow::Node* dims_expander = tensorflow::ops::ExpandDims(
      float_caster, tensorflow::ops::Const(0, b.opts()), b.opts());
  // Bilinearly resize the image to fit the required dimensions.
  tensorflow::Node* resized = tensorflow::ops::ResizeBilinear(
      dims_expander, tensorflow::ops::Const({input_height, input_width},
                                            b.opts().WithName(""size"")),
      b.opts());
  // Subtract the mean and divide by the scale.
  tensorflow::ops::Div(
      tensorflow::ops::Sub(
          resized, tensorflow::ops::Const({input_mean}, b.opts()), b.opts()),
      tensorflow::ops::Const({input_std}, b.opts()),
      b.opts().WithName(output_name));

  // This runs the GraphDef network definition that we've just constructed, and
  // returns the results in the output tensor.
  tensorflow::GraphDef graph;
  TF_RETURN_IF_ERROR(b.ToGraphDef(&graph));
  std::unique_ptr<tensorflow::Session> session(
      tensorflow::NewSession(tensorflow::SessionOptions()));
  TF_RETURN_IF_ERROR(session->Create(graph));
  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));
  return Status::OK();
}

// Reads a model graph definition from disk, and creates a session object you
// can use to run it.
Status LoadGraph(string graph_file_name,
                 std::unique_ptr<tensorflow::Session>* session) {
  tensorflow::GraphDef graph_def;
  Status load_graph_status =
      ReadBinaryProto(tensorflow::Env::Default(), graph_file_name, &graph_def);
  if (!load_graph_status.ok()) {
    return tensorflow::errors::NotFound(""Failed to load compute graph at '"",
                                        graph_file_name, ""'"");
  }
  session->reset(tensorflow::NewSession(tensorflow::SessionOptions()));
  Status session_create_status = (*session)->Create(graph_def);
  if (!session_create_status.ok()) {
    return session_create_status;
  }
  return Status::OK();
}


int main(int argc, char* argv[]) {
  // These are the command-line flags the program can understand.
  // They define where the graph and input data is located, and what kind of
  // input the model expects. If you train your own model, or use something
  // other than GoogLeNet you'll need to update these.
  string image = ""tensorflow/examples/facenet/data/img.png"";
 // string image = ""tensorflow/examples/label_image/data/grace_hopper.jpg"";
  string graph =
      ""tensorflow/examples/facenet/data/""
      ""FaceNet.pb"";
  // not necessary for facenet
  // string labels =
  //     ""tensorflow/examples/label_image/data/""
  //     ""imagenet_comp_graph_label_strings.txt"";
  int32 input_width = 96;
  int32 input_height = 96;
  int32 input_mean = 0;
  int32 input_std = 1;
  string input_layer = ""input"";
  string output_layer = ""embeddings"";
  bool self_test = false;
  string root_dir = """";
  const bool parse_result = tensorflow::ParseFlags(
      &argc, argv, {Flag(""image"", &image),                //
                    Flag(""graph"", &graph),                //
                    // Flag(""labels"", &labels),              //
                    Flag(""input_width"", &input_width),    //
                    Flag(""input_height"", &input_height),  //
                    Flag(""input_mean"", &input_mean),      //
                    Flag(""input_std"", &input_std),        //
                    Flag(""input_layer"", &input_layer),    //
                    Flag(""output_layer"", &output_layer),  //
                    Flag(""self_test"", &self_test),        //
                    Flag(""root_dir"", &root_dir)});
  if (!parse_result) {
    LOG(ERROR) << ""Error parsing command-line flags."";
    return -1;
  }

  // We need to call this to set up global state for TensorFlow.
  tensorflow::port::InitMain(argv[0], &argc, &argv);
  if (argc > 1) {
    LOG(ERROR) << ""Unknown argument "" << argv[1];
    return -1;
  }

  // First we load and initialize the model.
  std::unique_ptr<tensorflow::Session> session;
  string graph_path = tensorflow::io::JoinPath(root_dir, graph);
  Status load_graph_status = LoadGraph(graph_path, &session);
  if (!load_graph_status.ok()) {
    LOG(ERROR) << load_graph_status;
    return -1;
  }

  // Get the image from disk as a float array of numbers, resized and normalized
  // to the specifications the main graph expects.
  std::vector<Tensor> resized_tensors;
  string image_path = tensorflow::io::JoinPath(root_dir, image);
  Status read_tensor_status =
      ReadTensorFromImageFile(image_path, input_height, input_width, input_mean,
                              input_std, &resized_tensors);
  if (!read_tensor_status.ok()) {
    LOG(ERROR) << read_tensor_status;
    return -1;
  }
  const Tensor& resized_tensor = resized_tensors[0];

  // Actually run the image through the model.
  std::vector<Tensor> outputs;
  Status run_status = session->Run({{""input"", resized_tensor}},
                                    {""embeddings""}, {}, &outputs);
                                   // {output_layer}, {}, &outputs);
  if (!run_status.ok()) {
    LOG(ERROR) << ""Running model failed: "" << run_status;
    return -1;
  }


  return 0;
}

```

Thanks!
"
2530,Cannot run Tensorflow example for Android on Windows ,"I am trying to run Tensorflow example for Android on an ARM emulator (Android 5.0.1, API 21), but it does not run. What can be the reason for that?

> 05-25 17:14:31.340: E/AndroidRuntime(1189): FATAL EXCEPTION: main 05-25 17:14:31.340: E/AndroidRuntime(1189): Process: org.tensorflow.demo, PID: 1189 05-25 17:14:31.340: E/AndroidRuntime(1189): java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file ""/data/app/org.tensorflow.demo-2/base.apk""],nativeLibraryDirectories=[/vendor/lib, /system/lib]]] couldn't find ""libtensorflow_demo.so"" 05-25 17:14:31.340: E/AndroidRuntime(1189): at java.lang.Runtime.loadLibrary(Runtime.java:366) 05-25 17:14:31.340: E/AndroidRuntime(1189): at java.lang.System.loadLibrary(System.java:989) 05-25 17:14:31.340: E/AndroidRuntime(1189): at org.tensorflow.demo.TensorflowClassifier.(TensorflowClassifier.java:47) 05-25 17:14:31.340: E/AndroidRuntime(1189): at org.tensorflow.demo.TensorflowImageListener.(TensorflowImageListener.java:55) 05-25 17:14:31.340: E/AndroidRuntime(1189): at org.tensorflow.demo.CameraConnectionFragment.(CameraConnectionFragment.java:452) 05-25 17:14:31.340: E/AndroidRuntime(1189): at org.tensorflow.demo.CameraConnectionFragment.newInstance(CameraConnectionFragment.java:271) 05-25 17:14:31.340: E/AndroidRuntime(1189): at org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:33) 05-25 17:14:31.340: E/AndroidRuntime(1189): at android.app.Activity.performCreate(Activity.java:5937) 05-25 17:14:31.340: E/AndroidRuntime(1189): at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1105)
"
2525,the cudnn lib directory is not in the tensorflow gpu docker image's LD_LIBRARY_PATH,"libcudnn4 is installed in the gcr.io/tensorflow/tensorflow:latest-gpu docker image, but I get the following errors from the jupyter tensorflow tutorial:

F tensorflow/stream_executor/cuda/cuda_dnn.cc:204] could not find cudnnCreate in cudnn DSO; dlerror: /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so: undefined symbol: cudnnCreate

running env shows that LD_LIBRARY_PATH does not have a reference to the libcudnn.so location 

```
LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64:
```
"
2523,Incorrect error message,"This error message is out of date:

```
ValueError: Cannot execute operation using Run(): No default session is registered. Use 'with default_session(sess)' or pass an explicit session to Run(session=sess)
```

As far as I can tell, there is no longer any `default_session` function. Instead, one must call `sess.as_default()`.
"
2522,Install instructions for OS X GPU,"With the wonderful addition of #664, installation installation instructions for OS X with GPU support would be very helpful.
"
2521,Retrain.py with multiple GPUs,"I am trying to run **retrain.py** on an AWS GPU instance with 4 K520's. When running **retrain.py** and watching the GPU activity using `nvidia-smi`, it seems like all of the calculations are happening on one GPU. The output looks like:

```
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0      2833    C   python                                        3801MiB |
|    1      2833    C   python                                          37MiB |
|    2      2833    C   python                                          37MiB |
|    3      2833    C   python                                          37MiB |
+-----------------------------------------------------------------------------+

```

However, when I run **cifar10_multi_gpu_train.py** and set `--num_gpus` to 4, the computations are distributed evenly as follows:

```
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0     14226    C   python                                        3841MiB |
|    1     14226    C   python                                        3841MiB |
|    2     14226    C   python                                        3841MiB |
|    3     14226    C   python                                        3841MiB |
+-----------------------------------------------------------------------------+
```

Is there a way to run **retrain.py** on multiple GPUs like on the cifar10_multi_gpu_train.py? If not, is there an easy way to use my own custom images for the **cifar10_multi_gpu_train.py**?
"
2520,Error for using tensorflow on Ubuntu 14:04 with TITAN x,"Operating System:
   ubuntu 14.04
 ======================================================================  
Installed version of CUDA and cuDNN: 
 cuDNN v4 , CUDA 7.5

tensorflow)sal@sal-All-Series:~/tensorflow$ ls -l /home/sal/cuda/lib64/libcud*
lrwxrwxrwx 1 sal sal       15 Aug 21  2015 /home/sal/cuda/lib64/libcudnn.so -> libcudnn.so.7.0
lrwxrwxrwx 1 sal sal       17 Mar  1 18:27 /home/sal/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rw-rw-r-- 1 sal sal 61453024 Mar  1 18:27 /home/sal/cuda/lib64/libcudnn.so.4.0.7
lrwxrwxrwx 1 sal sal       18 Aug 21  2015 /home/sal/cuda/lib64/libcudnn.so.7.0 -> libcudnn.so.7.0.64
-rwxrwxr-x 1 sal sal 48217000 Aug 21  2015 /home/sal/cuda/lib64/libcudnn.so.7.0.64
-rw-rw-r-- 1 sal sal 62025862 Mar  1 18:27 /home/sal/cuda/lib64/libcudnn_static.a
(tensorflow)sal@sal-All-Series:~/tensorflow$ 
# 
1. Virtualenv installation # I am not sure if this the answer
2. (tensorflow)sal@sal-All-Series:~/tensorflow$ python -c ""import tensorflow; print(tensorflow.**version**)
   ""
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64/:/home/sal/torch/install/lib::/usr/local/cuda-7.5/lib64:/opt/OpenBLAS-no-openmp/lib
   I tensorflow/stream_executor/cuda/cuda_dnn.cc:1562] Unable to load cuDNN DSO
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
   0.8.0
   (tensorflow)sal@sal-All-Series:~/tensorflow$ 
# 

I am trying to import tensorflow and use it with my TITAN X GPU and I
I think I have cuda installed as I use it with caffe and Torch7 even though I tried to install it from the beginning but same message I kept receiving. Any help please.

> > > import tensorflow
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib64/:/home/sal/torch/install/lib::/usr/local/cuda-7.5/lib64:/opt/OpenBLAS-no-openmp/lib
> > > I tensorflow/stream_executor/cuda/cuda_dnn.cc:1562] Unable to load cuDNN DSO
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
"
2517,d,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2516,tf.test.compute_gradient returns unexpected analytical Jacobian for complex polynomial,"### Environment info

Operating System: Ubuntu 14.04.4 LTS
Titan X GPU
Python 2.7.11

Installed version of CUDA and cuDNN: Cuda 7.5, cuDNN 5.0.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
(tensorflow)sarroff@eltopo:~$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 59909104 May 22 13:27 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 59909104 May 22 13:27 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 59909104 May 22 13:27 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 58775484 May 22 13:27 /usr/local/cuda/lib64/libcudnn_static.a
```
1. Which pip package you installed.
   N/A (Installed from source)
2. The output from python -c ""import tensorflow; print(tensorflow.__version__)"".

```
(tensorflow)sarroff@eltopo:~$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
```

If installed from sources, provide the commit hash:
4b7bc3174ed67b4a0eb1803537c9d00f132e9ae7
### Steps to reproduce

I have a complex variable z = x+iy and complex polynomial function f(z) = z^2. I am computing df/dz. `tf.gradients` returns the expected value but the returned analytical value of `tf.test.compute_gradient` does not:

(In Python shell, logging messages snipped.)

``` python
>>> import numpy as np
>>> z = np.asarray(np.random.randn() + 1j*np.random.randn(), dtype=np.complex64)
>>> # Value of z
... print z
(-1.15801084042+0.433556616306j)
>>> z_tf = tf.constant(z)
>>> f = z_tf**2
>>> with tf.Session() as sess:
...     analytical, numerical = tf.test.compute_gradient(z_tf, (), f, (), x_init_value=z)
...     df_dz = sess.run(tf.gradients(f, z_tf))
... 
>>> # Expected derivative
... 2*z
(-2.3160216808319092+0.86711323261260986j)
>>> 
>>> # Automatically computed derivative:
... print df_dz
[(-2.3160217+0.86711359j)]
>>> 
>>> # analytical derivative from compute_gradient
... print analytical
[[-2.31602168 -0.86711359]
 [ 0.86711359 -2.31602168]]
>>> 
>>> # numerical derivative from compute_gradient
... print numerical
[[-2.31617689  0.86712837]
 [-0.86700916 -2.31587887]]
```

According to the [TensorFlow API documentation](https://www.tensorflow.org/versions/r0.8/api_docs/python/test.html#compute_gradient), `compute_gradient` returns the analytical and numerical Jacobians

```
J[:m, :n] = d(Re y)/d(Re x)
J[:m, n:] = d(Im y)/d(Re x)
J[m:, :n] = d(Re y)/d(Im x)
J[m:, n:] = d(Im y)/d(Im x)
```

It appears that the analytical Jacobian is incorrect, and more specifically, that `J[:m, n:] = d(Im y)/d(Re x)` and `J[m:, :n] = d(Re y)/d(Im x)` may be swapped.
"
2514,Feature Request: multi-epoch alternative to tf.QueueBase.close(),"Examples on the web demonstrate signaling the end of queue data by calling queue.close() in the data producer and then catching the tf.errors.OutOfRangeError exception in the data consumer.

This works fine for a single epoch, but I do multiple epochs, alternating between training data and testing data, and I can't reuse the queue after calling queue.close().

The two solutions that I have thought of using the existing code are:
1) enqueue() some sentinel at the end of an epoch in the data producer and then tf.Assert() against the sentinel and catch the tf.errors.InvalidArgumentError in the data consumer.
2) know the number of enqueue's for the epoch and only dequeue that number.
Both seem a little hacky.

Multi-epoch use of queues might be simplified by adding one of the following:
1) A queue.reset(), that throws one tf.errors.OutOfRangeError on dequeue() or some other exception.
2) A queue.close(reset=True), that only throws one tf.errors.OutOfRangeError on dequeue() or some other exception.

example usage of 1):

```
q = tf.FIFOQueue(...)
placeholder = ...
enqueue_op = q.enqueue(placeholder)
....

def producer(data_dir, sess, q, enqueue_op, placeholder):
  for ...:
    sess.run(enqueue_op, {placeholder:...})
  sess.run(q.reset())

def do_epoch(data_dir, learn):
  threading.Thread(target=producer, args=(data_dir, sess, q, enqueue_op, placeholder)).start()
  while True:
    try:
      sess.run(...)
    exception tf.errors.OutOfRangeError:
      break

for epoch in range(NUM_EPOCHS):
  ... = do_epoch(TRAIN_DIR, learn=True)
  ... = do_epoch(TEST_DIR, learn=False)
```
"
2513,connect trained inception model to classify_image.py file cannot find pbtxt file,"I have tried the training on flowers, it generated 2 files in /tmp a output_graph.pb and output_labels.txt file, but when i tried connecting these files to classify_image.py file I found the code is reading a .pbtxt apart from .pb and .txt file. How do I use the python code without the pbtxt file. 

find the classify_image code here
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py
"
2512,Problem about 'placeholder' function,"I installed Tensorflow using Pip in Vmware Simulation Machine Ubuntu Operation System with only CPU Evn.

When I used tensorflow in python 2.7:

> > > import tensorflow as tf
> > > x = tf.placeholder(name=""x"")

I met one error:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
TypeError: placeholder() takes at least 1 argument (1 given)

This code is an instance in http://download.tensorflow.org/paper/whitepaper2015.pdf
"
2511,Shape inference crashes in SpaceToBatch when padding input is a persistent tensor,"TLDR; is there a way to turn off shape inference, or allow support SpaceToBatch getting padding from GetSessionTensor op, which has unknown shape?

To reproduce

```
(holder1, input) = tf.get_session_tensor(tf.float32)
(holder2, paddings) = tf.get_session_tensor(tf.int32)
tf.space_to_batch(input, paddings, 2)


TypeError: 'NoneType' object has no attribute '__getitem__'

```
1. SpaceToBatch inputs are GetSessionTensor ops.
2. `_SpaceToBatchShape` calls tensor_util.constant_value
3. that goes to _ConstantValue which checks op.type, and returns None since GetSessionTensor not recognized
4. That goes back to `_SpaceToBatchShape` and crashes with
   TypeError: 'NoneType' object has no attribute `'__getitem__'`
   in this line because paddings is None

```
  paddings = tensor_util.constant_value(op.inputs[1])
  if (paddings[0, 0] < 0 or paddings[0, 1] < 0 or
      paddings[1, 0] < 0 or paddings[1, 1] < 0):
    raise ValueError(""paddings cannot be negative."")

```

I got this when trying to use atrous convolution

```
File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/contrib/immediate/python/immediate/ops/nn_test.py"", line 304, in testAtrousSequence
    y1 = tf.nn.atrous_conv2d(x, f, rate, padding=padding)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/python/ops/nn_ops.py"", line 205, in atrous_conv2d
    block_size=rate)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/python/ops/gen_array_ops.py"", line 1471, in space_to_batch
    block_size=block_size, name=name)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/contrib/immediate/python/immediate/op.py"", line 315, in apply_op
    **keywords)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/python/ops/op_def_library.py"", line 702, in apply_op
    op_def=op_def)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/python/framework/ops.py"", line 2188, in create_op
    set_shapes_for_outputs(ret)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/python/framework/ops.py"", line 1635, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/contrib/immediate/nn_test.runfiles/tensorflow/python/ops/array_ops.py"", line 1632, in _SpaceToBatchShape
    if (paddings[0, 0] < 0 or paddings[0, 1] < 0 or
TypeError: 'NoneType' object has no attribute '__getitem__'

```
"
2510,Tensorboard feature request - Text summary,"Would it be reasonable to add a basic text summary feature to Tensorboard? Personally I've run my network a few dozen times with really minor changes between them for testing and it would be really useful if there was a field where I could put some arbitrary text where I just wrote the key differences in my runs.

For example, on the Events page (or somewhere else) there would be a dropdown, similar to the summaries on the Events and Histograms page, with text I added (either hardcoded or as a script argument) that says what I did differently this run. Maybe I would print out the argument values for each run as well, that would be pretty useful, but basically something where I can say ""What did I do with this run again? Why was it different than the one before? Oh yeah I changed the batch size"" or ""Oh yeah I used my other dataset instead.""

Obviously if it's arbitrary text you could maybe use it to write up a description of the network or whatever you want. 
"
2508,Can't place tf.nn.moments() on GPU ,"While trying to optimize training of a network by moving most work to the GPU, I encountered the following error below.  Although this references a variable defined in the batch_normalization helper class I've used, removing that class (replacing all calls to it with an identify function) results in a similar error elsewhere.

```
Traceback (most recent call last):
  File ""train_resnet.py"", line 106, in <module>
    tf.app.run()
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""train_resnet.py"", line 103, in main
    run_training()
  File ""train_resnet.py"", line 97, in run_training
    sess.run(tf.initialize_all_variables())
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 333, in run
    run_metadata_ptr)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 573, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 648, in _do_run
    target_list, options, run_metadata)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 668, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'gradients/resnet_module_1/bn/moments/moments/mean_ss_grad/Maximum/y': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
         [[Node: gradients/resnet_module_1/bn/moments/moments/mean_ss_grad/Maximum/y = Const[_class=[""loc:@resnet_module_1/bn/moments/moments/mean_ss""], dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 1>, _device=""/device:GPU:0""]()]]
Caused by op 'gradients/resnet_module_1/bn/moments/moments/mean_ss_grad/Maximum/y', defined at:
  File ""train_resnet.py"", line 106, in <module>
    tf.app.run()
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""train_resnet.py"", line 103, in main
    run_training()
  File ""train_resnet.py"", line 89, in run_training
    train_op = opt.minimize(loss, colocate_gradients_with_ops=True, aggregation_method=2)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 193, in minimize
    grad_loss=grad_loss)
  File ""/data/Ray/policy_network/gpu/clipopt.py"", line 9, in compute_gradients
    *args, **kwargs)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py"", line 250, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py"", line 481, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py"", line 41, in _SumGrad
    tile_scaling = _safe_shape_div(input_shape, output_shape_kept_dims)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py"", line 33, in _safe_shape_div
    return x // math_ops.maximum(y, 1)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1173, in maximum
    result = _op_def_lib.apply_op(""Maximum"", x=x, y=y, name=name)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 455, in apply_op
    as_ref=input_arg.is_ref)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 620, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/constant_op.py"", line 166, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1224, in __init__
    self._traceback = _extract_stack()

...which was originally created as op 'resnet_module_1/bn/moments/moments/mean_ss', defined at:
  File ""train_resnet.py"", line 106, in <module>
    tf.app.run()
[elided 1 identical lines from previous traceback]
  File ""train_resnet.py"", line 103, in main
    run_training()
  File ""train_resnet.py"", line 77, in run_training
    depth=FLAGS.num_features)
  File ""train_resnet.py"", line 45, in model
    model = res_3x3_pair(model, depth, ""resnet_module_{}"".format(idx + 1), training_switch, keep_prob_var)
  File ""train_resnet.py"", line 29, in res_3x3_pair
    normed = tf.nn.relu(batch_norm(data, depth, training_switch))
  File ""/data/Ray/policy_network/gpu/batchnorm.py"", line 22, in batch_norm
    batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/nn.py"", line 712, in moments
    name=name)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/nn.py"", line 649, in sufficient_statistics
    m_ss = math_ops.reduce_sum(m_ss, axes, keep_dims=keep_dims, name=""mean_ss"")
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 909, in reduce_sum
    keep_dims, name=name)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 2087, in _sum
    keep_dims=keep_dims, name=name)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/thouis/VENV35/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1224, in __init__
    self._traceback = _extract_stack()
```
### Environment info

Operating System: Ubuntu 16.06

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root 189170 May 24 11:22 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 May 24 11:22 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 May 24 11:22 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 May 24 11:22 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 May 24 11:22 /usr/local/cuda/lib/libcudart_static.a
```

If installed from binary pip package, provide:

pip installed from May 25 nightly build of Linux GPU version.

```
python -c ""import tensorflow; print(tensorflow.__version__)""
0.8.0
```
### Steps to reproduce
- grab python files from https://gist.github.com/thouis/9bbd330a153b1f553fd58743a3ae4c9a
- `python -u -i train_resnet.py --learning_rate 0.005  --num_modules 16 --num_features 192 --summary_dir Workspace --checkpoint_dir Workspace --batch_size 64`
### What have you tried?
1. I tried to cast the values in _safe_shape_div() to int64 in case that was the underlying cause, but that seemed to cause different problems.
### Logs or other output that would be helpful

All files (python, run log) at:
https://gist.github.com/thouis/9bbd330a153b1f553fd58743a3ae4c9a
"
2507,Build Model in Python and Run in Java Example,"How would one go about doing this, and are there any examples? 
"
2505,No mod for int32 no GPU kernel support,"I apologize if this is not actually a issue. When trying to put tf.reduce_mean() on the gpu, I get the following error:

```
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'gradients/Mean_grad/mod': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
         [[Node: gradients/Mean_grad/mod = Mod[T=DT_INT32, _device=""/device:GPU:0""](gradients/Mean_grad/add, gradients/Mean_grad/Size)]]
```

I am on commit 43a8c49f04a485ffc33b510c27eda77f8f38377c from Tue 5/24/2016.

You can reproduce this by modifying the mnist/convolutional.py file by putting the tf.reduce_mean() and optimizer.minimize() inside ""with tf.device('/gpu:0'):"" statements.

I am trying to do gradient calculations on their respective gpu towers, but compute_gradients() gets hung up on tf.reduce_mean().

Thank you,
Mark
"
2502,Method to check for GPU op support,"So, given the basic word2vec example being bound to CPU (#514), we can see that `tf.nn.embedding_lookup` doesn't work on GPU. Therefore, ops that use `embedding_lookup` internally doesn't support GPU either (for example, `nce_loss`).
Can we have explicit info in the documentation on which operations are currently GPU-capable and which are not?
For example, are `tf.gather` or `LogUniformCandidateSampler` GPU-capable?
"
2501,nan values management in max_pool,"Hi,

I faced a strange behavior using the max_pool op, returning -3.40282347e+38 when Nan are provided.
A simple example run on CPU is shown bellow:

```

import tensorflow as tf
import numpy as np
x = tf.placeholder(tf.float32, [None, 2, 1, 1])
pool = tf.nn.max_pool(x, ksize=[1, 2, 1, 1], strides=[1,2,1,1], padding='VALID')
sess = tf.Session()
sess.run(tf.initialize_all_variables())
data = np.empty((1, 2, 1, 1))
data[:] = np.NAN
print sess.run(pool, feed_dict={x: data})

[[[[ -3.40282347e+38]]]]
```

Is there any reason for returning this arbitrary value? I feel much more comfortable with conv2D behavior which returns NaN in similar situations. I guess this behavior should be mentioned within the documentation.

Regards,
"
2500,Test fail: //tensorflow_serving/session_bundle:session_bundle_py_test,"http://ci.bazel.io/job/TensorFlow_Serving/BAZEL_VERSION=HEAD,PLATFORM_NAME=linux-x86_64/115/console

```
____From Testing //tensorflow_serving/session_bundle:session_bundle_py_test: 
====================
Test output for //tensorflow_serving/session_bundle:session_bundle_py_test: .E. 
====================================================================== 
ERROR: 
testBasic (__main__.SessionBundleLoadTest)
 ---------------------------------------------------------------------- 
Traceback (most recent call last): 
File ""/home/ci/.cache/bazel/_bazel_ci/e409f7152fa45ddf3337f1660b5273b9/execroot/linux-x86_64/bazel-out/local-fastbuild/bin/tensorflow_serving/session_bundle/session_bundle_py_test.runfiles/tf_serving/tensorflow_serving/session_bundle/session_bundle_test.py"", line 39, in testBasic base_path, target="""", config=tf.ConfigProto(device_count={""CPU"": 2})) 
File ""/home/ci/.cache/bazel/_bazel_ci/e409f7152fa45ddf3337f1660b5273b9/execroot/linux-x86_64/bazel-out/local-fastbuild/bin/tensorflow_serving/session_bundle/session_bundle_py_test.runfiles/tf_serving/tensorflow_serving/session_bundle/session_bundle.py"", line 57, in LoadSessionBundleFromPath meta_graph_filename) 
RuntimeError: Expected meta graph file missing /home/ci/.cache/bazel/_bazel_ci/e409f7152fa45ddf3337f1660b5273b9/execroot/linux-x86_64/bazel-out/local-fastbuild/bin/tensorflow_serving/session_bundle/session_bundle_py_test.runfiles/tensorflow_serving/session_bundle/example/half_plus_two/00000123/export.meta
 ---------------------------------------------------------------------- 
Ran 3 tests in 0.001s FAILED (errors=1) 
================================================================================
```
"
2499,Fedora 23: build fails with missing libcudart.so.7.5 without `--genrule_strategy=standalone`,"Hi, this is a continuation of Issue #2053, because that one was closed for no apparent reason.

Compiling the GPU version of the `tutorials_example_trainer` target fails on Fedora 23 with the message:

```
bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc: error while loading shared libraries: libcudart.so.7.5: cannot open shared object file: No such file or directory
Target //tensorflow/cc:tutorials_example_trainer failed to build
```

When using the command line

```
path/to/bazel/output/bazel build -c opt --config=cuda -j 4 //tensorflow/cc:tutorials_example_trainer
```

When adding `--genrule_strategy=standalone`, the compilation succeeds.

I believe that either the Documentation should be updated to include this flag, or that the build system is changed to pass it automatically.
"
2497,Setting up TensorFlow for Development broken on Linux,"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md

TLDR;
instead of
`ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .
`
I had to do
`ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/__main__/* .
`
Ubuntu 15.04, bazel-0.2.3, week-old TensorFlow from head

On MacOS, Bazel 0.2.1-homebrew, the command that works is `ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/* .`
"
2496,"tf.pad docstring is missing description of the ""mode"" argument","The docstring gives examples of using ""CONSTANT"", ""REFLECT"" and ""SYMMETRIC"" modes, but never describes what they actually are.

For example:
- What value is used to pad in constant mode? (The answer is 0.)
- What exactly is the difference between REFLECT and SYMMETRIC? (I don't know.)
"
2494,Saver.save inconsistently throws InvalidArgumentError with Batch Normalization,"Hi,

First off - thanks for releasing TensorFlow. It is immensely helpful in many ways (e.g. getting it working on my GPU was a breeze). However, because of its novelty I'm running into a problem I cannot just Google.

After adding batch normalization to the code for a variational autoencoder found here:
https://github.com/tensorflow/tensorflow/issues/new

saver.save() starts crashing inconsistently (sometimes it will save, sometimes it will crash). The error is unhelpful, so I'm not sure what is wrong (see error logs below).

I call the saver as follows:

```
    saver = tf.train.Saver()
        with tf.Session(graph=vae.graph) as sess:

            tf.train.SummaryWriter(""/tmp/vae_logs"", sess.graph)
            init = tf.initialize_all_variables()
```
### Environment info

Operating System:
Ubuntu 15.10

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root   322936 aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 apr  3 10:09 /usr/local/cuda-7.5/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 apr  3 10:09 /usr/local/cuda-7.5/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 apr  3 10:09 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 apr  3 10:09 /usr/local/cuda-7.5/lib64/libcudnn_static.a

```

If installed from binary pip package, provide:
1. Which pip package you installed.

```
pip freeze 
tensorflow==0.8.0
```
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

```
 print(tensorflow.__version__)
0.8.0
```

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Adapted the code from https://github.com/arahuja/generative-tf/tree/master/generative-tf for a Variational Autoencoder for Gaussian decoders
   (this works fine)
2. Added batch normalization:
   Added the following to variational_autoencoder.py in def **init**:

```
if self.batch_normalized:
                self.scale_decoder = tf.Variable(tf.ones([hidden_dim], name=""decoder_scale""))
                self.beta_decoder  = tf.Variable(tf.zeros([hidden_dim], name=""decoder_beta""))

                self.scale_encoder = tf.Variable(tf.ones([hidden_dim], name=""encoder_scale""))
                self.beta_encoder  = tf.Variable(tf.zeros([hidden_dim], name=""encoder_beta"" ))
```
1. Added the following to the _generate and _encode functions (changing the different variables of course):

```
if self.batch_normalized:
                layer_output = tf.matmul(z, self._decoder_W) + self._decoder_bias
                batch_mean, batch_var = tf.nn.moments(layer_output, axes=[0])
                epsilon = 1e-4
                batch_normalized = tf.nn.batch_normalization(layer_output, batch_mean, batch_var, self.beta_decoder, self.scale_decoder, epsilon, name=""normalization_decoder"")
                h = self.activation_func(batch_normalized)

```
1. Now sometimes the saver throws a very cryptic 'InvalidArgumentError', but it is unclear to me why.
### What have you tried?
1. Changed the names that I store the models in (does not help)
2. Turned off Batch normalization (helps)
3. Went through source code trying to track the error; but got stuck (not sure what protobuf does).
4. Tried using less or more epochs (does not help)

Is this a known bug?

Best regards
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```

Traceback (most recent call last):
  File ""train_mnist_vae.py"", line 374, in <module>
    batch_normalized=args.bn
  File ""train_mnist_vae.py"", line 212, in train_test_mnist_vae
    save_path = saver.save(sess, os.path.join(""saved_models/"", model_path + "".ckpt""))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1039, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: saved_models/bern=False_bn=True_bs=100_ds=frey_epochs=40000_ff=True_hd=300_iw=False_ld=2_lr=1e-05_mm=0_0_nt=2000_opt=rmsprop_wd=0_1.ckpt.tempstate10425989302811289116
     [[Node: save/save = SaveSlices[T=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/save/tensor_names, save/save/shapes_and_slices, Variable/_48233, Variable/RMSProp/_48235, Variable/RMSProp_1/_48237, Variable_1/_48239, Variable_1/RMSProp/_48241, Variable_1/RMSProp_1/_48243, Variable_2/_48245, Variable_2/RMSProp/_48247, Variable_2/RMSProp_1/_48249, Variable_3/_48251, Variable_3/RMSProp/_48253, Variable_3/RMSProp_1/_48255, decoderB/_48257, decoderB/RMSProp/_48259, decoderB/RMSProp_1/_48261, decoderW/_48263, decoderW/RMSProp/_48265, decoderW/RMSProp_1/_48267, encoderB/_48269, encoderB/RMSProp/_48271, encoderB/RMSProp_1/_48273, encoderW/_48275, encoderW/RMSProp/_48277, encoderW/RMSProp_1/_48279, log_var_decoder/_48281, log_var_decoder/RMSProp/_48283, log_var_decoder/RMSProp_1/_48285, log_var_decoder_b/_48287, log_var_decoder_b/RMSProp/_48289, log_var_decoder_b/RMSProp_1/_48291, log_var_encoder/_48293, log_var_encoder/RMSProp/_48295, log_var_encoder/RMSProp_1/_48297, log_var_encoder_b/_48299, log_var_encoder_b/RMSProp/_48301, log_var_encoder_b/RMSProp_1/_48303, mean_decoder/_48305, mean_decoder/RMSProp/_48307, mean_decoder/RMSProp_1/_48309, mean_decoderB/_48311, mean_decoderB/RMSProp/_48313, mean_decoderB/RMSProp_1/_48315, mean_encoder/_48317, mean_encoder/RMSProp/_48319, mean_encoder/RMSProp_1/_48321, mean_encoderB/_48323, mean_encoderB/RMSProp/_48325, mean_encoderB/RMSProp_1/_48327)]]
Caused by op u'save/save', defined at:
  File ""train_mnist_vae.py"", line 374, in <module>
    batch_normalized=args.bn
  File ""train_mnist_vae.py"", line 81, in train_test_mnist_vae
    saver = tf.train.Saver()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 833, in __init__
    restore_sequentially=restore_sequentially)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 501, in build
    save_tensor = self._AddSaveOps(filename_tensor, vars_to_save)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 197, in _AddSaveOps
    save = self.save_op(filename_tensor, vars_to_save)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 149, in save_op
    tensor_slices=[vs.slice_spec for vs in vars_to_save])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/io_ops.py"", line 172, in _save
    tensors, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 341, in _save_slices
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 661, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()
```
"
2492,seq2seq decoding after training in the same script,"According to [FAQ](https://www.tensorflow.org/versions/r0.8/resources/faq.html), when session is closed, the model should be removed. 

However, when trying to test the seq2seq model in TensorFlow 0.7.1 right after training (in a different session, but within the same python script), an error appears.

Specifically, [rnn/translate/translate.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py)

I add `decode()` function after training in order to not re-run the script for decoding:

```
def main(_):
   train()
   decode()
```

After training I get the following error message:

>  ValueError: Over-sharing: Variable embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding already exists, disallowed. Did you mean to set reuse=True in VarScope?

[Log file with error](https://github.com/tensorflow/tensorflow/files/280063/error_translate.txt)

When running decoding separately, this code works fine. So, I am just confused why closing training session and opening a new one for decoding makes the program stuck...does it mean some model variables are not removed when session closes?
"
2491,Buggy exit/termination after a couple of iterations ,"Buggy execution after a couple of iterations. I am running python3.5 on a mac and the model quits. Not sure if this is a compatibility issue with the Py3.5 site packages. Help appreciated! Thanks 

Average loss at step  100000 :  4.67189269698
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 699, in runfile
 execfile(filename, namespace)
File ""/Users/kg/anaconda/lib/python3.5/site-packages/spyderlib/widgets/externalshell/sitecustomize.py"", line 88, in execfile
    exec(compile(open(filename, 'rb').read(), filename, 'exec'), namespace)
  File ""/Users/kg/TF/trial_cnn.py"", line 243, in <module>
    low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 866, in fit_transform
    embedding = self._fit(X)
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 777, in _fit
    skip_num_points=skip_num_points)
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 832, in _tsne
    params, error, it = _gradient_descent(obj_func, params, **opt_args)
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 387, in _gradient_descent
    grad_norm = linalg.norm(grad)
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/scipy/linalg/misc.py"", line 129, in norm
    a = np.asarray_chkfinite(a)
  File ""/Users/kg/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py"", line 1022, in asarray_chkfinite
    ""array must not contain infs or NaNs"")
ValueError: array must not contain infs or NaNs
"
2489,New added variables cannot be saved,"I tested by running these 3 pieces of code respectively.

First, init some variables and save.

```
import tensorflow as tf

sess = tf.InteractiveSession()
v1 = tf.Variable(1,name=""v1"")
v2 = tf.Variable(2,name=""v2"")
sess.run(tf.initialize_all_variables())
saver = tf.train.Saver()
saver.save(sess,'v12.ckpt')
```

Then, restore the session, add one more variable, and save.

```
import tensorflow as tf

sess = tf.InteractiveSession()
v1 = tf.Variable(1,name=""v1"")
v2 = tf.Variable(2,name=""v2"")
saver = tf.train.Saver()
saver.restore(sess,'v12.ckpt')  #works fine here

v3 = tf.Variable(3,name=""v3"")
sess.run(tf.initialize_variables([v3]))

saver.save(sess,'v123.ckpt')

print v3.eval() #show value without problem
```

Then, restore them.

```
import tensorflow as tf

sess = tf.InteractiveSession()
v1 = tf.Variable(1,name=""v1"")
v2 = tf.Variable(2,name=""v2"")
v3 = tf.Variable(3,name=""v3"")

saver = tf.train.Saver()
saver.restore(sess,'v123.ckpt') #error here
```

This is the error:

```
tensorflow.python.framework.errors.NotFoundError: Tensor name ""v3"" not found in checkpoint files v123.ckpt [[Node: save/restore_slice_2 = RestoreSlice[dt=DT_INT32, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_2/tensor_name, save/restore_slice_2/shape_and_slice)]] Caused by op u'save/restore_slice_2'
```

What is the problem here?

I'm using version r0.8 on Ubuntu16.04
"
2488,change cudnn from v5 to v4,"  Hi there,
Currently I'm using cuDNN v5, which is not supported for tensorflow via pip install.

I dont want to install tf from source code.

so is there any way that I could sort of down-grading cudnn from v5 to v4?

Thanks!
"
2487,regression in skflow monitoring code,"Using the version [pip_gpu version #100](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/100), I noted that a corrected issue by ilblackdragon ([#2063](https://github.com/tensorflow/tensorflow/issues/2063)) re-occurred and a PR from him self [Ref #2063](https://github.com/ilblackdragon/tensorflow/commit/534deda849e389ea625cc3abca632177c95b9534#diff-0ac50f1931e3fc2819c02d8767edb1d3R29) has disappeared in the master code.

Could the issue be corrected and the enhancement reintegrated ?
Cordially 
"
2486,Problem in header file,"On this [line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/core/status.h#L22). 
The file `error_codes.pb.h` is not present.
"
2484,Importing tensorflow and PIL conflict.,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: 
 cat /etc/*-release
DISTRIB_ID=LinuxMint
DISTRIB_RELEASE=17.2
DISTRIB_CODENAME=rafaela
DISTRIB_DESCRIPTION=""Linux Mint 17.2 Rafaela""
NAME=""Ubuntu""
VERSION=""14.04.4 LTS, Trusty Tahr""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 14.04.4 LTS""
VERSION_ID=""14.04""
HOME_URL=""http://www.ubuntu.com/""
SUPPORT_URL=""http://help.ubuntu.com/""
BUG_REPORT_URL=""http://bugs.launchpad.net/ubuntu/""
cat: /etc/upstream-release: Is a directory

If installed from binary pip package, provide:
1. 1.5.4
2. Tensorflow version: 0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce

In python.

import tensorflow as tf
from PIL import Image
imageis = Image.open(""Image.jpeg"")
imageis.load()

produces this error. 
IOError: broken data stream when reading image file
### What have you tried?

In order to fix this error, you have to import PIL first. 
from PIL import Image
import tensorflow as tf
imageis = Image.open(""Image.jpeg"")
imageis.load()

and everything works fine. 
### Logs or other output that would be helpful

I wanted to submit this issue just in case someone else is affected by it. It took me a few hours to solve as i was searching my system for corrupt dependencies.
"
2483,I got a problem with Tensorflow installation mac,"https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#on-macosx

I followed the all instructions for mac installation
![screen shot 2016-05-24 at 8 49 07 am](https://cloud.githubusercontent.com/assets/19249239/15487984/a0fe6182-218c-11e6-9f75-2697ff446ac5.png)

After I typed ""import tensorflow as tf"" this shows some error but no idea what those lines mean..

Need help
"
2482,Tensor board installing issue with docker,"Hi I'm a new tensor flow installer~
I do not have any experienced with docker or tensor flow and i followed this web-cite 

http://www.netinstructions.com/how-to-install-and-run-tensorflow-on-a-windows-pc/

https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#requirements

![1](https://cloud.githubusercontent.com/assets/19249239/15487824/30c4a332-218b-11e6-8017-6b51cc276439.PNG)

[this screen stopped after showing this image]

![2](https://cloud.githubusercontent.com/assets/19249239/15487829/398ded3e-218b-11e6-8ac8-3bb39792301a.PNG)

[I do not know what they are doing in actual cmd line but it does not work]

Those are the stops I got stock.  can anyone help?
"
2480,Building TensorFlow with CMake,"I realize that building TensorFlow from CMake is not yet ready for prime time, but I am attempting to push through some of the challenges and issues getting that working on a Mac.
### Environment info

Operating System: Mac, OS X 10.11.5
Using CMake to create a make file (not interested in trying this with XCode yet)
Not currently using CUDA

Installed from sources, commit hash: 787b97e6
### Steps to reproduce

There are some issues with paths to eigen, json and re2 that I have been able to work around but I have run into a roadblock.

Several .cc files in tensorflow/core/framework/ directory attempt to include files that do not exist. The files to be included all end with "".pb_text.h"". I assume that these files are (or should be) generated by the protocol buffer compiler. 

For example, from tensorflow/core/framework/attr_value_util.cc:

```
#include ""tensorflow/core/framework/attr_value.pb_text.h""
#include ""tensorflow/core/framework/tensor.pb_text.h""
```

As a result I get ""file not found"" errors when building.
### What have you tried?

There are some files in tensorflow/contrib/cmake/build/tensorflow/core/framework with similar names (like attr_value.pb.h and tensor.b.h) which I assume are generated by the protocol buffer compiler. I modified the .cc files which were causing trouble to include these files:

```
#include ""tensorflow/core/framework/attr_value.pb.h""
#include ""tensorflow/core/framework/tensor.pb.h""
```

That results in errors related to using undeclared identifiers: 

.../tensorflow/tensorflow/core/framework/attr_value_util.cc:44:28: error: use of undeclared
      identifier 'ProtoShortDebugString'
                           ProtoShortDebugString(tensor_proto), "">"");

.../tensorflow/tensorflow/core/framework/attr_value_util.cc:62:14: error: use of undeclared
      identifier 'EnumName_DataType'
      return EnumName_DataType(attr_value.type());

(and so on)
"
2476,Feature request: RMSPropOptimizer support for sparse gradients,"I use RMSPropOptimizer to optimize parameters, I get NotImplementedError. **But when I change to use AdamOptimizer, it works fine.**

So I try to fix the problem and I find some key point, may be it can help.
Here is my code:

```
self.x = tf.placeholder(tf.int32, [None, sequence_length])  
point = tf.get_variable([len(embedding_matrix)])
............
............
outputs, states = rnn.rnn(lstm_cell, x, initial_state=initial_state, sequence_length=real_length)
index     =    self.x[:, 0]
index  = tf.reshape(index, [-1,1])
index_point  =    tf.gather(pointt, index)
output   =  tf.mul(outputs[-1] ,   index_point)

scores = tf.nn.xw_plus_b(output, self.W, b)
losses = tf.nn.softmax_cross_entropy_with_logits(scores, self.input_y)
self.loss = tf.reduce_mean(losses) 
optimizer = tf.train.RMSPropOptimizer(1e-3, decay = 0.9)
grads_and_vars = optimizer.compute_gradients(self.loss)
self.train_op = optimizer.apply_gradients(grads_and_vars)
```

When I try to change the line `output   =  tf.mul(outputs[-1] ,   index_point)` to some others such as `output   =  tf.mul(outputs[-1] ,   2)`, **the error disappear**. And I try to change to use `bidirectional_rnn`, **the error also disappear.**
"
2475,NotImplementedError when I use RMSPropOptimizer,"I am try to use RMSPropOptimizer to optimize parameters and I get NotImplementedError. **But when I try AdamOptimizer, it works fine**. 

**BTW, when I try to find the problem, it seems I find the key point:**
Here is part of my code:

```
self.x = tf.placeholder(tf.int32, [None, sequence_length])  
point = tf.get_variable( [vocabulary_size])
........
........
outputs, states = rnn.rnn(lstm_cell, x_vec, initial_state=initial_state, sequence_length = self.real_length)
index     =    self.x[:, 0]
index  = tf.reshape(index, [-1,1])
index_point  =    tf.gather(point, index)
output   =  tf.mul(outputs[-1] ,   index_point)
```

The key point is last line `output   =  tf.mul(outputs[-1] ,   index_point)`, when I change `index_point` to some others such as number `1`, **the error disappear**.
And, when I try to use `bidirectional_rnn`, **the error also can disappear**.
"
2474,Issue with deep dream example,"I get this error when creating the session in the Deep Dream notebook example without any modifications. Does anybody know what does exactly mean?
Input: 

```
sess = tf.InteractiveSession(graph=graph)
```

Output

```
Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x1128b5990>> ignored
Exception AssertionError: AssertionError() in <generator object get_controller at 0x1128a5af0> ignored
```

Thanks,
Manu
"
2473,Dynamic use of tensorflow.python.ops.array_ops.space_to_batch,"When calling ""tensorflow.python.ops.array_ops.space_to_batch"" in Python I need to specify the padding at compile time. In my use case I calculate the padding in the computation graph. Therefore it fails when I use a tensor as padding. I attached the stacktrace:

```
/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc in space_to_batch(input, paddings, block_size, name)
   1636   result = _op_def_lib.apply_op(""SpaceToBatch"", input=input,
   1637                                 paddings=paddings, block_size=block_size,
-> 1638                                 name=name)
   1639   return result
   1640 

/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
    691           op = g.create_op(op_type_name, inputs, output_types, name=scope,
    692                            input_types=input_types, attrs=attr_protos,
--> 693                            op_def=op_def)
    694           outputs = op.outputs
    695           return _Restructure(ops.convert_n_to_tensor(outputs),

/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2186                     original_op=self._default_original_op, op_def=op_def)
   2187     if compute_shapes:
-> 2188       set_shapes_for_outputs(ret)
   2189     self._add_op(ret)
   2190     self._record_op_seen_by_control_dependencies(ret)

/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   1640       raise RuntimeError(""No shape function registered for standard op: %s""
   1641                          % op.type)
-> 1642   shapes = shape_func(op)
   1643   if len(op.outputs) != len(shapes):
   1644     raise RuntimeError(

/home/user/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.pyc in _SpaceToBatchShape(op)
   1630 
   1631   paddings = tensor_util.constant_value(op.inputs[1])
-> 1632   if (paddings[0, 0] < 0 or paddings[0, 1] < 0 or
   1633       paddings[1, 0] < 0 or paddings[1, 1] < 0):
   1634     raise ValueError(""paddings cannot be negative."")
TypeError: 'NoneType' object has no attribute '__getitem__'
```

I think it has something to do with the Python shape op. If so how can I override the existing shape op to test a new one with dynamic calculation?
"
2472,distributed tensorflow mnist example hang at prepare_or_wait_for_session() ,"I tried both Distributed [tensorflow](https://www.tensorflow.org/versions/r0.8/how_tos/distributed/index.html) and [minist_softmax.py.txt](https://github.com/tensorflow/tensorflow/files/271770/mnist_softmax.py.txt). They both hang at the prepare_or_wait_for_session() function with non-chief worker tasks.

task_index == 0(chief worker ) can run as expected.
I can not find out the reasion why it behaves like this. 
Can anyone please give some advice?
"
2471,per_process_gpu_memory_fraction didn`t work,"per_process_gpu_memory_fracion Option didn't work in follow code.

gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)
sess = sv.prepare_or_wait_for_session(server.target,                                            config=tf.ConfigProto(gpu_options=gpu_options))
"
2470,per_process_gpu_memory_fraction didn',"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2467,conv3d_backprop_input,"I'm using `conv3d_backprop_input` to implement a 3d version of `tf.nn.conv2d_transpose`. Unlike `conv2d_backprop_input`, `conv3d_backprop_input` requires an `input` tensor (rather than just `input_shape`), and this seems a little inconsistent. I don't have the input tensor because it is actually the deconvolution output in this case. My current solution is to create a dummy tensor like the following:

``` python
def conv3d_transpose(value, filter, output_shape, strides, padding='SAME', name=None):
  dummy_tensor = tf.zeros(shape=output_shape, dtype=value.dtype)

  deconv = tf.nn.conv3d_backprop_input(input=dummy_tensor, filter=filter,
      out_backprop=value, strides=strides, padding=padding, name=name)

  return deconv
```

So my question is, in `conv3d_backprop_input`, do the values of `input` actually matter or is it only used to infer the shape of the output `deconv`?
"
2466,Feature request: tensordot,"I found one useful tensor operation ""tensordot"" is missing in tensorflow. [Theano has an implementation of it](http://deeplearning.net/software/theano/library/tensor/basic.html). It would be great to have tensordot also in tensorflow.
"
2465,Multidimennsionnal input for LSTM Issues,"I have a series of multdimensionnal time series as follow:

Input Xi   i=1..N samples
Xi=[y1,..yk..., yT] K=1..T , yk is a vector, T= 50 (sequence length) with yk= [yk1, ... ykm] m=3 with ykj : Float or Int

Using LSTM Tensor Flow,would like to predict the next step (T+1), given the training of samples like :

Xi=[y1,...., yT]`
The current code gives input form for m=1 (unidimensionnal Y),

input_data = tf.placeholder(tf.float32, [batchSize, numSteps, numInputs])
targets = tf.placeholder(tf.float32, [batchSize, numSteps, numInputs])
Wondering if there is a way to input data if m=2, 3 in the LSTM tensor flow ?

If not, is there a workaround to input multdimensionnal time series ?

Or new devs needs to be done in RNN ?
"
2464,Inconsistent tensor shapes in documentation for tf.nn.sampled_softmax_loss,"Hi,

In the documentation for tf.nn.sampled_softmax_loss (as viewed [here](https://www.tensorflow.org/versions/master/api_docs/python/nn.html#sampled_softmax_loss)) it says the equivalent full softmax probabilities can be computed using `tf.nn.softmax(tf.matmul(inputs, weights) + biases)`. However, under 'Args' it also states that `inputs` has shape `batch_size, dim` and `weights` has shape `[num_classes, dim]`  The dimensions of these tensors are incompatible for matrix multiplication.

I suspect that the _actual_ equivalent operation would be something like `tf.nn.softmax(tf.matmul(inputs, tf.transpose(weights)) + biases)` but I'm not 100% sure.
"
2463,Using `tf.nn.rnn_cell.LSTMCell` with `tf.nn.rnn` breaks when `state_is_tuple` is True,"### Environment info

Operating System: mac

If installed from sources, provide the commit hash: 7d9ab3eb485e6eb1778bad4ef01a1cd95b2d22d9
### Steps to reproduce

Creating an rnn based on a list of cell specified by `MultiRNNCell` breaks at the `zero_state` function:

``` python
num_units = 3
input_size = 5
num_proj = 4
max_length = 8
sequence_length = [4, 6]
initializer = tf.random_uniform_initializer(-0.01, 0.01)
inputs = max_length * [tf.placeholder(tf.float32, shape=(None, input_size))]
inputs_c = tf.pack(inputs)
cell = tf.nn.rnn_cell.LSTMCell(num_units, input_size, use_peepholes=True,
                               num_proj=num_proj, initializer=initializer, 
                               state_is_tuple=True)
cells = tf.nn.rnn_cell.MultiRNNCell([cell] * 2, state_is_tuple=True)
outputs_static, state_static = tf.nn.rnn(cells, inputs, dtype=tf.float32, 
                                         sequence_length=sequence_length)
```

The same model definition would work if `state_is_tuple=False`, the code break at this [line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L107)

The same code would work if we pass the cell directly to `tf.nn.rnn` i.e. without using `tf.nn.rnn_cell.MultiRNNCell`, the reason is that `tf.nn.rnn_cell.MultiRNNCell` would have a `state_size` value as tuple of tuples, in my example the value of the `state_size` is `<type 'tuple'>: ((3, 4), (3, 4))`
### What have you tried?

.1. Tried the same model definition without `state_is_tuple=False`, which works but shows a deprication warning.

``` python
num_units = 3
input_size = 5
num_proj = 4
max_length = 8
sequence_length = [4, 6]
initializer = tf.random_uniform_initializer(-0.01, 0.01)
inputs = max_length * [tf.placeholder(tf.float32, shape=(None, input_size))]
inputs_c = tf.pack(inputs)
cell = tf.nn.rnn_cell.LSTMCell(num_units, input_size, use_peepholes=True,
                               num_proj=num_proj, initializer=initializer)
cells = tf.nn.rnn_cell.MultiRNNCell([cell])
outputs_static, state_static = tf.nn.rnn(cells, inputs, dtype=tf.float32, 
                                         sequence_length=sequence_length)
```

.2. Tried the same model definition with `state_is_tuple=True` and without `tf.nn.rnn_cell.MultiRNNCell`, which works.

``` python
num_units = 3
input_size = 5
num_proj = 4
max_length = 8
sequence_length = [4, 6]
initializer = tf.random_uniform_initializer(-0.01, 0.01)
inputs = max_length * [tf.placeholder(tf.float32, shape=(None, input_size))]
inputs_c = tf.pack(inputs)
cell = tf.nn.rnn_cell.LSTMCell(num_units, input_size, use_peepholes=True,
                               num_proj=num_proj, initializer=initializer, 
                               state_is_tuple=True)
outputs_static, state_static = tf.nn.rnn(cell, inputs, dtype=tf.float32, 
                                         sequence_length=sequence_length)
```
### Logs or other output that would be helpful

```
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 123, in rnn
    state = cell.zero_state(batch_size, dtype)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 109, in zero_state
    for s in state_size)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 109, in <genexpr>
    for s in state_size)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 249, in pack
    return gen_array_ops._pack(values, name=name)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1126, in _pack
    result = _op_def_lib.apply_op(""Pack"", values=values, name=name)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 704, in apply_op
    op_def=op_def)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1696, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 439, in _PackShape
    input_shape = input_shape.merge_with(inp.get_shape())
  File ""/Users/mourad/.virtualenvs/ca/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 554, in merge_with
    (self, other))
ValueError: Shapes () and (2,) are not compatible
```
"
2462,Why is there no support for directly computing cross entropy?,"I see that we have methods for computing softmax and sigmoid cross entropy, which involve taking the softmax or sigmoid of the logit vector and then computing cross entropy with the target, and the weighted and sparse implementations of these. But what if I simply want to compute the cross entropy between 2 vectors?
"
2461,Server restarts silently on kubernetes and variables reset after restart,"### Environment info

Operating System:
Kubernetes with default images
### Steps to reproduce

Hard to reproduce due to lack of log
### Logs or other output that would be helpful

The kubernetes status:

```
NAME               READY     STATUS    RESTARTS   AGE
tf-ps2-l2ka8       1/1       Running   0          3h
tf-ps4-2jmuf       1/1       Running   1          3h
tf-worker1-fm1t8   1/1       Running   1          3h
tf-worker3-ujd7h   1/1       Running   0          3h
tf-worker5-ymx71   1/1       Running   0          3h
```

The log regarding restarted parameter server:

```
zeyu@perhaps:~$ kubectl logs -p tf-ps4-2jmuf
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {tf-worker1:2222, tf-worker3:2222, tf-worker5:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {tf-ps2:2222, localhost:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222
```

The log of current running server: (almost the same)

```
zeyu@perhaps:~$ kubectl logs  tf-ps4-2jmuf
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {tf-worker1:2222, tf-worker3:2222, tf-worker5:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {tf-ps2:2222, localhost:2222}
I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:2222
```

As the result of the restart, the global count  reset to 0 and the running log looks like:

```
Training step 269, global step 802
Training step 270, global step 805
Training step 271, global step 808
Training step 272, global step 810
Training step 273, global step 3
Training step 274, global step 6
Training step 275, global step 12
Training step 276, global step 19
Training step 277, global step 22
Training step 278, global step 27
Training step 279, global step 32
```

Is there any way that I can materialize the variables (like hostpath or persistent disk?) so that they won't be affected by restarts?
"
2460,set_random_seed with a value too large for an int fails during later call to random(),"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN:  No CUDA

If installed from sources, provide the commit hash: 7d9ab3eb485e6eb1778bad4ef01a1cd95b2d22d9
### Steps to reproduce

``` python
import tensorflow as tf
tf.set_random_seed(2 ** 70)
sess = tf.InteractiveSession()
tf.random_normal((1,)).eval()
```

Fails with ""Value out of range"" exception on eval. 

I'd would prefer that it would either fail on `tf.set_random_seed` or just truncate the seed to fit into the field (as this would be semantically correct behavior). Which one should be a correct one? I'd like to make a PR to fix it.
"
2459,,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
System-XPS-L321X:~$ python
Python 2.7.11+ (default, Apr 17 2016, 14:00:29) 
[GCC 5.3.1 20160413] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.

> > > import tensorflow
> > >  ()
"
2458,"Graph ""Training/Test"" flag & global_flags","I am not sure if this has been proposed yet, but I would like the ability in the .RUN() op to flag ""test"" rather than ""train"".  The motivation is around ""Dropout"".  When I am training a batch I would like the dropout in my graph, but when I am running a ""test"" I would like the Dropout to simply pass the tensor (0% dropout if you will).  I am sure I can pass the ""dropout"" as a param through the feeder but they need to be set and reset each time and could get cumbersome for larger and complex graphs.  It would be nice to have an internal feature in ""Dropout"" and other Training specific features such that they will adjust their behavior if ""Not-Training"".

Right now I have a graph that has 2 paths, one for training with the Dropouts Ops in-line and one that does note and I call the proper 'Output' based upon my Test/Training desire.  This complicated the graph.

Maybe this function can be extended to pass ""Flags"" into the graph so other features can be added that are based upon run-time demand.  This ""flag_dict"" could be global to the entire graph so Ops' could check their status upon a run.

`sess.run([cost,optimizer,merged], 
                                                                 feed_dict={X: Xbatch,
                                                                 Y: YDesired}, flag_dict={Training: True})`

I can think of another request where this would be useful.  As I search solution space, I would like to setup a Genetic Algorithm to assist.  One of the things I would like to change in each graph iteration might be the ""activation"", ""Cost"" and/or ""optimizer"" functions.  So a generic Activation Op or Optimizer op could be written (are maybe a simple ""Case"" Op based upon the flag)?

eg. `flag_dict={Training: True, Activation: Relu, Optimizer: AdagradOptimizer}`

Not sure how to deal with the parameters if they differ from Op to Op.  But maybe ""custom global flags"" could be passed as well. 

eg.  `layer2out    = tf.nn.genericActivation(layer1out,ActivationFlag=Activation)   #Activation=Relu from above`

Just a thought to help explore during training/testing.
"
2457,external/png_archive/BUILD:23:1: Executing genrule @png_archive//:configure failed: bash failed,"### Environment info

Operating System:
Red Hat 4.8.3-9

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
/usr/local/cuda-7.5/ 
cudnn-7.5-linux-x64-v5.0-ga-tgz
libcudnn.so.5

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Getting bazel from https://github.com/bazelbuild/bazel/archive/0.2.3.tar.gz
2. On 18, May , I Get tensor flow via git clone --recurse-submodules https://github.com/tensorflow/tensorflow
3. Running command /home/admin/bazel/bazel_source/bazel-0.2.3/output/bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures, I got error
   external/png_archive/BUILD:23:1: Executing genrule @png_archive//:configure failed
### What have you tried?
1.  After I modified external/png_archive/BUILD:30 by adding CPPFLAGS=\""-I /usr/local/zlib/usr /include\""; LDFLAGS=\""-L /usr/local/zlib/lib64\"" in cmd, it would get the error ""external/png_archive/BUILD:33:1: C++ compilation of rule '@png_archive//:png' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
   (cd /home/admin/.cache/bazel/_bazel_admin/b33b4c76bea799d489291f7bcf5433ae/tensorflow && \
   exec env - \
     PATH=/sbin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/X11R6/bin:/home/zy80232/.local/bin:/home/zy80232/bin \
   third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 -iquote external/png_archive -iquote bazel-out/host/genfiles/external/png_archive -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/host/genfiles/external/png_archive/libpng-1.2.53 -isystem external/bazel_tools/tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers '-frandom-seed=bazel-out/host/bin/external/png_archive/_objs/png/external/png_archive/libpng-1.2.53/pngwutil.o' -MD -MF bazel-out/host/bin/external/png_archive/_objs/png/external/png_archive/libpng-1.2.53/pngwutil.d -c external/png_archive/libpng-1.2.53/pngwutil.c -o bazel-out/host/bin/external/png_archive/_objs/png/external/png_archive/libpng-1.2.53/pngwutil.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
   In file included from external/png_archive/libpng-1.2.53/pngwutil.c:16:0:
   external/png_archive/libpng-1.2.53/png.h:548:18: fatal error: zlib.h""
2. Then I added one extra line in png_archive/BUILD:38 by copts = [""-Iexternal/zlib/usr/include""], and I get the error  ""/home/admin/.cache/bazel/_bazel_admin/b33b4c76bea799d489291f7bcf5433ae/external/png_archive/BUILD:33:1: undeclared inclusion(s) in rule '@png_archive//:png':
   this rule is missing dependency declarations for the following files included by 'external/png_archive/libpng-1.2.53/pngwio.c':
   'external/zlib/usr/include/zlib.h'
   'external/zlib/usr/include/zconf.h'""
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2456,Problem in distributed parameter server,"### Environment info

Running the distributed tensorflow on GCE kubernetes cluster using the [demo](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/scripts/dist_mnist_test.sh) with the default images.
### Steps to reproduce
1. Run the demo with [hidden_units](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L69) = 100
2. Run the demo with  [hidden_units](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/python/mnist_replica.py#L69) = 500
### What have you tried?
1. Restart all the pods (this worked)
### Logs or other output that would be helpful

```
Traceback (most recent call last):
  File ""/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py"", line 250, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py"", line 203, in main
    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 685, in prepare_or_wait_for_session
    config=config, init_feed_dict=self._init_feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 163, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]
     [[Node: layer2/weights/Variable/Assign = Assign[T=DT_FLOAT, _class=[""loc:@layer2/weights/Variable""], use_locking=true, validate_shape=true, _device=""/job:ps/replica:0/task:1/cpu:0""](layer2/weights/Variable, layer2/weights/truncated_normal_S19)]]
Caused by op u'layer2/weights/Variable/Assign', defined at:
  File ""/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py"", line 250, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py"", line 157, in main
    y = nn_layer(hidden1, FLAGS.hidden_units, 10, 'layer2', act=tf.nn.softmax)
  File ""/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py"", line 115, in nn_layer
    weights = weight_variable([input_dim, output_dim])
  File ""/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py"", line 85, in weight_variable
    return tf.Variable(initial)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 209, in __init__
    dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 308, in _init_from_args
    validate_shape=validate_shape).op
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 40, in assign
    use_locking=use_locking, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()
```

The error happened at the init time, and it seems that the log suggests the parameter server didn't clean up the information from previous job:

```
tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]
```
"
2455,Adding a New Op Error:  can not load the customed file,"### Environment info

Operating System:  Ubuntu 14.04 LTS

Installed version of CUDA and cuDNN: None 

If installed from binary pip package, provide:
1. Which pip package you installed.
   I use the command below to install tensorflow.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0
### What have you tried?

I have tried to create my new operation, but there was something wrong that made me fail to load the self-defined_tensorflow_op.so. Here are steps which are exactly the same as those in the official tutorial and what I have tried. 
1. Copy the whole content from the official tutorial to create a  file named tensorflow/core/user_ops/zero_out.cc . What is the file is as following.
   
   ```
   #include ""tensorflow/core/framework/op.h""
   
   REGISTER_OP(""ZeroOut"")
       .Input(""to_zero: int32"")
       .Output(""zeroed: int32"");
   
   \#include ""tensorflow/core/framework/op_kernel.h""
   
   using namespace tensorflow;
   
   class ZeroOutOp : public OpKernel {
    public:
     explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}
   
     void Compute(OpKernelContext* context) override {
       // Grab the input tensor
       const Tensor& input_tensor = context->input(0);
       auto input = input_tensor.flat<int32>();
   
       // Create an output tensor
       Tensor* output_tensor = NULL;
       OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),
                                                        &output_tensor));
       auto output = output_tensor->template flat<int32>();
   
       // Set all but the first element of the output tensor to 0.
       const int N = input.size();
       for (int i = 1; i < N; i++) {
         output(i) = 0;
       }
   
       // Preserve the first input value if possible.
       if (N > 0) output(0) = input(0);
     }
   };
   
   REGISTER_KERNEL_BUILDER(Name(""ZeroOut"").Device(DEVICE_CPU), ZeroOutOp);
   ```
2. Then I compile the zero_out.cc with following commands:
   
   ```
   TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')
   
   g++ -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC -I $TF_INC
   ```
3. Trying not to miss anything, I also create the BUILD file and run the corresponding commands.
   
   ```
   \# Here is the BUILD file
   load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")
   
   tf_custom_op_library(
       name = ""zero_out.so"",
       srcs = [""zero_out.cc""],
   )
   
   \# Then run this command
   $ bazel build -c opt //tensorflow/core/user_ops:zero_out.so
   ```
4. When I try to use the new op, the error comes out. 
       # Run in python 2.7.11, with following command
       import tensorflow as tf
       zero_out_module = tf.load_op_library('zero_out.so')
### Here is the error message

```
    Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
        File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py"", line 71, in load_op_library
            raise errors._make_specific_exception(None, None, error_msg, error_code)
            tensorflow.python.framework.errors.NotFoundError: zero_out.so: cannot open shared object file: No such file or directory
```

Please help me out with this. I have spent lots of time trying to figure out what is wrong and searching for the answer, but nothing works. Any advice is also will welcome. Thanks 
"
2454,Suggestion: adding Tags or descriptions to the run log,"Hi!

So far, I I have to say that TensorBoard is a really great tool to analyze the training procedure.
However, I often find myself comparing various runs and wondering ""wait, which version of my code was that and which parameters did I use?"".
Currently, the only way to ""document"" a Run is the name of the log directory - so I find myself encoding all kinds of cryptic acronyms into the directory name.

What would be really awesome is some sort of feature that allows the training scripts to pass Data to the TensorBoard logs. This could be in any form, maybe as sort of ""tags"" or as key-value pairs, or simply as a plain old string called ""description"" or something.

Is this something that sounds useful to others as well? Is this feasible?
"
2453,Building from local docker File,"### Environment info

Operating System:Docker / Win7 64bits

Following instructions here:
https://docs.docker.com/windows/step_four/

Using this docker file:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/Dockerfile

We build the tensorflow file for installation:

We had this error message:
Step 7 : COPY jupyter_notebook_config.py /root/.jupyter/
lstat jupyter_notebook_config.py: no such file or directory

How to solve this issue ?
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2452,ImportError: No module named 'tensorflow',"I downloaded tensorflow using Anacaonda environment installation (I use python 3.5). When I enter `import tensorflow as tf` it always shows the message: ""ImportError: No module named 'tensorflow' Can someone please help me resolve this issue? 
"
2451,Compile Issue about Eigen,"I want to compile tensorflow-r0.8 while meet an issue about Eigen.
This issue happened in both CPU and GPU version. 

The error log is 

```
ERROR: /home/wangbing/Git/tensorflow/tensorflow/core/kernels/BUILD:274:1: C++ compilation of rule '//tensorflow/core/kernels:mirror_pad_op' failed: gcc failed: error executing command 
  (cd /home/wangbing/.cache/bazel/_bazel_wangbing/ab8decc7da56ae5392500261af1cc855/tensorflow && \
  exec env - \
    PATH=/home/wangbing/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/wangbing/bin \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/local-opt/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -DTENSORFLOW_USE_EIGEN_THREADPOOL -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/mirror_pad_op/tensorflow/core/kernels/mirror_pad_op.o' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/mirror_pad_op/tensorflow/core/kernels/mirror_pad_op.d -c tensorflow/core/kernels/mirror_pad_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/mirror_pad_op/tensorflow/core/kernels/mirror_pad_op.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 4.
gcc: internal compiler error: Killed (program cc1plus)
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-4.8/README.Bugs> for instructions.
Target //tensorflow/cc:tutorials_example_trainer failed to build
```

Then I run that command by myself,and get the error as below

```
angbing@wangbing-MS-7996:~/Git/tensorflow$ /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/local-opt/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -DTENSORFLOW_USE_EIGEN_THREADPOOL -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/mirror_pad_op/tensorflow/core/kernels/mirror_pad_op.o' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/mirror_pad_op/tensorflow/core/kernels/mirror_pad_op.d -c tensorflow/core/kernels/mirror_pad_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/mirror_pad_op/tensorflow/core/kernels/mirror_pad_op.o
In file included from ./tensorflow/core/kernels/mirror_pad_op.h:19:0,
                 from tensorflow/core/kernels/mirror_pad_op.cc:20:
./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:67: fatal error: eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/Tensor: No such file or directory
 #include ""eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/Tensor""
```

It seems that a eigen model can not be found.  How can I fix it?
"
2450,gradient check,"Hi I have some problem to write new tensorflow op.<br>
I use tf.test.compute_gradient_error to write the test case. <br>
And get the error <br>
The error message <br>

> FAIL: test_grad (**main**.ZeroOut2Test) Traceback (most recent call
> last):   File ""test_case.py"", line 42, in test_grad
>     self.assertLess(err, 1e-4) AssertionError: 0.0072760284 not less than 0.0001

I already differential on f(data,truthdata).
How to write correct gradient calculate?<br>

The op have two inputs and two output.<br>
Input1 data<br>
Input2 truthdata<br>
output1 loss<br>
output2 delta(gradient)<br>
<br>
Here is the op code

```
#include ""tensorflow/core/framework/op.h""

REGISTER_OP(""DetectionOut"")
    .Attr(""T: {float}"")
    .Input(""detect: T"")
    .Input(""truthdata: T"")
    .Output(""loss: T"")
    .Output(""delta: T"");


#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

typedef Eigen::ThreadPoolDevice CPUDevice;
typedef Eigen::GpuDevice GPUDevice;

template <typename Device, typename T>
class DetectionOutOp : public OpKernel {
 public:
  explicit DetectionOutOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the input tensor
    const Tensor& input_tensor = context->input(0);
    auto PreDetection = input_tensor.flat<T>();

    const Tensor& input_tensor1 = context->input(1);
    auto TruthData = input_tensor1.flat<T>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, TensorShape({input_tensor.dim_size(0)}),
                                                     &output_tensor));
    auto loss = output_tensor->template flat<T>().setZero();

    Tensor* output_tensor1 = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(1, input_tensor.shape(),
                                                     &output_tensor1));
    auto back_detl = output_tensor1->template flat<T>().setZero();

    const int N = PreDetection.size();

    const int64 batch_size_ =  input_tensor.dim_size(0);
    const int64 bottom_count_ = input_tensor.dim_size(1);
    int b,i;
    for (b = 0; b < batch_size_ ; ++b){
        int index = b * bottom_count_;
        for (i = 0; i < bottom_count_; ++i) {
            loss(b) +=  pow(PreDetection(index+i)-TruthData(index+i), 2);
            back_detl(index+i) = 2 *(PreDetection(index+i) - TruthData(index+i));
        }
    }
  }
};

#define REGISTER_KERNEL(T)                                      \
  REGISTER_KERNEL_BUILDER(                                      \
      Name(""DetectionOut"").Device(DEVICE_CPU).TypeConstraint<T>(""T""), \
      DetectionOutOp<CPUDevice, T>);

REGISTER_KERNEL(float);
#undef REGISTER_KERNEL
```

Here is TestCase.py<br>
    import tensorflow as tf
    import numpy as np

```
from tensorflow.python.framework import ops
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import sparse_ops

D2Test = np.zeros((2,7*7*(15)),float) 
D2Truth = np.zeros((2,7*7*(15)),float) 

items = 1
coord = 4
num = 2
class_num = 5
localsize = 49

object_index = (class_num) * localsize + items
tobject_index = (class_num) * localsize + items

D2Truth[0,tobject_index] = 1.0
D2Test[0,object_index] = 0.5


@ops.RegisterGradient(""DetectionOut"")
def _detection_out_grad(op, grad, grad1):
  mat = op.outputs[1]
  vec = array_ops.expand_dims(grad, -1)
  vec = vec * mat
  return [vec, None]

detection_module = tf.load_op_library('detection.so')

class ZeroOut2Test(tf.test.TestCase):
  def test_grad(self):
    with self.test_session():
      shape=(2,7*7*(15))
      shape1=(2,)
      x = tf.constant(D2Test, dtype=tf.float32)
      y = tf.constant(D2Truth, dtype=tf.float32)
      result = detection_module.detection_out(x,y)
      err = tf.test.compute_gradient_error(x, shape, result[0], shape1)
      self.assertLess(err, 1e-4)

if __name__ == '__main__':
  tf.test.main()
```

Thanks for help to correct my errors
"
2448,Session got stuck after fork,"Version: nightly prebuilt for Python2 w/ GPU (just now)

I'm expecting the following code to print ""10.0"" 3 times, but session.run got stuck in all forked processes.

``` python
import tensorflow as tf
import multiprocessing as mp
import os

class Worker(mp.Process):
    def __init__(self, gid):
        self.gid = gid
        super(Worker, self).__init__()

    def run(self):
        G = tf.Graph()
        with G.as_default():
            x = tf.placeholder(tf.float32, shape=[])
            y = x * 2
            sess = tf.Session()
            print sess.run(y, feed_dict={x: 5})

G = tf.Graph()
with G.as_default():
    sess = tf.Session()
    with sess.as_default():
        x = tf.placeholder(tf.float32, shape=[])
        y = x * 2
        print sess.run(y, feed_dict={x: 5})

procs = [Worker(k) for k in range(2)]
for p in procs: p.start()
for p in procs: p.join()
```

Removing the graph/session in master process will solve the problem. So it seems like once there is a session, we cannot use fork?
The problem exists with and without GPU.

NOTE:  this code doesn't terminate normally. You'll probably need to manually kill the forked processes after the master exited. 
"
2447,TensorFlow segfaults on attempting to save a large variable,"The checkpoint format writes the value of a variable into a Protocol Buffer, which has a 2GB limit. The saving mechanism does not validate the size of a variable&mdash;which can be much larger than 2GB&mdash;before attempting to write it into the Protocol Buffer. The following code can cause a segfault:

``` python
with tf.Session("""") as sess:
  # Declare a variable of size 4GB.                                                                                                                    
  var = tf.Variable(tf.zeros([1024, 1024, 1024], dtype=tf.float32))
  save = tf.train.Saver({var.op.name: var})
  var.initializer.run()
  save.save(sess, save_path)
```
"
2444,"Reinforcement Learning can be really, really slow in tensorflow.","I was looking at applying DeepMind's [DDPG algorithm](http://arxiv.org/pdf/1509.02971.pdf) to the new OpenAI gym problem set, focusing on continuous control problems like: [the pendulum](https://gym.openai.com/evaluations/eval_I3x3s4DuS7CmIbpaTCs51w)

I noticed that a TensorFlow version of the algorithm was running about 10-20x slower than a theano version of the same algorithm.

[Tensorflow implementation](https://github.com/nivwusquorum/tensorflow-deepq/blob/continuous/tf_rl/controller/continuous_deepq.py)  (but with a couple bugs fixed)
[Theano implementation](https://github.com/scroyston/rllab/blob/master/rllab/algos/ddpg.py)

When I started profiling both implementations in detail, I noticed there were huge performance difference even when just comparing the forward pass of the actor neural network.

I built a quick script to just compare a forward pass of a layered net, varying the layer depth and layer breadth (code and results below), and using a ""mini batch"" size of 64.  (For reference, in Deepmind's DDPG paper, they used a network of 2 hidden layers, sized 400 and 300, mini batch size of 64).
Using the handy tf.RunOptions.FULL_TRACE, it showed 99% of the cost was in running the ops themselves (vs op scheduling, startup time, etc).

I then stumbled on a couple of settings that seemed to help:
    config_proto.intra_op_parallelism_threads = 1
    config_proto.inter_op_parallelism_threads = 1

That seemed to improve things a bunch, to where tensorflow was as fast in a couple instances, or ""only"" 2-3x slower.

Before finding the threading flags, I started looking at speeding up the individual ops. In MatMulOp I replaced the eigen matrix multiply call with a blas call.  That also seemed to help quite a bit.

Below are some chart of the performance delta vs Theano.
""EigenMultiThread"" is just vanilla tensorflow. 
""EigenSingleThread"" is tensorflow with intra/inter op_parallelism = 1. 
""BlasSingleThread is the same as ""EigenSingleThread"", with the eigen matrix multiply replaced by blas.
The data that makes up these charts can be [found here](https://docs.google.com/a/rgmadvisors.com/spreadsheets/d/1EU9xPFUqELDpRnFUOJUKCDNjm977sUC7AAM29iCwfgc/pubhtml).

![depth2](https://cloud.githubusercontent.com/assets/620227/15438353/62156fc2-1e91-11e6-9b22-5c7cf04aef91.png)
![depth4](https://cloud.githubusercontent.com/assets/620227/15438368/795d2698-1e91-11e6-979e-ea341f5d6720.png)
![depth6](https://cloud.githubusercontent.com/assets/620227/15438371/7d03b064-1e91-11e6-9589-33ccf83b926f.png)
![depth8](https://cloud.githubusercontent.com/assets/620227/15438374/80979718-1e91-11e6-8f88-ecdfeff44fef.png)

I primarily ran these tests on a mac pro (with avx).  I did compile tensorflow with the avx flag.  I also spot checked these results on a linux box and got similar results.  Blas implementation was OpenBlas

I guess my issue/question is: Is there any ongoing work to improve performance for Reinforcement Learning scenarios like these, especially on CPUs? 

I have heard DeepMind is moving completely to tensorflow, and they used/are using the new TPU chips. However, they also got a huge performance boost in runtime and error rate over GPUs by [using 16 normal cores asynchronously](http://arxiv.org/pdf/1602.01783v1.pdf) (which btw, I don't think I can set the threading options to 1 and have an [implementation](https://github.com/muupan/async-rl) still work).
### Environment info

Operating System: 
OS X 10.11.4,  3.5 GHz 6-Core Intel Xeon E5
and
Fedora 20, 12 physical cores, Xeon X5670  @ 2.93GHz

Installed version of CUDA and cuDNN: 
None

If installed from binary pip package, provide:
Tried both a release version:
pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl

and from source, commit hash:
371d341c7ef22d38b80235bbcb5a6e230546781c
compile command:
bazel build -c opt --copt=-mavx //tensorflow/tools/pip_package:build_pip_package
(for the Xeon E5 machine)
### Steps to reproduce
1. I used the script below to generate the numbers
   [tf_perf_test.py.zip](https://github.com/tensorflow/tensorflow/files/275280/tf_perf_test.py.zip)
"
2443,ImportError: cannot import name grid_rnn,"Docker - Tensor Flow Latest 
### Steps to reproduce

When typing:    from tensorflow.contrib import grid_rnn

i have this message:
ImportError: cannot import name grid_rnn

How can download the contrib part into tensorFlow Docker (in windows) ?

Thanks
"
2441,Understanding cause of bad performance,"I am training a convnet with multilple gpus and was using the cifar10 model as an example. It computes the gradients in every tower, stitches them and averages them. But that is mathematically equivalent to defining `total_loss = tf.add_n(tower_loss_list)` so I thought I would just do that.
But this implementation with 2 gpus runs at 1/2 the speed of the single gpu implementation. I am guessing the reason is that the gradient ops placement is very bad, and forces a lot data to be moved around.
Do you also think that is the reason?
If so, what could be done to improve the automatic device assignment?
"
2439,Plots in tensorboard overlay when change horizontal axis,"## Problem

When using tensorboard, if the axis is changed from 'step' to 'relative' and back to 'step' quickly a new graph is created and overlays the original one.  This looks confusing as in the images below.  Note that the issue can be cleared by refreshing the page.

Small graph, both of the graphs shown here have an extra graph overlayed.
![alt text](https://www.breadboardkiller.com.au/img/misc/tensorboard_issue_2.png)
If the graph is expanded, the old graph stays small and the new graph is enlarged showing the double graph issue more clearly.
![alt text](https://www.breadboardkiller.com.au/img/misc/tensorboard_issue_1.png)
### Environment info

Operating System: Fedora release 23
Tensorflow Version: 0.7.1
### Steps to reproduce
1. Run tensorboard from a directory with some tensorflow summary files.
2. Open tensorboard in on the 'Events' page.
3. Quickly change the 'Horizontal Axis' from 'Step' to 'Relative' and back to 'Step' (ie. all within < 1 second)
4. Graphs are now reproduced as described above.
### Workaround

Just refresh the page if you accidentally do this.  
Would be worth fixing if somebody is aware of the code responsible and it's an easy enough fix.
"
2437,Loaded cudnn library: 4007 but source was compiled against 4004,"when I install the tensorflow from souces in my ubuntu14.04 system, a cudnn version does not match  problem happened.
Omit some fine steps, the following is my installation steps:
### 1.Configure the cuda installation,  CUDA 7.5 and cudnn v4.0.7  have been chosen:

root@node4:/home/zhouzhiqiang/tensor_5_9/tensorflow# ./configure 
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 4.0.7
Please specify the location where cuDNN 4.0.7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 
Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Setting up CUPTI include
Setting up CUPTI lib64
Configuration finished
### 2. Create the pip package and install

bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

sudo pip install /tmp/tensorflow_pkg/tensorflow-0.8.0-py2-none-any.whl
### After the installation, The following example was carried out:

python tensor_5_9/tensorflow/tensorflow/models/image/alexnet/alexnet_benchmark.py
### Log for printing:

E tensorflow/stream_executor/cuda/cuda_dnn.cc:286] Loaded cudnn library: 4007 but source was compiled against 4004.  If using a binary install, upgrade your cudnn library to match.  If building from sources, make sure the library loaded matches the version you specified during compile configuration.
W tensorflow/stream_executor/stream.cc:301] attempting to perform DNN operation using StreamExecutor without DNN support
Traceback (most recent call last):
  File ""tensor_5_9/tensorflow/tensorflow/models/image/alexnet/alexnet_benchmark.py"", line 236, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""tensor_5_9/tensorflow/tensorflow/models/image/alexnet/alexnet_benchmark.py"", line 232, in main
    run_benchmark()
  File ""tensor_5_9/tensorflow/tensorflow/models/image/alexnet/alexnet_benchmark.py"", line 221, in run_benchmark
    time_tensorflow_run(sess, pool5, ""Forward"")
  File ""tensor_5_9/tensorflow/tensorflow/models/image/alexnet/alexnet_benchmark.py"", line 177, in time_tensorflow_run
    _ = session.run(target)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 332, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 572, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 652, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 672, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InternalError: cuDNN launch failure : input shape([128,3,225,225]) filter shape([11,11,3,64])
         [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 4, 4, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Variable/read, conv1/weights/read)]]
### Print notes that cudnn version  does not match, but in reality,  I haven't installed cudnn v4.0.4 and  cudnn v4.0.7 is configured  at installation time. Does anyone know why?
"
2433,Feature needed: configuration file,"Is there any configuration file which can be used to configure the default behavior such as which gpu device to use and so on? Just like the .theanorc file in package Theano? If there isn't, I hope some one can add this feature in the future code.
"
2432,Feature Request: Staircase function,"Right now for learning rates we have `exponential_decay`, which is useful but doesn't handle fine-tuned scheduling. For example, regardless of whether we did this manually or with `exponential_decay`, there'd be boilerplate code to use a learning rate of 1.0 for 100000 steps, 0.5 for the next 10000 steps, and 0.1 for all remaining steps.

This could be handled with a staircase function, maybe with usage like this:

```
boundaries = [100000, 110000]
values = [1.0, 0.5, 0.1]
learning_rate = staircase(global_step, boundaries, values)
```

This would create a `Tensor` that evaluates to 1.0 when `x <= 100000`, 0.5 when `x > 100000` and `x <= 110000`, and 0.1 when `x > 110000`.

Shouldn't be hard to build using `tf.case`.

Is this of interest or too specific?
"
2431,Better support for breaking up too-large operations,"Unless I'm missing something, the ability to automatically break up calculations that don't fit on a device does not seem to be part of the TensorFlow API. This surprises me since one of the very first things users (at least naive ones like me) encounter in readily accessible GPU machines (e.g. AWS EC2 instances) are memory crashes on GPUs. 

To avoid these errors users have to either give up on GPUs for large parts of their calculations (again, unless I'm missing something) or hand code some form of batching to avoid the crashes (if they can figure out where they're happening, which isn't always easy with such errors).

Shouldn't TensorFlow do this automatically ""under the hood"", breaking up too-large calculations and merging them, to avoid code like that below?

---

_From a [related question](http://stackoverflow.com/q/37327312/656912) asked on SO:_

I'm puzzled about how to efficiently assign my TensorFlow operations and variables to devices. It's clear that, at least for my implementation of a basic convolutional neural network, placing as many operations as possible on a GPU is desirable. But the GPU I currently have access to has limited memory and results in many warnings of the form

> `Ran out of memory trying to allocate 2.60GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.`

and occasional crashes for certain specific operations, like

> ```
> Ran out of memory trying to allocate 83.74MiB.  See logs for memory state.
> Resource exhausted: OOM when allocating tensor with shape[28000,1,28,28]
> ```

These can be avoided by placing variables on CPUs, but in my implementation, this results in training epochs taking 10 times as long to compute. 

Clearly the ideal policy is to identify specific chunks of code that generate errors, and attempt to place only those on CPUs. But it is unclear to me how to do this, because those calculations can't be isolated from others that require GPU placement to achieve efficiencies.

For example, simply generating predictions on a test set with something like

```
evals = sess.run(tf.argmax(y, 1), feed_dict={x: use_x_all})
```

where `x` is a `tf.placeholder` of inputs to my model, and `y` are the output activations of my network, produces the above error when `use_x_all` is a large array (here with `28000` examples). Attempting to put this calculation alone on a CPU fails, presumably because the network evaluation producing `y` is on the GPU.

Because of this I (seem to) need to resort to approaches like

```
use_x_all, _ = data_loader.stack_data(use_data, as_cols=False)
use_x_split = np.split(use_x_all, splits)
for use_x in use_x_split:
    # ...
    evals_part = sess.run(tf.argmax(y, 1), feed_dict={x: use_x})
    # accumulate evals
```

which clearly doesn't scale.

Is there a better way? Specifically:
- Is there a way to place calculations like the one above on a CPU and still have those calculations for the same graph (e.g. training) run on a GPU?

or, alternatively
- Is there an idiom (like batching) that can be more easily applied in such situations to reduce the memory demands of such calculations?
"
2430,Documentation describes Python 3 Anaconda installation but no support for current Anaconda Python 3 (i.e. Python 3.5),"Anaconda uses Python 3.5 as its version of Python 3.

If you follow the [instructions ](https://storage.googleapis.com/tensorflow/linux/cpu/)to install Tensorflow via Anaconda you'll fail with the error 

> not a supported wheel on this platform

presumably because the wheel is made for Python 3.4 instead of 3.5
"
2429,TypeError: List of Tensors when single Tensor expected when using tf.pack(),"I  get a confusion problem. I can run  code well on my computer. But when I copy the code to the cluster and run it. I get the error: `TypeError: List of Tensors when single Tensor expected.` on this line `outputs     =   tf.pack(outputs)`.  The input of pack function should be list. That is so wired. Why? The version of TF on cluster is 0.8.
"
2428,GloVe implementation for Tensorflow,"I think [GloVe](http://nlp.stanford.edu/projects/glove/) can be an useful embedding model for NLP.
The patch would be very similar to the current /models/embedding/word2vec 
"
2427,Error on retraining flowers,"Creating bottleneck at /tmp/bottleneck/roses/8949720453_66e8304c30.jpg.txt
Traceback (most recent call last):
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/tensorflow/examples/image_retraining/retrain.py"", line 827, in <module>
    tf.app.run()
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/tensorflow/examples/image_retraining/retrain.py"", line 754, in main
    bottleneck_tensor)
  File ""/home/ubuntu/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/tensorflow/examples/image_retraining/retrain.py"", line 676, in add_final_training_ops
    bottleneck_input = tf.placeholder_with_default(
AttributeError: 'module' object has no attribute 'placeholder_with_default'
"
2426,Supporting negative reduction indices.,"The reduce operations do not support negative indices as opposed to their numpy equivalents. In particular, the following code fails with the error message `ValueError: Invalid reduction dimension -1 for input with 2 dimensions`.

``` python
import tensorflow as tf
import numpy as np

# Create reference values in numpy
x = np.random.normal(0, 1, (40, 50))
y = np.sum(x, axis=-1)

# Try to reproduce the same in tensorflow
sess = tf.InteractiveSession()
tf_x = tf.constant(x)
tf_y = tf.reduce_sum(x, -1)
np.testing.assert_allclose(tf_y.eval(), y)
sess.close()    
```

The code that checks the reduction indices and throws the exception appears to know about the dimensionality of the vector (taken from [_ReductionShape](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/math_ops.py#L1610)).

``` python
for reduction_index in reduction_indices:
    if reduction_index < 0 or reduction_index >= input_shape.ndims:
        raise ValueError(""Invalid reduction dimension %d for input with %d dimensions"" % (reduction_index, input_shape.ndims))
```

I have thus started using the following function to support negative indices.

``` python
def _reduction_indices(input_tensor, reduction_indices):
    # Get the shape and convert indices to a list
    input_shape = input_tensor.get_shape()
    reduction_indices = np.ravel(reduction_indices)

    # Convert the indices
    return [(input_shape.ndims + index) if index < 0 else index for index in reduction_indices]
```

Would this be worth integrating into the main repository or is the lack of support for tensors with completely unknown shape problematic?
"
2425,Initializing saver after variables are initialized and queue runners are started causes inconsistent behaviour.,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:  Mac OsX (El Capitain)

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce
1.  Run the CNN example provided by tensorflow using a filename queue
2.  Initialize variable and queue runners
3.  Initialize a saver 
### What have you tried?
1.  Tried running the exact same code with a saver that saves no values and no saver.  Simply initializing the saver at the wrong time is sufficient to cause weird behaviour.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
App will crash intermittently somewhere completely unrelated in code (usually native).

I know this is user error, but it would have been really helpful if an exception had been raised.  I wasted a lot of time trying to hunt down a mystery error when it turned out it was the saver all along.  This can be confusing to beginners such as myself.
"
2424,"couldn't find ""libtensorflow_demo.so""","I got this error message after ran on Android 5

```
05-19 13:21:33.731 27653-27653/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: main
                                                                     Process: org.tensorflow.demo, PID: 27653
                                                                     java.lang.UnsatisfiedLinkError: com.android.tools.fd.runtime.IncrementalClassLoader$DelegateClassLoader[DexPathList[[dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_9-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_8-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_7-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_6-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_5-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_4-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_3-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_2-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_1-classes.dex"", dex file ""/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_0-classes.dex""],nativeLibraryDirectories=[/vendor/lib, /system/lib, /vendor/lib, /system/lib]]] couldn't find ""libtensorflow_demo.so""
                                                                         at java.lang.Runtime.loadLibrary(Runtime.java:366)
                                                                         at java.lang.System.loadLibrary(System.java:989)
                                                                         at org.tensorflow.demo.TensorflowClassifier.<clinit>(TensorflowClassifier.java:47)
                                                                         at org.tensorflow.demo.TensorflowImageListener.<init>(TensorflowImageListener.java:56)
                                                                         at org.tensorflow.demo.CameraConnectionFragment.<init>(CameraConnectionFragment.java:445)
                                                                         at org.tensorflow.demo.CameraConnectionFragment.newInstance(CameraConnectionFragment.java:266)
                                                                         at org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:33)
                                                                         at android.app.Activity.performCreate(Activity.java:6289)
                                                                         at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119)
                                                                         at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2646)
                                                                         at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2758)
                                                                         at android.app.ActivityThread.access$900(ActivityThread.java:177)
                                                                         at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1448)
                                                                         at android.os.Handler.dispatchMessage(Handler.java:102)
                                                                         at android.os.Looper.loop(Looper.java:145)
                                                                         at android.app.ActivityThread.main(ActivityThread.java:5942)
                                                                         at java.lang.reflect.Method.invoke(Native Method)
                                                                         at java.lang.reflect.Method.invoke(Method.java:372)
                                                                         at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1389)
                                                                         at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1184)
```

P.S: BTW i'm using android studio for this project (converted into gradle project based).

Please advice. Thank you.
"
2423,More random ops,"Tensorflow currently doesn't support too many random operations. It would be nice to have things like bernoulli, batched normal (the existing normal only takes scalars), beta, gamma, and so on.
"
2422,Why not allow feeding and fetching the same tensor?,"Currently this generates `InvalidArgumentError: Placeholder_2:0 is both fed and fetched.`

It doesn't seem like a particularly useful thing but why not trivially allow this behavior? We might as well allow users to fetch any tensor in the graph.
"
2421,SKLearn examples not working in the latest release,"I've been trying to run some examples from the provided SKFlow examples located at 

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/skflow

And most fail with dependency failures such as: 

AttributeError: 'module' object has no attribute 'datasets'

For:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/text_classification_builtin_rnn_model.py

I looked around the source code and some of this modules seem to have been moved around, maybe this examples should be updated or completely removed, I tried adapting the code to work however I ended copying big chunks of source code into the file to make it work.

using tensorflow 0.8
"
2420,TypeError: an integer is required executing skflow text classification examples,"Using a nightly build I'm unable to execute the text classification examples in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/skflow (I have tried text_classification.py, text_classification_cnn.py and text_classification_builtin_rnn_model.py).

`$ sudo pip3 install --upgrade http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl 

$ python3 -c ""import tensorflow; print(tensorflow.**version**)""
0.8.0

$ python3 rnn.py
Total words: 822383
Traceback (most recent call last):
  File ""rnn.py"", line 68, in <module>
    classifier.fit(X_train, y_train, logdir='/tmp/tf_examples/word_rnn')
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 270, in fit
    feed_params_fn=self._data_feeder.get_feed_params)
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/trainer.py"", line 49, in train
    feed_dict = feed_dict_fn()
  File ""/usr/local/lib/python3.4/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py"", line 324, in _feed_dict_fn
    out.itemset((i, self.y[sample]), 1.0)
TypeError: an integer is required`
"
2416,Memory error running tensorflow code on GPU,"### Environment info

Operating System: Scientific Linux release 7.2 (Nitrogen)

Installed version of CUDA and cuDNN: 
$ ll /usr/local/cuda/lib/libcud*

```
-rw-r--r-- 1 root root 185K Mar 18 15:29 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root   16 Mar 18 15:29 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root   19 Mar 18 15:29 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 305K Mar 18 15:29 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 545K Mar 18 15:29 /usr/local/cuda/lib/libcudart_static.a
```

Installed version 0.8.0 with anaconda.

I'm getting a MemoryError when I try to run a tensorflow script on a server with GPU support. The same code, with the same inputs, runs without problems on my local machine, which is CPU only and has 8 GB of RAM. 

I tried to allocate up to 64 GB to run the script, and the same problem occurred. Here's the stacktrace:

```
Traceback (most recent call last):
  File ""src/train.py"", line 93, in <module>
    learning_rate=args.rate, l2_constant=args.l2)
  File ""/hltsrv0/rocha/rte-lstm/src/rte_lstm.py"", line 189, in __init__
    gradients, v = zip(*optimizer.compute_gradients(self.loss))
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 241, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 485, in gradients
    in_grads = control_flow_ops.tuple(in_grads)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1784, in tuple
    tpl.append(with_dependencies([gate], t))
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1664, in with_dependencies
    return _Identity(output_tensor, name=name)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 114, in _Identity
    return array_ops.identity(data, name=name)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 609, in identity
    return _op_def_lib.apply_op(""Identity"", input=input, name=name)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1165, in __init__
    self._recompute_node_def()
  File ""/hltsrv0/rocha/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1318, in _recompute_node_def
    self._control_inputs])
MemoryError
```

From the stack trace, I see that the error happens sometime during the gradient computation, but I have no idea why it only happens when I run the code in the server. 

By the way, I'm not experienced in GPU computation. I just tried running the same code in an environment with the cuda libraries and tensorflow with GPU support installed.
"
2415,Feature Request: atrous convolution with stride > 1,"I'd like access to strides in atrous_conv2d for learning multi-scale raw audio filters. Using a stride of 1 is computationally infeasible, and as the goal is classification resolution does not need to be preserved.
"
2414,how to run lstm on multi gpus?,"I run a example of lstm on multi gpus using codes in `models/image/cifar10`, but it turns out that Attempting to use uninitialized value lstm/LSTMCell/W_0. I have read the issues 1390, so I have a question if the implementation of lstmcell is ok. when I want to store variables on cpu, and run ops on gpu, the implementation of lstmcell do initialization of `w` in blackbox, then variables and ops must be in the same place, cpu or gpu, it's not a good idea, right?
"
2413,Compile Failed Numerous Times,"Ubuntu 14.04
GCC 4.8.4
Cuda 7.5
Cudnn 4.0.7
Bazel 0.2.2b

---

`bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer`
INFO: Found 1 target...
ERROR: /home/peiguo/.cache/bazel/_bazel_peiguo/67521296d96959142b2d5d303d9c774c/external/re2/BUILD:9:1: undeclared inclusion(s) in rule '@re2//:re2':
this rule is missing dependency declarations for the following files included by 'external/re2/util/rune.cc':
  '/usr/include/stdc-predef.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stdarg.h'
  '/usr/include/string.h'
  '/usr/include/features.h'
  '/usr/include/x86_64-linux-gnu/sys/cdefs.h'
  '/usr/include/x86_64-linux-gnu/bits/wordsize.h'
  '/usr/include/x86_64-linux-gnu/gnu/stubs.h'
  '/usr/include/x86_64-linux-gnu/gnu/stubs-64.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stddef.h'
  '/usr/include/xlocale.h'
  '/usr/include/x86_64-linux-gnu/bits/string3.h'
  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stdint.h'
  '/usr/include/stdint.h'
  '/usr/include/x86_64-linux-gnu/bits/wchar.h'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2.329s, Critical Path: 2.01s

---

I have tried many times, the error is always undeclared inclusion(s) in rule xxxx, but the xxxx is changing constantly.
"
2412,Packaged TensorFlow C++ library for bazel-independent use,"Currently, building a C++ application in tensorflow requires creating a project in the tensorflow source tree and compiling with bazel. In my case I would like to use tensorflow in a (fairly large) existing application with an existing build system that would be difficult to port to bazel. The solution to me seems to be exposing tensorflow as a library that can be linked with.
"
2411,Android - Binary XML file line #*: Error inflating class com.android.internal.widget.ActionBarView,"I got this issue when trying to test tensorflow demo on android device.

```
05-18 10:25:44.494: E/AndroidRuntime(29965): FATAL EXCEPTION: main
05-18 10:25:44.494: E/AndroidRuntime(29965): java.lang.RuntimeException: Unable to start activity ComponentInfo{org.tensorflow.demo/org.tensorflow.demo.CameraActivity}: android.view.InflateException: Binary XML file line #39: Error inflating class com.android.internal.widget.ActionBarView
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2214)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2264)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.ActivityThread.access$600(ActivityThread.java:144)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1259)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.os.Handler.dispatchMessage(Handler.java:99)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.os.Looper.loop(Looper.java:137)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.ActivityThread.main(ActivityThread.java:5136)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at java.lang.reflect.Method.invokeNative(Native Method)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at java.lang.reflect.Method.invoke(Method.java:525)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:737)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:553)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at dalvik.system.NativeStart.main(Native Method)
05-18 10:25:44.494: E/AndroidRuntime(29965): Caused by: android.view.InflateException: Binary XML file line #39: Error inflating class com.android.internal.widget.ActionBarView
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.createView(LayoutInflater.java:620)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:696)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.rInflate(LayoutInflater.java:755)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.rInflate(LayoutInflater.java:758)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.rInflate(LayoutInflater.java:758)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.inflate(LayoutInflater.java:492)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.inflate(LayoutInflater.java:397)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.inflate(LayoutInflater.java:353)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.policy.impl.PhoneWindow.generateLayout(PhoneWindow.java:2825)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.policy.impl.PhoneWindow.installDecor(PhoneWindow.java:2888)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.policy.impl.PhoneWindow.setContentView(PhoneWindow.java:264)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.Activity.setContentView(Activity.java:1895)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:29)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.Activity.performCreate(Activity.java:5133)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1087)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2178)
05-18 10:25:44.494: E/AndroidRuntime(29965):    ... 11 more
05-18 10:25:44.494: E/AndroidRuntime(29965): Caused by: java.lang.reflect.InvocationTargetException
05-18 10:25:44.494: E/AndroidRuntime(29965):    at java.lang.reflect.Constructor.constructNative(Native Method)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at java.lang.reflect.Constructor.newInstance(Constructor.java:417)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.createView(LayoutInflater.java:594)
05-18 10:25:44.494: E/AndroidRuntime(29965):    ... 26 more
05-18 10:25:44.494: E/AndroidRuntime(29965): Caused by: android.view.InflateException: Binary XML file line #35: Error inflating class android.widget.TextView
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.createView(LayoutInflater.java:620)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.policy.impl.PhoneLayoutInflater.onCreateView(PhoneLayoutInflater.java:56)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.onCreateView(LayoutInflater.java:669)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:694)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.rInflate(LayoutInflater.java:755)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.rInflate(LayoutInflater.java:758)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.inflate(LayoutInflater.java:492)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.inflate(LayoutInflater.java:397)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.widget.ActionBarView.initTitle(ActionBarView.java:852)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.widget.ActionBarView.setDisplayOptions(ActionBarView.java:670)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at com.android.internal.widget.ActionBarView.<init>(ActionBarView.java:254)
05-18 10:25:44.494: E/AndroidRuntime(29965):    ... 29 more
05-18 10:25:44.494: E/AndroidRuntime(29965): Caused by: java.lang.reflect.InvocationTargetException
05-18 10:25:44.494: E/AndroidRuntime(29965):    at java.lang.reflect.Constructor.constructNative(Native Method)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at java.lang.reflect.Constructor.newInstance(Constructor.java:417)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.view.LayoutInflater.createView(LayoutInflater.java:594)
05-18 10:25:44.494: E/AndroidRuntime(29965):    ... 39 more
05-18 10:25:44.494: E/AndroidRuntime(29965): Caused by: java.lang.UnsupportedOperationException: Can't convert to color: type=0x2
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.content.res.TypedArray.getColor(TypedArray.java:326)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.widget.TextView.<init>(TextView.java:673)
05-18 10:25:44.494: E/AndroidRuntime(29965):    at android.widget.TextView.<init>(TextView.jav
```

CameraActivity.java

```
package org.tensorflow.demo;

import android.app.Activity;
import android.os.Bundle;
import android.view.WindowManager;

public class CameraActivity extends Activity {
  @Override
  protected void onCreate(final Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);

    setContentView(R.layout.activity_camera);
    if (null == savedInstanceState) {
      getFragmentManager()
          .beginTransaction()
          .replace(R.id.container, CameraConnectionFragment.newInstance())
          .commit();
    }
  }
}
```

activity_camera.xml

```
<?xml version=""1.0"" encoding=""utf-8""?><!--
<FrameLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:tools=""http://schemas.android.com/tools""
    android:id=""@+id/container""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:background=""#000""
    tools:context=""org.tensorflow.demo.CameraActivity"" />
```

Please advice. Thank you.
"
2410,Possible typo in doc of constant_initializer,"In the [doc](https://www.tensorflow.org/versions/master/api_docs/python/state_ops.html#constant_initializer) of `constant_initializer`, it says that the argument `value` should be:

> value: A Python scalar. All elements of the initialized variable will be set to this value.

But in fact, it can take array-like argument and initialize variables properly with it. So I guess it's a mistake in the doc? It's kind of misleading for beginners.

Thanks!
"
2407,TF learn has a problem with discontinuous categorical outputs,"I have a `train.csv` which looks like:

```
v1,v2,v3
5,4,10
1,2,5
4,5,20
1,11,50
1,12,20
```

and `test.csv`:

```
v1,v2
4,5
2,3
2,4
5,6
```

The idea is: the output variable (`v3`) can take four values:  `5,10,20,50` and nothing more. It is classification task.

Then code:

``` python
import numpy as np
import pandas as pd
from tensorflow.contrib import learn

print (""Reading data"")

df_train = pd.read_csv(""train.csv"")
df_test = pd.read_csv(""test.csv"")

print (""Dividing to train and test set"")

y_train = df_train ['v3']
X_train = df_train [['v1','v2']]

X_test = df_test[['v1','v2']]

classifier_1 = learn.TensorFlowDNNClassifier(
     hidden_units=[20, 10], 
     n_classes=4, 
     batch_size=128, 
     steps=500, 
     learning_rate=0.05)

# fit
print (""Fitting"")
classifier_1.fit(X_train, y_train)
```

Then I have a problem:

```
Traceback (most recent call last):
  File ""sample.py"", line 26, in <module>
    classifier_1.fit(X_train, y_train)
  File ""/Users/qdang/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.py"", line 254, in fit
    feed_params_fn=self._data_feeder.get_feed_params)
  File ""/Users/qdang/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/trainer.py"", line 49, in train
    feed_dict = feed_dict_fn()
  File ""/Users/qdang/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py"", line 281, in _feed_dict_fn
    out.itemset((i, self.y[sample]), 1.0)
IndexError: index 5 is out of bounds for axis 1 with size 4
```

I think the issue is because the absolute value of output value (`5`) is larger than the number of classes (`4`)
"
2406,TensorFlow grpc tensorflow server build on CentOS 7.2,"### Environment info

Operating System:
Linux 3.10.0-327.13.1.el7.x86_64
CentOS Linux release 7.2.1511 (Core)

Installed version of CUDA and cuDNN: 
CUDA is 7.5 and cuDNN is 4.0.7
ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 May 11 22:38 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 May 11 22:38 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 May 12 14:47 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 root root       17 May 12 14:47 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 61453024 Feb  8 17:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Feb  8 17:12 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   python -c ""import tensorflow; print(tensorflow.**version**)""
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
   0.8.0

If installed from sources, provide the commit hash:
Trying to build from sources the distributed version of tensorflow
### Steps to reproduce
1. git clone --recurse-submodules https://github.com/tensorflow/tensorflow
   The latest commit hash is 66edcda74c0f4823c9b9e3cddd17db9dfff63ad6
2. installed bazel from binaries
   sh bazel-0.2.2b-installer-linux-x86_64.sh
3. building with bazel fails
   bazel build -c opt --config=cuda --verbose_failures --spawn_strategy=standalone --genrule_strategy=standalone //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server
   WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
   INFO: Found 1 target...
   ERROR: /root/tmp/tensorflow/google/protobuf/BUILD:29:1: undeclared inclusion(s) in rule '//google/protobuf:protobuf_lite':
   this rule is missing dependency declarations for the following files included by 'google/protobuf/src/google/protobuf/stubs/once.cc':
   '/include/c++/4.8.5/string'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/c++config.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/os_defines.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/cpu_defines.h'
   '/include/c++/4.8.5/bits/stringfwd.h'
   '/include/c++/4.8.5/bits/memoryfwd.h'
   '/include/c++/4.8.5/bits/char_traits.h'
   '/include/c++/4.8.5/bits/stl_algobase.h'
   '/include/c++/4.8.5/bits/functexcept.h'
   '/include/c++/4.8.5/bits/exception_defines.h'
   '/include/c++/4.8.5/bits/cpp_type_traits.h'
   '/include/c++/4.8.5/ext/type_traits.h'
   '/include/c++/4.8.5/ext/numeric_traits.h'
   '/include/c++/4.8.5/bits/stl_pair.h'
   '/include/c++/4.8.5/bits/move.h'
   '/include/c++/4.8.5/bits/concept_check.h'
   '/include/c++/4.8.5/type_traits'
   '/include/c++/4.8.5/bits/stl_iterator_base_types.h'
   '/include/c++/4.8.5/bits/stl_iterator_base_funcs.h'
   '/include/c++/4.8.5/debug/debug.h'
   '/include/c++/4.8.5/bits/stl_iterator.h'
   '/include/c++/4.8.5/bits/postypes.h'
   '/include/c++/4.8.5/cwchar'
   '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdarg.h'
   '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stddef.h'
   '/include/c++/4.8.5/cstdint'
   '/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdint.h'
   '/include/c++/4.8.5/bits/allocator.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/c++allocator.h'
   '/include/c++/4.8.5/ext/new_allocator.h'
   '/include/c++/4.8.5/new'
   '/include/c++/4.8.5/exception'
   '/include/c++/4.8.5/bits/atomic_lockfree_defines.h'
   '/include/c++/4.8.5/bits/exception_ptr.h'
   '/include/c++/4.8.5/bits/nested_exception.h'
   '/include/c++/4.8.5/bits/localefwd.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/c++locale.h'
   '/include/c++/4.8.5/clocale'
   '/include/c++/4.8.5/iosfwd'
   '/include/c++/4.8.5/cctype'
   '/include/c++/4.8.5/bits/ostream_insert.h'
   '/include/c++/4.8.5/bits/cxxabi_forced.h'
   '/include/c++/4.8.5/bits/stl_function.h'
   '/include/c++/4.8.5/backward/binders.h'
   '/include/c++/4.8.5/bits/range_access.h'
   '/include/c++/4.8.5/bits/basic_string.h'
   '/include/c++/4.8.5/ext/atomicity.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/gthr.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/gthr-default.h'
   '/include/c++/4.8.5/x86_64-redhat-linux/bits/atomic_word.h'
   '/include/c++/4.8.5/initializer_list'
   '/include/c++/4.8.5/ext/string_conversions.h'
   '/include/c++/4.8.5/cstdlib'
   '/include/c++/4.8.5/cstdio'
   '/include/c++/4.8.5/cerrno'
   '/include/c++/4.8.5/bits/functional_hash.h'
   '/include/c++/4.8.5/bits/hash_bytes.h'
   '/include/c++/4.8.5/bits/basic_string.tcc'
   '/include/c++/4.8.5/cstddef'
   '/lib/gcc/x86_64-redhat-linux/4.8.5/include/limits.h'
   '/lib/gcc/x86_64-redhat-linux/4.8.5/include/syslimits.h'
   '/include/c++/4.8.5/utility'
   '/include/c++/4.8.5/bits/stl_relops.h'.
   Target //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server failed to build
   INFO: Elapsed time: 8.212s, Critical Path: 1.98s

rpm -qa | grep gcc
gcc-c++-4.8.5-4.el7.x86_64
libgcc-4.8.5-4.el7.x86_64
gcc-4.8.5-4.el7.x86_64
rpm -qa | grep glibc
glibc-common-2.17-106.el7_2.4.x86_64
glibc-devel-2.17-106.el7_2.4.x86_64
glibc-2.17-106.el7_2.4.x86_64
glibc-headers-2.17-106.el7_2.4.x86_64

I am not sure what are the dependencies. I saw that glibc 2.17 should at least meet the minimum.
### What have you tried?
1. Nothing else yet. Trying to build bazel from source.

Any thoughts?
"
2405,"HEAD compiles without error, but not completely? build_pip_package fails.","CentOS 6.7
Cuda 7.0
cuDNN 4.0.7

I resolve https://github.com/tensorflow/tensorflow/issues/2266 by hard coding the python2.7 path in `third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc`.

After also resolving a similar problem with `swig`, it compiles without errors:

```
Target //tensorflow/tools/pip_package:build_pip_package up-to-date:
  bazel-bin/tensorflow/tools/pip_package/build_pip_package
INFO: Elapsed time: 228.884s, Critical Path: 199.55s
```

But it seems that `build_pip_package` was only partially (?) completed:

```
rdipiet2@jhu.edu@login-node03 tensorflow $ bazel-bin/tensorflow/tools/pip_package/build_pip_package testonly
Tue May 17 11:09:33 EDT 2016 : === Using tmpdir: /tmp/tmp.akIEI1WBAX
cp: cannot stat `bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow': No such file or directory
cp: cannot stat `bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/external': No such file or directory
```

Any ideas? Could something be failing silently?
"
2403,"""Total error: nan"" for neural network model","Hi 

I have randomly generated exponential signal. I am training the network to predict y values depending on the random time constant (tau). I have added one hidden layer and used gardient descent for optimization. The code runs fine, but it doesnt print error properly. I get this - ('Total Error: ', nan)

here is my code-

`import tensorflow as tf
 import numpy as np
 import random
# input data

 lorange= 1
 hirange= 10
 amplitude= random.uniform(-10,10)
 t= 10
 random.seed()
 tau=random.uniform(lorange,hirange)

 def generate_data(randomsignal):
       x= np.arange(t)
       y= amplitude*np.exp(-x/tau)
       return x, y
 #tensors for input data

 x_input= tf.placeholder(tf.float32, shape=(10,))# t=10
 y_input= tf.placeholder(tf.float32, shape=(10,))

 #use 10 neurons-- just one layer for now

 weights_1= tf.Variable(tf.truncated_normal([10,10], stddev= .1)) 
 bias_1= tf.Variable(.1)

 #hidden output 
 hidden_output= tf.nn.relu(tf.matmul(tf.reshape(x_input,[1,10]), weights_1) + bias_1)

 weights_2 = tf.Variable(tf.truncated_normal([10, 10], stddev=.1))
 bias_2= tf.Variable(.1)

 calculated_output = tf.nn.softmax(tf.matmul(hidden_output, weights_2) + 

 bias_2)

 cross_entropy = tf.reduce_mean(y_input \* tf.log(calculated_output))

 optimizer = tf.train.GradientDescentOptimizer(.5).minimize(cross_entropy)

 sess = tf.Session()
 #session
 sess.run(tf.initialize_all_variables())

 for i in range(1000):
      x, y = generate_data(100)
      sess.run(optimizer, feed_dict={x_input: x, y_input: y})

 error = tf.reduce_sum(tf.abs(calculated_output - y_input))

 x, y = generate_data(100)
 print(""Total Error: "", sess.run(error, feed_dict={x_input: x, y_input: y}))`
"
2402,Problem with documentation regarding SparseTensors and TFRecord.,"I can't seem to find how to store sparse tensors to TFRecord. GitHub issues is not really a place for such a question but documentation was really hard to understand. Could anybody help me with this? Maybe link to a code that uses VarLenFeature or something similiar?
"
2400,modify grpc for local_repository,"Due to network limited, I modify grpc for local_repository in workspace.bzl file,  as shown below:

  #native.git_repository(
  native.local_repository(
    name = ""grpc"",
    path = ""/home/jason/localDep/grpc/grpc"",
    #commit = ""3d62fc6"",
    #init_submodules = True,
    #remote = ""https://github.com/grpc/grpc.git"",
  )
And when run  bazel build -c opt --config=cuda --verbose_failures --genrule_strategy=standalone //tensorflow/tools/pip_package:build_pip_package

it will report:

ERROR: /root/.cache/bazel/_bazel_root/5f279d276e3315e6a8baf89d39adcaeb/external/grpc/BUILD:514:1: no such target '//external:nanopb': target 'nanopb' not declared in package 'external' defined by /home/jason/tensor_5_9/tensorflow/WORKSPACE and referenced by '@grpc//:grpc_unsecure'.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 0.535s

Does anyone know why?
"
2399,Is it possible to add summaries to an existing event file ?,"When I continue to train my model from last interrupted training, `tf.train.SummaryWriter` create a new event file.
Could I add new summaries to my existing event file?  So I can visualize the whole learning run.

P.S. What's the right way to suspend the training binary on GPU?   We share one GPU, and I always use  ""Ctrl+c""   
"
2398,imac install failed.,"Installing collected packages: protobuf, wheel, numpy, tensorflow
  Found existing installation: numpy 1.8.0rc1
    DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
    Uninstalling numpy-1.8.0rc1:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-8.1.2-py2.7.egg/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-8.1.2-py2.7.egg/pip/commands/install.py"", line 317, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-8.1.2-py2.7.egg/pip/req/req_set.py"", line 736, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-8.1.2-py2.7.egg/pip/req/req_install.py"", line 742, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-8.1.2-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-8.1.2-py2.7.egg/pip/utils/**init**.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/tmp/pip-hgaRu9-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info'
"
2397,Performance of Tensorflow distributed training is much slower than caffe multi-GPU training,"I have trained inceptionv3 using tensorflow both on multi-GPU version and distributed version (two machine, four GPU each). Each GPU processes 32 images per iteration under both settings. However, the distributed training speed is twice as slow as the `caffe` multi-GPU version. I'm wondering how to improve the performance of distributed training. 

**Configuration:** 

Two machine, both of them have totally same environment: CentOS 7, 4 GTX TITAN X GPUs, 32 Intel Xeon CPU E5-2630 v3 2.40GHz processors, and 131GB Memory. Network IO between machines is 125MB/s, `ping` delay is 0.1ms and local read speed is 1GB/s (RAID5). The distributed training code is the newest master branch [here](https://github.com/tensorflow/models/tree/master/inception). In distributed version, there are 4 `workers` on each machine, each work are assigned to 1 GPU and there is only one `ps` server started. I read data file from local disk. 

the start script for each worker (8 workers in total) is

```
~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=2 \
--ps_hosts='10.10.102.28:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.28:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &
```

**Runtime logging:**

The training speed is 

```
INFO:tensorflow:Worker 6: 2016-05-16 21:07:22.101672: step 390, loss = 8.15(24.0 examples/sec; 1.334  sec/batch)
INFO:tensorflow:Worker 5: 2016-05-16 21:07:22.101666: step 390, loss = 8.10(24.0 examples/sec; 1.335  sec/batch)
INFO:tensorflow:Worker 4: 2016-05-16 21:07:22.101768: step 390, loss = 8.11(24.0 examples/sec; 1.333  sec/batch)
INFO:tensorflow:Worker 7: 2016-05-16 21:07:22.102245: step 390, loss = 8.03(24.1 examples/sec; 1.330  sec/batch)
```

This speed is twice as slow as `caffe` multi-GPU training on one machine(ensure that experiments are under same settings, each GPU process 32 images per iteration). I used `nvidia-smi -l 1` to watch the GPU usage, and find that GPUs only busy in 25% running time. The `top` command print like this:

```
 %Cpu(s):  2.4 us, 35.2 sy,  0.0 ni, 62.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem : 13174038+total, 21064972 free, 18241616 used, 92433792 buff/cache
KiB Swap: 16777212 total, 16724332 free,    52880 used. 88948128 avail Mem 

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     
  685 peter+  20   0  0.191t 2.336g 453624 S 878.1  1.9  83:03.03 python      
15102 peter+  20   0 13.715g 5.522g  41820 S 293.7  4.4 348:39.74 python      
  682 peter+  20   0  0.192t 2.476g 453608 S  13.0  2.0  69:18.00 python      
  683 peter+  20   0  0.193t 4.093g 978228 S  11.6  3.3  84:40.56 python      
  684 peter+  20   0  0.191t 2.410g 453612 S  10.6  1.9  88:50.77 python 
```

**What I have tried**
- By modifying the `num_preprocess_threads` and the `num_readers`, I got the best performance `1.333  sec/batch`, when I set both variable to 1.
- Modify the queue capacity is not helpful.
- I believe the `bath_inputs()` is executed on `CPU:0`, because in `image_processing.py` line 132: `with tf.device('/cpu:0'):`
- I refered to this [issue](https://github.com/tensorflow/models/issues/47) and wondering if the bottleneck is CPU/IO. 

How to get a better performance ?
"
2396,AttributeError: module 'tensorflow.contrib.learn' has no attribute 'datasets',"I was running :  tensorflow/tensorflow/examples/skflow/text_classification_cnn.py

The line at : dbpedia = learn.datasets.load_dataset('dbpedia') fails with the attribute error . 

Error: AttributeError: module 'tensorflow.contrib.learn' has no attribute 'datasets'
"
2395,"Tensors should have an ""ndim"" property","This is a useful shortcut property on NumPy arrays, and would nice to have in TensorFlow for the sake of cross-compatibility. `tensor.ndim` would be equivalent to `tf.rank(tensor)`.
"
2393,Update FAQ,"The FAQ here: https://www.tensorflow.org/versions/r0.8/resources/faq.html
still says that multi-machine isn't available yet. But it is available now.
"
2391,Implemented Tensorflow Op Kernel not found,"I would like to implement an fft op kernel for CPU. Since eigen got an fft implementation this shouldn't be too hard. It's compiling without problems, but I am always running into an InvalidArgumentError when trying to use it from python (see below).

Code of kernel for fft op on CPU (modification of [this file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fft_ops.cc)):

``` ...
// CPU Implementation
template <bool Forward>
class FFTCPU1D : public OpKernel {
 public:
  explicit FFTCPU1D(OpKernelConstruction* ctx) : OpKernel(ctx) {}

  void Compute(OpKernelContext* ctx) override {
    const Tensor& in = ctx->input(0);
    const TensorShape& shape = in.shape();
    OP_REQUIRES(ctx, shape.dims() != 1,
      errors::InvalidArgument(""Input must have rank 1, but got: "",
                                shape.DebugString()));

    Tensor* out;
    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, shape, &out));
    if (Forward) {
        out.vec<std::complex<Scalar>>() = kernel_variant.template fft<Eigen::BothParts, FFT_FORWARD>(fft).vec()<std::complex<Scalar>>;
    } else {
        out.vec<std::complex<Scalar>>() = kernel_variant.template fft<Eigen::BothParts, FFT_REVERSE>(fft).vec()<std::complex<Scalar>>;
    }
  }

};

REGISTER_KERNEL_BUILDER(Name(""FFT"").Device(DEVICE_CPU), FFTCPU1D<true>);
REGISTER_KERNEL_BUILDER(Name(""IFFT"").Device(DEVICE_CPU), FFTCPU1D<false>);
...
```

Python-Script for testing:

```
import numpy as np
import tensorflow as tf

sess = tf.Session()
data = np.complex64(np.random.normal(size=1024))
input = tf.constant(data)
fftOp = tf.fft(input)

print(sess.run(fftOp))
```

Error-Message:

```
# python ~/test.py
Traceback (most recent call last):
  File ""/root/test.py"", line 12, in <module>
    print(sess.run(fftOp))
  File ""/tensorflow/_python_build/tensorflow/python/client/session.py"", line 332, in run
    run_metadata_ptr)
  File ""/tensorflow/_python_build/tensorflow/python/client/session.py"", line 572, in _run
    feed_dict_string, options, run_metadata)
  File ""/tensorflow/_python_build/tensorflow/python/client/session.py"", line 652, in _do_run
    target_list, options, run_metadata)
  File ""/tensorflow/_python_build/tensorflow/python/client/session.py"", line 672, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: No OpKernel was registered to support Op 'FFT' with these attrs
         [[Node: FFT = FFT[](Const)]]
Caused by op u'FFT', defined at:
  File ""/root/test.py"", line 10, in <module>
    fftOp = tf.fft(input)
  File ""/tensorflow/_python_build/tensorflow/python/ops/gen_math_ops.py"", line 518, in fft
    return _op_def_lib.apply_op(""FFT"", input=input, name=name)
  File ""/tensorflow/_python_build/tensorflow/python/ops/op_def_library.py"", line 693, in apply_op
    op_def=op_def)
  File ""/tensorflow/_python_build/tensorflow/python/framework/ops.py"", line 2177, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/tensorflow/_python_build/tensorflow/python/framework/ops.py"", line 1161, in __init__
    self._traceback = _extract_stack()
```

I've got the gcr.io/tensorflow/tensorflow:latest-devel docker image and commit 5f4524 and built tensorflow according to the [instructions](https://www.tensorflow.org/versions/master/get_started/os_setup.html#setting_up_tensorflow_for_development).

I'm not sure whether it's a bug or I'm doing something wrong. I've already opened a [stackoverflow question](https://stackoverflow.com/questions/37252600/implemented-tensorflow-op-kernel-not-found).
"
2388,pip install failing for Python3.4 but fine for Python3.5,"I have been following the installation for Python3.4 using

sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl

The installation says it was successful

When I try to run the examples I get an error

Traceback (most recent call last):
  File ""/usr/lib/python3.4/inspect.py"", line 977, in getfullargspec
    skip_bound_arg=False)
  File ""/usr/lib/python3.4/inspect.py"", line 1965, in _signature_internal
    skip_bound_arg=skip_bound_arg)
  File ""/usr/lib/python3.4/inspect.py"", line 1890, in _signature_from_builtin
    raise ValueError(""no signature found for builtin {!r}"".format(func))
ValueError: no signature found for builtin <method 'max' of 'numpy.ndarray' objects>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""tensor_flow_test.py"", line 1, in <module>
    import tensorflow as tf
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/**init**.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/python/**init**.py"", line 62, in <module>
    import tensorflow.contrib as contrib
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/contrib/**init**.py"", line 26, in <module>
    from tensorflow.contrib import learn
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/contrib/learn/**init**.py"", line 20, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/contrib/learn/python/**init**.py"", line 20, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/**init**.py"", line 22, in <module>
    from tensorflow.contrib.learn.python.learn.io import *
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/io/**init**.py"", line 20, in <module>
    from tensorflow.contrib.learn.python.learn.io.dask_io import *
  File ""/home/padraig/.local/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/io/dask_io.py"", line 23, in <module>
    import dask.dataframe as dd
  File ""/usr/local/lib/python3.4/dist-packages/dask/dataframe/**init**.py"", line 1, in <module>
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/usr/local/lib/python3.4/dist-packages/dask/dataframe/core.py"", line 1234, in <module>
    class Index(Series):
  File ""/usr/local/lib/python3.4/dist-packages/dask/dataframe/core.py"", line 1266, in Index
    @derived_from(pd.Index)
  File ""/usr/local/lib/python3.4/dist-packages/dask/utils.py"", line 526, in wrapper
    original_args = getargspec(original_method).args
  File ""/usr/local/lib/python3.4/dist-packages/dask/compatibility.py"", line 190, in getargspec
    return _getargspec(func)
  File ""/usr/local/lib/python3.4/dist-packages/dask/compatibility.py"", line 35, in _getargspec
    return inspect.getfullargspec(func)
  File ""/usr/lib/python3.4/inspect.py"", line 983, in getfullargspec
    raise TypeError('unsupported callable') from ex
TypeError: unsupported callable

I manually downloaded, renamed and installed the wheel for Python3.5 and it is now working.
"
2387,Documentation on fault tolerance in distributed tensorflow,"Hi,

I know the white paper describes how Tensorflow handles failures in distributed execution, but the docs for open source tensorflow (specifically: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md) don't really explain what to expect if a machine goes down in a cluster. It would be nice to know:
1. What the expected behavior is if a machine fails.
2. If it's possible to add a new machine to the cluster if one fails.

Thanks!
Sulaiman
"
2386,Distributed tensorflow hang when turning from Async to Sync,"I follow [Distributed tensorflow](https://www.tensorflow.org/versions/r0.8/how_tos/distributed/index.html) to port our RNN to multi-GPU cards. I start 4 processes and each process run on a different GPU card.
After solving the [issue](https://github.com/tensorflow/tensorflow/issues/2292), I could run it on my 4 GPU cards server in Asynchronized mode. 

Then I change my code to Synchronized mode by adding only the following code:
    optimizer = tf.train.SyncReplicasOptimizer(
        optimizer,
        replicas_to_aggregate = 4, 
        replica_id = FLAGS.task_index,
        total_num_replicas = 4
        #variable_averages = exp_moving_averager,    # Remove this for simple.
        #variables_to_average = variables_to_average # Remove this for simple.
        )

Then the job will hang in session.run(...)
Is there any other thing needed to change when switch from Async mode to Sync mode?

Thanks a lot in advance!
"
2385,Hard to understand error message ,"x is a list of list of tensors, and im passing in one list at a time to the rnn but I get this hard to understand error message

Traceback (most recent call last):
  File ""autoencoder_m.py"", line 60, in <module>
    outputs, state = rnn.rnn(cell=dropout_cell, inputs = x[i], initial_state=initial_state, sequence_length=s[i], scope = scope)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py"", line 127, in rnn
    array_ops.pack([batch_size, cell.output_size]), inputs[0].dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 241, in pack
    return gen_array_ops._pack(values, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 916, in _pack
    return _op_def_lib.apply_op(""Pack"", values=values, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 379, in apply_op
    assert dtype is not None, ""Should not fail if dtype is None""
**AssertionError: Should not fail if dtype is None**

Does this mean that x[i][0] is of type None? I already checked that it is `<dtype: 'float32'>`

This is the code I am trying to run, basically trying to run rnn on multiple gpu in the following manner.

```
x = [[tf.placeholder(tf.float32, shape=[batch_size, input_width]) for _ in xrange(max_sequence_length)] for _ in xrange(num_gpu)]
y = [[tf.placeholder(tf.float32, shape=[batch_size, input_width]) for _ in xrange(max_sequence_length)] for _ in xrange(num_gpu)]
s = [tf.placeholder(tf.int32, shape=[batch_size]) for _ in xrange(num_gpu)]
cell = BasicLSTMCell(num_units = hidden_neurons, input_size = [batch_size, input_width])
initial_state = tf.zeros([batch_size, hidden_neurons * 2]) 
dropout_cell = DropoutWrapper(cell, input_keep_prob=0.9, output_keep_prob=1.0)
initial_state = tf.zeros([batch_size, cell.state_size])

gpu_grads = []  
losses = []
opt = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.99, beta2=0.97)

for i in xrange(num_gpu):
        gpu_id = '/gpu:'+str(i)
        with tf.device(gpu_id), tf.name_scope(gpu_id) as scope:
                print x[i][0].dtype
                outputs, state = rnn.rnn(cell=dropout_cell, inputs = x[i], initial_state=initial_state, sequence_length=s[i], scope = scope)
```

After this I get average of gradients similar to cifar10 multi gpu tutorial example.
"
2384,ps job in the distributed inception trainer killed by OOM killer,"Hi all:
  It seems that the distributed runtime has a memory leak problem, my tf version is the 0.8.0 wheel package from http://tensorflow.org.
  When I started the distributed inception trainer in http://github.com/tensorflow/models/ on a 64G RAM Linux server with 1 ps and 4 replicas, the footprint of the ps process increased slowly but continously, and the process was finally killed by the system oom killer after several days. 
  Anyone can reproduce this? @mrry 
"
2383,machine learning beginner: how to get custom input data to train a conv net?,"I have started learning tensorflow recently. I am trying to input my custom python code as training data. I have generated random exponential signals and want the network to learn from that. This is the code I am using for generating signal-

`import matplotlib.pyplot as plt
import random
import numpy as np

lorange= 1
hirange= 10
amplitude= random.uniform(-10,10)
t= 10
random.seed()
tau=random.uniform(lorange,hirange)
x=np.arange(t)

plt.xlabel('t=time"")
plt.ylabel('x(t)')
plt.plot(x, amplitude*np.exp(-x/tau))
plt.show()`

How can I use this graph as input vector in tensorflow?
"
2382,ValueError: GraphDef cannot be larger than 2GB,"I'm trying to implement a deep autoencoder with tensorflow. The RBM pretraining works just fine, but when it comes to fine tuning, it raises the error: 'ValueError: GraphDef cannot be larger than 2GB'. My input is an array in the shape of [12396, 8192], and here is my layers: [8192 16384 8192 4096 2048 1024 512 256 512 1024 2048 4096 8192 16384 8192]. 
I know where the problem is, but I have no idea how to fix it. I have thought about using multiple graph, but what if my input is too big to even store one layer? Besides I don't know how many graph I should use. Set up a graph for every layer? That would be too slow and unnecessary.
Thank you!
`  ...

```
def __init__(self, input_num, layers, rbm_learning_rate, deepnn_learning_rate, rbm_num_epoch, 
             deepnn_num_epoch, momentum=0, batch_size=128, data_type='float32'):
    self.input_num = input_num
    self.layers = layers
    self.n_layers = len(self.layers)
    self.rbm_learning_rate = rbm_learning_rate
    self.deepnn_learning_rate = deepnn_learning_rate
    if momentum == 0:
        self.momentum = []            
        for _ in range(self.n_layers):            
            self.momentum.append(1)
    self.rbm_num_epoch = rbm_num_epoch
    self.deepnn_num_epoch = deepnn_num_epoch
    self.batch_size = batch_size
    self.data_type = data_type
    self.rbm_list = []
    self.rbm_list.append(RBM(self.input_num, self.layers[0], self.rbm_num_epoch, 
                            self.momentum[0], self.rbm_learning_rate[0], self.batch_size, self.data_type))            
    for i in range(self.n_layers-1):
        self.rbm_list.append(RBM(self.layers[i], self.layers[i+1], self.rbm_num_epoch,
                            self.momentum[i], self.rbm_learning_rate[i], self.batch_size, self.data_type))

def pretrain(self, train_set):
    self.W_list = []
    self.b_list = []
    self.a_list = []   
    if not cmp(train_set.dtype, self.data_type):
        train_set.dtype = self.data_type        
    next_train = train_set        
    for i, rboltz in enumerate(self.rbm_list):
        next_train = self._pretrain_and_get_para(rboltz, next_train)

def _pretrain_and_get_para(self, rboltz, next_train):
    output, W_out, a_out, b_out = rboltz.fit(next_train)
    self.W_list.append(W_out)
    self.a_list.append(a_out)
    self.b_list.append(b_out)
    return output

def fine_tune(self, train_set):
    m, _ = train_set.shape
    self.num_per_epoch = m / self.batch_size         
    train_batch = tf.placeholder(self.data_type, [None, self.input_num])        
    logits = self._build_model(train_batch)
    loss = self._loss(logits, train_batch)
    train_op = self._training(loss)
    init = tf.initialize_all_variables()
    with tf.Session() as sess:
        sess.run(init)
        for _ in range(self.deepnn_num_epoch):
            for i in range(self.num_per_epoch):
                _, cost = sess.run([train_op, loss], feed_dict = self._feed_build(train_batch, train_set, i))
            print cost    

def _feed_build(self, train_batch, train_set, i):
    batch = prepare_data.next_batch(train_set, i, self.batch_size)
    feed_dict = {train_batch: batch}
    return feed_dict    

def _build_model(self, train_batch):      
    middle_layer = self._make_encoder(train_batch)
    last_layer = self._make_decoder(middle_layer)
    return last_layer

def _make_encoder(self, train_batch):
    encoder = []
    encoder.append(train_batch)        
    for i, layer in enumerate(self.layers):
        with tf.name_scope('encoder'+str(i)):
            W = tf.Variable(self.W_list[i], name = 'weights')
            b = tf.Variable(self.b_list[i], name = 'biases')
            encoder.append(tf.sigmoid(b + tf.matmul(encoder[i], W)))
    return encoder[self.n_layers]


def _make_decoder(self, middle_layer):
    decoder = []
    decoder.append(middle_layer)        
    for i, layer in enumerate(self.layers):
        with tf.name_scope('decoder'+str(i)):
            W = tf.Variable(self.W_list[self.n_layers-i-1], name = 'weights')
            a = tf.Variable(self.a_list[self.n_layers-i-1], name = 'biases')
            decoder.append(tf.sigmoid(a + tf.matmul(decoder[i], W, transpose_b = True)))
    return decoder[self.n_layers]        

def _loss(self, logits, labels):
    loss = tf.nn.l2_loss(logits-labels)
    return loss

def _training(self, loss):
    optimizer = tf.train.GradientDescentOptimizer(self.deepnn_learning_rate)
    train_op = optimizer.minimize(loss)
    return train_op `
```
"
2381,understanding the current state of dynamic_rnn vs buckets vs scan for seq2seq,"Bear with me as I am not an expert in the practical or theoretical details. 

Perhaps because tensorflow has developed so rapidly, I find it a little difficult to find the recommended procedure for RNNs with varying length, at least from my lay end-user perspective. It is unclear to me on May 15, 2016 what tool within tensorflow is best suited to this task.

It seems that originally RNNs of varying sequence length were handled by ""bucketing"". This means building a ""separate"" model for each of several bucket lengths so that inputs could be padded to the same length without wasting too much gpu memory. There is not presently a ""simple"" example with bucketing, but to those unfamiliar, I would look to the [seq2seq](https://github.com/tensorflow/tensorflow/blob/3c8780451007c27b69f10925d43d1f3501d94106/tensorflow/models/rnn/translate/seq2seq_model.py) model for clarity. Also the [model_with_buckets function](https://github.com/tensorflow/tensorflow/blob/82ff4cd8b0d541ede107d34d8eecc769c91dda11/tensorflow/python/ops/seq2seq.py)

Sometime between March and May a number of (maybe?) different tools were added that could possibly be used to avoid this bucketing trick without wasting memory.
1. [rnn.py/dynamic_rnn](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py)
2. [functional_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/functional_ops.py#L256), though within this code it's not clear without investigation if map_fn or tf.scan (!) would be better suited.
3. [control_flow_ops](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_ops.py)

In spite of this, the seq2seq model still uses bucketing, and I struggle to find any examples using these newer methods.

Creating detailed documentation is ultimately part of the endgoal, but _for now_ I thought it would be useful to at least make a mention of what the recommended approach is.

Thanks.

[relevant issue 208 ](https://github.com/tensorflow/tensorflow/issues/208)
[relevant reddit with broken link to example](https://www.reddit.com/r/MachineLearning/comments/4dtbks/tensorflow_now_has_an_unofficial_scan_function/)
"
2377,Will there be custom GPU kernels for NHWC Batchnorm in the future?,"NCHW Batchnorm #1759 is one merge away but as it currently stands the NHWC Batchnorm kernel is the single biggest performance killer in very deep networks. My testing shows that Resnet-164's forward pass taking more than twice as much time as that of Resnet-110, simply because the former has an additional BN of increased channel dimension (x4) in each block, despite the two architecture having nearly the same FLOPs.

Edit: Actually meant Resnet-164, not Resnet-152
"
2376,Beginner question: Error when running the conv net example,"I tried to learn Tensorflow and ran the .py file I created by copying the example code on the Tensorflow website. it runs well initially and printing it's training epochs. But finally, it gave some error showing as below:

(tensorflow)xu@xu-ThinkCentre-M72e:~ $ python BuildConvNet.py
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.2545
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.67GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0)
0.9092
step 0, training accuracy 0.04
step 100, training accuracy 0.78
step 200, training accuracy 0.9
step 300, training accuracy 0.86
step 400, training accuracy 0.96
step 500, training accuracy 0.94
step 600, training accuracy 0.9
step 700, training accuracy 0.98
step 800, training accuracy 0.96
step 900, training accuracy 0.92
step 1000, training accuracy 1
step 1100, training accuracy 1
step 1200, training accuracy 1
step 1300, training accuracy 0.94
step 1400, training accuracy 0.98
step 1500, training accuracy 0.98
step 1600, training accuracy 1
step 1700, training accuracy 1
step 1800, training accuracy 0.98
step 1900, training accuracy 1
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (256):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (512):     Total Chunks: 1, Chunks in use: 0 768B allocated for chunks. 6.4KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1024):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2048):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4096):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8192):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (32768):     Total Chunks: 1, Chunks in use: 0 32.0KiB allocated for chunks. 3.1KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (65536):     Total Chunks: 1, Chunks in use: 0 121.8KiB allocated for chunks. 4.79MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (131072):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (262144):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (524288):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (1048576):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (2097152):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (4194304):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (8388608):     Total Chunks: 1, Chunks in use: 0 12.21MiB allocated for chunks. 390.6KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (16777216):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (33554432):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (67108864):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:635] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/bfc_allocator.cc:652] Bin for 29.91MiB was 16.00MiB, Chunk State:
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a40000 of size 31488
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a47b00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a47c00 of size 31488
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a4f700 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a4f800 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a4f900 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a4fa00 of size 31488
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a57500 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a57600 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a57700 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a57800 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a57900 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a57a00 of size 4096
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a58a00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a58b00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a58c00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a58d00 of size 3328
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a59a00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a59b00 of size 204800
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a8bb00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x701a8bc00 of size 12845056
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026cbc00 of size 4096
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026ccc00 of size 40960
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d6c00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d6d00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d6e00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d6f00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7000 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7100 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7200 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7300 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7400 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7500 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7600 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7700 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7b00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7026d7c00 of size 80128
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x702709c00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x702709d00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x702709e00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x702709f00 of size 40960
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703349d00 of size 40960
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703353d00 of size 3328
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703354a00 of size 4096
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703355a00 of size 4096
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703356a00 of size 4096
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x70335fa00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x70335fb00 of size 40960
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703369b00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703369c00 of size 12845056
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703fa9c00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703fa9d00 of size 3328
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703faaa00 of size 3328
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703fab700 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703fab800 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703fab900 of size 204800
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x703fdd900 of size 204800
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x70400f900 of size 204800
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x704041900 of size 12845056
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x704c81900 of size 12845056
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7058c1900 of size 31360000
I tensorflow/core/common_runtime/bfc_allocator.cc:670] Chunk at 0x7076a9d00 of size 1485857536
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x7026d7800 of size 768
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x7026eb500 of size 124672
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x702713f00 of size 12803584
I tensorflow/core/common_runtime/bfc_allocator.cc:679] Free at 0x703357a00 of size 32768
I tensorflow/core/common_runtime/bfc_allocator.cc:685]      Summary of in-use Chunks by size:
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 35 Chunks of size 256 totalling 8.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 4 Chunks of size 3328 totalling 13.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 5 Chunks of size 4096 totalling 20.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 3 Chunks of size 31488 totalling 92.2KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 4 Chunks of size 40960 totalling 160.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 80128 totalling 78.2KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 4 Chunks of size 204800 totalling 800.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 4 Chunks of size 12845056 totalling 49.00MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 31360000 totalling 29.91MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:688] 1 Chunks of size 1485857536 totalling 1.38GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:692] Sum Total of in-use chunks: 1.46GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:694] Stats:
Limit:                  1582759936
InUse:                  1569798144
MaxInUse:               1570198272
NumAllocs:                  275908
MaxAllocSize:           1485857536

W tensorflow/core/common_runtime/bfc_allocator.cc:270] **********************************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 29.91MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:900] Resource exhausted: OOM when allocating tensor with shape[10000,1,28,28]
Traceback (most recent call last):
  File ""BuildConvNet.py"", line 78, in <module>
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 502, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 3334, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,1,28,28]
     [[Node: Conv2D = Conv2D[T=DT_FLOAT, data_format=""NHWC"", padding=""SAME"", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=""/job:localhost/replica:0/task:0/gpu:0""](Reshape, Variable_2/read)]]
     [[Node: Mean_3/_1035 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_911_Mean_3"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Conv2D', defined at:
  File ""BuildConvNet.py"", line 41, in <module>
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File ""BuildConvNet.py"", line 30, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 295, in conv2d
    data_format=data_format, name=name)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/xu/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()

(tensorflow)xu@xu-ThinkCentre-M72e:~ $ 
"
2375,Matplotlib incompatibility when using virtualenv,"RuntimeError when importing matplotlib.pyplot in a jupyter notebook from a virtual environment:

`RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see 'Working with Matplotlib in Virtual environments' in the Matplotlib FAQ`

I have solved the problem using one of the solutions mentioned at: [Matplotlib VirtualEnv FAQ](http://matplotlib.org/faq/virtualenv_faq.html) and that is ok when using python from the command line or a script file, but not with the kernel used in jupyter.

So, the question is: how to create a jupyter kernel that uses a specific bash which properly setups python to use matplotlib within a virtual environment.

Another solution is:

```
import matplotlib  
matplotlib.use('TkAgg')   
import matplotlib.pyplot as plt  
```

But maybe that is not the best thing to do. So, any suggestions?.
Operating System: OS X El capitan
Tensorflow version: 0.8.0
"
2373,Embedding lookup table doesn't mask padding value,"Hi there,

I'm using an _embedding_lookup_ operation in order to generate dense vector representations for each token in my document which are feed to a convolutional neural network (the network architecture is similar to the one in a [WildML article](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)). 

Everything works correctly but when I pad my document inserting a padding value in it, the embedding lookup generates a vector for this token too. I think that this approach could alterate the results in the classification task. What I want to achieve is something similar to what Torch [LookupTableMaskZero](https://github.com/Element-Research/rnn#rnn.LookupTableMaskZerol) does. 

1) Is correct what I want to do?
2) Is already implemented something like this? 
3) If not, how can I mask the padding value in order to prevent the generation of the corresponding vector for it? 

Thank you in advance, 
Alessandro
"
2371,C++ API header files missing from pip install,"I'm building a custom CPU/GPU operator with the pip binary [install](https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl) linked from

https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#pip-installation

Certain header files seem to be missing from the above binary. When following the [Adding an Op](https://www.tensorflow.org/versions/r0.8/how_tos/adding_an_op/index.html) tutorial the following is missing
- tensorflow/core/framework/register_types.h

but also header files for things like the GPU Stream Executor, Temp and Scratch Allocators which appear to be used by the inbuilt tensorflow ops

Is the omission of these header files intentional and if so can we trying using the headers from a source distribution? [Adding an Op](https://www.tensorflow.org/versions/r0.8/how_tos/adding_an_op/index.html) suggests that either a source or binary distribution is suitable for building a custom GPU operator.
"
2370,installation problem in ubuntu 64 gpu,"Tried installing it on ubuntu but getting this error even using Virtualenv:

```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""tensorflow.py"", line 11, in <module>
    W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
AttributeError: 'module' object has no attribute 'Variable'
```
### Environment info

Operating System: Ubuntu
Distributor ID: Ubuntu
Description:    Ubuntu 15.04
x86_64 x86_64 x86_64 GNU/Linux
python 2.7.9

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root 189170 Jan 12 14:47 /usr/local/cuda-7.5/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Jan 12 14:47 /usr/local/cuda-7.5/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Jan 12 14:47 /usr/local/cuda-7.5/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Jan 12 14:47 /usr/local/cuda-7.5/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Jan 12 14:47 /usr/local/cuda-7.5/lib/libcudart_static.a
```

If installed from binary pip package, provide:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
### What have you tried?

1.simple install
2.VirutalEnv install 
Both didn't worked.
"
2367,Incorrect gradients for scatter_add,"Hi Tensorflow Development Team,

Thank you so much for being so patient with me. I am currently working with scatter_add, and have encountered a None gradient where I believe there should be gradients.
### Environment info

Operating System: CentOS

Installed version of CUDA and cuDNN: 
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
CUDA version 7.5
cuDNN version 7.0 (64 bit)
tensorflow/0.8.0-gpu version
### Steps to reproduce

`N_rows = 10`
`N_cols = 3`

`X_ph = tf.placeholder(tf.float32, shape=(None, N_cols))`
`ind_ph = tf.placeholder(tf.int32, shape=(None))`

`Z = tf.Variable(tf.zeros([N_rows, N_cols]))`
`Z = Z.assign(tf.zeros([N_rows, N_cols]))`
`Z_add = tf.scatter_add(Z, ind_ph, X_ph)`
`Z_sum = tf.reduce_sum(Z_add)`

`grad_op = tf.gradients(Z_sum, X_ph)`

`X = np.array([[1,0,1],[2,2,1]])`

`ind = [0, 1]`
### What have you tried?

If you try to differentiate Z_sum with respect to Z_add, you get a nonzero gradient, as expected. However, It seems that if you differentiate Z_sum with respect to Z or X_ph, you get a None, indicating no connection between Z_sum and X_ph or Z. I would definitely expect there to be a connection between Z_add and X_ph/Z. Do you think you could take a look at this and tell me how I might be able to circumvent this issue? Thank you so much for your help!

Best,
Han
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

The output given by tensorflow when evaluating grad_op is
  File ""scatter_update_grad_test.py"", line 34, in <module>
    out = sess.run(grad_op, feed_dict={X_ph : X, ind_ph : ind})
  File ""/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py"", line 523, in _run
    processed_fetches = self._process_fetches(fetches)
  File ""/share/sw/free/tensorflow/0.8.0/tensorflow/python/client/session.py"", line 493, in _process_fetches
    % (subfetch, fetch, type(subfetch), str(e)))
TypeError: Fetch argument None of None has invalid type <type 'NoneType'>, must be a string or Tensor. (Can not convert a NoneType into a Tensor or Operation.)

If I take grad_op = tf.gradients(Z_sum, Z_add), I obtain
array([[ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.]], dtype=float32)]

as expected since we are using reduce sum.
"
2366,Functional ops don't accept Python lists as input.,"See error reported in [this Stack Overflow question](http://stackoverflow.com/q/37221092/3574081):

> ``` python
> import tensorflow as tf
> elems = [1, 2, 3, 4, 5, 6]
> squares = tf.map_fn(lambda x: x * x, elems)
> ```
> 
> Running this gives this error:
> 
> ```
> /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.pyc in make_tensor_proto(values, dtype, shape)
>     323   else:
>     324     if values is None:
> --> 325       raise ValueError(""None values not supported."")
>     326     # if dtype is provided, forces numpy array to be the type
>     327     # provided if possible.
> 
> ValueError: None values not supported.
> ```

The functions in [`functional_ops.py`](https://github.com/tensorflow/tensorflow/blob/ddd86c0ff110b332171638890ba990d79def877b/tensorflow/python/ops/functional_ops.py) each expect their `elems` inputs to have a `dtype` property. As a side-issue, they convert their input to a tensor multiple times (implicitly on use), which could create a wasteful number of constants if the input is a numpy array.
"
2365,pip install problem:SSLError,"I encountered "" SSLError: hostname 'storage.googleapis.com' doesn't match 'www.google.com' ""
after typing ""sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl"" 
can somebody help me fix this? thanks a lot!
"
2364,zlib.h not found when compile tensorflow with GPU support,"I am trying to compile tensorflow from source. I can build it **successfully** with CPU support only( i.e. not use `--config=cuda`) .

But when I try to build it with GPU support, I get error:

```
[chaowei@node07 tensorflow]$ export EXTRA_BAZEL_ARGS='-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'
[chaowei@node07 tensorflow]$ 
[chaowei@node07 tensorflow]$ /gpfs/home/chaowei/download/bazel-0.1.5/output/bazel  build -c opt --config=cuda --linkopt '-lrt' --copt=""-DGPR_BACKWARDS_COMPATIBILITY_MODE"" --conlyopt=""-std=c99"" //tensorflow/tools/pip_package:build_pip_package
...........
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
ERROR: /gpfs/home/chaowei/.cache/bazel/_bazel_chaowei/2ce35f089de902cec16e4a2c6a450834/external/grpc/BUILD:485:1: C++ compilation of rule '@grpc//:grpc_unsecure' failed: gcc failed: error executing command /gpfs/home/chaowei/software/gcc-6.1.0/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 ... (remaining 39 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/grpc/src/core/compression/message_compress.c:41:18: fatal error: zlib.h: No such file or directory
 #include <zlib.h>
                  ^
compilation terminated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 71.894s, Critical Path: 58.77s
```

**I also compile python3 from source in my computer. And when I `import zlib`, it works fine.**

Here is the information of my system:
`[chaowei@mgt ~]$ cat /etc/redhat-release Red Hat Enterprise Linux Server release 6.5 (Santiago)`

```
[chaowei@node07 gcc-6.1.0]$ gcc -v
built-in specs
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/gpfs/home/chaowei/software/gcc-6.1.0/libexec/gcc/x86_64-pc-linux-gnu/6.1.0/lto-wrapper
Targetx86_64-pc-linux-gnu
Configured with./configure --prefix=/gpfs/home/chaowei/software/gcc-6.1.0
Thread modelposix
gcc version 6.1.0 (GCC) 
```

I wonder  why I get `zlib.h` error  when I only build tensorflow with GPU support.
"
2363,(skflow) issue in batch normalization after restore,"Hi,
I'm using Tensorflow [last succeed build #85](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/lastSuccessfulBuild/)

I succeed to train a classifier with batch normalization and saving it with classifier.save(logdir) and restoring the classifier with 
classifier = tf.contrib.skflow.TensorFlowEstimator.restore(logdir)

the classifier is restored but when using prediction classifier.predict(X_test) it seems that the batch normalization is applied as is in Training mode.

Looking to the code of batch normalization (batch_norm_ops.py)
`is_training = array_ops_.squeeze(ops.get_collection(""IS_TRAINING""))
    mean, variance = control_flow_ops.cond(is_training, update_mean_var,
                                           lambda: (ema_mean, ema_var))`

I suppose as the graph is loaded in restore step, the ""IS_TRAINING"" is defined at the state of True at the saved step. and the cond function used will be update_mean_var at predict step , however the ""IS_TRAINING"" is changed at _predict step.
you can detect the problem when classifying 2 class problem and adding a batch normalization before the softmax the mean of the softmax of any tested data will be 0.

Maybe a solution will be to use a placeholder in place of the variable is_training

Or I'm missing something ?
"
2362,Tensor flow installation problem: import error,"I am having the following issue when I try to install TensorFlow for Python 2.7 on mac OS. This seems to be an issue with Tensor flow's libraries, thank you for your help!

![screen shot 2016-05-14 at 3 11 14 pm](https://cloud.githubusercontent.com/assets/8773483/15266421/badcb0ec-19e7-11e6-9ad5-599c656cba59.png)
"
2361,Why the software history was not kept?,"Hi there, 

I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. Tensorflow was in my list. However, I observed that the software history of when the software was developed as a proprietary software was not kept after the transition to Github.

Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask **TensorFlow** developers the following four brief questions:
1. Why did you decide to not keep the software history?
2. Do the _core developers_ faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems?
3. Do the _newcomers_ faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems?
4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software?

Thanks in advance for your collaboration,

Gustavo Pinto, PhD
http://www.gustavopinto.org
"
2358,scatter_add for non variable tensors,"Hi,

I am interested in using scatter_add when the tensor being update is not a variable. Is this possible?

I am looking to do something like this:

`X1_ph = tf.placeholder(tf.float32, shape=(None, 3))`
`ind_ph = tf.placeholder(tf.int32, shape=(None))`

`#Z = tf.Variable(tf.zeros([10, 3]))`
`Z = tf.zeros([10, N_feat])`

`X1 = np.array([[1,0.00,1],`
`[2,0.00,1],`
`[3,0.00,1],`
`[5,0.00,1.1],`
`[6,1.0,1.8]])`

`ind = [0, 1, 1, 0, 0]`

`Z = tf.scatter_add(Z, ind_ph, X1)`

If I declare Z as a tf.Variable, I can do this, but I need to call this operation hundreds of thousands of times, and do not want to store any copies of Z once I am done with them. If I were to declare Z as a Variable, would there be any way to destroy Z once I am done with it (maybe with a garbage collector or something similar)? Thank you so much for your help!
"
2355,skflow example text_classification needs file text_datasets.py,"### Environment info

Operating System:

0.8.0

pip version 0.8.0 installation using

sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl

does not install text_datasets.py needed to run several skflow examples using text_classification su as 

tensorflow/tensorflow/examples/skflow/text_classification.py

the location of text_datasets.py is at

tensorflow/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py

See image below comparing the pip installed directory structure with the github structure.

![both](https://cloud.githubusercontent.com/assets/5605614/15260720/47deb1f6-190d-11e6-97cb-02d4ce859929.png)
"
2354,add shuffling option to tf.train.batch which handles variable-length sequence,"tf.train.batch is the only one can handle variable-length sequence, but it does not have shuffling option.
For RNN training, shuffling is needed.
"
2353,Tensorboard: graph is shown but no scalar data was found,"I can see the graph, but no scalar is shown.
## Environment info

Mac OS 10.11.4
Anaconda Python 2.7
Tensoflow installed from binary pip package
The output from python -c ""import tensorflow as tf; print(tf.**version**)"": 0.8.0
## About the code

I am trying to log values of loss using: `tf.scalar_summary('loss',loss)`

I have the writer set to a particular folder: `summary_writer = tf.train.SummaryWriter(LogDir, sess.graph)`

After calling `sess.run([optimizer, loss, learning_rate, train_prediction], feed_dict=feed_dict)` I do `summary_writer.flush()`
## What have you tried?

I can see a log file called events.out.tfevents.1463159389.Matheuss-MacBook-Pro.local in the folder I set. The file is about **16Mb** big.

I call `tensorboard --logdir=/Users/mviana/Desktop/tf/log/` --debug and I can verify the log dir is correct.

On the browser I can see the graph corresponding to my deep neural network, but no scalar is shown.

If I call `tensorboard --inspect --logdir=/Users/mviana/Desktop/tf/log/` nothing but `Starting TensorBoard 16 on port 6006 (You can navigate to http://0.0.0.0:6006)` is shown in the terminal.

If I comment the line `tf.scalar_summary('loss',loss)` the log file size remains unchanged. So, it seems that only the graph is being logged.
"
2351,No gradient for log_softmax,"It appears that the log_softmax doesn't have a gradient:

```
>>> import tensorflow as tf
>>> var = tf.Variable([[1.0, 2.0]])
>>> softmax = tf.nn.softmax(var)
>>> log_softmax = tf.nn.log_softmax(var)
>>> entropy = tf.reduce_sum(softmax * log_softmax)
>>> trainer = tf.train.GradientDescentOptimizer(0.1).minimize(-entropy)
LookupError: gradient registry has no entry for: LogSoftmax
```
"
2348,Build failure ArchLinux with nvcc + gcc 6.1.1,"Just downloaded and built on Archlinux, and it failed with:

```
external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(828): error: more than one instance of overloaded function ""fmin"" matches the argument list:
            function ""std::fmin(float, float)""
            function ""fmin(float, float)""
            argument types are: (const float, const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/MathFunctions.h(840): error: more than one instance of overloaded function ""fmax"" matches the argument list:
            function ""std::fmax(float, float)""
            function ""fmax(float, float)""
            argument types are: (const float, const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(126): error: more than one instance of overloaded function ""erf"" matches the argument list:
            function ""std::erf(float)""
            function ""erf(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(126): error: more than one instance of overloaded function ""erf"" matches the argument list:
            function ""std::erf(float)""
            function ""erf(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(126): error: more than one instance of overloaded function ""erf"" matches the argument list:
            function ""std::erf(float)""
            function ""erf(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(126): error: more than one instance of overloaded function ""erf"" matches the argument list:
            function ""std::erf(float)""
            function ""erf(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(138): error: more than one instance of overloaded function ""erfc"" matches the argument list:
            function ""std::erfc(float)""
            function ""erfc(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(138): error: more than one instance of overloaded function ""erfc"" matches the argument list:
            function ""std::erfc(float)""
            function ""erfc(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(138): error: more than one instance of overloaded function ""erfc"" matches the argument list:
            function ""std::erfc(float)""
            function ""erfc(float)""
            argument types are: (const float)

external/eigen_archive/eigen-eigen-50812b426b7c/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/CUDA/MathFunctions.h(138): error: more than one instance of overloaded function ""erfc"" matches the argument list:
            function ""std::erfc(float)""
            function ""erfc(float)""
            argument types are: (const float)

10 errors detected in the compilation of ""/tmp/tmpxft_000017f0_00000000-10_batchtospace_op_gpu.cu.compute_52.cpp1.ii"".
ERROR: /.../tensorflow/tensorflow/core/kernels/BUILD:1320:1: output 'tensorflow/core/kernels/_objs/batchtospace_op_gpu/tensorflow/core/kernels/batchtospace_op_gpu.cu.o' was not created.
ERROR: /.../tensorflow/tensorflow/core/kernels/BUILD:1320:1: not all outputs were created.
```

gcc version 6.1.1 20160501 (GCC) 
Cuda compilation tools, release 7.5, V7.5.17
cudnn version 5
ecd5b7255e05634cad6ea5e0bc680f7a9d981ba8
"
2345,Numpy Layer,"Is there no way for me to create a new layer in python as a function with inputs and outputs as cpu numpy arrays. This would be especially useful for certain custom operations (say an opencv call in the middle of the network, or a special logging layer). But as far as I can tell, it is not available, and one has to go through the hassle of writing a c++ layer and recompiling to be able to get direct access to any data below the symbolic level. Am I missing something?

The fact I can't do this creates massive workarounds. In some cases, I call sess.run() once, getting the result as a numpy array, do my operations, and then call sess.run() again. So there are 2 sess.run() calls for one iteration of training.
"
2343,Distributed Runtime protos aren't sandbox compatible,"The master/worker protos don't include their dependent source files in the rules that constitute them in a way that enables tensorflow to be used from a skylark rule. This is annoying.
"
2342,"""_too_large_attrs"" for Graph visualization on Tensorboard. ","I am not sure if this issue is beyond the Github scope. If it is, I apologize.

I am trying to visualize the computation graph for the project I am working. I can see all the histograms as well as the events. However, computation graph visualization displays following message.

![](https://raw.githubusercontent.com/agupta83/shared_data/master/tf-failed_adding_edges.png)
Please find the [tfevent-file](https://drive.google.com/folderview?id=0BzP3qMqdjzOwb1pGN2diWElyNWs&usp=sharing) shared on google drive
### Environment info

Operating System: Ubuntu 14.04. 

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root  60M Apr 10 17:49 /usr/local/cuda-7.5/lib64/libcudnn_static.a
-rw-r--r-- 1 root root  59M Apr 10 17:49 /usr/local/cuda-7.5/lib64/libcudnn.so.7.0.64
-rw-r--r-- 1 root root  59M Apr 10 17:49 /usr/local/cuda-7.5/lib64/libcudnn.so.7.0
-rwxr-xr-x 1 root root  59M Apr 10 17:49 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rwxr-xr-x 1 root root  59M Apr 10 17:49 /usr/local/cuda-7.5/lib64/libcudnn.so.4
-rw-r--r-- 1 root root  59M Apr 10 17:49 /usr/local/cuda-7.5/lib64/libcudnn.so
-rw-r--r-- 1 root root 316K Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
-rw-r--r-- 1 root root 704K Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 root root   16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root   19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 375K Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
```

If installed from binary pip package, provide:
1. Which pip package you installed.

Virtualenv with `https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl`
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: 'module' object has no attribute 'version'
```

If installed from sources, provide the commit hash:
- Build from source with commit 2296dd8060ce77c71fc820c77442835f050399dd
### Steps to reproduce
1. Download the tf [tfevent-file](https://drive.google.com/folderview?id=0BzP3qMqdjzOwb1pGN2diWElyNWs&usp=sharing).
2. `tensorboard --logdir=path/to/downloaded/folder/`
### What have you tried?
1. Modified `prepare_graph_for_ui` [process_graph.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/backend/process_graph.py) from `limit_attr_size=1024` to `limit_attr_size=None`
2. Modified `LIMIT_ATTR_SIZE = 1024` in [`graph.ts` ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/components/tf-graph-common/lib/graph.ts) to large value (5 \* 1024 \* 1024).
3. Explicitly built tensorboard using `bazel build tensorflow/tensorboard:tensorboard`
### Logs or other output that would be helpful

```
...
...
...
127.0.0.1 - - [12/May/2016 10:43:58] ""GET /data/runs HTTP/1.1"" 200 -
127.0.0.1 - - [12/May/2016 10:43:58] ""GET /data/runs HTTP/1.1"" 200 -
127.0.0.1 - - [12/May/2016 10:44:02] ""GET /data/graph?run=.&limit_attr_size=1024&large_attrs_key=_too_large_attrs HTTP/1.1"" 200 -
```

![](https://raw.githubusercontent.com/agupta83/shared_data/master/tf-failed_adding_edges.png)
"
2340,Tensor.eval() Performance Decay,"I used Tensorflow 0.6 (I pip installed TensorFlow: `pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.6.0-cp34-none-linux_x86_64.whl`) with Python 3 to train Neural Network on GPU (Nvidia GeForce GTX Titan X with Cuda 7.0 and Cudnn 6.5), and I noticed an interesting problem: The time consumption for running `tensor.eval(session=..., feed_dict=...)` at each iteration was continuously growing as iteration goes by, which indicated that performance of tensor.eval() decayed. Specifically, the code looks like this:

```
import tensorflow as tf
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)
session = tf.Session(config=tensorflow.ConfigProto(gpu_options=gpu_options))

""""""Then build the neural network tensor graph, For example,""""""
""""""we define an neural network to compute output layer tensor a.""""""

# input tensor is an numpy array with dimension 32 * 336 * 84.
dict = {input_tensor: input_tensor}
for _ in 1000000:
     a.eval(session=session, feed_dict=dict)
```

In this code, the running time for each `a.eval()` gradually got larger and larger as iteration time goes by. So I used Profiling tooI (CProfile) to dig into the code to see at which part of code performance going wrong, and it indicated that time consumption for executing `built-in method TF_Run` for running `a.eval()` was very long and kept growing. I am pretty sure the `input_tensor` size keeps exactly same for each iteration, I wonder if anyone can help me figure out the problem, and how I can improve my current performance. Thanks!!!
"
2335,"""bazel test"" fails on MacOS with setuptools-21.0","I just went through official MacOS instructions to setup bazel/swig and tried the following

```
git clone --recurse-submodules https://github.com/tensorflow/tensorflow
cd tensorflow
./configure
bazel test -c opt //tensorflow/python/...
```

They all fail with stack trace like below, any suggestions?

```
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_yaroslavvb/ea642be0829ea15e6d2092d22e894d3d/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/python/zero_division_test.runfiles/tensorflow/python/kernel_tests/zero_division_test.py"", line 22, in <module>
    import tensorflow as tf
  File ""/Users/yaroslavvb/g/src/hacking/tensorflow/_python_build/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Users/yaroslavvb/g/src/hacking/tensorflow/_python_build/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/Users/yaroslavvb/g/src/hacking/tensorflow/_python_build/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/Library/Python/2.7/site-packages/protobuf-3.0.0b2-py2.7.egg/google/__init__.py"", line 1, in <module>

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2927, in <module>

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2913, in _call_aside

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2952, in _initialize_master_working_set

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 956, in subscribe

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2952, in <lambda>

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2515, in activate

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2097, in declare_namespace

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2047, in _handle_ns

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2066, in _rebuild_mod_path

  File ""/Library/Python/2.7/site-packages/setuptools-21.0.0-py2.7.egg/pkg_resources/__init__.py"", line 2064, in position_in_sys_path

ValueError: '/private/var/tmp/_bazel_yaroslavvb/4a326dbae226c596bf5de825a172dee9/tensorflow/bazel-out/local_darwin-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles' is not in list
```
"
2334,Immediate-mode execution in TensorFlow,"Mirror TensorFlow API to provide ""numpy/Torch""-like mode for executing TensorFlow programs. 

Briefly, provide a mode where you can do the following: 

```
a = tf.constant([[1,1],[1,1]])   # constant is created
b = tf.constant([[2,2],[2,2]])
c = tf.matmul(a, b)  # executes matrix multiplication
print c                      # transfers contents of c from TensorFlow runtime to Python runtime and prints it

```

Goals
1. No separation between graph-construction and evaluation - each op is executed in TensorFlow runtime the moment the corresponding wrapper is evaluated by Python
2. Reuse of TensorFlow Graph for efficiency. For instance, after float32 addition was performed once, any additional float32 addition operations should be done by reusing previously created OpDef
3. Immediate-style Tensor object implements functions in [3.4.8. Emulating numeric types](https://docs.python.org/2/reference/datamodel.html#emulating-numeric-types) and translates them to appropriate TensorFlow operations 
4. Immediate-style Tensor object keep contents of underlying tensors in TensorFlow runtime and only transfers them to Python when necessary, such when needed for flow control and printing.

Design doc: https://docs.google.com/document/d/1CRfhT2_-EaboFbN1U7gKXlGIVAZ21bWpcl1fOwDZLjw/edit#heading=h.yhcm0hj5bq25

CLA signed (for design doc). I'll start submitting code for this as soon as I figure out github/bazel workflow

@keveman @yuanbyu 
"
2333,"Building from source fail, error in tensorflow/core/lib/core/threadpool.cc","Hi, 
I try to build tensorflow from source, but I get the ERROR as following:

```
ERROR: /WORK/sysu_sc_ll/tf-rh/tensorflow-/tensorflow/core/BUILD:766:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command /HOME/sysu_sc_ll/WORKSPACE/tf-rh/bazel-/hackbin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/HOME/sysu_sc_ll/WORKSPACE/tf-rh/bazel-/hackbin -B/usr/bin ... (remaining 78 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/core/lib/core/threadpool.cc:82:49: error: expected template-name before '<' token
 struct ThreadPool::Impl : Eigen::ThreadPoolTempl<EigenEnvironment> {
                                                 ^
tensorflow/core/lib/core/threadpool.cc:82:49: error: expected '{' before '<' token
tensorflow/core/lib/core/threadpool.cc:82:49: error: expected unqualified-id before '<' token
tensorflow/core/lib/core/threadpool.cc:220:1: error: expected '}' at end of input
 }  // namespace tensorflow
 ^
tensorflow/core/lib/core/threadpool.cc:220:1: error: expected '}' at end of input
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 12.663s, Critical Path: 10.84s

```

OS:  redhat 6.7
gcc: 4.9.2
building with cuda

run command:
export EXTRA_BAZEL_ARGS='-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

I did not change any source file,
And previously, the is another error in the source tensorflow/core/lib/io/record_reader.cc
which claim that the SIZE_MAX is not defined, I solve it by define it as size_t -1. And now this error show up.

Could anyone give me some help here? Thanks.
"
2332,install_name_tool error when running reduction_ops_test_gpu on OS X,"I ran into this while testing my patch tensorflow/tensorflow#1289 on OS X. At first, I thought that it was caused by my patch but then I found that it also reproduces at HEAD.

I am not entirely sure whether this is a TensorFlow issue (the error seems to indicate that we need to add a `ld` flag) or a Bazel issue in the gcc wrapper.

+cc @lberki @damienmg
### Environment info

Operating System: Mac OS X 10.11.4

Installed version of CUDA and cuDNN: Building without GPU support

If installed from sources, provide the commit hash: d3d1a63a8b8ad99347d95756e88ae0589ed1a9b0
### Steps to reproduce
1. Run `bazel test //tensorflow/core/kernels:reduction_ops_test_gpu` on OS X
### What have you tried?
1. This does not reproduce on Linux
### Logs or other output that would be helpful

```
 bazel test //tensorflow/core/kernels:reduction_ops_test_gpu --test_output=errors
WARNING: /private/var/tmp/_bazel_dzc/50d95479571c8b29601dcbccdd342764/external/re2/WORKSPACE:1: Workspace name in /private/var/tmp/_bazel_dzc/50d95479571c8b29601dcbccdd342764/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
WARNING: /Users/dzc/Projects/tensorflow/tensorflow/google/protobuf/BUILD:59:16: in includes attribute of cc_library rule //google/protobuf:protobuf_lite: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
WARNING: /Users/dzc/Projects/tensorflow/tensorflow/google/protobuf/BUILD:124:16: in includes attribute of cc_library rule //google/protobuf:protobuf: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
WARNING: /Users/dzc/Projects/tensorflow/tensorflow/google/protobuf/BUILD:266:16: in includes attribute of cc_library rule //google/protobuf:protoc_lib: 'src/' resolves to 'google/protobuf/src' not in 'third_party'. This will be an error in the future.
INFO: Found 1 test target...
ERROR: /Users/dzc/Projects/tensorflow/tensorflow/tensorflow/core/kernels/BUILD:1044:1: Linking of rule '//tensorflow/core/kernels:reduction_ops_test_gpu' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -o bazel-out/local-fastbuild/bin/tensorflow/core/kernels/reduction_ops_test_gpu '-Wl,-rpath,$ORIGIN/../../../_solib_darwin/' ... (remaining 53 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
clang: warning: argument unused during compilation: '-pthread'
error: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/install_name_tool: changing install names or rpaths can't be redone for: bazel-out/local-fastbuild/bin/tensorflow/core/kernels/reduction_ops_test_gpu (for architecture x86_64) because larger updated load commands do not fit (the program must be relinked, and you may need to use -headerpad or -headerpad_max_install_names)
Target //tensorflow/core/kernels:reduction_ops_test_gpu failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 0.623s, Critical Path: 0.49s

Executed 0 out of 1 test: 1 fails to build.
```
"
2331,No ability to verify a jpeg before decode_jpeg-ing,"Say we are writing images to a dir and feeding them to a TF queue.  If TF goes to read a JPEG that isn't there for some reason or hasn't finished writing, `decode_jpeg` will fail.  Using something like `os.stat()` will not work on the tensor that `decode_csv` returns.

It would be great if we could verify a jpeg is our target image size before decoding so TF doesn't shutdown completely.
"
2330,softmax_classifier input argument not right?,"The softmax_classifier in losses_ops.py file seems not right to me. I haven't done any test yet, but just look at the the input argument definition, the tensor_in and weight are not compatible for matrix multiplication. 
====== begin ============
tensor_in: Input tensor, [batch_size, feature_size], features.
    labels: Tensor, [batch_size, n_classes], labels of the output classes.
    weights: Tensor, [batch_size, feature_size], linear transformation
      matrix.
    biases: Tensor, [batch_size], biases.
======== end ==============
Their inner dimensions do not match for matmul in xw_plus_b function. 

Also, since it is done in a batch, isn't it we should use batch_matmul?
"
2328,Can't mix tensors and python objects,"I'd like to do things such as the following:

``` python
>>> tf.convert_to_tensor([tf.constant(1), 2])
>>> tf.slice(..., [0, 1, some_tensor], ...)
```

Currently both of these raise exceptions. The alternative is to use a combination of `tf.expand_dims` and `tf.concat`, which is a bit unwieldy.
"
2327,Numerical Problem in tf.nn.softmax_cross_entropy_with_logits ,"The function `tf.nn.softmax_cross_entropy_with_logits(logits, labels)` is numerical unstable when used in weak labelling scenarios (i.e. there are no labels for some rows of the labels). 

The instability does not occure, when using `tf.nn.softmax` followed by a simple cross_entropy implementation, i.e.:

```
epsilon = tf.constant(value=0.00001, shape=shape)
logits = logits + epsilon
softmax = tf.nn.softmax(logits)
cross_entropy = -tf.reduce_sum(labels * tf.log(softmax),
                                                 reduction_indices=[1])
```

I therefore conclude, that this is a bug occurring in the softmax layer. I can not give a a minimal example, as it only occurs in bigger models. Also, I did only observe the Bug when using `weakly labeled data`, that is, when cases without labels occur. This case however is explicitly mentioned in the documentation. 

`labels: Each row labels[i] must be a valid probability distribution or all zeros. If all zeros, the corresponding loss will be 0, regardless of the contents of logits[i].`

If the unstability occurs, tf.nn.softmax_cross_entropy_with_logits() produces high gradients, causing the training process to diverge. This usually happens after about 450 iterations. Changing the learning rate will not avoid this issue.
### Environment info

Operating System: Linux

Installed version of CUDA and cuDNN: CUDA 7.5; CUDNN 7.0

Installed from Pip: 
1. Which pip package you installed. `https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl`
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"". 0.8.0
### Steps to reproduce
1. Use loss function provided below
2. Use data containing about 10% unlabeled entries.
### What have you tried?
1. Implementing tf.nn.softmax_cross_entropy_with_logits() myselfe. It works fine.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

The error occurs, when estimating the loss like below.

```
def loss(hypes, logits, labels):
    """"""Calculates the loss from the logits and the labels.
    Args:
      logits: Logits tensor, float - [batch_size, 2].
      labels: Labels tensor, int32 - [batch_size, 2].
    Returns:
      loss: Loss tensor of type float.
    """"""

    with tf.name_scope('loss'):
        logits = tf.reshape(logits, (-1, 2))
        labels = tf.to_float(tf.reshape(labels, (-1, 2)))
        shape = [logits.get_shape()[0], 2]
        epsilon = tf.constant(value=hypes['solver']['epsilon'], shape=shape)
        logits = logits + epsilon
        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(
            logits, labels, name='xentropy')

        cross_entropy_mean = tf.reduce_mean(
            cross_entropy, name='xentropy_mean')
        tf.add_to_collection('losses', cross_entropy_mean)

        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return loss
```

When the error occurs my training output looks like this:

```
2016-05-10 20:20:56,256 root INFO Step 0/10000: loss = 11.98 ( 0.013 sec (per Batch); 74.5 examples/sec)
2016-05-10 20:21:01,804 root INFO Step 10/10000: loss = 11.47 ( 0.028 sec (per Batch); 35.1 examples/sec)
2016-05-10 20:21:07,565 root INFO Step 20/10000: loss = 10.82 ( 0.029 sec (per Batch); 34.7 examples/sec)
2016-05-10 20:21:12,554 root INFO Step 30/10000: loss = 10.32 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:21:17,317 root INFO Step 40/10000: loss = 9.90 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:21:22,387 root INFO Step 50/10000: loss = 9.50 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:21:27,209 root INFO Step 60/10000: loss = 9.27 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:21:32,134 root INFO Step 70/10000: loss = 8.75 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:21:37,198 root INFO Step 80/10000: loss = 8.34 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:21:42,074 root INFO Step 90/10000: loss = 8.10 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:21:49,483 root INFO Doing Evaluate with Training Data.
2016-05-10 20:22:09,883 root INFO Data: train  Num examples:  200  Num correct:  168.3478 Precision @ 1:  0.8417 
2016-05-10 20:22:09,883 root INFO Doing Evaluation with Testing Data.
2016-05-10 20:22:15,032 root INFO Data: val  Num examples:  50  Num correct:  41.3079 Precision @ 1:  0.8262 
2016-05-10 20:22:15,323 root INFO Step 100/10000: loss = 8.03 ( 0.003 sec (per Batch); 344.2 examples/sec)
2016-05-10 20:22:20,180 root INFO Step 110/10000: loss = 7.56 ( 0.028 sec (per Batch); 35.2 examples/sec)
2016-05-10 20:22:25,208 root INFO Step 120/10000: loss = 7.13 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:22:30,053 root INFO Step 130/10000: loss = 6.93 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:22:34,883 root INFO Step 140/10000: loss = 6.65 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:22:39,765 root INFO Step 150/10000: loss = 6.34 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:22:44,741 root INFO Step 160/10000: loss = 6.23 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:22:49,867 root INFO Step 170/10000: loss = 5.88 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:22:54,890 root INFO Step 180/10000: loss = 5.70 ( 0.028 sec (per Batch); 35.2 examples/sec)
2016-05-10 20:22:59,822 root INFO Step 190/10000: loss = 5.61 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:23:07,190 root INFO Doing Evaluate with Training Data.
2016-05-10 20:23:27,775 root INFO Data: train  Num examples:  200  Num correct:  167.6011 Precision @ 1:  0.8380 
2016-05-10 20:23:27,776 root INFO Doing Evaluation with Testing Data.
2016-05-10 20:23:32,933 root INFO Data: val  Num examples:  50  Num correct:  42.5874 Precision @ 1:  0.8517 
2016-05-10 20:23:33,231 root INFO Step 200/10000: loss = 5.41 ( 0.003 sec (per Batch); 336.0 examples/sec)
2016-05-10 20:23:38,108 root INFO Step 210/10000: loss = 5.36 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:23:43,053 root INFO Step 220/10000: loss = 5.05 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:23:48,021 root INFO Step 230/10000: loss = 4.96 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:23:52,982 root INFO Step 240/10000: loss = 4.70 ( 0.028 sec (per Batch); 35.2 examples/sec)
2016-05-10 20:23:58,049 root INFO Step 250/10000: loss = 4.55 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:24:03,004 root INFO Step 260/10000: loss = 4.43 ( 0.028 sec (per Batch); 35.1 examples/sec)
2016-05-10 20:24:07,973 root INFO Step 270/10000: loss = 4.32 ( 0.029 sec (per Batch); 35.0 examples/sec)
2016-05-10 20:24:12,886 root INFO Step 280/10000: loss = 4.14 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:24:17,765 root INFO Step 290/10000: loss = 4.80 ( 0.028 sec (per Batch); 35.3 examples/sec)
2016-05-10 20:24:25,209 root INFO Doing Evaluate with Training Data.
2016-05-10 20:24:45,899 root INFO Data: train  Num examples:  200  Num correct:  156.8744 Precision @ 1:  0.7844 
2016-05-10 20:24:45,900 root INFO Doing Evaluation with Testing Data.
2016-05-10 20:24:51,048 root INFO Data: val  Num examples:  50  Num correct:  40.3362 Precision @ 1:  0.8067 
2016-05-10 20:24:51,349 root INFO Step 300/10000: loss = 6.08 ( 0.003 sec (per Batch); 333.3 examples/sec)
2016-05-10 20:24:56,176 root INFO Step 310/10000: loss = 136.59 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:25:01,130 root INFO Step 320/10000: loss = 2029.89 ( 0.028 sec (per Batch); 35.6 examples/sec)
2016-05-10 20:25:05,964 root INFO Step 330/10000: loss = 75585.02 ( 0.028 sec (per Batch); 35.6 examples/sec)
2016-05-10 20:25:10,901 root INFO Step 340/10000: loss = 7492798.00 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:25:15,863 root INFO Step 350/10000: loss = 50291024.00 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:25:20,790 root INFO Step 360/10000: loss = 1344814592.00 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:25:25,716 root INFO Step 370/10000: loss = 8610205696.00 ( 0.028 sec (per Batch); 35.4 examples/sec)
2016-05-10 20:25:30,749 root INFO Step 380/10000: loss = 344546377728.00 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:25:35,588 root INFO Step 390/10000: loss = 2766554529792.00 ( 0.028 sec (per Batch); 35.5 examples/sec)
2016-05-10 20:25:43,335 root INFO Doing Evaluate with Training Data.
```

When training longer, the loss will eventually become `Nan`. The error does not occure, when using the following `Loss` Code:

```
def loss(hypes, logits, labels):
    """"""Calculates the loss from the logits and the labels.

    Args:
      logits: Logits tensor, float - [batch_size, 2].
      labels: Labels tensor, int32 - [batch_size, 2].

    Returns:
      loss: Loss tensor of type float.
    """"""
    with tf.name_scope('loss'):
        logits = tf.reshape(logits, (-1, 2))
        shape = [logits.get_shape()[0], 2]
        epsilon = tf.constant(value=hypes['solver']['epsilon'], shape=shape)
        logits = logits + epsilon
        labels = tf.to_float(tf.reshape(labels, (-1, 2)))

        softmax = tf.nn.softmax(logits)
        cross_entropy = -tf.reduce_sum(labels * tf.log(softmax),
                                       reduction_indices=[1])

        cross_entropy_mean = tf.reduce_mean(cross_entropy,
                                            name='xentropy_mean')
        tf.add_to_collection('losses', cross_entropy_mean)

        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return loss
```
"
2326,tf.QueueBase.close() docs,"I think the docs should specify that a dequeue might raises a OutOfRange error.
Right?
"
2325,Random numbers and tf.less_equal,"### Environment info

Operating System: Ubuntu 16.04 LTS 64-Bit
Installed version of CUDA and cuDNN: none
Tensorflow Version: 0.8.0
### Steps to reproduce
1. When comparing a random variable with a tensor using the tf.less_equal operation, the output result is wrong. I can reproduce the error with the minimal example code shown below. When I use a fixed number rather than a random variable, the output result is correct.

`
import tensorflow as tf
import numpy as np

x=[0,0.3333,0.6666,1] # matrix that I want to compare against another number
x = tf.convert_to_tensor(np.reshape(x,[2,2]), dtype=tf.float32) # turn into tensor
y = tf.random_uniform([1,1], minval=0, maxval=1, dtype=tf.float32, seed=12) # random number
# y = tf.convert_to_tensor(0.63615251, dtype=tf.float32) **# uncomment to use fixed number instead**

**z = tf.less_equal(x,y)**

init_op = tf.initialize_all_variables()  
with tf.Session() as sess:
  sess.run(init_op)
  xe = x.eval()
  ye = y.eval()
  ze = z.eval()

  print('2-by-2 matrix x:')
  print(xe)
  print(' ')
  print('random value y:')
  print(ye)
  print(' ')
  print('output result of x <= y:')
  print(ze)
`
### I tried:
1. I tried using tf.tile to make ""y"" the same size as ""x""
2. I checked with fixed numbers rather than random numbers; then tf.less_equal works just fine
### Console output of above minimal example

2-by-2 matrix x:
[[ 0.          0.33329999]
 [ 0.66659999  1.        ]]

random value y:
[[ 0.63615251]]

output result of x <= y:
[[ True False]
 [False False]]
### comment to above example:

0.333... <= 0.636... should be True, not False
"
2324,Issue with tensorflow/core/lib/core/threadpool.cc,"Operating System:  Ubuntu 14.04.4
CUDA version: 7.5
cuNN: 4.0.7

Installed from sources:
commit 5681406

running : bazel build -c opt //tensorflow/cc:tutorials_example_trainer --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone

Note : that i have configured my WORKSPACE file as per : https://github.com/bazelbuild/bazel/issues/623#issuecomment-158151936: 

(made the following corrections:) 
download jpeg.BUILD.txt, png.BUILD.txt, and WORKSPACE.txt from @srsaharoy 's message #623 (comment) . (the 2nd post with attachments) and place these files in the tensorflow lib without the .txt extension instead of the existing files (in my case ~/git/tensorflow/tensorflow).
create folder with external source files: ~/git/tensorflow/fix/files/re2 ~/git/tensorflow/fix/files/jpeg-9a/jpeg-9a ~/git/tensorflow/fix/files/gemmlowp ~/git/tensorflow/fix/files/libpng-1.2.53/libpng-1.2.53 ~/git/tensorflow/fix/files/six-1.10.0 Note the dir-in-dir for jpeg-9a and libpng-1.2.53. This is necessary.
change paths in WORKSPACE file to match the location of the aux source files
 .... 

Now I am just stuck with the following error: 

ERROR: /home/julialintern/tensorflow/tensorflow/core/BUILD:756:1: C++ compilation of rule '//tensorflow/core:lib_internal' failed: gcc failed: error executing command 
  (cd /home/julialintern/.cache/bazel/_bazel_julialintern/1a7b4f00b1b7d4c4a3ca618f554c7ad8/tensorflow && \
  exec env - \
    PATH=/home/julialintern/torch/install/bin:/home/julialintern/bin:/usr/local/cuda/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/julialintern/bin \
    TMPDIR=/tmp/user/1001 \
  /usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++0x' -iquote . -iquote bazel-out/host/genfiles -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/host/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/host/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/host/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/host/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/host/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/host/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/host/genfiles/external/png_archive/libpng-1.2.53 -isystem third_party/eigen3 -isystem bazel-out/host/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/host/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -DTENSORFLOW_USE_EIGEN_THREADPOOL -pthread -no-canonical-prefixes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' '-frandom-seed=bazel-out/host/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/core/threadpool.o' -MD -MF bazel-out/host/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/core/threadpool.d -c tensorflow/core/lib/core/threadpool.cc -o bazel-out/host/bin/tensorflow/core/_objs/lib_internal/tensorflow/core/lib/core/threadpool.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/core/lib/core/threadpool.cc:83:49: error: expected template-name before '<' token
 struct ThreadPool::Impl : Eigen::ThreadPoolTempl<EigenEnvironment> {
                                                 ^
tensorflow/core/lib/core/threadpool.cc:83:49: error: expected '{' before '<' token
tensorflow/core/lib/core/threadpool.cc:83:49: error: expected unqualified-id before '<' token
tensorflow/core/lib/core/threadpool.cc:221:1: error: expected '}' at end of input
 }  // namespace tensorflow
 ^
tensorflow/core/lib/core/threadpool.cc:221:1: error: expected '}' at end of input
Target //tensorflow/cc:tutorials_example_trainer failed to build
"
2323,the process wil be so slow when reading batch data from csv files in tensorflow,"def read_data(filename):

```
    filename_queue = tf.train.string_input_producer([filename])
    reader = tf.TextLineReader()
    key, value = reader.read(filename_queue)
    record_defaults = [[1.0 for col in range(1)] for row in range(280)]
    record_defaults[279][0] = 1
    a = tf.decode_csv(value, record_defaults=record_defaults)
    data = tf.pack(a[0:278])
    label = a[-1]
    min_after_dequeue = 10000
    capacity = min_after_dequeue + 3 * batch_size
    data_batch, label_batch = tf.train.shuffle_batch([data, label], batch_size=batch_size, capacity=capacity,min_after_dequeue=min_after_dequeue)
    return data_batch, label_batch
```

def main(argv=None):  

```
    data,label = read_data(FLAGS.train_file)

    tf.initialize_all_variables()
    with tf.Session() as sess:
            coord = tf.train.Coordinator()
            threads = tf.train.start_queue_runners(coord=coord)
            example, label = sess.run([data, label])
            print (example)
```

Here is my code above ,why it take 10 minutes to print example data?How can I optimise my code? I have only set batchsize is 2
"
2322,InvalidArgumentError: Cannot assign a device to node when distributed running,"I tried running [this script](https://github.com/tensorflow/models/tree/master/inception) on two machine, start script as follows, Note that each machine has 4 GPUs. 

```
# machine 10.10.12.28
~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=0 \
--gpu_device_id=0 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=1 \
--gpu_device_id=1 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=2 \
--gpu_device_id=2 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=3 \
--gpu_device_id=3 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

CUDA_VISIBLE_DEVICES='' ~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--job_name='ps' \
-task_id=0 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

#machine 10.10.12.29
~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=4 \
--gpu_device_id=0 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=5 \
--gpu_device_id=1 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=6 \
--gpu_device_id=2 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--batch_size=32 \
--data_dir=/data1/imagenet1k \
--job_name='worker' \
--task_id=7 \
--gpu_device_id=3 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &

CUDA_VISIBLE_DEVICES='' ~/models/inception/bazel-bin/inception/imagenet_distributed_train \
--job_name='ps' \
-task_id=1 \
--ps_hosts='10.10.102.28:2220,10.10.102.29:2220' \
--worker_hosts='10.10.102.28:2221,10.10.102.28:2222,10.10.102.28:2223,10.10.102.29:2224,10.10.102.29:2221,10.10.102.29:2222,10.10.102.29:2223,10.10.102.29:2224' &
```

error log as follows: 

```
Traceback (most recent call last):
  File ""/home/zhufengda/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py"", line 65, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/zhufengda/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py"", line 61, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File ""/home/zhufengda/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py"", line 264, in train
    sess = sv.prepare_or_wait_for_session(target, config=sess_config)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 681, in prepare_or_wait_for_session
    max_wait_secs=max_wait_secs)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 282, in wait_for_session
    sess.run([self._local_init_op])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 355, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 606, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 695, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 715, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'save/restore_slice_837/shape_and_slice': Could not satisfy explicit device specification '/job:ps/task:1/device:CPU:0' because no devices matching that specification are registered in this process; available devices: /job:ps/replica:0/task:0/cpu:0, /job:worker/replica:0/task:0/cpu:0, /job:worker/replica:0/task:0/gpu:0, /job:worker/replica:0/task:0/gpu:1, /job:worker/replica:0/task:0/gpu:2, /job:worker/replica:0/task:0/gpu:3, /job:worker/replica:0/task:1/cpu:0, /job:worker/replica:0/task:1/gpu:0, /job:worker/replica:0/task:1/gpu:1, /job:worker/replica:0/task:1/gpu:2, /job:worker/replica:0/task:1/gpu:3, /job:worker/replica:0/task:2/cpu:0, /job:worker/replica:0/task:2/gpu:0, /job:worker/replica:0/task:2/gpu:1, /job:worker/replica:0/task:2/gpu:2, /job:worker/replica:0/task:2/gpu:3, /job:worker/replica:0/task:4/cpu:0, /job:worker/replica:0/task:4/gpu:0, /job:worker/replica:0/task:4/gpu:1, /job:worker/replica:0/task:4/gpu:2, /job:worker/replica:0/task:4/gpu:3, /job:worker/replica:0/task:5/cpu:0, /job:worker/replica:0/task:5/gpu:0, /job:worker/replica:0/task:5/gpu:1, /job:worker/replica:0/task:5/gpu:2, /job:worker/replica:0/task:5/gpu:3, /job:worker/replica:0/task:6/cpu:0, /job:worker/replica:0/task:6/gpu:0, /job:worker/replica:0/task:6/gpu:1, /job:worker/replica:0/task:6/gpu:2, /job:worker/replica:0/task:6/gpu:3, /job:worker/replica:0/task:7/cpu:0, /job:worker/replica:0/task:7/gpu:0, /job:worker/replica:0/task:7/gpu:1, /job:worker/replica:0/task:7/gpu:2, /job:worker/replica:0/task:7/gpu:3
     [[Node: save/restore_slice_837/shape_and_slice = Const[dtype=DT_STRING, value=Tensor<type: string shape: [] values: >, _device=""/job:ps/task:1/device:CPU:0""]()]]
Caused by op u'save/restore_slice_837/shape_and_slice', defined at:
  File ""/home/zhufengda/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py"", line 65, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""/home/zhufengda/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/imagenet_distributed_train.py"", line 61, in main
    inception_distributed_train.train(server.target, dataset, cluster_spec)
  File ""/home/zhufengda/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/__main__/inception/inception_distributed_train.py"", line 237, in train
    saver = tf.train.Saver()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 845, in __init__
    restore_sequentially=restore_sequentially)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 515, in build
    filename_tensor, vars_to_save, restore_sequentially, reshape)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 271, in _AddRestoreOps
    values = self.restore_op(filename_tensor, vs, preferred_shard)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 186, in restore_op
    preferred_shard=preferred_shard)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py"", line 201, in _restore_slice
    preferred_shard, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 271, in _restore_slice
    preferred_shard=preferred_shard, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 444, in apply_op
    as_ref=input_arg.is_ref)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py"", line 166, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2177, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1161, in __init__
    self._traceback = _extract_stack()
```
"
2320,examples/udacity/1_notmnist.ipynb image normalization is not equal to Udacity video,"Hi,
This is just a minor thing, but it might be confusing for people who follow the Udacity course. The video about normalization of the input (https://www.youtube.com/watch?v=0mxNQA95mYE) describes the normalization as: pixel_value - 128 / 128. However the code seems to compute: pixel_value - 128 / 255 (since pixel_depth = 255). This changes the range of the data from -1 to 1 into -0.5 to 0.5 and might be confusing for people who blindly copy the function and expect it to work like in the video.
"
2319,tf.constant does not raise an error if too few values are provided,"It is difficult to see the current behavior (repeating the final value) being useful for anyone:

```
>>> tf.constant(np.arange(5), shape=(10,)).eval()
array([0, 1, 2, 3, 4, 4, 4, 4, 4, 4])
```

In contrast, there is a sensible error message if too many values are provided:

```
>>> tf.constant(np.arange(5), shape=(3,)).eval()
ValueError: Too many elements provided. Needed at most 3, but received 5
```

I am running the internal version of TensorFlow.
"
2318,tf.constant should support pandas Series and DataFrame as input,"Currently, it does not.

I would suggest implementing this by checking for a `__array__` method, which is the [standard API](http://docs.scipy.org/doc/numpy/reference/arrays.classes.html#numpy.class.__array__) used for indicating that an object is coercible into NumPy arrays, and is implemented by nearly every library that implements ""array like"" objects in the Python ecosystem. This includes pandas, as well as many other widely used libraries, including xarray and dask.array.
"
2317,"Install the latest version whl of tensorflow from Jenkins daily build system, but can not find a part of the directory","hello, i have a question:

Operating System:
ubuntu 14.04

question
Install the latest version whl of tensorflow from Jenkins daily build system, but can not find a part of the directory

If installed from binary pip package, provide:
1. Which pip package you installed.

first download the latest stable package:

http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastStableBuild/
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

> > > import tensorflow; print(tensorflow.**version**)
> > > 0.8.0
### Steps to reproduce
1.  pip uninstall tensorflow
2.  pip install  --upgrade  tensorflow-0.8.0-cp27-none-linux_x86_64.whl  
### What have you tried?
1. in  the  path anaconda2\envs\tensorflow\lib\python2.7\site-packages\tensorflow\models\image dictionarycan not find the alexnet and imagenet dictionary, but can find them from the github path https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image.

how can i update to get alexnet and imagenet dictionary?
"
2316,Try to build label_image:main.cc on Android,"1.If I build  tensorflow_jni.cc with the BUILD file in label_image,I added android_binary.it ask me to compile with -std=c++.because the ndk r10e running with GCC4.9.I donot know how to set -std=c++11.
2.If I build it with .mk.and copy the .h files in bazel-genfiles/tensorflow/cc/ops,like array_ops.h etc,  to tensorflow folder,setted include like this
`#include ""tensorflow/cc/ops/array_ops.h""
# include ""tensorflow/cc/ops/const_op.h""
# include ""tensorflow/cc/ops/data_flow_ops.h""
# include ""tensorflow/cc/ops/image_ops.h""`...

it give me:
`jni/./tensorflow_jni.cc:132: error: undefined reference to 'tensorflow::ops::Cast(tensorflow::NodeBuilder::NodeOut, tensorflow::DataType, tensorflow::GraphDefBuilder::Options const&)'`
for every tensorflow::ops:: method.it seems,ndk have found the method ,but not compile?
3.Did any guies build label_image:main.cc on Android?
the android demo on tensorflow does not working will with my own graph,retrained by image_retraining .
"
2315,tf.nn.softmax outputs negative values (equal to tf.nn.log_softmax)!,"### Environment info

Operating System: Ubuntu 14.04.03

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

ls -l /usr/local/cuda/lib_/libcud_
-rw-r--r-- 1 root root    322936 Apr 25 11:05 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Apr 25 11:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Apr 25 11:05 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Apr 25 11:05 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Apr 25 11:05 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn_static.a
-rw-r--r-- 1 root root    189170 Apr 25 11:05 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Apr 25 11:05 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Apr 25 11:05 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    311596 Apr 25 11:05 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root    558020 Apr 25 11:05 /usr/local/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.

https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

0.8.0rc0

If installed from sources, provide the commit hash:
### Steps to reproduce

It appears that tf.nn.softmax is output'ing negative values. After a lot of debugging, i added the following tf.Print line right after the call to tf.nn.softmax(). The output does indeed have negative values.. Strangely enough, the values match the output of tf.nn.log_softmax()!

https://github.com/sdlg/nlc/blob/04af660b23218c026983785f339afeea19cd4e25/nlc_model.py#L152

This issue could not be reproduced with simple test cases. tf.nn.softmax() behaves well in simple test cases.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

I tensorflow/core/kernels/logging_ops.cc:79] Checking for negative[-29.343697]
I tensorflow/core/kernels/logging_ops.cc:79] Checking for negative[-26.83346]
I tensorflow/core/kernels/logging_ops.cc:79] Checking for negative[-29.535496]
I tensorflow/core/kernels/logging_ops.cc:79] Checking for negative[-26.830235]
I tensorflow/core/kernels/logging_ops.cc:79] Checking for negative[-26.42857]
"
2314,SparseApply* operators for the GPU,"At the moment, it appears that only GradientDescentOptimizer supports running on the GPU when there is a SparseTensor update. This is particularly relevant for any RNNs which train their embeddings, including the word2vec example (yes w2v isn't an RNN ;)

So far the common workaround everyone seems to use is to force the embedding variables to be on the CPU, but there can be _substantial_ speed improvements by allowing them to be stored on the GPU. For one, there is no need to transfer the vectors of embeddings to/from the GPU, and instead one can just transfer the embedding indexes, and then the gradients also don't need to be transferred backwards. In one test I've run where I implemented a version on the GPU, the difference in one epoch was roughly 1100s vs 300s. Basically anyone who doesn't freeze their embeddings can substantially benefit from this.

This is related to #1310 and #464. In #1310, there is a bug where variables are placed on the GPU, even though an op that appears later isn't available on the GPU. My understanding is a fix for this is under development, but it will only make sure variables are placed on devices which can perform the necessary ops. It will not actually include SparseApply's. This feature request would resolve the OP's reported bug in #1310, but not solve the variable-operator placement issue.

In #464, the issue is that no one has implemented any `SparseApplyRMSProp`, along with another bug that has since been resolved. The issue used to contain all optimizers except GDO, but since then SparseApply ops have been added for AdaGrad, yet they're currently only implemented for the CPU, not the GPU. This feature request is a rough superset of #464.

One thing that is presently unclear to me, is whether these really need to be implemented as C++ operators, with all the associated book keeping. Currently that is how the CPU version of the SparseApply*'s are updated (see [example](https://github.com/tensorflow/tensorflow/blob/5681406e2874a02835d34be579810a93ad74a473/tensorflow/core/kernels/training_ops.cc#L1101)), except for [GradientDescent](https://github.com/tensorflow/tensorflow/blob/5681406e2874a02835d34be579810a93ad74a473/tensorflow/python/training/gradient_descent.py#L54). Its `_sparse_apply` is implemented in python and uses `scatter_sub`.

I already have a Python implementation of `_sparse_apply` for `MomentumOptimizer`, which uses `tf.gather`, `tf.scatter_update`, and `tf.scatter_sub`. It passes unit tests, and performs on both CPU and the GPU, though it does take about a 1% performance hit compared to the current CPU C++ `SparseApplyMomentum`. Would this be of interest, or is there a motivation behind implementing this in C++?
"
2313,Batched gather,"This is related to #2170, which describes how to use `tf.gather` to index on the first dimension of a tensor. What I'd like to do now is batch this operation:

```
params = tf.constant([[1, 2], [3, 4], [5. 6]])
indices = tf.constant([0, 1, 0])
gathered = tf.batch_gather(params, indices)
# gathered = [1, 4, 5]
```
"
2312,'module' object has no attribute 'atrous_conv2d',"### Environment info

Operating System: ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
```
### Tensorflow version

lateset one
### What have you tried?

1.

```
import tensorflow as tf
tf.nn.atrous_conv2d
```
"
2311,Calling variable.assign() too many times crashes on memory allocation.,"**Background**: I'm working on a set of networks that only share some layers, so I have a parameter server that sends new weights for the different clients to use.  These clients accept the new weights and bias for the layers they are using and assign the values to the TF.Variables via `sess.run(self.w1.assign(new_weights))`.  However, when I start it up and let it run, it crashes saying 

```
W tensorflow/core/common_runtime/bfc_allocator.cc:271] Ran out of memory trying to allocate 16B.  See logs for memory state.
```

(Sometimes it's allocating 16B, other times its 3.9KiB)

To give you an idea of the size of the weights, I have three layers of: 
Layer 1(W,b): `(2, 1000), (1000, )`
Layer 2(W,b): `(1000, 1000), (1000, )`
Layer 3(W,b): `(1000, 4), (4, )`
I'm running on a Titan X with 12G memory.

With `per_process_gpu_memory_fraction = 0.01`, the program dies at ~190 assign commands.
With `per_process_gpu_memory_fraction = 0.02`, the program dies at ~384 assign commands.
With `per_process_gpu_memory_fraction = 0.03`, the program dies at ~780 assign commands.
With `per_process_gpu_memory_fraction = 0.04`, the program dies at ~784 assign commands.
With `per_process_gpu_memory_fraction = 0.05`, the program dies at ~1582 assign commands.
With `per_process_gpu_memory_fraction = 0.06`, the program dies at ~1586 assign commands.

I've tried to set `allow_growth=True`, and `deferred_deletion_bytes=1` in the session's GPUOptions after reading issue #1578, but that didn't get me much further.  (I have no idea what `deferred_deletion_bytes` does...)  Looking at the numbers just above (GPU%vsAssignmentCommands), it seems to be fairly linear, so it seems to me that the assign operation takes some of the GPU ram and it's never freed up.  **Is there any sense of GC on the GPU memory allocated durring the `var.assign()` op?**

It seems that I could delete and create a new session, but that sounds expensive to me, and I'd have to maintain the weights outside of session to be able to restore them correctly.  The second idea I had would to use placeholders and ship the weights in every time with the feed_dict, but again, that seems less that ideal and I think it would struggle in the optimizer on knowing what to optimize if they are just placeholders.

Let me know if you would like any other logs or reports from me.  I figure this is the first time someone has tried to use assign operations like this, so I want to be helpful in fixing it if it's a bug.

Thanks
### Environment info

**Operating System:** Ubuntu 16.04
**Installed version of CUDA and cuDNN:**
/usr/local/cuda/lib/libcudart.so -> libcudart.so.7.0
/usr/local/cuda/lib/libcudart.so.7.0 -> libcudart.so.7.0.28
/usr/local/cuda/lib/libcudart.so.7.0.28
/usr/local/cuda/lib/libcudart_static.a
**Built from source.  Commit hash:**  35cd6a30112abd4302a8b3a17dda277899f1ed40
"
2310,Bug: tf.app.run() does not allow to import ipdb,"When using tensorflow with `tf.app.run()` one cannot `import ipdb`. I have tested several Tensorflow Versions and did run Tensorflow in several environments, all of them seems to be affected by this Bug.

The following script provides a minimal Example reproducing the error:

```
#!/usr/bin/env python
import ipdb
import tensorflow as tf


def main(_):
    """"""Run main function.""""""
    print(""Hello World."")


if __name__ == '__main__':
    tf.app.run()
```

Executing the  script yields the following error message:

```
Traceback (most recent call last):
  File ""tensorapp.py"", line 14, in <module>
    tf.app.run()
  File ""/home/marvin/.virtualenvs/tensorvision/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 29, in run
    main = main or sys.modules['__main__'].main
AttributeError: 'module' object has no attribute 'main'

If you suspect this is an IPython bug, please report it at:
    https://github.com/ipython/ipython/issues
or send an email to the mailing list at ipython-dev@scipy.org

You can print a more detailed traceback right now with ""%tb"", or use ""%debug""
to interactively debug it.

Extra-detailed tracebacks for bug-reporting purposes can be enabled via:
    %config Application.verbose_crash=True
```
### Environment info

Operating System: Linux (varies)

Effected Tensorflow Versions: 0.7.0; 0.7.1; 0.8.0 
1. Which pip package you installed. https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"": 0.8.0
### Steps to reproduce
1. Run provided script
"
2309,Slice all but last element of tensor,"I'm trying to slice all but the last element of a tensor, equivalent to python's `a[:-1]`. However, I understand that tensorflow instead uses a start and size rather than start and end for slicing. My current workaround is to do something like this:

```
a = tf.constant([1, 2, 3, 4])
# b = [1, 2, 3]
b = tf.reverse(tf.reverse(a, [True])[1:], [True])
```

This is obviously a bit awkward, and potentially inefficient. Is there a better way to do this?
"
2308,Theano-like scan non-sequences,"It would be nice to add some functionality that allows passing non-sequences to `scan` function (introduced in 0.8.0). [Theano implements this feature](http://deeplearning.net/software/theano/library/scan.html) and it is very useful.

The suggested usage could be (pseudocode):

``` python
scan(fn=lambda state, c1, c2, el: state+c1+c2+el,
     elems=[10,20,30],
     initializer=[0],
     non_sequences=[1, 2])
```

The first argument could be the last output (state), then all `non_sequences` could be passed and, finally, the current input `el`. The pseudocode above would produce the following operations:

```
0 +1+2+10 => 13
13+1+2+20 => 26
26+1+2+30 => 59
```

Unfortunatelly I haven't found any hack that would achieve the same behavior (especially when `non_sequences` contain objects other than tensors, such as `GruCells`). Maybe there is some, in that case I would really appreciate some hint :)

I believe that this, together with #2294, would help developers to write their scans equally effectively as they do in theno.
"
2307,Tensorflow serving with Retrained Inception graph,"Hello!

Are there any plans to release a tutorial similar to the one to use a checkpointed Inception graph with Tensorflow Serving, but with a Retrained Inception graph as created with the [transfer learning tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md)?
"
2306,Building from source in Ubuntu 16.04 LTS amd64,"I have installed the `nvidia-cuda-toolkit` from Ubuntu Multiverse package and I wish to compile TensorFlow from source. I realize that I still need CuDNN to be installed the traditional way because its not (yet) packaged by Ubuntu.

The `configure` scripts has some issues which hinders me to configure it for Compute Capability 3.0.
### Environment info

Operating System: Ubuntu 16.04 LTS (amd64)

TensorFlow version hash as reported by `git log -1 --oneline`:
`5681406 Add polygamma and zeta function to tensorflow (#1834)`

Installed version of CUDA and cuDNN: 

```
# find /usr/lib -name libcud\*
/usr/lib/i386-linux-gnu/libcuda.so.1
/usr/lib/i386-linux-gnu/libcuda.so.361.42
/usr/lib/i386-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcuda.so.1
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5.18
/usr/lib/x86_64-linux-gnu/libcuda.so.361.42
/usr/lib/x86_64-linux-gnu/libcudart.so
/usr/lib/x86_64-linux-gnu/libcudart.so.7.5
/usr/lib/x86_64-linux-gnu/libcudadevrt.a
/usr/lib/x86_64-linux-gnu/stubs/libcuda.so
/usr/lib/x86_64-linux-gnu/libcuda.so
/usr/lib/x86_64-linux-gnu/libcudart_static.a
```

```
# find /usr/local/cuda
/usr/local/cuda
/usr/local/cuda/lib64
/usr/local/cuda/lib64/libcudnn_static.a
/usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudnn.so.4
/usr/local/cuda/lib64/libcudnn.so.4.0.7
/usr/local/cuda/include
/usr/local/cuda/include/cudnn.h
```
### Steps to reproduce
1. `git checkout https://github.com/tensorflow/tensorflow`
2. `git checkout 5681406`
3. `./configure`
"
2305,FR: Create/Support an automated hyperparameter selector like TPOT,"Not sure if you've seen TPOT (http://rhiever.github.io/tpot/, introductory blog post at http://www.randalolson.com/2016/05/08/tpot-a-python-tool-for-automating-data-science/) but it would be awesome if you collaborated with them to add something like this to TensorFlow.
"
2304,Tensorflow retrain.py random distortions,"### Environment info

Operating System: Mac OS X with Tensorflow 0.8 installed.

I am trying to run retrain.py with my custom training set, but whenever I try passing in the argument `--random_crop 5` when running retrain.py the program errors out and says:

> tensorflow.python.framework.errors.InvalidArgumentError: assertion failed: [Need value.shape >= size, got ] [314 314 1] [299 299 3]
>    [[Node: random_crop/Assert = [Assert T=[DT_STRING, DT_INT32, DT_INT32], summarize=3, _device=""/job:localhost/replica:0/task:0/cpu:0""(random_crop/All, random_crop/Assert/data_0, random_crop/Shape, random_crop/size)]]
> Caused by op u'random_crop/Assert'

The command I am using is:

`bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir /path/to/my/training_images --how_many_training_steps 5000 --random_crop 5`

Is this an issue with the size of the images that I am using for my training set?
"
2303,Error parsing bazel version (bazel 0.2.2b),"TensorFlow version: v0.8.0
Bazel version: 0.2.2b (installed via deb package)

Command: `bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer --verbose_failures`
Error message:

```
ERROR: /path_to_my_workspace/tensorflow/WORKSPACE:21:1: Traceback (most recent call last):
    File ""/path_to_my_workspace/tensorflow/WORKSPACE"", line 21
        check_version(""0.1.4"")
    File ""/path_to_my_workspace/tensorflow/tensorflow/tensorflow.bzl"", line 22, in check_version
        _parse_bazel_version(native.bazel_version)
    File ""/path_to_my_workspace/tensorflow/tensorflow/tensorflow.bzl"", line 15, in _parse_bazel_version
        int(number)
invalid literal for int(): ""2b"".
ERROR: Error evaluating WORKSPACE file.
ERROR: no such package 'external': Package 'external' contains errors.
```

The error seems to be `_parse_bazel_version` not expecting a non decimal character.
"
2301,Contact for legal issues,"Good night

Currently my university wants to use Tensorflow for a software project. The lawyers of my university want a letter which says TensorFlow creators allow my university to use his library. Any idea who must I contact for this issue? Thanks a lot.
"
2300,what is the format of model when using save,"Can it possbile to give the doc about the format of model when using save function?

How can I define the self-model,just only using fwrite ,and read-model using fread?
"
2298,opt.compute_gradients() returns values different from the weight difference of opt.apply_gradients(),"This isn't a bug, bug I wasn't sure where to ask for help on this one, so I'm sorry to just throw in another issue here on github.  I've tried searching, but haven't found answers to my questions yet.

My question is what is the most efficient way to get the delta of my weights when training?  I assume it's related to gradients, but the optimizer (I think) does a lot more than just apply the raw gradients returned from `opt.compute_gradients()`.

**Where I'm at**: I've got the operators hooked up as follows (thanks to this [SO question](http://stackoverflow.com/questions/34687761/efficiently-grab-gradients-from-tensorflow)):

<pre>
self.cost = `the rest of the network`
self.rmsprop = tf.train.RMSPropOptimizer(lr,rms_decay,0.0,rms_eps)
self.comp_grads = self.rmsprop.compute_gradients(self.cost)
self.grad_placeholder = [(tf.placeholder(""float"", shape=grad[1].get_shape(), name=""grad_placeholder""), grad[1]) for grad in self.comp_grads]
self.apply_grads = self.rmsprop.apply_gradients(self.grad_placeholder)
</pre>


Now, to feed in information, I run the following:

<pre>
feed_dict = `training variables`
start_weights = self.sess.run([self.w1,self.b1, etc])
grad_vals = self.sess.run([grad[0] for grad in self.comp_grads], feed_dict=feed_dict)

feed_dict2 = `feed_dict plus gradient values added to self.grad_placeholder`
self.sess.run(self.apply_grads, feed_dict=feed_dict2) # Updates the weights
end_weights = self.sess.run([self.w1,self.b1, etc])
delta_weights = [end_weights[i]-start_weights[i] for i in range(len(start_weights))]
# Note: delta_weights != grad_vals...
</pre>


The command of `run(self.apply_grads)` will update the network weights, but when I compute the differences in the starting and ending weights (`run(self.w1)`), those numbers are different than what is stored in `grad_vals[0]`.  I figure this is because the RMSPropOptimizer does more to the raw gradients, but I'm not sure what, or where to find out what it does.  I could go to the paper and write it myself, but I don't want to hardcode things in like that where TF already does it somewhere else.  I'll admit I'm still new to TF, but I tried to figure out what happens by looking at the source, but it's still confusing for me.

So back to the question: Is there a way to get the delta's for the weights in a more efficient way than calculating the difference?  Am I stuck running `self.w1.eval(sess)` multiple times to get the weights and calculate the difference?  Is there something that I'm missing with the `tf.RMSPropOptimizer` (or any other Optimizer for that matter) function that I haven't seen or heard about

Thanks!  And sorry again for adding to the issues list.
"
2296,"Issue with retrain.py, ""could not convert string to float"" when creating bottlenecks","### Environment info

Operating System:
Ubuntu 14.04 
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 7.5, cuDNN v2 (6.5)
`lrwxrwxrwx 1 root root 19 May  9 09:11 /usr/local/cuda -> /usr/local/cuda-7.5`

Installed the Nightly pip package from April 12th, with GPU support
Tensorflow version: 0.7.1

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Running the retrain with a very large image directory (around 600k files) causes the training to fail around 3/4 the way through, during the bottleneck creation process. It always seems to fail while within the same label folder, but it does not appear that any file names within that label folder are corrupted or named incorrectly.
### What have you tried?
1. Changing the number of training steps
2. Checking to see if any files are less than 30k (theoretically, very small files are likely to be corrupted jpeg data)
### Logs or other output that would be helpful

For 610,000 files, the process can't seem to get through more than 415k. Am I simply just using too many files? Or am I missing a very, very subtle naming convention issue?
## Full stack trace:

`File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""retrain_reshape_error.py"", line 695, in main
    cache_bottlenecks(sess, image_lists, FLAGS.image_dir, FLAGS.bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)
  File ""retrain_reshape_error.py"", line 400, in cache_bottlenecks
    image_dir, category, bottleneck_dir, jpeg_data_tensor, bottleneck_tensor)
  File ""retrain_reshape_error.py"", line 372, in get_or_create_bottleneck
    bottleneck_values = [float(x) for x in bottleneck_string.split(',')] 
ValueErrror: could not convert string to float`

I should also note that I have been using this training process for the last few months with absolutely no failure.

Thanks!

Oren
"
2295,pow() gradients create +inf at 0.0,"Hi,

I had a pipeline where I was first clamping to [0..1] and then doing x^2.4 (converting to/from gamma RGB to linear RGB):

```
y = tf.minimum(tf.maximum(y, 0.0), 1.0)
gamma = tf.constant(1.0/2.4, tf.float32)
y = tf.pow(y, gamma)
```

However, this instantly created inf values (and NaNs in the next step), seemingly due to the use of log() to compute the gradients. The gradient of pow() in 0.0 should be pretty well defined as long as the exponent is nonzero; at the very least, it is not infinity.

As a workaround, clamping to 1e-5 instead of 0.0 caused the NaNs to disappear.
"
2294,Feature Request: Let tf.scan accept/return tuples of Tensors in addition to just Tensors,"Right now, `tf.scan` splits `Tensors` along dimension 0, and to process multiple state/input `Tensors` with `tf.scan`, we need to concatenate/split. For example, to create an LSTM block using `tf.scan`, we might have something like

```
def lstm_block(c_prev_and_m_prev, x):
    c_prev, m_prev = tf.split(1, 2, c_prev_and_m_prev)
    # Compute new c, m
    c_and_m = tf.concat(1, [c, m])
    return c_and_m
```

This has been asked about by others in https://github.com/tensorflow/tensorflow/issues/1725 and https://github.com/rdipietro/jupyter-notebooks/issues/2

Also, if we hope to process multiple `Tensors` with significantly different shapes, then the current solution will become even less concise, as we'd probably have to do something like flatten, maintain shape info, unflatten, etc.

I can probably make this change if it's something that'd be accepted.
"
2293,Documentation update: virtualenv should not be run from ~,"Hi,

The documentation suggests that you make a virtualenv essentially by cd ~; mkdir tensorflow; virtualenv ~/tensorflow. Unfortunately, for some reason I cannot comprehend, this makes virtualenv try to scan every HTML file (possibly also others) in ~; in my case, this hit a 22 MB file I had lying around, causing virtualenv to use 5+ minutes (I eventually aborted it) and 4.5 GB of RAM without really saying why.

A better workaround is cd ~; mkdir tensorflow; cd tensorflow; virtualenv ., since seemingly the scanning is of the current directory. The documentation should probably be updated.
"
2292,Bug on specifying GPU to tutorial example minist,"I tried to specify GPU ID to run the tutorial example [mnist](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/fully_connected_feed.py). I change the code to:

```
with tf.device('/gpu:3):
    # Generate placeholders for the images and labels.
    images_placeholder, labels_placeholder = placeholder_inputs(
        FLAGS.batch_size)
    # Build a Graph that computes predictions from the inference model.
    logits = mnist.inference(images_placeholder,
                                FLAGS.hidden1,
                                FLAGS.hidden2)
    # Add to the Graph the Ops for loss calculation.
    loss = mnist.loss(logits, labels_placeholder)

    # Add to the Graph the Ops that calculate and apply gradients.
    train_op = mnist.training(loss, FLAGS.learning_rate)
```

Then it reports error when running:

tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'global_step': Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available
     [[Node: global_step = Variable[container="""", dtype=DT_INT32, shape=[], shared_name="""", _device=""/device:GPU:3""]()]]
Caused by op u'global_step', defined at:
  File ""fully_connected_feed.py"", line 232, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_feed.py"", line 228, in main
    run_training()
  File ""fully_connected_feed.py"", line 150, in run_training
    train_op = mnist.training(loss, FLAGS.learning_rate)
  File ""/search/guangliang/package/tensorflow/tensorflow/examples/tutorials/mnist/mnist.py"", line 125, in training
    global_step = tf.Variable(0, name='global_step', trainable=False)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 209, in **init**
    dtype=dtype)
...

Then I fix the line 125 in ""mnist.py"" with the following code:

  with tf.device('/cpu:0'):
    global_step = tf.Variable(0, name='global_step', trainable=False)

Then it reports the following error on rerunning:

tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'gradients/xentropy_mean_grad/Prod': Could not satisfy explicit device specification '/device:GPU:3' because no supported kernel for GPU devices is available
     [[Node: gradients/xentropy_mean_grad/Prod = Prod[T=DT_INT32, keep_dims=false, _device=""/device:GPU:3""](gradients/xentropy_mean_grad/Shape_2, gradients/xentropy_mean_grad/range_1)]]
Caused by op u'gradients/xentropy_mean_grad/Prod', defined at:
  File ""fully_connected_feed.py"", line 232, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""fully_connected_feed.py"", line 228, in main
    run_training()
  File ""fully_connected_feed.py"", line 150, in run_training
    train_op = mnist.training(loss, FLAGS.learning_rate)
  File ""/search/guangliang/package/tensorflow/tensorflow/examples/tutorials/mnist/mnist.py"", line 129, in training
    train_op = optimizer.minimize(loss, global_step=global_step)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 190, in minimize
    colocate_gradients_with_ops=colocate_gradients_with_ops)
...

Would you please help on this?
Thanks a lot in advance!
"
2291,Add -lm (Was: undefined reference to symbol 'ceil@@GLIBC_2.2.5),"### Environment info

Operating System:

epel-release-6-8.noarch
redhat-release-server-6Server-6.7.0.3.el6.x86_64

Installed version of CUDA and cuDNN: 

None

If installed from sources, provide the commit hash:

f8eb1d70a7ea7dc2cd5e1eddde389395f88a6be9
### Steps to reproduce
1. bazel clean
2. ./configure
3. bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

ERROR: /home/ebice/tensorflow/google/protobuf/BUILD:272:1: Linking of rule '//google/protobuf:protoc' failed: gcc failed: error executing command /opt/rh/devtoolset-2/root/usr/bin/gcc -o bazel-out/host/bin/google/protobuf/protoc -no-canonical-prefixes -B/opt/rh/devtoolset-2/root/usr/bin -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' ... (remaining 11 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/opt/rh/devtoolset-2/root/usr/bin/ld: /opt/rh/devtoolset-2/root/usr/lib/gcc/x86_64-redhat-linux/4.8.2/libstdc++_nonshared.a(hashtable_c++0x44.o): undefined reference to symbol 'ceil@@GLIBC_2.2.5'
/opt/rh/devtoolset-2/root/usr/bin/ld: note: 'ceil@@GLIBC_2.2.5' is defined in DSO /lib64/libm.so.6 so try adding it to the linker command line
/lib64/libm.so.6: could not read symbols: Invalid operation
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
"
2290,why does sess.run()so slow on android?,"I used retrain.py to retrain inception_v3 with my own images.It works will on pc with label_image.cc.It costs about 2-4s on android demo(just change the graph.pb) once sess.run().In original demo,it costs only 400ms?whats wase,the result always get wrong.I have no idea,why it works so slow?why the accuracy so low on android device?
"
2289,Broadcasting ops on numpy arrays creates tons of ops,"Hi,

I had a little toy project where I took in some data from numpy:

```
x_data = np.zeros([18145, 3], np.float32)
b_init = np.zeros([1, 3], np.float32)
b_init[0][0] = 16.0
b_init[0][1] = 128.0
b_init[0][2] = 128.0
W_init = np.zeros([3, 3], np.float32)

[fill in x_data here]

W = tf.Variable(W_init)
b = tf.Variable(b_init)
y = tf.matmul(x_data - b, W)
```

This took a _lot_ of time and memory to set up (several minutes), and it was nowhere obvious why.

It eventually turned out that the broadcasting on the subtraction is what's causing the issue; it creates one op per line in x_data. I needed to write

```
y = tf.matmul(tf.constant(x_data) - b, W)
```

to make it fast.

Shouldn't this be the default behavior?
"
2288,NaN checker does not check outputs of optimizers,"Hi,

I noticed this while debugging fp16 support for the Adam optimizer, so I thought I'd write it down here before it was forgotten.

I had problems with NaNs in my pipeline, but couldn't really figure out where they came from. So I called tf.add_check_numerics_ops(), but it turns out that if the Adam optimizer creates a NaN (in my case, because the default epsilon of 1e-8 was too small for fp16), it is not actually checked.

Instead, you get the error on a later Read op (when the NaN is attempted used), which can be very confusing, especially since there's a lot of Read ops and it's not always easy to figure out which one the error message is about.
"
2286,Why resize_image_with_crop_or_pad require fully defined image?,"I would like to ask, why `tensorflow.image.resize_image_with_crop_or_pad` require fully defined image? Wouldn't it be better to have some function that is more general and that can handle dynamically created tensor?

I am currently playing with this function and I would like to use it for not fully defined Tensors.

Is there some plan to implement some more complex `crop_tensor` function that would work with dynamic tensors? And that would possibly be able to handle https://github.com/tensorflow/tensorflow/issues/2284 
"
2285,"the bug of using multiple GPUs, related to tf.Variable pinned to CPU","### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5 and 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from sources, provide the commit hash: 4a4f2461533847dde239851ecebe5056088a828c
### Steps to reproduce

Run the following code

``` python
import tensorflow as tf

def main():
    a = tf.Variable(1)
    init_a = tf.initialize_all_variables()
    with tf.Session() as sess:
        sess.run(init_a)

    with tf.device(""/gpu:0""):
        b = tf.constant(2)
        init_b = tf.initialize_all_variables()
    with tf.Session() as sess:
        sess.run(init_b)

    with tf.device(""/cpu:0""):
        c = tf.Variable(2)
        init_c = tf.initialize_all_variables()
    with tf.Session() as sess:
        sess.run(init_c)

    with tf.device(""/gpu:0""):
        d = tf.Variable(2)
        init_d = tf.initialize_all_variables()
    with tf.Session() as sess:
        sess.run(init_d)

if __name__ == '__main__':
    main()
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.266
pciBusID 0000:05:00.0
Total memory: 12.00GiB
Free memory: 11.02GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.2785
pciBusID 0000:09:00.0
Total memory: 4.00GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:756] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 980, pci bus id: 0000:09:00.0)
Traceback (most recent call last):
  File ""test_multi_gpu.py"", line 30, in <module>
    main()
  File ""test_multi_gpu.py"", line 26, in main
    sess.run(init_d)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 332, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 572, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 652, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 672, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'Variable_2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available
     [[Node: Variable_2 = Variable[container="""", dtype=DT_INT32, shape=[], shared_name="""", _device=""/device:GPU:0""]()]]
Caused by op u'Variable_2', defined at:
  File ""test_multi_gpu.py"", line 30, in <module>
    main()
  File ""test_multi_gpu.py"", line 23, in main
    d = tf.Variable(2)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 211, in __init__
    dtype=dtype)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"", line 292, in _init_from_args
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 139, in variable_op
    container=container, shared_name=shared_name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 351, in _variable
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 693, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2177, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1161, in __init__
    self._traceback = _extract_stack()
```

I also noticed that the documentation for [Using GPUs](https://www.tensorflow.org/versions/r0.8/how_tos/using_gpu/index.html) doesn't mentioned about tf.Variable, it only involves the tf.constant and tf.matmul.

**OK, I found the documentation from [Convolutional Neural Networks]**(https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html),
quotes:

```
All variables are pinned to the CPU and accessed via tf.get_variable() in order to share them in a multi-GPU version. See how-to on Sharing Variables.
```

I want ask that since tf.Variables is pinned to CPU by tensorflow, could we fix this error? Do we need to looking very carefully to exclude the tf.Variable declaration outside the `with tf.device('/gpu:xx')` scope, or use netsted `with tf.device(None)` to handle it?
"
2284,tensorflow `resize_image_with_crop_or_pad` for whole batch,"Currently there exists `tensorflow.image.resize_image_with_crop_or_pad()` that works well, but for me it would be very beneficial to have also something that would be able to perform crop on whole batch of images or even conv2d or conv2d_transpose outputs.

In other words it should work on Tensor of shape `[batch, height, width, channels]`.

So far I have found this mentioned here http://stackoverflow.com/questions/33944683/tensorflow-map-operation-for-tensor

And for now I'd probably go with the `tf.while_loop`, but general built in function in tensorflow would be helpful.
"
2283,IndexedSlices problem on porting ptb_word_lm.py to multi-GPU-towers,"I try to port RNN model in [ptb_word_lm.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py) to multi-GPU cards. I follow the multi-tower style in [cifar10_multi_gpu_train.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py) 
However, I found the ""grads"" returned by `tf.clip_by_global_norm(tf.gradients(cost, tvars), config.max_grad_norm)` is not list of Tensor type. It is a list of type `tensorflow.python.framework.ops.IndexedSlices`.  Now I need to sum & average the lists of ""grads"" returned by multiple GPU towers into one list of IndexedSlices or Tensor, in order to pass it into `self._train_op = optimizer.apply_gradients(zip(grads, tvars))`
 I've tried the `tf.convert_to_tensor` to conver IndexedSlices to Tensor, but it failed with the following errors:

  File ""ptb_word_lm.py"", line 328, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""ptb_word_lm.py"", line 305, in main
    m = PTBModel(is_training=True, config=config)
  File ""ptb_word_lm.py"", line 152, in __init__
    grads_0_tensor = tf.convert_to_tensor(grads[0])
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 77, in _IndexedSlicesToTensor
    % str(value))
ValueError: Tensor conversion requested for IndexedSlices without dense_shape: IndexedSlices(indices=Tensor(""model/gradients/concat_1:0"", shape=(400,), dtype=int32), values=Tensor(""model/clip_by_global_norm/model/clip_by_global_norm/_0:0"", shape=(?, 200), dtype=float32))

Is it a bug?
How could I reduce_mean these IndexedSlices(reduce_mean seems only accept ""Tensor"" as input)? Or is there any existing code that parallelize RNN in multi-GPU-towers style?

Thanks a lot in advance!
"
2281,Weird partial_run segment fault bug,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5 and 4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.7.5.18  /usr/local/cuda/lib64/libcudnn.so.4
/usr/local/cuda/lib64/libcudart.so      /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.4.0.7
/usr/local/cuda/lib64/libcudart.so.7.5  /usr/local/cuda/lib64/libcudnn.so          /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: 4a4f2461533847dde239851ecebe5056088a828c
### Steps to reproduce

``` python
import tensorflow as tf
import numpy as np

# @profile
def main():
    a = tf.Variable(tf.random_normal(shape=[1000, 1000]))
    b = a * 2
    c = b * 3
    sess = tf.Session()
    sess.run(tf.initialize_all_variables())


    sess.run(c)

    # Uncomment this code region, and segment fault will be gone.
    # for _ in xrange(1000):
    #     h = sess.partial_run_setup([b, c], [])
    #     res = sess.partial_run(h, [b, c])

    for _ in xrange(1000):
        d = sess.run(b)
    for _ in xrange(1000):
        e = sess.run(c)
    for _ in xrange(1000):
        f = sess.run([b, c])
    for _ in xrange(1000):
        h = sess.partial_run_setup([b, c], [])
        res = sess.partial_run(h, [b, c])

if __name__ == '__main__':
    main()
```
### What have you tried?
1. Uncomment the commented region will make segment fault disappear.
"
2280,Can we optimize redundant computation?,"I just find that for now, tensorflow haven't optimize the computation and leads to very slow performance. This issue I think might be very severe while compute the gradients to all trainable variables of a DNN network via **tf.gradients()**. To simplify the issue demonstration, I wrote a toy code snippets and run a small experiment.

``` python
import tensorflow as tf
import numpy as np

@profile
def main():
    a = tf.Variable(tf.random_normal(shape=[1000, 1000]))
    b = a * 2
    c = b * 3
    sess = tf.Session()
    sess.run(tf.initialize_all_variables())

    for _ in xrange(1000):
        d = sess.run(b)
    for _ in xrange(1000):
        e = sess.run(c)
    for _ in xrange(1000):
        f = sess.run([b, c])

if __name__ == '__main__':
    main()
```

And here's the profile result using line_profiler.

```
Timer unit: 1e-06 s

Total time: 7.54528 s
File: test_tf_time.py
Function: main at line 4

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
     4                                           @profile
     5                                           def main():
     6         1         9650   9650.0      0.1      a = tf.Variable(tf.random_normal(shape=[1000, 1000]))
     7         1         1611   1611.0      0.0      b = a * 2
     8         1         1501   1501.0      0.0      c = b * 3
     9         1       375872 375872.0      5.0      sess = tf.Session()
    10         1       232079 232079.0      3.1      sess.run(tf.initialize_all_variables())
    11                                           
    12      1001         1663      1.7      0.0      for _ in xrange(1000):
    13      1000      1321475   1321.5     17.5          d = sess.run(b)
    14      1001         2179      2.2      0.0      for _ in xrange(1000):
    15      1000      1570674   1570.7     20.8          e = sess.run(c)
    16      1001         2835      2.8      0.0      for _ in xrange(1000):
    17      1000      4025739   4025.7     53.4          f = sess.run([b, c])
```

You see what I mean? If the graph is like below:

```
a-------b--------c
     *         *
     |          |
    2         3
```

And if calculating `b` and `c` will consume comparable 20% time, then when I want to get [b, c], it should be optimized to consume around 20% time, right? Since I already have result of ""b"" in the middle of the procedure if I want to get result of ""c"".

Let's think about the gradient computing as I stated in the head of this issue. You have, say 10 layers DNN.
You want to get the gradients to all the 10 ""W"" variables, then will the computation being very unoptimized? Since you treat the 10 gradients separately, you will compute gradients to the 10th layer first, and get the result, and compute gradients to the 9th layer while not using the result of 10th layer, and so on.
"
2278,OS X segfault on import,"OS X 10.11.2, with CUDA:

```
/Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
/Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
/Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib -> libcudart.7.5.dylib
/Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a
/Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib
/Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib -> libcudnn.5.dylib
/Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a
```

Tensorflow built according to https://medium.com/@fabmilo/how-to-compile-tensorflow-with-cuda-support-on-osx-fd27108e27e1#.v8ibv617m, main difference being that CUDA toolkit was installed from NVidia installer instead of via `brew cask install cuda`, and using homebrew Python 3.5 instead of Anaconda Python.

In other words:

1) Install CUDA toolkit.
2) Download cudnn-7.5-osx-x64-v5.0-rc.tgz and move files to /Developer/NVIDIA/CUDA-7.5/{include,lib}
3) Install bazel 0.2.1 via brew.
4) Create Python 3.5 virtualenv, install numpy 1.11 into it so tensorflow can build against it(?).
5) Clone tensorflow repo.
6) Build with:

```
PYTHON_BIN_PATH=""/Users/pikeas/.virtualenvs/hnn/bin/python"" CUDA_TOOLKIT_PATH=""/Developer/NVIDIA/CUDA-7.5"" CUDNN_INSTALL_PATH=""/Developer/NVIDIA/CUDA-7.5"" TF_UNOFFICIAL_SETTING=1 TF_NEED_CUDA=1 TF_CUDA_COMPUTE_CAPABILITIES=""3.0"" TF_CUDNN_VERSION=""5"" TF_CUDA_VERSION=""7.5"" TF_CUDA_VERSION_TOOLKIT=7.5 ./configure
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package
```

7) `export DYLD_LIBRARY_PATH=/Developer/NVIDIA/CUDA-7.5/lib`
8) Install built tensorflow-0.8.0-py3-none-any.whl into virtualenv.
9) `import tensorflow` fails with:

```
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally
[1]    78583 segmentation fault  python
```

I've tried removing scipy per the recent similar Linux issue, which didn't help.
"
2277,Udacity assignment 4 run time error,"Hi, Thanks for the tutorials. I was able to run everything until now. I'm trying to run assignment 4 and in last step in the following part, I get exception which is related to ""session"" and its graph! I haven't change anything, I'm just running the code:

``` python
num_steps = 1001

with tf.Session(graph=graph) as session:
  tf.initialize_all_variables().run()
  print('Initialized')
  for step in range(num_steps):
    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)
    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]
    batch_labels = train_labels[offset:(offset + batch_size), :]
    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}
    _, l, predictions = session.run(
      [optimizer, loss, train_prediction], feed_dict=feed_dict)
    if (step % 50 == 0):
      print('Minibatch loss at step %d: %f' % (step, l))
      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))
      print('Validation accuracy: %.1f%%' % accuracy(
        valid_prediction.eval(), valid_labels))
  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))
```

and the error messages are:

```
Initialized
Minibatch loss at step 0: 3.362968
Minibatch accuracy: 6.2%

InternalErrorTraceback (most recent call last)
<ipython-input-23-c56b394d9d7c> in <module>()
     15       print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))
     16       print('Validation accuracy: %.1f%%' % accuracy(
---> 17         valid_prediction.eval(), valid_labels))
     18   print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in eval(self, feed_dict, session)
    500 
    501     """"""
--> 502     return _eval_using_default_session(self, feed_dict, self.graph, session)
    503 
    504 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in _eval_using_default_session(tensors, feed_dict, graph, session)
   3346                        ""the tensor's graph is different from the session's ""
   3347                        ""graph."")
-> 3348   return session.run(tensors, feed_dict)
   3349 
   3350 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    341     try:
    342       result = self._run(None, fetches, feed_dict, options_ptr,
--> 343                          run_metadata_ptr)
    344       if run_metadata:
    345         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    565     try:
    566       results = self._do_run(handle, target_list, unique_fetches,
--> 567                              feed_dict_string, options, run_metadata)
    568     finally:
    569       # The movers are no longer used. Delete them.

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    638     if handle is None:
    639       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 640                            target_list, options, run_metadata)
    641     else:
    642       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
    660       # pylint: disable=protected-access
    661       raise errors._make_specific_exception(node_def, op, error_message,
--> 662                                             e.code)
    663       # pylint: enable=protected-access
    664 

InternalError: Dst tensor is not initialized.
     [[Node: Const = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [10000,28,28,1] values: -0.45294118 0.029411765 0.40588236...>, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
Caused by op u'Const', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py"", line 3, in <module>
    app.launch_new_instance()
  File ""/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py"", line 596, in launch_instance
    app.start()
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py"", line 442, in start
    ioloop.IOLoop.instance().start()
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py"", line 160, in start
    super(ZMQIOLoop, self).start()
  File ""/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py"", line 883, in start
    handler_func(fd_obj, events)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 433, in _handle_events
    self._handle_recv()
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 465, in _handle_recv
    self._run_callback(callback, msg)
  File ""/usr/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py"", line 407, in _run_callback
    callback(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py"", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py"", line 391, in execute_request
    user_expressions, allow_stdin)
  File ""/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py"", line 199, in do_execute
    shell.run_cell(code, store_history=store_history, silent=silent)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2723, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2825, in run_ast_nodes
    if self.run_code(code, result):
  File ""/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py"", line 2885, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-18-aedb1ef46e04>"", line 14, in <module>
    tf_valid_dataset = tf.constant(valid_dataset)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 166, in constant
    attrs={""value"": tensor_value, ""dtype"": dtype_value}, name=name).outputs[0]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1154, in __init__
    self._traceback = _extract_stack()
```

Is there anything I have to do ? I can see the exception comes from `.eval()` function. I guess @vincentvanhoucke might be right person to ping. 

Thanks
"
2271,Sudden slowdowns due to the TLB shootdowns,"### Environment info

Operating System: Arch Linux

Installed version of CUDA and cuDNN: CUDA 7.5, CUDNN v4
If installed from binary pip package, provide:
1. Which pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"": 0.8.0
### Steps to reproduce

I am experiencing slowdowns due to some problem with memory caching. My system has 32GB of RAM. I am training a CNN on one large image dataset. During training at some point almost 100% of memory is cached which is expected when working with a large dataset. But then soon after TF starts to experience slowdowns (3-5x slower execution per batch). I used netdata and observed that the slowdowns are accompanied by a sudden huge spikes in TLB shootdowns. I found a way how to fix a problem from outside, the slowdowns disappear for quite some time if I just clear all the cached memory like this:

```
$ free && sync && echo 3 > /proc/sys/vm/drop_caches && free
              total        used        free      shared  buff/cache   available
Mem:       32825492     3454324      209124      638072    29162044    28463116
              total        used        free      shared  buff/cache   available
Mem:       32825492     3455692    28603760      637636      766040    28476376

```

Then later when memory is fully cached again they reappear. First row is the state at which the slowdown is happening. You can see that most memory is cached and I am actually using only around 10% of RAM.
Does anyone have an idea what could cause these TLB shootdowns or what can I do to find out more about what is going on?
"
2270,Sequence2Sequence decode does not work,"The rnn sample, ""translate"" or ""sequence2sequence"" has some issues during ""decode"". After I successfully trained, it always gives the following error:

python translate.py --data_dir tensorflow/tensorflow/models/rnn/translate/data --train_dir tensorflow/tensorflow/models/rnn/translate/train-data --size=256 --num_layers=2 --steps_per_checkpoint=50

tensorflow.python.framework.errors.NotFoundError: Tensor name ""embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias"" not found in checkpoint files tensorflow/tensorflow/models/rnn/translate/train-data/translate.ckpt-750
         [[Node: save/restore_slice_13 = RestoreSlice[dt=DT_FLOAT, preferred_shard=-1, _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/restore_slice_13/tensor_name, save/restore_slice_13/shape_and_slice)]]
Caused by op u'save/restore_slice_13', defined at:

I tried with many checkpoints stored, but I get the same error. This is with latest tensorflow-0.8.

Please see if I am missing something.
"
2269,"How to resize one tensor to (e.g., 1.5 * its original shape)?","The tensor shape is not fixed, and can change with different input.
"
2267,fully_connected_preloaded.py fails with Error on Python 2.7.6,"### Environment info

Operating System: Linux xxxxx-Lenovo-Ideapad-V570 3.19.0-58-generic #64~14.04.1-Ubuntu SMP Fri Mar 18 19:05:43 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: n/a
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   n/a - used install.sh
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.6.0

If installed from sources, provide the commit hash:
0d350f9324ae08dcbe0c14f0dbfde169da260a37
### Steps to reproduce
1. python tensorflow/examples/how_tos/reading_data/fully_connected_preloaded.py 
   2.
   3.
### What have you tried?
1. cd tensorflow/examples/how_tos/reading_data
   python fully_connected_preloaded.py
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
Extracting /tmp/data/train-images-idx3-ubyte.gz
Extracting /tmp/data/train-labels-idx1-ubyte.gz
Extracting /tmp/data/t10k-images-idx3-ubyte.gz
Extracting /tmp/data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4
Traceback (most recent call last):
  File ""tensorflow/examples/how_tos/reading_data/fully_connected_preloaded.py"", line 157, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""tensorflow/examples/how_tos/reading_data/fully_connected_preloaded.py"", line 153, in main
    run_training()
  File ""tensorflow/examples/how_tos/reading_data/fully_connected_preloaded.py"", line 106, in run_training
    summary_writer = tf.train.SummaryWriter(FLAGS.train_dir, sess.graph)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/summary_io.py"", line 103, in __init__
    self.add_graph(graph_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/summary_io.py"", line 151, in add_graph
    event = event_pb2.Event(wall_time=time.time(), graph_def=graph_def)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/python_message.py"", line 455, in init
    _ReraiseTypeErrorWithFieldName(message_descriptor.name, field_name)
  File ""/usr/local/lib/python2.7/dist-packages/google/protobuf/internal/python_message.py"", line 386, in _ReraiseTypeErrorWithFieldName
    raise type(exc)(exc, sys.exc_info()[2])
TypeError: (TypeError('Parameter to MergeFrom() must be instance of same class: expected GraphDef got Graph. for field Event.graph_def',), <traceback object at 0x7fce35658b00>)
"
2266,CentOS 6.7 Compilation Issue at HEAD,"CentOS 6.7
Cuda 7.0
cuDNN 6.5

I previously got TensorFlow 7.x to compile with an older version of Bazel (1.x), but this fails with HEAD, and it also fails if I use Bazel 0.2.0 as suggested in other issues.

Bazel 0.2.0 builds fine.

Keeping with what worked before, I run

```
export EXTRA_BAZEL_ARGS='-s --verbose_failures --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone --jobs 8'

bazel build -c opt --config=cuda --linkopt '-lrt' --copt=""-DGPR_BACKWARDS_COMPATIBILITY_MODE"" --conlyopt=""-std=c99"" //tensorflow/tools/pip_package:build_pip_package
```

Here is the error I now get. Any ideas? Please note that python2.7 is in my path, and /usr/bin/env python2.7 opens an interpreter with no problem.

Thanks.

```
ERROR: /home-4/rdipiet2@jhu.edu/install/tensorflow/google/protobuf/BUILD:520:1: Linking of rule '//google/protobuf:internal/_api_implementation.so' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home-4/rdipiet2@jhu.edu/.cache/bazel/_bazel_rdipiet2@jhu.edu/549db212089e33b4d213773753834e47/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/google/protobuf/internal/_api_implementation.so -Wl,-whole-archive bazel-out/local_linux-opt/bin/google/protobuf/_objs/internal/_api_implementation.so/google/protobuf/python/google/protobuf/internal/api_implementation.pic.o -Wl,-no-whole-archive -Wl,-R/cm/shared/apps/gcc/4.8.2/lib64 -lstdc++ -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -lrt): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127: crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /home-4/rdipiet2@jhu.edu/.cache/bazel/_bazel_rdipiet2@jhu.edu/549db212089e33b4d213773753834e47/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -shared -o bazel-out/local_linux-opt/bin/google/protobuf/internal/_api_implementation.so -Wl,-whole-archive bazel-out/local_linux-opt/bin/google/protobuf/_objs/internal/_api_implementation.so/google/protobuf/python/google/protobuf/internal/api_implementation.pic.o -Wl,-no-whole-archive -Wl,-R/cm/shared/apps/gcc/4.8.2/lib64 -lstdc++ -B/usr/bin/ -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -lrt): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.
/usr/bin/env: python2.7: No such file or directory
```
"
2264,TensorFlow 1st Test: could not open file to read NUMA node - what's wrong?,"I went to StackOverflow with this and was pointed back to Github. ;-)
see [http://stackoverflow.com/questions/37067297]
### Environment info

Operating System: Gentoo Linux on Lenovo P50

Installed version of CUDA and cuDNN: 
I installed dev-util/nvidia-cuda-toolkit package, version 7.5.18-r2

```
# ll /opt/cuda/lib/libcud*
-rw-r--r-- 1 root root 189082 May  6 10:42 /opt/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 19  2015 /opt/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Sep 19  2015 /opt/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Sep 19  2015 /opt/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 557240 May  6 10:42 /opt/cuda/lib/libcudart_static.a
```

Plus I installed cuDNN 5 downloaded from Nvidia

```
# ll libcud*
lrwxrwxrwx 1 rj rj       13 Mar 22 08:44 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 rj rj       17 Mar 22 08:44 libcudnn.so.5 -> libcudnn.so.5.0.4
-rwxrwxr-x 1 rj rj 59823168 Mar 22 02:37 libcudnn.so.5.0.4
-rw-rw-r-- 1 rj rj 58734618 Mar 22 02:37 libcudnn_static.a
```

If installed from binary pip package, provide:

Which pip package you installed.

```
# pip3 -V
pip 8.1.1 from /usr/lib64/python3.4/site-packages (python 3.4)
```

The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

```
# python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
```
### Steps to reproduce
1. import tensorflow as tf
2. hello = tf.constant('Hello, TensorFlow!')
3. sess = tf.Session()
### What have you tried?
1. stackoverflow ;-)
"
2262,tensors_flowing.gif,"who knows how to make this gif? https://www.tensorflow.org/images/tensors_flowing.gif
"
2260,tensorflow can't support float64 type when reading from csv data?,"I just follow the  examples,and tried to read csv data with float types

filename_queue = tf.train.string_input_producer([""test1.csv""])

reader = tf.TextLineReader()
key, value = reader.read(filename_queue)

record_defaults = [[1], [1.0], [1.0], [1.0], [1.0]]
col1,col2,col3,col4, col5 = tf.decode_csv(
    value, record_defaults=record_defaults)
features = tf.pack([col1, col2, col3, col4])

with tf.Session() as sess:
  #print sess.run(value)
  # Start populating the filename queue.
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)
  print key,value
  for i in range(1200):
    # Retrieve a single instance:
    example, label = sess.run([features, col5])

  coord.request_stop()
  coord.join(threads)
~ 
But it need to read data into memory first.Because the csv file it too big to read into memory.Can it possbile read with shuffle and minibatch and then training?
"
2256,missing build_pip_package runfiles tensorflow external,"-bash-4.1$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Fri May 6 18:41:53 UTC 2016 : === Using tmpdir: /tmp/tmp.HLtyx30grJ
cp: cannot stat `bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow': No such file or directory
cp: cannot stat`bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/external': No such file or directory
### Environment info

Operating System:

redhat-release-server-6Server-6.7.0.3.el6.x86_64
epel-release-6-8.noarch
scl python27 devtoolset-2 enable
numpy 1.11.0

Installed version of CUDA and cuDNN: 

No CUDA -- configured without GPU

If installed from sources, provide the commit hash:

f8eb1d70a7ea7dc2cd5e1eddde389395f88a6be9
### Steps to reproduce

git clone https://github.com/bazelbuild/bazel.git
cd bazel/
./compile.sh

--git 1.7.1
git clone --recursive https://github.com/tensorflow/tensorflow
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
### What have you tried?
1. With previously installed protobuf from source 3.0.0b2- thought that was the problem so
2. Tried on another box with no previously installed protobuf
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
WARNING: /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/grpc/WORKSPACE:1: Workspace name in /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/grpc/WORKSPACE (@__main__) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions.
WARNING: /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/re2/WORKSPACE:1: Workspace name in /home/ebice/.cache/bazel/_bazel_ebice/e10106cd0aa7dd3e05f3af5f70558af6/external/re2/WORKSPACE (@__main__) does not match the name given in the repository's definition (@re2); this will cause a build error in future versions.
INFO: Loading complete.  Analyzing...
"
2255,Calculating Gradients Through tf.complex64 Numbers,"Hey TF,

Its very nice that you support so many complex number calculations like `tf.complex_abs` and `fft`. I am trying replicate this [Associative LSTM paper ](http://arxiv.org/abs/1602.03032)where complex numbers are needed. 

However, when I try to calculate the gradient using `tf.gradient`, I get the traceback below. Is it not possible to calculate the gradient if complex numbers are used with type `tf.complex64`? If not, this would be an incredibly useful feature as there are several new RNN papers that require complex numbers to be used. 

I am initializing a `tf.complex64` dtype weight matrix as follows:

``` python
      if complex_weights: 
        a = tf.truncated_normal([total_arg_size, output_size], stddev=0.1)
        weight_matrix = tf.Variable(tf.complex(a,a), name=""Complex_Weight"")
```

Perhaps I'm missing something or not writing the code properly. I have TF 0.8 installed. 

`````` python
    gradients = tf.gradients(self.average_mean_loss, params)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 481, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py"", line 414, in _DivGrad
    return (array_ops.reshape(math_ops.reduce_sum(grad / y, rx), sx),
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 526, in r_binary_op_wrapper
    x = ops.convert_to_tensor(x, dtype=y.dtype.base_dtype, name=""x"")
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 94, in _IndexedSlicesToTensor
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1759, in unsorted_segment_sum
    num_segments=num_segments, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 486, in apply_op
    _Attr(op_def, input_arg.type_attr))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 59, in _SatisfiesTypeConstraint
    "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
TypeError: DataType complex64 for attr 'T' not in list of allowed values: float32, float64, int32, int64, uint8, int16, int8, uint16```

``````
"
2254,segfault if import nltk after tensorflow,"### Environment info

Operating System: Centos 7
Linux c7-dev01 3.10.0-327.el7.x86_64 #1 SMP Thu Nov 19 22:10:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux

Tensorflow version 0.8.0 (CPU tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl)
Nltk version 3.2.1 
### Steps to reproduce

When import tensorflow and nltk:
(core) [gbelousov@c7-dev01 ~]$ python -c ""import tensorflow; import nltk;""
Segmentation fault

When importing nltk and then tensorfklow:
(core) [gbelousov@c7-dev01 ~]$ python -c ""import nltk; import tensorflow""
Ok.
### Logs or other output that would be helpful

python[5334]: segfault at 7f63fea092a0 ip 00007f63fea092a0 sp 00007ffde9450138 error 15 in multiarray.cpython-34m.so[7f63fea01000+f000]
"
2253,Tensorflow GPU r0.7 compilation => gcc:  language cuda not recognized,"Hi, 
I am facing an issue while compiling tensorflow-r0.7 on centos6 with gcc-4.9.3(Configured with: ./configure --prefix=/home/soft/gcc-4.9.3)+cuda 7.0 + cudnn 7.0.3.0:

`____[72 / 801] Compiling tensorflow/core/kernels/cwise_op_gpu_real.cu.cc
ERROR: /home/user/TENSOR_GPU/tensorflow/tensorflow/core/BUILD:334:1: C++ compilation of rule '//tensorflow/core:gpu_kernels' failed: gcc failed: error executing command 
  (cd /home/user/.cache/bazel/_bazel_jca142469/fc6103a815c76da222bbe3b7c887440a/tensorflow && \
  exec env - \
    PATH=/home/soft/cuda-7.0/bin:/home/apps/BINUTILS/2.25/gnu/bin:/home/soft/intel2015/composer_xe_2015.3.187/mkl/bin:/home/soft/gcc-4.9.3/bin:/home/user/TENSOR_GPU/jdk1.8.0_92/jre/bin:/home/user/TENSOR_GPU/jdk1.8.0_92/bin:/home/apps/PROTOBUF/2.6.1/gnu/include:/home/apps/PROTOBUF/2.6.1/gnu/bin:/home/apps/Caffe/CaffeDependencies/include:/home/soft/cuda-6.5/bin:/usr/lib64/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/opt/pbs/default/bin:/opt/pbs/default/sbin:/opt/pbs/default/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/home/apps/MATLAB/R2014b/bin:/home/user/bin \
  /home/soft/gcc-4.9.3/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-opt/genfiles/external/eigen_archive -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda/include -isystem external/bazel_tools/tools/cpp/gcc3 -isystem google/protobuf/src -isystem bazel-out/local_linux-opt/genfiles/google/protobuf/src -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-c5e90d9e764e -isystem bazel-out/local_linux-opt/genfiles/external/eigen_archive/eigen-eigen-c5e90d9e764e -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-opt/genfiles/third_party/gpus/cuda -x cuda '-DGOOGLE_CUDA=1' -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-opt/bin/tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.pic.o' -MD -MF bazel-out/local_linux-opt/bin/tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.pic.d -fPIC -c tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.cc -o bazel-out/local_linux-opt/bin/tensorflow/core/_objs/gpu_kernels/tensorflow/core/kernels/cwise_op_gpu_equal_to.cu.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
gcc: error: language cuda not recognized`

also in  gcc man page, i can't locate **cuda** as a possible value of language switch:
 -x language
           Specify explicitly the language for the following input files (rather than letting the compiler choose a default based on the file name suffix).  This option applies to all following input files until the next -x option.  Possible values for language are:
**c  c-header  c-cpp-output  c++  c++-header  c++-cpp-output  objective-c  objective-c-header  objective-c-cpp-output objective-c++ objective-c++-header objective-c++-cpp-output assembler  assembler-with-cpp ada  f77  f77-cpp-input f95  f95-cpp-input  java**

Any help/hint will be very useful.
Eagerly awaiting your replies..
"
2251,get error when slice tensor,"I want to slice tensor to get specific tensor by list of index, for example:

```
word_weight   = tf.get_variable(""word_weight"", [20])
a= word_weight[ [1,6,5] ]
```

(I want to get word_weight[1],  word_weight[6],  word_weight[5])

---

But I get error when I run above code.

```
raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape (16491,) must have rank 3

```
"
2248,Tensorflow r0.8 doesn't work with scikit-learn and scikit-Image,"I tried two installation method. Without scikit-Learn and scikit-Image, tensorflow works fine and I can run the deepdream ipynb. 
1. cuda 7.5 + cudnn v5 with source code compiled
2. cuda 7.5 + cudnn v4 pip GPU install

All according to https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html

After I installed scikit-learn, the segmentation fault (core dumped) following the Tensorflow loading message even though I import numpy before tesorflow. I will post more info here later.
"
2247,Doubt with sharing variable ,"http://tensorflow.org/how_tos/variable_scope/index.md

I was experiencing serious difficulties at first and believed we're endeavoring to utilize the same weights for both of the conv layers. It didn't help that the definition for ""variables_dict"" just unequivocally expresses the presence for the weights for the primary conv layer, persuading that the weights of the 2 layers are really shared also.
"
2245,how to delete node from old graph,"I build retrain_image for 5 new flowers,and got a pb file ,87M,has 1001 nodes.I put it in android demo.Every run costs 2S.It is terrorable.I guess,because of too many unusefull nodes.So,how to delete nodes those I wish in retraining?
"
2243,Error when building on Mac with GPU,"I am new to this so feel free to delete this if this is trivial.

I encountered the following errors when building from source on Mac with GPU support

`tensorflow/core/kernels/cudnn_pooling_gpu.cc:71:32: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'
  for (size_t i = 0; i < window.size(); ++i) {
                               ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__tuple:95:65: note: template is declared here
template <class _Tp, size_t _Size> struct _LIBCPP_TYPE_VIS_ONLY array;
                                                                ^
tensorflow/core/kernels/cudnn_pooling_gpu.cc:73:42: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'
    pooling_desc.set_window(dim_i, window.rbegin()[i]);
                                         ^
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/../include/c++/v1/__tuple:95:65: note: template is declared here
template <class _Tp, size_t _Size> struct _LIBCPP_TYPE_VIS_ONLY array;
`
and seven other similar errors.

Including `<array>` in `tensorflow/tensorflow/core/kernels/cudnn_pooling_gpu.cc` seems to fix the problem
"
2242,Silent fail when network is big,"### Steps to reproduce
1. Build a 10 layer hidden network with 2400 neurons in each layer 
2. Have data with correlation
3. Accuracy will be 1 / n_classes_outputs for each training step. 
### What have you tried?
1. If you will have less neurons and layers, everything works

I presume that there is a issue with memory and setting weights, but a error message would be nice.
"
2241,Core dumped error for specific example codes (virtualenv related?),"Hi there,

I have installed TensorFlow on my system, and was able to run some examples just fine on the gpu: (e.g. 0_multiply.py, 1_linear_regression.py, 4_modern_net.py, etc). However, when I try to run some CNN-related codes, I am getting a core-dumped error.
### Environment info

Operating System: Ubuntu 14.04, TensorFlow installed in virtualenv

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

> -rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
> lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
> lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
> -rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
> -rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
> lrwxrwxrwx 1 root root       13 May  5 12:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
> lrwxrwxrwx 1 root root       17 May  5 12:48 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.0.4
> -rwxrwxr-x 1 root root 59823168 Mar 21 20:37 /usr/local/cuda/lib64/libcudnn.so.5.0.4
> -rwxr-xr-x 1 root root 19340472 Apr 19 09:43 /usr/local/cuda/lib64/libcudnn.so.6.5
> -rwxr-xr-x 1 root root 19340472 Apr 19 09:43 /usr/local/cuda/lib64/libcudnn.so.6.5.18
> -rw-rw-r-- 1 root root 58734618 Mar 21 20:37 /usr/local/cuda/lib64/libcudnn_static.a

I installed TF using this page: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#virtualenv-installation
via virtualenv. I needed virtualenv because I don't want it to screw with my python/Theano.
### Steps to reproduce
1. Running 5_convolutional_net.py will produce the log file.
### What have you tried?

I'm using CUDA 7.5, so I tried reinstalling CUDA 7.0 and CUDA 6.5
### Logs or other output that would be helpful

> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN Black, pci bus id: 0000:03:00.0)
> Building graph...
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
> I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN Black, pci bus id: 0000:03:00.0)
> Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f4bf7816390>> ignored
> F tensorflow/stream_executor/cuda/cuda_dnn.cc:204] could not find cudnnCreateTensorDescriptor in cudnn DSO; dlerror: /usr/local/lib/libcudnn.so: undefined symbol: cudnnCreateTensorDescriptor
> Aborted (core dumped)

Thanks for your help! It was able to use my GPU fine for other codes, not particularly the ones involving CNNs.
"
2240,"Will it conflict installing by soucecode ,with installing by pip","I have install tensorflow by pip.
And Because I have to add some code in tensorflow ,so I need to build tensorflow by sourcecode.
And when run bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
it will report 
configure: error: zlib not installed
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2.743s, Critical Path: 2.24s
But in fact ,I have install zlib.

INFO: Elapsed time: 2.743s, Critical Path: 2.24s
[@sjs_88_31 tensorflow]# yum install zlib
Loaded plugins: fastestmirror, langpacks
Loading mirror speeds from cached hostfile
- epel: mirrors.neusoft.edu.cn
  _Package zlib-1.2.7-13.el7.x86_64 already installed and latest version
  _Nothing to do
  So how can I fixed it?
  My Os is cenos7.1.

And how can i add souce files if just only using pip install?
"
2239,tensorflow error in a docker container ,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5 and 4 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide: 
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce
1. Install tensorflow-gpu-devel
2. docker run the image
3. python and import tensorflow
### What have you tried?
1. Tried the example from tensorflow website: https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#test-the-tensorflow-installation
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

> > > import tensorflow as tf
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.5 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.4 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.5 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so.7.5 locally
> > > sess = tf.Session()
> > > E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUresult(-1)
> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: 18a61c37a941
> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: 18a61c37a941
> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: Invalid argument: expected %d.%d form for driver version; got ""1""
> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.93  Tue Apr  5 18:18:24 PDT 2016
> > > GCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) 
> > > """"""
> > > I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.93
> > > I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.
"
2238,Issue with conditional comparing (equal returning wrong type),"### Environment info

Operating System: Ubuntu

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): (this path did not exist)
7.5 is CUDA

If installed from binary pip package, provide:
1. Which pip package you installed. GPU Ubuntu .8.0
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
   0.8.0
### Steps to reproduce

Code is also in this stack Overflow:
http://stackoverflow.com/questions/37044006/tensorflow-conditional-throwing-value-error/37053896#37053896

```
import tensorflow as tf
import numpy as np

X = tf.constant([1, 0])
Y = tf.constant([0, 1])
BOTH = tf.constant([1, 1])
WORKING = tf.constant(1)

def create_mult_func(tf, amount, list):
    def f1():
        return tf.scalar_mul(amount, list)
    return f1

def create_no_op_func(tensor):
    def f1():
        return tensor
    return f1

def stretch(tf, points, dim, amount):
    """"""points is a 2 by ??? tensor, dim is a 1 by 2 tensor, amount is tensor scalor""""""
    x_list, y_list = tf.split(0, 2, points)
    x_stretch, y_stretch = tf.split(0, 2, dim)
    is_stretch_X = tf.equal(x_stretch, WORKING, name=""is_stretch_x"")
    is_stretch_Y = tf.equal(y_stretch, WORKING, name=""is_stretch_Y"")
    print tf.shape(is_stretch_X)
    print tf.shape(is_stretch_Y)
    x_list_stretched = tf.cond(is_stretch_X,
                               create_mult_func(tf, amount, x_list), create_no_op_func(x_list))
    y_list_stretched = tf.cond(is_stretch_Y,
                               create_mult_func(tf, amount, y_list), create_no_op_func(y_list))
    return tf.pack(x_list_stretched, y_list_stretched)

example_points = np.array([[1, 1], [2, 2], [3, 3]], dtype=np.float32)
example_point_list = tf.placeholder(tf.float32)

result = stretch(tf, example_point_list, X, 1)
sess = tf.Session()

with tf.Session() as sess:
    result = sess.run(result, feed_dict={example_point_list: example_points})
    print(result)
```
### What have you tried?
1. passing in a scalar instead of a tensor by reshaping the tensor
2. changing `WORKING` to ```tf.constant([1]) 
### This fixes the error but seems very wrong and does not fix the other issues

```
is_stretch_X = tf.reshape(tf.cast(tf.equal(x_stretch, WORKING, name=""is_stretch_x""), tf.bool), [])
is_stretch_Y = tf.reshape(tf.cast(tf.equal(y_stretch, WORKING, name=""is_stretch_Y""), tf.bool), [])
```

The result of equal should be passed to the conditional without needing to reshape or cast to a boolean first.
Btw it ignores the cast to the boolean as well leaving it as an int32
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
File ""/path/test2.py"", line 36, in <module>
    result = stretch(tf, example_point_list, X, 1)
  File ""/path/test2.py"", line 28, in stretch
    create_mult_func(tf, amount, x_list), create_no_op_func(x_list))
  File ""/path/tensorflow/python/ops/control_flow_ops.py"", line 1142, in cond
    p_2, p_1 = switch(pred, pred)
  File ""/path/tensorflow/python/ops/control_flow_ops.py"", line 203, in switch
    return gen_control_flow_ops._switch(data, pred, name=name)
  File ""/path/tensorflow/python/ops/gen_control_flow_ops.py"", line 297, in _switch
    return _op_def_lib.apply_op(""Switch"", data=data, pred=pred, name=name)
  File ""/path/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/path/tensorflow/python/framework/ops.py"", line 2156, in create_op
    set_shapes_for_outputs(ret)
  File ""/path/tensorflow/python/framework/ops.py"", line 1612, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/path/tensorflow/python/ops/control_flow_ops.py"", line 2032, in _SwitchShape
    unused_pred_shape = op.inputs[1].get_shape().merge_with(tensor_shape.scalar())
  File ""/path/tensorflow/python/framework/tensor_shape.py"", line 554, in merge_with
    (self, other))
ValueError: Shapes (1,) and () are not compatible
```
"
2237,Add support for recursive neural networks,"I'd like to implement a recursive neural network as in [[Socher et al. 2011]](http://www.socher.org/index.php/Main/ParsingNaturalScenesAndNaturalLanguageWithRecursiveNeuralNetworks) in TensorFlow.

Note that this is different from recurrent neural networks, which are nicely supported by TensorFlow. The difference is that the network is not replicated into a linear sequence of operations, but into a tree structure.

Maybe a tree traversal can already be implemented using `While` ops, but I'm not sure how.
(A bottom-up traversal of a tree would have to be performed for each entry in the dataset, applying the network at each node)
Instinctively, I have the impression that this would need a new C++ op that generalizes `While`.
"
2236,Can't separate by sentences when running word2vec model?,"In gensim word2vec, the input can be a list of sentences. However, in tensorflow word2vec, the input is a list of words (concatenate sentences together). Can you add the feature to separate by sentences to word2vec?
 I am using the following code: https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/models/embedding/word2vec.py
"
2235,'module' object has no attribute 'conv3d' but only in Jupyter Notebook,"Hi! This isn't really a bug, but more a support request.

I tried to use the new conv3d operations from 6a187ccddaebb741ea77fc3201c6e36625f0aadb, so I built a pip wheel from the latest sources, created a virtualenv called ""tensorflow-dev"" and instlled the wheel there.

Now I am running into weirdness that I cannot explain...

Python works:

```
$ python3
Python 3.5.1 (default, Mar  7 2016, 18:39:06) 
[GCC 5.3.1 20151207 (Red Hat 5.3.1-2)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
>>> tf.nn.conv3d
<function conv3d at 0x7fb58acc3400>
>>> 
```

Ipython works:

```
$ ipython3
Python 3.5.1 (default, Mar  7 2016, 18:39:06) 
Type ""copyright"", ""credits"" or ""license"" for more information.

IPython 4.2.0 -- An enhanced Interactive Python.
?         -> Introduction and overview of IPython's features.
%quickref -> Quick reference.
help      -> Python's own help system.
object?   -> Details about 'object', use 'object??' for extra details.

In [1]: import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally

In [2]: tf.nn.conv3d
Out[2]: <function tensorflow.python.ops.gen_nn_ops.conv3d>
```

But the Jupyter notebook does not!!

```
In [1]: import tensorflow as tf
In [2]: tf.nn.conv3d
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-2-9e3b7db30b11> in <module>()
----> 1 tf.nn.conv3d

AttributeError: 'module' object has no attribute 'conv3d'
```

All three were started form the same shell, after activating the same virtualenv. I really can't explain this. Does anyone have any ideas what's wrong with my install?
"
2234,`_tanh(x)` returns different values for the same `x`,"Why is the last one (`0.99505478`) different from the first four?

``` python
>>> import tensorflow as tf
>>> from tensorflow.python.ops.gen_math_ops import _tanh
>>> a = tf.ones([1, 3], tf.float32)
>>> b = tf.ones([3, 5], tf.float32)
>>> c = tf.matmul(a, b)
>>> sess = tf.Session()
>>> print(sess.run(_tanh(c)))
[[ 0.99505472  0.99505472  0.99505472  0.99505472  0.99505478]]
```

With `tf.float64`, the values are all `0.99505475`.
"
2233,protobuf message overflow on trying distributed ,"I'm trying to build an RNN on multi-machines following the [Distributed Tensorflow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md). 
when I use ""with sv.managed_session(server.target) as sess:"", it shows error:
AttributeError: 'Supervisor' object has no attribute 'managed_session'
So I follow the code of ""Inception"":
with sv.prepare_or_wait_for_session(server.target, config = sess_config) as sess :

Then it starts to run, but hangs immediately after reporting the following error:

[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:569] Reading dangerously large protocol message.  If the message turns out to be larger than 67108864 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/src/google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 67108864
E tensorflow/core/framework/tensor.cc:105] Input size was 67108839 and expected 72000800

Would you please help me on this?
Thanks a lot in advance!
"
2232,Links for API broken,"On tensorflow website the links for API are broken on [this](https://www.tensorflow.org/versions/r0.7/api_docs/cc/index.html) page. 
"
2231,add R-CNN support with ROI pooling ?,"Hi, 
I'm interested in implementing a R-CNN or similar object detection/recognition model. there is a theano [port](https://github.com/ddtm/theano-roi-pooling) of Ross. Girshick's implementation in Caffe. 
please let me know if there is a plan to implement R-CNN / release the ROI pooling layer in Tensorflow?

please see.
[Faster RCNN on caffe.](https://github.com/rbgirshick/py-faster-rcnn)
"
2229,Check failed,"F tensorflow/core/framework/tensor_shape.cc:211] Check failed: num_elements_ <= kMaxElements (9291474468864 vs. 1099511627776)
I can't figure out why the above error happens. What's wrong ?
"
2228,Inconsistence output with resize_images() using different method ,"Extended from [Stackoverflow question](http://stackoverflow.com/questions/37032251/tensorflow-image-resize-mess-up-image-on-unknown-image-size)
### Environment info

Operating System: Ubuntu 14.04 / OS X Yosemite

Installed version of CUDA and cuDNN: 
CUDA Version : 7.5
cuDnn: 4

Tensorflow version: 0.8.0

When resizing image with variable dimension (output from `decode_jpeg`), image tend to get messed up. However, if `reshape()` is applied prior to `resize()`, image will get resized properly. This issue does not affect `ResizeMethod.Nearest_Neighbour`. 
### Steps to reproduce

```

import tensorflow as tf
import matplotlib.pyplot as plt

file_contents = tf.read_file('./2008_000002.jpg')
im = tf.image.decode_jpeg(file_contents)
im_bi = tf.image.resize_images(im, 256, 256, method=tf.image.ResizeMethod.BILINEAR)
im_nn = tf.image.resize_images(im, 256, 256, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
im_bic = tf.image.resize_images(im, 256, 256, method=tf.image.ResizeMethod.BICUBIC)
im_ar = tf.image.resize_images(im, 256, 256, method=tf.image.ResizeMethod.AREA)

# im = tf.reshape(im, shape=[256, 256, 3])

sess = tf.Session()
sess.run(tf.initialize_all_variables())

img_bi, img_nn, img_bic, img_ar = sess.run([im_bi, im_nn, im_bic, im_ar])

plt.imshow(img_bi)
plt.title(""BILINEAR"")
plt.figure()

plt.imshow(img_nn)
plt.title(""NEAREST_NEIGHBOR"")
plt.figure()

plt.imshow(img_bic)
plt.title(""BICUBIC"")
plt.figure()

plt.imshow(img_ar)
plt.title('AREA')
plt.show()
```

[Original image](http://imgur.com/MskVWIV)

Result
![nearest Neighbour](https://cloud.githubusercontent.com/assets/650407/15034074/7b973208-12a4-11e6-943e-ea04e1389c01.png)
![bilinear](https://cloud.githubusercontent.com/assets/650407/15034080/88bfbc84-12a4-11e6-81be-b0fa632d7997.png)
![bicubic](https://cloud.githubusercontent.com/assets/650407/15034081/88c2a41c-12a4-11e6-9681-f008ec36ff0f.png)
![area](https://cloud.githubusercontent.com/assets/650407/15034079/88bb4604-12a4-11e6-9ff9-1a53c49a5ab3.png)
"
2226,Evaluated expressions of variables differ sometimes when using the GPU,"The evaluated value of the l1 or l2 loss of variables differ sometimes when using the GPU. This seems to happen when the variables are ""large"".

Even though the difference is not that much in the example below, these differences have resulted in a 98% test accuracy on a network trained on the CPU, but a 10% test accuracy on the same network trained on the GPU.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5 and 7.0 [cuda_info.txt](https://github.com/tensorflow/tensorflow/files/249768/cuda_info.txt)
GPU: Titan X

If installed from binary pip package, provide:
1. Which pip package you installed.
pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
python -c ""import tensorflow; print(tensorflow.**version**)""I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
### Steps to reproduce

```
import tensorflow as tf
W1 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))
W2 = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1))
sess = tf.InteractiveSession()
sess.run(tf.initialize_all_variables())
l2 = tf.reduce_sum(W1 * W1) + tf.reduce_sum(W2 * W2)
for i in range(100):
    print('%.10f' % sess.run(l2))
```
"
2225,"InvalidArgumentError: No OpKernel T=DT_INT32 for log, exp, etc.","### Environment info

Operating System: Mac/Ubuntu
Installed version of CUDA and cuDNN: None
commit b8883a237b71e877759327fb4b9077847d4cb16c
### Steps to reproduce

Thanks to http://stackoverflow.com/questions/37027762:

```
import tensorflow as tf
import numpy as np
x = np.array([1], dtype=np.int32)
sess = tf.Session()
print(sess.run(tf.log(x)))
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

https://www.tensorflow.org/versions/r0.8/api_docs/python/math_ops.html#log says ""x: A Tensor. Must be one of the following types: float32, float64, int32, complex64, int64"", but int32 and in64 throws InvalidArgumentError:

InvalidArgumentError: No OpKernel was registered to support Op 'Log' with these attrs
     [[Node: Log_4 = Log[T=DT_INT32](Log_4/x)]].

I haven't checked all, but `exp`, `cos` and `sin` have the same issue.

I added a simple test:

```
--- a/tensorflow/python/ops/math_ops_test.py
+++ b/tensorflow/python/ops/math_ops_test.py
@@ -28,6 +28,21 @@ from tensorflow.python.platform import googletest
 exp = np.exp
 log = np.log

+class LogTest(test_util.TensorFlowTestCase):
+
+  def testLog(self):
+    x = np.array([1], dtype=np.int32)
+    with self.test_session():
+      y_tf = math_ops.log(x).eval()
+      self.assertEqual(y_tf, 0)

```

which clearly reveals this issue:

```
exec ${PAGER:-/usr/bin/less} ""$0"" || exit 1
-----------------------------------------------------------------------------
..E..........
======================================================================
ERROR: testLog (__main__.LogTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/ops/math_ops_test.py"", line 44, in testLog
    y_tf = math_ops.log(x).eval()
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/framework/ops.py"", line 502, in eval
    return _eval_using_default_session(self, feed_dict, self.graph, session)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/framework/ops.py"", line 3352, in _eval_using_default_session
    return session.run(tensors, feed_dict)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/client/session.py"", line 343, in run
    run_metadata_ptr)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/client/session.py"", line 578, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/client/session.py"", line 651, in _do_run
    target_list, options, run_metadata)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/client/session.py"", line 673, in _do_call
    e.code)
InvalidArgumentError: No OpKernel was registered to support Op 'Log' with these attrs
     [[Node: Log = Log[T=DT_INT32, _device=""/device:CPU:0""](Log/x)]]
Caused by op u'Log', defined at:
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/ops/math_ops_test.py"", line 110, in <module>
    googletest.main()
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/platform/googletest.py"", line 84, in main
    benchmark.benchmarks_main(true_main=g_main)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/platform/benchmark.py"", line 301, in benchmarks_main
    true_main()
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/platform/googletest.py"", line 58, in g_main
    return unittest_main(*args, **kwargs)
  File ""/usr/lib/python2.7/unittest/main.py"", line 95, in __init__
    self.runTests()
  File ""/usr/lib/python2.7/unittest/main.py"", line 232, in runTests
    self.result = testRunner.run(self.test)
  File ""/usr/lib/python2.7/unittest/runner.py"", line 151, in run
    test(result)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 70, in __call__
    return self.run(*args, **kwds)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 108, in run
    test(result)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 70, in __call__
    return self.run(*args, **kwds)
  File ""/usr/lib/python2.7/unittest/suite.py"", line 108, in run
    test(result)
  File ""/usr/lib/python2.7/unittest/case.py"", line 395, in __call__
    return self.run(*args, **kwds)
  File ""/usr/lib/python2.7/unittest/case.py"", line 331, in run
    testMethod()
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/ops/math_ops_test.py"", line 44, in testLog
    y_tf = math_ops.log(x).eval()
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/ops/gen_math_ops.py"", line 843, in log
    return _op_def_lib.apply_op(""Log"", x=x, name=name)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/ops/op_def_library.py"", line 694, in apply_op
    op_def=op_def)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/framework/ops.py"", line 2153, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/hunkim/.cache/bazel/_bazel_hunkim/6785122ce03f8c29e79889062219c7d3/tensorflow/bazel-out/local-fastbuild/bin/tensorflow/python/math_ops_test.runfiles/tensorflow/python/framework/ops.py"", line 1153, in __init__
    self._traceback = _extract_stack()


----------------------------------------------------------------------
Ran 13 tests in 0.144s

FAILED (errors=1)
```
"
2223,feed_previous argument for basic_rnn_seq2seq,"Feature request: can the `basic_rnn_seq2seq` function in the seq2seq module implement a `feed_previous` argument, just like the `embedding_rnn_seq2seq` function?
"
2219,Can't allocate memory from GPU error in digits.py,"### Environment info

Operating System: 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r--   1 root root    322936 Eyl 19  2015 libcudadevrt.a
lrwxrwxrwx   1 root root        16 Mar 30 15:25 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx   1 root root        19 Mar 30 15:25 libcudart.so.7.5 -> libcudart.so.7.5.18
-rw-r--r--   1 root root    383336 Eyl 19  2015 libcudart.so.7.5.18
-rw-r--r--   1 root root    720192 Eyl 19  2015 libcudart_static.a
lrwxrwxrwx   1 root root        12 Nis 14 18:53 libcuda.so -> libcuda.so.1
lrwxrwxrwx   1 root root        17 Nis 14 18:53 libcuda.so.1 -> libcuda.so.361.42
-rw-r--r--   1 root root  16881416 Mar 23 02:42 libcuda.so.361.42
-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so
-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so.4
-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so.4.0.7
-rwxr-xr-x   1 root root  59823168 Nis 30 11:12 libcudnn.so.5
-rwxr-xr-x   1 root root  59823168 Nis 30 11:12 libcudnn.so.5.0.4
-rw-r--r--   1 root root  62025862 Nis 30 11:36 libcudnn_static.a
```

Installed using:

``````
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl```
``````

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
```
### Steps to reproduce

```
(tensorflow)username@pcname:~/Research/ai/tf_examples$ python digits.py 
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.291
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.53GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:932] failed to allocate 5.53G (5935898624 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
Step #100, epoch #8, avg. train loss: 2.79814
Step #200, epoch #16, avg. train loss: 1.27029
Step #300, epoch #25, avg. train loss: 0.98960
Step #400, epoch #33, avg. train loss: 0.84844
Step #500, epoch #41, avg. train loss: 0.75324
Accuracy: 0.744444
```

Running digits.py throws the ""failed to allocate 5.53G"" (the available memory on GPU is 6GB).  
### Possible solution

I can restrict the allocated memory using 

```
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
```

but I am wondering if there is any other way to handle this error. 
"
2218,Add HDFS support,"Becase of massive data,data is stored in hdfs
Can tensorflow support to read from hdfs directly?
"
2217,Wrap cuSOLVER in stream,"I have started to wrap NVIDIA's cusolver library (LAPACK-like) for my work on #367. Is this something the TF team would consider supporting/helping with? I have so far only wrapped potrf, but adding more functions should be fairly easy now that I have done the long-winded bit.

[Its in my fork](https://github.com/c0g/tensorflow).
"
2216,DirectSessionRegistrar not found in libraries,"tensorflow branch r0.7    android-ndk-r10e    bazel-0.2.1

I build the android:tensorflow_demo with the command below:

=> bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures

The build is successful, and it generate some files:

=> ??????????????.apk
=> tensorflow_demo.so
=> libandroid_tensorflow_lib.a
=> libre2.a and so on

I want to use Windows Android SDK/NDK to develop Android APP with these static libraries.

When I initialize the tensorflow session, it prompt that direct session not found.

Then I browse the code tensorflow\core\common_runtime\direct_session.cc.
At the tail, I find:

""""""
class DirectSessionFactory : public SessionFactory {
 public:
  DirectSessionFactory() {}

  Session\* NewSession(const SessionOptions& options) override {
    std::vector<Device*> devices;
    DeviceFactory::AddDevices(options, ""/job:localhost/replica:0/task:0"",
                              &devices);
    return new DirectSession(options, new DeviceMgr(devices));
  }
};

class DirectSessionRegistrar {
 public:
  DirectSessionRegistrar() {
    SessionFactory::Register(""DIRECT_SESSION"", new DirectSessionFactory());
  }
};
static DirectSessionRegistrar registrar;
""""""

nm libandroid_tensorflow_lib.a | grep ""???""
nm direct_session.o | grep ""???""

I can grep DirectSessionFactory from libandroid_tensorflow_lib.a/direct_session.o, but not DirectSessionRegistrar.

It seems that libandroid_tensorflow_lib.a/direct_session.o does not contain DirectSessionRegistrar.

What can i do?
"
2215,How to classify an image with the trained cifar10 model?,"After trained a cifar10 model, I want to test the model with a image. There are some other people trying to make it, but it's still a confusing question. My test code is presented, as follows:

```
from datetime import datetime
import math
import time

import numpy as np
import tensorflow as tf
import cifar10

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_string('checkpoint_dir', 'cifar10_train/',
                           """"""Directory where to read model checkpoints."""""")


def  evaluate_images(images):
  logit = cifar10.inference(images)
  load_trained_model(logit)

def load_trained_model(logits):
  with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)
    if ckpt and ckpt.model_checkpoint_path:
      # Restores from checkpoint
      saver.restore(sess, ckpt.model_checkpoint_path)
    else:
      print('No checkpoint file found')
      return

    predict = tf.argmax(logits,1)
    print(predict.eval(), '\n')

def img_read(filename):
  if not tf.gfile.Exists(filename):
    tf.logging.fatal('File does not exists %s', filename)
  image_data = tf.gfile.FastGFile(filename, 'rb').read()
  image = tf.cast(image_data, tf.float32)
  return image

filename = '1.png'
images = img_read(filename)
evaluate_images(images)
```

But it occurs the bug: 

```
File ""/home/swoda/tensorflow/tensorflow/models/image/cifar10/cifar10.py"", line 192, in inference
    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 295, in conv2d
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2156, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1612, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/common_shapes.py"", line 202, in conv2d_shape
    input_shape = op.inputs[0].get_shape().with_rank(4)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 625, in with_rank
    raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape () must have rank 4
```

If you know how to fix this problem, please tell me. Thank you very much!
"
2212,installation issue on Mac OS,"Hello,

I am following the installation guide here (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md), and here is the message I met with. I want to install on Mac OSX. Thanks.

sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
The directory '/Users/foo/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/Users/foo/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Collecting tensorflow==0.8.0 from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
  Downloading https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl (19.3MB)
    100% || 19.3MB 65kB/s
Requirement already up-to-date: six>=1.10.0 in /Library/Python/2.7/site-packages/six-1.10.0-py2.7.egg (from tensorflow==0.8.0)
Collecting protobuf==3.0.0b2 (from tensorflow==0.8.0)
  Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)
    100% || 327kB 2.4MB/s
Collecting wheel (from tensorflow==0.8.0)
  Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)
    100% || 71kB 9.5MB/s
Collecting numpy>=1.10.1 (from tensorflow==0.8.0)
  Downloading numpy-1.11.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.9MB)
    100% || 3.9MB 322kB/s
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.8.0)
  Downloading setuptools-21.0.0-py2.py3-none-any.whl (509kB)
    100% || 512kB 1.9MB/s
Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow
  Found existing installation: setuptools 1.1.6
    Uninstalling setuptools-1.1.6:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/basecommand.py"", line 209, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/commands/install.py"", line 317, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/req/req_set.py"", line 726, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/req/req_install.py"", line 746, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/utils/**init**.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 299, in move
    copytree(src, real_dst, symlinks=True)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 208, in copytree
    raise Error, errors
Error: [('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', ""[Errno 1] Operation not permitted: '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', ""[Errno 1] Operation not permitted: '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', ""[Errno 1] Operation not permitted: '/tmp/pip-a1DXRT-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib'"")]
"
2211,tf.add_check_numerics_ops() adds ops to while_loop frame,"When I construct a graph that contains a tf.while_loop, and then try to call tf.add_check_numerics_ops(), I get an InvalidArgumentError.

Given the code

``` python
import tensorflow as tf

def test():
    i = tf.constant(0, tf.float32)
    c = lambda i: tf.less(i, 10)
    b = lambda i: tf.add(i, 1)
    r = tf.while_loop(c, b, [i])

    check = tf.add_check_numerics_ops()

    with tf.Session() as sess:
        print sess.run([r,check])
```

I get the error

``` python
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""minimal_bug_example.py"", line 12, in test
    print sess.run([r,check])
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 340, in run
    run_metadata_ptr)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 564, in _run
    feed_dict_string, options, run_metadata)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 637, in _do_run
    target_list, options, run_metadata)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: All inputs to node CheckNumerics_1 must be from the same frame.
```

I'm running Tensorflow installed from pip, version 0.8.0. As far as I can tell, this is caused by the while_loop creating a new control flow context, but the check numerics op living outside that context.
"
2210,Sharing a GPU between tensorflow and another cuda code.,"Hello,

I am trying to run tensorflow and another cuda code in the same python script. My script is coded such that it iteratively uses the other cuda code to generate bunch of samples and then it uses tensorflow to process them. The tensoflow session is always open while doing these iterations.

The problem is that in tensorflow 0.7, I get the following error when the session is closing (exiting python):

F tensorflow/stream_executor/cuda/cuda_driver.cc:302] current context was not created by the StreamExecutor cuda_driver API: 0x2eb5c50; a CUDA runtime call was likely performed without using a StreamExecutor context

And, in tensorflow 0.8, I get another error in middle of run:

**\* Error in `python': munmap_chunk(): invalid pointer: 0x00007ffea63b7380 ***
Aborted (core dumped)

I have modified my other cuda code to use cuda's Stream Executor context but this did not solve any of these issues. I'm also pretty sure my cuda code does not have any memory leak. If I replace my cuda code with its cpu version or the tensorflow operations with numpy counterparts every thing works perfectly. I have also limited gpu memory for TF using: 

tf.GPUOptions(per_process_gpu_memory_fraction=0.5)

I am wondering if we actually can share a single GPU between tenorflow and another cuda code in the same script? If so, is there any particular protocol that I should follow.
"
2209,Word2vec overflows int32 corpus_size_,"Hello, I'm trying to build a big word model, and I'm getting overflows in the corpus_size_ declared here
https://github.com/tensorflow/tensorflow/blob/e39d8feebb9666a331345cd8d960f5ade4652bba/tensorflow/models/embedding/word2vec_kernels.cc#L119

The error is being thrown here:

https://github.com/tensorflow/tensorflow/blob/e39d8feebb9666a331345cd8d960f5ade4652bba/tensorflow/models/embedding/word2vec_kernels.cc#L191

Because negative numbers are less than positive numbers. I'm going to change them to uint64 in my own build, if it doesn't cause problems should I make a PR?
"
2207,Feature request: Implement SVD,"Feature request: Implement SVD

Like for example in Torch:
https://github.com/torch/torch7/blob/master/doc/maths.md#torchsvdresu-ress-resv-a--s-or-a
"
2205,Wheel not supported Python3.5 ,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: ArchLinux x64 Anaconda Environment

Installed version of CUDA and cuDNN: CPU Only Version
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   pip 8.1.1 from /opt/conda/envs/AI_Playground/lib/python3.5/site-packages (python 3.5)
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   Tensorflow is not yet Installed
   If installed from sources, provide the commit hash:
### Steps to reproduce
1. Install anaconda
2. Create Python3.5 environment
3. Follow tensorflow install guide for Anaconda
### What have you tried?
1. The command the tutorial provides to create the env : 

$ conda create -n tensorflow python=3.5

and then the command:

 pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl

reference different c python versions 3.5 and c python 3.4 respectively.

I tried tweaking the version in the link to cp35 in both instances which resulted in a 404 error from the pip script. Which I kind of expected. 
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2201,issues when installing on EC2,"I am trying to install TF on EC2 GPU instance, I'm following http://eatcodeplay.com/installing-gpu-enabled-tensorflow-with-python-3-4-in-ec2/ tutorial. In following step I will get this error. I should mention I am using Master not the specific head that is in tutorial (I guess it's version 6.5):

```
ubuntu@ip:/mnt/tmp/tensorflow$ bazel build -c opt --verbose_failures --config=cuda //tensorflow/cc:tutorials_example_trainer
INFO: Found 1 target...
INFO: From Compiling tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:
tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:198:15: warning: 'std::string perftools::gputools::cuda::GetBinaryDir(bool)' defined but not used [-Wunused-function]
 static string GetBinaryDir(bool strip_exe) {
               ^
INFO: From Compiling tensorflow/stream_executor/cuda/cuda_dnn.cc:
tensorflow/stream_executor/cuda/cuda_dnn.cc: In constructor 'perftools::gputools::cuda::ScopedFilterDescriptor::ScopedFilterDescriptor(perftools::gputools::cuda::CUDAExecutor*, const perftools::gputools::dnn::FilterDescriptor&, const perftools::gputools::dnn::BatchDescriptor&, cudnnDataType_t)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:404:25: warning: variable 'format' set but not used [-Wunused-but-set-variable]
     cudnnTensorFormat_t format;
                         ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'cudnnStatus_t perftools::gputools::cuda::dynload::DynLoadShim__cudnnSetConvolutionNdDescriptor::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...) [with Args = {cudnnConvolutionStruct*, int, int*, int*, int*, cudnnConvolutionMode_t, cudnnDataType_t}]':
tensorflow/stream_executor/cuda/cuda_dnn.cc:485:43:   required from here
tensorflow/stream_executor/cuda/cuda_dnn.cc:159:38: error: too many arguments to function
       cudnnStatus_t retval = DynLoad()(args...);                     \
                                      ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:185:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
   __macro(cudnnSetConvolutionNdDescriptor)                \
   ^
tensorflow/stream_executor/cuda/cuda_dnn.cc:192:1: note: in expansion of macro 'CUDNN_DNN_ROUTINE_EACH'
 CUDNN_DNN_ROUTINE_EACH(PERFTOOLS_GPUTOOLS_CUDNN_WRAP)
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoNormalize(perftools::gputools::Stream*, const perftools::gputools::dnn::NormalizeDescriptor&, const perftools::gputools::DeviceMemory<float>&, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1423:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoElementwiseOperate(perftools::gputools::Stream*, perftools::gputools::dnn::ElementwiseOperation, tensorflow::gtl::ArraySlice<perftools::gputools::dnn::BatchDescriptor>, tensorflow::gtl::ArraySlice<const perftools::gputools::DeviceMemory<float>*>, const perftools::gputools::dnn::BatchDescriptor&, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1484:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoXYPad(perftools::gputools::Stream*, const perftools::gputools::dnn::BatchDescriptor&, const perftools::gputools::DeviceMemory<float>&, tensorflow::int64, tensorflow::int64, tensorflow::int64, tensorflow::int64, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1492:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: In member function 'virtual bool perftools::gputools::cuda::CudnnSupport::DoXYSlice(perftools::gputools::Stream*, const perftools::gputools::dnn::BatchDescriptor&, const perftools::gputools::DeviceMemory<float>&, tensorflow::int64, tensorflow::int64, tensorflow::int64, tensorflow::int64, perftools::gputools::DeviceMemory<float>*)':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1501:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
tensorflow/stream_executor/cuda/cuda_dnn.cc: At global scope:
tensorflow/stream_executor/cuda/cuda_dnn.cc:114:26: warning: 'tensorflow::thread::ThreadPool* perftools::gputools::cuda::dynload::GetCudaThreadpool()' defined but not used [-Wunused-function]
 static port::ThreadPool* GetCudaThreadpool() {
                          ^
ERROR: /mnt/tmp/tensorflow/tensorflow/stream_executor/BUILD:5:1: C++ compilation of rule '//tensorflow/stream_executor:stream_executor' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/de8e797a514efeb5b22d3fa9bb2a44c2/tensorflow && \
  exec env - \
    PATH=/home/ubuntu/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-py3-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.d -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/de8e797a514efeb5b22d3fa9bb2a44c2/tensorflow && \
  exec env - \
    PATH=/home/ubuntu/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-py3-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -iquote external/jpeg_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive -iquote external/png_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/png_archive -iquote external/re2 -iquote bazel-out/local_linux-py3-opt/genfiles/external/re2 -iquote external/eigen_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive -isystem google/protobuf/src -isystem bazel-out/local_linux-py3-opt/genfiles/google/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/jpeg_archive/jpeg-9a -isystem bazel-out/local_linux-py3-opt/genfiles/external/jpeg_archive/jpeg-9a -isystem external/png_archive/libpng-1.2.53 -isystem bazel-out/local_linux-py3-opt/genfiles/external/png_archive/libpng-1.2.53 -isystem external/re2 -isystem bazel-out/local_linux-py3-opt/genfiles/external/re2 -isystem third_party/eigen3 -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/eigen3 -isystem external/eigen_archive/eigen-eigen-50812b426b7c -isystem bazel-out/local_linux-py3-opt/genfiles/external/eigen_archive/eigen-eigen-50812b426b7c -isystem third_party/gpus/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda -isystem third_party/gpus/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/third_party/gpus/cuda/include -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fno-canonical-system-headers '-frandom-seed=bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o' -MD -MF bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.d -c tensorflow/stream_executor/cuda/cuda_dnn.cc -o bazel-out/local_linux-py3-opt/bin/tensorflow/stream_executor/_objs/stream_executor/tensorflow/stream_executor/cuda/cuda_dnn.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 6.773s, Critical Path: 6.41s
```

Thanks
"
2199,Tensorflow GRU error when trying to concatenate activations to outputs,"I have been trying to grab the activations of the GRU cell layer in the following manner

```
def __call__(self, inputs, state, scope=None):
    """"""Gated recurrent unit (GRU) with nunits cells.""""""
    with vs.variable_scope(scope or type(self).__name__):  # ""GRUCell""
      with vs.variable_scope(""Gates""):  # Reset gate and update gate.
        # We start with bias of 1.0 to not reset and not update.
        r, u = array_ops.split(1, 2, linear([inputs, state], 2 * self._num_units, True, 1.0))
        r, u = sigmoid(r), sigmoid(u)
      with vs.variable_scope(""Candidate""):
        c = tanh(linear([inputs, r * state], self._num_units, True))
      new_h = u * state + (1 - u) * c

      # store the activations, everything else is the same
      h_activations = array_ops.concat(1, [new_h,r,u,c])
    return h_activations, h_activations
```

Later I try to grab the activations in the following way

`cell = ClusterableGRUCell(num_units=hidden_neurons)
initial_state = tf.zeros([batch_size, cell.state_size])
outputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)
outputs_activations = tf.concat(0, outputs_activations)
outputs, rs, us, cs = tf.split(1, 4, outputs_activations)
activations = tf.concat(1, [rs, us, cs])`

However this fails in the `rnn()` step with the following error

Traceback (most recent call last):
  File ""myautoencoder.py"", line 29, in <module>
    outputs_activations, outputs_activations = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)
  File ""xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 141, in rnn
    zero_output, state, call_cell)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 265, in _rnn_step
    _maybe_copy_some_through)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1157, in cond
    res_f = context_f.BuildCondBranch(fn2)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1073, in BuildCondBranch
    r = fn()
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 247, in _maybe_copy_some_through
    lambda: _copy_some_through(new_output, new_state))
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1157, in cond
    res_f = context_f.BuildCondBranch(fn2)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py"", line 1073, in BuildCondBranch
    r = fn()
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 247, in <lambda>
    lambda: _copy_some_through(new_output, new_state))
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 236, in _copy_some_through
    return (math_ops.select(copy_cond, zero_output, new_output),
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 1396, in select
    name=name)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2156, in create_op
    set_shapes_for_outputs(ret)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1612, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py"", line 1411, in _SelectShape
    t_e_shape = t_shape.merge_with(e_shape)
  File ""/xxx/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/tensor_shape.py"", line 554, in merge_with
    (self, other))
ValueError: Shapes (32, 33) and (32, 132) are not compatible

My batch size is 32 and number of neurons is 33, 132 = 33*4 which makes sense. What I dont understand is why is there a lingering (32,33) tensor? Thank you.
"
2198,Allow manual changing a restored TensorFlowEstimator,"For TensorFlowEstimator models, currently there's no way to change learning rate once the model is saved and restored.

Referencing: /tensorflow/tensorflow/contrib/learn/python/learn/estimators/base.py
"
2197,Importing the fast protobuf installed from pip package results in segmentation fault,"### Operating System:

Ubuntu 14.04 amd64
### Installed version of CUDA and cuDNN:

no version of CUDA installed
### If installed from binary pip package, provide:

https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl
Version 0.8.0
### Steps to reproduce

try `import tensorflow`, it works as expected.
Then install the suggested package for fast protobuf: https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b2.post2-cp34-none-linux_x86_64.whl

Now trying `import tensorflow` results in a segmentation fault.
"
2196,Tensorflow GRU cell error when fetching activations with variable sequence length,"I want to run a GRU cell on some time series data to cluster them according to the activations in the last layer. I made one small change to the GRU cell implementation

`def **call**(self, inputs, state, scope=None):
""""""Gated recurrent unit (GRU) with nunits cells.""""""
with vs.variable_scope(scope or type(self).**name**):  # ""GRUCell""
  with vs.variable_scope(""Gates""):  # Reset gate and update gate.
    # We start with bias of 1.0 to not reset and not update.
    r, u = array_ops.split(1, 2, linear([inputs, state], 2 \* self._num_units, True, 1.0))
    r, u = sigmoid(r), sigmoid(u)
  with vs.variable_scope(""Candidate""):
    c = tanh(linear([inputs, r \* state], self._num_units, True))
  new_h = u \* state + (1 - u) \* c

  # store the activations, everything else is the same
  self.activations = [r,u,c]
return new_h, new_h`

After this I concatenate the activations in the following manner before I return them in the script which calls this GRU cell

`@property
def activations(self):
    return self._activations

@activations.setter
def activations(self, activations_array):
    print ""PRINT THIS""  
    concactivations = tf.concat(concat_dim=0, values=activations_array, name='concat_activations')
    self._activations = tf.reshape(tensor=concactivations, shape=[-1], name='flatten_activations')
 `

I invoke the GRU cell in the following manner

`outputs, state = rnn.rnn(cell=cell, inputs=x, initial_state=initial_state, sequence_length=s)`

Where `s` is an array of batch length with the number of timestamps in each element of the input batch.

And finally I fetch using

`fetched = sess.run(fetches=cell.activations, feed_dict=feed_dict)`

When executing I get the following error

Traceback (most recent call last): File ""xxx.py"", line 162, in fetched = sess.run(fetches=cell.activations, feed_dict=feed_dict) File ""/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 315, in run return self._run(None, fetches, feed_dict) File ""/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 511, in _run feed_dict_string) File ""/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 564, in _do_run target_list) File ""/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 588, in _do_call six.reraise(e_type, e_value, e_traceback) File ""/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 571, in _do_call return fn(*args) File ""/xxx/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 555, in _run_fn

return tf_session.TF_Run(session, feed_dict, fetch_list, target_list) tensorflow.python.pywrap_tensorflow.StatusNotOK: Invalid argument: The tensor returned for RNN/cond_396/ClusterableGRUCell/flatten_activations:0 was not valid.

Can someone give an insight as to how to fetch the activations from a GRU cell at the last step, with passing variable length sequences? Thanks.
"
2194,how to convert std::vector<float> to tensor in c++,
2193,tf.py_func returned object doesn't supported in tf.train.shuffle_batch,"```
def unpackbits(arr):
    return np.unpackbits(arr).astype(np.int64)

labels, = tf.py_func(unpackbits, [labels], [tf.int64])
```

I use py_func for reading input data. Returned object from tf.py_func(...) has get_shape()._dim equal to None. Its raise exception when passing to tf.train.shuffle_batch
"
2192,"Row distances Tensorflow for models like K-Means, SOM and RBFN","I am wondering if Tensorflow has some op for fast calculation of distances. For example like Matlab's [pdist](http://nl.mathworks.com/help/stats/pdist.html) or [pdist2](http://nl.mathworks.com/help/stats/pdist2.html)

Or do you know of any way to optimize this piece of code?

``` python
with tf.name_scope(""Hidden_layer"") as scope:
  centroids = tf.Variable(tf.random_uniform([num_centr,D],dtype=tf.float32),name='centroids')
  var = tf.Variable(tf.truncated_normal([num_centr],mean=225,stddev=1,dtype=tf.float32))
  exp_list = []

  for i in xrange(num_centr):
        exp_list.append(tf.exp((-1*tf.reduce_sum(tf.square(tf.sub(x,centroids[i,:])),1))/(2*var[i])))
        phi = tf.transpose(tf.pack(exp_list))
```

For now my code works and the results beautifully surpass my expectations. My prof deemed this impossible. With Tensorflow, I was able to prototype within two hours. 
For future, I am curious if TensorFlow can improve this for-loop for calculating distances with a function like matlab's pdist()

Thanks for your help!

Rob
"
2190,failed to enqueue CUDNN_STATUS_MAPPING_ERROR,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 15

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

The following were installed

cuda-repo-ubuntu1504_7.5-18_amd64.deb
cudnn-7.0-linux-x64-v4.0-prod.tgz

```
jeffw@chill:~/src/tensorflow/tensorflow/examples/skflow$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root     34 Apr 30 16:31 /usr/local/cuda/lib64/libcudnn.so -> /usr/local/cudnn/lib64/libcudnn.so
lrwxrwxrwx 1 root root     36 Apr 30 16:32 /usr/local/cuda/lib64/libcudnn.so.4 -> /usr/local/cudnn/lib64/libcudnn.so.4
lrwxrwxrwx 1 root root     40 Apr 30 16:32 /usr/local/cuda/lib64/libcudnn.so.4.0.7 -> /usr/local/cudnn/lib64/libcudnn.so.4.0.7
lrwxrwxrwx 1 root root     40 Apr 30 16:31 /usr/local/cuda/lib64/libcudnn_static.a -> /usr/local/cudnn/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

the above command fails, with `AttributeError: 'module' object has no attribute 'version'`however, the version is 0.8.0
- pip freeze:
  tensorflow==0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce
1. start with  the example `tensorflow/tensorflow/examples/skflow/text_classification_cnn.py`
2. use GTX 980 
3. modify example steps fairly large number (e.g. 2400)
4. modify **EMBEDDING_SIZE** to 16
5. modify **N_FILTERS** to 16
6. modify **WINDOW_SIZE** to 32.
7. run until crash 
### What have you tried?
1. various step numbers.  The default (100) does not crash, various other step crash eventually with larger number crashing sooner.  Perhaps this is a memory leak or other general failure to maintain datastructures. 
2. various values for the above variables some combinations work some don't.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

Can be found in [this gist](https://gist.github.com/waTeim/f243b94ff52f0bc1d9584991cd3cad8d)
"
2189,No scalar data was found,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: CentOS 7

Installed version of CUDA and cuDNN:  Using CPU version
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed. 
   https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   >>> print(tensorflow.**version**)
   0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce

1.In you TensorFlow program:
 # Set logs writer into folder /tmp/tensorflow_logs
summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)
2.
python ./lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/tensorflow_logs 
3.Open http://[address]:6006/ into your web browser
### What have you tried?
1. Tried to enable debug and see if anything is wrong.
   python ./lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/tensorflow_logs --debug
2. Looked if there files in exist in /tmp/tensorflow_logs 
3. Checked their sizes
4. Everything looked correct
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
When I open web page:
Web application itself works, but this error is shown:
""No scalar data was found.""
"
2188,Missing support for Ubuntu 16.04 with Python 3.5,"### Environment info

Operating System:
Ubuntu 16.04 Xenial Xerus

Installed version of CUDA and cuDNN: 
none (using CPU version)

If installed from binary pip package, provide:

https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl
### What have you tried?

I tried to install

```
https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl
```

but it failed with the following message:

```
tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.
```

This is probably because the python3 version in Xenial is Python 3.5.x

I managed to install tensorflow using instead:

```
linux/cpu/tensorflow-0.7.0-py3-none-linux_x86_64.whl
```

but there's not anything like that neither for the protobuf nor for the tensorflow-0.8.0 packages.
"
2186,TensorBoard build failure on Jenkins,"TensorBoard build has failed for quite a while in Jenkins now. The failure seems to have to do with gulp config, for example:

> [16:46:28] Using gulpfile /workspace/tensorflow/tensorboard/gulpfile.js
> [16:46:28] Task 'compile.all' is not in your gulpfile
> [16:46:28] Please check the documentation for proper gulpfile formatting

For full build log, see example: http://ci.tensorflow.org/job/tensorflow-master-tensorboard/161/console
### Environment info

Operating System: Linux + Docker

Installed version of CUDA and cuDNN: Not applicable.
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide: N/A

To reproduce locally:
`tensorflow/tools/ci_build/ci_build.sh TENSORBOARD tensorflow/tools/ci_build/builds/tensorboard.sh
`
"
2185,How to compute confusion matrix from CNN example?,"In the tutorial 'Convolutional Neural Networks', tensorflow just computed the accuracy, but I wanted to compute the confusion matrix. I have trained the model, saved the variable and don't want to do it again. I am able to load the variables. Then three approaches crossed my mind: give new input to cifar10.inference; replace with new operations; directly output the prediction result. But I failed all of them, because: the inference does not take placeholder, no such operation could be implemented; multi-threaded code stopped me.

I posted a more detailed way of my trial in [stackoverflow](http://stackoverflow.com/questions/36960457/tensorflow-evaluate-with-confusion-matrix). Please help. And even will be more grateful if solutions are given more than one. 

Thanks in advance.
"
2180,SparseTensor   transpose,"Is  there a way to transpose a SparseTensor without converting it to dense?
"
2177,tf.argmax Should Not Permit Backprop Through It,"Hey Tensorflow,

Lately, I have been using the argmax function but I have always placed a tf.stop_gradient before using it. However, when I remove the stop_gradient, tensorflow still works fine. 

Maybe I'm misunderstanding something, but argmax is not a differentiable function. How is backprop still working when you remove it? Shouldn't an error be thrown when you pass argmax without any stop_gradient?

If it is possible to differentiate argmax, then I would greatly appreciate any resource showing how this is done. Thanks TF!
"
2176,setting allocated memory of gpu,"By using options like `gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)` , it gives  the process this fraction of **free** gpu's memory. it means when you want to give a process an exact value of memory you must change the fractions due to running sequence of processes. For example if you want to run 2 process simultaneously with half of the memory you have to run the first one with 0.5 fraction and the second one with 1.0 fraction.
Is there any way to allocate an exact  size for each process (for example 2gb)?
"
2175,"Can't run TensorFlow on CPU, defaults to GPU","### Environment info

Operating System: 

```
Ubuntu 16.04
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r--   1 root root    322936 Eyl 19  2015 libcudadevrt.a
lrwxrwxrwx   1 root root        16 Mar 30 15:25 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx   1 root root        19 Mar 30 15:25 libcudart.so.7.5 -> libcudart.so.7.5.18
-rw-r--r--   1 root root    383336 Eyl 19  2015 libcudart.so.7.5.18
-rw-r--r--   1 root root    720192 Eyl 19  2015 libcudart_static.a
lrwxrwxrwx   1 root root        12 Nis 14 18:53 libcuda.so -> libcuda.so.1
lrwxrwxrwx   1 root root        17 Nis 14 18:53 libcuda.so.1 -> libcuda.so.361.42
-rw-r--r--   1 root root  16881416 Mar 23 02:42 libcuda.so.361.42
-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so
-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so.4
-rwxr-xr-x   1 root root  61453024 Nis 30 11:36 libcudnn.so.4.0.7
-rwxr-xr-x   1 root root  59823168 Nis 30 11:12 libcudnn.so.5
-rwxr-xr-x   1 root root  59823168 Nis 30 11:12 libcudnn.so.5.0.4
-rw-r--r--   1 root root  62025862 Nis 30 11:36 libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
   Installed using the command 

```
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
```
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0
```

If installed from sources, provide the commit hash:
### Steps to reproduce

```
>>> import tensorflow as tf
>>> 
>>> with tf.Session() as sess:
...     with tf.device('/cpu:0'):
...             matrix1 = tf.constant([[3., 3.]])
...             matrix2 = tf.constant([[2.],[2.]])
...             product = tf.matmul(matrix1, matrix2)
...             result = sess.run(product)
...             print(result)
... 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.291
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.48GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
[[ 12.]]
```
"
2174,Unable to find a suitable algorithm for doing forward convolution,"### Environment info

Operating System: Ubuntu 14.04 LTS
Graphics card: GeForce GTX 750 Ti/PCIe/SSE2

Installed version of CUDA and cuDNN: CUDA 7.5, cuNN v5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): see cudalib.txt

If installed from sources, provide the commit hash:
I installed from source -> git clone --recurse-submodules https://github.com/tensorflow/tensorflow
Pulled it today: 04/29/2016
### Steps to reproduce
1.  From the tutorial section I copied the partial differential equations example exactly
2. I started a tensorflow environment: ""source ~/tensorflow/bin/activate""
3. I ran example from the command line: ""python pde_example.py""
4. I get this segmentation fault when I run it on a system using GPUs (details of this are in pde_error.txt) in the loop at:  step.run({eps: 0.03, damping: 0.04})
   NOTE: I've run this example on a system not using GPUs and it works splendidly.  Also, I've run other scripts just fine using using the GPUs, it's just this one that doesn't seem to be working.
### What have you tried?
1. I've tried running ./configure with the system default values and putting in them myself, then rebuilding.
2. Running other scripts using the GPU work fine.
3. Running this script using a CPU on other machines works fine.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

[pde_error.txt](https://github.com/tensorflow/tensorflow/files/243444/pde_error.txt)
[cudalib.txt](https://github.com/tensorflow/tensorflow/files/243447/cudalib.txt)
"
2171,TF-Learn early stopping monitor doesn't disable dropout,"I'm training a custom CNN model that uses dropout for regularization. I'm using tf-learn r0.8 (skflow)  ValidationMonitor as follows.

``` Python
from tensorflow.contrib.learn.python.learn import monitors
m = monitors.ValidationMonitor(X_validate, Y_validate, 0, print_steps=100, 
    early_stopping_rounds=500)
regressor.fit(X_train, Y_train, monitor=monitor)
```

I noticed that after early stopping is triggered, the validation error I calculate on the final model is significantly different from what the ValidationMonitor reports as the best validation error. To narrow the problem I set `early_stopping_rounds = 1` but even then the difference between the ""best"" validation error and the one calculated on the final model was too large. Large enough to make the early stopping feature unusable for my case.

I tracked the issue down to the fact that ValidationMonitor calculates the validation error without disabling dropouts, which is why the results were so different from what you'd get from calling model.predict(). I implemented a fix here. 

I'd appreciate it if one of the maintainers reviews it and confirms that it's the right fix. If so, I'll create a pull request. 

https://github.com/waleedka/tensorflow/commit/ee095f83ffedf2e2cefff126b76191ab691d5097
"
2170,Index into tensor,"I'd like to have a `tf.index` function that works like this:

``` python
import tensorflow as tf

weights = tf.constant([[0, 0], [1, 1], [2, 2]])
indices = tf.constant([0, 2, 1, 2])

indexed = tf.index(weights, indices)
#indexed = [[0, 0], [2, 2], [1, 1], [2, 2]]
```

That is, `indexed[i] = weights[indices[i]]`. Of the existing functions, `tf.slice` comes close, but it doesn't seem to allow for multiple slices. A less efficient way of doing this is to use `tf.one_hot` and a matrix multiply, but this should be straightforward to do.
"
2168,Feature Request:  API for the Julia Language.,
2167,Dropout in skflow has a problem when save & restore the model because the graph collection is not loaded.," Operating System: 
ubunutu 14.04 LTS

 Installed version of CUDA and cuDNN: 
CUDA 7.5.18 / cuDNN 7.0(v4)
NVIDIA-SMI 352.39     Driver Version: 352.39
GeForce GTX TITAN X

 I installed tensorflow with next command line. And that is a link of tensorflow Github, 'Linux GPU, python 2' whl file.

sudo pip install --upgrade http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.8.0-cp27-none-linux_x86_64.whl

 TensorFlow version: 0.8.0
(outputs of python -c ""import tensorflow; print(tensorflow.**version**)"" )

---
### Steps to reproduce
1. Save and Restore a tfmodel modifying [tensorflow/tensorflow/examples/skflow/mnist.py] 
   ![image](https://cloud.githubusercontent.com/assets/4004593/14917371/a93e2882-0e59-11e6-8ff0-8154c0cd318f.png)
2. And see the accuracy is not deterministic but stochastic after restored.
   ![image](https://cloud.githubusercontent.com/assets/4004593/14917401/d8e70342-0e59-11e6-86f6-aa778b66ede2.png)
### What have you tried?

When I try to predict MNIST data after save() and restore() the 'tfmodel' with skflow function, the dropout shows stochastic outcomes. And when I remove the dropout, there is no stochasticity. 

---

I guess when the model has been restored, the collections of a graph about DROPOUT are may not properly loaded. So some codes on
![image](https://cloud.githubusercontent.com/assets/4004593/14917208/dcbbfcc6-0e58-11e6-8b4f-8188a99fda8a.png)
     feed_dict = {prob: 1.0 for prob in dropouts}
the function of ""_predict()"" at [tensorflow/contrib/learn/python/learn/estimators/base.py] may dont' work. 

If you run following code after restore tfmodel, then you will see that there is no 'droputs' key.
     print (classifier._graph.get_all_collection_keys())
"
2166,Restored variables have unknown shape?,"When restoring a saved graph, the variables all have `<unknown>` shape. I have searched a lot, and haven't seen this problem anywhere else. It is also stated in the docs that the size of variables is indeed saved, so it is confusing to me why it is not restored?

Relevant part of the code:

```
saved = tf.train.import_meta_graph('save.ckpt.meta')
saved.restore(sess, 'save.ckpt')
for x in tf.trainable_variables():
  print x.get_shape()
```

Output:

```
<unknown>
<unknown>
<unknown>
<unknown>
... etc
```
"
2165,Convolution for 1D,"Dear community,

Do you know of any implementation for 1 dimensional convolution in TensorFlow?

For the moment, I circumvented this by using conv2d with a filter of 5x1. This works good and I was able to surpass state-of-the-art performances on some datasets. However, this short-term 'hack' doesn't allow for longer strides. With a 5x1 filter, I cannot make strides of 2. Tensorflow will raise error that 'stride must be less than or equal to filter size'

Do you know of any 1D implementation for tf.nn.conv2d?
If not, how can I recommend this to the developing team of TensorFlow? A 1D conv would make TensorFlow useful to the world of time-series classification, which is a plus for TensorFlow as well

Thank you in advance!

Rob
"
2164,Inception needs retraining (Was: Op is deprecated in Image Recognition tutorial),"When I'm running the Inception examples from the Image Recognition tutorial (https://tensorflow.org/tutorials/image_recognition/), I'm getting a lot of warnings in the following form:

W tensorflow/core/kernels/batch_norm_op.cc:36] Op is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().

I recently upgraded Tensorflow to version 0.8.0, and I'm working on Mac OS X 10.10.2. While this isn't harming the performance, I'm wondering if there's a fix or an update that I'm missing.
"
2163,Floating point exception when computing gradients,"Hi tensorflow developer team! 

I just wanted to first let you know that I really appreciate all the work you are putting into this amazing open source system. It has been a terrific system for me so far. However, I have come into a roadblock when using the tf.gather function in gradients.

I am using
### Environment info

Operating System: CentOS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA version 7.5
cuDNN version 7.0 (64 bit)
tensorflow/0.8.0-gpu version
### Steps to reproduce

I obtain a floating point exception when I run the following code

`A_ph = tf.placeholder(tf.float32, shape=(None, 2))`
`ind_ph = tf.placeholder(tf.int32, shape=(None, 2))`

`gather = tf.gather(A_ph, ind_ph)`
`redsum = tf.reduce_sum(gather, 1)`
`l2 = tf.reduce_sum(redsum)`

`A = np.array([[0,0],[0,0],[0,0]])`
`ind = np.zeros((0,2))`

`grad_op = tf.gradients(l2, A_ph)`

`out = sess.run(grad_op, feed_dict={A_ph:A, ind_ph:ind})`
### What have you tried?

If you replace ind with a non-empty array, such as [[0,1]] it works fine. 

I suspect that the output of redsum = [], which makes l2 disconnected from A_ph for the given ind. Fed forward to computing l2, I get the correct value of 0.0 (since there is nothing to be summed). However, for backpropagation of gradients, I think the output of redsum=[] chokes the algorithm, and causes it to evaluate some illegal operation using an empty tensor, instead of just backpropagating 0.0. 

Are there any solutions to this problem currently? In my use of this computation, I won't know ahead of time whether or not the intermediate computations produce [](empty tensor), but I also want to be able to get the correct gradients when this happens. Thank you so much for your consideration! 
"
2161,make data_feeder for sparse matrices,"### Environment info

Operating System: OS X El Capitan 10.11.4

Installed version of CUDA and cuDNN: N/A
1. pip install: https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
2. version: 0.8.0
### Steps to reproduce

Run this code with svm light data:

``` python
from sklearn import datasets, metrics
from tensorflow.contrib import skflow

train_data, train_labels = datasets.load_svmlight_file(TRAIN)

classifier = skflow.TensorFlowDNNClassifier(hidden_units=[10, 20, 10], n_classes=2)
classifier.fit(train_data, train_labels)
score = metrics.accuracy_score(train_labels, classifier.predict(train_data))
```
### What have you tried?

I think the classifier doesn't handle the CSR matrix matrix produced by the loader
### Logs or other output that would be helpful

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-27-01a3edd34655> in <module>()
      1 classifier = skflow.TensorFlowDNNClassifier(hidden_units=[10, 20, 10], n_classes=2)
----> 2 classifier.fit(train_data, train_labels)
      3 score = metrics.accuracy_score(train_labels, classifier.predict(train_data))

/Users/nicolas/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in fit(self, X, y, monitor, logdir)
    216         self._data_feeder = setup_train_data_feeder(X, y,
    217                                                     self.n_classes,
--> 218                                                     self.batch_size)
    219 
    220         if monitor is None:

/Users/nicolas/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc in setup_train_data_feeder(X, y, n_classes, batch_size)
     97                              ""streaming learning to work."")
     98         data_feeder_cls = StreamingDataFeeder
---> 99     return data_feeder_cls(X, y, n_classes, batch_size)
    100 
    101 

/Users/nicolas/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc in __init__(self, X, y, n_classes, batch_size, random_state)
    189         x_dtype = np.int64 if X.dtype == np.int64 else np.float32
    190         y_dtype = np.int64 if n_classes > 1 else np.float32
--> 191         self.X = check_array(X, dtype=x_dtype)
    192         self.y = (None if y is None else check_array(y, dtype=y_dtype))
    193         self.n_classes = n_classes

/Users/nicolas/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.pyc in check_array(array, dtype)
    159         Original array or converted.
    160     """"""
--> 161     array = np.array(array, dtype=dtype, order=None, copy=False)
    162     return array
    163 

ValueError: setting an array element with a sequence.
```
"
2159,unchanging minibatches from skflow DataFeeder for unsupervised tasks,"I'm pretty sure there's a bug [here](https://github.com/tensorflow/tensorflow/blob/ec0552f1bc0e7c6ec6bd84ea1c3c92ff046d6d3c/tensorflow/contrib/learn/python/learn/io/data_feeder.py#L272) in the DataFeeder class for skflow (tf.contrib.learn).  If there are no labels, then the mapping of input placeholders to inputs is returned without updating the minibatch offsets.  [The code for updating offsets and shuffling](https://github.com/tensorflow/tensorflow/blob/ec0552f1bc0e7c6ec6bd84ea1c3c92ff046d6d3c/tensorflow/contrib/learn/python/learn/io/data_feeder.py#L289) won't be reached.
"
2158,Division by num_steps when calculating language model perplexity,"Hi all,

I think I found something on the language modeling example that might be a bug: 

As pointed in the tutorial, the perplexity can obtained from the averaged cross entropy. The code show [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py#L260) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py#L263) the division of the costs by `num_iters`.

Nevertheless, the seq2seq.sequence_loss_by_example is averaging losses across timesteps [(here)](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L871). As no value is passed to the parameter `average_across_timesteps` I'm assuming it is using the default value `True`.

After that, the model is further averaging the losses by the batch size [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py#L133).

If I'm not wrong (and please correct me if I am), there is no need to divide the costs by `num_iters` as we already averaged over timesteps and the batch. There is no reference in the tutorial regarding why one should do that. If it is something that we should do it would be nice to include an instruction in the tutorial or a comment in the code. In addition, the Seq2seq tutorial is also showing the perplexity calculation and does not have any further division by the number of steps representing the length of the sequence, but by the number of steps between two verbosity points. 

Also, imo, if the intention is averaging, the `step` parameter [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py#L249)  is the one that should be added to `iters`.
"
2155,How to query the amount of memory needed for a model?,
2154,Import error: TypeError: <method 'max' of 'numpy.ndarray' objects> is not a Python function,"Having a import error on Ubuntu 14.04 LTS 64 bit with python 2.7, and trying to import tensorflow 0.8.0

In [1]: import tensorflow
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally

TypeError                                 Traceback (most recent call last)
<ipython-input-1-a649b509054f> in <module>()
----> 1 import tensorflow

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/**init**.py in <module>()
     21 from **future** import print_function
     22 
---> 23 from tensorflow.python import *

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/python/**init**.py in <module>()
     60 from tensorflow.core.util.event_pb2 import *
     61 # Import things out of contrib
---> 62 import tensorflow.contrib as contrib
     63 
     64 # Framework

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/contrib/**init**.py in <module>()
     24 from tensorflow.contrib import framework
     25 from tensorflow.contrib import layers
---> 26 from tensorflow.contrib import learn
     27 from tensorflow.contrib import linear_optimizer
     28 from tensorflow.contrib import lookup

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/**init**.py in <module>()
     18 from **future** import print_function
     19 
---> 20 from tensorflow.contrib.learn.python.learn import *

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/**init**.py in <module>()
     18 from **future** import print_function
     19 
---> 20 from tensorflow.contrib.learn.python.learn import *

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/**init**.py in <module>()
     20 import numpy as np
     21 
---> 22 from tensorflow.contrib.learn.python.learn.io import *
     23 from tensorflow.contrib.learn.python.learn.estimators import *
     24 from tensorflow.contrib.learn.python.learn import ops

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/**init**.py in <module>()
     18 
     19 from tensorflow.contrib.learn.python.learn.io.pandas_io import *
---> 20 from tensorflow.contrib.learn.python.learn.io.dask_io import *

/home/weiliu/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/io/dask_io.py in <module>()
     21 
     22 try:
---> 23     import dask.dataframe as dd
     24     allowed_classes = (dd.Series, dd.DataFrame)
     25     HAS_DASK = True

/home/weiliu/.local/lib/python2.7/site-packages/dask/dataframe/**init**.py in <module>()
----> 1 from .core import (DataFrame, Series, Index, _Frame, map_partitions,
      2                    repartition)
      3 from .io import (read_csv, from_array, from_bcolz, from_array, from_bcolz,
      4                  from_pandas, from_dask_array, from_castra, read_hdf,
      5                  from_imperative)

/home/weiliu/.local/lib/python2.7/site-packages/dask/dataframe/core.py in <module>()
   1232 
   1233 
-> 1234 class Index(Series):
   1235 
   1236     _partition_type = pd.Index

/home/weiliu/.local/lib/python2.7/site-packages/dask/dataframe/core.py in Index()
   1264         return self.drop_duplicates().count()
   1265 
-> 1266     @derived_from(pd.Index)
   1267     def max(self):
   1268         # it doesn't support axis and skipna kwds

/home/weiliu/.local/lib/python2.7/site-packages/dask/utils.pyc in wrapper(method)
    524 
    525             method_args = getargspec(method).args
--> 526             original_args = getargspec(original_method).args
    527 
    528             not_supported = [m for m in original_args if m not in method_args]

/home/weiliu/.local/lib/python2.7/site-packages/dask/compatibility.pyc in getargspec(func)
    188             return _getargspec(func.__init__)
    189         else:
--> 190             return _getargspec(func)
    191 
    192 def skip(func):

/home/weiliu/.local/lib/python2.7/site-packages/dask/compatibility.pyc in _getargspec(func)
     54 
     55     def _getargspec(func):
---> 56         return inspect.getargspec(func)
     57 
     58     if sys.version_info[1] <= 7:

/usr/lib/python2.7/inspect.pyc in getargspec(func)
    814         func = func.im_func
    815     if not isfunction(func):
--> 816         raise TypeError('{!r} is not a Python function'.format(func))
    817     args, varargs, varkw = getargs(func.func_code)
    818     return ArgSpec(args, varargs, varkw, func.func_defaults)

TypeError: <method 'max' of 'numpy.ndarray' objects> is not a Python function

========== end of import error =========================

It looks like a upstream (dask package) error, because I can reproduce it by running: 

In [2]: import dask.dataframe

---

TypeError                                 Traceback (most recent call last)
<ipython-input-2-8010029fbbe3> in <module>()
----> 1 import dask.dataframe

/home/weiliu/.local/lib/python2.7/site-packages/dask/dataframe/**init**.py in <module>()
----> 1 from .core import (DataFrame, Series, Index, _Frame, map_partitions,
      2                    repartition)
      3 from .io import (read_csv, from_array, from_bcolz, from_array, from_bcolz,
      4                  from_pandas, from_dask_array, from_castra, read_hdf,
      5                  from_imperative)

/home/weiliu/.local/lib/python2.7/site-packages/dask/dataframe/core.py in <module>()
   1232 
   1233 
-> 1234 class Index(Series):
   1235 
   1236     _partition_type = pd.Index

/home/weiliu/.local/lib/python2.7/site-packages/dask/dataframe/core.py in Index()
   1264         return self.drop_duplicates().count()
   1265 
-> 1266     @derived_from(pd.Index)
   1267     def max(self):
   1268         # it doesn't support axis and skipna kwds

/home/weiliu/.local/lib/python2.7/site-packages/dask/utils.pyc in wrapper(method)
    524 
    525             method_args = getargspec(method).args
--> 526             original_args = getargspec(original_method).args
    527 
    528             not_supported = [m for m in original_args if m not in method_args]

/home/weiliu/.local/lib/python2.7/site-packages/dask/compatibility.pyc in getargspec(func)
    188             return _getargspec(func.__init__)
    189         else:
--> 190             return _getargspec(func)
    191 
    192 def skip(func):

/home/weiliu/.local/lib/python2.7/site-packages/dask/compatibility.pyc in _getargspec(func)
     54 
     55     def _getargspec(func):
---> 56         return inspect.getargspec(func)
     57 
     58     if sys.version_info[1] <= 7:

/usr/lib/python2.7/inspect.pyc in getargspec(func)
    814         func = func.im_func
    815     if not isfunction(func):
--> 816         raise TypeError('{!r} is not a Python function'.format(func))
    817     args, varargs, varkw = getargs(func.func_code)
    818     return ArgSpec(args, varargs, varkw, func.func_defaults)

TypeError: <method 'max' of 'numpy.ndarray' objects> is not a Python function
======== end of import dask ==========
The dask verison is 0.8.2 from 'pip freeze'. 

I can provide more information if needed. 
"
2153,Optimisations do not seem to be active during building,"When building Tensorflow with Bazel master following the instructions in #2109 , I get many warnings like:

```
In file included from third_party/gpus/cuda/include/host_config.h:161:0,
                 from third_party/gpus/cuda/include/cuda_runtime.h:76,
                 from <command-line>:0:
/usr/include/features.h:328:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]
 #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)
    ^
```

In fact, running a simple network on TF built by me and linked against Cudnn 5  is10% slower than the wheel built by Google against the default Cudnn.
"
2150,rnn_cell.py improvements,"## Motivation

Current implementation of [rnn_cell.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py) does not support custom initialization on a gate and input-to-hidden/hidden-to-hidden level (like setting forgetgate bias to 0 while leaving updategate bias at 1, etc.). Further when debugging the gates in TensorBoard, the matrix is represented as one large matrix, which makes it difficult to see whats happening inside a specific matrix (e.g. hidden-to-hidden) of a specific gate (e.g. forgetgate).

In recurrent neural networks (RNNs) GRU and LSTM uses various gates with separate weights, for both hidden-to-hidden and input-to-hidden, to computing steps in a recurrent sequence.
To optimize computational speed these gates, and their separate weights, are often stacked and computed simultaneous at every step.
In TensorFlows rnn_cell.py the [GRUCell](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L123) and [BasicLSTMCell](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L153) are implemented using [linear](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L677) to handle weigths and computation hereof.
However, the implementation of _linear_ does not initialize separate matrices for each gate, but initializes the gates, and their input-to-hidden/hidden-to-hidden matrices, as one big matrix for [weights](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L712) and [bias](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L719).
## Proposal

Implementing separate initialization of gates, and their input-to-hidden/hidden-to-hidden matrices, and concatenating these gates. This allows custom initializatio, TensorBoard information on hid_in/hid_hid/bias for every gate and still retains the advantage of weights in a large matrix.
## Implementation

With minimal rewriting of the current structure in [rnn_cell.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py) I implemented a [lasagne-gate](https://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#lasagne.layers.Gate) like structure, made a new _linear_ function and made some minor changes to _GRUCell_.
All of these changes should, with minor modifications, work for _BasicLSTM_ as well.

Do notice that code below is for my own purpose, it is not rigorously tested yet.

First, the gate to hold initialization for every weight matrix/bias in a gate (notice it also handles LSTM's by having W_cell)

``` python
class Gate(object):
  """"""Gate to handle to handle initialization""""""  

  def __init__(self, W_in=init_ops.random_normal_initializer(stddev=0.1),
               W_hid=init_ops.random_normal_initializer(stddev=0.1),
               W_cell=init_ops.random_normal_initializer(stddev=0.1),
               b=init_ops.constant_initializer(0.),
               activation=None):
    self.W_in = W_in
    self.W_hid = W_hid
    # Don't store a cell weight vector when cell is None
    if W_cell is not None:
        self.W_cell = W_cell
    if b is not None:
      self.b = b
    # For the activation, if None is supplied, use identity
    if activation is None:
        self.activation = control_flow_ops.identity
    else:
        self.activation = activation
```

A modified GRU cell to handle weigths (took only minimal modification to **init** and **call**)

``` python
class GRUCell(rnn_cell.RNNCell):
  """"""Gated Recurrent Unit cell (cf. http://arxiv.org/abs/1406.1078).""""""

  def __init__(self, num_units, input_size=None,
               resetgate=Gate(W_cell=None, activation=sigmoid),
               updategate=Gate(W_cell=None, activation=sigmoid),
               candidategate=Gate(W_cell=None, activation=tanh)):
    self._num_units = num_units
    self._input_size = num_units if input_size is None else input_size
    self._resetgate = resetgate
    self._updategate = updategate
    self._candidategate = candidategate

  @property
  def input_size(self):
    return self._input_size

  @property
  def output_size(self):
    return self._num_units

  @property
  def state_size(self):
    return self._num_units

  def __call__(self, inputs, state, scope=None):
    """"""Gated recurrent unit (GRU) with nunits cells.""""""
    with vs.variable_scope(scope or type(self).__name__):  # ""GRUCell""
      with vs.variable_scope(""Gates""):  # Reset gate and update gate.
        # We start with bias of 1.0 to not reset and not update.
        r, u = array_ops.split(1, 2, Modified_linear([inputs, state],
          [(self._num_units, ""Reset"", self._resetgate),
           (self._num_units, ""Update"", self._updategate)]))
        r, u = self._resetgate.activation(r), self._updategate.activation(u)
      with vs.variable_scope(""Candidate""):
        c = Modified_linear([inputs, r * state],
          (self._num_units, ""Candidate"", self._candidategate))
        c = self._candidategate.activation(c)
      new_h = u * state + (1 - u) * c
    return new_h, new_h
```

I found _linear_ required the largest amount of rewriting, however I have tried to keep the original structure and functionality intact.

``` python
def Modified_linear(args, output, scope=None):
  """"""Modified linear takes args and output.
     Args is same as in linear, but output is a tuple consisting of:
     output_size, name of gate, gate object (with all initializations)
  """"""
  if args is None or (isinstance(args, (list, tuple)) and not args):
    raise ValueError(""`args` must be specified"")
  if not isinstance(args, (list, tuple)):
    args = [args]
  if not isinstance(output, list):
    output = [output]
  shapes = [a.get_shape().as_list() for a in args]
  for shape in shapes:
    if len(shape) != 2:
      raise ValueError(""Linear is expecting 2D arguments: %s"" % str(shapes))
    if not shape[1]:
      raise ValueError(""Linear expects shape[1] of arguments: %s"" % str(shapes))

  matrices = []
  biases = []
  with vs.variable_scope(scope or ""Linear""):
    for output_size, name, gate in output: # loops over every gate
      with vs.variable_scope(name):
        W_in = vs.get_variable(""W_in"", [args[0].get_shape()[1], output_size],
          initializer=gate.W_in)
        W_hid = vs.get_variable(""W_hid"", [args[1].get_shape()[1], output_size],
          initializer=gate.W_hid)
        if hasattr(gate, 'b'):
          b = vs.get_variable(""Bias"", [output_size],
            initializer=gate.b)
          biases.append(b)
        if hasattr(gate, ""W_cell""):
          pass
          # do some LSTM stuff ...
        else:
          matrix = array_ops.concat(0, [W_in, W_hid]) # concats all matrices
        matrices.append(matrix)

  total_matrix = array_ops.concat(1, matrices) # concats across gates
  res = math_ops.matmul(array_ops.concat(1, args), total_matrix) # computes the results

  if biases is not []:
    total_bias = array_ops.concat(0, biases) # concats across gates biases
    if total_matrix.get_shape()[1] != total_bias.get_shape()[0]:
      raise ValueError('Must have same output dimensions for W and b')
    res += total_bias
  return res
```
## Questions
- Would this be of interest for a PR to _rnn_cell.py_? (given further development of code and _BasicLSTMCell_ implementation)
- General comments/thoughts would be much appreciated
"
2146,CTC GPU support,"Very happy to see CTC in  #tensorflow! #32
My question is:
Is someone working on CTC GPU implement internal? Or is it 'contribution welcomed'?
Baidu has a CTC GPU implement:

https://github.com/baidu-research/warp-ctc
"
2145,there is log about cannot enable peer access from device ordinal 0 to device ordinal 2,"I tried to install tensorflow with gpu ,and then run demo code,hello word,it will report

I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 1

is it a issue?
How can it prevent it ?
"
2144,Tensorboard tensor representation when a Op (or a node) has multiple output tensors,"I'm using the op 'tf.train.shuffle_batch,' has two output tensors, feature and label.

When I visualize it on tensorboard, thickness of edge(tensor) looks weird.
The label tensor, to loss node, has thickness of the feature tensor.

It seems like current tensorboard visualizes thickness using first output tensor of the op for all out edges.
Is it possible? multiple output tensors has their own shape?

![screenshot from 2016-04-28 23 26 19](https://cloud.githubusercontent.com/assets/15023894/14878512/a15912fc-0d56-11e6-991a-f7445ff36823.png)
"
2143,Error like 'batchtospace_op_gpu.cu.pic.o' was not created,"For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:Ubuntu 16.04

Installed version of CUDA and cuDNN: 
CUDA toolkit 7.5
cudnn 7.0(3.0)

it seems NVIDIA have not provided the .run file for Ubuntu16.04, so I installed the 15.04 version.

installed from sources, encounter the errors like below:
ERROR: /home/huangzh/Github/tensorflow/tensorflow/core/kernels/BUILD:1190:1: output 'tensorflow/core/kernels/_objs/batchtospace_op_gpu/tensorflow/core/kernnel/batchtospace_op_gpu.cu.pic.o' was not created.
ERROR: /home/huangzh/Github/tensorflow/tensorflow/core/kernels/BUILD:1190:1: not all outputs were created.
"
2141,tf.learn: Loading pre-trained variables into Estimators,"Add support for loading pre-trained variables into Estimators.

Simple API can be:

```
est = learn.TensorFlowEstimator(..)
est.restore_variables(path_to_checkpoints, {'embeddings': 'embed/matrix'})
```

where `restore_variables` takes path and map of new variable name to variable name in the checkpoint.

Ref https://github.com/tensorflow/skflow/issues/160
"
2140,Feature request: support symbolic links for tensorboard,"It would be nice if one could use symbolic links to organize groups of training files. Tensorboard does not search over symbolic links for event files because the following line 178 of python/summary/event_multiplexer.py:

``` python
subdirs = [
        subdir
        for (subdir, files) in io_wrapper.ListRecursively(path)
        if list(filter(event_accumulator.IsTensorFlowEventsFile, files))
]
```

does not walk across symbolic links. This would be easy to fix by adding a symlink option to ListRecursively().

Current difficulties: 
1) Over time, the number of distinct training runs in a directory can grow to over 10, at which point tensorboard becomes slow and too information rich. Reorganizing a subset with symbolic links would be quite nice.

2) Sometimes it would be nice to compare a small subset of training runs that exist in different directories. Copying these files with `cp -r` is quite slow.
"
2139,conditional rbm ,"Will conditional rbm ever be available in tensor flow library?

[Here](http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf) is the original paper
"
2138,embedding_attention_seq2seq fails / embedding_rnn_seq2seq works,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: Cuda 7.0 and CUDNN 6.5 v4

So when I use a simple Embedding RNN Sequence to Sequence Model like this

```
# choose RNN/GRU/LSTM cell
        with tf.variable_scope(""train_test"", reuse=True):
            self.cell = rnn_cell.LSTMCell(self.memory_dim)

        # embedding model
        with tf.variable_scope(""train_test""):
            self.dec_outputs, self.dec_memory = seq2seq.embedding_rnn_seq2seq(\
                            self.enc_inp, self.dec_inp, self.cell, \
                            self.vocab_size, self.vocab_size, self.seq_length)
        with tf.variable_scope(""train_test"", reuse = True):
            self.dec_outputs_tst, _ = seq2seq.embedding_rnn_seq2seq(\
                            self.enc_inp, self.dec_inp, self.cell, \
                            self.vocab_size, self.vocab_size, self.seq_length, feed_previous=True)
```

The above implementation works perfectly, but when I just change the model from simple embedding seq2seq to Embedding Attention Seq2Seq, like this,

```

        # choose RNN/GRU/LSTM cell
        with tf.variable_scope(""train_test"", reuse=True):
            self.cell = rnn_cell.LSTMCell(self.memory_dim)

        with tf.variable_scope(""train_test""):
            self.dec_outputs, self.dec_memory = seq2seq.embedding_attention_seq2seq(\
                            self.enc_inp, self.dec_inp, self.cell, \
                            self.vocab_size, self.vocab_size, self.seq_length)
        with tf.variable_scope(""train_test"", reuse = True):
            self.dec_outputs_tst, _ = seq2seq.embedding_attention_seq2seq(\
                            self.enc_inp, self.dec_inp, self.cell, \
                            self.vocab_size, self.vocab_size, self.seq_length, feed_previous=True)

```

I get segmentation fault, with absolutely no information. My memory does not run out, neither my CPU, as I tried this with 

```
batch_size =1 
see.memory_dim = 1
```

and still got the same segmentation fault. 

I get the same error, and the above configuration can certainly not eat my RAM.

This is a potential bug, if I am not getting something worng. The LSTM and GRU cell just takes the size of the hidden layer as parameter, which is a scaler. 

THE BUG REPORT 

The Debug result

```
(gdb) run train_script_lstm_attn.py 
Starting program: /lusr/bin/python train_script_lstm_attn.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
[New Thread 0x7fffd7a25700 (LWP 45650)]
[New Thread 0x7fffd7224700 (LWP 45651)]
[New Thread 0x7fffd4a23700 (LWP 45652)]
[New Thread 0x7fffd2222700 (LWP 45653)]
[New Thread 0x7fffcfa21700 (LWP 45654)]
[New Thread 0x7fffcd220700 (LWP 45655)]
[New Thread 0x7fffcaa1f700 (LWP 45656)]
[Thread 0x7fffcaa1f700 (LWP 45656) exited]
[Thread 0x7fffcfa21700 (LWP 45654) exited]
[Thread 0x7fffd7a25700 (LWP 45650) exited]
[Thread 0x7fffd2222700 (LWP 45653) exited]
[Thread 0x7fffd7224700 (LWP 45651) exited]
[Thread 0x7fffcd220700 (LWP 45655) exited]
[Thread 0x7fffd4a23700 (LWP 45652) exited]
[New Thread 0x7fffcaa1f700 (LWP 45661)]
[New Thread 0x7fffcd220700 (LWP 46103)]
[New Thread 0x7fffcfa21700 (LWP 46104)]
[New Thread 0x7fffd2222700 (LWP 46105)]
[New Thread 0x7ffed22bf700 (LWP 46106)]
[New Thread 0x7ffed1abe700 (LWP 46107)]
[New Thread 0x7ffed12bd700 (LWP 46108)]
[New Thread 0x7ffed0abc700 (LWP 46109)]
[New Thread 0x7ffec3fff700 (LWP 46110)]
[New Thread 0x7ffec37fe700 (LWP 46111)]
[New Thread 0x7ffec2ffd700 (LWP 46112)]
[New Thread 0x7ffeb77ff700 (LWP 46114)]
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN Black
major: 3 minor: 5 memoryClockRate (GHz) 0.98
pciBusID 0000:05:00.0
Total memory: 6.00GiB
Free memory: 5.91GiB
[New Thread 0x7ffeb6ffe700 (LWP 46115)]
[New Thread 0x7ffeb67fd700 (LWP 46116)]
[New Thread 0x7ffea2bff700 (LWP 46117)]
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX TITAN Black
major: 3 minor: 5 memoryClockRate (GHz) 0.98
pciBusID 0000:42:00.0
Total memory: 6.00GiB
Free memory: 5.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:05:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN Black, pci bus id: 0000:42:00.0)
[New Thread 0x7ffea23fe700 (LWP 46118)]
[New Thread 0x7ffea1bfd700 (LWP 46119)]
[New Thread 0x7ffea13fc700 (LWP 46120)]
[New Thread 0x7ffea0bfb700 (LWP 46121)]
[New Thread 0x7ffe8bfff700 (LWP 46122)]
[New Thread 0x7ffe8b7fe700 (LWP 46123)]
[New Thread 0x7ffe8affd700 (LWP 46124)]
[New Thread 0x7ffe8a7fc700 (LWP 46125)]
[New Thread 0x7ffe89ffb700 (LWP 46126)]
[New Thread 0x7ffe897fa700 (LWP 46127)]
[New Thread 0x7ffe88ff9700 (LWP 46128)]
[New Thread 0x7ffe7bfff700 (LWP 46129)]
[New Thread 0x7ffe3d23c700 (LWP 46167)]

Program received signal SIGSEGV, Segmentation fault.
__memmove_ssse3_back () at ../sysdeps/x86_64/multiarch/memcpy-ssse3-back.S:2143
2143    ../sysdeps/x86_64/multiarch/memcpy-ssse3-back.S: No such file or directory.
```

The Backtrace is attached below

```
(gdb) backtrace
#0  __memmove_ssse3_back () at ../sysdeps/x86_64/multiarch/memcpy-ssse3-back.S:2143
#1  0x00007fffedd56ae1 in tensorflow::Tensor::FromProto(tensorflow::Allocator*, tensorflow::TensorProto const&) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#2  0x00007fffedc4577f in tensorflow::ThreadPoolDevice::MakeTensorFromProto(tensorflow::TensorProto const&, tensorflow::AllocatorAttributes, tensorflow::Tensor*) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007fffecea4f76 in tensorflow::ConstantOp::ConstantOp(tensorflow::OpKernelConstruction*) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#4  0x00007fffecea50f2 in tensorflow::{lambda(tensorflow::OpKernelConstruction*)#1}::_FUN ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#5  0x00007fffedd408bd in tensorflow::CreateOpKernel(tensorflow::DeviceType, tensorflow::DeviceBase*, tensorflow::Allocator*, tensorflow::FunctionLibraryRuntime*, tensorflow::NodeDef const&, int, tensorflow::OpKernel**) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#6  0x00007fffedc1caf4 in tensorflow::CreateNonCachedKernel(tensorflow::Device*, tensorflow::FunctionLibraryRuntime*, tensorflow::NodeDef const&, int, tensorflow::OpKernel**) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#7  0x00007fffedc10c97 in std::_Function_handler<tensorflow::Status (tensorflow::NodeDef const&, tensorflow::OpKernel**), tensorflow::DoConstantFolding(tensorflow::ConstantFoldingOptions const&, tensorflow::Device*, tensorflow::Graph*)::{lambda(tensorflow::NodeDef const&, tensorflow::OpKernel**)#2}>::_M_invoke(std::_Any_data const&, tensorflow::NodeDef const&, tensorflow::OpKernel**) () from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#8  0x00007fffedc287de in tensorflow::(anonymous namespace)::ExecutorImpl::Initialize() ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#9  0x00007fffedc292b3 in tensorflow::NewLocalExecutor(tensorflow::LocalExecutorParams const&, tensorflow::Graph const*, tensorflow::Executor**) () from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#10 0x00007fffedc1608d in tensorflow::DoConstantFolding(tensorflow::ConstantFoldingOptions const&, tensorflow::Device*, tensorflow::Graph*) () from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#11 0x00007fffedc36dda in tensorflow::GraphOptimizer::Optimize(tensorflow::FunctionLibraryRuntime*, tensorflow::Device*, tensorflow::Graph**) () from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#12 0x00007fffeda06d9d in tensorflow::DirectSession::GetOrCreateExecutors(tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::gtl::ArraySlice<std::string>, tensorflow::DirectSession::ExecutorsAndKeys**, tensorflow::DirectSession::RunStateArgs*) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#13 0x00007fffeda07e6a in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std---Type <return> to continue, or q <return> to quit---
::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#14 0x00007fffeda0a992 in tensorflow::DirectSession::Run(std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) () from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#15 0x00007fffedc0b7c7 in TF_Run_Helper(TF_Session*, char const*, TF_Buffer const*, char const**, TF_Tensor**, int, char const**, TF_Tensor**, int, char const**, int, TF_Buffer*, TF_Status*) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#16 0x00007fffedc0bc11 in TF_Run ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#17 0x00007fffece8dff5 in tensorflow::TF_Run_wrapper_helper(TF_Session*, char const*, TF_Buffer const*, tensorflow::gtl::InlinedVector<std::pair<char const*, tagPyArrayObject*>, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) () from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#18 0x00007fffece8e661 in tensorflow::TF_Run_wrapper(TF_Session*, TF_Buffer const*, tensorflow::gtl::InlinedVector<std::pair<char const*, tagPyArrayObject*>, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#19 0x00007fffece7a4d7 in _wrap_TF_Run ()
   from /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#20 0x000000000049968d in call_function (oparg=<optimized out>, pp_stack=0x7fffffffdb20) at ../Python/ceval.c:4020
#21 PyEval_EvalFrameEx (f=f@entry=
    Frame 0xe341a40, for file /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py, line 628, in _run_fn (session=<SwigPyObject at remote 0x7fffb3547b70>, feed_dict={}, fetch_list=[], target_list=['init'], options=None, run_metadata=<TF_Buffer(this=<SwigPyObject at remote 0x7ffe3d2864e0>) at remote 0x7ffe496ff990>), 
    throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#22 0x00000000004a1c9a in PyEval_EvalCodeEx (closure=<optimized out>, defcount=<optimized out>, defs=0x0, 
    kwcount=<optimized out>, kws=<optimized out>, argcount=238295616, args=<optimized out>, locals=0x0, 
    globals=<optimized out>, co=<optimized out>) at ../Python/ceval.c:3252
#23 function_call.15337 (func=<optimized out>, arg=<optimized out>, kw=<optimized out>) at ../Objects/funcobject.c:526
#24 0x0000000000505f96 in PyObject_Call (func=<function at remote 0x7ffe3d39d938>, arg=<optimized out>, kw=<optimized out>)
    at ../Objects/abstract.c:2529
#25 0x000000000049b07a in ext_do_call (nk=<optimized out>, na=<optimized out>, flags=<optimized out>, 
    pp_stack=0x7fffffffdd60, func=<function at remote 0x7ffe3d39d938>) at ../Python/ceval.c:4333
---Type <return> to continue, or q <return> to quit---
#26 PyEval_EvalFrameEx (
    f=f@entry=Frame 0xe341820, for file /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py, line 644, in _do_call (self=<InteractiveSession(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <Ne...(truncated), throwflag=throwflag@entry=0) at ../Python/ceval.c:2705
#27 0x00000000004a090c in PyEval_EvalCodeEx (co=0x7fffc3e25330, globals=<optimized out>, locals=<optimized out>, 
    args=<optimized out>, argcount=<optimized out>, kws=<optimized out>, kwcount=0, defs=0x0, defcount=0, closure=0x0)
    at ../Python/ceval.c:3252
#28 0x000000000049ab45 in fast_function (nk=0, na=8, n=<optimized out>, pp_stack=0x7fffffffdf50, 
    func=<function at remote 0x7fffc3e28de8>) at ../Python/ceval.c:4116
#29 call_function (oparg=<optimized out>, pp_stack=0x7fffffffdf50) at ../Python/ceval.c:4041
#30 PyEval_EvalFrameEx (
    f=f@entry=Frame 0xe3415e0, for file /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py, line 637, in _do_run (self=<InteractiveSession(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <Neu...(truncated), throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#31 0x00000000004a090c in PyEval_EvalCodeEx (co=0x7fffc3e25230, globals=<optimized out>, locals=<optimized out>, 
    args=<optimized out>, argcount=<optimized out>, kws=<optimized out>, kwcount=0, defs=0x0, defcount=0, closure=0x0)
    at ../Python/ceval.c:3252
#32 0x000000000049ab45 in fast_function (nk=0, na=7, n=<optimized out>, pp_stack=0x7fffffffe140, 
    func=<function at remote 0x7fffc3e28d70>) at ../Python/ceval.c:4116
#33 call_function (oparg=<optimized out>, pp_stack=0x7fffffffe140) at ../Python/ceval.c:4041
#34 PyEval_EvalFrameEx (
    f=f@entry=Frame 0xe33d060, for file /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py, line 564, in _run (self=<InteractiveSession(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variabl---Type <return> to continue, or q <return> to quit---
es': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <Neural...(truncated), throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#35 0x00000000004a090c in PyEval_EvalCodeEx (co=0x7fffc3e25030, globals=<optimized out>, locals=<optimized out>, 
    args=<optimized out>, argcount=<optimized out>, kws=<optimized out>, kwcount=0, defs=0x0, defcount=0, closure=0x0)
    at ../Python/ceval.c:3252
#36 0x000000000049ab45 in fast_function (nk=0, na=6, n=<optimized out>, pp_stack=0x7fffffffe330, 
    func=<function at remote 0x7fffc3e28cf8>) at ../Python/ceval.c:4116
#37 call_function (oparg=<optimized out>, pp_stack=0x7fffffffe330) at ../Python/ceval.c:4041
#38 PyEval_EvalFrameEx (
    f=f@entry=Frame 0x1648a420, for file /u/harshal/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py, line 340, in run (self=<InteractiveSession(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <Neural...(truncated), throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#39 0x00000000004a090c in PyEval_EvalCodeEx (co=0x7fffc3e22a30, globals=<optimized out>, locals=<optimized out>, 
    args=<optimized out>, argcount=<optimized out>, kws=<optimized out>, kwcount=0, defs=0x7fffc3e24608, defcount=3, 
    closure=0x0) at ../Python/ceval.c:3252
#40 0x0000000000499a52 in fast_function (nk=0, na=2, n=<optimized out>, pp_stack=0x7fffffffe520, 
    func=<function at remote 0x7fffc3e28b18>) at ../Python/ceval.c:4116
#41 call_function (oparg=<optimized out>, pp_stack=0x7fffffffe520) at ../Python/ceval.c:4041
#42 PyEval_EvalFrameEx (
    f=f@entry=Frame 0x7ffe3d280de0, for file /v/filer4b/v20q001/harshal/NLP/Final_Project/deep-summarization/algorithms/lstm.py, line 125, in __start_session (self=<NeuralNet(dec_memory=<Tensor(_consumers=[<Operation(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_t---Type <return> to continue, or q <return> to quit---
ype_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__'...(truncated), throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#43 0x0000000000499ef2 in fast_function (nk=<optimized out>, na=<optimized out>, n=1, pp_stack=0x7fffffffe670, 
    func=<function at remote 0x7fffb4449b18>) at ../Python/ceval.c:4106
#44 call_function (oparg=<optimized out>, pp_stack=0x7fffffffe670) at ../Python/ceval.c:4041
#45 PyEval_EvalFrameEx (
    f=f@entry=Frame 0x7fffb3511050, for file /v/filer4b/v20q001/harshal/NLP/Final_Project/deep-summarization/algorithms/lstm.py, line 62, in form_model_graph (self=<NeuralNet(dec_memory=<Tensor(_consumers=[<Operation(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__'...(truncated), throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#46 0x0000000000499ef2 in fast_function (nk=<optimized out>, na=<optimized out>, n=1, pp_stack=0x7fffffffe7c0, 
    func=<function at remote 0x7fffb4449938>) at ../Python/ceval.c:4106
#47 call_function (oparg=<optimized out>, pp_stack=0x7fffffffe7c0) at ../Python/ceval.c:4041
#48 PyEval_EvalFrameEx (f=f@entry=Frame 0x7ffff7ebf7b0, for file train_script_lstm_attn.py, line 11, in <module> (), 
    throwflag=throwflag@entry=0) at ../Python/ceval.c:2666
#49 0x00000000004a1634 in PyEval_EvalCodeEx (closure=0x0, defcount=0, defs=0x0, kwcount=0, kws=0x0, argcount=0, args=0x0, 
Python Exception <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0x91 in position 1: invalid start byte: 
    locals=<unknown at remote 0x7ffff7ebf928>, globals=, co=0x7ffff7ec9130) at ../Python/ceval.c:3252
Python Exception <class 'UnicodeDecodeError'> 'utf-8' codec can't decode byte 0x91 in position 1: invalid start byte: 
#50 PyEval_EvalCode (locals=<unknown at remote 0x7ffff7ebf928>, globals=, co=0x7ffff7ec9130) at ../Python/ceval.c:667
#51 run_mod.42576 (mod=mod@entry=0x9c1f30, filename=filename@entry=0x7fffffffed54 ""train_script_lstm_attn.py"", 
    globals=globals@entry={'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <NeuralNet(dec_memory=<Tensor(_consumers=[<Operation(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {...}), ('/v/filer4b/v20q001/harshal/NLP/Final_Project/deep-summarization/algorithms/lstm.py', 60, 'form_mo...(truncated), 
---Type <return> to continue, or q <return> to quit---
    locals=locals@entry={'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <NeuralNet(dec_memory=<Tensor(_consumers=[<Operation(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {...}), ('/v/filer4b/v20q001/harshal/NLP/Final_Project/deep-summarization/algorithms/lstm.py', 60, 'form_mo...(truncated), flags=flags@entry=0x7fffffffe970, 
    arena=arena@entry=0x9aa9c0) at ../Python/pythonrun.c:1370
#52 0x000000000044e4a5 in PyRun_FileExFlags (fp=fp@entry=0x976cd0, 
    filename=filename@entry=0x7fffffffed54 ""train_script_lstm_attn.py"", start=start@entry=257, 
    globals=globals@entry={'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <NeuralNet(dec_memory=<Tensor(_consumers=[<Operation(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {...}), ('/v/filer4b/v20q001/harshal/NLP/Final_Project/deep-summarization/algorithms/lstm.py', 60, 'form_mo...(truncated), 
    locals=locals@entry={'review_summary_file': 'extracted_data/review_summary.csv', 'gru': <module at remote 0x7fffb442f9b8>, 'out_file': 'result/test_results_lstm_with_attention.csv', '__builtins__': <module at remote 0x7ffff7f90b08>, '__file__': 'train_script_lstm_attn.py', 'lstm_net': <NeuralNet(dec_memory=<Tensor(_consumers=[<Operation(_graph=<Graph(_default_original_op=None, _handle_feeders={}, _collections={'variables': [<Variable(_variable=<Tensor(_consumers=[<Operation(_graph=<...>, _control_inputs=[], _outputs=[<Tensor(_consumers=[], _value_index=0, _shape=<TensorShape(_dims=[<Dimension(_value=130088) at remote 0x7ffea024e310>, <Dimension(_value=200) at remote 0x7ffea024e190>]) at remote 0x7ffea024e290>, _op=<...>, _dtype=<DType(_type_enum=101) at remote 0x7fffc463a810>) at remote 0x7ffea024e3d0>], _control_flow_context=None, _id_value=1022, _original_op=None, _traceback=[('train_script_lstm_attn.py', 11, '<module>', {...}), ('/v/filer4b/v20q001/harshal/NLP/Final_Project/deep-summarization/algorithms/lstm.py', 60, 'form_mo...(truncated), closeit=closeit@entry=1, flags=flags@entry=0x7fffffffe970)
    at ../Python/pythonrun.c:1356
#53 0x000000000044ec9f in PyRun_SimpleFileExFlags (fp=fp@entry=0x976cd0, filename=<optimized out>, 
    filename@entry=0x7fffffffed54 ""train_script_lstm_attn.py"", closeit=closeit@entry=1, flags=flags@entry=0x7fffffffe970)
    at ../Python/pythonrun.c:948
#54 0x000000000044ed9b in PyRun_AnyFileExFlags (fp=fp@entry=0x976cd0, 
---Type <return> to continue, or q <return> to quit---
    filename=filename@entry=0x7fffffffed54 ""train_script_lstm_attn.py"", closeit=closeit@entry=1, 
    flags=flags@entry=0x7fffffffe970) at ../Python/pythonrun.c:752
#55 0x000000000044f904 in Py_Main (argc=<optimized out>, argv=0x7fffffffeb28) at ../Modules/main.c:640
#56 0x00007ffff7818ec5 in __libc_start_main (main=0x44f9c2 <main>, argc=2, argv=0x7fffffffeb28, init=<optimized out>, 
    fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffeb18) at libc-start.c:287
#57 0x0000000000578c4e in _start ()
(gdb) 

```
"
2135,Diagnostic / assessment tools for network,"It would be convenient to have some tools out of the box for assessing networks complexity, computational cost, resources use etc without need for the user to do it 'by hand'. Do you think the following would be possible to implement in a general way?
- getting a command to know how many parameters will be optimized by a tf.train node, and how many floating operations are required
- more generally, getting a command to know how many operations are required to execute a node with sess.run
- getting a set of commands to evaluate memory, cuda cores and bandwith use (both absolute value and proportion of the device) by a node on gpu, and cpu use. A little bit as mentioned here: http://stackoverflow.com/questions/34629613/how-to-profile-tensorflow-networks
"
2134,tf.image.extract_glimpse does not work as expected,"tf.image.extract_glimpse function does not work as expected. In some cases, the extracted glimpses are the same regardless of offset parameters. Please see the below code to reproduce.
### Environment info

Operating System: Ubuntu 14.04 

Installed version of CUDA and cuDNN: CUDA 7.5, cuDNN R4

If installed from sources, provide the commit hash: cf1659d
### Steps to reproduce

Try to run the code

```
import tensorflow as tf
import numpy as np

input_img = np.arange(25).reshape((1,5,5,1))

first_glimpse = tf.image.extract_glimpse(input_img, [3,3], [[1,1]],
                                    centered=False, normalized=False)
second_glimpse = tf.image.extract_glimpse(input_img, [3,3], [[2,1]],
                                    centered=False, normalized=False)

sess = tf.Session()

print first_glimpse.eval(session=sess)[0,:,:,0]
print second_glimpse.eval(session=sess)[0,:,:,0]
```

Results are

```
first_glimpse = [[  0.   1.   2.]
                 [  5.   6.   7.]
                 [ 10.  11.  12.]]
second_glimpse = [[  0.   1.   2.]
                  [  5.   6.   7.]
                  [ 10.  11.  12.]]
```

Is this a bug? Or am I missing something?
"
2133,Both logs of single- and multi-GPU training are same in the CNN tutorial,"This is not about tensorflow source code, but the tutorial page for convolutional neural networks.
In the [tutorial](https://www.tensorflow.org/versions/r0.8/tutorials/deep_cnn/index.html#training-a-model-using-multiple-gpu-cards), the train logs of both single gpu and multiple gpus are exactly same.
I think it should be changed.
"
2131,control_dependencies of ExponentialMovingAverage in cifar10_multi_gpu_train.py,"There are two ExponentialMovingAverage in cifar10_multi_gpu_train.py.  
- For model parameters https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L220  
  Should the `apply` operation of ExponentialMovingAverage be called after the update of parameters? 

``` python
with tf.control_dependencies([apply_gradient_op]):
    train_op = variable_averages.apply(tf.trainable_variables())
```
- For loss
  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py#L105-L106  
  Are these two lines redundant? Loss value won't change within a single run.

P.S. The document of ExponentialMovingAverage (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/moving_averages.py#L172-L177) says

> `````` python
> maintain_averages_op = ema.apply([var0, var1])
>   # Create an op that will update the moving averages after each training
>   # step.  This is what we will use in place of the usual training op.
> with tf.control_dependencies([opt_op]):
>     training_op = tf.group(maintain_averages_op)```
> ``````

If we want to update the moving averages after the training step, should we call `ema.apply` within the context of tf.control_dependencies([opt_op])?
"
2130,coord.request_stop() doesn't stop the threads,"### Environment info

Operating System: Arch Linux

Installed version of CUDA and cuDNN: cuda 7.5 cuDNNv4

If installed from sources, provide the commit hash:
commit cf1659d1c233f8ddbee13fd298464d76e58bdccb
### Steps to reproduce

```
import tensorflow as tf

queue_size = 100
with tf.Graph().as_default():
  sess = tf.Session()
  queue = tf.FIFOQueue(capacity=queue_size, dtypes=tf.int32)
  enqueue_placeholder = tf.placeholder(dtype=tf.int32)
  enqueue_op = queue.enqueue(enqueue_placeholder)
  dequeue_op = queue.dequeue()
  for f in range(queue_size):
    sess.run([enqueue_op], feed_dict={enqueue_placeholder: f})
  queue.close()

  dequeue_op = tf.reshape(dequeue_op, shape=[1])
  queue_batch = tf.train.batch([dequeue_op], batch_size=1, num_threads=1, capacity=64)

  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(sess=sess, coord=coord)

  for i in range(queue_size):
    print(sess.run([queue_batch]))

  coord.request_stop()
  coord.join(threads, stop_grace_period_secs=5)
  sess.close()
```
### What have you tried?

https://www.tensorflow.org/versions/r0.8/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects

According to documentation coord.request_stop() should stop the threads but in this case
we get a deadlock in coord.join().
### Logs or other output that would be helpful

```
...
[array([[97]], dtype=int32)]
[array([[98]], dtype=int32)]
[array([[99]], dtype=int32)]
Traceback (most recent call last):
  File ""test_queue.py"", line 26, in <module>
    sess.close()
  File ""/usr/lib/python3.5/contextlib.py"", line 77, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 3213, in get_controller
    yield default
  File ""test_queue.py"", line 25, in <module>
    coord.join(threads, stop_grace_period_secs=5)
  File ""/usr/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py"", line 289, in join
    "" "".join(stragglers))
RuntimeError: ('Coordinator stopped with threads still running: %s', 'Thread-1')
```

If I put sess.close() before coord.join() the threads are killed but there is still a weird warning which should not exist because I called queue.close() before.

```
...
W tensorflow/core/kernels/queue_base.cc:300] _0_fifo_queue: Skipping cancelled dequeue attempt with queue not closed
```
"
2129,core dump when import tensorflow ,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Centos 7

Installed version of CUDA and cuDNN: cuda 7.5 cuDNNv4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
total 987720
-rw-r--r--. 1 root root  28585480 Aug 16  2015 libcublas_device.a
lrwxrwxrwx. 1 root root        16 Sep  9  2015 libcublas.so -> libcublas.so.7.5
lrwxrwxrwx. 1 root root        19 Sep  9  2015 libcublas.so.7.5 -> libcublas.so.7.5.18
-rwxr-xr-x. 1 root root  23938736 Aug 16  2015 libcublas.so.7.5.18
-rw-r--r--. 1 root root  28220076 Aug 16  2015 libcublas_static.a
-rw-r--r--. 1 root root    322936 Aug 16  2015 libcudadevrt.a
lrwxrwxrwx. 1 root root        16 Sep  9  2015 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx. 1 root root        19 Sep  9  2015 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x. 1 root root    383336 Aug 16  2015 libcudart.so.7.5.18
-rw-r--r--. 1 root root    720192 Aug 16  2015 libcudart_static.a
-rwxr-xr-x. 1 root root  61453024 Apr 27 15:55 libcudnn.so
-rwxr-xr-x. 1 root root  61453024 Apr 27 15:55 libcudnn.so.4
-rwxr-xr-x. 1 root root  61453024 Apr 27 15:55 libcudnn.so.4.0.7
-rw-r--r--. 1 root root  62025862 Apr 27 15:55 libcudnn_static.a
lrwxrwxrwx. 1 root root        15 Sep  9  2015 libcufft.so -> libcufft.so.7.5
lrwxrwxrwx. 1 root root        18 Sep  9  2015 libcufft.so.7.5 -> libcufft.so.7.5.18
-rwxr-xr-x. 1 root root 111231960 Aug 16  2015 libcufft.so.7.5.18
-rw-r--r--. 1 root root 115104400 Aug 16  2015 libcufft_static.a
lrwxrwxrwx. 1 root root        16 Sep  9  2015 libcufftw.so -> libcufftw.so.7.5
lrwxrwxrwx. 1 root root        19 Sep  9  2015 libcufftw.so.7.5 -> libcufftw.so.7.5.18
-rwxr-xr-x. 1 root root    447664 Aug 16  2015 libcufftw.so.7.5.18
-rw-r--r--. 1 root root     42206 Aug 16  2015 libcufftw_static.a
lrwxrwxrwx. 1 root root        17 Sep  9  2015 libcuinj64.so -> libcuinj64.so.7.5
lrwxrwxrwx. 1 root root        20 Sep  9  2015 libcuinj64.so.7.5 -> libcuinj64.so.7.5.18
-rwxr-xr-x. 1 root root   5751400 Aug 16  2015 libcuinj64.so.7.5.18
-rw-r--r--. 1 root root   1649726 Aug 16  2015 libculibos.a
lrwxrwxrwx. 1 root root        16 Sep  9  2015 libcurand.so -> libcurand.so.7.5
lrwxrwxrwx. 1 root root        19 Sep  9  2015 libcurand.so.7.5 -> libcurand.so.7.5.18
-rwxr-xr-x. 1 root root  51765952 Aug 16  2015 libcurand.so.7.5.18
-rw-r--r--. 1 root root  51992564 Aug 16  2015 libcurand_static.a
lrwxrwxrwx. 1 root root        18 Sep  9  2015 libcusolver.so -> libcusolver.so.7.5
lrwxrwxrwx. 1 root root        21 Sep  9  2015 libcusolver.so.7.5 -> libcusolver.so.7.5.18
-rwxr-xr-x. 1 root root  37034328 Aug 16  2015 libcusolver.so.7.5.18
-rw-r--r--. 1 root root  16613348 Aug 16  2015 libcusolver_static.a
lrwxrwxrwx. 1 root root        18 Sep  9  2015 libcusparse.so -> libcusparse.so.7.5
lrwxrwxrwx. 1 root root        21 Sep  9  2015 libcusparse.so.7.5 -> libcusparse.so.7.5.18
-rwxr-xr-x. 1 root root  36816424 Aug 16  2015 libcusparse.so.7.5.18
-rw-r--r--. 1 root root  44445334 Aug 16  2015 libcusparse_static.a
lrwxrwxrwx. 1 root root        14 Sep  9  2015 libnppc.so -> libnppc.so.7.5
lrwxrwxrwx. 1 root root        17 Sep  9  2015 libnppc.so.7.5 -> libnppc.so.7.5.18
-rwxr-xr-x. 1 root root    427168 Aug 16  2015 libnppc.so.7.5.18
-rw-r--r--. 1 root root     20664 Aug 16  2015 libnppc_static.a
lrwxrwxrwx. 1 root root        14 Sep  9  2015 libnppi.so -> libnppi.so.7.5
lrwxrwxrwx. 1 root root        17 Sep  9  2015 libnppi.so.7.5 -> libnppi.so.7.5.18
-rwxr-xr-x. 1 root root  63516808 Aug 16  2015 libnppi.so.7.5.18
-rw-r--r--. 1 root root  90106200 Aug 16  2015 libnppi_static.a
lrwxrwxrwx. 1 root root        14 Sep  9  2015 libnpps.so -> libnpps.so.7.5
lrwxrwxrwx. 1 root root        17 Sep  9  2015 libnpps.so.7.5 -> libnpps.so.7.5.18
-rwxr-xr-x. 1 root root   6047400 Aug 16  2015 libnpps.so.7.5.18
-rw-r--r--. 1 root root   8647292 Aug 16  2015 libnpps_static.a
lrwxrwxrwx. 1 root root        16 Sep  9  2015 libnvblas.so -> libnvblas.so.7.5
lrwxrwxrwx. 1 root root        19 Sep  9  2015 libnvblas.so.7.5 -> libnvblas.so.7.5.18
-rwxr-xr-x. 1 root root    456112 Aug 16  2015 libnvblas.so.7.5.18
lrwxrwxrwx. 1 root root        24 Sep  9  2015 libnvrtc-builtins.so -> libnvrtc-builtins.so.7.5
lrwxrwxrwx. 1 root root        27 Sep  9  2015 libnvrtc-builtins.so.7.5 -> libnvrtc-builtins.so.7.5.18
-rwxr-xr-x. 1 root root  22408512 Aug 16  2015 libnvrtc-builtins.so.7.5.18
lrwxrwxrwx. 1 root root        15 Sep  9  2015 libnvrtc.so -> libnvrtc.so.7.5
lrwxrwxrwx. 1 root root        18 Sep  9  2015 libnvrtc.so.7.5 -> libnvrtc.so.7.5.17
-rwxr-xr-x. 1 root root  18199288 Aug 16  2015 libnvrtc.so.7.5.17
lrwxrwxrwx. 1 root root        18 Sep  9  2015 libnvToolsExt.so -> libnvToolsExt.so.1
lrwxrwxrwx. 1 root root        22 Sep  9  2015 libnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0
-rwxr-xr-x. 1 root root     37936 Aug 16  2015 libnvToolsExt.so.1.0.0
-rw-r--r--. 1 root root     25840 Aug 16  2015 libOpenCL.so
lrwxrwxrwx. 1 root root        12 Sep  9  2015 libOpenCL.so.1 -> libOpenCL.so
drwxr-xr-x. 2 root root      4096 Sep  9  2015 stubs

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce
1. write a python script test.py which only has one line: import tensorflow

2, gdb python

3,  run test.py

4,  core dumped, use bt to get stacktrace
### What have you tried?
1. install from pip
   2, install form source
   3, try cudnn V4, V5
### Logs or other output that would be helpful

stacktrace from gdb

rogram received signal SIGSEGV, Segmentation fault.
0x00007fffd50e0220 in PyArray_API () from /usr/lib64/python2.7/site-packages/numpy/core/multiarray.so
(gdb) bt
#0  0x00007fffd50e0220 in PyArray_API () from /usr/lib64/python2.7/site-packages/numpy/core/multiarray.so
#1  0x00007fffc513f3c4 in initspecfun () from /usr/lib64/python2.7/site-packages/scipy/special/specfun.so
#2  0x00007ffff7b09eb9 in _PyImport_LoadDynamicModule () from /lib64/libpython2.7.so.1.0
#3  0x00007ffff7b07f91 in import_submodule () from /lib64/libpython2.7.so.1.0
#4  0x00007ffff7b0848f in ensure_fromlist () from /lib64/libpython2.7.so.1.0
#5  0x00007ffff7b08cca in PyImport_ImportModuleLevel () from /lib64/libpython2.7.so.1.0
#6  0x00007ffff7aef3bf in builtin___import__ () from /lib64/libpython2.7.so.1.0
#7  0x00007ffff7a5f073 in PyObject_Call () from /lib64/libpython2.7.so.1.0
#8  0x00007ffff7af0fd7 in PyEval_CallObjectWithKeywords () from /lib64/libpython2.7.so.1.0
#9  0x00007ffff7af2aa3 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#10 0x00007ffff7af718d in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#11 0x00007ffff7af7292 in PyEval_EvalCode () from /lib64/libpython2.7.so.1.0
#12 0x00007ffff7b0707c in PyImport_ExecCodeModuleEx () from /lib64/libpython2.7.so.1.0
#13 0x00007ffff7b072f8 in load_source_module () from /lib64/libpython2.7.so.1.0
#14 0x00007ffff7b07f91 in import_submodule () from /lib64/libpython2.7.so.1.0
#15 0x00007ffff7b081dd in load_next () from /lib64/libpython2.7.so.1.0
#16 0x00007ffff7b08bbe in PyImport_ImportModuleLevel () from /lib64/libpython2.7.so.1.0
#17 0x00007ffff7aef3bf in builtin___import__ () from /lib64/libpython2.7.so.1.0
#18 0x00007ffff7a5f073 in PyObject_Call () from /lib64/libpython2.7.so.1.0
#19 0x00007ffff7af0fd7 in PyEval_CallObjectWithKeywords () from /lib64/libpython2.7.so.1.0
#20 0x00007ffff7af2aa3 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#21 0x00007ffff7af718d in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#22 0x00007ffff7af7292 in PyEval_EvalCode () from /lib64/libpython2.7.so.1.0
#23 0x00007ffff7b0707c in PyImport_ExecCodeModuleEx () from /lib64/libpython2.7.so.1.0
#24 0x00007ffff7b072f8 in load_source_module () from /lib64/libpython2.7.so.1.0
#25 0x00007ffff7b0878a in load_package () from /lib64/libpython2.7.so.1.0
#26 0x00007ffff7b07f91 in import_submodule () from /lib64/libpython2.7.so.1.0
#27 0x00007ffff7b081dd in load_next () from /lib64/libpython2.7.so.1.0
#28 0x00007ffff7b08bf8 in PyImport_ImportModuleLevel () from /lib64/libpython2.7.so.1.0
#29 0x00007ffff7aef3bf in builtin___import__ () from /lib64/libpython2.7.so.1.0
#30 0x00007ffff7a5f073 in PyObject_Call () from /lib64/libpython2.7.so.1.0
#31 0x00007ffff7af0fd7 in PyEval_CallObjectWithKeywords () from /lib64/libpython2.7.so.1.0
#32 0x00007ffff7af2aa3 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#33 0x00007ffff7af718d in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#34 0x00007ffff7af7292 in PyEval_EvalCode () from /lib64/libpython2.7.so.1.0
#35 0x00007ffff7b0707c in PyImport_ExecCodeModuleEx () from /lib64/libpython2.7.so.1.0
#36 0x00007ffff7b072f8 in load_source_module () from /lib64/libpython2.7.so.1.0
#37 0x00007ffff7b07f91 in import_submodule () from /lib64/libpython2.7.so.1.0
#38 0x00007ffff7b081dd in load_next () from /lib64/libpython2.7.so.1.0
#39 0x00007ffff7b08bf8 in PyImport_ImportModuleLevel () from /lib64/libpython2.7.so.1.0
"
2128,TensorFlow does not import in ipython when using virtualenv,"I have installed tensorflow and ipython inside of the virtualenv.
When I run ipython and try to import tensorflow by `import tensorflow as tf` I got following stack trace:

```
TypeError                                 Traceback (most recent call last)
<ipython-input-1-41389fad42b5> in <module>()
----> 1 import tensorflow as tf

/Users/janzikes/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()
     21 from __future__ import print_function
     22
---> 23 from tensorflow.python import *

/Users/janzikes/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()
     47
     48 try:
---> 49   from tensorflow.core.framework.graph_pb2 import *
     50 except ImportError:
     51   msg = """"""%s\n\nError importing tensorflow.  Unless you are using bazel,

/Users/janzikes/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py in <module>()
     14
     15
---> 16 from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
     17 from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2
     18 from tensorflow.core.framework import versions_pb2 as tensorflow_dot_core_dot_framework_dot_versions__pb2

/Users/janzikes/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py in <module>()
     14
     15
---> 16 from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
     17 from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
     18 from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2

/Users/janzikes/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py in <module>()
     14
     15
---> 16 from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
     17 from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2
     18

/Users/janzikes/.virtualenvs/research/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py in <module>()
     20   package='tensorflow',
     21   syntax='proto3',
---> 22   serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB/\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\x62\x06proto3')
     23 )
     24 _sym_db.RegisterFileDescriptor(DESCRIPTOR)

TypeError: __init__() got an unexpected keyword argument 'syntax'
```

I was trying to search for previous answers, but only thing that I have found was this [stackoverflow question](http://stackoverflow.com/questions/34270632/tensorflow-and-ipython-on-virtualenv) without any answer.

**Note:**
When I run just python and then run `import tensorflow as tf`, then everything works well, the same for anaconda.
I am on Mac and I have installed `tensorflow=0.8.0`
"
2127,tf.nn.dynamic_rnn fails when batch_size is 0,"### Environment info

Operating System: Ubuntu 15.10

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn_static.a
```

Commit hash: 8d310bfcffcd46418d68dd535fb0fbcfee74b8a0
### Steps to reproduce

Run the following test case:

```
import tensorflow as tf

outputs, state = tf.nn.dynamic_rnn(
  tf.nn.rnn_cell.BasicRNNCell(1),
  tf.zeros((0, 1, 1)),
  dtype=tf.float32)

with tf.Session() as sess:
  initializer = tf.random_uniform_initializer(-0.1, 0.1)
  tf.initialize_all_variables().run()
  print sess.run([state])
```

When TensorFlow is compiled with `-c dbg`, this fails with the following message:

```
python: external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h:124: Eigen::internal::TensorIntDivisor<T, div_gt_one>::TensorIntDivisor(T) [with T = long int; bool div_gt_one = false]: Assertion `divider > 0' failed.
```

Using gdb, we get the following backtrace:

```
(gdb) bt
#0  0x00007ffff7826267 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:55
#1  0x00007ffff7827eca in __GI_abort () at abort.c:89
#2  0x00007ffff781f03d in __assert_fail_base (fmt=0x7ffff7980fe8 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", assertion=assertion@entry=0x7fffeb82f7fe ""divider > 0"",
    file=file@entry=0x7fffeb82f738 ""external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h"", line=line@entry=124,
    function=function@entry=0x7fffeb860080 <Eigen::internal::TensorIntDivisor<int, false>::TensorIntDivisor(int)::__PRETTY_FUNCTION__> ""Eigen::internal::TensorIntDivisor<T, div_gt_one>::TensorIntDivisor(T) [with T = int; bool div_gt_one = false]"") at assert.c:92
#3  0x00007ffff781f0f2 in __GI___assert_fail (assertion=0x7fffeb82f7fe ""divider > 0"", file=0x7fffeb82f738 ""external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h"", line=124,
    function=0x7fffeb860080 <Eigen::internal::TensorIntDivisor<int, false>::TensorIntDivisor(int)::__PRETTY_FUNCTION__> ""Eigen::internal::TensorIntDivisor<T, div_gt_one>::TensorIntDivisor(T) [with T = int; bool div_gt_one = false]"") at assert.c:101
#4  0x00007fffe9173cf5 in Eigen::internal::TensorIntDivisor<int, false>::TensorIntDivisor (this=0x7fff3dff9e40, divider=0)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h:124
#5  0x00007fffe9793fd5 in Eigen::TensorEvaluator<Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> const, Eigen::GpuDevice>::TensorEvaluator (this=0x7fff3dff9f20, op=..., device=...) at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:352
#6  0x00007fffe979370a in Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16>, Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> const> const, Eigen::GpuDevice>::TensorEvaluator (this=0x7fff3dff9f00, op=..., device=...)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:106
#7  0x00007fffe97930b3 in Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16>, Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> const> const, Eigen::GpuDevice, false>::run (expr=..., device=...)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:233
#8  0x00007fffe9792bd2 in Eigen::TensorDevice<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16>, Eigen::GpuDevice>::operator=<Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> > (this=0x7fff3dffa040, other=...) at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35
#9  0x00007fffe9792570 in tensorflow::functor::Split<Eigen::GpuDevice, float>::operator() (this=0x7fff3dffa1e0, d=..., output=..., input=..., slice_indices=..., slice_sizes=...)
    at tensorflow/core/kernels/split_lib_gpu.cu.cc:37
#10 0x00007fffe96be665 in tensorflow::TensorArrayUnpackOp<Eigen::GpuDevice, float>::Compute (this=0xe44040, ctx=0x7fff3dffab20) at tensorflow/core/kernels/tensor_array_ops.cc:753
#11 0x00007fffeaf8e561 in tensorflow::BaseGPUDevice::Compute (this=0x2ba8110, op_kernel=0xe44040, context=0x7fff3dffab20) at tensorflow/core/common_runtime/gpu/gpu_device.cc:388
#12 0x00007fffeb1b22eb in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0xdf4290, tagged_node=..., scheduled_usec=0) at tensorflow/core/common_runtime/executor.cc:1092
#13 0x00007fffeb1bdbeb in std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)>::operator()<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode&, long long&, void> (this=0x7fff200008c0, __object=0xdf4290) at /usr/include/c++/4.9/functional:569
#14 0x00007fffeb1bd03e in std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>::__call<void, 0ul, 1ul, 2ul>(<unknown type in /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so, CU 0xf323471, DIE 0xf3a21e7>, std::_Index_tuple<0ul, 1ul, 2ul>) (this=0x7fff200008c0, __args=<unknown type in /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so, CU 0xf323471, DIE 0xf3a21e7>)
    at /usr/include/c++/4.9/functional:1264
#15 0x00007fffeb1bb69a in std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>::operator()<, void>(void) (this=0x7fff200008c0) at /usr/include/c++/4.9/functional:1323
#16 0x00007fffeb1b98b6 in std::_Function_handler<void(), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)> >::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/4.9/functional:2039
#17 0x00007fffe8e4788c in std::function<void ()>::operator()() const (this=0x7fff3dffadd0) at /usr/include/c++/4.9/functional:2439
#18 0x00007fffeb450454 in tensorflow::thread::ThreadPool::Impl::WorkerLoop (this=0x2bb28f0) at tensorflow/core/lib/core/threadpool.cc:196
#19 0x00007fffeb44fe95 in tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int)::{lambda()#1}::operator()() const ()
    at tensorflow/core/lib/core/threadpool.cc:123
#20 0x00007fffeb45086d in std::_Function_handler<void(), tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&, const string&, int)::<lambda()> >::_M_invoke(const std::_Any_data &) (
    __functor=...) at /usr/include/c++/4.9/functional:2039
#21 0x00007fffe8e4788c in std::function<void ()>::operator()() const (this=0x2bb4c48) at /usr/include/c++/4.9/functional:2439
#22 0x00007fffeb471f5e in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x2bb4c48) at /usr/include/c++/4.9/functional:1700
#23 0x00007fffeb471ea3 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x2bb4c48) at /usr/include/c++/4.9/functional:1688
#24 0x00007fffeb471e20 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x2bb4c30) at /usr/include/c++/4.9/thread:115
#25 0x00007fffdc3bc030 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#26 0x00007ffff7bc26aa in start_thread (arg=0x7fff3dffb700) at pthread_create.c:333
#27 0x00007ffff78f7e9d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109

(gdb) f 10
#10 0x00007fffe96be665 in tensorflow::TensorArrayUnpackOp<Eigen::GpuDevice, float>::Compute (this=0xe44040, ctx=0x7fff3dffab20) at tensorflow/core/kernels/tensor_array_ops.cc:753
753           functor::Split<Device, T>()(ctx->eigen_device<Device>(), tensor_value_i_t,
(gdb) p this->name()
$1 = (const std::string &) @0xdc49e0: {static npos = <optimized out>, _M_dataplus = {<std::allocator<char>> = {<__gnu_cxx::new_allocator<char>> = {<No data fields>}, <No data fields>},
    _M_p = 0x2bee918 ""RNN/TensorArrayUnpack""}}
```
"
2126,Auto device placement for distributed runtime,"In a distributed TF setting, we need to place variables and ops to different devices. This is annoying to manually assign each variable and op, especially when we have GPU resources in our environment.

TF offer a context named `tf.train.replica_device_setter` which place variables to ps devices in round-robin manner, and this is helpful but not enough. @mrry can you shed some light on the auto distributed devices placement problem?
"
2125,"Taking gradient of tf.cond(..., tf.nn.dyamic_rnn(...)) raises exception","### Environment info

Operating System: Ubuntu 15.10

Installed version of CUDA and cuDNN: 

```
-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn_static.a
```

Commit hash: 8d310bfcffcd46418d68dd535fb0fbcfee74b8a0
### Steps to reproduce

Run the following test case:

```
import tensorflow as tf

out = tf.cond(tf.constant(False),
        lambda: tf.nn.dynamic_rnn(tf.nn.rnn_cell.BasicRNNCell(1),
            tf.zeros((1, 1, 1)),
            dtype=tf.float32)[1],
        lambda: tf.zeros((1, 1, 1))
)

tvars = tf.trainable_variables()
grads = tf.gradients(tf.reduce_sum(out), tvars)
```

The above gives the following traceback:

```
Traceback (most recent call last):
  File ""cond_rnn_bug.py"", line 11, in <module>
    grads = tf.gradients(tf.reduce_sum(out), tvars)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 481, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py"", line 254, in _TanhGrad
    return grad * (1 - math_ops.square(y))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 1655, in square
    return _op_def_lib.apply_op(""Square"", x=x, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 694, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2153, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1157, in __init__
    self._control_flow_context.AddOp(self)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1330, in AddOp
    self._AddOpInternal(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1352, in _AddOpInternal
    self.AddValue(x)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 1288, in AddValue
    real_val = grad_ctxt.grad_state.GetRealValue(val)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 662, in GetRealValue
    real_value = self.AddBackPropAccumulatedValue(h_value, value)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 612, in AddBackPropAccumulatedValue
    history_value = _SwitchRefOrTensor(history_value, pred)[branch]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 306, in _SwitchRefOrTensor
    return ref_switch(data, pred, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_control_flow_ops.py"", line 275, in ref_switch
    return _op_def_lib.apply_op(""RefSwitch"", data=data, pred=pred, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 449, in apply_op
    as_ref=input_arg.is_ref).dtype.name
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 565, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.py"", line 162, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.py"", line 336, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
```
### What have you tried?

Running tf.nn.dynamic_rnn outside the lambda works, but my understanding is that the two are not semantically equivalent (although I'm not sure exactly in which ways).

That is, the following works:

```
import tensorflow as tf

rnn_out = tf.nn.dynamic_rnn(tf.nn.rnn_cell.BasicRNNCell(1),
            tf.zeros((1, 1, 1)),
            dtype=tf.float32)[1]
out = tf.cond(tf.constant(False),
        lambda: rnn_out,
        lambda: tf.zeros((1, 1, 1))
)

tvars = tf.trainable_variables()
grads = tf.gradients(tf.reduce_sum(out), tvars)
```
"
2123,Different models for training and testing,"```
# choose RNN/GRU/LSTM cell
        self.cell = rnn_cell.LSTMCell(self.memory_dim)

        # embedding model
        if not self.attention:
            self.dec_outputs, self.dec_memory = seq2seq.embedding_rnn_seq2seq(\
                            self.enc_inp, self.dec_inp, self.cell, \
                            self.vocab_size, self.vocab_size, self.seq_length)
            self.dec_outputs_tst, _ = seq2seq.embedding_rnn_seq2seq(\
                            self.enc_inp, self.dec_inp, self.cell, \
                            self.vocab_size, self.vocab_size, self.seq_length, feed_previous=True)
```

I want to have feed_previous = False for the Training (self.dec_outputs), while feed_previous=True for Testing(self.dec_output_tst). This is the reasonable case, in any seq2seq translation model.

However, when I try to run it I get following error. This is exactly not a bug, but there is absolutely no source of information on this

The error is as follows:

```
File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/seq2seq.py"", line 320, in embedding_rnn_seq2seq
    _, encoder_state = rnn.rnn(encoder_cell, encoder_inputs, dtype=dtype)
  File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 143, in run
    (output, state) = call_cell()
  File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py"", line 136, in <lambda>
    call_cell = lambda: cell(input_, state)
  File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 609, in __call__
    initializer=initializer)
  File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 334, in get_variable
    collections=collections)
  File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 257, in get_variable
    collections=collections, caching_device=caching_device)
  File ""/Users/harshal/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 118, in get_variable
    name, """".join(traceback.format_list(tb))))
ValueError: Variable embedding_rnn_seq2seq/RNN/EmbeddingWrapper/embedding already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:
```

Now I know that I have to use variable scoping, but exactly where is the question. I apologize if I have missed on something
"
2122,"MacOS successful installed, fail to import","### Environment info

Operating System:
OSX EI Capitan, 10.11.4
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
None

If installed from binary pip package, provide:
1. Which pip package you installed.
   tensorflow-0.8.0-py2-none-any.whl for mac
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
     examples python -c ""import tensorflow; print(tensorflow.**version**)"".
   File ""<string>"", line 1
     import tensorflow; print(tensorflow.**version**).
                                                     ^
   SyntaxError: invalid syntax
### What have you tried?
1. pip uninstall, reinstall , however, still failed.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

> > > import tensorflow as tf
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/**init**.py"", line 23, in <module>
> > >     from tensorflow.python import *
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/**init**.py"", line 49, in <module>
> > >     from tensorflow.core.framework.graph_pb2 import *
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py"", line 16, in <module>
> > >     from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
> > >     from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
> > >     from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
> > >   File ""/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 22, in <module>
> > >     serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\""z\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x12\x14\n\x0cunknown_rank\x18\x03 \x01(\x08\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tB/\n\x18org.tensorflow.frameworkB\x11TensorShapeProtosP\x01\x62\x06proto3')
> > > TypeError: __init__() got an unexpected keyword argument 'syntax'
"
2121,TF freezes while running.,"Operating System: CentOS7
Installed version of CUDA and cuDNN: 7.5.18; 4.0.7
Package: Python2 GPU nightly built on Apr 23.

While I'm training an inception-like model on multi GPUs, the training totally freezed after hours.
Then I could see one of the GPUs stay at a 99~100% GPU utilization and a 0% GPU memory utilization. Others stayed at 0%:

```
$ nvidia-smi --query-gpu=temperature.gpu,clocks.current.sm,power.draw,utilization.gpu,utilization.memory,memory.free --format=csv | column -t -s ,
temperature.gpu   clocks.current.sm [MHz]   power.draw [W]   utilization.gpu [%]   utilization.memory [%]   memory.free [MiB]
53                987 MHz                   71.80 W          0 %                   0 %                      38 MiB
30                324 MHz                   14.33 W          0 %                   0 %                      38 MiB
30                324 MHz                   14.81 W          0 %                   0 %                      38 MiB
29                324 MHz                   14.34 W          0 %                   0 %                      38 MiB
60                1151 MHz                  87.82 W          100 %                 0 %                      39 MiB
54                987 MHz                   74.47 W          0 %                   0 %                      39 MiB
28                324 MHz                   14.16 W          0 %                   0 %                      12264 MiB
29                324 MHz                   14.06 W          0 %                   0 %                      12264 MiB
```

This problem happened to me several times, but still hard to reproduce (happen after hours of training).

I attached the process with `gdb -p [proc]` and did stack trace on thread 1 (there are a lot other threads):

```
#0  0x00007fda5a3156d5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0
#1  0x00007fda506ee9ec in std::condition_variable::wait(std::unique_lock<std::mutex>&) () from /lib64/libstdc++.so.6
#2  0x00007fda33a1ed13 in tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, long long) ()
   from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007fda33a28634 in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) () from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#4  0x00007fda33a2a8e2 in tensorflow::DirectSession::Run(std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) ()
   from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#5  0x00007fda33c2ff87 in TF_Run_Helper(TF_Session*, char const*, TF_Buffer const*, char const**, TF_Tensor**, int, char const**, TF_Tensor**, int, char const**, int, TF_Buffer*, TF_Status*) ()
   from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#6  0x00007fda33c303d1 in TF_Run () from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#7  0x00007fda32da7855 in tensorflow::TF_Run_wrapper_helper(TF_Session*, char const*, TF_Buffer const*, tensorflow::gtl::InlinedVector<std::pair<char const*, tagPyArrayObject*>, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#8  0x00007fda32da7ec1 in tensorflow::TF_Run_wrapper(TF_Session*, TF_Buffer const*, tensorflow::gtl::InlinedVector<std::pair<char const*, tagPyArrayObject*>, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::gtl::InlinedVector<char const*, 8> const&, tensorflow::Status*, tensorflow::gtl::InlinedVector<_object*, 8>*, TF_Buffer*) ()
   from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#9  0x00007fda32d93d17 in _wrap_TF_Run () from /home/wyx/.local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#10 0x00007fda5a606aa4 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#11 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#12 0x00007fda5a594f68 in function_call () from /lib64/libpython2.7.so.1.0
#13 0x00007fda5a5700b3 in PyObject_Call () from /lib64/libpython2.7.so.1.0
#14 0x00007fda5a6032f7 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#15 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#16 0x00007fda5a60676f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#17 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#18 0x00007fda5a60676f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#19 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#20 0x00007fda5a60676f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#21 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#22 0x00007fda5a60676f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#23 0x00007fda5a606860 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#24 0x00007fda5a606860 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#25 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#26 0x00007fda5a60676f in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#27 0x00007fda5a6080bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#28 0x00007fda5a6081c2 in PyEval_EvalCode () from /lib64/libpython2.7.so.1.0
#29 0x00007fda5a6215ff in run_mod () from /lib64/libpython2.7.so.1.0
#30 0x00007fda5a6227be in PyRun_FileExFlags () from /lib64/libpython2.7.so.1.0
#31 0x00007fda5a623a49 in PyRun_SimpleFileExFlags () from /lib64/libpython2.7.so.1.0
#32 0x00007fda5a634b9f in Py_Main () from /lib64/libpython2.7.so.1.0
#33 0x00007fda59861b15 in __libc_start_main () from /lib64/libc.so.6
#34 0x0000000000400721 in _start ()
```

The process doesn't respond to Ctrl-C (SIGINT), but can be killed by SIGTERM.
I'm happy to try other methods to gather more information about the problem.
"
2118,Default for tf.nn.conv2d_transpose output_shape,"I am currently working with `tf.nn.conv2d_transpose`. From the past I am used to Caffe deconvolution layer and `tf.nn.conv2d_transpose` is kind of TensorFlow equivalent to it.

My question here is if someone could point me to detailed behaviour/documenatation of `tf.nn.conv2d_transpose`.
Particularly I am confused by `output_shape` parameter. My question is, why there is needed the `output_shape` parameter. Isn't the output shape directly come from the conv2d_transpose operation?
Based on how I understand it from Caffe and from [here](http://cs231n.stanford.edu/slides/winter1516_lecture13.pdf), computed as:

```
h = ((len(value[1]) - 1) * stride_h) + kernel_h - 2 * pad_h
w = ((len(value[2]) - 1) * stride_w) + kernel_w - 2 * pad_w
```

What happens when I set `output_shape` smaller than `h` and `w`? Is the new layer being cropped?

What happens when I set it higher? Is there being created padding with only zeros?
"
2117,Failed to memcpy from device to host: CUDA_ERROR_LAUNCH_TIMEOUT when running CIFAR10 after 113K steps,"I tried to run the cifar10 model provided from TF with GPU support. I was able to successfully install Tensorflow from source (with GPU) and also was able to run the `cifar10_train.py` with utilizing my GPU. However, after step=113330, I encountered the following error which is probably related to async memcpy from device to host. As my graphic card compute capability is 5.2, I thought it should not be due to compute capability conflicts. 
### Similar issues
#1477
#1060

But my error is slightly different
### Environment info

Operating System: Ubuntu 14.04
GPU:  GM200 - GeForce GTX TITAN X (rev a1)
Tensorflow 0.8 (installed from source)
Installed version of CUDA and cuDNN: 
cuda 7.5
cudnn 7.0 (v4)
using Anaconda virtual env
### Logs

```
2016-04-25 22:10:14.937118: step 113330, loss = 0.74 (1276.4 examples/sec; 0.100 sec/batch)

E tensorflow/stream_executor/cuda/cuda_driver.cc:1197] failed to enqueue async memcpy from device to host: CUDA_ERROR_LAUNCH_TIMEOUT; host dst: 0x7fbdd0001680; GPU src: 0xb06c84600; size: 3=0x3
E tensorflow/stream_executor/cuda/cuda_driver.cc:1099] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_TIMEOUT :: No stack trace available
E tensorflow/stream_executor/stream.cc:272] Error recording event in stream: error recording CUDA event on stream 0x1efe980: CUDA_ERROR_LAUNCH_TIMEOUT; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.
E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_TIMEOUT
F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:198] Unexpected Event status: 1
F tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed
E tensorflow/stream_executor/cuda/cuda_driver.cc:1099] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_TIMEOUT :: No stack trace available
E tensorflow/stream_executor/cuda/cuda_driver.cc:1099] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_TIMEOUT :: No stack trace available
E tensorflow/stream_executor/cuda/cuda_driver.cc:1099] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_TIMEOUT :: No stack trace available
I tensorflow/stream_executor/stream.cc:826] stream 0x1efe860 did not wait for stream: 0x1efd340
Aborted (core dumped)

```
"
2115,"Tutorial yields ""tensorboard: Command not found""","GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Mac OS X Yosemite, 10.10.5
MacPorts
python 2.7

Installed version of CUDA and cuDNN:  None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   % sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
   Collecting tensorflow==0.8.0 from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl
   Downloading https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl (19.3MB)
     100% || 19.3MB 53kB/s 
   Requirement already up-to-date: six>=1.10.0 in /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages (from tensorflow==0.8.0)
   Collecting protobuf==3.0.0b2 (from tensorflow==0.8.0)
   Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)
     100% || 327kB 2.0MB/s 
   Collecting wheel (from tensorflow==0.8.0)
   Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)
     100% || 71kB 10.1MB/s 
   Collecting numpy>=1.10.1 (from tensorflow==0.8.0)
   Downloading numpy-1.11.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.9MB)
     100% || 3.9MB 265kB/s 
   Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.8.0)
   Downloading setuptools-20.10.1-py2.py3-none-any.whl (509kB)
     100% || 512kB 1.9MB/s 
   Installing collected packages: setuptools, protobuf, wheel, numpy, tensorflow
   Found existing installation: setuptools 19.2
     Uninstalling setuptools-19.2:
       Successfully uninstalled setuptools-19.2
   Found existing installation: numpy 1.10.4
     DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
     Uninstalling numpy-1.10.4:
       Successfully uninstalled numpy-1.10.4
   Successfully installed numpy-1.11.0 protobuf-3.0.0b2 setuptools-20.10.1 tensorflow-0.8.0 wheel-0.29.0
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   % python -c ""import tensorflow; print(tensorflow.**version**)""
   0.8.0

If installed from sources, provide the commit hash:
### Steps to reproduce

1: Read  the documentation at https://www.tensorflow.org/versions/r0.8/how_tos/summaries_and_tensorboard/index.html:
""Launching TensorBoard

To run TensorBoard, use the command

tensorboard --logdir=path/to/log-directory""

2: Do what it says

```
% tensorboard --logdir=path/to/log-directory
tensorboard: Command not found.
```
### What have you tried?

1: Try rehash

```
% rehash
% tensorboard --logdir=path/to/log-directory
tensorboard: Command not found.
```

2:

```
% locate tensorboard
%
```

3:

```
% which tensorboard
tensorboard: Command not found.

```

4:

Check Google, find StackExchange post ""How to install tensorboard""
http://stackoverflow.com/questions/33634008/how-to-install-tensorboard
Comments suggest that if one installs via pip (as I did), then tensorboard is available on the command-line, but it is not.
Alternate invocation of tensorboard via python is not the same as in the Tutorial but does work....

```
% python /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py --logdir=/tmp/mnist_logs
Starting TensorBoard 16 on port 6006
(You can navigate to http://0.0.0.0:6006)...
```

and everything works.

...Conclusion is that either online Tutorial documentation is incorrect and needs revision, or pip installation does not perform as advertised, or...user error.

Workarounds:

1.

```
% alias tensorboard 'python /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py'
% tensorboard --logdir=/tmp/mnist_logs
```

2.

```
`echo '#! /usr/bin/env python' > tmp.txt ; cat tmp.txt /opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/tensorboard/tensorboard.py > tensorboard ; chmod u+x tensorboard ; rm -f tmp.txt; sudo mv tensorboard /opt/local/bin/
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2111,Two versions of Grid LSTM cells,"I noticed that there are two distinct versions of Grid RNN and LSTM cells in contrib:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/grid_rnn/python/ops/grid_rnn_cell.py
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py

I realize that the RNN interface is still in flux, but I was wondering if these will be harmonized at some point?
"
2109,Undeclared inclusions and missing dependencies in building,"The following commands were run on a Fedora 23 64 bits on Tensorflow master, but I get similar results on the 0.8 branch. 

Using Bazel 0.2.1 on a laptop without graphics card:

```
$ bazel build -c opt --verbose_failures //tensorflow/tools/pip_package:build_pip_package
INFO: Found 1 target...
ERROR: /home/david/.cache/bazel/_bazel_david/47d00ffdd2fc0515138a34f138cebd63/external/re2/BUILD:9:1: undeclared inclusion(s) in rule '@re2//:re2':
this rule is missing dependency declarations for the following files included by 'external/re2/util/rune.cc':
  '/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdarg.h'
  '/lib/gcc/x86_64-redhat-linux/5.3.1/include/stddef.h'
  '/lib/gcc/x86_64-redhat-linux/5.3.1/include/stdint.h'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1.394s, Critical Path: 0.34s
```

On a machine with Cuda 7.5 and cudnn 5 installed, GCC 4.9 built locally (but I get the same results with system's GCC 5.3.1):

With bazel 0.1.1:

```
$ bazel build -c opt --config=cuda --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package
Warning: ignoring LD_PRELOAD in environment.
ERROR: /home/david/gits/tensorflow/WORKSPACE:16:6: First argument of load() is a path, not a label. It should start with a single slash if it is an absolute path..
ERROR: /home/david/gits/tensorflow/WORKSPACE:20:6: First argument of load() is a path, not a label. It should start with a single slash if it is an absolute path..
ERROR: WORKSPACE file could not be parsed.
ERROR: no such package 'external': Package 'external' contains errors.
INFO: Elapsed time: 0.065s
```

With Bazel 0.2.1:

```
bazel build -c opt --config=cuda --spawn_strategy=standalone //tensorflow/tools/pip_package:build_pip_package
Warning: ignoring LD_PRELOAD in environment.
Sending SIGTERM to previous Bazel server (pid=19634)... done.
.....
INFO: Found 1 target...
ERROR: /home/david/.cache/bazel/_bazel_david/47d00ffdd2fc0515138a34f138cebd63/external/re2/BUILD:9:1: undeclared inclusion(s) in rule '@re2//:re2':
this rule is missing dependency declarations for the following files included by 'external/re2/re2/perl_groups.cc':
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stddef.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdarg.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdint.h'
  '/home/david/.local/include/c++/4.9.3/ctime'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/home/david/.local/include/c++/4.9.3/vector'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algobase.h'
  '/home/david/.local/include/c++/4.9.3/bits/functexcept.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/cpp_type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/numeric_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_pair.h'
  '/home/david/.local/include/c++/4.9.3/bits/move.h'
  '/home/david/.local/include/c++/4.9.3/bits/concept_check.h'
  '/home/david/.local/include/c++/4.9.3/type_traits'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_types.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_funcs.h'
  '/home/david/.local/include/c++/4.9.3/debug/debug.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator.h'
  '/home/david/.local/include/c++/4.9.3/bits/ptr_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/predefined_ops.h'
  '/home/david/.local/include/c++/4.9.3/bits/allocator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/new_allocator.h'
  '/home/david/.local/include/c++/4.9.3/new'
  '/home/david/.local/include/c++/4.9.3/exception'
  '/home/david/.local/include/c++/4.9.3/bits/atomic_lockfree_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_ptr.h'
  '/home/david/.local/include/c++/4.9.3/bits/nested_exception.h'
  '/home/david/.local/include/c++/4.9.3/bits/memoryfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_construct.h'
  '/home/david/.local/include/c++/4.9.3/ext/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_uninitialized.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_vector.h'
  '/home/david/.local/include/c++/4.9.3/initializer_list'
  '/home/david/.local/include/c++/4.9.3/bits/stl_bvector.h'
  '/home/david/.local/include/c++/4.9.3/bits/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/bits/hash_bytes.h'
  '/home/david/.local/include/c++/4.9.3/bits/range_access.h'
  '/home/david/.local/include/c++/4.9.3/bits/vector.tcc'
  '/home/david/.local/include/c++/4.9.3/string'
  '/home/david/.local/include/c++/4.9.3/bits/stringfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/char_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/postypes.h'
  '/home/david/.local/include/c++/4.9.3/cwchar'
  '/home/david/.local/include/c++/4.9.3/cstdint'
  '/home/david/.local/include/c++/4.9.3/bits/localefwd.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++locale.h'
  '/home/david/.local/include/c++/4.9.3/clocale'
  '/home/david/.local/include/c++/4.9.3/iosfwd'
  '/home/david/.local/include/c++/4.9.3/cctype'
  '/home/david/.local/include/c++/4.9.3/bits/ostream_insert.h'
  '/home/david/.local/include/c++/4.9.3/bits/cxxabi_forced.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_function.h'
  '/home/david/.local/include/c++/4.9.3/backward/binders.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.h'
  '/home/david/.local/include/c++/4.9.3/ext/atomicity.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr-default.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/atomic_word.h'
  '/home/david/.local/include/c++/4.9.3/ext/string_conversions.h'
  '/home/david/.local/include/c++/4.9.3/cstdlib'
  '/home/david/.local/include/c++/4.9.3/cstdio'
  '/home/david/.local/include/c++/4.9.3/cerrno'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.tcc'
  '/home/david/.local/include/c++/4.9.3/algorithm'
  '/home/david/.local/include/c++/4.9.3/utility'
  '/home/david/.local/include/c++/4.9.3/bits/stl_relops.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algo.h'
  '/home/david/.local/include/c++/4.9.3/bits/algorithmfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_heap.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_tempbuf.h'
  '/home/david/.local/include/c++/4.9.3/random'
  '/home/david/.local/include/c++/4.9.3/cmath'
  '/home/david/.local/include/c++/4.9.3/limits'
  '/home/david/.local/include/c++/4.9.3/bits/random.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/opt_random.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/x86intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/ia32intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/mmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/mm_malloc.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/emmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/pmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/tmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/ammintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/smmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/popcntintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/wmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/immintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avxintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx2intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512fintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512erintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512pfintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512cdintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/shaintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/lzcntintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/bmiintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/bmi2intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/fmaintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/f16cintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/rtmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xtestintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/mm3dnow.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/prfchwintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/fma4intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xopintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/lwpintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/tbmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/rdseedintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/fxsrintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xsaveintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xsaveoptintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/adxintrin.h'
  '/home/david/.local/include/c++/4.9.3/bits/random.tcc'
  '/home/david/.local/include/c++/4.9.3/numeric'
  '/home/david/.local/include/c++/4.9.3/bits/stl_numeric.h'
  '/home/david/.local/include/c++/4.9.3/map'
  '/home/david/.local/include/c++/4.9.3/bits/stl_tree.h'
  '/home/david/.local/include/c++/4.9.3/ext/aligned_buffer.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_map.h'
  '/home/david/.local/include/c++/4.9.3/tuple'
  '/home/david/.local/include/c++/4.9.3/array'
  '/home/david/.local/include/c++/4.9.3/stdexcept'
  '/home/david/.local/include/c++/4.9.3/bits/uses_allocator.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_multimap.h'
  '/home/david/.local/include/c++/4.9.3/stack'
  '/home/david/.local/include/c++/4.9.3/deque'
  '/home/david/.local/include/c++/4.9.3/bits/stl_deque.h'
  '/home/david/.local/include/c++/4.9.3/bits/deque.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/stl_stack.h'
  '/home/david/.local/include/c++/4.9.3/ostream'
  '/home/david/.local/include/c++/4.9.3/ios'
  '/home/david/.local/include/c++/4.9.3/bits/ios_base.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_classes.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_classes.tcc'
  '/home/david/.local/include/c++/4.9.3/streambuf'
  '/home/david/.local/include/c++/4.9.3/bits/streambuf.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/basic_ios.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_facets.h'
  '/home/david/.local/include/c++/4.9.3/cwctype'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/ctype_base.h'
  '/home/david/.local/include/c++/4.9.3/bits/streambuf_iterator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/ctype_inline.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_facets.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/basic_ios.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/ostream.tcc'
  '/home/david/.local/include/c++/4.9.3/set'
  '/home/david/.local/include/c++/4.9.3/bits/stl_set.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_multiset.h'
  '/home/david/.local/include/c++/4.9.3/tr1/unordered_set'
  '/home/david/.local/include/c++/4.9.3/tr1/type_traits'
  '/home/david/.local/include/c++/4.9.3/tr1/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/tr1/hashtable.h'
  '/home/david/.local/include/c++/4.9.3/tr1/hashtable_policy.h'
  '/home/david/.local/include/c++/4.9.3/tr1/unordered_set.h'
  '/home/david/.local/include/c++/4.9.3/sstream'
  '/home/david/.local/include/c++/4.9.3/istream'
  '/home/david/.local/include/c++/4.9.3/bits/istream.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/sstream.tcc'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
```

```
bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
Warning: ignoring LD_PRELOAD in environment.
INFO: Found 1 target...
ERROR: /home/david/.cache/bazel/_bazel_david/47d00ffdd2fc0515138a34f138cebd63/external/re2/BUILD:9:1: undeclared inclusion(s) in rule '@re2//:re2':
this rule is missing dependency declarations for the following files included by 'external/re2/util/valgrind.cc':
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stddef.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdarg.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdint.h'
  '/home/david/.local/include/c++/4.9.3/ctime'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/home/david/.local/include/c++/4.9.3/vector'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algobase.h'
  '/home/david/.local/include/c++/4.9.3/bits/functexcept.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/cpp_type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/numeric_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_pair.h'
  '/home/david/.local/include/c++/4.9.3/bits/move.h'
  '/home/david/.local/include/c++/4.9.3/bits/concept_check.h'
  '/home/david/.local/include/c++/4.9.3/type_traits'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_types.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_funcs.h'
  '/home/david/.local/include/c++/4.9.3/debug/debug.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator.h'
  '/home/david/.local/include/c++/4.9.3/bits/ptr_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/predefined_ops.h'
  '/home/david/.local/include/c++/4.9.3/bits/allocator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/new_allocator.h'
  '/home/david/.local/include/c++/4.9.3/new'
  '/home/david/.local/include/c++/4.9.3/exception'
  '/home/david/.local/include/c++/4.9.3/bits/atomic_lockfree_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_ptr.h'
  '/home/david/.local/include/c++/4.9.3/bits/nested_exception.h'
  '/home/david/.local/include/c++/4.9.3/bits/memoryfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_construct.h'
  '/home/david/.local/include/c++/4.9.3/ext/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_uninitialized.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_vector.h'
  '/home/david/.local/include/c++/4.9.3/initializer_list'
  '/home/david/.local/include/c++/4.9.3/bits/stl_bvector.h'
  '/home/david/.local/include/c++/4.9.3/bits/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/bits/hash_bytes.h'
  '/home/david/.local/include/c++/4.9.3/bits/range_access.h'
  '/home/david/.local/include/c++/4.9.3/bits/vector.tcc'
  '/home/david/.local/include/c++/4.9.3/string'
  '/home/david/.local/include/c++/4.9.3/bits/stringfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/char_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/postypes.h'
  '/home/david/.local/include/c++/4.9.3/cwchar'
  '/home/david/.local/include/c++/4.9.3/cstdint'
  '/home/david/.local/include/c++/4.9.3/bits/localefwd.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++locale.h'
  '/home/david/.local/include/c++/4.9.3/clocale'
  '/home/david/.local/include/c++/4.9.3/iosfwd'
  '/home/david/.local/include/c++/4.9.3/cctype'
  '/home/david/.local/include/c++/4.9.3/bits/ostream_insert.h'
  '/home/david/.local/include/c++/4.9.3/bits/cxxabi_forced.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_function.h'
  '/home/david/.local/include/c++/4.9.3/backward/binders.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.h'
  '/home/david/.local/include/c++/4.9.3/ext/atomicity.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr-default.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/atomic_word.h'
  '/home/david/.local/include/c++/4.9.3/ext/string_conversions.h'
  '/home/david/.local/include/c++/4.9.3/cstdlib'
  '/home/david/.local/include/c++/4.9.3/cstdio'
  '/home/david/.local/include/c++/4.9.3/cerrno'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.tcc'
  '/home/david/.local/include/c++/4.9.3/algorithm'
  '/home/david/.local/include/c++/4.9.3/utility'
  '/home/david/.local/include/c++/4.9.3/bits/stl_relops.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algo.h'
  '/home/david/.local/include/c++/4.9.3/bits/algorithmfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_heap.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_tempbuf.h'
  '/home/david/.local/include/c++/4.9.3/random'
  '/home/david/.local/include/c++/4.9.3/cmath'
  '/home/david/.local/include/c++/4.9.3/limits'
  '/home/david/.local/include/c++/4.9.3/bits/random.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/opt_random.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/x86intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/ia32intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/mmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/mm_malloc.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/emmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/pmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/tmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/ammintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/smmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/popcntintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/wmmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/immintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avxintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx2intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512fintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512erintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512pfintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/avx512cdintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/shaintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/lzcntintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/bmiintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/bmi2intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/fmaintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/f16cintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/rtmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xtestintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/mm3dnow.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/prfchwintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/fma4intrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xopintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/lwpintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/tbmintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/rdseedintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/fxsrintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xsaveintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/xsaveoptintrin.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/adxintrin.h'
  '/home/david/.local/include/c++/4.9.3/bits/random.tcc'
  '/home/david/.local/include/c++/4.9.3/numeric'
  '/home/david/.local/include/c++/4.9.3/bits/stl_numeric.h'
  '/home/david/.local/include/c++/4.9.3/map'
  '/home/david/.local/include/c++/4.9.3/bits/stl_tree.h'
  '/home/david/.local/include/c++/4.9.3/ext/aligned_buffer.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_map.h'
  '/home/david/.local/include/c++/4.9.3/tuple'
  '/home/david/.local/include/c++/4.9.3/array'
  '/home/david/.local/include/c++/4.9.3/stdexcept'
  '/home/david/.local/include/c++/4.9.3/bits/uses_allocator.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_multimap.h'
  '/home/david/.local/include/c++/4.9.3/stack'
  '/home/david/.local/include/c++/4.9.3/deque'
  '/home/david/.local/include/c++/4.9.3/bits/stl_deque.h'
  '/home/david/.local/include/c++/4.9.3/bits/deque.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/stl_stack.h'
  '/home/david/.local/include/c++/4.9.3/ostream'
  '/home/david/.local/include/c++/4.9.3/ios'
  '/home/david/.local/include/c++/4.9.3/bits/ios_base.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_classes.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_classes.tcc'
  '/home/david/.local/include/c++/4.9.3/streambuf'
  '/home/david/.local/include/c++/4.9.3/bits/streambuf.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/basic_ios.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_facets.h'
  '/home/david/.local/include/c++/4.9.3/cwctype'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/ctype_base.h'
  '/home/david/.local/include/c++/4.9.3/bits/streambuf_iterator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/ctype_inline.h'
  '/home/david/.local/include/c++/4.9.3/bits/locale_facets.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/basic_ios.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/ostream.tcc'
  '/home/david/.local/include/c++/4.9.3/set'
  '/home/david/.local/include/c++/4.9.3/bits/stl_set.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_multiset.h'
  '/home/david/.local/include/c++/4.9.3/tr1/unordered_set'
  '/home/david/.local/include/c++/4.9.3/tr1/type_traits'
  '/home/david/.local/include/c++/4.9.3/tr1/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/tr1/hashtable.h'
  '/home/david/.local/include/c++/4.9.3/tr1/hashtable_policy.h'
  '/home/david/.local/include/c++/4.9.3/tr1/unordered_set.h'
  '/home/david/.local/include/c++/4.9.3/sstream'
  '/home/david/.local/include/c++/4.9.3/istream'
  '/home/david/.local/include/c++/4.9.3/bits/istream.tcc'
  '/home/david/.local/include/c++/4.9.3/bits/sstream.tcc'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2.889s, Critical Path: 2.49s
```

With Bazel 0.1.5:

```
bazel build -c opt --config=cuda --verbose_failures //tensorflow/cc:tutorials_example_trainer
Warning: ignoring LD_PRELOAD in environment.
INFO: Found 1 target...
ERROR: /home/david/gits/tensorflow/google/protobuf/BUILD:64:1: undeclared inclusion(s) in rule '//google/protobuf:protobuf':
this rule is missing dependency declarations for the following files included by 'google/protobuf/src/google/protobuf/io/strtod.cc':
  '/home/david/.local/include/c++/4.9.3/cstdio'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stddef.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdarg.h'
  '/home/david/.local/include/c++/4.9.3/cstring'
  '/home/david/.local/include/c++/4.9.3/limits'
  '/home/david/.local/include/c++/4.9.3/string'
  '/home/david/.local/include/c++/4.9.3/bits/stringfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/memoryfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/char_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algobase.h'
  '/home/david/.local/include/c++/4.9.3/bits/functexcept.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/cpp_type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/numeric_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_pair.h'
  '/home/david/.local/include/c++/4.9.3/bits/move.h'
  '/home/david/.local/include/c++/4.9.3/bits/concept_check.h'
  '/home/david/.local/include/c++/4.9.3/type_traits'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_types.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_funcs.h'
  '/home/david/.local/include/c++/4.9.3/debug/debug.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator.h'
  '/home/david/.local/include/c++/4.9.3/bits/ptr_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/predefined_ops.h'
  '/home/david/.local/include/c++/4.9.3/bits/postypes.h'
  '/home/david/.local/include/c++/4.9.3/cwchar'
  '/home/david/.local/include/c++/4.9.3/cstdint'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdint.h'
  '/home/david/.local/include/c++/4.9.3/bits/allocator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/new_allocator.h'
  '/home/david/.local/include/c++/4.9.3/new'
  '/home/david/.local/include/c++/4.9.3/exception'
  '/home/david/.local/include/c++/4.9.3/bits/atomic_lockfree_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_ptr.h'
  '/home/david/.local/include/c++/4.9.3/bits/nested_exception.h'
  '/home/david/.local/include/c++/4.9.3/bits/localefwd.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++locale.h'
  '/home/david/.local/include/c++/4.9.3/clocale'
  '/home/david/.local/include/c++/4.9.3/iosfwd'
  '/home/david/.local/include/c++/4.9.3/cctype'
  '/home/david/.local/include/c++/4.9.3/bits/ostream_insert.h'
  '/home/david/.local/include/c++/4.9.3/bits/cxxabi_forced.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_function.h'
  '/home/david/.local/include/c++/4.9.3/backward/binders.h'
  '/home/david/.local/include/c++/4.9.3/bits/range_access.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.h'
  '/home/david/.local/include/c++/4.9.3/ext/atomicity.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr-default.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/atomic_word.h'
  '/home/david/.local/include/c++/4.9.3/initializer_list'
  '/home/david/.local/include/c++/4.9.3/ext/string_conversions.h'
  '/home/david/.local/include/c++/4.9.3/cstdlib'
  '/home/david/.local/include/c++/4.9.3/cerrno'
  '/home/david/.local/include/c++/4.9.3/bits/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/bits/hash_bytes.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.tcc'
  '/home/david/.local/include/c++/4.9.3/cstddef'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed/limits.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed/syslimits.h'
  '/home/david/.local/include/c++/4.9.3/utility'
  '/home/david/.local/include/c++/4.9.3/bits/stl_relops.h'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 2.634s, Critical Path: 2.21s

$ bazel build -c opt --config=cuda --verbose_failures --spawn_strategy=standalone //tensorflow/cc:tutorials_example_trainer
Warning: ignoring LD_PRELOAD in environment.
INFO: Found 1 target...
ERROR: /home/david/gits/tensorflow/google/protobuf/BUILD:64:1: undeclared inclusion(s) in rule '//google/protobuf:protobuf':
this rule is missing dependency declarations for the following files included by 'google/protobuf/src/google/protobuf/stubs/substitute.cc':
  '/home/david/.local/include/c++/4.9.3/string'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/stringfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/memoryfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/char_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algobase.h'
  '/home/david/.local/include/c++/4.9.3/bits/functexcept.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/cpp_type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/numeric_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_pair.h'
  '/home/david/.local/include/c++/4.9.3/bits/move.h'
  '/home/david/.local/include/c++/4.9.3/bits/concept_check.h'
  '/home/david/.local/include/c++/4.9.3/type_traits'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_types.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_funcs.h'
  '/home/david/.local/include/c++/4.9.3/debug/debug.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator.h'
  '/home/david/.local/include/c++/4.9.3/bits/ptr_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/predefined_ops.h'
  '/home/david/.local/include/c++/4.9.3/bits/postypes.h'
  '/home/david/.local/include/c++/4.9.3/cwchar'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdarg.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stddef.h'
  '/home/david/.local/include/c++/4.9.3/cstdint'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdint.h'
  '/home/david/.local/include/c++/4.9.3/bits/allocator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/new_allocator.h'
  '/home/david/.local/include/c++/4.9.3/new'
  '/home/david/.local/include/c++/4.9.3/exception'
  '/home/david/.local/include/c++/4.9.3/bits/atomic_lockfree_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_ptr.h'
  '/home/david/.local/include/c++/4.9.3/bits/nested_exception.h'
  '/home/david/.local/include/c++/4.9.3/bits/localefwd.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++locale.h'
  '/home/david/.local/include/c++/4.9.3/clocale'
  '/home/david/.local/include/c++/4.9.3/iosfwd'
  '/home/david/.local/include/c++/4.9.3/cctype'
  '/home/david/.local/include/c++/4.9.3/bits/ostream_insert.h'
  '/home/david/.local/include/c++/4.9.3/bits/cxxabi_forced.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_function.h'
  '/home/david/.local/include/c++/4.9.3/backward/binders.h'
  '/home/david/.local/include/c++/4.9.3/bits/range_access.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.h'
  '/home/david/.local/include/c++/4.9.3/ext/atomicity.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr-default.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/atomic_word.h'
  '/home/david/.local/include/c++/4.9.3/initializer_list'
  '/home/david/.local/include/c++/4.9.3/ext/string_conversions.h'
  '/home/david/.local/include/c++/4.9.3/cstdlib'
  '/home/david/.local/include/c++/4.9.3/cstdio'
  '/home/david/.local/include/c++/4.9.3/cerrno'
  '/home/david/.local/include/c++/4.9.3/bits/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/bits/hash_bytes.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.tcc'
  '/home/david/.local/include/c++/4.9.3/cstddef'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed/limits.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed/syslimits.h'
  '/home/david/.local/include/c++/4.9.3/utility'
  '/home/david/.local/include/c++/4.9.3/bits/stl_relops.h'
  '/home/david/.local/include/c++/4.9.3/vector'
  '/home/david/.local/include/c++/4.9.3/bits/stl_construct.h'
  '/home/david/.local/include/c++/4.9.3/ext/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_uninitialized.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_vector.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_bvector.h'
  '/home/david/.local/include/c++/4.9.3/bits/vector.tcc'
  '/home/david/.local/include/c++/4.9.3/limits'
  '/home/david/.local/include/c++/4.9.3/unordered_map'
  '/home/david/.local/include/c++/4.9.3/tuple'
  '/home/david/.local/include/c++/4.9.3/array'
  '/home/david/.local/include/c++/4.9.3/stdexcept'
  '/home/david/.local/include/c++/4.9.3/bits/uses_allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/aligned_buffer.h'
  '/home/david/.local/include/c++/4.9.3/bits/hashtable.h'
  '/home/david/.local/include/c++/4.9.3/bits/hashtable_policy.h'
  '/home/david/.local/include/c++/4.9.3/bits/unordered_map.h'
  '/home/david/.local/include/c++/4.9.3/unordered_set'
  '/home/david/.local/include/c++/4.9.3/bits/unordered_set.h'.
Target //tensorflow/cc:tutorials_example_trainer failed to build
ERROR: /home/david/gits/tensorflow/tensorflow/cc/BUILD:28:1 undeclared inclusion(s) in rule '//google/protobuf:protobuf':
this rule is missing dependency declarations for the following files included by 'google/protobuf/src/google/protobuf/stubs/substitute.cc':
  '/home/david/.local/include/c++/4.9.3/string'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++config.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/os_defines.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/cpu_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/stringfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/memoryfwd.h'
  '/home/david/.local/include/c++/4.9.3/bits/char_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_algobase.h'
  '/home/david/.local/include/c++/4.9.3/bits/functexcept.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/cpp_type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/type_traits.h'
  '/home/david/.local/include/c++/4.9.3/ext/numeric_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_pair.h'
  '/home/david/.local/include/c++/4.9.3/bits/move.h'
  '/home/david/.local/include/c++/4.9.3/bits/concept_check.h'
  '/home/david/.local/include/c++/4.9.3/type_traits'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_types.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator_base_funcs.h'
  '/home/david/.local/include/c++/4.9.3/debug/debug.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_iterator.h'
  '/home/david/.local/include/c++/4.9.3/bits/ptr_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/predefined_ops.h'
  '/home/david/.local/include/c++/4.9.3/bits/postypes.h'
  '/home/david/.local/include/c++/4.9.3/cwchar'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdarg.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stddef.h'
  '/home/david/.local/include/c++/4.9.3/cstdint'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include/stdint.h'
  '/home/david/.local/include/c++/4.9.3/bits/allocator.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/new_allocator.h'
  '/home/david/.local/include/c++/4.9.3/new'
  '/home/david/.local/include/c++/4.9.3/exception'
  '/home/david/.local/include/c++/4.9.3/bits/atomic_lockfree_defines.h'
  '/home/david/.local/include/c++/4.9.3/bits/exception_ptr.h'
  '/home/david/.local/include/c++/4.9.3/bits/nested_exception.h'
  '/home/david/.local/include/c++/4.9.3/bits/localefwd.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/c++locale.h'
  '/home/david/.local/include/c++/4.9.3/clocale'
  '/home/david/.local/include/c++/4.9.3/iosfwd'
  '/home/david/.local/include/c++/4.9.3/cctype'
  '/home/david/.local/include/c++/4.9.3/bits/ostream_insert.h'
  '/home/david/.local/include/c++/4.9.3/bits/cxxabi_forced.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_function.h'
  '/home/david/.local/include/c++/4.9.3/backward/binders.h'
  '/home/david/.local/include/c++/4.9.3/bits/range_access.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.h'
  '/home/david/.local/include/c++/4.9.3/ext/atomicity.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/gthr-default.h'
  '/home/david/.local/include/c++/4.9.3/x86_64-unknown-linux-gnu/bits/atomic_word.h'
  '/home/david/.local/include/c++/4.9.3/initializer_list'
  '/home/david/.local/include/c++/4.9.3/ext/string_conversions.h'
  '/home/david/.local/include/c++/4.9.3/cstdlib'
  '/home/david/.local/include/c++/4.9.3/cstdio'
  '/home/david/.local/include/c++/4.9.3/cerrno'
  '/home/david/.local/include/c++/4.9.3/bits/functional_hash.h'
  '/home/david/.local/include/c++/4.9.3/bits/hash_bytes.h'
  '/home/david/.local/include/c++/4.9.3/bits/basic_string.tcc'
  '/home/david/.local/include/c++/4.9.3/cstddef'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed/limits.h'
  '/home/david/.local/lib/gcc/x86_64-unknown-linux-gnu/4.9.3/include-fixed/syslimits.h'
  '/home/david/.local/include/c++/4.9.3/utility'
  '/home/david/.local/include/c++/4.9.3/bits/stl_relops.h'
  '/home/david/.local/include/c++/4.9.3/vector'
  '/home/david/.local/include/c++/4.9.3/bits/stl_construct.h'
  '/home/david/.local/include/c++/4.9.3/ext/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/alloc_traits.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_uninitialized.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_vector.h'
  '/home/david/.local/include/c++/4.9.3/bits/stl_bvector.h'
  '/home/david/.local/include/c++/4.9.3/bits/vector.tcc'
  '/home/david/.local/include/c++/4.9.3/limits'
  '/home/david/.local/include/c++/4.9.3/unordered_map'
  '/home/david/.local/include/c++/4.9.3/tuple'
  '/home/david/.local/include/c++/4.9.3/array'
  '/home/david/.local/include/c++/4.9.3/stdexcept'
  '/home/david/.local/include/c++/4.9.3/bits/uses_allocator.h'
  '/home/david/.local/include/c++/4.9.3/ext/aligned_buffer.h'
  '/home/david/.local/include/c++/4.9.3/bits/hashtable.h'
  '/home/david/.local/include/c++/4.9.3/bits/hashtable_policy.h'
  '/home/david/.local/include/c++/4.9.3/bits/unordered_map.h'
  '/home/david/.local/include/c++/4.9.3/unordered_set'
  '/home/david/.local/include/c++/4.9.3/bits/unordered_set.h'.
INFO: Elapsed time: 0.999s, Critical Path: 0.80s
```

Bazel 2.2b fails when tensorflow tries to parse the version:

```
 bazel build -c opt --config=cuda --verbose_failures --spawn_strategy=standalone //tensorflow/cc:tutorials_example_trainer
Warning: ignoring LD_PRELOAD in environment.
Sending SIGTERM to previous Bazel server (pid=24216)... done.
......
ERROR: /home/david/gits/tensorflow/WORKSPACE:21:1: Traceback (most recent call last):
    File ""/home/david/gits/tensorflow/WORKSPACE"", line 21
        check_version(""0.1.4"")
    File ""/home/david/gits/tensorflow/tensorflow/tensorflow.bzl"", line 22, in check_version
        _parse_bazel_version(native.bazel_version)
    File ""/home/david/gits/tensorflow/tensorflow/tensorflow.bzl"", line 15, in _parse_bazel_version
        int(number)
invalid literal for int(): ""2b"".
ERROR: Error evaluating WORKSPACE file.
ERROR: no such package 'external': Package 'external' contains errors.
INFO: Elapsed time: 0.610s
```

Correcting that mistake I get a bulld error again:

```
 bazel build -c opt --config=cuda --spawn_strategy=standalone --verbose_failures //tensorflow/tools/pip_package:build_pip_package
Warning: ignoring LD_PRELOAD in environment.
ERROR: no such package 'external': Package 'external' contains errors.
INFO: Elapsed time: 0.084s
```

How can I get it to work? I am interested in building Tensorflow with vector instructions for my laptop and linking against the latest cudnn for my workstation.
"
2108,How to recognize a jpg from sdcard,"I try to use tensorflow to recognize a jpg from sdcard, Is it right?
Bitmap bitmap = BitmapFactory.decodeFile(""/storage/8A38-1900/1/1.jpg"");
        if (bitmap != null && !bitmap.isRecycled()) {
            List<Recognition> recogns = tensorflow.recognizeImage(bitmap);
            if(recogns!=null){
                for (Recognition recognition:recogns) {
                    Log.e(""recognition"", ""recognition=""+recognition.toString());
                }
            }
        }
"
2107,"""CUDNN_STATUS_BAD_PARAM"" raised when running MNIST expert tutorial on GPU","I tried the code from MNIST expert tutorial and it works only on cpu. When I try to execute it in the gpu I get a session crash.
The code for begginers tutorial however works well in both the gpu and cpu.
### Environment info
- OS: Ubuntu 16.04
- CUDA: 7.5
- cuDNN: 5
- Pip: 8.1.1
- Python: 2.7.11
- Anaconda:  4.0.0 (64-bit)
- Tensorflow: 0.8.0 (running on conda environment)
- GPU: GeForce GTX 860M
### Steps to reproduce
1. conda create -n tensorflow python=2.7
2. pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
### What have you tried?
1. I tried the MNIST tutorial for begginer and it works well on both cpu and gpu
2. I tried the MNIST tutorial for expert on cpu and it works well
3. I tried the MNIST tutorial for expert on gpu and its not working, here's the output:

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 860M
major: 5 minor: 0 memoryClockRate (GHz) 1.0195
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.67GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0)
F tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
Aborted (core dumped)
```
## Additional information (the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root  189170 Apr 22 15:05 libcudadevrt.a
lrwxrwxrwx 1 root root      16 Apr 22 15:05 libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root      19 Apr 22 15:05 libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root  311596 Apr 22 15:05 libcudart.so.7.5.18
-rw-r--r-- 1 root root  558020 Apr 22 15:05 libcudart_static.a
lrwxrwxrwx 1 root root      17 Apr 22 15:05 libcuinj32.so -> libcuinj32.so.7.5
lrwxrwxrwx 1 root root      20 Apr 22 15:05 libcuinj32.so.7.5 -> libcuinj32.so.7.5.18
-rwxr-xr-x 1 root root 5396088 Apr 22 15:05 libcuinj32.so.7.5.18
lrwxrwxrwx 1 root root       13 Apr 22 16:38 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Apr 22 16:38 libcudnn.so.5 -> libcudnn.so.5.0.4
-rwxrwxr-x 1 root root 59823168 Mar 22 10:37 libcudnn.so.5.0.4
```
"
2106,[ distribution ] How to use multiple GPU on each replica ?,"The [Code Here](https://github.com/tensorflow/models/blob/master/inception/inception/imagenet_distributed_train.py) shows how to set each replica which has a single tower that uses one GPU. I'm wondering if there is a way changing this code a little bit to make use of multiple GPU on one machine like [that example](https://github.com/tensorflow/models/blob/master/inception/inception/inception_train.py). 

The way I currently used for using all GPU on a worker machine is starting the number of workers that equal to the number of GPUs. then the workers can communicate to each other as if they are not on one machine. That is slower than if I can start a woker that control more than one GPU. 
"
2105,Faile to run tensorflow ,"I just want to install the tensorflow using pip.
$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
and it succeed.

And I run python -c ""import tensorflow;it will report
ImportError: /lib64/libc.so.6: version `GLIBC_2.15' not found (required by /usr/local/python2710/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so)

And I tried to upgrade GLIBC_2.15,and then now it reported that
ImportError: /opt/glibc-2.15/lib/libc.so.6: version `GLIBC_2.17' not found (required by /usr/local/python2710/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.s

And then tried to upgrade to GLIBC_2.17,and then type ls ,the error as below:
ls: error while loading shared libraries: __vdso_time: invalid mode for dlopen(): Invalid argument

My machine is 
Linux sjs_88_78 2.6.32-504.23.4.el6.x86_64 #1 SMP Fri May 29 10:16:43 EDT 2015 x86_64 x86_64 x86_64 GNU/Linux
"
2101,TensorFlow_0.8.0 somehow breaks PIL ? ,"### Environment info

Operating System:

```
ubuntu@ip-172-31-32-186:~$ uname -a
Linux ip-172-31-32-186 3.13.0-48-generic #80-Ubuntu SMP Thu Mar 12 11:16:15 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
```

TensorFlow version and installation method:

```
ubuntu@ip-172-31-32-186:~$ python -c ""import tensorflow; print(tensorflow.__version__)""
0.8.0
```

I installed with command:
`sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl`

My problem: Tensorflow break the PIL image read
### Steps to reproduce

Following command verifies that my PIL works good without importing TensorFlow:

```
ubuntu@ip-172-31-32-186:~$ python
Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from PIL import Image
>>> a = Image.open('bubble-counting/images/original/bubble.jpg')
>>> b = a.getdata()
>>> b[0]
(166, 56, 57)
```

After importing TensorFlow, same code does not work any more:

```
ubuntu@ip-172-31-32-186:~$ python
Python 2.7.6 (default, Jun 22 2015, 17:58:13) 
[GCC 4.8.2] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> from PIL import Image
>>> a = Image.open('bubble-counting/images/original/bubble.jpg')
>>> b = a.getdata()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/PIL/Image.py"", line 1151, in getdata
    self.load()
  File ""/usr/local/lib/python2.7/dist-packages/PIL/ImageFile.py"", line 235, in load
    raise_ioerror(e)
  File ""/usr/local/lib/python2.7/dist-packages/PIL/ImageFile.py"", line 59, in raise_ioerror
    raise IOError(message + "" when reading image file"")
IOError: broken data stream when reading image file
```
### Other info

**After uninstall TensorFlow0.8 and install TensorFlow0.7.1, the problem disappeared!**

installation code:
`sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl`

```
>>> PIL.VERSION
'1.1.7'
>>> pandas.__version__
u'0.18.0'
>>> dask.__version__
'0.8.2'
>>> numpy.__version__
'1.11.0'
>>> scipy.__version__
'0.17.0'
```

My questions:
1. Can you reproduce the problem ?
2. What might be the reason of this problem since I am not familiar with PIL or TensorFlow code ?

If there were any information you need, pls let me know.
"
2099,"Misleading error message when using ""empty"" variables","The code below fails with ""Attempting to use uninitialized value Variable"". This came up [here](http://stackoverflow.com/questions/36763913/tensorflow-failedpreconditionerror-but-all-variables-have-been-initialized) and makes debugging harder. Maybe instead it should fail during Variable creation or Shape inference with ""Variable must have non-zero size""

sess = tf.InteractiveSession()
empty = np.zeros(shape=(0, 0) )
a = tf.Variable(empty)
sess.run(tf.initialize_all_variables())
sess.run(tf.reduce_sum(a))
"
2098,max_pool_with_argmax: No gradient defined,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Linux Ubuntu 14.04

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide: pip package:
tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl
1. Which pip package you installed.  
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce
1. include a max_pool_with_argmax layer in a convolutional neural network and use it for training.
   The process terminate with this error:
   LookupError: No gradient defined for operation 'conv2/MaxPoolWithArgmax' (op type: MaxPoolWithArgmax)
"
2097,Undefined symbol in GPU user op,"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 7.5, 5 (see bottom for ls output)
If installed from sources, provide the commit hash: 55068f32c87c73c8de7a417d8be735306e5307a1
### Steps to reproduce
1. Get BUILD, get_diag.cc, get_diag.cu.cc from [my fork](https://github.com/c0g/tensorflow/tree/master/tensorflow/core/user_ops)
2. Build the get_diag op with `bazel build -c opt --config cuda //tensorflow/core/user_ops:get_diag.so`
3. Try to run it on the GPU.

Error messages is: 
`
tensorflow.python.framework.errors.NotFoundError: /home/tron/Source/tensorflow/bazel-bin/tensorflow/core/user_ops/get_diag.so: undefined symbol: _Z21GetDiagKernelLauncherIdEvPKT_iiPS0_
`

however, running `nm -an get_diag.so | grep _Z21GetDiagKernelLauncherIdEvPKT_iiPS0_` shows `U _Z21GetDiagKernelLauncherIdEvPKT_iiPS0_` , so it appears the symbol is present.

This works fine with the CPU version of the op - is there something I'm missing to make Bazel link things properly?
### Logs or other output that would be helpful

-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 tron tron       13 Mar 22 07:44 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 tron tron       17 Mar 22 07:44 /usr/local/cuda-7.5/lib64/libcudnn.so.5 -> libcudnn.so.5.0.4
-rwxrwxr-x 1 tron tron 59823168 Mar 22 01:37 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.4
-rw-rw-r-- 1 tron tron 58734618 Mar 22 01:37 /usr/local/cuda-7.5/lib64/libcudnn_static.a
"
2092,'ClusterSpec' object has no attribute '_cluster_spec',"I want to test tensorflow cluster,According tothe website https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md
ERROR 'ClusterSpec' object has no attribute '_cluster_spec'  happend

> > > import numpy
> > > import matplotlib
> > > import tensorflow as tf
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
> > > cluster = tf.train.ClusterSpec({""local"": [""localhost:2222"", ""localhost:2223""]})
> > > server = tf.train.Server(cluster, job_name=""local"", task_index=0)
> > > Traceback (most recent call last):
> > >   File ""<stdin>"", line 1, in <module>
> > >   File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/server_lib.py"", line 135, in **init**
> > >     job_name, task_index, protocol)
> > >   File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/server_lib.py"", line 65, in _make_server_def
> > >     cluster_spec = ClusterSpec(server_or_cluster_def)
> > >   File ""/usr/lib/python2.7/site-packages/tensorflow/python/training/server_lib.py"", line 242, in __init__
> > >     self._cluster_spec[job_def.name] = [t for t in job_def.tasks.values()]
> > > AttributeError: 'ClusterSpec' object has no attribute '_cluster_spec'
"
2091,installing TensorFlow  on Ubuntu 16.04,"I'm trying to install gpu version of TensorFlow using pip3 on Ubuntu 16.04 
To do so I'm running below command(I've downloaded the file to make an archive of stable versions for me):
`sudo pip3 install --upgrade tensorflow-0.8.0-cp34-cp34m-linux_x86_64.whl`
I'm getting some error about locale setting as below:
`File ""/usr/bin/pip3"", line 11, in <module>`
`sys.exit(main())`
`File ""/usr/lib/python3/dist-packages/pip/__init__.py"", line 215, in main`
`locale.setlocale(locale.LC_ALL, '')`
`File ""/usr/lib/python3.5/locale.py"", line 595, in setlocale`
`return _setlocale(category, locale)`
`locale.Error: unsupported locale setting`

any help?
"
2089,Add support for reading HDF5,"HDF5 is a popular format to store complicated datasets (alternative to proto files).
Also has different random seeking functionality and is widely used in scientific community.

This is FR for:
- Adding HDF5 reader.
- Support of HDF5 in tf.learn.

(originally from https://github.com/tensorflow/skflow/issues/52)
"
2085,segmentation fault with tensorflow 0.8.0 and matplotlib,"When I build a simple script:

`import tensorflow`
`import matplotlib.pyplot as plt`
`import numpy as np`

`plt.plot(np.arange(100))`
`plt.show()`

I get a segmentation fault with TensorFlow 0.8.0. Tested with both, Matplotlib 1.5.1 and 1.4.3.

When I downgrade TensorFlow to 0.7.1 everything runs fine, with both, Matplotlib 1.5.1 and 1.4.3.

TensorFlow is installed via pip inside a virtual environment. I've not installed it outside of a virtual-env, because I do not want to break anything on my system.
### Environment info

Operating System: Manjaro Linux

`uname --all`
Linux 4.4.6-1-MANJARO #1 SMP PREEMPT Sat Mar 19 06:00:37 CET 2016 x86_64 GNU/Linux

`pip freeze`
backports.shutil-get-terminal-size==1.0.0
cycler==0.10.0
decorator==4.0.9
funcsigs==1.0.1
ipython==4.2.0
ipython-genutils==0.1.0
louis==2.6.5
matplotlib==1.5.1
mock==2.0.0
netsnmp-python==1.0a1
nose==1.3.7
numpy==1.11.0
packaging==16.6
pathlib2==2.1.0
pbr==1.9.1
pexpect==4.0.1
pickleshare==0.7.2
protobuf==3.0.0b2
ptyprocess==0.5.1
pwquality==1.3.0
pyparsing==2.1.1
python-dateutil==2.5.3
python-libtorrent==1.0.9
python-musicbrainz==0.0.0
pytz==2016.4
simplegeneric==0.8.1
six==1.10.0
team==1.0
tensorflow==0.7.1
traitlets==4.2.1
virtualenv==15.0.0
"
2084, Check failed: message->ParseFromZeroCopyStream(&adaptor) ,"I replaced the pb&labels.txt files in asset in android demo with what I retrained in examples/image_retraining . I built the demo successfully,but when running ,it shut down,and toast the error message: 
`Check failed: message->ParseFromZeroCopyStream(&adaptor)`
`Fatal signal 6 (SIGABRT), code -6 in tid 14617 (ImageListener)`
I have no idea about this,please give some advice.
"
2083,build doc enhancements,"The installation guide https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html could use the following improvements:
1. In the ""pip installation"" and ""virtualenv installation"" section, should specify that the wheel package is _specifically_ for Python 3.4. 
   As a side note, a wheel package for Python 3.5 would be greatly appreciated.
2. In build from sources -> install other dependencies:
   Replace:
   $ sudo apt-get install python-numpy swig python-dev
   With:
   For Python 2.7:
   $ sudo apt-get install python-numpy swig python-dev python-wheel
   For Python 3.x:
   $ sudo apt-get install python3-numpy swig python3-dev python3-wheel
3. In the build from sources section: specify that the compilation is VERY memory hungry (it won't fit on 8GB RAM), and suggest to add --local_resources 2048,.5,1.0 to the bazel build command as a workaround.
   Alternatively, change the bazel script to detect the available RAM and scale down automatically.
"
2081,install from source fails on Mac,"The installation of tensorflow from source fails on Mac.

The step it fails on is ./configure. The configure script looks like it has never been written to work on the Mac, even though the install guide suggests running ./configure in the section for Mac installation.

The script contains these lines which is where the failure happens:

  if [ -e $CUDA_TOOLKIT_PATH/lib64/libcudart.so$TF_CUDA_EXT ]; then
    break
  fi
  echo ""Invalid path to CUDA $TF_CUDA_VERSION toolkit. $CUDA_TOOLKIT_PATH/lib64/libcudart.so$TF_CUDA_EXT cannot be found""
## 

Of course the Mac doesn't have .so libs, or a lib64 dir. For example, my Cuda installation is at /usr/local/cuda, with /usr/local/cuda/lib/ containing *.dylib files including libcudart.dylib.
"
2077,Gradient of TensorArray updated during while loop yields error,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Mac OS X 10.11.4

Installed version of CUDA and cuDNN: none
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed: Installed from source
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"": 0.8.0rc0

If installed from sources, provide the commit hash:
commit 504e8a6ac678f83f88862b3826d54bb9b484cc33
### Steps to reproduce
1. See http://stackoverflow.com/questions/36807107/strange-error-when-taking-gradient-of-tensorarray
### What have you tried?
1. I've tried removing the while loop (just writing out one iteration) and it works.  Introducing the while loop back in yields error.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
See http://stackoverflow.com/questions/36807107/strange-error-when-taking-gradient-of-tensorarray
"
2076,Including timestamp with tf.Print?,"I'm trying to implement a batched version of the Inception example for TensorFlow Serving, and I'd like to benchmark the performance. 

Is it possible to have `tf.Print` emit a timestamp along with the logging information? Particularly if the op is bundled via `tensorflow_serving.session_bundle.exporter`?

I think it's possible to do with:

`x = tf.Print(x, [x], ""(%s) Obtained: "" % asctime())`

although I'm not sure if this will work appropriately when exported.
"
2075,tf.unravel_index (Was: tf.argmin across all dimensions),"Hi,

tf.argmin only works in one dimension.
Let's say I have a picture which is a 2x2 array of pixels (each pixels is a 3 value array) and I want to know which pixel is closest to a certain color. In that case I have to reshape the 2x2 array to a 1-D array then get the min index, then find out that index to what 2x2 array position corresponds.

Couldn't I just as tensorflow to give me the index in the 2x2 array. For instance [1,15]?

I really don't understand the reason for having to translate between lineal index and array location all the time.

Thanks.
"
2072,run image_retraining always get  integer division or modulo by zero,"I tried `bazel build tensorflow/examples/image_retraining:retrain && \
bazel-bin/tensorflow/examples/image_retraining/retrain \
--image_dir ~/flowers`
but get `retrain.py"", line 257, in get_image_path
    mod_index = index % len(category_list)
ZeroDivisionError: integer division or modulo by zero
`
I have got some files, like  flower.jpg.txt. 
why the length of category list could be zero?
"
2071,Tensorflow placeholders and exporting to c++,"Hello everyone,

My TF installation is working fine, but I'm running into a serious issue when exporting my trained model to a c++ environment. I'm trying to do something similar to this tutorial:
https://www.tensorflow.org/versions/r0.8/tutorials/image_recognition/index.html

I replaced the inception model with my own trained model, however, the graph won't run in c++. My own model is based on this tutorial:
https://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html#deep-mnist-for-experts

It gives me this error:

Running model failed: Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float
     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

The problem appears to be the placeholders at the input layer of my model. The model expects a feed_dict for them, but I don't believe there is c++ API for defining feed_dicts? If placeholders cannot be used with c++ API, I wonder how I should set up the input layer of my model for use with c++.

Thanks!
"
2070,Guide Tensorflow for JAVA EE,"Hello all,

Do we have any guideline or document to help get started with JAVA EE? In case we want to build with Java server application.

Best regards
Johnny
"
2068,No mechanism for handling user-defined Tensor wrappers in the arguments to `Session.run()`,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

-rw-r--r-- 1 root root   322936 Feb 25 17:24 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Feb 25 17:24 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Feb 25 17:24 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Feb 25 17:24 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Feb 25 17:24 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.

Version: 0.8.0rc0
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0rc0

If installed from sources, provide the commit hash:
### Steps to reproduce

A simple script to illustrate what I'm trying to do is pasted below. The conversion function works as advertised when applying a downstream TensorFlow operator to a registered class. However, it appears that the run function does not try to apply registered conversion functions to the fetches. It seems intuitive that it would try. Adding in this functionality would make libraries built on top of TensorFlow feel a bit more seamless.

``` python
import numpy as np
import tensorflow as tf


# create some dummy class that wraps a tensor
class SquaredTensor(object):
    def __init__(self, tensor):
        self.sq = tf.square(tensor)


# create conversion function back to a tensor
def squared_to_tensor(value, dtype=None, name=None, as_ref=False):
    return value.sq

# register conversion function
tf.register_tensor_conversion_function(SquaredTensor, squared_to_tensor)

with tf.Session() as sess:
    a = np.random.random(1000)
    b = SquaredTensor(a)

    # works as intended when a tf function is applied to class with conversion function
    c = tf.sqrt(b)
    c_eval = sess.run([c])
    assert np.allclose(a, c_eval)

    # directly evaluating the registered class fails
    # seems like this should work by trying to apply conversions on run fetches:
    # b_eval = sess.run([b])
    # instead we need to explicitly convert:
    b_eval = sess.run([b.sq])
    assert np.allclose(a*a, b_eval)
```
### What have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

Trying to fetch a SquaredTensor directly yields:

`TypeError: Fetch argument <__main__.SquaredTensor object at 0x7f63a5fa84d0> of <__main__.SquaredTensor object at 0x7f63a5fa84d0> has invalid type <class '__main__.SquaredTensor'>, must be a string or Tensor. (Can not convert a SquaredTensor into a Tensor or Operation.)`
"
2066,segmentation fault when stride > ksize in conv2d,"Hello,

I experience segfault trying to use recently merged modification of conv2d to support stride > ksize (yes, residual networks). Somehow it only arises in a complicated graph. I wrote minimal example, but it is still pretty big.
### Environment info

Operating System: Fedora 21
Python 3.4, GPU Titan X and Titan Z

Installed version of CUDA and cuDNN: Cuda 7.5, Cudnn 4.
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$ ls -1 $CUDA_HOME/lib/libcud*
$CUDA_HOME/lib/libcudadevrt.a
$CUDA_HOME/lib/libcudart.so
$CUDA_HOME/lib/libcudart.so.7.5
$CUDA_HOME/lib/libcudart.so.7.5.18
$CUDA_HOME/lib/libcudart_static.a

$ ls -1 $CUDA_HOME/lib64/libcud*
$CUDA_HOME/lib64/libcudadevrt.a
$CUDA_HOME/lib64/libcudart.so
$CUDA_HOME/lib64/libcudart.so.7.5
$CUDA_HOME/lib64/libcudart.so.7.5.18
$CUDA_HOME/lib64/libcudart_static.a
$CUDA_HOME/lib64/libcudnn.so
$CUDA_HOME/lib64/libcudnn.so.4
$CUDA_HOME/lib64/libcudnn.so.4.0.7
$CUDA_HOME/lib64/libcudnn_static.a
```

commit hash (nightly): 7b536cd5cfdbfd0fbc80496a38624557fb977783
### Steps to reproduce

Run the following code.

```
import tensorflow as tf
import numpy as np

FLAGS = tf.app.flags.FLAGS

tf.app.flags.DEFINE_integer('res_n', 18,
                            """"""Residual network parameter."""""")
tf.app.flags.DEFINE_integer('batch_size', 128,
                            """"""Batch size."""""")
tf.app.flags.DEFINE_integer('proj_ksize', 1,
                            """"""Kernel size of identity projection."""""")


def weight_variable(shape):
    init = tf.uniform_unit_scaling_initializer()
    var = tf.get_variable('weights', shape, initializer=init)
    return var


def batch_norm(x, conv=True, scope='bn'):
    phase_train = tf.get_collection('is_train')[0]
    n_out = int(x.get_shape()[-1])
    with tf.variable_scope(scope):
        beta = tf.get_variable('beta', shape=[n_out],
                initializer=tf.constant_initializer(0.0), trainable=True)
        gamma = tf.get_variable('gamma', shape=[n_out],
                initializer=tf.constant_initializer(1.0), trainable=True)

        axes = [0, 1, 2] if conv else [0]
        batch_mean, batch_var = tf.nn.moments(x, axes, name='moments')
        ema = tf.train.ExponentialMovingAverage(decay=0.9)
        ema_apply_op = ema.apply([batch_mean, batch_var])
        ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)
        def mean_var_with_update():
            with tf.control_dependencies([ema_apply_op]):
                return tf.identity(batch_mean), tf.identity(batch_var)
        mean, var = tf.python.control_flow_ops.cond(phase_train,
            mean_var_with_update,
            lambda: (ema_mean, ema_var))

        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)
    return normed


def create_conv_layer(src, name, ksize, out_filters,
                      stride=1, padding='SAME'):
    in_filters = int(src.get_shape()[-1])
    with tf.variable_scope(name):
        W = weight_variable([ksize, ksize, in_filters, out_filters])
        conv = tf.nn.conv2d(src, W, strides=[1, stride, stride, 1],
                            padding=padding)
    return conv


def res_block(layer, i, lvl, num_filters, preact=True):
    in_filters = int(layer.get_shape()[-1])
    name = 'conv%i_%i' % (lvl, i)
    if preact:
        layer_act = tf.nn.relu(batch_norm(layer,
                                          scope='bn_%i_%i_0' % (lvl, i)))
    else:
        layer_act = layer
    if num_filters != in_filters:
        stride = 2
    else:
        stride = 1
    layer2 = create_conv_layer(layer_act, name+'_1', 3, num_filters, stride=stride)
    layer2_act = tf.nn.relu(batch_norm(layer2, scope='bn_%i_%i_1' % (lvl, i)))
    layer3 = create_conv_layer(layer2_act, name+'_2', 3, num_filters)
    if stride > 1:
        layer_proj = create_conv_layer(layer, name+'_proj', FLAGS.proj_ksize, num_filters,
                                       stride=stride)
        res = layer_proj + layer3
    else:
        res = layer + layer3
    return res


def inference(layer, n):
    layer = create_conv_layer(layer, 'conv1_0', 3, 16)
    layer = tf.nn.relu(batch_norm(layer, scope='conv1_bn'))
    for i in range(n):
        layer = res_block(layer, i, 1, 16, preact=(i > 0))
    for i in range(n):
        layer = res_block(layer, i, 2, 32)
    for i in range(n):
        layer = res_block(layer, i, 3, 64)
    layer = tf.nn.relu(batch_norm(layer, scope='bn_post'))
    layer = tf.reduce_mean(layer, [1, 2], keep_dims=True)
    layer = create_conv_layer(layer, 'conv5', 1, 10)
    layer = tf.squeeze(layer)
    return layer


if __name__ == '__main__':
    np.random.seed(42)
    a = np.random.randn(FLAGS.batch_size, 32, 32, 3)
    b = np.random.randint(0, 10, size=FLAGS.batch_size)

    sess = tf.Session()

    phase_train = tf.Variable(True, trainable=False, name='phase_train')
    tf.add_to_collection('is_train', phase_train)

    x = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, 32, 32, 3))
    y = tf.placeholder(tf.int64, shape=(FLAGS.batch_size))
    logits = inference(x, FLAGS.res_n)
    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y))

    opt = tf.train.GradientDescentOptimizer(0.01)
    train_op = opt.minimize(loss)

    sess.run(tf.initialize_all_variables())
    sess.run(train_op, feed_dict={x: a, y: b})
```

It fails with an error cited below (if run on gpu with cudnn).
### What have you tried?
1. It doesn't look like a memory issue, it still fails with tiny batch size.
2. It works on CPU though.
3. It works if `proj_ksize=3` which again shows it isn't OOM issue and points to recently introduced feature.
4. It doesn't fail on a trivial example (just isolated conv2d with stride=2, ksize=1). While writing it, I realize I forgot to check the trivial example with backward pass.
5. It works for forward pass even on gpu.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
$ python3 conv_bug.py
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX TITAN Z
major: 3 minor: 5 memoryClockRate (GHz) 0.8755
pciBusID 0000:05:00.0
Total memory: 6.00GiB
Free memory: 5.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN Z, pci bus id: 0000:05:00.0)
F tensorflow/stream_executor/cuda/cuda_dnn.cc:904] failed to enqueue convolution on stream: CUDNN_STATUS_BAD_PARAM
[1]    10160 abort (core dumped)  python3 conv_bug.py
```
"
2064,sess = tf.Session() get stuck!,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-85-generic x86_64)

Installed version of CUDA and cuDNN: 
-rw-r--r-- 1 root root   322936 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn_static.a

My cudnn package: cudnn-7.0-linux-x64-v4.0-prod
If installed from binary pip package, provide:
1. Which pip package you installed.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
   0.8.0rc0
### What have you tried?

1.I ran 'python -m tensorflow.models.image.mnist.convolutional', and for the first time the model can print 'initialization' and train, but got stuck at the end. The second time I want to run it, it got stuck at the beginning after extracting from data. When I debug it, I find it's tf.Session() that making it get stuck.  When I tried '>>> hello = tf.constant('Hello, TensorFlow!')  >>> sess = tf.Session()', it got stuck here.
2.I have run the NVIDIA_CUDA-7.5_Samples/1_Utilities/deviceQuery, and the result is PASS. I have even reinstall the cuda, but the result remain the same.
3.I have tried the CPU model, and it went just fine.
4.I tried to install from the source, the result remain the same.

Where is wrong? It seemed that the cuda and cudnn went wrong, but how to fix it?
Please help me!
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2063,skflow and missing scalar_summary ?,"Hi,
I'm having issue to get the loss summary showing in tensorboard using skflow

this is my code

---

classifier = skflow.TensorFlowEstimator(  model_fn=conv_model, n_classes=2,   batch_size=BATCH_SIZE, 
                                          steps=100000,  learning_rate=0.001,
                                          config=RunConfig(gpu_memory_fraction=0.9))                                          

val_monitor = monitors.ValidationMonitor(X_val, y_val, n_classes=2, print_steps=100)
classifier.fit(X_train, y_train, val_monitor, logdir='my_model_1/')
classifier.save('my_model_1/')

---

everything runs well

---

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py:281: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future
  out.itemset((i, self.y[sample]), 1.0)
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX 980
major: 5 minor: 2 memoryClockRate (GHz) 1.253
pciBusID 0000:03:00.0
Total memory: 4.00GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:03:00.0)
/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py:370: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  out.itemset((i, y), 1.0)
Step #99, avg. train loss: 2.22587, avg. val loss: 2.14521
Step #199, avg. train loss: 0.82641, avg. val loss: 0.89103
Step #299, avg. train loss: 0.78344, avg. val loss: 0.85636
Step #399, avg. train loss: 0.76420, avg. val loss: 0.85675
Step #499, avg. train loss: 0.75868, avg. val loss: 0.84104
Step #599, avg. train loss: 0.75467, avg. val loss: 0.84945
Step #699, avg. train loss: 0.73990, avg. val loss: 0.91238
Step #799, avg. train loss: 0.73400, avg. val loss: 0.92720
Step #899, avg. train loss: 0.72879, avg. val loss: 0.91054
Step #999, avg. train loss: 0.73448, avg. val loss: 0.89823
Step #1099, avg. train loss: 0.70125, avg. val loss: 0.91640
Step #1199, avg. train loss: 0.71879, avg. val loss: 0.90597
Step #1299, avg. train loss: 0.70713, avg. val loss: 0.90736
Step #1399, avg. train loss: 0.70023, avg. val loss: 0.91414
Step #1499, avg. train loss: 0.69566, avg. val loss: 0.91007
Step #1599, avg. train loss: 0.68030, avg. val loss: 0.92729
Step #1699, avg. train loss: 0.68919, avg. val loss: 0.91168
Step #1799, avg. train loss: 0.67088, avg. val loss: 0.91744
Step #1899, avg. train loss: 0.68732, avg. val loss: 0.88844
Step #1999, avg. train loss: 0.67585, avg. val loss: 0.88854

---

it generates the file .tfevents that have  4,8M size (attached)

when I connect to the machine using chrome as explorer I have data in graphs/histograms/ but nothing in events(No scalar data was found)

did I miss something to have loss logged ?

NB:I added 
`logging_ops.scalar_summary(""model_loss"", self._model_loss)`
in learn/python/learn/estimators/base.py  and the loss is appearing in tensorbord

Ps: I'm running on GPU machine using the last build [tensorflow](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/lastBuild/)
attached tfevents [my_model_1.zip](https://github.com/tensorflow/skflow/files/229812/my_model_1.zip)
"
2062,tf.cond not working with depedencies,"tf.cond seems to have a bug if one of the condition have a dependency. (Dependencies are run, whatever tf.cond arg is True or False).

To illustrate:

```
import tensorflow as tf

a = tf.Variable(0)
incr = a.count_up_to(1)

def todo_if_true():
  with tf.control_dependencies([incr]):
    return tf.identity(a)
def todo_if_false():
  return tf.identity(a)

g = tf.cond(tf.constant(False), todo_if_true, todo_if_false)
init = tf.initialize_all_variables()

with tf.Session() as sess:
  sess.run(init)
  print(sess.run(g))
```

Output:

```
1 #But should be 0
```
"
2061,no variable name in repr() of variables from tf.trainable_variables(),"`repr()` does not show names of variables obtained from `tf.trainable_variables()`
### Environment info

Operating System:
MacOSX Yosemite, Python3.5

If installed from sources, provide the commit hash:
nightly build a week ago from wheel
### Steps to reproduce

```
       scope = ""myscope""
       trainables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)
       ""OR""
       trainables = tf.trainable_variables()
       print(""trainable variables in scope '%s':\t%s"" % (scope, [""%s"" % repr(x) for x in trainables] ) )
       ""trainable variables in scope 'model/states':    ['<tensorflow.python.ops.variables.Variable object at 0x10bb3a518>', '<tensorflow.python.ops.variables.Variable object at 0x10bb3aa20>']""
       print(""trainable variables in scope '%s':\t%s"" % (scope, [""%s"" % repr(x.name) for x in trainables] ) )
       ""scope/name ...""
```
"
2060,ResourceExhaustedError: When using VGG16 model architecture and training on own images,
2057,Word2Vec model crashes with unicode train data,"### Environment info

Operating System: OS X 10.11.3

Installed version of CUDA and cuDNN: CUDA-7.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
/Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
/Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
/Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a

If installed from binary pip package, provide: 0.8.0rc0
### Steps to reproduce
1. Clone folder https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/models/embedding/
2. Run successful python word2vec_optimized.py --train_data=questions-words.txt --eval_data=questions-words.txt --save_path=model/
3. Run failed if i add some unicode text in train data (e.g. russian word """")
### Logs or other output that would be helpful

Traceback (most recent call last):
  File ""../lib/word2vec/word2vec_optimized.py"", line 431, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""../lib/word2vec/word2vec_optimized.py"", line 416, in main
    model = Word2Vec(opts, session)
  File ""../lib/word2vec/word2vec_optimized.py"", line 146, in **init**
    self.save_vocab()
  File ""../lib/word2vec/word2vec_optimized.py"", line 242, in save_vocab
    opts.vocab_counts[i]))
UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-5: ordinal not in range(128)
"
2056,"error with ""import tensorflow; print(tensorflow.__version__)""","Why the fuck is this not in assembly? What happened to the good old days where people couldn't just drag and drop chunks of code? Anti-Fortran Elitist scum. Viva la resistance. This is why bush did 9/11 3========D~~~~~~ ps. I bounced to my boys dick while writing this. #TrumpForPresident #MakeAssemblyGreatAgain #HuckFitler #WhyDoesEveryoneHateHitler? #Cornflakes 
"
2055,libpthread.so was not created => can't build Android example,"I don't know if it is a tensorflow bug, a bazel bug or a misconfiguration on my side (maybe with SDK/NDK) but could you guys just have a short look at my stackoverflow issue: http://stackoverflow.com/q/36731061/828184

Here the errors (also can be seen on stackoverflow):

> ERROR: /home/administrator/TensorFlow_Git/tensorflow/examples/android/BUILD:41:1: output 'tensorflow/examples/android/libpthread.so' was not created.
> 
> ERROR: /home/administrator/TensorFlow_Git/tensorflow/examples/android/BUILD:41:1: not all outputs were created.

Sorry for cross-posting but I waited a while, would really need this and don't even know if stackoverflow is the right address at this point.
"
2054,Manual placement on GPU of a custom operator with both CPU and GPU implementation will always run the CPU version,"### Environment info

Operating System: ubuntu 14.04 64-bit

Installed version of CUDA and cuDNN: 7.5 and 4
$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:
1. Which pip package you installed. tensorflow==0.8.0rc0
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
python -c ""import tensorflow; print(tensorflow.**version**)""
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0rc0
### Steps to reproduce
1. Modify the How-to example cuda_op_kernel.cc to create both a CPU and GPU implementation for the AddOneOp operator
2. Make the GPU version do a different operation - I added 2 instead of 1 - so you can verify which version is running
3. Change the input and output type from int32 to float. This step is bizarre but critical!
4. Test the operator with manual placement - ie. with tf.device('/gpu:0'). This has to be done NOT in the self.test_session as in the example, but rather with a regular tf session - ie:  with tf.Session(config=tf.ConfigProto(log_device_placement=True)). This step is also critical. The tf.test.TestCase.test_session()  masks the issue. 
5. The operator will run the CPU version despite the placer saying it is being placed on the GPU and the test fails. 
   $ python cuda_op_unittest.py 
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
   I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
   name: GeForce GTX TITAN
   major: 3 minor: 5 memoryClockRate (GHz) 0.928
   pciBusID 0000:05:00.0
   Total memory: 6.00GiB
   Free memory: 5.29GiB
   I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
   I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
   I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0)
   Device mapping:
   /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0
   I tensorflow/core/common_runtime/direct_session.cc:149] Device mapping:
   /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0

AddOne/input: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:388] AddOne/input: /job:localhost/replica:0/task:0/gpu:0
AddOne: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:388] AddOne: /job:localhost/replica:0/task:0/gpu:0
**\* running on CPU ***
# F
## FAIL: test (**main**.AddOneTest)

Traceback (most recent call last):
  File ""cuda_op_unittest.py"", line 30, in test
    assert allclose(result.eval(), [7.0, 6.0, 5.0, 4.0, 3.0])
AssertionError

---

Ran 1 test in 0.342s

FAILED (failures=1)
### What have you tried?

We first noticed this on a much more complicated custom operator. This is a regression from the tensorflow version 0.7.1, which worked for us. The steps above are the result of several days spent trying to reproduce the problem with a minimal operator. The critical things seem to be using floats instead of ints and using the standard session instead of the tf test one. 

Note also, that if I comment out the REGISTER_KERNEL_BUILDER line for the CPU and try to run only on the gpu device, the test passes, but the executor is still trying to create a CPU version. Log looks like:
$ python cuda_op_unittest.py 
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN
major: 3 minor: 5 memoryClockRate (GHz) 0.928
pciBusID 0000:05:00.0
Total memory: 6.00GiB
Free memory: 5.29GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0)
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0
I tensorflow/core/common_runtime/direct_session.cc:149] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0

AddOne/input: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:388] AddOne/input: /job:localhost/replica:0/task:0/gpu:0
AddOne: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:388] AddOne: /job:localhost/replica:0/task:0/gpu:0
E tensorflow/core/common_runtime/executor.cc:332] Executor failed to create kernel. Not found: No registered 'AddOne' OpKernel for CPU devices compatible with node AddOne = AddOne[_device=""/job:localhost/replica:0/task:0/gpu:0""](AddOne/input)
     [[Node: AddOne = AddOne[_device=""/job:localhost/replica:0/task:0/gpu:0""](AddOne/input)]]
**\* running on GPU ***
## .

Ran 1 test in 0.552s

OK
### Logs or other output that would be helpful

attaching source files. To build I do:
/usr/local/cuda/bin/nvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc -I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC
g++ -std=c++11 -shared -o cuda_op_kernel.so cuda_op_kernel.cc cuda_op_kernel.cu.o -I $TF_INC -fPIC -Wl,-rpath .
python cuda_op_unittest.py

I am running python 2.7. 

[cuda_op.tar.gz](https://github.com/tensorflow/tensorflow/files/230677/cuda_op.tar.gz)
"
2053,Failed to build from source due to missing libcudart.so.7.5:,"Hi! I tried to compile the tutorials_example_trainer file, and I have quite a journey behind me. I recompiled GCC several times, I recompiled bazel dozens of times and did a fair share of CROSSTOOLS editing.
At this point, I am stuck. The compliation fails with the message:

`bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc: error while loading shared libraries: libcudart.so.7.5: cannot open shared object file: No such file or directory
Target //tensorflow/cc:tutorials_example_trainer failed to build`

I am using Tensorflow HEAD (currently 7b536cd5cfdbfd0fbc80496a38624557fb977783), I have CUDA 7.5 installed in /usr/local/cuda-7.5 .

My LD_LIBRARY_PATH is set to :/usr/local/cuda/lib64:/usr/local/cuda/lib64 , and the files exist there.
I tried to point bazel to the library directory by adding 

`+  linker_flag: ""-L/usr/local/cuda/lib64""`
.
### Environment info

Operating System: Fedora 23

Installed version of CUDA and cuDNN: 7.5 and 4.0.7

```
$ ls /usr/local/cuda-7.5/lib64/libcud*
/usr/local/cuda-7.5/lib64/libcudadevrt.a    /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18  /usr/local/cuda-7.5/lib64/libcudnn.so.4
/usr/local/cuda-7.5/lib64/libcudart.so      /usr/local/cuda-7.5/lib64/libcudart_static.a   /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7
/usr/local/cuda-7.5/lib64/libcudart.so.7.5  /usr/local/cuda-7.5/lib64/libcudnn.so          /usr/local/cuda-7.5/lib64/libcudnn_static.a
```

If installed from sources, provide the commit hash: 7b536cd5cfdbfd0fbc80496a38624557fb977783
### Steps to reproduce
1. Recompiled Bazel, version 0.2.1 with the following patch: https://gist.github.com/akors/5db13e874c144b3b111f0e0326d7b771#file-bazel-custom-gcc-patch
2. Applied the following patch to TensorFlow: https://gist.github.com/akors/5db13e874c144b3b111f0e0326d7b771#file-tensorflow-custom-gcc-patch
3. Ran ./configure with /opt/gcc-4.9/bin/gcc as compiler, but default otherwise.
4. Ran bazel build -c opt --config=cuda --local_resources 4096,3.0,1.0 -j 4 //tensorflow/cc:tutorials_example_trainer --verbose_failures
### What have you tried?
1. I cried a lot.
2. Add `linker_flag: ""-L/usr/local/cuda/lib64""` to `third_party/gpus/crosstool/CROSSTOOL`
3. Add `linker_flag: ""-Wl,-R/usr/local/cuda/lib64""`  to `third_party/gpus/crosstool/CROSSTOOL`
4. Recompile bazel, with added `linker_flag: ""-Wl,-R/usr/local/cuda/lib64""` in `tools/cpp/CROSSTOOL`
5. Create a file `/etc/ld.so.conf.d/LOCAL_cuda-lib64.conf` with the contents `/usr/local/cuda/lib64` and ran `ldconfig`
### Logs or other output that would be helpful

Here's the full output of the last operation:

```
ERROR: /home/alexander/.local/src/tensorflow/tensorflow/cc/BUILD:28:1: Executing genrule //tensorflow/cc:random_ops_genrule failed: namespace-sandbox failed: error executing command 
  (cd /home/alexander/.cache/bazel/_bazel_alexander/3fc3a90944d6c7fe99106d6e515412c7/tensorflow && \
  exec env - \
    PATH=/usr/lib/ccache:/usr/lib/ccache:/usr/lib64/qt-3.3/bin:/usr/lib64/ccache:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/home/alexander/.local/bin:/home/alexander/bin:/home/alexander/.local/bin:/home/alexander/bin \
  /home/alexander/.cache/bazel/_bazel_alexander/3fc3a90944d6c7fe99106d6e515412c7/tensorflow/_bin/namespace-sandbox @/home/alexander/.cache/bazel/_bazel_alexander/3fc3a90944d6c7fe99106d6e515412c7/tensorflow/bazel-sandbox/7d27406c-6595-46a2-a8dc-b7faf7c28c88-0.params -- /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc bazel-out/local_linux-opt/genfiles/tensorflow/cc/ops/random_ops.h bazel-out/local_linux-opt/genfiles/tensorflow/cc/ops/random_ops.cc 0').
bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc: error while loading shared libraries: libcudart.so.7.5: cannot open shared object file: No such file or directory
Target //tensorflow/cc:tutorials_example_trainer failed to build
INFO: Elapsed time: 630.365s, Critical Path: 137.07s
```

ps.: Out of curiosity, what are you TensorFlow devs using for a development machine? Has any of you actually tried using a modern Linux distribution that comes with GCC newer than 4.9 for compilation? You really should. It's quite the experience.
"
2051,"Document the type of ""feed_dict"" values","Seems undocumented in session, came up in http://stackoverflow.com/questions/36758114/valueerror-setting-an-array-element-with-a-sequence-when-using-feed-dict-in-ten
"
2050,TensorBoard: Refresh Backend when the frontend refreshes,"Tensorboard seems to scan the log infrequently. Right now, I have to kill and re-start the server to make it re-scan the log. Could we have tensorboard re-scan the log when the tensorboard webpage is refreshed?
"
2049,FCN Crop Layer,"Hi all,

I am currently trying to implement FCN for semantic segmentation in TensorFlow as it was previously done in Caffe here https://github.com/shelhamer/fcn.berkeleyvision.org.

Unfortunately I'm struggling with following 3 things:

1) How to map `Deconvolution` layer from Caffe to TensorFlow? But I guess that I have found the solution in `tf.nn.conv2d_transpose`?
2) How to map `Crop` layer from Caffe to TensorFlow? **Unfortunately I can't see any alternative in TensorFlow. Is there equivalent for this?**
3) Does Caffe `SoftmaxWithLoss` correspond to TensorFlow softmax_cross_entropy_with_logits?

Thank you in advance for any advices, hints and help.
"
2048,"Input to reshape is a tensor with 4889 values, but the requested shape has 4800","Operating System:Ubuntu 14.04
1.I fixed my images to 200*200 .jpg,and stored into TFRecord file
2.I read TFR file and try to train in cifar10 model,it raised error:
Input to reshape is a tensor with 4889 values, but the requested shape has 4800
on :`depth_major = tf.reshape(image,[result.depth, result.height, result.width])`
It seems cause of diffrent of images' buffer size?
Should I  fix the sizes before put into TFR file?
"
2047,Not found: Could not find session factory for DIRECT_SESSION,"Operating System:  Android

because my android system is below Android 5.0, so I rebuild the tensorflow librarys for android with NDK android-11.  the building is success.   

then,  with these librarys, I write a android demo.  But when I run, it output the message ...

```
  **Not found: Could not find session factory for DIRECT_SESSION**
```

I don't know, what's wrong with my works.
"
2046,Segment fault after upgrade the protobuf for >64MB limit,"### Environment info

Operating System:  CentOS Linux release 7.2.1511 (Core)

Installed version of CUDA and cuDNN: 

```
-rw-r--r--. 1 root root   322936 4   5 01:42 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx. 1 root root       16 4   5 01:42 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx. 1 root root       19 4   5 01:42 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x. 1 root root   383336 4   5 01:42 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r--. 1 root root   720192 4   5 01:42 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x. 1 root root 61453024 4  19 05:36 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x. 1 root root 61453024 4  19 05:36 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x. 1 root root 61453024 4  19 05:36 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rwxr-xr-x. 1 root root 11172416 4  12 01:12 /usr/local/cuda/lib64/libcudnn.so.6.5
-rwxr-xr-x. 1 root root 11172416 4  12 01:12 /usr/local/cuda/lib64/libcudnn.so.6.5.48
-rwxr-xr-x. 1 root root 48217000 4  19 05:36 /usr/local/cuda/lib64/libcudnn.so.7.0
-rwxr-xr-x. 1 root root 48217000 4  19 05:36 /usr/local/cuda/lib64/libcudnn.so.7.0.64
-rw-r--r--. 1 root root 62025862 4  19 05:36 /usr/local/cuda/lib64/libcudnn_static.a

```
### Steps to reproduce
1. Install the tensorflow 0.8.0rc0
   pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl
2. Upgrade the protobuf
   pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/protobuf-3.0.0b2.post2-cp27-none-linux_x86_64.whl
3. ""import tensorflow"" will have segment fault
   No segment fault if not upgrade the protobuf.

The core info is:
`(gdb) bt
#0  0x00007f9606e2a2f1 in std::__detail::_Map_base<google::protobuf::Descriptor const*, std::pair<google::protobuf::Descriptor const* const, google::protobuf::DynamicMessage::TypeInfo const*>, std::allocator<std::pair<google::protobuf::Descriptor const* const, google::protobuf::DynamicMessage::TypeInfo const*> >, std::__detail::_Select1st, std::equal_to<google::protobuf::Descriptor const*>, google::protobuf::hash<google::protobuf::Descriptor const*>, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true>, true>::operator[](google::protobuf::Descriptor const* const&) () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#1  0x00007f9606e2a3d3 in google::protobuf::DynamicMessageFactory::GetPrototypeNoLock(google::protobuf::Descriptor const*) ()

   from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#2  0x00007f9606e2b02a in google::protobuf::DynamicMessageFactory::GetPrototype(google::protobuf::Descriptor const*) () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007f95ee4f5129 in google::protobuf::python::cmessage::New (cls=<optimized out>, unused_args=<optimized out>, unused_kwargs=<optimized out>) at google/protobuf/pyext/message.cc:1255
#4  0x00007f9618131d23 in type_call () from /lib64/libpython2.7.so.1.0
#5  0x00007f96180dc0b3 in PyObject_Call () from /lib64/libpython2.7.so.1.0
#6  0x00007f961817025c in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0
#7  0x00007f96181740bd in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0
#8  0x00007f96181741c2 in PyEval_EvalCode () from /lib64/libpython2.7.so.1.0
#9  0x00007f9618183fac in PyImport_ExecCodeModuleEx () from /lib64/libpython2.7.so.1.0
#10 0x00007f9618184228 in load_source_module () from /lib64/libpython2.7.so.1.0`

I also reported the problem here: [tensorflow_serving issue](https://github.com/tensorflow/serving/issues/24)
"
2045,TypeError('{!r} is not a Python function'.format(func)),"When I import tensorflow, It raise an error like this(the newest version of tensorflow via pip installtaion)

`
/usr/bin/python2.7 /home/dell/wxm/Code/ImageCaption-tensorflow/test.py
Traceback (most recent call last):
  File ""/home/dell/wxm/Code/ImageCaption-tensorflow/test.py"", line 3, in <module>
    import tensorflow as tf
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/**init**.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py"", line 62, in <module>
    import tensorflow.contrib as contrib
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/**init**.py"", line 26, in <module>
    from tensorflow.contrib import learn
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/**init**.py"", line 20, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/**init**.py"", line 20, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/**init**.py"", line 22, in <module>
    from tensorflow.contrib.learn.python.learn.io import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/**init**.py"", line 20, in <module>
    from tensorflow.contrib.learn.python.learn.io.dask_io import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/dask_io.py"", line 23, in <module>
    import dask.dataframe as dd
  File ""/usr/local/lib/python2.7/dist-packages/dask/dataframe/**init**.py"", line 1, in <module>
    from .core import (DataFrame, Series, Index, _Frame, map_partitions,
  File ""/usr/local/lib/python2.7/dist-packages/dask/dataframe/core.py"", line 1234, in <module>
    class Index(Series):
  File ""/usr/local/lib/python2.7/dist-packages/dask/dataframe/core.py"", line 1266, in Index
    @derived_from(pd.Index)
  File ""/usr/local/lib/python2.7/dist-packages/dask/utils.py"", line 526, in wrapper
    original_args = getargspec(original_method).args
  File ""/usr/local/lib/python2.7/dist-packages/dask/compatibility.py"", line 190, in getargspec
    return _getargspec(func)
  File ""/usr/local/lib/python2.7/dist-packages/dask/compatibility.py"", line 56, in _getargspec
    return inspect.getargspec(func)
  File ""/usr/lib/python2.7/inspect.py"", line 816, in getargspec
    raise TypeError('{!r} is not a Python function'.format(func))
TypeError: <method 'max' of 'numpy.ndarray' objects> is not a Python function

Process finished with exit code 1
`
"
2044,inception,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2041,power activation function,"Hi, I am a newbie with Tensorflow. I just found there is no power activation function existing in Tensorflow? How can I implement a new activation function in TF?
"
2040,building pip package issue,"```
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
2016 04 21  07:34:12 CST : === Using tmpdir: /tmp/tmp.cMsLMGw3bz
cp: cannot stat bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/tensorflow: No such file or directory
cp: cannot stat bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/external: No such file or directory
```
"
2039,latest-gpu Docker image has broken cudnn,"Running import tensorflow:

> > > import tensorflow
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcudnn.so. LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:
> > > I tensorflow/stream_executor/cuda/cuda_dnn.cc:1562] Unable to load cuDNN DSO
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally

Note that this seems to work with the latest-devel-gpu image. As far as I can tell the problem is caused by a missing symlink from /usr/lib/x86_64-linux-gnu/libcudnn.so to /usr/lib/x86_64-linux-gnu/libcudnn.so.4
"
2037,NaN problem on tutorials_example_trainer with tensorflow 0.8,"I worked for several months on versions of tensorflow installed from sources. Today, I tried to upgrade it to 0.8. The installation seemed to go fine.  ""bazel-bin/tensorflow/cc/tutorials_example_trainer"" gave the expected result. However, the output of ""bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu"" is unexpected: the first lines seem to be fine but then NaN values appear, the proportion of NaN values increases until there is nothing but NaN values (see the first half of the output here http://pastebin.com/EhuD2Z5S , the remaining lines are only ""nan"" lines which I omitted because the total output exceeded pastebin limit).

I expected this tutorials_example_trainer to either work seamlessly or not at all (if I provided wrong paths for CUDA and CuDNN), but this in-between puzzles me.

I tried to debug it with my own programs, but I can not import tensorflow :

```
import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 45, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name pywrap_tensorflow
```

I am not sure whether the two problems are related.

In the case I made a mistake during configuration, I typed:

```
matthieu@gpu2:~/external/tensorflow$ ./configure 
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.0
Please specify the location where CUDA 7.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 4
Please specify the location where cuDNN 4 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 
Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Setting up CUPTI include
Setting up CUPTI lib64
Configuration finished""
```

I hope this issue belongs here, else I will try stackoverflow.

Thanks in advance,
### Environment info

I work on ubuntu 14.04

With CUDA 7.0 and cuDNN 4

```
ls /usr/local/cuda-7.0/lib/libcud*        
/usr/local/cuda-7.0/lib/libcudadevrt.a  /usr/local/cuda-7.0/lib/libcudart.so.7.0     /usr/local/cuda-7.0/lib/libcudart_static.a
/usr/local/cuda-7.0/lib/libcudart.so    /usr/local/cuda-7.0/lib/libcudart.so.7.0.28
```

Commit hash: e1c017624fd6bd8562c1da27e0014b32f389b524
"
2035,how to build the project for intel x86 emulator instead of armeabi v7?,"Hi, I am beginner in android,

  I have successfully built the android demo with bazel. Now I am trying to work with it in Android studio.

 I found this repository [https://github.com/miyosuda/TensorFlowAndroidDemo](url).
 It currently works well with **armeabiv7** but crashes with **intel x86**  emulator. 

But I want to build it for **intel x86 and x86_64** and I want to **build it in Android studio** using gradle what should I do? Please help

I am using 
                  NDK 10re 
                  Android Studio 2.0
                  UBUNTU 14.04
"
2034,segmentation fault,"I install tensorflow use:sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl

linux version is :Linux version 3.10.0-229.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.2 20140120 (Red Hat 4.8.2-16) (GCC) ) #1 SMP Fri Mar 6 11:36:42 UTC 2015

when I learn python, and import tensorflow,segmentation fault

> > > import tensorflow
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
> > > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
> > > Segmentation fault (core dumped)
"
2033,CudNN error running TensorFlow: Could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
$ ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 59823168 Apr 19 15:15 /usr/local/cuda-7.5/lib64/libcudnn.so
-rwxr-xr-x 1 root root 59823168 Apr 19 15:15 /usr/local/cuda-7.5/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 59823168 Apr 19 15:15 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.4
-rw-r--r-- 1 root root 58734618 Apr 19 15:15 /usr/local/cuda-7.5/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.8.0rc0
```

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?
1. When I run the deep convolutional nn tutorial from TensorFlow's website, I get the following error:

```
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow dev\
ice (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)
Successfully loaded: saved_networks/dqn-2920000
F tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter d\
escriptor: CUDNN_STATUS_BAD_PARAM
```
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
2031,python  trap divide error,"# Environment info

Operating System:CentOS 7
GCC version:4.8.5
Cuda Toolkit:7.5
Cuda compiler driver:6.5
Built with GPU
# What have you tried?
## I run /usr/lib/python2.7/site-packages/tensorflow/models/image/mnist/convolutional.py will print:Floating point exception

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: Tesla K40m
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:04:00.0
Total memory: 11.25GiB
Free memory: 3.08GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0)
Failed to get the number of CUDA devices: CUDA driver version is insufficient for CUDA runtime version
Floating point exception
## I view the system message:

Apr 20 10:53:43 milan kernel: traps: python[66624] trap divide error ip:7fc0113304d2 sp:7fbf74ff0170 error:0 in _pywrap_tensorflow.so[7fc00f573000+a38a000]
"
2030,Pass grid search params to TensorFlowEstimator custom model,"GridSearchCV is a great way to test and optimize hyper-parameters automatically. I use it with TensorFlowEstimator to optimize learning_rate, batch_size, ...etc. It would be a great addition if I can also use it to customize other parameters in my custom model. 

For example, say I have a custom model with a convnet and I want to optimize the stride value. This **pseudo code** explains what I'm trying to achieve. 

**I used a custom ""params"" input to the model function just as an example, not to imply that this is necessarily the right way to implement this feature.**

```
# My custom model. 
# Feature request: New params dict with values filled by GridSearchCV
def cnn_model(X, Y, params):
  stride = params['stride']
  ... custom model definition here ...

# Create the Convnet classifier
cnn_classifier = learn.TensorFlowEstimator(model_fn=cnn_model)

# Grid search on different stride values.
parameters = {'stride': [1, 2, 3],}
grid_searcher = GridSearchCV(cnn_classifier, parameters)
grid_searcher.fit(X, Y)
```
"
2029,question about LSTM cell state size,"hi everyone:
with the config as below for a BasicLSTM cell:

```
   init_scale = 0.05
learning_rate = 0.01
max_grad_norm = 5
num_layers = 2
num_steps = 10
hidden_size = 200
keep_prob = 0.5
lr_decay = 0.8
batch_size = 30  
```

I use 2-hidden layers model:

lstm_cell = rnn_cell.BasicLSTMCell(hidden_size, forget_bias=0.0)
cell = rnn_cell.MultiRNNCell([lstm_cell] \* 2)

Then: What is the cell.state_size?
I got it as 30 x 800, but I can't understand how it come to?
"
2025,Constraint optimization?,"Hello! Are there any plans for adding constraints to trainable variables? If not, I'd like to request it. Thanks!
"
2021,bazel not respecting PYTHONPATH,"### Environment info

Operating System: Fedora 23

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
Built without GPU

If installed from sources, provide the commit hash:
c303ff7
### Steps to reproduce
1.  bazel --output_base=/projects/.cache test //tensorflow/...
### What have you tried?
1.  starting python from command line and import tensorflow is ok.
2.  the above command line produces tests shown below in the pastebin in the log section
3.  echo $PYTHONPATH
   /usr/local/lib/python3.4/site-packages:/projects/.cache/tensorflow/bazel-out/local_linux-fastbuild/bin/tensorflow/tools/pip_package/build_pip_package.runfiles
4.  I think there is an imports function recently added for bazel, would like some pointers to see if this is the best way to solve this problem and change all the bazel files (and not commit them to pull requests), or if there are better ways.
   http://bazel.io/docs/be/python.html
5. (EDIT) #1704 following comments did not work.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
http://pastebin.com/hTw53y2X
"
2017,Tensor Forest regression,"I was not able to find any documentation for Tensor Forest, however from the comment on line 90 in [tensor_forest.py](https://github.com/tensorflow/tensorflow/edit/master/tensorflow/contrib/tensor_forest/python/tensor_forest.py) it seems to follow that it is intended for regression as well as classification. However it does not accept floats as labels.

The following code:
`params = tensor_forest.ForestHParams(num_classes=1, num_features=features, num_trees=10, max_nodes=1000).fill()`
`graph_builder = tensor_forest.RandomForestGraphs(params)`
`graph = graph_builder.training_graph(X, y)`

Returns a value error:
`TypeError:  Input 'input_labels' of 'CountExtremelyRandomStats' Op has type float32 that does not match expected type of int32.`
"
2016,cuda 7.5 // AttributeError: type object 'NewBase' has no attribute 'is_abstract',"Hello everyone,

   have the following problem after the tensorflow installation via pip:

`>>> import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 94, in <module>
    from tensorflow.python.platform import test
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/test.py"", line 62, in <module>
    from tensorflow.python.framework import test_util
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/test_util.py"", line 41, in <module>
    from tensorflow.python.platform import googletest
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/googletest.py"", line 32, in <module>
    from tensorflow.python.platform import benchmark  # pylint: disable=unused-import
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/benchmark.py"", line 112, in <module>
    class Benchmark(six.with_metaclass(_BenchmarkRegistrar, object)):
  File ""/usr/lib/python2.7/dist-packages/six.py"", line 617, in with_metaclass
    return meta(""NewBase"", bases, {})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/benchmark.py"", line 107, in __new__
    if not newclass.is_abstract():
AttributeError: type object 'NewBase' has no attribute 'is_abstract'`

I'm using Nvidia GTX Titan X (comp. capability 5.2) and CUDA 7.5. Does anybody have an idea?

Many thanks in advance for your help!

Cheers,
A
"
2015,recurrent layer on top of convolution layer fails with GPU,"### Environment info

Operating System: Ubuntu 15.04

Installed version of CUDA and cuDNN: 
CUDA 7.5
cuDNN 5.0.4
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root 189170 Oct 10  2015 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Oct 10  2015 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Oct 10  2015 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Oct 10  2015 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Oct 10  2015 /usr/local/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
   pip list
   tensorflow (0.7.1)
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.7.1
### Problem description

I simply try to put a recurrent layer on top of a convolution layer, which directly manipulate the inputs. It is ok with cpu, but fails with gpu. When i remove either the convolution layer or the recurrent layer, it works well with gpu. 

The error message is 

> python: external/eigen_archive/eigen-eigen-3f653ace7d28/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:223: static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, false>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long int>, 16>, const Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, const Eigen::TensorReductionOpEigen::internal::SumReducer<float, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<const float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16> > > > >]: Assertion `cudaGetLastError() == cudaSuccess' failed.

I run some black-box test (as i don't know a better way to debug it), and found that it raises error when it try to compute gradients with the statement 
`grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),
                                      config.max_grad_norm)
`

The following is a simplified version of the code which has the same problem. (There ought to be a softmax layer on top of the recurrent layer, but i replace it with sum to make it simpler)

```
import numpy as np
import tensorflow as tf

import sys
sys.path.append('/home/jiahua/tensorflow')
import math
import time

from tensorflow.contrib.ctc import ctc_ops
from tensorflow.python.ops import rnn_cell
from tensorflow.python.ops import rnn
from conv_batch_normalizer import ConvolutionalBatchNormalizer

import load_data

class Model(object):

  def __init__(self, is_training, config):
    self._batch_size = batch_size = config.batch_size
    self._freq_size = freq_size = config.freq_size
    self._hidden_size = hidden_size = config.hidden_size
    self._seq_max_length = seq_max_length = config.seq_max_length

    num_channels = 10
    filter_dimension = 2
    conv_stride = 2

    self._inputs = inputs = tf.placeholder(tf.float32, [batch_size, seq_max_length, freq_size]) 
    self._sequence_lengths = sequence_lengths = tf.placeholder(tf.int32, [batch_size])
    inputs = tf.reshape(inputs, [batch_size, seq_max_length, freq_size, 1])

    padding_size = filter_dimension - (seq_max_length - 1)  % conv_stride - 1 
    print 'padding_size', padding_size
    paddings = [[0, 0], [0, padding_size], [0, 0], [0, 0]]
    inputs = tf.pad(inputs, paddings)

    if is_training and config.keep_prob < 1:
      inputs = tf.nn.dropout(inputs, config.keep_prob)
    print 'inputs', tf.Tensor.get_shape(inputs)

    parameters = []
    # conv1
    with tf.name_scope('conv1') as scope:
      kernel = tf.Variable(tf.truncated_normal([filter_dimension, freq_size, 1, num_channels], dtype=tf.float32, stddev=1e-1), name='weights')
      conv = tf.nn.conv2d(inputs, kernel, [1, conv_stride, conv_stride, 1], padding='VALID')
      biases = tf.Variable(tf.constant(0.0, shape=[num_channels], dtype=tf.float32), trainable=True, name='biases')
      bias = tf.nn.bias_add(conv, biases)
      conv1 = tf.nn.relu(bias, name=scope)
      parameters += [kernel, biases]

    # batch normalization
    print 'conv1', tf.Tensor.get_shape(conv1)

    inter1 = tf.reshape(conv1, [batch_size, -1, 1, num_channels])
    print 'inter1', tf.Tensor.get_shape(inter1)

    new_length = (seq_max_length + padding_size - filter_dimension) / conv_stride + 1
    print 'new length = ', new_length 

    # rnn
    rnn_inputs = tf.reshape(inter1, [batch_size, new_length, num_channels])
    print 'rnn_inputs', tf.Tensor.get_shape(rnn_inputs)

    lstm_cell = rnn_cell.BasicLSTMCell(hidden_size, forget_bias=0.0)
    if is_training and config.keep_prob < 1:
      lstm_cell = rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=config.keep_prob)
    cell = rnn_cell.MultiRNNCell([lstm_cell] * 2)

    self._initial_state = cell.zero_state(batch_size, tf.float32)

    rnn_outputs = []
    state = self._initial_state
    with tf.variable_scope(""rnn""):
      for time_step in range(new_length):
        if time_step > 0: tf.get_variable_scope().reuse_variables()
        (cell_output, state) = cell(rnn_inputs[:, time_step, :], state)
        rnn_outputs.append(cell_output)

    print 'rnn_outputs ', tf.Tensor.get_shape(rnn_outputs[0]) , ' * ', len(rnn_outputs)
    self._final_state = state

    self._cost = cost = tf.reduce_sum(tf.add_n(rnn_outputs)) / batch_size

    if not is_training:
      return

    self._lr = tf.Variable(0.0, trainable=False)
    tvars = tf.trainable_variables()
    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),
                                      config.max_grad_norm)

    optimizer = tf.train.GradientDescentOptimizer(self._lr)
    self._train_op = optimizer.apply_gradients(zip(grads, tvars))


  def assign_lr(self, session, lr_value):
    session.run(tf.assign(self._lr, lr_value))

  @property
  def input_data(self):
    return self._input_data

  @property
  def cost(self):
    return self._cost

  @property
  def final_state(self):
    return self._final_state

  @property
  def lr(self):
    return self._lr

  @property
  def train_op(self):
    return self._train_op

  @property
  def predict(self):
    return self._predict


class Config(object):
  batch_size = 2
  freq_size = 2
  hidden_size = 2
  seq_max_length = 5
  init_scale = 1.0
  lr_decay = 0.5
  max_epoch = 10
  max_max_epoch = 100
  keep_prob = 0.9
  max_grad_norm = 5
  learning_rate = 1


def run_epoch(session, m, data, eval_op):
  start_time = time.time()
  iters = 0
  costs = 0.0
  state = m._initial_state.eval()
  for (inputs, labels_indices, labels_values, labels_shape, seq_lens) in data:
    cost, state, _ = session.run([m._cost, m._final_state, eval_op],
                                 {m._inputs: inputs,
                                  m._initial_state: state})
    costs += cost
    iters += 1
    if iters % 1 == 0:
      print iters
      print ""time: %f"" % (time.time() - start_time)
      print ""cost: %f"" % cost
  print 'finish'
  print ""total time: %f"" % (time.time() - start_time)
  return costs / iters
  return 0.0


def main():
  config = Config()
  with tf.Graph().as_default(), tf.Session() as session:
    initializer = tf.random_uniform_initializer(-config.init_scale,
                                                config.init_scale)
    with tf.variable_scope(""model"", reuse=None, initializer=initializer):
      m = Model(is_training=True, config=config)
    init_op = tf.initialize_all_variables()
    session.run(init_op)

    train_data = [([[[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]], [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]]], [[0, 0], [0, 1], [1, 0], [1, 1]], [0, 1, 1, 2], [2, 2], [2, 2])]
    for i in range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i - config.max_epoch, 0.0)
      print '#iter %d start lr: %f' % (i, config.learning_rate * lr_decay)
      m.assign_lr(session, config.learning_rate * lr_decay)

      print 'average loss: %f' % (run_epoch(session, m, train_data, m._train_op))


if __name__ == ""__main__"":
  main()
```
### What have you tried?

Below is the stack status printed using gdb python, in case you want to look at it. It seems that there is a problem when it tries to launch a cuda kernel to compute the l2loss.

> # 0  0x00007ffff7826267 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:55
> # 1  0x00007ffff7827eca in __GI_abort () at abort.c:89
> # 2  0x00007ffff781f03d in **assert_fail_base (fmt=0x7ffff7981028 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", assertion=assertion@entry=0x7fffe3c03fe8 ""cudaGetLastError() == cudaSuccess"", file=file@entry=0x7fffe3c03f80 ""external/eigen_archive/eigen-eigen-3f653ace7d28/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h"", line=line@entry=223, function=function@entry=0x7fffe3c04180 <Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const> const, Eigen::GpuDevice, false>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const> const&, Eigen::GpuDevice const&)::__PRETTY_FUNCTION**> ""static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, false>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen:""...) at assert.c:92
> # 3  0x00007ffff781f0f2 in **GI___assert_fail (assertion=0x7fffe3c03fe8 ""cudaGetLastError() == cudaSuccess"", file=0x7fffe3c03f80 ""external/eigen_archive/eigen-eigen-3f653ace7d28/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h"", line=223, function=0x7fffe3c04180 <Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const> const, Eigen::GpuDevice, false>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const> const&, Eigen::GpuDevice const&)::__PRETTY_FUNCTION**> ""static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, false>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen:""...) at assert.c:101
> # 4  0x00007fffe2487e26 in Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const> const, Eigen::GpuDevice, false>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const> const&, Eigen::GpuDevice const&) (expr=..., device=...) at external/eigen_archive/eigen-eigen-3f653ace7d28/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:223
> # 5  0x00007fffe24879ea in Eigen::TensorDevice<Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>, Eigen::GpuDevice>::operator=Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> >(Eigen::TensorCwiseUnaryOpEigen::internal::scalar_multiple_op<float, Eigen::TensorReductionOpEigen::internal::SumReducer<float, Eigen::DimensionList<long, 1ul> const, Eigen::TensorCwiseUnaryOp<Eigen::internal::scalar_square_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16> const> const> const> const&) (this=0x7fff357f91c0, other=...) at external/eigen_archive/eigen-eigen-3f653ace7d28/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35
> # 6  0x00007fffe248785a in tensorflow::functor::L2Loss<Eigen::GpuDevice, float>::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16>, Eigen::TensorMap<Eigen::TensorFixedSize<float, Eigen::Sizes<>, 1, long>, 16>) (this=0x7fff357f9250, d=..., input=..., output=...) at ./tensorflow/core/kernels/l2loss_op.h:32
> # 7  0x00007fffe247ee64 in tensorflow::L2LossOp<Eigen::GpuDevice, float>::Compute (this=0x402f9e0, context=0x7fff357f9b20) at tensorflow/core/kernels/l2loss_op.cc:45
> # 8  0x00007fffe293d927 in tensorflow::BaseGPUDevice::Compute (this=0x3dc5b60, op_kernel=0x402f9e0, context=0x7fff357f9b20) at tensorflow/core/common_runtime/gpu/gpu_device.cc:388
> # 9  0x00007fffe2b61689 in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0x3facbc0, tagged_node=..., scheduled_usec=0) at tensorflow/core/common_runtime/executor.cc:1092
> # 10 0x00007fffe2b6cf89 in std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)>::operator()<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode&, long long&, void> (this=0x7fff200008c0, __object=0x3facbc0) at /usr/include/c++/4.9/functional:569
> # 11 0x00007fffe2b6c3dc in std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>::__call<void, 0ul, 1ul, 2ul>(<unknown type in /home/jiahua/tensorflow/bazel-bin/speech/model.runfiles/tensorflow/python/_pywrap_tensorflow.so, CU 0xdb55fb8, DIE 0xdbd4a7f>, std::_Index_tuple<0ul, 1ul, 2ul>) (this=0x7fff200008c0, __args=<unknown type in /home/jiahua/tensorflow/bazel-bin/speech/model.runfiles/tensorflow/python/_pywrap_tensorflow.so, CU 0xdb55fb8, DIE 0xdbd4a7f>) at /usr/include/c++/4.9/functional:1264
> # 12 0x00007fffe2b6aa38 in std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>::operator()<, void>(void) (this=0x7fff200008c0) at /usr/include/c++/4.9/functional:1323
> # 13 0x00007fffe2b68c54 in std::_Function_handler<void(), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)> >::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/4.9/functional:2039
> # 14 0x00007fffe0b01732 in std::function<void ()>::operator()() const (this=0x7fff357f9dd0) at /usr/include/c++/4.9/functional:2439
> # 15 0x00007fffe2da977a in tensorflow::thread::ThreadPool::Impl::WorkerLoop (this=0x3ddaa90) at tensorflow/core/lib/core/threadpool.cc:196
> # 16 0x00007fffe2da91bb in tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int)::{lambda()#1}::operator()() const () at tensorflow/core/lib/core/threadpool.cc:123
> # 17 0x00007fffe2da9b93 in std::_Function_handler<void(), tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&, const string&, int)::<lambda()> >::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/4.9/functional:2039
> # 18 0x00007fffe0b01732 in std::function<void ()>::operator()() const (this=0x3ddba58) at /usr/include/c++/4.9/functional:2439
> # 19 0x00007fffe2dcb472 in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x3ddba58) at /usr/include/c++/4.9/functional:1700
> # 20 0x00007fffe2dcb3b7 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x3ddba58) at /usr/include/c++/4.9/functional:1688
> # 21 0x00007fffe2dcb334 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x3ddba40) at /usr/include/c++/4.9/thread:115
> # 22 0x00007fffd4e4bf20 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
> # 23 0x00007ffff7bc26aa in start_thread (arg=0x7fff357fa700) at pthread_create.c:333
> # 24 0x00007ffff78f7eed in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109
"
2014,Tensorboard not showing anything ,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Mac OS
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
None installed.
If installed from binary pip package, provide:
1. Which pip package you installed.
   pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0rc0-py2-none-any.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0rc0
### Steps to reproduce
1. tensorboard --logdir=board 
### What have you tried?
1. checked things according to the instructions in ready.md
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/Users/jcyk/tensorflow/lib/python2.7/site-packages/tensorflow/tensorboard/TAG' on path /Users/jcyk/tensorflow/lib/python2.7/site-packages/tensorflow/tensorboard/TAG
WARNING:tensorflow:Unable to read TensorBoard tag
Starting TensorBoard  on port 6006
(You can navigate to http://0.0.0.0:6006)

[board.zip](https://github.com/tensorflow/tensorflow/files/225193/board.zip)
"
2013,Question:How does Tensorflow deal with numpy.nan values?,"1. raise error
2. treat them as empty: I would say this is the proper way but the developers have to some math works to let the codes work
3. treat them as zero
"
2011,mod operation missing on GPU,"To verify:

```

def run_summarize(run_metadata):
  print ""***""
  for device in run_metadata.step_stats.dev_stats:
    print device.device
    for node_stats in device.node_stats:
      print '   ', node_stats.node_name

def sessrun(*arglist, **dictlist):
  run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
  run_metadata = tf.RunMetadata()
  dictlist['options'] = run_options
  dictlist['run_metadata'] = run_metadata
  result = tf.get_default_session().run(*arglist, **dictlist)
  run_summarize(run_metadata)
  return result

tf.reset_default_graph()
sess = create_session()
a = tf.constant(10)
b = tf.constant(5)
c = a%b
sessrun(c)

***
/job:localhost/replica:0/task:0/cpu:0
    _SOURCE
    mod
    _SINK
/job:localhost/replica:0/task:0/gpu:0
    _SOURCE
    Const_1
    Const
    _SINK
```
"
2008,multivariate_normal,"Is there a function can output random values from a multivariate normal distribution?? or how to  implement this with tensorflow?
"
2005,No ImageNet folder,"No ImageNet folder found at `/usr/local/lib/python2.7/dist-packages/tensorflow/models/image`.  Only `mnist` and `cifar10`.

Am I missing something?

Installed with `sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl` on Ubuntu 15.1
"
2004,Open source performance benchmarks,"In #2001 we discussed about the performance benchmark, I suggest maybe we can have some benchmark code (in automatically tests or something else) for common NN architecture like Alex, Inception v3, ResNet  on some famous dataset like cifar10, cifar100, ImageNet.
By doing this, we can continuously trace our performance when we update our algorithms or code.
Also, we could show our benchmark test on our website or github page.
"
2001,feature request: improve the training speed of GPU,"tensorflow seems to have a good performance on CPU compared to other frameworks, however relatively poor on GPU according to third-party benchmark
![image](https://cloud.githubusercontent.com/assets/11470826/14587474/6e4106ae-04e6-11e6-9102-0a4e63b2b82f.png)
![image](https://cloud.githubusercontent.com/assets/11470826/14587481/862ef96a-04e6-11e6-8e43-1bc4ebff7e22.png)
Could I ask the reason why this happen? I belive Tensorflow is the hottest Deep Learning Framework on github. If we could make the performance of Tensorflow better, it will help a lot of people.

Anyone can help or contribute to this issue? 
"
1998,wrong step_time calculation in RNN translation,"step_time is the total time for handling a batch of training data. In [translate.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py#L175):

```
      # Get a batch and make a step.
      start_time = time.time()
      encoder_inputs, decoder_inputs, target_weights = model.get_batch(train_set, bucket_id)
      _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs,
                                   target_weights, bucket_id, False)
      step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint

```

I just interested to know why the consuming time is divided to FLAGS.steps_per_checkpoints? @lukaszkaiser 
"
1997,Training accuracy falling down after some epoches since upgrading to 0.8.0rc0,"I'm trying to use a simple network to classify some 64*64 images. in v0.7 it worked fine and consistent. The training phase was showing a consistent  average growth in accuracy. But since I'm trying to use 0.8, the accuracy fall down occasionally from ~0.9 to ~0!
I'm using cpu  version for python 2.7

is it a bug in TF or I'm doing something wrong?
###### 
### Environment info

Operating System: Ubuntu 14.04
I've installed pip with the following command : sudo apt-get install python-pip python-dev
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0rc0
   #############################################
   ### my learning code is as below:

```
sess = tf.InteractiveSession()

x = tf.placeholder(tf.float32, shape=[None, 64,64])
y_ = tf.placeholder(tf.float32, shape=[None, 31])
input = tf.reshape(x,shape=[-1,64*64])
w1 = tf.Variable(tf.random_uniform([64*64,128],minval=-0.1,maxval=0.1),dtype=tf.float32)
b1 = tf.Variable(tf.random_uniform([128],minval=-0.1,maxval=0.1),dtype=tf.float32);
y1_ = tf.nn.softmax(tf.matmul(input, w1) + b1)
keep_prob = tf.placeholder(tf.float32)
y1 = tf.nn.dropout(y1_, keep_prob)
w2 = tf.Variable(tf.random_uniform([128,31],minval=-0.1,maxval=0.1),dtype=tf.float32)
b2 = tf.Variable(tf.random_uniform([31],minval=-0.1,maxval=0.1),dtype=tf.float32);
y2 = tf.nn.softmax(tf.matmul(y1, w2) + b2)
cross_entropy = -tf.reduce_sum(y_*tf.log(y2))
learn_rate = tf.placeholder(tf.float32)
train_step = tf.train.AdamOptimizer(learn_rate).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y2,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
sess.run(tf.initialize_all_variables())
d = Dataset()
dat = d.load()
for i in range(9000):
    if i%200==0:
        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-2})
        print(""step %d, training accuracy %g"" % (i, a))
    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8 ,learn_rate:1e-2})

for i in range(5000):
    if i%100==0:
        a = accuracy.eval(feed_dict={x: dat.data, y_: dat.label,keep_prob: 1.0,learn_rate:1e-3})
        print(""step %d, training accuracy %g"" % (i, a))
    train_step.run(feed_dict={x: dat.data, y_: dat.label,keep_prob: 0.8,learn_rate:1e-3 })
```
# 

some line of the output is as below:
step 7400, training accuracy 0.870539
step 7600, training accuracy 0.875406
step 7800, training accuracy 0.877677
step 8000, training accuracy 0.882868
step 8200, training accuracy 0.884491
step 8400, training accuracy 0.887735
step 8600, training accuracy 0.888709
step 8800, training accuracy 0.893251
step 0, training accuracy 0.894549
step 100, training accuracy 0.895198
step 200, training accuracy 0.894873
step 300, training accuracy 0.895198
step 400, training accuracy 0.894873
step 500, training accuracy 0.895198
step 600, training accuracy 0.895198
step 700, training accuracy 0.895522
step 800, training accuracy 0.895522
step 900, training accuracy 0.895847
step 1000, training accuracy 0.896171
step 1100, training accuracy 0.896171
step 1200, training accuracy 0.896496
step 1300, training accuracy 0.89682
step 1400, training accuracy 0
step 1500, training accuracy 0
step 1600, training accuracy 0
step 1700, training accuracy 0
"
1996,Distributed tensorflow on Mesos,"In the [distributed howto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/distributed/index.md): ""We are working on tools for launching tasks programmatically, e.g. using a cluster manager like Kubernetes. If there are particular cluster managers for which you'd like to see support, please raise a GitHub issue.""
It could be interesting to have CPU and GPU dockefiles ready for distributed than can run in a scalable way on Mesos (with Marathon and Kubernetes)
"
1993,Cannot reshape variable with `validate_shape=False`,"Given the following code:

``` python
import tensorflow as tf

x = tf.Variable(tf.zeros((3, 4)), validate_shape=False)
transposed = tf.reshape(x, [tf.shape(x)[1], -1])

init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

print(sess.run(transposed))
```

I got the following error:

```
TypeError: Expected int32, got list containing Tensors of type '_Message' instead.
```
"
1992,scipy needs to be imported before tensorflow,"### Environment info

Operating System: 
Ubuntu 14.04.4 LTS

Installed version of CUDA and cuDNN: 
cuda-7.5
cuDNN 5
### Steps to reproduce
1. import tensorflow
2. import scipy.misc
3. scipy.misc.imread fails with ""IOError: broken data stream when reading image file""

Importing scipy before tensorflow solves the issue.
"
1990,Installation of Tensorflow 0.8 in an Anaconda Python 3.5 Environment Failed,"Dear friends,

I have tried to install tensorflow 0.8 in an anaconda python 3.5 environment but it didn't worked. I got a message saying something like ""not a supported wheel on this platform"".
### Environment info

Operating System: Ubuntu 14.04.LTS
### Steps to reproduce

```
dlm@pc-aero-01:~$ 
dlm@pc-aero-01:~$ conda create -n tensorflow python=3.5
(...)
dlm@pc-aero-01:~$ 
dlm@pc-aero-01:~$ source activate tensorflow
discarding /home/dlm/anaconda3/bin from PATH
prepending /home/dlm/anaconda3/envs/tensorflow/bin to PATH
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ python -V
Python 3.5.1 :: Continuum Analytics, Inc.
(tensorflow)dlm@pc-aero-01:~$ pip -V
pip 8.1.1 from /home/dlm/anaconda3/envs/tensorflow/lib/python3.5/site-packages (python 3.5)
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl
**tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl is not a supported wheel on this platform.**
(tensorflow)dlm@pc-aero-01:~$ 
```
### What have you tried?

I have tried to use the pip3 for python 3.4 instead of 3.5. It appears to install but didn't worked after all. I think the the problem now is that conda is using the pip of the system environment since this version isn't installed in the tensorflow environment. See below:

```
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ pip3 -V
pip 8.1.1 from /usr/local/lib/python3.4/dist-packages (python 3.4)
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ sudo -H pip3 install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl
[sudo] password for dlm: 
Collecting tensorflow==0.8.0rc0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl
  Using cached https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl
Collecting numpy>=1.8.2 (from tensorflow==0.8.0rc0)
  Using cached numpy-1.11.0-cp34-cp34m-manylinux1_x86_64.whl
Collecting wheel>=0.26 (from tensorflow==0.8.0rc0)
  Using cached wheel-0.29.0-py2.py3-none-any.whl
Collecting six>=1.10.0 (from tensorflow==0.8.0rc0)
  Using cached six-1.10.0-py2.py3-none-any.whl
Collecting protobuf==3.0.0b2 (from tensorflow==0.8.0rc0)
  Using cached protobuf-3.0.0b2-py2.py3-none-any.whl
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.8.0rc0)
  Using cached setuptools-20.9.0-py2.py3-none-any.whl
Installing collected packages: numpy, wheel, six, setuptools, protobuf, tensorflow
Successfully installed numpy-1.11.0 protobuf-3.0.0b2 setuptools-20.9.0 six-1.10.0 tensorflow-0.8.0rc0 wheel-0.29.0
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ python
Python 3.5.1 |Continuum Analytics, Inc.| (default, Dec  7 2015, 11:16:01) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> 
>>> import sys
>>> sys.path
['', '/home/dlm/anaconda3/envs/tensorflow/lib/python35.zip', '/home/dlm/anaconda3/envs/tensorflow/lib/python3.5', '/home/dlm/anaconda3/envs/tensorflow/lib/python3.5/plat-linux', '/home/dlm/anaconda3/envs/tensorflow/lib/python3.5/lib-dynload', '/home/dlm/anaconda3/envs/tensorflow/lib/python3.5/site-packages', '/home/dlm/anaconda3/envs/tensorflow/lib/python3.5/site-packages/setuptools-20.7.0-py3.5.egg']
>>> 
>>> import tensorflow
>>> 
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ python -c 'import os; import inspect; import tensorflow; print(os.path.dirname(inspect.getfile(tensorflow)))'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/dlm/anaconda3/envs/tensorflow/lib/python3.5/inspect.py"", line 607, in getfile
    raise TypeError('{!r} is a built-in module'.format(object))
TypeError: <module 'tensorflow' (namespace)> is a built-in module
(tensorflow)dlm@pc-aero-01:~$ python3 -c 'import os; import inspect; import tensorflow; print(os.path.dirname(inspect.getfile(tensorflow)))'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/home/dlm/anaconda3/envs/tensorflow/lib/python3.5/inspect.py"", line 607, in getfile
    raise TypeError('{!r} is a built-in module'.format(object))
TypeError: <module 'tensorflow' (namespace)> is a built-in module
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ python -m tensorflow.models.image.mnist.convolutional
/home/dlm/anaconda3/envs/tensorflow/bin/python: Error while finding spec for 'tensorflow.models.image.mnist.convolutional' (<class 'ImportError'>: No module named 'tensorflow.models')
(tensorflow)dlm@pc-aero-01:~$ 
(tensorflow)dlm@pc-aero-01:~$ python -c ""import tensorflow; print(tensorflow.__version__)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute '__version__'
(tensorflow)dlm@pc-aero-01:~$ 
```

But, if you try to create a conda environment using python 3.4 it works. Therefore, one possible way to fix it is change the installation procedure in order to create a conda environment using python 3.4 and not python 3.5.

```
dlm@pc-aero-01:~$ conda create -n tensorflowX python=3.4
Using Anaconda Cloud api site https://api.anaconda.org
Fetching package metadata: ....
Solving package specifications: .........
(...)
dlm@pc-aero-01:~$ source activate tensorflowX
discarding /home/dlm/anaconda3/bin from PATH
prepending /home/dlm/anaconda3/envs/tensorflowX/bin to PATH
(tensorflowX)dlm@pc-aero-01:~$ 
(tensorflowX)dlm@pc-aero-01:~$ pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl
Collecting tensorflow==0.8.0rc0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl
(...)
Successfully installed numpy-1.11.0 protobuf-3.0.0b2 setuptools-20.7.0 six-1.10.0 tensorflow-0.8.0rc0 wheel-0.29.0
(tensorflowX)dlm@pc-aero-01:~$ python -m tensorflow.models.image.mnist.convolutional
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.19
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.46GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
Initialized!
Step 0 (epoch 0.00), 18.8 ms
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Step 100 (epoch 0.12), 6.0 ms
Minibatch loss: 3.281, learning rate: 0.010000
Minibatch error: 6.2%
Validation error: 6.9%
Step 200 (epoch 0.23), 5.7 ms
```
"
1988,tf.Print not printing,"### Environment info

Operating System: Ubuntu 14.04 LST
Tensorflow v0.7.1 (no CUDA)
Python 2.7.6
### Steps to reproduce

``` python
import tensorflow as tf
sess = tf.InteractiveSession()
x = tf.placeholder(tf.float32, shape=[None, 2, 2])
x = tf.Print(x, [x], message=""P1"")
i = tf.reshape(x, [-1, 4])
i = tf.Print(i, [i], message=""P2"")
i.eval(feed_dict={x: [[[1,2], [3,4]], [[5,6], [7,8]]]})
```

prints

```
I tensorflow/core/kernels/logging_ops.cc:79] P2[1 2 3...]
array([[ 1.,  2.,  3.,  4.],
       [ 5.,  6.,  7.,  8.]], dtype=float32)
```

Where is the first print with P1 message?
"
1984,"Unclear what parallel_iterations does in While/scan (docs issue, possible functional_ops issue)","It's unclear from both the code and documentation why scan() defaults to 10 parallel iterations. doesn't that cause it to sometimes run the function before the accumulated value is available? I also poked around and read the documentation for While, and that didn't clear things up. Things it looks like it might do:
- Run steps in parallel if and only if there are no graph dependencies on the last step
- Run steps in parallel but provide nonsense values for graph dependencies on the last step
- Ignore it because the parameter doesn't do anything yet?
- Do magic beyond my ken to skip ahead in serial computations? if so, can I tell it to only run the last one, thereby creating a halting oracle?
### Steps to reproduce
1. read the docs in master for scan() and while()
2. read the code for functional_ops.scan()
3. compare to the code for functional_ops.map_fn()
4. be confused that scan() appears to get the right answer when you use it
"
1983,./configure failed on mac with GPU support,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System: mac os 10.11

Installed version of CUDA and cuDNN: 7.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rwxr-xr-x  1 root  wheel  8280 Oct 29 09:50 /usr/local/cuda/lib/libcuda.dylib
lrwxr-xr-x@ 1 root  wheel    45 Sep 25  2015 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a
lrwxr-xr-x@ 1 root  wheel    50 Sep 25  2015 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib
lrwxr-xr-x@ 1 root  wheel    46 Sep 25  2015 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib
lrwxr-xr-x@ 1 root  wheel    49 Sep 25  2015 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
   alembic (0.8.5)
   appnope (0.1.0)
   Babel (2.2.0)
   cffi (1.5.2)
   click (6.4)
   colorama (0.3.7)
   cryptography (1.3.1)
   cvxopt (1.1.8)
   Cython (0.23.4)
   decorator (4.0.9)
   enum34 (1.1.2)
   Flask (0.10.1)
   Flask-AppBuilder (1.6.0)
   Flask-BabelPkg (0.9.6)
   Flask-Cache (0.13.1)
   Flask-Login (0.2.11)
   Flask-Migrate (1.8.0)
   Flask-OpenID (1.2.5)
   Flask-Script (2.0.5)
   Flask-SQLAlchemy (2.0)
   Flask-Testing (0.4.2)
   Flask-WTF (0.12)
   gnureadline (6.3.3)
   gunicorn (19.4.5)
   h5py (2.5.0)
   humanize (0.5.1)
   idna (2.1)
   ipaddress (1.0.16)
   ipython (4.1.2)
   ipython-genutils (0.1.0)
   itsdangerous (0.24)
   Jinja2 (2.8)
   Mako (1.0.4)
   Markdown (2.6.6)
   MarkupSafe (0.23)
   numpy (1.11.0)
   pathlib2 (2.1.0)
   pexpect (4.0.1)
   pickleshare (0.7.2)
   pip (8.1.1)
   ptyprocess (0.5.1)
   pyasn1 (0.1.9)
   pycparser (2.14)
   python-editor (0.5)
   python-openid (2.2.5)
   setuptools (20.9.0)
   simplegeneric (0.8.1)
   six (1.10.0)
   speaklater (1.3)
   SQLAlchemy (1.0.12)
   traitlets (4.2.1)
   vboxapi (1.0)
   Werkzeug (0.11.5)
   wheel (0.26.0)
   WTForms (2.1)
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

I tried to build tensorflow from source on macbook pro. It only looks for .so cuda library but on mac the shared libraries end with .dylib. Also it only looks for lib64 sub-directory, which is not present for cuda 7.5 on mac, in which the libraries are in /usr/local/cuda/lib folder. Does the configure script support mac with gpu now?

Tianweis-Macbook:tensorflow STW$ ./configure 
Please specify the location of python. [Default is /usr/local/bin/python]: 
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc nvcc should use as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 
Please specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Invalid path to CUDA  toolkit. /usr/local/cuda/lib64/libcudart.so cannot be found
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 
### What have you tried?

I tried to build tensorflow on mac with GPU support. It seems that tensorflow only supports gpu build on linux?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1981,Make sklearn adapter to use LabelBinarizer by default,"TensorFlowDNNClassifier doesn't handle cases, when target labels are not in `{0, 1}`. Usually `scikit-learn` models transform labels internally using `LabelBinarizer` so this is slightly misleading. 

``` python
from sklearn import datasets, metrics, cross_validation
from tensorflow.contrib import skflow

## Load dataset and select only first two classes
iris = datasets.load_iris()
ids = np.where((iris.target==0) | (iris.target==1))
iris.data = iris.data[ids]
iris.target = iris.target[ids]

## Change labels from 0/1 to -1/1
## Comment out the following line to get 1.0 accuracy
iris.target[iris.target==0] = -1 

## Train and predict on iris (copied from example)
X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target,
    test_size=0.2, random_state=42)

classifier = skflow.TensorFlowDNNClassifier(hidden_units=[10, 20, 10],
    n_classes=3, steps=200)

# Fit and predict.
classifier.fit(X_train, y_train)
score = metrics.accuracy_score(y_test, classifier.predict(X_test))
print('Accuracy: {0:f}'.format(score)) # Prints 0.4, but prints 1.0 without label change
```

TF version is `0.8.0rc0`

EDIT:

What happens is that `classifier.predict(X_test)` is in [1,2] instead of [-1, 1]
"
1978,Feature Request: Viewing Only Computation Graph in Tensorboard,"For study and debug purposes it could be very useful to view computation network graph in tensor flow, without having to dump any histogram/learning data. 

@dsmilkov , I learnt from @danmane , that such a feature already exists for debug purposes in tensor flow, not yet available for users. What do think about possibility of making it accessible to users.
"
1975,Incorrect Download URL,"It appears the location has been changed and not updated in the tutorial.

```
sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl

Collecting tensorflow==0.8.0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
  HTTP error 404 while getting https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
  Could not install requirement tensorflow==0.8.0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
Could not install requirement tensorflow==0.8.0 from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl for URL https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl
```
"
1970,Scikit Flow Readme file,"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/README.md

Seems to me that README file extension should be rst. But instead it is a markdown and now all links are broken etc.

If this is true then first row should be changed to `|License| |Join the chat at https://gitter.im/tensorflow/skflow|` and everything is alright.
"
1969,What version of cuda and cudnn does TF 0.8 support?,"Hi, I have installed Cuda 7.5 and Cudnn v5 for use with TensorFlow 0.8 and am getting the following error when trying to run /tensorflow/models/image/mnist/convolutional.py

F tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
Aborted (core dumped)

Should I be using an older version of Cuda and/or Cudnn? Thank you
"
1968,Common shape ops for SparseTensor,"It should be easy to extend/modify `tf.rank()`, `tf.shape()`, and `tf.size()` to have them work on `SparseTensor`s.

Happy to review PRs!
"
1967,how could tf.nn.max_pool work with dynamic kernel size?,
1965,"AttributeError: NewBase is_abstract, ImportError: libcudart.so.7.5","Hi,

I have tried to install tensorflow as in https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html
I have cuda 7.0 installed under /usr/local/cuda
 After I install gpu version using pip it gives the error-  ImportError: libcudart.so.7.5: cannot open shared object file: No such file or directory. 
But I have  libcudart.so.7.0 file. Why this is referring 7.5 by default ? 
(issues for version 0.7 and 0.8)

Then I tried to install cpu only version and giving me the error
AttributeError: type object 'NewBase' has no attribute 'is_abstract' (only to version 0.8)

How can I solve those issues ?
Thanks
"
1962,Killed during checkpoint save (v0.8),"### Environment info

Operating System: Ubuntu 15.10

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

`-rw-r--r-- 1 root root   322936 aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 mar  6 15:08 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 mar  6 15:08 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 mar  6 15:08 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rwxr-xr-x 1 root root 11172416 feb 29 22:12 /usr/local/cuda/lib64/libcudnn.so.6.5
-rwxr-xr-x 1 root root 11172416 feb 29 22:12 /usr/local/cuda/lib64/libcudnn.so.6.5.48
-rw-r--r-- 1 root root 62025862 mar  6 15:08 /usr/local/cuda/lib64/libcudnn_static.a`

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

`0.8.0rc0`
### Relevant code:

Unfortunately I can't upload everything, but the code is based on your CIFAR-10 example. Here is the structure of my network:
http://pastebin.com/5QEJWqtm

After running for some time, I save a checkpoint:

`saver.save(sess, checkpoint_path, global_step=step)`

Which _sometimes_ allocates all memory on my system and gets killed. I have 8gb RAM and 8gb swap. For the first few checkpoints it seems fine, it allocates 2gb RAM (equal to checkpoint file size), but after some time it locks up my entire system and gets killed automatically.

Didn't have any issues in 0.7.
"
1961,'ClusterSpec' object has no attribute '_cluster_spec',"### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0rc0
### Steps to reproduce
1. https://github.com/dsindex/tensorflow/blob/master/mlp_mnist_dist.py
2. python mlp_mnist_dist.py --ps_hosts=localhost:2222,localhost:2223 --worker_hosts=localhost:2224,localhost:2225 --job_name=ps --task_index=0
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

{'ps': ['localhost:2222', 'localhost:2223'], 'worker': ['localhost:2224', 'localhost:2225']}
Traceback (most recent call last):
  File ""mlp_mnist_dist.py"", line 90, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""mlp_mnist_dist.py"", line 35, in main
    server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/server_lib.py"", line 135, in **init**
    job_name, task_index, protocol)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/server_lib.py"", line 65, in _make_server_def
    cluster_spec = ClusterSpec(server_or_cluster_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/server_lib.py"", line 242, in __init__
    self._cluster_spec[job_def.name] = [t for t in job_def.tasks.values()]
AttributeError: 'ClusterSpec' object has no attribute '_cluster_spec'
"
1956,Why rnn final state shape[0] is uncertain when has sequence_length?,"inputs = [tf.placeholder(tf.float32, [batch_size])] \* 12
initial_state = cell.zero_state(batch_size, tf.float32)
outputs, final_state = rnn.rnn(cell, inputs, initial_state=initial_state, sequence_length=early_stop)

Why the final_state shape is Tensor(... shape=(?, 256)), instead of batch number?
"
1951,Running graph in C++,"After reading #615 and the related StackOverflow [question](http://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c) (which only has one, unsatisfactory answer) I'd like to know what the right way to do this is. Writing a `MetaGraphDef` proto seems like it would be more convenient than running the freeze_graph python script, but I'm not sure how to read the `MetaGraphDef` with the C++ Session API.
"
1950,tf.gather doesn't support SparseTensors as an input,"As the code in `tf.nn.embedding_lookup` suggests, there were attempts in 0.8 to make it accept SparseTensors, but then everything funnels into `tf.gather` that tries to convert SparseTensor to Tensor and fails.

Is it a correct behaviour or is it a bug? If not, is there any workaround to achieve the same effect (get some of the rows of a SparseTensor based on a index list)? Otherwise, SparseTensors are close to being completely unusable.
### Environment info

Operating System: OS X 10.10.5
TensorFlow version: 0.8.0rc0
### Log:

```
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 566, in gather
    validate_indices=validate_indices, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py"", line 411, in apply_op
    as_ref=input_arg.is_ref)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py"", line 179, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/constant_op.py"", line 162, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py"", line 390, in make_tensor_proto
    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/util/compat.py"", line 44, in as_bytes
    raise TypeError('Expected binary or unicode string, got %r' % bytes_or_text)
TypeError: Expected binary or unicode string, got <tensorflow.python.framework.ops.SparseTensor object at 0x103dbc350>
```
"
1947,tensor flow programs using gpu freeze instance,"### Environment info

Operating System: Ubuntu 14.04 on AWS g2.2xlarge

Installed version of CUDA and cuDNN: cuda-7.15 cudnn-4.0.7
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
lib/libcudart.so  lib/libcudart.so.7.5  lib/libcudart.so.7.5.18  lib/libcudart_static.a

If installed from sources, provide the commit hash:
commit bc5e961e1988fdefff8e8aa062f4ab3066c3a9e5
so tensorflow 0.8.0
but also tried 0.7.1
commit 028d0b46004c921acd48fdd0ec18128d79e18bf4
### Steps to reproduce

all larger tensor flow scripts freeze. I can run simple examples like doing a matmul on the GPU but all larger programs, either my own or from the source (for example tensorflow/tensorflow/models/image/cifar10_train.py) freeze after a short time (no more output and not able to ctrl-C or ctrl-Z). Also the time of freeze seems to vary - I once made it through 2 epochs of training of my own NN before it froze.
### example output:

python cifar10_train.py                              

> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
> > I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
> > Downloading cifar-10-binary.tar.gz 100.0%
> > Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.
> > Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
> > ^C
> > ^Z
> > ^C

and nothing happening (I did wait a lot longer than a few minutes before ctrl-C as well)

but this  script here works and executes on GPU:

```
import tensorflow as tf
a = tf.constant([[3.,3.]])
b = tf.constant([[2.],[2.]])
c = tf.matmul(a,b)
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
print sess.run(c)

```
"
1943,Error trying on GPU ,"Hi Everyone 

I'm new in TensorFlow , I'm running some tests . I tried the Convolutional.py on my local machine and it ran perfectly and everything was ok .On my local pc I don't have a Nvidia GPU , so I tried to connect to a server computer which has Nvidia M4000, I installed Cudnn 7.5 the last version from their website and my CUDA toolkit  is the last version of CUDA (7.5) .

When I run the "" import tensorflow as tf "" everything is ok and it recognize all the libraries and Cudnn .
I manually downloaded the mnist data and I put it in the directory ,when I run the Convolutional.py ,the extracting and everything goes ok when it wants to initialize I receive this error 

ConvolutionalBackwardFilter_V2 cudnn DSO dlerror 

I looked at the cudnn library and searched in it , there is ConvolutionalBackwardFilter in it but there isn't ConvolutionalBackwardFilter_V2. 

I changed the cudnn 7.5 to cudnn 6.5 but still the same story .
At this point I don't know what to do and how can I fix this issue ? I would be grateful if someone could help me 

P.S :My operating system is Linux Ubunto and the server operating system is CentOs 
"
1942,My TensorBoard isn't showing any data! What's wrong?,"I went through [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#my-tensorboard-isnt-showing-any-data-whats-wrong):
1. `tensorboard --logdir=output/trash --debug` showed the expected path
2. `find output/trash | grep tfevents` showed two event files
3. `find output/trash | grep tfevents | xargs ls -lh` showed that they are 6.4M and 1.2M big.

Still, the tensorboard looks like this:

![Imgur](http://i.imgur.com/JLnLCB6.png)

The console shows:

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/TAG
WARNING:tensorflow:Unable to read TensorBoard tag
Starting TensorBoard  on port 6006
(You can navigate to http://0.0.0.0:6006)
WARNING:tensorflow:Found new file_version for event.proto. This will affect purging logic for TensorFlow restarts. Old: 1.0 New: 2.0
WARNING:tensorflow:Found more than one graph event per run. Overwriting the graph with the newest event.
127.0.0.1 - - [14/Apr/2016 15:39:12] ""GET / HTTP/1.1"" 200 -
127.0.0.1 - - [14/Apr/2016 15:39:12] ""GET /external/lodash/lodash.min.js HTTP/1.1"" 200 -
WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/css/global.css' on path /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/lib/css/global.css
127.0.0.1 - - [14/Apr/2016 15:39:12] code 404, message Not Found
127.0.0.1 - - [14/Apr/2016 15:39:12] ""GET /external/d3/d3.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Apr/2016 15:39:12] ""GET /external/plottable/plottable.min.js HTTP/1.1"" 200 -
127.0.0.1 - - [14/Apr/2016 15:39:12] ""GET /external/plottable/plottable.css HTTP/1.1"" 200 -
127.0.0.1 - - [14/Apr/2016 15:39:12] ""GET /external/graphlib/dist/graphlib.core.min.js HTTP/1.1"" 200 -
```
### Environment info

Operating System: Linux Mint 17 Qiana

Installed version of CUDA and cuDNN: 

``` bash
$ ls -l /usr/local/cuda-7.5/lib64/libcud*
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a
```
1. Which pip package you installed: pip 8.1.1 from /usr/local/lib/python2.7/dist-packages (python 2.7)
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".: 0.8.0rc0
### Steps to reproduce
1. Execute `tensorboard --logdir output/trash`
2. Open the browser with http://0.0.0.0:6006
"
1941,Idea: support dictionary fetches with tf.Session.run(),"# The Idea

The [`tf.Session.run()` method](https://www.tensorflow.org/versions/r0.8/api_docs/python/client.html#Session.run), currently supports taking either a _single graph element_, or _a list of graph elements_ as input for the `fetches` argument, and will return either a single value or a list of values correspondingly.

**I propose adding support for using a dictionary as input for the fetch argument**, and receiving a corresponding dictionary as the return value.

Using dictionaries has at least two advantages compared to lists:
1. It will make the code **more readable**, and keys are easier to remember than indices. In the following example the return value of the loss can be accessed as `result['loss']` instead of `result[2]`.
   
   ``` python
   fetches = {
   'train_op': train_op,
   'accuracy': accuracy,
   'loss': loss
   }
   
   result = sess.run(fetches, feed_dict)
   
   print(result['loss'], result['accuracy'])
   ```
2. It will be much **easier to only fetch certain elements on flexible schedules**.
   
   For example i might want to fetch summaries for TensorBoard every 20 iterations while only fetching the loss printing to the console every 50 iterations.
   
   That means that the return value would be a list that sometimes have none of the extra elements, sometimes one of them, and sometimes both. As a consequence the index in the returned list that contains the loss might vary from one run to the next, and I would have to build extra logic to handle this.
   
   With dictionaries the key doesn't change depending on other elements in the dict, so it would be possible to do something like saving summaries without even knowing the schedule:
   
   ``` python
   if 'summaries' in result:
       writer.add_summary(result['summaries'], i)
   ```
# Implementation

I have recently been emulating the proposed behavior in a project using using the following wrapper function to translate from dictionary to list and back.

I suspect that it wouldn't be hard to do something similar in [tensorflow/python/client/session.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py) perhaps as part of [_process_fetches()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/client/session.py#L455), but I didn't want to spend a lot of time on it before asking.

``` python
def run(session, fetches, feed_dict):
    """"""Wrapper for making Session.run() more user friendly.

    With this function, fetches can be either a list or a dictionary.

    If fetches is a list, this function will behave like
    tf.session.run() and return a list in the same order as well. If
    fetches is a dict then this function will also return a dict where
    the returned values are associated with the corresponding keys from
    the fetches dict.

    Keyword arguments:
    session -- An open TensorFlow session.
    fetches -- A list or dict of ops to fetch.
    feed_dict -- The dict of values to feed to the computation graph.
    """"""
    if isinstance(fetches, dict):
        keys, values = fetches.keys(), list(fetches.values())
        res = session.run(values, feed_dict)
        return {key: value for key, value in zip(keys, res)}
    else:
        return session.run(fetches, feed_dict)
```
# Questions
- Is this a bad idea for some reason I don't realize? Or maybe I just overlooked some disadvantages that are worth considering?
- Why stop at dictionaries? What about tuples, nested dictionaries, or dictionaries containing lists of elements?
- General comments and thoughts?
"
1940,convolution on dimension variable inputs ,"I would like to perform a convolution on dimension variable inputs. 
The only solution I find and I think that it would work is to perform a convolution on each input and perform a scan on batch_size. I think this is not optimal.
Is there another function or method to do this differently in TensorFlow?

Thanks in advance. 
"
1939,Tensorflow setup on clound9,"I am doing the project using Tensorflow. I set up it on Clound9 since It run on Ubuntu. I chose python 2.7. However, It kept showing an error: enter image description here . Does anyone have any idea why it keep happening? By the way, I clone tensorflow github in my repository. Thanks

(tensorenv)ngoduyvu:~/workspace (master) $ pip install --upgrade https://storage.googleapis
.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl
Collecting tensorflow==0.8.0rc0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl
  Downloading https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp27-none-linux_x86_64.whl (22.2MB)
    100% || 22.2MB 40kB/s 
Collecting six>=1.10.0 (from tensorflow==0.8.0rc0)
  Downloading six-1.10.0-py2.py3-none-any.whl
Collecting protobuf==3.0.0b2 (from tensorflow==0.8.0rc0)
  Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)
    100% || 327kB 1.8MB/s 
Requirement already up-to-date: wheel in ./miniconda/envs/tensorenv/lib/python2.7/site-packages (from tensorflow==0.8.0rc0)
Collecting numpy>=1.8.2 (from tensorflow==0.8.0rc0)
  Downloading numpy-1.11.0-cp27-cp27mu-manylinux1_x86_64.whl (15.3MB)
    100% || 15.3MB 60kB/s 
Collecting setuptools (from protobuf==3.0.0b2->tensorflow==0.8.0rc0)
  Downloading setuptools-20.7.0-py2.py3-none-any.whl (508kB)
    100% || 512kB 1.8MB/s 
Installing collected packages: six, setuptools, protobuf, numpy, tensorflow
  Found existing installation: setuptools 20.6.7
Cannot remove entries from nonexistent file /home/ubuntu/workspace/miniconda/envs/tensorenv/lib/python2.7/site-packages/easy-install.pth
"
1937,Build from source fail : web_animations_js,"### Environment info

Ubuntu 14.04
hardware - NVidia DIGITS DevBox

Installed version of CUDA and cuDNN: CUDA 7.5, cuDNN 5
### Issue

Issue: trying to install TensorFlow from source and have run into a number of issues. 
1. Resolved: Issue reported elsewhere with pulling eigen. Resolved by downloading eigen manually and modifying workspace.bzl to point to local eigen repository.
2. Unresolved: Error with getting web-animations for bower:
##### Output

xxx@yyy:~/tensorflow bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
ERROR: /home/liam/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@web_animations_js//': Error cloning repository: https://github.com/web-animations/web-animations-js.git: cannot open git-upload-pack caused by https://github.com/web-animations/web-animations-js.git: cannot open git-upload-pack caused by https://github.com/web-animations/web-animations-js.git: cannot open git-upload-pack and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Loading failed; build aborted.

I'm not sure how to fix this - any help at all would be appreciated.
"
1936,Can't re-install tensorflow,"Hi Everyone,

I have encountered a problem. I installed the tensorflow version 0.7.0, and using it to test mnist example, which outputted the error AttributeError: 'module' object has no attribute 'gfile'

I searched for the solution about this error, and realised that I need to roll back to version 0.6.0 or version 0.7.1, so I did un-installed the tensorflow and tried to install version 0.7.1 using
      sudo -H pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl
However, it gave me the error:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip/basecommand.py"", line 209, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip/commands/install.py"", line 317, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip/req/req_set.py"", line 732, in install
    *_kwargs
  File ""/Library/Python/2.7/site-packages/pip/req/req_install.py"", line 835, in install
    self.move_wheel_files(self.source_dir, root=root, prefix=prefix)
  File ""/Library/Python/2.7/site-packages/pip/req/req_install.py"", line 1030, in move_wheel_files
    isolated=self.isolated,
  File ""/Library/Python/2.7/site-packages/pip/wheel.py"", line 477, in move_wheel_files
    generated.extend(maker.make(spec))
  File ""/Library/Python/2.7/site-packages/pip/_vendor/distlib/scripts.py"", line 372, in make
    self._make_script(entry, filenames, options=options)
  File ""/Library/Python/2.7/site-packages/pip/_vendor/distlib/scripts.py"", line 276, in _make_script
    self._write_script(scriptnames, shebang, script, filenames, ext)
  File ""/Library/Python/2.7/site-packages/pip/_vendor/distlib/scripts.py"", line 250, in _write_script
    self._fileop.write_binary_file(outname, script_bytes)
  File ""/Library/Python/2.7/site-packages/pip/_vendor/distlib/util.py"", line 401, in write_binary_file
    with open(path, 'wb') as f:
*_IOError: [Errno 2] No such file or directory: '/usr/local/bin/easy_install' **

As I checked, easy_install is lying in the directory  '/usr/local/bin/easy_install' , I don't know why this error happened.

Please help me solve this problem. It drives me crazy!!!!

Thank you!!
"
1935,ArgumentError: argument --self_test: conflicting option string(s): --self_test,"I just installed tensorflow and no problem when I enter **python -m tensorflow.models.image.mnist.convolutional** in console  
But when I open convolutional.py on spyder, it appears that

```
File ""/usr/lib/python2.7/argparse.py"", line 1467, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
ArgumentError: argument --self_test: conflicting option string(s): --self_test
```

and other example have the same problem such as

```
 File ""/usr/lib/python2.7/argparse.py"", line 1467, in _handle_conflict_error
    raise ArgumentError(action, message % conflict_string)
ArgumentError: argument --batch_size: conflicting option string(s): --batch_size
```

anyone can solve it??
"
1934,Is there a way improve memory strategy with in-place & broadcasting & bsxfun?,"Suppose I have 4GB gpu memory, see the following code.

``` python
A = tf.Variable(tf.zeros([5000, 5000, 25]))  # 5000*5000*25*4byte=2.5GB
B = tf.Variable(tf.zeros([5000, 25])  # 5000*25*4byte=500KB
sub_op = A.assign(A - B)
```

So, if you run sub_op, apparently, it will lead to OOM error, since A-B will need 5GB peak memory because of the broadcasting repetition.

Question 1: Is there a way to use functions like `bsxfun` in matlab which will not extend two object into the same big size and then calculate? i.e.

``` python
sub_op = A.assign(tf.bsxfun(@minus, A, B))
```

Question 2: So, there's another problem about in-place assignment. Since sub_op related to in-place assignment, if the tensorflow haven't implemented it reasonable, it will lead to OOM error two, since there's no 5GB gpu memory to handle two 2.5GB objects.

Any ideas?
"
1933,use seq2seq to output context vector,"When I use tensorflow seq2seq library, how can i get the context vector of input sequence?
Thanks a lot.
"
1932,"When I install tensorflow for gpu mode, I got a error! hellp!","GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:Ubuntu 15.10

Installed version of CUDA and cuDNN: both are 7.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

Before I install tensorflow of GPU,I installed tensorflow of CPU and It work. And I want to install tensorflow of GPU. I get this error:
### Order:bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

Error info:

`bazel-out/local_linux-opt/bin/tensorflow/core/libcore_cpu_internal.lo(device.o): In function`tensorflow::Device::BuildDeviceAttributes(std::string const&, tensorflow::DeviceType, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::BusAdjacency, std::string const&)':
device.cc:(.text._ZN10tensorflow6Device21BuildDeviceAttributesERKSsNS_10DeviceTypeENS_3gtl7IntTypeINS_10Bytes_tag_ExEENS_12BusAdjacencyES2_+0x2d): undefined reference to `google::protobuf::internal::empty_string_'
bazel-out/local_linux-opt/bin/tensorflow/core/libcore_cpu_internal.lo(device.o): In function`tensorflow::Device::Device(tensorflow::Env_, tensorflow::DeviceAttributes const&, tensorflow::Allocator_)':
device.cc:(.text._ZN10tensorflow6DeviceC2EPNS_3EnvERKNS_16DeviceAttributesEPNS_9AllocatorE+0xe0): undefined reference to `tensorflow::ResourceMgr::ResourceMgr(std::string const&)'
bazel-out/local_linux-opt/bin/tensorflow/core/libcore_cpu_internal.lo(threadpool_device.o): In function`tensorflow::ThreadPoolDevice::MakeTensorFromProto(tensorflow::TensorProto const&, tensorflow::AllocatorAttributes, tensorflow::Tensor_)':
threadpool_device.cc:(.text._ZN10tensorflow16ThreadPoolDevice19MakeTensorFromProtoERKNS_11TensorProtoENS_19AllocatorAttributesEPNS_6TensorE+0x69): undefined reference to `google::protobuf::Message::DebugString() const'
bazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(types.o): In function`tensorflow::DataTypeString[abi:cxx11](tensorflow::DataType)':
types.cc:(.text._ZN10tensorflow14DataTypeStringB5cxx11ENS_8DataTypeE+0xa5): undefined reference to `tensorflow::strings::StrCat[abi:cxx11](tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(types.o): In function`tensorflow::DataTypeSliceString[abi:cxx11](tensorflow::gtl::ArraySlice<tensorflow::DataType)':
types.cc:(.text._ZN10tensorflow19DataTypeSliceStringB5cxx11ENS_3gtl10ArraySliceINS_8DataTypeEEE+0xda): undefined reference to `tensorflow::strings::StrAppend(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >_, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(mirror_pad_mode.o): In function `tensorflow::GetNodeAttr(tensorflow::NodeDef const&, tensorflow::StringPiece, tensorflow::MirrorPadMode*)':
mirror_pad_mode.cc:(.text._ZN10tensorflow11GetNodeAttrERKNS_7NodeDefENS_11StringPieceEPNS_13MirrorPadModeE+0x1fd): undefined reference to`tensorflow::strings::StrCat[abi:cxx11](tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/local_linux-opt/bin/tensorflow/core/libframework_internal.lo(padding.o): In function `tensorflow::GetNodeAttr(tensorflow::NodeDef const&, tensorflow::StringPiece, tensorflow::Padding*)':
padding.cc:(.text._ZN10tensorflow11GetNodeAttrERKNS_7NodeDefENS_11StringPieceEPNS_7PaddingE+0x1fd): undefined reference to`tensorflow::strings::StrCat[abi:cxx11](tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 3.377s, Critical Path: 3.16s`

Another:
### bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

Error info:
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2117): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2140): undefined reference to`tensorflow::strings::Appendf(std::string_, char const_, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2549): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x262a): undefined reference to`tensorflow::strings::Appendf(std::string_, char const_, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x2726): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x30db): undefined reference to`tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
python_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_1L11GetPythonOpERKNS_5OpDefEbSs+0x31b3): undefined reference to `tensorflow::strings::StrCat(tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&, tensorflow::strings::AlphaNum const&)'
bazel-out/host/bin/tensorflow/python/libpython_op_gen.lo(python_op_gen.o): In function`tensorflow::GetPythonOps(tensorflow::OpList const&, std::string const&, bool)':
python_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x4e): undefined reference to `tensorflow::strings::Appendf(std::string*, char const*, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x37b): undefined reference to`tensorflow::strings::StrAppend(std::string_, tensorflow::strings::AlphaNum const&)'
python_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x3d7): undefined reference to `tensorflow::strings::Appendf(std::string_, char const_, ...)'
python_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x494): undefined reference to `google::protobuf::Message::DebugString() const'
python_op_gen.cc:(.text._ZN10tensorflow12GetPythonOpsERKNS_6OpListERKSsb+0x4b0): undefined reference to`tensorflow::strings::Appendf(std::string_, char const*, ...)'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 0.646s, Critical Path: 0.42s

nvidia info:
forfish1@Mercury:~/forfish1/workplace/gpu/tensorflow$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17
forfish1@Mercury:~/forfish1/workplace/gpu/tensorflow$ nvcc
nvcc fatal   : No input files specified; use option --help for more information
forfish1@Mercury:~/forfish1/workplace/gpu/tensorflow$ 

Help!!!!!
"
1931,error when import skflow from tensorflow.contrib..,"I successfully installed tensorflow using ' pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp34-none-linux_x86_64.whl'!!!
Instead when i run the examples in tensorflow/examples/skflow, an error occurred.
' ImportError: cannot import name 'skflow'! 
it seems that the error comes from one sentence ' from tensorflow.contrib import skflow'.

I tried to solve this problem, and asked the author(maybe). he said 'you should install 0.8 RC0 (released today) - it has skflow/learn now 0.7.1 didn't have it yet (it was a separate repo when it was released)'.

I really confused about this.

So, how to insert the skflow(from a separate repo) into tensorflow?
"
1928,Some tests (GPU ones?) hang for about 300 seconds before running ,"A lot of tests seem to run very slowly - like for 5 minutes - I think it's the ones that use the GPU. It always hangs at the start of the test right after:

`I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 750 Ti, pci bus id: 0000:01:00.0)`

The python test process runs at 100% CPU. If I interrupt it with `cuda-gdb` I see this:

```
1 ryan@gpu:~$ sudo /usr/local/cuda/bin/cuda-gdb -p 12367
NVIDIA (R) CUDA Debugger
7.5 release
[...]
(cuda-gdb) bt
#0  0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 ()
   from /lib/x86_64-linux-gnu/libpthread.so.0
#1  0x00007fcaee409cdc in std::condition_variable::wait(std::unique_lock<std::mutex>&) ()
   from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#2  0x00007fcafa9d2455 in tensorflow::Notification::WaitForNotification() ()
   from /home/ryan/src/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007fcafbe4e157 in tensorflow::DirectSession::WaitForNotification(tensorflow::DirectSession::RunState*, long long) ()
   from /home/ryan/src/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#4  0x00007fcafbe499ef in tensorflow::DirectSession::Run(tensorflow::RunOptions const&, std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::RunMetadata*) ()
   from /home/ryan/src/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#5  0x00007fcafbe49291 in tensorflow::DirectSession::Run(std::vector<std::pair<std::string, tensorflow::Tensor>, std::allocator<std::pair<std::string, tensorflow::Tensor> > > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<std::string, std::allocator<std::string> > const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*) () from /home/ryan/src/tensorflow/_python_build/tensorflow/python/_pywrap_tensorflow.so
#6  0x00007fcafc0a5894 in TF_Run_Helper(TF_Session*, char const*, TF_Buffer const*, char const**, TF_Tensor**, int, char const**, TF_Tensor**, int, char const**, int, TF_Buffer*, TF_Status---Type <return> to continue, or q <return> to quit---q
Quit
(cuda-gdb) info threads
  Id   Target Id         Frame
  10   Thread 0x7fcb11450700 (LWP 12373) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
  9    Thread 0x7fcad0d66700 (LWP 12374) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
  8    Thread 0x7fcacbfff700 (LWP 12375) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
  7    Thread 0x7fcacb7fe700 (LWP 12376) ""python"" 0x00007fcb151b988d in poll ()
   from /lib/x86_64-linux-gnu/libc.so.6
  6    Thread 0x7fcabffff700 (LWP 12377) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
  5    Thread 0x7fcabf7fe700 (LWP 12378) ""python"" 0x00007fcb15495149 in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
  4    Thread 0x7fcabeffd700 (LWP 12379) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
  3    Thread 0x7fcabe7fc700 (LWP 12380) ""python"" 0x00007fcae1280e5f in ?? ()
   from /usr/lib/x86_64-linux-gnu/libcuda.so.1
  2    Thread 0x7fcabdffb700 (LWP 12381) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
* 1    Thread 0x7fcb1589e700 (LWP 12367) ""python"" 0x00007fcb15494da0 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib/x86_64-linux-gnu/libpthread.so.0
(cuda-gdb) thread 3
[Switching to thread 3 (Thread 0x7fcabe7fc700 (LWP 12380))]
#0  0x00007fcae1280e5f in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
(cuda-gdb) bt
#0  0x00007fcae1280e5f in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#1  0x00007fcae159fdcd in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#2  0x00007fcae1595f75 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#3  0x00007fcae1537423 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#4  0x00007fcae151f416 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#5  0x00007fcae1503a3d in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#6  0x00007fcae15244be in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#7  0x00007fcae1527932 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#8  0x00007fcae151ee1f in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#9  0x00007fcae14fb6c4 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#10 0x00007fcae14fca7d in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#11 0x00007fcae1351204 in cuMemGetAttribute_v2 () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#12 0x00007fcae1351bfe in cuMemGetAttribute_v2 () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#13 0x00007fcae143f8a0 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#14 0x00007fcae143fbb0 in cudbgGetAPIVersion () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#15 0x00007fcaee6fe52d in cudaGetExportTable ()
   from /home/ryan/src/tensorflow/_python_build/tensorflow/python/../../_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64/libcudart.so.7.5
#16 0x00007fcaee6f2ba0 in cudaGetExportTable ()
   from /home/ryan/src/tensorflow/_python_build/tensorflow/python/../../_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64/libcudart.so.7.5
#17 0x00007fcaee6fd796 in cudaGetExportTable ()
---Type <return> to continue, or q <return> to quit---q
 from /home/ryan/src/tensorflow/_python_build/tQuit
(cuda-gdb)
```

So it looks like it's waiting for a GPU compilation. nvidia-smi doesn't make it seem like it's working hard though:

```
0 ryan@gpu:~$ nvidia-smi
Wed Apr 13 16:13:25 2016
+------------------------------------------------------+
| NVIDIA-SMI 352.39     Driver Version: 352.39         |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 750 Ti  On   | 0000:01:00.0      On |                  N/A |
| 42%   29C    P0     2W /  52W |    898MiB /  2044MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0       652    G   /usr/bin/X                                     135MiB |
|    0      1143    G   compiz                                          52MiB |
|    0     12367    C   /home/ryan/src/python-local/bin/python         700MiB |
+-----------------------------------------------------------------------------+
```

Here is a partial list of tests that ran in hundreds of seconds:

```
//tensorflow/python:argmax_op_test                                       PASSED in 301.2s
//tensorflow/python:attention_ops_test                                   PASSED in 303.4s
//tensorflow/python:bias_op_test                                         PASSED in 317.5s
//tensorflow/python:cast_op_test                                         PASSED in 318.2s
//tensorflow/python:concat_op_test                                       PASSED in 321.0s
//tensorflow/python:constant_op_test                                     PASSED in 308.4s
//tensorflow/python:control_flow_ops_py_test                             PASSED in 321.2s
//tensorflow/python:conv_ops_test                                        PASSED in 330.7s
//tensorflow/python:dense_update_ops_test                                PASSED in 307.6s
//tensorflow/python:depthtospace_op_test                                 PASSED in 323.4s
//tensorflow/python:fft_ops_test                                         PASSED in 343.8s
//tensorflow/python:gather_nd_op_test                                    PASSED in 317.7s
//tensorflow/python:gather_op_test                                       PASSED in 315.2s
//tensorflow/python:gradient_checker_test                                PASSED in 288.4s
//tensorflow/python:gradients_test                                       PASSED in 317.1s
//tensorflow/python:graph_util_test                                      PASSED in 304.8s
//tensorflow/python:image_grad_test                                      PASSED in 296.9s
//tensorflow/python:image_ops_test                                       PASSED in 301.3s
//tensorflow/python:init_ops_test                                        PASSED in 317.3s
//tensorflow/python:math_grad_test                                       PASSED in 317.3s
//tensorflow/python:math_ops_test                                        PASSED in 368.2s
//tensorflow/python:matmul_op_test                                       PASSED in 319.3s
//tensorflow/python:nn_test                                              PASSED in 338.6s
//tensorflow/python:numerics_test                                        PASSED in 310.5s
//tensorflow/python:one_hot_op_test                                      PASSED in 306.0s
//tensorflow/python:pack_op_test                                         PASSED in 318.6s
//tensorflow/python:pad_op_test                                          PASSED in 320.0s
//tensorflow/python:pooling_ops_test                                     PASSED in 333.5s
//tensorflow/python:random_ops_test                                      PASSED in 325.2s
//tensorflow/python:reduction_ops_test                                   PASSED in 313.2s
//tensorflow/python:relu_op_test                                         PASSED in 308.5s
//tensorflow/python:reverse_sequence_op_test                             PASSED in 304.1s
//tensorflow/python:rnn_test                                             PASSED in 371.4s
//tensorflow/python:saver_test                                           PASSED in 305.0s
//tensorflow/python:scatter_ops_test                                     PASSED in 344.2s
//tensorflow/python:server_lib_test                                      PASSED in 315.3s
//tensorflow/python:session_manager_test                                 PASSED in 342.9s
//tensorflow/python:shape_ops_test                                       PASSED in 312.7s
//tensorflow/python:slice_op_test                                        PASSED in 429.0s
//tensorflow/python:softmax_op_test                                      PASSED in 303.4s
//tensorflow/python:softplus_op_test                                     PASSED in 314.8s
//tensorflow/python:softsign_op_test                                     PASSED in 313.2s
//tensorflow/python:spacetodepth_op_test                                 PASSED in 315.3s
//tensorflow/python:sparse_tensor_dense_matmul_grad_test                 PASSED in 299.8s
//tensorflow/python:sparse_tensor_dense_matmul_op_test                   PASSED in 319.6s
//tensorflow/python:sparse_xent_op_test                                  PASSED in 318.2s
//tensorflow/python:split_op_test                                        PASSED in 302.2s
//tensorflow/python:stack_ops_test                                       PASSED in 317.1s
//tensorflow/python:supervisor_test                                      PASSED in 327.9s
//tensorflow/python:template_test                                        PASSED in 302.0s
//tensorflow/python:tensor_array_ops_test                                PASSED in 313.5s
//tensorflow/python:training_ops_test                                    PASSED in 312.4s
//tensorflow/python:transpose_op_test                                    PASSED in 303.2s
//tensorflow/python:unpack_op_test                                       PASSED in 299.1s
//tensorflow/python:variable_ops_test                                    PASSED in 317.2s
//tensorflow/python:cwise_ops_test                                      TIMEOUT in 505.0s
//tensorflow/python:xent_op_test                                        TIMEOUT in 505.0s
//tensorflow/python:depthwise_conv_op_test                               FAILED in 304.2s
//tensorflow/python:function_test                                        FAILED in 309.4s
//tensorflow/python:session_test                                         FAILED in 320.8s
```
"
1927,libpng error when plotting in notebook after importing tensorflow,"### Environment info

Operating System: CentOS Linux 7 x86_64
### Tensorflow version

0.8.0rc0 (from binary)
### Steps to reproduce
1. Fresh conda environment: `conda create -y -n plt_tf python=3.4 jupyter notebook matplotlib numpy && source activate plt_tf`
2. `pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.8.0rc0-cp34-cp34m-linux_x86_64.whl`
3. Launch a notebook server and execute the following:

```
import tensorflow as tf
import matplotlib.pyplot as plt
%matplotlib inline

plt.plot([1,2], [1,2])
```
### Logs or other output that would be helpful

Traceback:

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/home/bnaul/miniconda3/envs/plt_tf/lib/python3.5/site-packages/IPython/core/formatters.py in __call__(self, obj)
    337                 pass
    338             else:
--> 339                 return printer(obj)
    340             # Finally look for special method names
    341             method = _safe_get_formatter_method(obj, self.print_method)

/home/bnaul/miniconda3/envs/plt_tf/lib/python3.5/site-packages/IPython/core/pylabtools.py in <lambda>(fig)
    224 
    225     if 'png' in formats:
--> 226         png_formatter.for_type(Figure, lambda fig: print_figure(fig, 'png', **kwargs))
    227     if 'retina' in formats or 'png2x' in formats:
    228         png_formatter.for_type(Figure, lambda fig: retina_figure(fig, **kwargs))

/home/bnaul/miniconda3/envs/plt_tf/lib/python3.5/site-packages/IPython/core/pylabtools.py in print_figure(fig, fmt, bbox_inches, **kwargs)
    115 
    116     bytes_io = BytesIO()
--> 117     fig.canvas.print_figure(bytes_io, **kw)
    118     data = bytes_io.getvalue()
    119     if fmt == 'svg':

/home/bnaul/miniconda3/envs/plt_tf/lib/python3.5/site-packages/matplotlib/backend_bases.py in print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)
   2178                     orientation=orientation,
   2179                     dryrun=True,
-> 2180                     **kwargs)
   2181                 renderer = self.figure._cachedRenderer
   2182                 bbox_inches = self.figure.get_tightbbox(renderer)

/home/bnaul/miniconda3/envs/plt_tf/lib/python3.5/site-packages/matplotlib/backends/backend_agg.py in print_png(self, filename_or_obj, *args, **kwargs)
    535             close = False
    536         try:
--> 537             _png.write_png(renderer._renderer, filename_or_obj, self.figure.dpi)
    538         finally:
    539             if close:

RuntimeError: Could not create write struct
```

Server log:

```
libpng warning: Application was compiled with png.h from libpng-1.6.17
libpng warning: Application  is  running with png.c from libpng-1.2.53
libpng error: Incompatible libpng version in application and library
```
### Workaround

Importing `tensorflow` after `matplotlib` prevents this from happening.
"
1924,opencv imported after tensorflow can't read jpeg,"### Environment info

Operating System: Ubuntu 14.04. 

If installed from sources, provide the commit hash: f952246b17562
### Steps to reproduce

``` bash
$ python2 -c ""import tensorflow; import cv2; print cv2.imread('cat.jpg')""
None
```
### What have you tried?

import cv2 before tensorflow works.

This problem also exists on CentOS 7. It doesn't happen on a latest ArchLinux.
It's likely due to that tensorflow has it's own libjpeg that conflicts with opencv on some platforms.
"
1923,TensorBoard issue on Mac (0.8.0rc0),"### Environment info

Operating System: Mac OS X
Using virtualenv

Installed version of CUDA and cuDNN: None
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0rc0-py2-none-any.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.8.0rc0

If installed from sources, provide the commit hash:
### Steps to reproduce
1. git clone --recurse-submodule https://github.com/tensorflow/tensorflow.git
2. cd tensorflow
3. git checkout r0.8
4. python tensorflow/examples/tutorials/mnist/mnist_with_summaries.py --summaries_dir=/tmp/summaries_1
5. tensorboard --logdir /tmp/summaries_1
6. Open http://127.0.0.1:6006 in Chrome

Notice that the CSS don't load properly. The graphs and charts don't show either. 
### What have you tried?
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
If accessed from non-localhost, tensorboard prints messages like the following in console:

WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/Users/cais/venv1/lib/python2.7/site-packages/tensorflow/tensorboard/**_rPc_sWiTcH_**' on path /Users/cais/venv1/lib/python2.7/site-packages/tensorflow/tensorboard/**_rPc_sWiTcH_**
10.1.2.3 - - [13/Apr/2016 12:28:20] code 404, message Not Found
"
1922,Logo is imprecise,"In Tensorflow logo, the left arm of the T looks like 2 units long, while the right arm is 1 unit long. So, if I am not mistaken, the shadow should look different (asymmetrical).

![tensorflow](https://cloud.githubusercontent.com/assets/695274/14502882/c8289650-01ad-11e6-8cb6-69b4b3052edc.jpg)
"
1919,"Support for ""Prod"" on GPU","As brought up on [so](http://stackoverflow.com/questions/35724469/where-can-i-have-a-look-at-tensorflow-gradient-descent-main-loop/35728022#35728022), Prod on GPU is only registered for float/double but not int inputs

This happens when computing gradient of network with tf.mean() because tf.gradients inserts a ""Prod"" node with integer inputs.

We already have support on GPU for Prod for float/double, could it be as simple as adding an extra registration clause to [reduction_ops_prod.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/reduction_ops_prod.cc#L37)?
"
1917,Run time error raised from image.random_contrast,"### Environment info

Operating System: SUSE 64bit
Tensorflow version: 0.6.0
### Steps to reproduce

I am following the [CNN tutorial](https://www.tensorflow.org/versions/0.6.0/tutorials/deep_cnn/index.html#convolutional-neural-networks), and encounter the problem:
`E tensorflow/core/common_runtime/executor.cc:264] Executor failed to create kernel. Unimplemented: Op AdjustContrast is not available in GraphDef version 5. It has been removed in version 2. Use AdjustContrastv2 instead.`

`[[Node: adjust_contrast = AdjustContrast[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](RandomCrop, random_uniform, adjust_contrast/min_value, adjust_contrast/max_value)]]`

And something like this:
`UnimplementedError: Op AdjustContrast is not available in GraphDef version 5. It has been removed in version 2. Use AdjustContrastv2 instead.`

Thank you in advance.
"
1916,Unable to install tensorflow.,"**I get the error below**

Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/basecommand.py"", line 209, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/commands/install.py"", line 317, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/req/req_set.py"", line 726, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/req/req_install.py"", line 746, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-8.1.1-py2.7.egg/pip/utils/**init**.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/var/folders/6x/c66cmr110rqbfmz_m75t3zp00000gn/T/pip-TzGuiv-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info'
"
1915,Gradient for self_adjoint_eig,"Well, what to say. This would be cool to have.
According to the theano [docs](http://deeplearning.net/software/theano/library/tensor/nlinalg.html#theano.tensor.nlinalg.Eigh) and [sources](https://github.com/Theano/Theano/blob/master/theano/tensor/nlinalg.py#L402) it is not all that complicated.
Their implementation uses the triangle functions mentioned in #1825 though.
"
1914,I got an error with MomentumOptimizer,"I can't use MomentumOptimizer,it show that:

tensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'target_embeddings/read': Could not satisfy explicit device specification '/device:GPU:0' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0'
"
1913,Tensorboard is missing css in lib/,"I've noticed that since April 2016 built python wheel files are missing css in tensorboard/lib.
Take a look at those two builds from Jenkins:
1. [13.04.2016](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/63/)
2. [31.03.2016](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/50/)
and compare the contents of wheel file:
![tfboard-missing-css](https://cloud.githubusercontent.com/assets/18440238/14491109/3bfd4a3a-0177-11e6-91e9-8de4a8b34ec4.png)
This causes issues when trying to run tensorboard after installation of wheel file.
Manual installation from source provides the same result as above.
"
1899,partial_run won't accept optimizers as fetch,"### Environment info

Operating System: ubuntu 14.04
tensorflow 0.7.1
Installed version of CUDA and cuDNN: cuda-7.5, cuDNN 4

I'd like to use partial_run to insert some lookahead processing during training attention-based image processing, but I can't complete the step because partial_run won't accept an operation as a fetch arg, and optimizers don't return any downstream variables. See the trivial case below.
Seems like a bug in the partial_run implementation, or do I misunderstand its use?
....
y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2,name='softmax')
cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
tf.initialize_all_variables().run()
for i in range(100000):
    batch =shapes.train.next_batch(batch_size)
    h = sess.partial_run_setup([y_conv,train_step],[x,y_,keep_prob])
    im_state=sess.partial_run(h,y_conv,feed_dict={x:batch[0], y_: batch[1], keep_prob: 0.5})
    final=sess.partial_run(h,[train_step])

looking at the code, it seems any ops put in fetch are moved to the target_list, which must be empty when _do_call is running for partial_run. As a result, this error on the ""final="" last step above:

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _prun_fn(session, handle, feed_dict, fetch_list)
    557     def _prun_fn(session, handle, feed_dict, fetch_list):
    558       if target_list:
--> 559         raise RuntimeError('partial_run() requires empty target_list.')
    560       return tf_session.TF_PRun(session, handle, feed_dict, fetch_list)
    561 
RuntimeError: partial_run() requires empty target_list.
"
1894,Missing types in C++ API,"It looks like there are some missing types in tensorflow/core/framework/types.h, such as uint32 and uint64. This means I can't make tensors of these types in C++.
"
1893,Problem with shape inference with diag_part operator. ,"Running` from master the following small code snippet gives an error.

```
import tensorflow as tf
import numpy as np

W = tf.constant(3., tf.float64)
X = tf.placeholder(tf.float64, [5,3])
Y = tf.scalar_mul( W , tf.ones(tf.pack([tf.shape(X)[0], tf.shape(X)[0]]), tf.float64) )
Z = tf.diag_part(Y)

init = tf.initialize_all_variables()

sess = tf.Session()
sess.run(init)
print(sess.run(Z, feed_dict={X: np.ones((5,3))}))
```

The relevant part of the error is 

> /tensorflow/python/ops/array_ops.py"", line 960, in _DiagPartShape
>     "" do not match "")
> ValueError: Invalid shape, shape[:mid] (?,) and shape[mid:] (?,) do not match 

I think it is reasonable to be able to get the diagonal of this matrix. Therefore I think this is a bug with the shape inference. 

Thanks,
Alex 
"
1892,Broken links in C++ API documentation,"It looks like all of the links from https://www.tensorflow.org/versions/r0.7/api_docs/cc/index.html are broken. For example, https://www.tensorflow.org/versions/r0.7/api_docs/cc/classTensor.html.
"
1890,graph.pb.h missing,"The issue is quite simple: I downloaded and built TF from source, but the include files like tensorflow/core/public/session.h reference non-existing files. One culprit is tensorflow/core/framework/graph.pb.h. Attempted compilation produces the following error:

22:31:27 ***\* Build of configuration Debug for project hello_world ****
make all 
make: Warning: File `objects.mk' has modification time 1,8e+02 s in the future
Building file: ../src/hello_world.cpp
Invoking: GCC C++ Compiler
g++ -I/home/sander/tensorflow -O0 -g3 -Wall -c -fmessage-length=0 -MMD -MP -MF""src/hello_world.d"" -MT""src/hello_world.d"" -o ""src/hello_world.o"" ""../src/hello_world.cpp""
In file included from ../src/hello_world.cpp:8:0:
/home/sander/tensorflow/tensorflow/core/public/session.h:22:48: fatal error: tensorflow/core/framework/graph.pb.h: No such file or directory
 #include ""tensorflow/core/framework/graph.pb.h""
                                                ^
compilation terminated.

I cannot rule out a mistake on my part, but I've tried a bunch of things to no avail. Either a file is missing or there may be a linking issue. Any help would be greatly appreciated.
### Environment info

Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
None

If installed from binary pip package, provide:
1. Which pip package you installed.
   I followed these steps:

1 git clone --recurse-submodules https://github.com/tensorflow/tensorflow

2 run ./configure

3 bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

4 bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

5 pip install /tmp/tensorflow_pkg/tensorflow-0.7.1-py2-none-linux_x86_64.whl
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   0.7.1

If installed from sources, provide the commit hash:
not sure, retrieved on 11 april from terminal:
$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow
### Steps to reproduce
1. The error occurs simply when any file from TF is included in c++
   example:
   #include ""tensorflow/core/public/session.h""
### What have you tried?
1. Reinstall/upgrade: pip, bazel, tensorflow, gcc/g++, add additional include paths
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1888,Feature request: Ability to specify some GPUs and ignore all others,"Right now, to specify a particular GPU, I do something like this:

```
gpu = 0
available_devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')
os.environ['CUDA_VISIBLE_DEVICES'] = available_devices[gpu]
```

after which TensorFlow will only allocate resources on the first GPU device. It would be nice to include a native way to do this.

Side note: There isn't much documentation (any?) on `device_count`, so I'm not sure if it's meant to handle this. Either way, I have experimented with the `device_count`, but with no luck: if I use `device_count = {'GPU': 1}`, TensorFlow still allocates memory on all available GPUs.
"
1882,Distortions in Retrain.py (Transfer learning w/ inception model) take exceedingly long,"### Environment info

Operating System:
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA: 7.5
cuDNN: 6.5 (v2)
Using nVidia Quadro K2200

If installed from sources, provide the commit hash:
fe9dafd1583da5ccc205eab776f86afcb00411d2
### Steps to reproduce

Retrain.py runs fine without any distortions. Not massively faster than CPU, but faster.
NVIDIA-SMI shows that the GPU has 3824mb used during training.

If any distortions are used, training becomes very, very, long. It takes almost ten minutes for ten images to be trained.

Is this very slow speed intended?

Best

Oren
"
1881,Update website with correct Cuda info,"I received this on twitter:
""Can you please help update TF website to state TF-GPU needs nvidia compute cap. >= 3.5 and to install cudNN v4 (not 5). Thanks""
https://twitter.com/AlliseeSolution/status/719789250082766848

I'm not using Cuda myself, so I'm not sure of the details here, but wanted to get it logged so somebody more knowledgeable can take a look.
"
1879,"Evaluate dev set in Translate.py: the decoder stills fetches from decoder_inputs, instead of previous predictions.","In the training process defined in Translate.py, the model is created with `model = create_model(sess, False)` where `forward_only=False` means every step of decoding the decoder would fetch from decoder_inputs, instead of previous prediction. 

That's the same for evaluation of dev set, since the command 
`_, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)` 
with `forward_only=True` actually doesn't change the decoding way. (It just decides the backward.)

So I guess the evaluation of dev set is not a real evaluation? Or is it a trick? I guess the correct way should be creating a model with current checkpoint params and set `forward_only=True`.

Thanks.
"
1875,Gradient for MatrixTriangularSolve ,"We have a gradient op in master for MatrixSolve . It seems like it shouldn't be too difficult to define a gradient for MatrixTriangularSolve in a similar way. Are there any imminent plans to do this? @rmlarsen @girving ?

I actually had a look at doing it myself but I was getting some strange numerical behaviour from the finite differences test. Possibly just something I am doing wrong. If we can work out what is going on with the test I would be happy to help. 
"
1874,"Does TensorBoard (TensorFlow) have the features to add labels for axes and legends on plots? If so, how? ","Need to know if these features are available for scalar and histogram summaries in the  python3  GPU-enabled 0.7.1 version
"
1872,How to get top N results for seq2seq?,"In the example translate seq2seq model, mentioned in the tutorial and in the code here (reproduced below):

```
      # Get a 1-element batch to feed the sentence to the model.
      encoder_inputs, decoder_inputs, target_weights = model.get_batch(
          {bucket_id: [(token_ids, [])]}, bucket_id)
      # Get output logits for the sentence.
      _, _, output_logits = model.step(sess, encoder_inputs, decoder_inputs,
                                       target_weights, bucket_id, True)
      # This is a greedy decoder - outputs are just argmaxes of output_logits.
      outputs = [int(np.argmax(logit, axis=1)) for logit in output_logits]

```

It uses only a greedy decoder, and uses argmax to find the best match. I'm wondering if there's a way to get the top N results instead of just doing it greedily. I've tried argsort, but everything apart from the 0th index is just garbage results. I've also looked into tf.nn.top_k(), but because this is batched, I get the error ""List of Tensors when single Tensor expected"" and I'm not sure how to unroll the list within TF.
"
1870,crosstool_wrapper_driver_is_not_gcc failed: python2: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory,"### Environment info

Operating System: Scientific Linux 6.5

Installed version of CUDA and cuDNN: 
CUDA - 7.5.18
CuDNN - 4.0.7

Tensorflow installation attempt from source..

ERROR: /global/home/users/kmuriki/.cache/bazel/_bazel_kmuriki/7a46079e1611cbcdacd2bbe4113de14c/external/re2/BUILD:9:1: C++ compilation of rule '@re2//:re2' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object ... (remaining 36 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 127.
python2: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory

python2 on my machine is located here : /global/software/sl-6.x86_64/modules/langs/python/2.7.8/bin/python2 and I do have libpython2.7.so.1.0 located here: /global/software/sl-6.x86_64/modules/langs/python/2.7.8/lib/libpython2.7.so.1.0. 

LD_LIBRARY_PATH points to /global/software/sl-6.x86_64/modules/langs/python/2.7.8/lib

$ python-config --ldflags
-lpthread -ldl -lutil -lm -lpython2.7 -Xlinker -export-dynamic

What else am I missing ?
"
1861,Bug: tf.scan loses shape information when available,"Operating System: CentOS 6.7
If installed from sources, provide the commit hash: b4b276e

`tf.scan` loses shape information when available, which in turn makes it necessary to pass around shape information that could be inferred from the `Tensors` themselves.

Example where we should see shape `[3]` (after conversion to list), but where we instead get a shape of `<unknown>`:

```
def fn(previous_output, current_input):
    print(current_input.get_shape())
    return current_input

x = tf.constant([[1, 2, 3], [4, 5, 6]])
initializer = tf.constant([0, 0, 0])

y = tf.scan(fn, x, initializer=initializer)

with tf.Session() as sess:
    print(sess.run(y))

# <unknown>
# [[1 2 3]
# [4 5 6]]
```
"
1859,Python 2 linux GPU nightly link in readme is wrong,"Hey! I wanted to try out the scan op, so I installed the latest. however, on doing so, I discovered that no nightly build has been attempted in jenkins for about 20 days. if this is simply because one has not been run, could someone at google hit build and then take a look at why it hasn't run?

Note: I don't mean it's failed; I mean there are no builds in the list newer than that, failed or otherwise.

In the meantime, I'll install from source.
### Environment info

Operating System: Linux; Ubuntu/14.04

Installed version of CUDA and cuDNN: irrelevant

installed from binary pip package: http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
### What are you about to try?
1. building from source.
"
1856,Incremental builds are very slow,"I'm following the instructions from ""Setting up TensorFlow for Development"" in `tensorflow/g3doc/get_started/os_setup.md`

If I make a small change to `core/kernels/eigen_spatial_convolutions.h` and rebuild the pip package (`bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package`) the process takes **204 seconds**.
"
1853,shuffle_batch gives ZeroDivisionError when computing capacity stat,"```
import tensorflow as tf
raw = tf.ones((2))
tf.train.shuffle_batch([raw], batch_size=2, capacity=4, min_after_dequeue=4, seed=5)

```

this fails with

```
ZeroDivisionError                         Traceback (most recent call last)
<ipython-input-11-86e4af7ca1ee> in <module>()
      1 import tensorflow as tf
      2 raw = tf.ones((2))
----> 3 tf.train.shuffle_batch([raw], batch_size=2, capacity=4, min_after_dequeue=4, seed=5)

/Users/yaroslav/anaconda/envs/tim-jan17/lib/python3.5/site-packages/tensorflow/python/training/input.py in shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, num_threads, seed, enqueue_many, shapes, allow_smaller_final_batch, shared_name, name)
   1220       allow_smaller_final_batch=allow_smaller_final_batch,
   1221       shared_name=shared_name,
-> 1222       name=name)
   1223 
   1224 

/Users/yaroslav/anaconda/envs/tim-jan17/lib/python3.5/site-packages/tensorflow/python/training/input.py in _shuffle_batch(tensors, batch_size, capacity, min_after_dequeue, keep_input, num_threads, seed, enqueue_many, shapes, allow_smaller_final_batch, shared_name, name)
    779     full = (math_ops.cast(math_ops.maximum(0, queue.size() - min_after_dequeue),
    780                           dtypes.float32) *
--> 781             (1. / (capacity - min_after_dequeue)))
    782     # Note that name contains a '/' at the end so we intentionally do not place
    783     # a '/' after %s below.

```

Unlike TF tensors, Python doesn't handle float division by zero. One solution is to wrap ""capacity"" and ""min_after_dequeue"" into TF tensors so that you get ""inf"" as a result instead of RuntimeError
"
1852,skflow save sets absolute paths for checkpoint that break on production,"### Environment info

Running on latest [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.7.1-cp27-none-linux_x86_64.whl).
### Steps to reproduce
1. Save an estimator to a folder (let's call it classifier.model)
2. Attempt to restore on another machine in different machine

This breaks since the checkpoint file is pointing to the place in the new machine.
### What have you tried?
1. Manually changing the path in the checkpoint file fixes the issue
"
1850,Surprising behaviour with distributed Tensorflow,"Hello, I'm observing some surprising behaviour with distributed Tensorflow, in terms of performance. In short, for the exact same Graph, I get a very different performance based on the machine I connect my tf.Session to.

In my experiments, I have two machines A and B in a cluster. Machine A has a GPU with cuDNN. I declare a graph that executes the cifar10 gpu example exclusively on machine A. No operators (including the variables) are declared on machine B. I log the device placement and Tensorboard does not see any operators associated with anything other device than machine A. 

When I execute the graph, starting my session using `tf.Session(""grpc://machineA:2222"", ...` results in significantly better performance than using `tf.Session(""grpc://machineB:2222"", ...`. It is also not just a constant overhead, as I increase the batch size, the difference seems to scale linearly:

| Batch Size | Connect to machine A | Connect to machine B |
| --- | --- | --- |
| 128 | 0.19s | 0.50s |
| 256 | 0.38s | 1.00s |
| 512 | 0.74s | 1.78s |
| 1024 | 1.42s | 3.38s |

(Averaged over 10 iterations not including the first two)

When looking at the output of `top` on machine B, it does seem like python is doing some work when I connect to machine B as it averages around 30% CPU vs ~0% otherwise, but I cannot tell what that is/how to prevent it.

I am working with Tensorflow installed from source with commit ed1a947d5b306d74af24821110dc2eb2f36c038a. 
"
1848,tensorflow version not updating to 0.7.1 using pip,"Hi,

I recently updated to tensorflow version 0.7.1 using the command:

`pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl`

If I run `pip show tensorflow`, then it gives me that version of tensorflow as `0.6.0`. However, `tf.__version__` in python gives me `0.7.1` 

I am using pip to install a few other dependencies(like prettytensor), it looks for the latest  version of tensorflow. Since it fails to find the latest version using pip, it isnt updating my other dependencies.

Please let me know if there is a workaround for this. Thanks in advance!
"
1846,the documentation of master branch on tensorflow.org is not updated,"the documentation of master branch on tensorflow.org is not updated
Still some old version of documents
"
1844,tensorflow/google/protobuf/BUILD:520:1: no such package 'util/python',"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:   redhat, tensorflow (0.5.0), bazel (0.1.1)

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce
1.  I am compiling tensorflow (0.5.0)  ,  run this :
   bazel build -c opt --spawn_strategy=standalone --genrule_strategy=standalone --jobs=20 //tensorflow/cc:tutorials_example_trainer
2.  The compile error looks like: 
   Object of type 'Label' has no field ""workspace_root""
   3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

ERROR: /opt/TensorFlow/tensorflow/tensorflow/core/BUILD:297:1: in _proto_gen rule //tensorflow/core:protos_all_cc_genproto: 
Traceback (most recent call last):
        File ""/opt/TensorFlow/tensorflow/tensorflow/core/BUILD"", line 297
                _proto_gen(name = 'protos_all_cc_genproto')
        File ""/opt/TensorFlow/tensorflow/google/protobuf/protobuf.bzl"", line 54, in _proto_gen_impl
                _GenDir(ctx)
        File ""/opt/TensorFlow/tensorflow/google/protobuf/protobuf.bzl"", line 11, in _GenDir
                ctx.label.workspace_root
Object of type 'Label' has no field ""workspace_root"".
ERROR: Analysis of target '//tensorflow/cc:tutorials_example_trainer' failed; build aborted.
INFO: Elapsed time: 16.462s
"
1843,Implement an efficient AssignMatMul() for general BLAS GEMM pattern,"TensorFlow currently lacks efficient in-place matrix updates such as rank-1 update `A += U V'`. @rmlarsen recommends supporting these in-place updates through a single new `AssignMatMul()` method that wraps the underlying GEMM kernels in Eigen or cuBlas etc.
"
1841,ValueError: No gradients provided for any variable,"I'm trying to optimize only a specific subset of my variables like so:

``` python
my_train = tf.train.RMSPropOptimizer(0.001).minimize(my_loss, var_list=my_variables)
```

This gives me an error message

```
ValueError: No gradients provided for any variable: ((None, <tensorflow.python.ops.variables.Variable object at 0x7f30317a5f10>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f303146fa10>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f3031522390>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f30314e1dd0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f30314a5fd0>), (None, <tensorflow.python.ops.variables.Variable object at 0x7f303146ae90>))
```

There is no error if I leave out the `var_list`, but this obviously isn't what I want, and from the error message it isn't clear to me what the problem is.
"
1839,"Got ""ValueError: array must not contain infs or NaNs"" error in word2vec_basic.py.","I ran https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py, and got ""ValueError: array must not contain infs or NaNs"" error from this line ""low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])"".
There wasn't any inf or Nan in final_embeddings[:plot_only,:].
I think it is scipy or numpy's issue. 
Is there any suggestion for me ?
### Environment info

Operating System:OS X EI Capitan 10.11.4
under anaconda python 3.5
numpy (1.11.0)
scipy (0.17.0)

Installed version of CUDA and cuDNN: 
Didn't install CUDA.

If installed from sources, provide the commit hash:
de5101da4638ac469041575dadb4921ebb33eb6a
### Steps to reproduce

python3 word2vec_basic.py
### Logs or other output that would be helpful

Traceback (most recent call last):
  File ""word2vec_basic.py"", line 237, in <module>
    low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only,:])
  File ""/Users/zhongzyd/anaconda/envs/TensorFlow-master/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 866, in fit_transform
    embedding = self._fit(X)
  File ""/Users/zhongzyd/anaconda/envs/TensorFlow-master/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 777, in _fit
    skip_num_points=skip_num_points)
  File ""/Users/zhongzyd/anaconda/envs/TensorFlow-master/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 832, in _tsne
    params, error, it = _gradient_descent(obj_func, params, **opt_args)
  File ""/Users/zhongzyd/anaconda/envs/TensorFlow-master/lib/python3.5/site-packages/sklearn/manifold/t_sne.py"", line 387, in _gradient_descent
    grad_norm = linalg.norm(grad)
  File ""/Users/zhongzyd/anaconda/envs/TensorFlow-master/lib/python3.5/site-packages/scipy/linalg/misc.py"", line 129, in norm
    a = np.asarray_chkfinite(a)
  File ""/Users/zhongzyd/anaconda/envs/TensorFlow-master/lib/python3.5/site-packages/numpy-1.11.0-py3.5-macosx-10.5-x86_64.egg/numpy/lib/function_base.py"", line 1022, in asarray_chkfinite
    ""array must not contain infs or NaNs"")
ValueError: array must not contain infs or NaNs
"
1836,Tensorboard can't work.,"### Environment info

Operating System: Mac OS X 10.11.4

Didn't install CUDA.

Under anaconda.

Installed from sources, provide the commit hash:
### Steps to reproduce

1.$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow
2.$ brew install bazel swig
3.$ cd tensorflow/
4.$ ./configure
Please specify the location of python. [Default is /anaconda/lib/python2.7]:
Do you wish to build TensorFlow with GPU support? [y/N] n
5.$ bazel build -c opt --define=use_fast_cpp_protos=true //tensorflow/tools/pip_package:build_pip_package
6.$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tenso
rflow_pkg
7.$ sudo pip install /tmp/tensorflow_pkg/tensorflow-0.7.1-py2-none-any.whl
### Try

1.$ python tensorflow/tensorflow/tensorboard/tensorboard.py --logdir=path/to/log-directory
didn't work
2.$ tensorboard --logdir=/path/to/log-directory
didn't work 
### Logs or other output that would be helpful

WARNING:tensorflow:IOError [Errno 2] No such file or directory: '//anaconda/lib/python2.7/site-packages/tensorflow/tensorboard/TAG' on path //anaconda/lib/python2.7/site-packages/tensorflow/tensorboard/TAG
WARNING:tensorflow:Unable to read TensorBoard tag
Starting TensorBoard  on port 6006
(You can navigate to http://0.0.0.0:6006)
"
1835,pdf version of the TF document,"Recently we often can't access https://www.tensorflow.org, could you provide a pdf version of the TF document, It will be very convenient for us

. 
"
1830,A way to get the last non-zero output of a variable-length RNN,"Feature request: The _sequence_length_ parameter in rnn.rnn() is a convenient way to support variable length sequences. The great thing about it is that it propagates the state at an example's sequence length to the final state output. However, it doesn't similarly propagate the output at an example's sequence length. This is the feature being requested here.

If one is interested in the last output only, reading outputs[-1] returns zeros for all the examples that are shorter than the max sequence length. It would simplify things considerably if there was a way to get the output value at the example's sequence length. 
"
1828,SparseTensor: common unary ops,"Currently, we have a slew of common unary ops that work on Tensors, but not SparseTensors ([ref](https://www.tensorflow.org/versions/r0.7/api_docs/python/math_ops.html#basic-math-functions)):

```
tf.pow()
tf.exp()
tf.log()

# lower priority?
tf.abs()
tf.neg()
tf.sign()
tf.inv()
tf.square()
tf.round()
tf.sqrt()
tf.ceil()
tf.floor()
```

and so on.

We'd like these ops to work on SparseTensor. These do not change the indices nor shape of `SparseTensor`s, so all that's needed is transform the `.values` field on Python side in O(1) line.
"
1825,Various matrix triangular functions. ,"A feature request.

At the moment as far as I'm aware TensorFlow doesn't have equivalents of the following numpy functionality:

1) np.tril: http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.tril.html and similarly
np.triu: http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.triu.html

2) np.tril_indeces http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.tril_indices.html and the upper triangular equivalent and the ability to assign to a tensor using them.

3) The ability to convert a vector to a lower or upper triangular square matrix which blas has. 

This sort of thing is useful for instance in linear algebra usages of TensorFlow. 

I am unaware of an easy work around for these but I would be happy to be wrong. 
"
1824,Profiling tools for open source TensorFlow ,"It would be very useful to understand which parts of the computational graph are causing computational bottlenecks.

This question has been asked on Stack Overflow here:

http://stackoverflow.com/questions/34293714/tensorflow-can-i-measure-the-execution-time-of-individual-operations

and here:

http://stackoverflow.com/questions/34629613/how-to-profile-tensorflow-networks

but it seems more appropriate as a feature request as this would allow systematic discussion. The TensorFlow white paper talks about very advanced internal tools that Google have along these lines. Something like that would make open source TensorFlow even better. I did it look at the road map but I'm not sure it explicitly mentioned this topic. 

My apologies if I have missed a post about this. 
"
1823,Saver optimistic restore,"Hello,

I have a feature request about `Saver`. Is it possible to add an option to stop it from complaining about absent variables in a checkpoint? Quite often when I experiment with different architectures, I change layers between runs, but want to reuse pretrained earlier checkpoints. An option ""just restore whatever you can from this checkpoint without complaining"" would be very useful. Now I play with `var_list`, but find it tiring and error-prone. Another idea is to retrieve variable names from a given checkpoint, but I couldn't find API for that.
"
1821,Basic Lstm cell giving NAN loss and 0 acuraccy.,"### Environment info

Operating System: Ubuntu 14.04 

Installed version of CUDA and cuDNN:  7.5 cudnnv4.0
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
-rw-r--r-- 1 root root 189170 Mr 29 12:20 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Mr 29 12:20 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Mr 29 12:20 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Mr 29 12:20 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Mr 29 12:20 /usr/local/cuda/lib/libcudart_static.a
```

If installed from binary pip package, provide:
1. Which pip package you installed. `sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl`
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

```
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.7.1

```

Hi,

I had modified [this](https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/recurrent_network.py) code to accept an input 4096 vector with 16 time steps.
and changed very little.
The loss is always nan and acuraccy 0.
I have tried several combinations of Learningrate/batchsize/optimizers with no change.

[Here Is my code.](http://pastebin.com/S1WcVNmk)
# Output

```
Iter 640, Minibatch Loss= nan, Training Accuracy= 0.75000
Testing Accuracy: 0.75
Iter 1280, Minibatch Loss= nan, Training Accuracy= 0.75000
Testing Accuracy: 0.0
Iter 1920, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 2560, Minibatch Loss= nan, Training Accuracy= 0.01562
Testing Accuracy: 0.0
Iter 3200, Minibatch Loss= nan, Training Accuracy= 0.01562
Testing Accuracy: 0.0
Iter 3840, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 4480, Minibatch Loss= nan, Training Accuracy= 0.03125
Testing Accuracy: 0.0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4696 get requests, put_count=4701 evicted_count=1000 eviction_rate=0.212721 and unsatisfied allocation rate=0.21678
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 256 to 281
Iter 5120, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 5760, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 6400, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.015625
Iter 7040, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 7680, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.015625
Iter 8320, Minibatch Loss= nan, Training Accuracy= 0.00000
```

Any ideas on y this is happening? 
"
1820,Tensorflow version of word2vec issue with huge corpora," Hi All,

I have the pip wheel distribution of Tensorflow r7.1 in Red Hat 6 in our cluster.

My issue is that I wanted to extract the embedding from a huge corpora (5*10 tokens), but  the 32 bit ""corpus_size_"" counter in ""word2vec_kernel.cc"" is not enough. It seems that it is not so straightforward to fix it (changing the counter to int64). 

I have seen that this very error was reported last  17th of Dec 2015 in issue #531.

I also receive the following error:

W tensorflow/models/embedding/word2vec_kernels.cc:59] Invalid argument: The text file wbu.txt contains too little data: -522037214 words
E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Invalid argument: The text file wbu.txt contains too little data: -522037214 words
E tensorflow/core/common_runtime/executor.cc:275] Executor failed to create kernel. Invalid argument: The text file wbu.txt contains too little data: -522037214 words
     [[Node: Skipgram = Skipgram[batch_size=16, filename=""wbu.txt"", min_count=5, subsample=0.001, window_size=5, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""word2vec_minibatch.py"", line 425, in <module>
    tf.app.run()
  File ""/opt/python-2.7/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""word2vec_minibatch.py"", line 411, in main
    model = Word2Vec(opts, session)
  File ""word2vec_minibatch.py"", line 175, in __init__
    self.build_graph()
  File ""word2vec_minibatch.py"", line 312, in build_graph
    opts.words_per_epoch) = self._session.run([words, counts, words_per_epoch])
  File ""/opt/python-2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 315, in run
    return self._run(None, fetches, feed_dict)
  File ""/opt/python-2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 511, in _run
    feed_dict_string)
  File ""/opt/python-2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 564, in _do_run
    target_list)
  File ""/opt/python-2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 586, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: The text file wbu.txt contains too little data: -522037214 words
     [[Node: Skipgram = Skipgram[batch_size=16, filename=""wbu.txt"", min_count=5, subsample=0.001, window_size=5, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'Skipgram', defined at:
  File ""word2vec_minibatch.py"", line 425, in <module>
    tf.app.run()
  File ""/opt/python-2.7/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""word2vec_minibatch.py"", line 411, in main
    model = Word2Vec(opts, session)

Thanx
"
1819,python cifar10_eval.py hang forever sometimes,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Linux ubuntu 4.2.0-27-generic #32-Ubuntu SMP Fri Jan 22 04:49:08 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
james@ubuntu:~/practice$ ls -l /usr/local/cuda*
lrwxrwxrwx 1 root root    8 Mar 29 13:21 /usr/local/cuda -> cuda-7.5

/usr/local/cuda-7.5:
total 32
drwxr-xr-x  3 root root 4096 Mar 29 14:48 bin
drwxr-xr-x  2 root root 4096 Mar 29 12:16 doc
lrwxrwxrwx  1 root root   28 Aug 16  2015 include -> targets/x86_64-linux/include
lrwxrwxrwx  1 root root   24 Aug 16  2015 lib64 -> targets/x86_64-linux/lib
-rw-r--r--  1 root root  365 Aug 16  2015 LICENSE
drwxr-xr-x  7 root root 4096 Mar 29 12:16 nvvm
-rw-r--r--  1 root root  365 Aug 16  2015 README
drwxr-xr-x 11 root root 4096 Mar 29 14:48 samples
drwxr-xr-x  3 root root 4096 Feb  3 18:04 targets
-rw-r--r--  1 root root   20 Aug 15  2015 version.txt

installed from docker.
tag   ""b.gcr.io/tensorflow/tensorflow:latest-devel-gpu""
(id:7f61540f94b2951574fd313b5980b850c7326933fc5a857779a36a94443c64cb)
### Steps to reproduce
1. pull images from docker
   2.docker run -it -v /lib/modules/4.2.0-22-generic:/lib/modules/4.2.0-22-generic -v /lib/modules/4.2.0-23-generic:/lib/modules/4.2.0-23-generic -v /lib/modules/4.2.0-25-generic:/lib/modules/4.2.0-25-generic -v /lib/modules/4.2.0-27-generic:/lib/modules/4.2.0-27-generic -v /usr/lib/x86_64-linux-gnu/libcuda.so:/usr/lib/x86_64-linux-gnu/libcuda.so -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/lib/x86_64-linux-gnu/libcuda.so.1 -v /usr/lib/x86_64-linux-gnu/libcuda.so.352.79:/usr/lib/x86_64-linux-gnu/libcuda.so.352.79 --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uvm -v /home/james:/home/james -P tensor-james
2. python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_train.py 
3. stop train after some checkpoint file been written to disk
4. python /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10/cifar10_eval.py  --run_once true
5. the last step hanging forever some times. 
### What have you tried?

1.I add some logs to the cifar10_eval.py and it comes out that all threads of queue runner is active, and  it is hanging at the first call to   `predictions = sess.run([top_k_op])`

print([t.isAlive() for t in threads]);
      while step < num_iter and not coord.should_stop():
        print(""begin step %d;"" %(step))
        predictions = sess.run([top_k_op])
        print(""step %d: %d;"" %(step, true_count))

[train_checkpoints.zip](https://github.com/tensorflow/tensorflow/files/209762/train_checkpoints.zip)
### Logs or other output that would be helpful

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
...
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning N
UMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.291
pciBusID 0000:01:00.0
Total memory: 5.99GiB
Free memory: 5.43GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
... 
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 5.14GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x706400000 extends to 0x84ef38000
"
1817,400 Bad Request caused by https://github.com/google/boringssl.git:,"GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
yunlong@dl-y9:~/github/tensorflow$ ls -l /usr/local/cuda/lib/libcud*
-rw-r--r-- 1 root root 189170 Mar 19 15:48 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Mar 19 15:48 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Mar 19 15:48 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Mar 19 15:48 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Mar 19 15:48 /usr/local/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
commit 51f5f6be3ede7242b01c4bdf136de938fd00839f
### Steps to reproduce

yunlong@dl-y9:~/github/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
ERROR: /home/yunlong/github/tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:207:1: no such package '@grpc//': Error cloning repository: https://github.com/google/boringssl.git: 400 Bad Request caused by https://github.com/google/boringssl.git: 400 Bad Request and referenced by '//tensorflow/core/distributed_runtime/rpc:grpc_server_lib'.
ERROR: Loading failed; build aborted.
INFO: Elapsed time: 0.189s
### What have you tried?

yunlong@dl-y9:~/tmp$ git clone https://github.com/google/boringssl.git
Cloning into 'boringssl'...
remote: Counting objects: 24195, done.
remote: Compressing objects: 100% (117/117), done.
Receiving objects:  12% (3019/24195), 2.64 MiB | 256.00 KiB/s     
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1816,`tf.reverse_sequence()` doesn't work with arguments of totally unknown shape.,"From [Stack Overflow](http://stackoverflow.com/questions/36480456/dynamic-rnn-and-array-ops-reverse-sequence-problems):

> I am trying to reverse my inputs with array_ops.reverse_sequence() before sending it to dynamic_rnn(), the inference graph can be build with no problem, but when building the training graph, I got the following error:
> 
> ```
>   Traceback (most recent call last):
>   File ""bin/trainer.py"", line 158, in <module>
>     kmer_len=args.kmer_len)
>   File ""/home/ubuntu/GIT/IvyMike/ivymike/base_model.py"", line 193, in run_training
>     train_op = model.training(loss, learning_rate)
>   File ""/home/ubuntu/GIT/IvyMike/ivymike/base_model.py"", line 100, in training
>     train_op = optimizer.minimize(loss, global_step=global_step)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 190, in minimize
>     colocate_gradients_with_ops=colocate_gradients_with_ops)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py"", line 241, in compute_gradients
>     colocate_gradients_with_ops=colocate_gradients_with_ops)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py"", line 481, in gradients
>     in_grads = _AsList(grad_fn(op, *out_grads))
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_grad.py"", line 307, in _ReverseSequenceGrad
>     seq_lengths=seq_lengths),
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"", line 1143, in reverse_sequence
>     batch_dim=batch_dim, name=name)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
>     op_def=op_def)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2119, in create_op
>     set_shapes_for_outputs(ret)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1586, in set_shapes_for_outputs
>     shapes = shape_func(op)
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py"", line 1257, in _ReverseSequenceShape
>     (batch_dim, input_shape.ndims))
> TypeError: %d format: a number is required, not NoneType
> ```

The problem appears to arise when `input_shape.ndims` is `None` (which is a valid possibility).
"
1815,"feature request: ""a trou""  (with hole algorithm)","To generate dense feature maps (e.g. semantic segmentation) the convolution and the maxpooling operators should have the option to define ""holes"" in the kernel.
The concept is used  in the paper:
Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs
(Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille)

and it is implemented in the excellent  deeplab library based on Caffe.
"
1814,Implementing a Siamese Network,"I want to implement a Siamese Convolutional Neural Network, where two images share weights in the convolutional layers, and are then concatenated before being passed through the fully-connected layers. I have tried an implementation, but it seems rather a ""hacked"" solution. In particular, I have defined an operation on tensors as simply a Python function, and I'm not sure whether this is allowed.

Here is the code I have tried:

```
images = tf.placeholder(tf.float32, shape=[None, 64 * 64])
# Convolutional layers
# ...
# ...
# Results in pool3_flat, which is the flattened output of the third convolutional layer
pool3_flat = tf.reshape(pool3, [-1, 8 * 8 * 128])

# Now, merge the image pairs, where each pair is composed of adjacent images in the batch, with a stride of 2
def merge_pairs():
  # Create a tensor to store the merged image pairs
  # The batch size is 128, therefore there will be 64 pairs (64 in the first dimension of this tensor)
  merged_pairs = tf.Variable(tf.zeros([64, 8 * 8 * 128]))
  # Split the images into 64 pairs
  pairs = tf.split(0, 64, pool3_flat)
  # For each pair, concatenate the two images across dimension 1, and set this tensor in the appropriate row of merged_pairs
  for pair_num, pair in enumerate(pairs):
    merged_pair = tf.concat(1, pair)
    merged_pairs[pair_num] = merged_pair

# Proceed with operations on the merged_pair tensor, as if the batch size is 64
fc4 = tf.matmul(merge_pairs, weights4)
# ...
# ...
```

When running this, I get the following error message:

`TypeError: Expected binary or unicode string, got <function merge_pairs at 0x7f006edbed70>`

So it seems that I cannot simple replace a TensorFlow operation with a Python function. Is there a way to implement a Siamese network using built-in operations in TensorFlow?
"
1813,[feature request] port benchmarks to google benchmark,"you have a simple benchmark framework in tensorflow/tensorflow/core/platform/test_benchmark.h but i was curious if you'd be interested in integrating with github.com/google/benchmark instead.

i'm happy to help with the integration if you are.
"
1812,model parameters contains a lot of 'nan' at certain stage of training using AdamOptimizer,"I am training a deep neural network using a simple and well defined case. The training goes very well and reach a high accuracy (~95%), and then, suddenly, just one step iteration, the accuracy is drop to almost zero. I then printed out all the model parameters, and there are lot of 'nan', something like this 
....0.076455489, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 0.08646702....

Here is the information about my system.

1) Installation. I installed tensor flow from source code on AWS ubuntu g2 instance (GPU instance). During the installation, I use customized configuration so that the tensor flow can run on g2 instance with computing capacity 3.0. 

2) DNN structure: I have a 30 hidden fully connected layers. Each layer has 32 nodes. To make the DNN more stable, I have added short-cuts for every three layers (similar to a recent publication from Microsoft Research ""Deep Residual Learning for Image Recognition"", by Kaiming He et al.) 

3) Optimizer: AdamOptimizer. 
  I first found the problem with AdamOptimzer. However, I just realized that the same problem also happens to GradientDescentOptimizer.

4) Procedure to produce the bug. 

I have a saved model, which has good accuracy, and I restart the training by reading the saved model, and the problem shows up for the first iteration. 

I wonder if this is a known issue or not. I would be happy to provide my code and input data if this is necessary. I need to create a simple case with simplified code as I am working on a production code that I cannot post it here. 
"
1811,Python 3 not installing in virtual environment,"Using Tensorflow 0.7.1

I have tried to install the Python 3 version of Tensorflow in a Virtual environment but I think it didn't work since the command

$ python3 -c 'import os; import inspect; import tensorflow; print(os.path.dirname(inspect.getfile(tensorflow)))' 

returned

$ /usr/local/lib/python3.4/dist-packages/tensorflow

instead of

/home/dlm/tensorflow/local/lib/python3.4/site-packages/tensorflow

I was sure I had activated the tensorflow virtual env before insstaling tensorflow with suport to python 3.
"
1810,segmentation fault 11 when call Node's name method,"I try to write a cnn using tensorflow and I want to use the c++ api. When I create a node using the api in   cc folder, it is fine, for example:
Node\* images_identity = Identity(images, b.opts().WithName(""images_identity""));
but when I use images_identity->name(), it will show a segmentation fault 11. It confuses me a lot. How should i get the name of the node if i want to ?
"
1808,Python 3.5 Wheel,"Thanks for all your work so far.

Is there any chance of providing a wheel for Python 3.5? I have been having a rough time trying to install it from scratch and a wheel would be very helpful!
"
1807,KeyError: u'PlaceholderWithDefault' while running transfer learning model through Python,"I followed the transfer learning example, and trained on my own image to create my model file. Then in the classify_image.py file, in place of the original 'classify_image_graph_def.pb' file, I replaced it with my model. However, while running I get the following error:

```
Traceback (most recent call last):
  File ""classify_image.py"", line 214, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""classify_image.py"", line 210, in main
    run_inference_on_image(image)
  File ""classify_image.py"", line 158, in run_inference_on_image
    create_graph()
  File ""classify_image.py"", line 141, in create_graph
    _ = tf.import_graph_def(graph_def, name='')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 227, in import_graph_def
    op_def = op_dict[node.op]
KeyError: u'PlaceholderWithDefault'

```

I can run my model fine through the terminal using bazel. Only through Python it is crashing. I'm using version 0.7.1.
Do I need to make any more changes in code before running?
"
1803,Core Dump Error on running examples,"I am getting Core dump errors on running the example codes (e.g convolutional.py on mnist).  Installed it through pip (Linux 64 bit, gpu enabled).  The output is below. 

Doing simple graph construction  ( [here](https://www.tensorflow.org/versions/r0.7/how_tos/using_gpu/index.html) ) to check gpu device works fines. 

I already checked [1534](https://github.com/tensorflow/tensorflow/issues/1534) but in my case the compute mode for GPU is set to default. So I don't think that is the problem. 

What could be the problem then ? 

---

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:02:00.0
Total memory: 11.25GiB
Free memory: 11.15GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.60GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xf047a0000 extends to 0x11aa9d1e67
Floating point exception (core dumped)

---
"
1802,Max Pooling Across Batch Dimension,"I would like to use Tensor Flow to do max pooling over images. For example, with 10 images of size 500x500, this would yield a single image of size 500x500, where each pixel is the max of that pixel coordinate across the 10 images.

To do this, I tried:

```
`image_pool = tf.nn.max_pool(input, ksize=[10, 1, 1, 1], strides=[10, 1, 1, 1], padding='VALID')`
```

Here, the ideas is that for each batch of images, every sub-batch of 10 images is pooled into a single image. However, this gives me the error message:

```
`ValueError: Current implementation does not support pooling in the batch dimension.`
```

Therefore it appears that right now, this function is not yet supported in this way. So, firstly, it would be great if a later version would support this. And secondly, I'm wondering if there is another way to achieve what I want by using existing tools in Tensor Flow, or otherwise?
"
1801,Can't reshape tensor,"I'm getting a strange error when trying basic reshape operations:

``` python
import tensorflow as tf
t = tf.constant([0, 1])
tf.reshape([2, 1], t) # should be [[0], [1]]
```

This gives me the following error:

```
ValueError: Cannot reshape a tensor with 2 elements to shape [0, 1] (0 elements)
```
"
1799,One hot embedding?,"I'd like to embed integer labels into a fixed dimension space via the classic one-hot embedding. Here is an example:

```
onehot(inputs=[0, 2], num_labels=4) -> [[1, 0, 0, 0], [0, 0, 1, 0]]
```

It seems that sparse_to_dense does something similar, but not quite what I want. I've found some solutions online but they are rather convoluted. Is there a straightforward way to do this in tensorflow?
"
1798,Saving custom graph collections in graph_def,"Would be useful to facilitate, e.g., restoring desired subset of nodes when re-loading model with graph_def if custom graph collections were persisted.
"
1797,No way to re-enter previous name/variable-scoped context,"As far as I can tell, there is no way to re-enter the same name_scope or variable_scope (once closed) without the name being ""unique-ified.""

The [example in the docs](https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#Graph.name_scope) shows how to re-enter the original scope from within a nested scope - but not when context is closed.

Perhaps this could be solved by enabling access to the scope reference as `tf.Variable.scope` ?

Current hack-y workaround is to manually specify variable name as `""{}/name"".format(previous_scope_name)`
"
1796,Tensorflow serving with transfer learning retrained inception model,"Hi

Trying to use a retrained inception model (as in the transfer learning tutorial) with Tensorflow serving as described by the example, [here](https://tensorflow.github.io/serving/serving_basic). However, I am unclear how to set up the exporter.

The exporter flow as shown in the tutorial looks as such:

`
 export_path = sys.argv[-1] print 'Exporting trained model to', export_path saver = tf.train.Saver(sharded=True) model_exporter = exporter.Exporter(saver) signature = exporter.classification_signature(input_tensor=x, scores_tensor=y) model_exporter.init(sess.graph.as_graph_def(), default_graph_signature=signature) model_exporter.export(export_path, tf.constant(FLAGS.export_version), sess) 
`

Since there is no ""input_tensor"" and ""scores_tensor"" as described by this tutorial within the Inception transfer learning, I am unsure of what tensors to use to get the signature. The bottleneck tensor? The ground_truth tensor?

I'd love an explanation of how to set up this retrained model with Tensorflow Serving as shown in this example!

Thanks

Oren
"
1793,Missing gradient for tf.nn.max_pool_with_argmax,"I swapped out the first max_pool operation in [convolutional.py](https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/mnist/convolutional.py) tutorial for a max_pool_with_argmax operation and there doesn't seem to exist a gradient for that op:

`(virtenv)$ python convolutional.py`
`Extracting data/train-images-idx3-ubyte.gz`
`Extracting data/train-labels-idx1-ubyte.gz`
`Extracting data/t10k-images-idx3-ubyte.gz`
`Extracting data/t10k-labels-idx1-ubyte.gz`
`Traceback (most recent call last):`
`File ""convolutional.py"", line 316, in <module>`
`tf.app.run()`
`File ""/home/name/virtenv/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run`
`sys.exit(main(sys.argv))`
`File ""convolutional.py"", line 244, in main`
`global_step=batch)`
`File ""/home/name/virtenv/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 190, in minimize`
`colocate_gradients_with_ops=colocate_gradients_with_ops)`
`File ""/home/name/virtenv/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 241, in compute_gradients`
`colocate_gradients_with_ops=colocate_gradients_with_ops)`
`File ""/home/name/virtenv/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 453, in gradients`
`(op.name, op.type))`
`LookupError: No gradient defined for operation 'MaxPoolWithArgmax' (op type: MaxPoolWithArgmax)`
### Environment info

Operating System: Ubuntu 14.04.1 LTS

If installed from binary pip package, provide:

(virtenv)$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
(virtenv)$ python -c ""import tensorflow; print(tensorflow.**version**)""
0.7.1
### Steps to reproduce
1. Change line 192-5 of [convolutional.py](https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/models/image/mnist/convolutional.py) from:
   
   `pool = tf.nn.max_pool(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')`
   
   to:
   
   `pool, pos = tf.nn.max_pool_with_argmax(relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')`
2. Run:
   
   `(virtenv)$ python convolutional.py`
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1792,FIFOQueue stopping early when graph restored from checkpoint,"I'm running into an issue when evaluating a previously-trained graph on test data: namely, the FIFOQueue returned by `tf.train.string_input_producer` is iterating fewer times over the data than the `num_epochs` parameter I give it.

More specifically, I have my data stored as `.tfrecords` files, separated into training/validation/test sets.  To both train and evaluate the model, I do the following:
1. Get the input data from a call to `tf.train.string_input_producer(trainingdata, num_epochs=N, shuffle=True)`
2. instantiate a `tf.train.Coordinator()`
3. Call `tf.train.start_queue_runners`
4. Run the following loop:

``` python
try:
    while not coord.should_stop():
        # run the appropriate operations
except tf.errors.OutOfRangeError:
    print('Halting -- epoch limit reached.')
finally:
    coord.request_stop()
coord.join(threads)
```

For training, I train the model for multiple epochs on the training data, saving a checkpoint every half epoch.

Then, for evaluation, I restore the graph from one of those checkpoints as follows:
1. Instantiate the input variables from the data pipeline as above
2. Use those to construct the graph
3. Call `tf.train.Saver().restore()` to restore the graph from the appropriate checkpoint

The problem is, an `OutOfRangeError` is getting thrown the very first time I call `sess.run()` on any node.  If I keep increasing the number of epochs for the evaluation, I can eventually get it to actually iterate over the data (e.g. using `num_epochs=4` may give me 1 iteration over the data).  It's consistent with the same checkpoint file (e.g. if `num_epochs=4` gives me 1 iteration, `num_epochs=5` gives me 2, etc.), but it varies between checkpoint files.  It also does not seem to be consistent with the number of training epochs that had been completed when the checkpoint was saved.

My expectation is that using `num_epochs=1` when initializing the data pipeline for the evaluation should be fine for doing a single iteration over those data points.  What am I missing?
## Environment info

Operating System: RHEL
TF commit hash: f82ad360140a2078afcef6af40ad6ec75bd11c1 (version 7.0)
Python version: 3.5.1
"
1791,`GLIBCXX_3.4.14' not found (required by tensorflow/_bin/build-runfiles),"I get that a version of GLIBC is not found when I try to build. I am running Linux Redhat Enterprise 6, with `java/1.8.0_31,  gcc/5.2.0,  python/2.7.5, cuda/7.5`.

Any help will be greatly appreciated. Thank you -- 

```
[davido@dev1 tensorflow]$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer
Warning: ignoring _JAVA_OPTIONS in environment.
WARNING: Output base '/home/davido/.cache/bazel/_bazel_davido/cc29e96f6fa78af6982c629de060eac7' is on NFS. This may lead to surprising failures and undetermined behavior.
...........
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
ERROR: /home/davido/tensorflow/tensorflow/cc/BUILD:28:1: Creating runfiles tree bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc.runfiles [for host] failed: build-runfiles failed: error executing command /home/davido/.cache/bazel/_bazel_davido/cc29e96f6fa78af6982c629de060eac7/tensorflow/_bin/build-runfiles bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc.runfiles_manifest ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
/home/davido/.cache/bazel/_bazel_davido/cc29e96f6fa78af6982c629de060eac7/tensorflow/_bin/build-runfiles: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.14' not found (required by /home/davido/.cache/bazel/_bazel_davido/cc29e96f6fa78af6982c629de060eac7/tensorflow/_bin/build-runfiles)
Target //tensorflow/cc:tutorials_example_trainer failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 7.223s, Critical Path: 0.05s
```
"
1790,ImportError: No module named 'tensorflow.tensorboard.tensorboard',"When I try:

```
tensorboard --logdir=/path/to/eventlogs
```

I get

```
ImportError: No module named 'tensorflow.tensorboard.tensorboard'
```
## Packages

I use Ubuntu 14.04, Python 3.4.3 and I installed tensorflow using:

```
pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp34-none-linux_x86_64.whl
```
"
1787,CUDNN_STATUS_BAD_PARAM with included cifar10 model,"### Environment info

Operating System:
Debian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux
Python 2.7

If installed from binary pip package, provide:
1. Which pip package you installed.
   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
   0.7.1
### Steps to reproduce
1. Go to /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10
2. Run python cifar10_train.py as root
3. Observe output 
   F tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
   Aborted
### What have you tried?
1. Messing with LD_LIBRARY_PATH and making sure all cuda packages are updated to 7.5 (and CudNN 5.0). Training the simple softmax models on GPU is possible.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
root@leviathan:/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10# python cifar10_train.py 
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
... Loads other CUDA libraries as above ...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:01:00.0
Total memory: 11.25GiB
Free memory: 11.15GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
... and so on up to 16.00 GB:
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.60GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x5047a0000 extends to 0x7aaa4019a
F tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
Aborted
"
1786,feature request: support for cudnn v5 rc,"Anyone can help this?
https://developer.nvidia.com/rdp/cudnn-download
"
1784,Add support for stochastic depth networks,"This issue is a feature request to add support to tensorflow to implement networks with stochastic depth (http://arxiv.org/abs/1603.09382).
"
1783,feature request: complex64 support in diag op,"[`tf.diag`](https://www.tensorflow.org/versions/r0.7/api_docs/python/math_ops.html#diag) only supports `float32`, `float64`, `int32`, `int64` right now; is it possible to also include `complex64`? 

I may get around to extending the op to do this for my own purposes, but perhaps someone else is better positioned to add this functionality. Or is there some deeper reason it's not supported?
"
1782,Why doesn't TensorBoard order objects according to information flow?,"I would infer that TensorBoard orders objects according to how information flows through the graph, but this doesn't appear to be the case. Namely, considering Inception-v3. The operation makes it clear that, in each conv unit, batch normalization is performed on the output of the convolution layer:

```
conv = tf.nn.conv2d(inputs, weights, [1, stride, stride, 1],
                    padding=padding)
if batch_norm_params is not None:
  with scopes.arg_scope([batch_norm], is_training=is_training,
                        trainable=trainable, restore=restore):
    outputs = batch_norm(conv, **batch_norm_params)
```

i.e., `outputs` is `batch_norm(conv(inputs, ...), ...)`

However, the TensorBoard representation of the graph orders `batch_norm` before the `conv` operation. 

![screenshot from 2016-04-05 11 15 36](https://cloud.githubusercontent.com/assets/6423093/14293082/e17a1776-fb1f-11e5-8073-341d087f11cb.png)

Granted, these don't appear to be connected by a line. However, it _does_ order the convolutions correctly:

![screenshot from 2016-04-05 11 17 32](https://cloud.githubusercontent.com/assets/6423093/14293119/031168da-fb20-11e5-9c7a-8f2c6596088f.png)

Is this due to the fact that these nodes are disconnected ""given"" `Identity...` and are thereby ordered alphabetically? Is there a way to disable this, and have it structure the graph according to the flow of information? Presumably it can disambiguate between the various `Identity...` nodes. Or am I interpreting this situation wrong?
"
1781,[Question] Nightly wheels,"Are you generating the wheels nightly?
If so, that would be interesting to have access to them, given as is of course.
"
1779,Request: dynamic RNN in bidirectional_rnn(),"The bidirectional_rnn() is not taking the advantages of dynamic_rnn(), it runs into memory issues for even moderate length of time steps. I guess this should be really easy to implement, but a really big help for people using the bidirectional version.

Thanks!

Jiajie  
"
1778,error during buile tensorflow_demo,"I installed tensorflow from sources. convolution.py works well
but when I try to build android demo apk, I got the build error
It is looking for libz.so.1. which package include it?
### Environment info

Operating System: 14.04.1-Ubuntu

I installed from sources
### Steps to reproduce
1. in WORKSPACE
   android_sdk_repository(
   name = ""androidsdk"",
   api_level = 21,
   build_tools_version = ""21.0.1"",
   path = ""../../Android/android-sdk-linux/"",
   )

android_ndk_repository(
    name=""androidndk"",
    path = ""../../Android/android-ndk-r10e/"",
    api_level=21)

2.bazel build //tensorflow/examples/android:tensorflow_demo

3.error message is like this
Exception in thread ""main"" Error: Failed to run command:
        bazel-out/host/bin/external/androidsdk/aapt_binary s -i /tmp/android_resources_tmp451471447479393920/tmp-deduplicated/tensorflow/examples/android/res/drawable-hdpi/ic_action_info.png -o /tmp/android_resources_tmp451471447479393920/merged_resources/drawable-hdpi-v4/ic_action_info.png
Error Code:
        127
Output:
        bazel-out/host/bin/external/androidsdk/aapt_binary.runfiles/external/androidsdk/build-tools/21.0.1/aapt: error while loading shared libraries: libz.so.1: cannot open shared object file: No such file or directory
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1774,Bazel build fails /usr/lib/tensorflow/tensorflow/cc/BUILD:28:1,"Ubuntu 15.10
cuda v 7.5
python v 2.7
jdk8
gcc 4.9
980Ti

Installing from source: 
b0774e1b473494dc4e2434ae20295a9fdf433867

ERROR: /usr/lib/tensorflow/tensorflow/cc/BUILD:28:1: Linking of rule '//tensorflow/cc:ops/state_ops_gen_cc' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/e14db5a97cb9042cd7bbcf71326995ef/tensorflow && \
  exec env - \
  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/cc/ops/state_ops_gen_cc '-Wl,-rpath,$ORIGIN/../../../_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64' -Lbazel-out/host/bin/_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64 bazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a -Wl,-whole-archive bazel-out/host/bin/tensorflow/core/libstate_ops_op_lib.lo -Wl,-no-whole-archive -Wl,-whole-archive bazel-out/host/bin/tensorflow/core/libframework_internal.lo -Wl,-no-whole-archive bazel-out/host/bin/tensorflow/core/liblib_internal.a bazel-out/host/bin/external/jpeg_archive/libjpeg.a bazel-out/host/bin/external/png_archive/libpng.a bazel-out/host/bin/external/re2/libre2.a bazel-out/host/bin/tensorflow/core/libprotos_all_cc.a bazel-out/host/bin/google/protobuf/libprotobuf.a bazel-out/host/bin/google/protobuf/libprotobuf_lite.a -lcudart -lm -ldl -lm -ldl -lz -pthread -lpthread -Wl,-rpath,third_party/gpus/cuda/lib64 -lstdc++ -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,-S -Wl,--gc-sections): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a(cc_op_gen.o): In function `std::string* tensorflow::internal::Check_EQImpl<tensorflow::Status, tensorflow::Status>(tensorflow::Status const&, tensorflow::Status const&, char const*)':
cc_op_gen.cc:(.text._ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc[_ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc]+0x2d): undefined reference to`tensorflow::Status::ToString() const'
cc_op_gen.cc:(.text._ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc[_ZN10tensorflow8internal12Check_EQImplINS_6StatusES2_EEPSsRKT_RKT0_PKc]+0x38): undefined reference to `tensorflow::Status::ToString() const'
bazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a(cc_op_gen.o): In function`tensorflow::(anonymous namespace)::WriteCCOp(tensorflow::OpDef const&, tensorflow::WritableFile_, tensorflow::WritableFile_)':
cc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0x8b9): undefined reference to `tensorflow::Status::ToString() const'
cc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0x8d2): undefined reference to`tensorflow::Status::ToString() const'
cc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0xc15): undefined reference to `tensorflow::Status::ToString() const'
bazel-out/host/bin/tensorflow/cc/libcc_op_gen_main.a(cc_op_gen.o):cc_op_gen.cc:(.text._ZN10tensorflow12_GLOBAL__N_19WriteCCOpERKNS_5OpDefEPNS_12WritableFileES5_+0xc2e): more undefined references to`tensorflow::Status::ToString() const' follow
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(attr_value_util.o): In function `tensorflow::(anonymous namespace)::SummarizeTensor(tensorflow::TensorProto const&)':
attr_value_util.cc:(.text._ZN10tensorflow12_GLOBAL__N_115SummarizeTensorERKNS_11TensorProtoE+0x65): undefined reference to`google::protobuf::Message::ShortDebugString() const'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(attr_value_util.o): In function `tensorflow::ParseAttrValue(tensorflow::StringPiece, tensorflow::StringPiece, tensorflow::AttrValue*)':
attr_value_util.cc:(.text._ZN10tensorflow14ParseAttrValueENS_11StringPieceES0_PNS_9AttrValueE+0x207): undefined reference to`google::protobuf::TextFormat::ParseFromString(std::string const&, google::protobuf::Message_)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(attr_value_util.o): In function `tensorflow::SummarizeAttrValue(tensorflow::AttrValue const&)':
attr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0x3f4): undefined reference to`google::protobuf::internal::empty_string_'
attr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0x4d8): undefined reference to `google::protobuf::internal::NameOfEnum(google::protobuf::EnumDescriptor const_, int)'
attr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0x54c): undefined reference to `google::protobuf::internal::empty_string_'
attr_value_util.cc:(.text._ZN10tensorflow18SummarizeAttrValueERKNS_9AttrValueE+0xda9): undefined reference to `google::protobuf::internal::NameOfEnum(google::protobuf::EnumDescriptor const*, int)'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o): In function`tensorflow::OpRegistry::Register(tensorflow::OpDef const&)':
op.cc:(.text._ZN10tensorflow10OpRegistry8RegisterERKNS_5OpDefE+0x91): undefined reference to `tensorflow::Status::ToString() const'
op.cc:(.text._ZN10tensorflow10OpRegistry8RegisterERKNS_5OpDefE+0xaa): undefined reference to`tensorflow::Status::ToString() const'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o): In function `tensorflow::OpRegistry::CallDeferred() const [clone .part.129]':
op.cc:(.text._ZNK10tensorflow10OpRegistry12CallDeferredEv.part.129+0x159): undefined reference to`tensorflow::Status::ToString() const'
op.cc:(.text._ZNK10tensorflow10OpRegistry12CallDeferredEv.part.129+0x168): undefined reference to `tensorflow::Status::ToString() const'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o): In function`tensorflow::OpRegistry::LookUp(std::string const&, tensorflow::Status*) const':
op.cc:(.text._ZNK10tensorflow10OpRegistry6LookUpERKSsPNS_6StatusE+0x110): undefined reference to `tensorflow::Status::ToString() const'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op.o):op.cc:(.text._ZNK10tensorflow10OpRegistry6LookUpERKSsPNS_6StatusE+0x129): more undefined references to`tensorflow::Status::ToString() const' follow
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o): In function `tensorflow::OpDefBuilder::OpDefBuilder(tensorflow::StringPiece)':
op_def_builder.cc:(.text._ZN10tensorflow12OpDefBuilderC2ENS_11StringPieceE+0xd4): undefined reference to`google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o): In function `tensorflow::(anonymous namespace)::FinalizeAttr(tensorflow::StringPiece, tensorflow::OpDef*, std::vector<std::string, std::allocator<std::string> >*)':
op_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_112FinalizeAttrENS_11StringPieceEPNS_5OpDefEPSt6vectorISsSaISsEE+0x32d): undefined reference to`google::protobuf::internal::empty_string_'
op_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_112FinalizeAttrENS_11StringPieceEPNS_5OpDefEPSt6vectorISsSaISsEE+0x5ff): undefined reference to `google::protobuf::internal::empty_string_'
op_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_112FinalizeAttrENS_11StringPieceEPNS_5OpDefEPSt6vectorISsSaISsEE+0xc06): undefined reference to `google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o): In function `tensorflow::(anonymous namespace)::FinalizeInputOrOutput(tensorflow::StringPiece, bool, tensorflow::OpDef*, std::vector<std::string, std::allocator<std::string> >*)':
op_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_121FinalizeInputOrOutputENS_11StringPieceEbPNS_5OpDefEPSt6vectorISsSaISsEE+0x36a): undefined reference to`google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_builder.o):op_def_builder.cc:(.text._ZN10tensorflow12_GLOBAL__N_121FinalizeInputOrOutputENS_11StringPieceEbPNS_5OpDefEPSt6vectorISsSaISsEE+0xaee): more undefined references to `google::protobuf::internal::empty_string_' follow
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `void tensorflow::errors::AppendToMessage<char const*, std::string, char const*, std::string, char const*>(tensorflow::Status*, char const*, std::string, char const*, std::string, char const*)':
op_def_util.cc:(.text._ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_SsS3_EEEvPNS_6StatusEDpT_[_ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_SsS3_EEEvPNS_6StatusEDpT_]+0x208): undefined reference to`tensorflow::Status::empty_string()'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `void tensorflow::errors::AppendToMessage<char const*, std::string, char const*>(tensorflow::Status*, char const*, std::string, char const*)':
op_def_util.cc:(.text._ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_EEEvPNS_6StatusEDpT_[_ZN10tensorflow6errors15AppendToMessageIIPKcSsS3_EEEvPNS_6StatusEDpT_]+0x201): undefined reference to`tensorflow::Status::empty_string()'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `tensorflow::ValidateAttrValue(tensorflow::AttrValue const&, tensorflow::OpDef_AttrDef const&)':
op_def_util.cc:(.text._ZN10tensorflow17ValidateAttrValueERKNS_9AttrValueERKNS_13OpDef_AttrDefE+0x472): undefined reference to`google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o): In function `tensorflow::ValidateArg(tensorflow::OpDef_ArgDef const&, tensorflow::OpDef const&, bool, std::set<std::string, std::less<std::string>, std::allocator<std::string> >*)':
op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x15e): undefined reference to`google::protobuf::Message::ShortDebugString() const'
op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x1c9): undefined reference to `google::protobuf::Message::ShortDebugString() const'
op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x247): undefined reference to`google::protobuf::Message::ShortDebugString() const'
op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x285): undefined reference to `google::protobuf::Message::ShortDebugString() const'
op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x393): undefined reference to`google::protobuf::Message::ShortDebugString() const'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_def_util.o):op_def_util.cc:(.text._ZN10tensorflowL11ValidateArgERKNS_12OpDef_ArgDefERKNS_5OpDefEbPSt3setISsSt4lessISsESaISsEE+0x539): more undefined references to `google::protobuf::Message::ShortDebugString() const' follow
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(tensor.o): In function`tensorflow::(anonymous namespace)::BufferBase::FillAllocationDescription(tensorflow::AllocationDescription*) const':
tensor.cc:(.text._ZNK10tensorflow12_GLOBAL__N_110BufferBase25FillAllocationDescriptionEPNS_21AllocationDescriptionE+0x40): undefined reference to `google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::OutputToLog(google::protobuf::Message const&)':
log_memory.cc:(.text._ZN10tensorflow9LogMemory11OutputToLogERKN6google8protobuf7MessageE+0x52): undefined reference to`google::protobuf::TextFormat::Printer::PrintToString(google::protobuf::Message const&, std::string*) const'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::RecordTensorAllocation(std::string const&, long long, tensorflow::Tensor const&)':
log_memory.cc:(.text._ZN10tensorflow9LogMemory22RecordTensorAllocationERKSsxRKNS_6TensorE+0x27): undefined reference to`google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(log_memory.o): In function `tensorflow::LogMemory::RecordTensorDeallocation(long long, std::string const&)':
log_memory.cc:(.text._ZN10tensorflow9LogMemory24RecordTensorDeallocationExRKSs+0x22): undefined reference to`google::protobuf::internal::empty_string_'
bazel-out/host/bin/tensorflow/core/libframework_internal.lo(op_kernel.o): In function `tensorflow::ValidateKernelRegistrations(tensorflow::OpRegistryInterface const&)':
op_kernel.cc:(.text._ZN10tensorflow27ValidateKernelRegistrationsERKNS_19OpRegistryInterfaceE+0x2b7): undefined reference to`google::protobuf::Message::ShortDebugString() const'
collect2: error: ld returned 1 exit status
Target //tensorflow/cc:tutorials_example_trainer failed to build
"
1772,tensorflow extremely slow on GPU,"MNIST example and CIFAR10 example run very slow on GPU, much slower than posted benchmarks for my specs (2 titan X).  GPU utilization very low when running these models.  Loading 20k images for CIFAR10 takes more than 10 mins
### Environment info

Operating System: Ubuntu 15.04, CUDA 7.5, cuDNN 3, gcc 4.9, numpy 1.7
1. Which pip package you installed.
   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
   tensorflow 0.6
### What have you tried?
1. reinstalling from source using bazel but problem persists
### Logs or other output that would be helpful

image/cifar10$ python cifar10_train.py
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Downloading cifar-10-binary.tar.gz 100.0%
Successfully downloaded cifar-10-binary.tar.gz 170052171 bytes.
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2405
pciBusID 0000:09:00.0
Total memory: 12.00GiB
Free memory: 11.21GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:06:00.0
Total memory: 12.00GiB
Free memory: 11.10GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.54GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb0d900000 extends to 0xdb057b99a
2016-04-04 11:00:46.190354: step 0, loss = 4.68 (0.1 examples/sec; 870.357 sec/batch)
2016-04-04 11:01:41.540616: step 10, loss = 4.66 (31.8 examples/sec; 4.029 sec/batch)

python convolutional.py
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2405
pciBusID 0000:09:00.0
Total memory: 12.00GiB
Free memory: 11.23GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.2155
pciBusID 0000:06:00.0
Total memory: 12.00GiB
Free memory: 11.12GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.56GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb0d900000 extends to 0xdb1a08b34
Initialized!
Step 0 (epoch 0.00), 10.2 ms
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Step 100 (epoch 0.12), 417.7 ms
Minibatch loss: 3.282, learning rate: 0.010000
Minibatch error: 6.2%
Validation error: 7.0%
Step 200 (epoch 0.23), 392.7 ms
Minibatch loss: 3.482, learning rate: 0.010000
Minibatch error: 14.1%
Validation error: 3.6%
"
1769,Bazel build Android shared object libtensorflow_demo.so fails with jni.h not found,"I'm trying to build a .so of the Tensorflow Android lib in order to include in the build process of an existing app. Bazel is able to build the full apk fine, but it's having trouble when I tell it to only build the .so, complaining that jni.h is not found.
### Environment info

Operating System:

Ubuntu 14.04 x64

If installed from binary pip package, provide:
1. Which pip package you installed:

https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
1. The output from python -c ""import tensorflow; print(tensorflow.**version**)"":
   0.7.1

If installed from sources, provide the commit hash:
### Steps to reproduce
1.  bazel build //tensorflow/examples/android:libtensorflow_demo.so
2. You get the error message: 

ERROR: /Code/tensorflow/tensorflow/examples/android/BUILD:12:1: C++ compilation of rule '//tensorflow/examples/android:libtensorflow_demo.so' failed: namespace-sandbox failed: error executing command /home/user/.cache/bazel/_bazel_user/460c757144c1d801a3560f7277d7643a/tensorflow/_bin/namespace-sandbox ... (remaining 63 argument(s) skipped).
In file included from tensorflow/examples/android/jni/jni_utils.cc:16:0:
./tensorflow/examples/android/jni/jni_utils.h:19:17: fatal error: jni.h: No such file or directory
 #include <jni.h>
                 ^
compilation terminated.
### What have you tried?
1. Running bazel build //tensorflow/examples/android:tensorflow_demo does in fact work correctly.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1768,Show responsible nodes when ValueError: No gradients provided for any variable,"The error message 

```
ValueError: No gradients provided for any variable
```

Is not particularly informative and it would be nice to see if there is a node preventing the gradient calculation (ie Gradient Cannot be calculated for `Cast` or `ResizeBilinear` operation) or if there is simply no connection (the variable is not connected to the loss function in any way.)

Both of the following issues dealt with this and debugging would be easier if the error message was more explicit. 
- Shows a specific example where the Inception network has nodes which are not differentiable: https://github.com/tensorflow/tensorflow/issues/1758
- A more obscure but related issue: https://github.com/tensorflow/tensorflow/issues/1511
"
1767,Adaptive neural network optimized for solving specific issue,"Hey!

From Kolmogorov theorem we can accept that neural network is able to represent any function, but it is unknown what should be the specific configuration of the network.

TensorFlow has a lot of helpful parts (behind scenes back prop, learning rate decay, gradient optimizers etc), but the topology of the network (how many layers and neurons) is currently arbitrary and the best solution is found by manual testing.

Would it make sense to have auto of the box some kind of  ""find the best solution for my classification problem""? Just adding layers, neurons and autoencoders to find the best solution? 

Genetic programming of neural network. Plugin & play black box would be awesome? :)
"
1766,Multi-dimensional argmax and one-hot,"This is a feature request, unless someone can show me how the following might be done with the current API.

Say I have a tensor WxHxD, and I want to keep only the largest element in each WxH slice, setting the rest to zero. These indices could be obtained in numpy by doing something like
`(row,col) = np.unravel_index(A.argmax(), A.shape)`
on each slice WxH slice A.
Collecting the D row and column indices, I could create a boolean mask using advanced indexing
`mask[rows,cols, range(D)] = 1`
Then, an elementwise multiplication between the WxHxD tensor and the mask gives the desired tensor.
"
1763,"image processing functions should not convert dtypes unless necessary (e.g. resize/crop/transpose/rotate, ...)","### Environment info

Operating System: OSX

If installed from binary pip package, provide:
1. package: tensorflow
2. version: 0.7.1
### Steps to reproduce

Perform a resize action on a decoded jpeg before passing it to convert_image_dtype with a target of float32.  The values will still be in the range 0-255 rather than 0-1.

This line works as expected
tf.image.convert_image_dtype(tf.image.decode_jpeg(value, channels=3), tf.float32)
This line doesn't(values in the tensor are still 0-255 rather than 0-1)
tf.image.convert_image_dtype(tf.resize_images(tf.image.decode_jpeg(value, channels=3), x, y), tf.float32)
### What have you tried?
1. Changing the order as described above works.
"
1760,"TypeError in random.sample(np.array()), word2vec_basic.py with Python3.5","### Environment info

Operating System:
MacOS10.10.5 (14F1713)
1. Which pip package you installed.
    pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl
   
   git clone https://github.com/tensorflow/tensorflow
   git checkout r0.7
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".
    0.7.1
3. `numpy.version.full_version`
   
     Out[4]: '1.11.0'
   
   _Installed as described above with  pip3_, running script from commit `263d00d`
### Steps to reproduce

```
  python3 tensorflow/examples/tutorials/word2vec/word2vec_basic.py
```
### What have you tried?
1. This simple example fails:
    random.sample(np.arange(1000), 60)

it looks like it relates to [this numpy issue](https://github.com/numpy/numpy/issues/2776)
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).

```
Found and verified text8.zip
Data size 17005207
Most common words (+UNK) [['UNK', 418391], (b'the', 1061396), (b'of', 593677), (b'and', 416629), (b'one', 411764)]
Sample data [5240, 3084, 12, 6, 195, 2, 3135, 46, 59, 156]
3084 -> 5240
b'originated' -> b'anarchism'
3084 -> 12
b'originated' -> b'as'
12 -> 6
b'as' -> b'a'
12 -> 3084
b'as' -> b'originated'
6 -> 12
b'a' -> b'as'
6 -> 195
b'a' -> b'term'
195 -> 2
b'term' -> b'of'
195 -> 6
b'term' -> b'a'
Traceback (most recent call last):
  File ""tensorflow/examples/tutorials/word2vec/word2vec_basic.py"", line 131, in <module>
    valid_examples = np.array(random.sample(np.arange(valid_window), valid_size))
  File ""/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/random.py"", line 311, in sample
    raise TypeError(""Population must be a sequence or set.  For dicts, use list(d)."")
TypeError: Population must be a sequence or set.  For dicts, use list(d).
```
"
1758,Network Surgery: Changing Inputs in existing networks,"I am trying to modify an existing graph (inception) loaded using the standard approach 

```
with gfile.FastGFile(os.path.join(
      model_dir, 'classify_image_graph_def.pb'), 'r') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    _ = tf.import_graph_def(graph_def, name='')
```

The nodes are accessible using the `get_tensor_by_name` method. Here I try to replace the input to `Cast` (which is `DecodeJpeg`) with a `tf.Variable` with the same contents (allowing it to be used for optimization)

```
old_cast_node = sess.graph.get_tensor_by_name('Cast:0')
old_image_input = old_cast_node.op.inputs[0]
tf_new_image = tf.Variable(old_image_input.eval())
old_cast_node.op.inputs[0] = tf_new_image
```

Results in this error

```
TypeError: '_InputList' object does not support item assignment
```

Can the inputlist of an op be modified in any other way?
"
1757,"Running out of memory, even on small network","Operating System: Ubuntu 14.04 on a PC
Pip Installation: 64-bit, GPU-enabled, Version 0.7.1

---

My issue is that Tensor Flow is running out of memory when building my network, even though based on my calculations, there should easily be sufficient room on my GPU.

Below is a minimal example of my code, which is based on the Tensor Flow MNIST tutorial. The network is a two-layer fully-connected network, and the number of nodes in the hidden layer is defined by the variable `n`. The size of the training minibatch is 1. Here is my code:

```
n = 23000

mnist = read_data_sets('MINST_Data', one_hot=True)
session = tf.InteractiveSession()
x = tf.placeholder(tf.float32, [None, 784])
W1 = tf.Variable(tf.truncated_normal([784, n], stddev=0.1))
b1 = tf.Variable(tf.constant(0.1, shape=[n]))
nn1 = tf.matmul(x, W1) + b1
W2 = tf.Variable(tf.truncated_normal([n, 10], stddev=0.1))
b2 = tf.Variable(tf.constant(0.1, shape=[10]))
nn2 = tf.matmul(nn1, W2) + b2
y = tf.nn.softmax(nn2)
y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)
for i in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(1)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
```

Now, if `n <= 22000`, then the network runs fine. However, if `n >= 23000`, I get the following error:

```
W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state
W tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]
```

However, according to my calculations, there should not be a problem with the memory. The number of parameters in the network is as follows:

```
First layer weights: 784 * n
First layer biases: n
Second layer weights: 10 * n
Second layer biases: 10
Total: 795n + 10
```

So with `n = 23000`, and using `float32` data, the total memory required for the network should therefore be 73.1 MB.

Now, my graphics card is the NVIDIA GeForce GTX 780 Ti, which has 3072 MB of memory. After finding my graphics card, Tensor Flow prints out the following:

```
Total memory: 3.00GiB
Free memory: 2.32GiB
```

So, there should be around 2.32 GB memory available, which is far greater than the 73.1 MB calculated above. The minibatch size is 1, so this has minimal effect. Why am I getting this error?

---

I have also now tried this on my laptop, which has an NVIDIA GeForce GTX 880M GPU. Here, Tensor Flow reads out `Free memory: 7.60GiB`. Running the same code as above, it gives me a memory error at around `n = 700,000`, which is equivalent to 2.2 GB. This makes a bit more sense, and is significantly higher than the point at which my PC code breaks. However, it is still puzzling to me why it does not break closer to the 7.6 GB mark.

---

The full output from Tensor Flow whilst running the above code on my PC, with `n = 23000`, is:

```
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 780 Ti
major: 3 minor: 5 memoryClockRate (GHz) 1.0455
pciBusID 0000:01:00.0
Total memory: 3.00GiB
Free memory: 2.32GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 780 Ti, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 2.03GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0xb04720000 extends to 0xb86295000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8192):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16384):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (524288):    Total Chunks: 2, Chunks in use: 0 819.0KiB allocated for chunks. 390.6KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4194304):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (16777216):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (134217728):     Total Chunks: 1, Chunks in use: 0 68.79MiB allocated for chunks. 29.91MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (536870912):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (1073741824):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (2147483648):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:431] Bin (4294967296):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:450] Bin for 877.38MiB was 1.00GiB, Chunk State: 
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d239400 of size 80128
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7600 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d24cd00 of size 438528
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7500 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3200 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a302800 of size 920064
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15d58800 of size 920064
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7500 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736b00 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7f00 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15e39200 of size 72128000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c16b00 of size 920064
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c61500 of size 92160
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736d00 of size 72128000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8100 of size 72128000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c4ad00 of size 92160
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736a00 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b7e00 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7900 of size 400128
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720200 of size 92160
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04736c00 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08cf7600 of size 72128000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb1a3e3300 of size 1810570496
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1c0c00 of size 92160
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb08c00300 of size 92160
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d2b8000 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7800 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720100 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7700 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb04720000 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb0d1d7400 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb11781700 of size 72128000
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77d00 of size 256
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:465] Chunk at 0xb15c77e00 of size 920064
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:468]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 16 Chunks of size 256 totalling 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 80128 totalling 78.2KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 92160 totalling 450.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 400128 totalling 390.8KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 438528 totalling 428.2KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 4 Chunks of size 920064 totalling 3.51MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 5 Chunks of size 72128000 totalling 343.93MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:471] 1 Chunks of size 1810570496 totalling 1.69GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:475] Sum Total of in-use chunks: 2.03GiB
W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:211] Ran out of memory trying to allocate 877.38MiB.  See logs for memory state
W tensorflow/core/kernels/cwise_ops_common.cc:56] Resource exhausted: OOM when allocating tensor with shape[10000,23000]
W tensorflow/core/common_runtime/executor.cc:1102] 0x50f40e0 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]
     [[Node: add = Add[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](MatMul, Variable_1/read)]]
W tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]
     [[Node: add = Add[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](MatMul, Variable_1/read)]]
     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_97_range_1"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
W tensorflow/core/common_runtime/executor.cc:1102] 0x3234d30 Compute status: Resource exhausted: OOM when allocating tensor with shape[10000,23000]
     [[Node: add = Add[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](MatMul, Variable_1/read)]]
     [[Node: Cast/_11 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_96_Cast"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py"", line 232, in <module>
    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 315, in run
    return self._run(None, fetches, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 511, in _run
    feed_dict_string)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 564, in _do_run
    target_list)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 586, in _do_call
    e.code)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[10000,23000]
     [[Node: add = Add[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""](MatMul, Variable_1/read)]]
     [[Node: range_1/_13 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_97_range_1"", tensor_type=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Caused by op u'add', defined at:
  File ""/home/jrowlay/Projects/Tensor_Flow_Tutorial/MNIST_CNN_Simple/memory_test.py"", line 215, in <module>
    nn1 = tf.matmul(x, W1) + b1
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py"", line 468, in binary_op_wrapper
    return func(x, y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py"", line 44, in add
    return _op_def_lib.apply_op(""Add"", x=x, y=y, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py"", line 655, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2040, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1087, in __init__
    self._traceback = _extract_stack()
```
"
1756,Ran out of memory trying to allocate.....,"Operating System: Ubuntu 14.04
Tensor Flow: 0.7.1 (install with pip, 64-bit GPU version)

My issue is that Tensor Flow is telling me that it has run out of memory when constructing my Convolutional Neural Network. However, according to my calculations, my network should be able to fit well within the memory of my GPU.

Here is my network structure:

> ```
> Input image: 256x256, one channel
> Convolutional layer 1: 48 filters of size 11x11, max pool with 4x4 kernel and 4x4 stride
> Convolutional layer 2: 128 filters of size 5x5, max pool with 2x2 kernel and 2x2 stride
> Convolutional layer 3: 128 filters of size 3x3, no max pool
> Fully-connected layer 4: 128 * 32 * 32 input nodes and 1024 output nodes
> Fully-connected layer 5: 1024 input nodes and 10 output nodes
> ```

So, according to my calculations, the number of parameters are as follows:

> ```
> Convolutional layer 1: 48 * 11 * 11 + 48 = 5,856
> Convolutional layer 2: 128 * 48 * 5 * 5 + 128 = 153,728
> Convolutional layer 3: 128 * 128 * 3 * 3 + 128 = 147,584
> Fully-connected layer 4: 128 * 64 * 64 * 1024 + 1024 = 536,871,936
> Fully-connected layer 5: 10 * 1024 + 10 = 10,250
> 
> 
> Total:  537,189,354 (~ 2150 MB with float32 data)
> ```

And the memory required (number of nodes) to store one image on the network is:

> ```
> Input: 256 * 256 = 65,536
> Convolutional layer 1: 48 * 256 * 256 = 3,145,728
> Convolutional layer 2: 128 * 64 * 64 = 524,288
> Convolutional layer 3: 128 * 32 * 32 = 131,072
> Fully-connected layer 4: 1024
> Fully-connected layer 5: 10
> 
> Total:  3,802,122 (~ 1.52 MB with float32 data)
> ```

So the shared parameters require 2150 MB of memory, and each image requires 1.52 MB of memory.

Now, my graphics card is the NVIDA GeForce GTX 780 Ti, which has 3072 MB of memory. However, when I run the above network, even with a training minibatch size of 1, I get the following error form Tensor Flow:

> ```
> Ran out of memory trying to allocate 600.0KiB.
> Compute status: Resource exhausted: OOM when allocating tensor with shape[5,5,48,128]
> ```

Why am I getting this error? According to my calculations, the weights for the network should be able to fit on my GPU, even without any training images.

---

The full output from Tensor Flow can be found here: https://jpst.it/GKtY
"
1755,anaconda environment: install of protobuf library does not work ,"Hello,
I tried to install the special package of protobuf as proposed in [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#protobuf-library-related-issues). I get errors 
### Environment info

Operating System: MAC OSX Yosemite 10.10.5 (14F1713)

If installed from binary pip package, provide:
1. I use anaconda environment
2. created environment like ""conda create -n tf python=2.7""
3. activated environment with ""source activate tf""
4. installed easy_setup with ""sudo -H curl https://bootstrap.pypa.io/ez_setup.py -o - | python""
5. installed tensorflow with ""sudo -H pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp27-none-any.whl""
6. tested if I can import tensorflow from python. OK, no problem
7. installed protobuf by ""pip install --upgrade https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp27-none-any.whl""
8. tested again if I can import tensorflow in python. NOK

terminal showed
File ""/Users/peterhirt/anaconda/envs/tf1/lib/python2.7/site-packages/google/protobuf/descriptor.py"", line 46, in <module>
    from google.protobuf.pyext import _message
ImportError: dlopen(/Users/peterhirt/anaconda/envs/tf1/lib/python2.7/site-packages/google/protobuf/pyext/_message.so, 2): Library not loaded: /usr/local/lib/libprotobuf.10.dylib
  Referenced from: /Users/peterhirt/anaconda/envs/tf1/lib/python2.7/site-packages/google/protobuf/pyext/_message.so
  Reason: image not found

Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.

Repeated above flow twice in newly created envs to see if problem repeatable, yes ;-(

thanks for the help
"
1751,master branch building problem,"when using bazel (0.20 or 0.21 or master) to build tensorflow master branch, the process get stalled on Analyzing....
"
1750,NotImplementedError: grad(Digamma) == Polygamma(1) is not implemented,"when my graph has the digamma function
"
1749,Request: Better documentation on TFRecords and their use,"I am using TFRecords to use the sharding/queuing machinery. For simple problems for which the examples can be cloned, it is easy to use. But recently I tried to do something more complex: train examples where there are multiple labels. I posted a question on Stackoverflow about the specific issue I have: http://stackoverflow.com/questions/36365118/how-do-you-write-and-retrieve-tfrecord-features-that-are-lists

It would be nice to have clearer guidance on the use of TFRecords. I've looked through the code, have a pretty good understanding of Protocol Buffers, etc. In spite of this it is difficult to understand how the machinery works.
"
1748,Optimizers incompatible with sampling -- missing docs?,"Hi,

perhaps Tensorflow docs should mention that 5 out of 7 available optimizers will not work with sampling losses? For now, they fail with mysterious messages.

The following script will fail for Momentum, AdaGrad, AdaDelta, RMSProp and FTRL.

Also, where should I look if I'd like to implement my own optimizers for GPU?

``` python
import tensorflow as tf
import numpy.random as nr
import numpy as np

# config 
num_classes = 10000
num_sampled = 512
num_true = 32
activation_dim = 512
batch_sz = 16

# ""model"" setup
activations = tf.placeholder(tf.float32, shape=(None, activation_dim))
labels = tf.placeholder(tf.int64, shape=(None, num_true))

nce_W = tf.Variable(tf.truncated_normal((num_classes, activation_dim)))
nce_b = tf.Variable(tf.truncated_normal((num_classes, )))

nce_loss = tf.reduce_mean(
                tf.nn.nce_loss(nce_W, nce_b, 
                               activations, labels, 
                               num_sampled, num_classes, num_true))

# optimizer setup
global_step   = tf.Variable(1)
initial_alpha = tf.Variable(0.1)
alpha         = tf.Variable(0.01)

optimizer = tf.train.FtrlOptimizer(alpha)

# fetches
step = optimizer.minimize(nce_loss, global_step=global_step, name='sgd_step') 
init = tf.initialize_all_variables()

# synthetic data
X = nr.randn(batch_sz, activation_dim).astype(np.float32)
y = nr.randint(0, num_classes, (batch_sz, num_true)).astype(np.int64)

with tf.Session() as sess:
    sess.run(init)
    sess.run(step, feed_dict={activations:X, labels:y})
```

The error message is:

```
---------------------------------------------------------------------------
StatusNotOK                               Traceback (most recent call last)
StatusNotOK: Invalid argument: Cannot assign a device to node 'Variable_1/read': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/GPU:0'
     [[Node: Variable_1/read = Identity[T=DT_FLOAT, _class=[""loc:@Variable_1""]](Variable_1)]]
```
"
1747,Support OpenMP and SIMD?,"char foo(char *A, int n){
int i;
char x = 0;
# pragma omp parallel for simd

for(i = 0; i < n; i++)
x = x + A[i];
return 0;
}

$ icc test.c -c -vec-report2 -c -openmp-report2 -openmp
test.c(4): (col. 1) remark: OpenMP DEFINED LOOP WAS PARALLELIZED
test.c(5): (col. 1) remark: OpenMP SIMD LOOP WAS VECTORIZED
"
1745,install fails on ubuntu ,"install per recomendatoin from github fails on ubuntu 

sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
Downloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl

sandy@sandy-laptop:~$ sudo apt-get install python-pip python-dev
[sudo] password for sandy: 
Reading package lists... Done
Building dependency tree  
Reading state information... Done
python-pip is already the newest version.
python-dev is already the newest version.
0 upgraded, 0 newly installed, 0 to remove and 268 not upgraded.
sandy@sandy-laptop:~$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
Downloading/unpacking https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
  Downloading tensorflow-0.7.1-cp27-none-linux_x86_64.whl (13.8Mb): 13.8Mb downloaded
  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
    Traceback (most recent call last):
      File ""<string>"", line 14, in <module>
    IOError: [Errno 2] No such file or directory: '/tmp/pip-8L3Eho-build/setup.py'
    Complete output from command python setup.py egg_info:
    Traceback (most recent call last):

  File ""<string>"", line 14, in <module>

IOError: [Errno 2] No such file or directory: '/tmp/pip-8L3Eho-build/setup.py'

---

Command python setup.py egg_info failed with error code 1
Storing complete log in /home/sandy/.pip/pip.log
sandy@sandy-laptop:~$ 

GitHub issues are for bugs / installation problems / feature requests.  
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
### Environment info

Operating System:

If installed from binary pip package, provide:
1. Which pip package you installed.
2. The output from python -c ""import tensorflow; print(tensorflow.**version**)"".

If installed from sources, provide the commit hash:
### Steps to reproduce

1.
2.
3.
### What have you tried?

1.
### Logs or other output that would be helpful

(If logs are large, please upload as attachment).
"
1743,Retrain Inception Image,"I'm running Tensorflow on Ubuntu 14.04
newest version 0.7.1

when I try to retrain by using this command

python retrain.py --image_dir ~/flower

After it extract bottleneck, it shows that errors

Traceback (most recent call last):
  File ""retrain.py"", line 824, in <module>
    tf.app.run()
  File ""/home/trungdn/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""retrain.py"", line 751, in main
    bottleneck_tensor)
  File ""retrain.py"", line 673, in add_final_training_ops
    bottleneck_input = tf.placeholder_with_default(
**AttributeError: 'module' object has no attribute 'placeholder_with_default'**

Name: tensorflow
Version: 0.7.1
Location: /home/trungdn/tensorflow/lib/python2.7/site-packages
Requires: numpy, protobuf, wheel, six

I tried to git pull with update repo but it doesn't help. Thanks
"
1742,CTC: Add support for dense label matrix,"I'm working on integrating the new CTC operation into Keras and the SparseTensor used to pass the labels is causing a lot challenges due internal Keras requirements about the shape of the data going into the layers. What would be make integration trivial is an alternative dense label input format:

``` python
def ctc_loss_dense(inputs, labels, sequence_length, label_length,
             preprocess_collapse_repeated=False, ctc_merge_repeated=True):
  """"""Computes the CTC (Connectionist Temporal Classification) Loss.
  Requires:
       max_label_length <= sequence_length
  If ctc_merge_repeated is set False, then *during* CTC calculation
  repeated non-blank labels will not be merged and are interpreted
  as individual labels.  This is a simplified version of CTC.
  Args:
    inputs: 3-D `float` `Tensor` sized
      `[max_time x batch_size x num_classes]`.  The logits.
    labels: 2-D `int` `Tensor` sized
       `[max_label_length x batch_size]
    sequence_length: 1-D `int32` vector, size `[batch_size]`.
      The sequence lengths.
    label_length: 1-D `int32` vector, size `[batch_size]`.
      The label lengths.
    preprocess_collapse_repeated: Boolean.  Default: False.
      If True, repeated labels are collapsed prior to the CTC calculation.
    ctc_merge_repeated: Boolean.  Default: True.
  Returns:
    A 1-D `float` `Tensor`, size `[batch]`, containing logits.
  Raises:
    TypeError: if labels is not a `SparseTensor`.
  """"""
```

This dense input format would also be consistent with Baidu's Warp-CTC and various Theano CTC implementations, so projects using cross-library platforms like Keras would be a lot cleaner.  Also, for common CTC uses like OCR and speech processing, the sequence lengths are often a lot smaller than the input lengths, so I don't think the increased bandwidth from not having a spare tensor would be too noticeable. 
"
1741,Polygamma and zeta function for tensorflow,"The polygamma function is necessary to evaluate the derivative of the digamma function which is already supported by tensorflow. As suggested by @ebrevdo in #291, I have ported the code for the two-parameter zeta function from cephes which allows us to evaluate the polygamma function. A pull request for eigen is [here](https://bitbucket.org/eigen/eigen/pull-requests/173/added-zeta-function-of-two-arguments-and). 

What is the best way to proceed integrating the new functionality into tensorflow? I'm happy to contribute the code with a bit of input regarding the right procedure. In particular, how do you update the eigen sources within the tensorflow repo?
"
1740,Tensorflow Adam Multigpu Gradient,"I am trying to implement a network multiple gpu on tensorflow using ADAM Optimization.

I am coping the code from the Cifar10_multigpu, but it looks that when the gradient calls the second tower it calls the gradient of the first and generated error on the average of the two towers. the code of the two tower is this

```
 for d in devs:
        with tf.device(d):
            with tf.name_scope('%s_%d' % (tf_model.TOWER_NAME, i)) as scope:
                loss = tower_loss(scope)
                tf.get_variable_scope().reuse_variables()
                summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope)
                grads = opt.compute_gradients(loss)
                print('\n'.join('{}: {}'.format(*k) for k in enumerate(grads)))
                tower_grads.append(grads)
        i +=1
```

and this generates each tower:

```
stream, target= placeholder_inputs(FLAGS.batch_size*tf_model.ANGLES/FLAGS.num_gpus)
    logits = tf_model.inference_noisy_simulate(stream)
    _ = tf_model.loss(logits, target)
    losses = tf.get_collection('losses', scope)
    total_loss = tf.add_n(losses, name='total_loss')
```

looking at the gradients the first tower generate this:

```
0: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca11d0ae10>)
1: (<tf.Tensor 'tower_0/gradients/tower_0/conv1/Conv2D_grad/tuple/control_dependency_1:0' shape=(1, 1, 8, 16) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351b10>)
2: (<tf.Tensor 'tower_0/gradients/tower_0/conv1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c380dd0>)
3: (<tf.Tensor 'tower_0/gradients/tower_0/conv2/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 16, 16) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351a10>)
4: (<tf.Tensor 'tower_0/gradients/tower_0/conv2/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c3a6dd0>)
5: (<tf.Tensor 'tower_0/gradients/tower_0/conv3/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 16, 32) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c3a6490>)
6: (<tf.Tensor 'tower_0/gradients/tower_0/conv3/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351990>)
7: (<tf.Tensor 'tower_0/gradients/tower_0/conv4/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 32, 64) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351890>)
8: (<tf.Tensor 'tower_0/gradients/tower_0/conv4/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c3b7790>)
9: (<tf.Tensor 'tower_0/gradients/tower_0/conv5/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 64, 128) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2d9110>)
10: (<tf.Tensor 'tower_0/gradients/tower_0/conv5/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2849d0>)
11: (<tf.Tensor 'tower_0/gradients/tower_0/conv6/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 128, 256) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2e6f10>)
12: (<tf.Tensor 'tower_0/gradients/tower_0/conv6/BiasAdd_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2afed0>)
13: (<tf.Tensor 'tower_0/gradients/tower_0/fc1/MatMul_grad/tuple/control_dependency_1:0' shape=(18944, 4096) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c1f9550>)
14: (<tf.Tensor 'tower_0/gradients/tower_0/fc1/add_grad/tuple/control_dependency_1:0' shape=(4096,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c214a10>)
15: (<tf.Tensor 'tower_0/gradients/tower_0/fc1_1/MatMul_grad/tuple/control_dependency_1:0' shape=(4096, 1024) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c23dfd0>)
16: (<tf.Tensor 'tower_0/gradients/tower_0/fc1_1/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c269bd0>)
17: (<tf.Tensor 'tower_0/gradients/tower_0/softmax_linear/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 360) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c1d1a50>)
18: (<tf.Tensor 'tower_0/gradients/tower_0/softmax_linear/softmax_linear_grad/tuple/control_dependency_1:0' shape=(360,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c1def50>)
```

and the second generates this;

```
0: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca11d0ae10>)
1: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351b10>)
2: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c380dd0>)
3: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351a10>)
4: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c3a6dd0>)
5: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c3a6490>)
6: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351990>)
7: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c351890>)
8: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c3b7790>)
9: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2d9110>)
10: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2849d0>)
11: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2e6f10>)
12: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c2afed0>)
13: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c1f9550>)
14: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c214a10>)
15: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c23dfd0>)
16: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c269bd0>)
17: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c1d1a50>)
18: (None, <tensorflow.python.ops.variables.Variable object at 0x7fca0c1def50>)
19: (<tf.Tensor 'tower_1/gradients/tower_1/conv1/Conv2D_grad/tuple/control_dependency_1:0' shape=(1, 1, 8, 16) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0c178c50>)
20: (<tf.Tensor 'tower_1/gradients/tower_1/conv1/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bfbb490>)
21: (<tf.Tensor 'tower_1/gradients/tower_1/conv2/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 16, 16) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bfda950>)
22: (<tf.Tensor 'tower_1/gradients/tower_1/conv2/BiasAdd_grad/tuple/control_dependency_1:0' shape=(16,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf91bd0>)
23: (<tf.Tensor 'tower_1/gradients/tower_1/conv3/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 16, 32) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bfcb590>)
24: (<tf.Tensor 'tower_1/gradients/tower_1/conv3/BiasAdd_grad/tuple/control_dependency_1:0' shape=(32,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf39e90>)
25: (<tf.Tensor 'tower_1/gradients/tower_1/conv4/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 32, 64) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf499d0>)
26: (<tf.Tensor 'tower_1/gradients/tower_1/conv4/BiasAdd_grad/tuple/control_dependency_1:0' shape=(64,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf14fd0>)
27: (<tf.Tensor 'tower_1/gradients/tower_1/conv5/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 64, 128) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf39150>)
28: (<tf.Tensor 'tower_1/gradients/tower_1/conv5/BiasAdd_grad/tuple/control_dependency_1:0' shape=(128,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bebd8d0>)
29: (<tf.Tensor 'tower_1/gradients/tower_1/conv6/Conv2D_grad/tuple/control_dependency_1:0' shape=(45, 4, 128, 256) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf23110>)
30: (<tf.Tensor 'tower_1/gradients/tower_1/conv6/BiasAdd_grad/tuple/control_dependency_1:0' shape=(256,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf04610>)
31: (<tf.Tensor 'tower_1/gradients/tower_1/fc1/MatMul_grad/tuple/control_dependency_1:0' shape=(18944, 4096) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bebdc50>)
32: (<tf.Tensor 'tower_1/gradients/tower_1/fc1/add_grad/tuple/control_dependency_1:0' shape=(4096,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bebd310>)
33: (<tf.Tensor 'tower_1/gradients/tower_1/fc1_1/MatMul_grad/tuple/control_dependency_1:0' shape=(4096, 1024) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0be96e10>)
34: (<tf.Tensor 'tower_1/gradients/tower_1/fc1_1/add_grad/tuple/control_dependency_1:0' shape=(1024,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0be96990>)
35: (<tf.Tensor 'tower_1/gradients/tower_1/softmax_linear/MatMul_grad/tuple/control_dependency_1:0' shape=(1024, 360) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0be52c90>)
36: (<tf.Tensor 'tower_1/gradients/tower_1/softmax_linear/softmax_linear_grad/tuple/control_dependency_1:0' shape=(360,) dtype=float32>, <tensorflow.python.ops.variables.Variable object at 0x7fca0bf56f50>)
```

I am wondering how to remove from the second the first None, but no targeting indexes so i can make for more towers.
"
1737,android:tensorflow_demo issue..,"`poporo@poporo-All-Series://tensorflow/tensorflow/examples/android$ bazel build //tensorflow/examples/android:tensorflow_demo

WARNING: /tensorflow/tensorflow/core/BUILD:638:9: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.
.
.
.
INFO: Found 1 target...
WARNING: failed to create one or more convenience symlinks for prefix 'bazel-':
  cannot create symbolic link bazel-out -> /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out:  /tensorflow/bazel-out (Permission denied)
  cannot create symbolic link bazel-tensorflow -> /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow:  /tensorflow/bazel-tensorflow (Permission denied)
  cannot create symbolic link bazel-bin -> /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-opt/bin:  /tensorflow/bazel-bin (Permission denied)
  cannot create symbolic link bazel-testlogs -> /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-opt/testlogs:  /tensorflow/bazel-testlogs (Permission denied)
  cannot create symbolic link bazel-genfiles -> /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-opt/genfiles:  /tensorflow/bazel-genfiles (Permission denied).
ERROR: /tensorflow/tensorflow/examples/android/BUILD:63:1: Processing resources failed: resources_processor failed: error executing command bazel-out/host/bin/external/bazel_tools/tools/android/resources_processor --buildToolsVersion 23.0.1 --aapt bazel-out/host/bin/external/androidsdk/aapt_binary --annotationJar ... (remaining 13 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Error: bazel-out/host/bin/external/androidsdk/aapt_binary: line 3: /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/host/bin/external/androidsdk/aapt_binary.runfiles/external/androidsdk/build-tools/23.0.1/aapt: No such file or directory
.
.
.
.
Apr 01, 2016 10:48:05 AM com.google.devtools.build.android.AndroidResourceProcessingAction main
SEVERE: Error during merging resources
Error: Failed to run command:
    bazel-out/host/bin/external/androidsdk/aapt_binary s -i /tmp/android_resources_tmp1623410823562764165/tmp-deduplicated/tensorflow/examples/android/res/drawable-hdpi/ic_launcher.png -o /tmp/android_resources_tmp1623410823562764165/merged_resources/drawable-hdpi-v4/ic_launcher.png
Error Code:
    1
Output:
    bazel-out/host/bin/external/androidsdk/aapt_binary: line 3: /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/host/bin/external/androidsdk/aapt_binary.runfiles/external/androidsdk/build-tools/23.0.1/aapt: No such file or directory

```
at com.android.ide.common.res2.MergeWriter.end(MergeWriter.java:54)
at com.android.ide.common.res2.MergedResourceWriter.end(MergedResourceWriter.java:113)
at com.android.ide.common.res2.DataMerger.mergeData(DataMerger.java:291)
at com.android.ide.common.res2.ResourceMerger.mergeData(ResourceMerger.java:48)
at com.google.devtools.build.android.AndroidResourceProcessor.mergeData(AndroidResourceProcessor.java:390)
at com.google.devtools.build.android.AndroidResourceProcessingAction.main(AndroidResourceProcessingAction.java:321)
```

Caused by: com.android.ide.common.internal.LoggedErrorException: Failed to run command:
    bazel-out/host/bin/external/androidsdk/aapt_binary s -i /tmp/android_resources_tmp1623410823562764165/tmp-deduplicated/tensorflow/examples/android/res/drawable-hdpi/ic_launcher.png -o /tmp/android_resources_tmp1623410823562764165/merged_resources/drawable-hdpi-v4/ic_launcher.png
Error Code:
    1
Output:
    bazel-out/host/bin/external/androidsdk/aapt_binary: line 3: /home/poporo/.cache/bazel/_bazel_poporo/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/host/bin/external/androidsdk/aapt_binary.runfiles/external/androidsdk/build-tools/23.0.1/aapt: No such file or directory

```
at com.android.ide.common.internal.CommandLineRunner.runCmdLine(CommandLineRunner.java:123)
at com.android.ide.common.internal.CommandLineRunner.runCmdLine(CommandLineRunner.java:96)
at com.android.ide.common.internal.AaptCruncher.crunchPng(AaptCruncher.java:58)
at com.android.ide.common.res2.MergedResourceWriter$1.call(MergedResourceWriter.java:188)
at com.android.ide.common.res2.MergedResourceWriter$1.call(MergedResourceWriter.java:139)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
at java.util.concurrent.FutureTask.run(FutureTask.java:266)
at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
at java.lang.Thread.run(Thread.java:745)
```

Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 7.359s, Critical Path: 4.34s
`

help me..
"
1736,Batch normalization for RNNs,"I realize that this is hot off the press, but since batch normalization for feed forward layers is being added, any chance we can see it for RNNs? The performance improvements seem substantial.

http://arxiv.org/abs/1603.09025
"
1734,Random functions always return 0 when using CUDA 7.5 ,"### Environment info

Operating System:
Ubuntu 14.04.3 LTS

If installed from sources, provide the commit hash: 48e6165fc864d0a222571507613c63c77ec6bf61
### Steps to reproduce
1. Compile from source and during `./configure` process specify CUDA 7.5
2. Run the following script

```
import tensorflow as tf
v = tf.Variable(tf.truncated_normal([3,2], mean = 12.0, stddev = 0.1))
sess = tf.InteractiveSession()
sess.run(tf.initialize_all_variables())
sess.run(v)
```
1. The result is 3x2 array of zeros rather than random value centered at 12.0. The same happens for all random variables
### To solve it

Use CUDA 7.0 solved the problem for me.
"
1733,rnn.dynamic_rnn() causes gradients graph building error,"I found rnn.dynamic_rnn() that seems to do what I want, but when I modified the following lines 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/ptb_word_lm.py#L114-L116 into 

```
from tensorflow.models.rnn import rnn
outputs, state = rnn.dynamic_rnn(cell, inputs, initial_state=self._initial_state)
output = tf.reshape(outputs, [-1, size])
```

It throws out error at the line containing `tf.gradients(cost, tvars)`

```
  File ""/data/lisatmp3/yaoli/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""ptb_word_lm.py"", line 304, in main
    m = PTBModel(is_training=True, config=config)
  File ""ptb_word_lm.py"", line 148, in __init__
    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),
  File ""/data/lisatmp3/yaoli/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 477, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""/data/lisatmp3/yaoli/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_grad.py"", line 137, in _TensorArrayPackGrad
    grad_source = _GetGradSource(grad)
  File ""/data/lisatmp3/yaoli/anaconda/lib/python2.7/site-packages/tensorflow/python/ops/tensor_array_grad.py"", line 62, in _GetGradSource
    % op_or_tensor.name)
ValueError: Expected op/tensor name to start with gradients, got: model/gradients/model/RNN/transpose_grad/transpose:0
Uncaught exception. Entering post mortem debugging
Running 'cont' or 'step' will restart the program
```

I couldn't find any examples in the repo of using dynamic_rnn(), and hope someone could point out where it went wrong. The complete file is attached below (adapted based on `tensorflow/tensorflow/models/rnn/ptb/ptb_word_lm.py`). LOOP_VERSION=0 and 1 run all right, 2 raises the issue.  

```
# Copyright 2015 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

""""""Example / benchmark for building a PTB LSTM model.

Trains the model described in:
(Zaremba, et. al.) Recurrent Neural Network Regularization
http://arxiv.org/abs/1409.2329

There are 3 supported model configurations:
===========================================
| config | epochs | train | valid  | test
===========================================
| small  | 13     | 37.99 | 121.39 | 115.91
| medium | 39     | 48.45 |  86.16 |  82.07
| large  | 55     | 37.87 |  82.62 |  78.29
The exact results may vary depending on the random initialization.

The hyperparameters used in the model:
- init_scale - the initial scale of the weights
- learning_rate - the initial value of the learning rate
- max_grad_norm - the maximum permissible norm of the gradient
- num_layers - the number of LSTM layers
- num_steps - the number of unrolled steps of LSTM
- hidden_size - the number of LSTM units
- max_epoch - the number of epochs trained with the initial learning rate
- max_max_epoch - the total number of epochs for training
- keep_prob - the probability of keeping weights in the dropout layer
- lr_decay - the decay of the learning rate for each epoch after ""max_epoch""
- batch_size - the batch size

The data required for this example is in the data/ dir of the
PTB dataset from Tomas Mikolov's webpage:

$ wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz
$ tar xvf simple-examples.tgz

To run:

$ python ptb_word_lm.py --data_path=simple-examples/data/

""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import time

import numpy as np
import tensorflow as tf

from tensorflow.models.rnn.ptb import reader

flags = tf.flags
logging = tf.logging

flags.DEFINE_string(
    ""model"", ""small"",
    ""A type of model. Possible options are: small, medium, large."")
flags.DEFINE_string(""data_path"", None, ""data_path"")

FLAGS = flags.FLAGS

LOOP_VERSION = 2

class PTBModel(object):
  """"""The PTB model.""""""

  def __init__(self, is_training, config):
    self.batch_size = batch_size = config.batch_size
    self.num_steps = num_steps = config.num_steps
    size = config.hidden_size
    vocab_size = config.vocab_size

    self._input_data = tf.placeholder(tf.int32, [batch_size, num_steps])
    self._targets = tf.placeholder(tf.int32, [batch_size, num_steps])

    # Slightly better results can be obtained with forget gate biases
    # initialized to 1 but the hyperparameters of the model would need to be
    # different than reported in the paper.
    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(size, forget_bias=0.0)
    if is_training and config.keep_prob < 1:
      lstm_cell = tf.nn.rnn_cell.DropoutWrapper(
          lstm_cell, output_keep_prob=config.keep_prob)
    cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * config.num_layers)
    self._initial_state = cell.zero_state(batch_size, tf.float32)

    with tf.device(""/cpu:0""):
      embedding = tf.get_variable(""embedding"", [vocab_size, size])
      inputs = tf.nn.embedding_lookup(embedding, self._input_data) # (b, t, 200)

    if is_training and config.keep_prob < 1:
      inputs = tf.nn.dropout(inputs, config.keep_prob)

    # Simplified version of tensorflow.models.rnn.rnn.py's rnn().
    # This builds an unrolled LSTM for tutorial purposes only.
    # In general, use the rnn() or state_saving_rnn() from rnn.py.
    #
    # The alternative version of the code below is:
    if LOOP_VERSION == 0:
      from tensorflow.models.rnn import rnn
      inputs = [tf.squeeze(input_, [1])
               for input_ in tf.split(1, num_steps, inputs)]
      outputs, state = rnn.rnn(cell, inputs, initial_state=self._initial_state)
      output = tf.reshape(tf.concat(1, outputs), [-1, size])
    if LOOP_VERSION == 1:
      outputs = []
      state = self._initial_state
      with tf.variable_scope(""RNN""):
        for time_step in range(num_steps):
          if time_step > 0: tf.get_variable_scope().reuse_variables()
          (cell_output, state) = cell(inputs[:, time_step, :], state)
          outputs.append(cell_output)
      output = tf.reshape(tf.concat(1, outputs), [-1, size])
    if LOOP_VERSION == 2:
      from tensorflow.models.rnn import rnn
      # inputs: (b,t,d)
      outputs, state = rnn.dynamic_rnn(cell, inputs, initial_state=self._initial_state)
      output = tf.reshape(outputs, [-1, size])

    softmax_w = tf.get_variable(""softmax_w"", [size, vocab_size])
    softmax_b = tf.get_variable(""softmax_b"", [vocab_size])
    logits = tf.matmul(output, softmax_w) + softmax_b
    loss = tf.nn.seq2seq.sequence_loss_by_example(
        [logits],
        [tf.reshape(self._targets, [-1])],
        [tf.ones([batch_size * num_steps])])
    self._cost = cost = tf.reduce_sum(loss) / batch_size
    self._final_state = state

    if not is_training:
      return

    self._lr = tf.Variable(0.0, trainable=False)
    tvars = tf.trainable_variables()
    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),
                                      config.max_grad_norm)

    optimizer = tf.train.GradientDescentOptimizer(self.lr)
    self._train_op = optimizer.apply_gradients(zip(grads, tvars))

  def assign_lr(self, session, lr_value):
    session.run(tf.assign(self.lr, lr_value))

  @property
  def input_data(self):
    return self._input_data

  @property
  def targets(self):
    return self._targets

  @property
  def initial_state(self):
    return self._initial_state

  @property
  def cost(self):
    return self._cost

  @property
  def final_state(self):
    return self._final_state

  @property
  def lr(self):
    return self._lr

  @property
  def train_op(self):
    return self._train_op


class SmallConfig(object):
  """"""Small config.""""""
  init_scale = 0.1
  learning_rate = 1.0
  max_grad_norm = 5
  num_layers = 2
  num_steps = 20
  hidden_size = 200
  max_epoch = 4
  max_max_epoch = 13
  keep_prob = 1.0
  lr_decay = 0.5
  batch_size = 20
  vocab_size = 10000


class MediumConfig(object):
  """"""Medium config.""""""
  init_scale = 0.05
  learning_rate = 1.0
  max_grad_norm = 5
  num_layers = 2
  num_steps = 35
  hidden_size = 650
  max_epoch = 6
  max_max_epoch = 39
  keep_prob = 0.5
  lr_decay = 0.8
  batch_size = 20
  vocab_size = 10000


class LargeConfig(object):
  """"""Large config.""""""
  init_scale = 0.04
  learning_rate = 1.0
  max_grad_norm = 10
  num_layers = 2
  num_steps = 35
  hidden_size = 1500
  max_epoch = 14
  max_max_epoch = 55
  keep_prob = 0.35
  lr_decay = 1 / 1.15
  batch_size = 20
  vocab_size = 10000


class TestConfig(object):
  """"""Tiny config, for testing.""""""
  init_scale = 0.1
  learning_rate = 1.0
  max_grad_norm = 1
  num_layers = 1
  num_steps = 2
  hidden_size = 2
  max_epoch = 1
  max_max_epoch = 1
  keep_prob = 1.0
  lr_decay = 0.5
  batch_size = 20
  vocab_size = 10000


def run_epoch(session, m, data, eval_op, verbose=False):
  """"""Runs the model on the given data.""""""
  epoch_size = ((len(data) // m.batch_size) - 1) // m.num_steps
  start_time = time.time()
  costs = 0.0
  iters = 0
  state = m.initial_state.eval()
  for step, (x, y) in enumerate(reader.ptb_iterator(data, m.batch_size,
                                                    m.num_steps)):
    cost, state, _ = session.run([m.cost, m.final_state, eval_op],
                                 {m.input_data: x,
                                  m.targets: y,
                                  m.initial_state: state})
    costs += cost
    iters += m.num_steps

    if verbose and step % (epoch_size // 10) == 10:
      print(""%.3f perplexity: %.3f speed: %.0f wps"" %
            (step * 1.0 / epoch_size, np.exp(costs / iters),
             iters * m.batch_size / (time.time() - start_time)))

  return np.exp(costs / iters)


def get_config():
  if FLAGS.model == ""small"":
    return SmallConfig()
  elif FLAGS.model == ""medium"":
    return MediumConfig()
  elif FLAGS.model == ""large"":
    return LargeConfig()
  elif FLAGS.model == ""test"":
    return TestConfig()
  else:
    raise ValueError(""Invalid model: %s"", FLAGS.model)


def main(_):
  if not FLAGS.data_path:
    raise ValueError(""Must set --data_path to PTB data directory"")

  raw_data = reader.ptb_raw_data(FLAGS.data_path)
  # train: 929589, valid: 73760, test: 82430
  train_data, valid_data, test_data, _ = raw_data

  config = get_config()
  eval_config = get_config()
  eval_config.batch_size = 1
  eval_config.num_steps = 1

  with tf.Graph().as_default(), tf.Session() as session:
    initializer = tf.random_uniform_initializer(-config.init_scale,
                                                config.init_scale)
    with tf.variable_scope(""model"", reuse=None, initializer=initializer):
      m = PTBModel(is_training=True, config=config)
    with tf.variable_scope(""model"", reuse=True, initializer=initializer):
      mvalid = PTBModel(is_training=False, config=config)
      mtest = PTBModel(is_training=False, config=eval_config)

    tf.initialize_all_variables().run()

    for i in range(config.max_max_epoch):
      lr_decay = config.lr_decay ** max(i - config.max_epoch, 0.0)
      m.assign_lr(session, config.learning_rate * lr_decay)

      print(""Epoch: %d Learning rate: %.3f"" % (i + 1, session.run(m.lr)))
      train_perplexity = run_epoch(session, m, train_data, m.train_op,
                                   verbose=True)
      print(""Epoch: %d Train Perplexity: %.3f"" % (i + 1, train_perplexity))
      valid_perplexity = run_epoch(session, mvalid, valid_data, tf.no_op())
      print(""Epoch: %d Valid Perplexity: %.3f"" % (i + 1, valid_perplexity))

    test_perplexity = run_epoch(session, mtest, test_data, tf.no_op())
    print(""Test Perplexity: %.3f"" % test_perplexity)


if __name__ == ""__main__"":
  tf.app.run()


```
"
1727,GPU resources not released when session is closed,"As I understand from the documentation, running `sess.close()` is supposed to release the resources, but it doesn't. I have been running the following test:

``` python
with tf.Session() as sess:
    with tf.device('/gpu:0'):
        matrix1 = tf.constant([[3., 3]])
        matrix2 = tf.constant([[2.], [2.]])
        product = tf.matmul(matrix1, matrix2)
        result = sess.run(product)
        print(result)
```

This allocates all the free memory of gpu0, but it is not released when `sess` is closed (both using a context manager as in the code above, but also when calling `sess.close()` manually). The memory usage persists until that Python process is terminated. The way I have been checking memory usage is through `nvidia-smi`, but I have also confirmed that other processes can't allocate that GPU memory until the process terminates (not the session closes). I would like to be able to free the resources and still keep the Python process running.
### Environment info

I am running a 64-bit Linux (CentOS) with a computer that has two Tesla K40c (driver 346.46, CUDA 7.0). I installed the 0.7.1 tensorflow for Linux and Python 3.4 through pip. The output of `tf.__version__` is 0.7.1.
### Steps to reproduce

Simply running the code above should according to the document allocate and then release the memory. However, the GPU memory is still allocated and thus unusable by other processes. However, it can be re-used by the same Python process, meaning that I can re-run the snippet over and over as long as I do it from the same Python process.
### Logs or other output that would be helpful

Here is a log of the session. At the end, the memory is still allocated. Note that another user is connected to both GPUs through Torch7, and is actively using gpu0.

``` python
In [1]: import tensorflow as tf
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally

In [2]: with tf.Session() as sess:
    with tf.device('/gpu:1'):
        matrix1 = tf.constant([[3., 3]])
        matrix2 = tf.constant([[2.], [2.]])
        product = tf.matmul(matrix1, matrix2)
        result = sess.run(product)
        print(result)
   ...:
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:03:00.0
Total memory: 11.25GiB
Free memory: 3.27GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties:
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:82:00.0
Total memory: 11.25GiB
Free memory: 11.05GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:82:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.50GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 1 memory begins at 0x4208f40000 extends to 0x44a8b030cd
[[ 12.]]

In [3]: 
```
"
1725,scan / TensorArray bug,"### Environment info

Operating System: CentOS 6.7
If installed from sources, provide the commit hash: b4b276e
### Issue

According to https://github.com/tensorflow/tensorflow/issues/208, `scan` will soon be part of the public API.

The snippet of code

```
from __future__ import division, print_function
import tensorflow as tf
from tensorflow.python.ops import functional_ops

def fn(previous_state, current_input):
    return previous_state + current_input

x = tf.Variable([0.0, 1.0, 2.0, 3.0, 4.0])
y = functional_ops.scan(fn, x, parallel_iterations=1)

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())
    print(sess.run(y))
```

results in the error below.

I get the same error
- whether or not I use a REPL
- whether or not I define `x` and `y` inside of a `with tf.device('/cpu:0')` block
- whether or not `swap_memory` is `True`
- whether or not I use soft device placement

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-1-73ddd8c32a4f> in <module>()
     10 
     11 with tf.Session() as sess:
---> 12     sess.run(tf.initialize_all_variables())
     13     print(sess.run(y))

/home-4/rdipiet2@jhu.edu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    331     try:
    332       result = self._run(None, fetches, feed_dict, options_ptr,
--> 333                          run_metadata_ptr)
    334       if run_metadata:
    335         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home-4/rdipiet2@jhu.edu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    536     # Run request and get response.
    537     results = self._do_run(handle, target_list, unique_fetches,
--> 538                            feed_dict_string, options, run_metadata)
    539 
    540     # User may have fetched the same tensor multiple times, but we

/home-4/rdipiet2@jhu.edu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
    599     if handle is None:
    600       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
--> 601                            target_list, options, run_metadata)
    602     else:
    603       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home-4/rdipiet2@jhu.edu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
    606   def _do_call(self, fn, *args):
    607     try:
--> 608       return fn(*args)
    609     except tf_session.StatusNotOK as e:
    610       error_message = compat.as_text(e.error_message)

/home-4/rdipiet2@jhu.edu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)
    583                 run_metadata):
    584       # Ensure any changes to the graph are reflected in the runtime.
--> 585       self._extend_graph()
    586       if options:
    587         return tf_session.TF_Run(session, options,

/home-4/rdipiet2@jhu.edu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _extend_graph(self)
    636               self._session, graph_def.SerializeToString(), status)
    637           if tf_session.TF_GetCode(status) != 0:
--> 638             raise RuntimeError(compat.as_text(tf_session.TF_Message(status)))
    639           self._opened = True
    640         finally:

RuntimeError: AttrValue must not have reference type value of float_ref
     for attr 'dtype'
    ; NodeDef: scan/TensorArray = TensorArray[dtype=DT_FLOAT_REF, dynamic_size=false, tensor_array_name=""""](scan/Squeeze); Op<name=TensorArray; signature=size:int32 -> handle:Ref(string); attr=dtype:type; attr=dynamic_size:bool,default=false; attr=tensor_array_name:string,default=""""; is_stateful=true>
```
"
1724,Updating ExponentialMovingAverage based on a condition,"Using tensorflow 0.7.1.

I have followed issue #804 to make use of batch normalization with tensorflow. However, I struggle to get the snippet to work as expected and have nailed down the problem to something more concise.

Let us assume we want to perform a moving average over incoming scalars; sometimes we want to update the statistics of that moving average, sometimes we don't. We will model that with a placeholder `do_update`, which we can set to `True` or `False` in the `feed_dict` passed to `sess.run(...)`. Basically, this is the code from #804 but greatly simplified.

```
import tensorflow as tf
import numpy as np

inpt = tf.Variable(np.array([1.]))
do_update = tf.placeholder(tf.bool)

ema = tf.train.ExponentialMovingAverage(.9)
ema_assign = ema.apply([inpt])


def update():
    with tf.control_dependencies([ema_assign]):
        return tf.identity(ema.average(inpt))      # note the identity.

def no_update():
    return ema.average(inpt)

run = tf.python.control_flow_ops.cond(do_update, update, no_update)
```

However, when I execute `run` updating will happen. It does not matter what the value of `do_update` is.

```
print run.eval({inpt: np.array([2.]), do_update: True})
print run.eval({inpt: np.array([2.]), do_update: True})
print run.eval({inpt: np.array([2.]), do_update: True})

# prints:
# [ 1.10000002]
# [ 1.19000004]
# [ 1.27100006]

print run.eval({inpt: np.array([2.]), do_update: False})
print run.eval({inpt: np.array([2.]), do_update: False})
print run.eval({inpt: np.array([2.]), do_update: False})

# prints:
# [ 1.34390007]
# [ 1.40951008]
# [ 1.46855908]
```

Curiously, if I remove the `tf.identity` above in the definition of `update`, neither of them performs an update after starting a new session.

```
print run.eval({inpt: np.array([2.]), do_update: True})
print run.eval({inpt: np.array([2.]), do_update: True})
print run.eval({inpt: np.array([2.]), do_update: True})

# prints:
# [ 1.]
# [ 1.]
# [ 1.]

print run.eval({inpt: np.array([2.]), do_update: False})
print run.eval({inpt: np.array([2.]), do_update: False})
print run.eval({inpt: np.array([2.]), do_update: False})

# prints:
# [ 1.]
# [ 1.]
# [ 1.]
```

This seems as uninteded behaviour to me, but maybe I am missing something.
"
1723,"tf.concat(tensorA, tensorB) should throw an error","### Environment info

Operating System: Ubuntu 15.10
CPU-only pip package, version 0.7.1
### Steps to reproduce

```
import tensorflow as tf
a = tf.Variable(tf.constant(1.0, shape=[10]))
b = tf.Variable(tf.constant(2.0, shape=[10]))
print tf.concat(a, b) # <tf.Tensor 'concat:0' shape=(10,) dtype=float32>
```

Since the second argument to concat can be converted into a list of length 1, tensorflow takes a fast-path and immediately returns it, before type-checking the first argument. I would have expected an error that enabled me to find my incorrect API usage.
"
1722,The nightly gpu builds for python 3 are failing consistently,"The nightly gpu builds for python 3 are failing some tests consistently.

In the [most recent console output log](http://ci.tensorflow.org/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-working/50/consoleFull), the following 4 tests seem to fail: (each item links to the relevant test output log)
- [(66 / 224) Python test-on-install FAILED (): tensorflow/python/kernel_tests/bias_op_test.py](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-working/ws/pip_test/tests/logs/tensorflow/python/kernel_tests/bias_op_test.py.log)
- [(75 / 224) Python test-on-install FAILED (): tensorflow/python/kernel_tests/conv_ops_test.py](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-working/ws/pip_test/tests/logs/tensorflow/python/kernel_tests/conv_ops_test.py.log)
- [(93 / 224) Python test-on-install FAILED (): tensorflow/python/kernel_tests/fft_ops_test.py](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-working/ws/pip_test/tests/logs/tensorflow/python/kernel_tests/fft_ops_test.py.log)
- [(120 / 224) Python test-on-install FAILED (): tensorflow/python/kernel_tests/pooling_ops_test.py](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-working/ws/pip_test/tests/logs/tensorflow/python/kernel_tests/pooling_ops_test.py.log)

(Also: The link in the [readme file](https://github.com/tensorflow/tensorflow/blob/master/README.md) to the nightly gpu builds for python 3 seems to pointing to some old build that hasn't been updated for a week?)
"
1720,Eigen version in cmake mismatch,"In `tensorflow/contrib/cmake/external/eigen.cmake`, both `eigen_archive_hash` and `eigen_HASH` don't match those in `tensorflow/workspace.bzl` and the source (e.g. `third_party/eigen3/Eigen/Cholesky`). This leads to build failure when using cmake.

Could anyone update `tensorflow/contrib/cmake/external/eigen.cmake`?
"
1714,translate.py -- dev set batches,"The code to evaluate the dev set at each checkpoint selects a random sample from the dev set for each bucket which is only as large as the minibatch size.

This seems very non-standard to have such a small dev set that changes from checkpoint to checkpoint.

I modified my code to use a larger fixed dev set, but getting errors because the shape of the model depends on the batch size.

```
tensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [260,512] vs. [64,512]
     [[Node: model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/add_2 = Add[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/add_1, model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/SparseToDense)]]
Caused by op u'model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/add_2', defined at:

```

Any suggestions for constructing model so that it accommodates a flexible batch size?

I suppose this a feature request to update translate.py, otherwise let me know if I should take this issue over to Stack Overflow.
"
1711,error import tensorflow,"I have installed the tensorflow and set the environment variables. However I got the following error when importing tensor flow:

ImportError: /myproject/lib/python2.7/sitepackages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header

Can anyone help me? Thanks
"
1707,Clip gradients option in contrib.layers.optimize_loss broken,"Using the nightly build from 30 Mar 2016 trying to call:

```
train_op = tf.contrib.layers.optimize_loss(train_loss,
              global_step,
              0.002,
              ""Adam"",
              clip_gradients=10.0)
```

will throw:

```
TypeError: List of Tensors when single Tensor expected
```

I think `opt.compute_gradients()` returns a list of tuples not tensors so [line 106](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/optimizers.py#L106) needs to replace `gradients` with `[g[0] for g in gradients]`.
"
